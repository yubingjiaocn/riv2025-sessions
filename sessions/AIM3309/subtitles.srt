1
00:00:01,080 --> 00:00:02,490
- Hello everyone.

2
00:00:02,490 --> 00:00:03,900
Nice to see you all here.

3
00:00:03,900 --> 00:00:06,090
Hope everyone got to Vegas safely

4
00:00:06,090 --> 00:00:09,420
and ready for a great re:Invent.

5
00:00:09,420 --> 00:00:11,220
My name is Prashanth Ganapathy

6
00:00:11,220 --> 00:00:13,680
I'm a Senior Solutions Architect with AWS.

7
00:00:13,680 --> 00:00:16,530
I've been with AWS for
about five years now.

8
00:00:16,530 --> 00:00:17,850
I just completed five years,

9
00:00:17,850 --> 00:00:19,740
but I've been in the
solution architecting role

10
00:00:19,740 --> 00:00:21,660
for about 20 years now.

11
00:00:21,660 --> 00:00:24,990
And my claim to fame is I was doing AI/ML

12
00:00:24,990 --> 00:00:27,960
before it was cool like three years ago,

13
00:00:27,960 --> 00:00:30,630
so helping customers in AWS

14
00:00:30,630 --> 00:00:35,400
with AI/ML technology
since I joined in 2020.

15
00:00:35,400 --> 00:00:37,650
But I'm excited to be here today

16
00:00:37,650 --> 00:00:39,850
and share Slack's journey

17
00:00:40,800 --> 00:00:42,420
of their Developer Experience group

18
00:00:42,420 --> 00:00:46,200
and their internal developers,
how they used Generative AI

19
00:00:46,200 --> 00:00:49,470
and then eventually agents
over the last couple of years

20
00:00:49,470 --> 00:00:52,110
and what kind of success they saw.

21
00:00:52,110 --> 00:00:53,850
And that's what we'll be sharing today.

22
00:00:53,850 --> 00:00:58,500
With me is Srivani and
Mani from AWS and Slack

23
00:00:58,500 --> 00:01:00,660
and I'll let them introduce themselves.

24
00:01:00,660 --> 00:01:03,720
- Thank you Prashanth, hello
everyone, I'm Srivani Bethi.

25
00:01:03,720 --> 00:01:07,980
I'm a Staff Software Engineer
on DevXP-AI team at Slack.

26
00:01:07,980 --> 00:01:09,960
I've been with Slack for about seven years

27
00:01:09,960 --> 00:01:14,223
and I've been on DevXP-AI
team for about three years.

28
00:01:15,090 --> 00:01:18,450
So today I'm very excited to
share some of our learnings

29
00:01:18,450 --> 00:01:20,613
and journey in developing AI tooling.

30
00:01:21,570 --> 00:01:23,190
- Awesome.
- Thanks Srivani,

31
00:01:23,190 --> 00:01:27,300
Mani here I lead the
strategic ISV accounts,

32
00:01:27,300 --> 00:01:29,373
the GenAI, the cool stuff.

33
00:01:30,330 --> 00:01:32,310
I've been working with AWS for five years

34
00:01:32,310 --> 00:01:34,080
and like this entire journey I've worked

35
00:01:34,080 --> 00:01:36,420
with some of our largest ISV providers

36
00:01:36,420 --> 00:01:38,160
and our product teams.

37
00:01:38,160 --> 00:01:41,280
So basically helping
customers put their ideas

38
00:01:41,280 --> 00:01:42,870
into actual work

39
00:01:42,870 --> 00:01:45,180
and then helping our product
teams develop their roadmap.

40
00:01:45,180 --> 00:01:47,280
So consider me as a bridge

41
00:01:47,280 --> 00:01:49,140
between the customers
and our product teams.

42
00:01:49,140 --> 00:01:52,470
And today here to share
about all the good work

43
00:01:52,470 --> 00:01:53,643
that we did with Slack.

44
00:01:54,630 --> 00:01:57,080
That's what the session
is going to be all about.

45
00:01:59,310 --> 00:02:01,800
So before we get started,
quick show of hands,

46
00:02:01,800 --> 00:02:04,593
how many of you checked
your Slack before coming in?

47
00:02:06,330 --> 00:02:10,710
Exactly, Slack is where I would
say the work truly happens.

48
00:02:10,710 --> 00:02:14,790
You know, we get into
conversations, this is where ideas,

49
00:02:14,790 --> 00:02:16,890
you know, turn out, they become decisions.

50
00:02:16,890 --> 00:02:19,930
Decisions become actions in turn

51
00:02:20,820 --> 00:02:23,910
and every idea that turns into action,

52
00:02:23,910 --> 00:02:28,910
the teams are talking, building
in Slack every single day.

53
00:02:28,950 --> 00:02:32,460
And because of that,
Slack can never slow down.

54
00:02:32,460 --> 00:02:35,340
They have to be fast,
they have to be reliable,

55
00:02:35,340 --> 00:02:37,320
and they have to be secure.

56
00:02:37,320 --> 00:02:39,750
All of this at a scale.

57
00:02:39,750 --> 00:02:41,040
Now, as Slack continues

58
00:02:41,040 --> 00:02:44,493
to grow across different
enterprises across the world,

59
00:02:45,660 --> 00:02:48,030
the innovation becomes
absolutely critical.

60
00:02:48,030 --> 00:02:50,790
And that's what I would say AWS comes in.

61
00:02:50,790 --> 00:02:54,810
You know, AWS came in
and helped Slack develop

62
00:02:54,810 --> 00:02:56,520
and build things faster.

63
00:02:56,520 --> 00:03:00,240
It helped, it unlocked the
new levels of innovation.

64
00:03:00,240 --> 00:03:02,460
So in this session we'll
talk about how Bedrock kind

65
00:03:02,460 --> 00:03:04,860
of became the foundation that powers

66
00:03:04,860 --> 00:03:07,530
and governs this next chapter for Slack.

67
00:03:07,530 --> 00:03:09,750
And I love the quote from Andy Jassy,

68
00:03:09,750 --> 00:03:12,390
which says that "together AWS

69
00:03:12,390 --> 00:03:15,180
and Slack are giving
developer teams the ability

70
00:03:15,180 --> 00:03:17,307
to collaborate and innovate faster."

71
00:03:18,930 --> 00:03:23,340
Now this is quick and easy,
what we are gonna cover today.

72
00:03:23,340 --> 00:03:25,050
First I'll share a little bit

73
00:03:25,050 --> 00:03:27,990
about the Slack's Developer
Experience AI journey,

74
00:03:27,990 --> 00:03:31,680
that's the Slack team using Bedrock.

75
00:03:31,680 --> 00:03:32,550
Then we'll talk about

76
00:03:32,550 --> 00:03:36,570
how Slack rolled out the
code assistant tools,

77
00:03:36,570 --> 00:03:38,760
follow it up with the real impact

78
00:03:38,760 --> 00:03:39,990
because I think that's important

79
00:03:39,990 --> 00:03:41,610
on the developer community.

80
00:03:41,610 --> 00:03:42,810
And then we'll explore

81
00:03:42,810 --> 00:03:46,950
how Slack is now moving
into Agents and Strands.

82
00:03:46,950 --> 00:03:50,220
And finally we close,
what's the road ahead?

83
00:03:50,220 --> 00:03:51,060
What does it look like?

84
00:03:51,060 --> 00:03:53,070
So by the end of this session,

85
00:03:53,070 --> 00:03:56,460
you'll see not just what
Slack built, why they built it

86
00:03:56,460 --> 00:03:58,950
and how they built it,

87
00:03:58,950 --> 00:04:01,230
I promise no pop quiz at the end,

88
00:04:01,230 --> 00:04:03,870
but hopefully you'll
get some few good ideas

89
00:04:03,870 --> 00:04:07,203
that you can take back and
implement in your work life.

90
00:04:08,850 --> 00:04:11,490
Now this slide is really about the people

91
00:04:11,490 --> 00:04:15,660
behind the Slack
Developer Experience team.

92
00:04:15,660 --> 00:04:20,610
The team that build this
integration, it exists

93
00:04:20,610 --> 00:04:24,210
to make the life of
Slack engineers better.

94
00:04:24,210 --> 00:04:26,580
They bring in AI closer to developers

95
00:04:26,580 --> 00:04:28,890
and they remove the
friction from everyday work.

96
00:04:28,890 --> 00:04:31,650
While we use Slack for
our day-to-day work,

97
00:04:31,650 --> 00:04:36,300
how do we make the
developers much more agile

98
00:04:36,300 --> 00:04:38,430
and much more productive?

99
00:04:38,430 --> 00:04:39,630
So this journey started

100
00:04:39,630 --> 00:04:43,500
by Slack Developer team building
something called Buddy Bot

101
00:04:43,500 --> 00:04:45,300
to help build documentation, you know,

102
00:04:45,300 --> 00:04:48,870
to help these developer answer
these questions more quickly.

103
00:04:48,870 --> 00:04:52,230
And today this team touches
everything they build,

104
00:04:52,230 --> 00:04:54,120
they touch the build and release tools,

105
00:04:54,120 --> 00:04:58,470
they have the testing
infrastructure, they developer tools,

106
00:04:58,470 --> 00:05:00,540
they develop these tools at scale

107
00:05:00,540 --> 00:05:01,620
and they're roundabout,

108
00:05:01,620 --> 00:05:04,380
I think Srivani like 70 to 80 people.

109
00:05:04,380 --> 00:05:07,500
They are powering the entire
Slack engineering team.

110
00:05:07,500 --> 00:05:08,820
And then, you know, even further

111
00:05:08,820 --> 00:05:11,283
to the Salesforce organization.

112
00:05:12,510 --> 00:05:14,700
What I would like to
highlight is what's powerful

113
00:05:14,700 --> 00:05:17,760
about this team is that their approach,

114
00:05:17,760 --> 00:05:19,530
they start internally fast.

115
00:05:19,530 --> 00:05:24,390
So they kind of build
something, put it for a POC

116
00:05:24,390 --> 00:05:25,470
or internal usage.

117
00:05:25,470 --> 00:05:27,930
They roll it out at a
smaller engineering team

118
00:05:27,930 --> 00:05:30,840
and once they are able
to prove it successful,

119
00:05:30,840 --> 00:05:33,030
they roll it out to a bigger audience.

120
00:05:33,030 --> 00:05:38,030
So this team is a huge
reason for Slack to move fast

121
00:05:38,280 --> 00:05:42,003
and to move things very
quickly without breaking it.

122
00:05:44,790 --> 00:05:47,289
Now before I jump into
Slack's journey, you know,

123
00:05:47,289 --> 00:05:49,110
between Srivani and Prashanth
they're gonna talk about

124
00:05:49,110 --> 00:05:50,460
how they implemented.

125
00:05:50,460 --> 00:05:55,110
I quickly wanted to level set
on the AWS Stack that exists

126
00:05:55,110 --> 00:05:59,470
that the team used to
build this entire solution.

127
00:05:59,470 --> 00:06:03,030
So at the foundation level,
we have our Amazon SageMaker

128
00:06:03,030 --> 00:06:05,040
and AI Compute

129
00:06:05,040 --> 00:06:09,720
that basically Developer
teams can use to build,

130
00:06:09,720 --> 00:06:11,790
train and deploy custom models

131
00:06:11,790 --> 00:06:14,763
and they manage their own data and MLOps.

132
00:06:16,800 --> 00:06:19,470
About this layer is our Amazon Bedrock,

133
00:06:19,470 --> 00:06:23,130
which is a fully managed
foundation model layer.

134
00:06:23,130 --> 00:06:26,520
Now this is where if the
teams want to move faster,

135
00:06:26,520 --> 00:06:29,850
they want to experiment,
Bedrock gives you a choice

136
00:06:29,850 --> 00:06:32,580
of leading model providers.

137
00:06:32,580 --> 00:06:36,330
It gives you built in guardrails,
it has knowledge basis

138
00:06:36,330 --> 00:06:39,090
for RAG, Retrieval-Augmented Generation,

139
00:06:39,090 --> 00:06:41,520
and it has multiple
flexible hosting options.

140
00:06:41,520 --> 00:06:42,930
Pay as you go.

141
00:06:42,930 --> 00:06:45,810
You can probably, you know, pay up front

142
00:06:45,810 --> 00:06:49,230
and all of this in the most secure way

143
00:06:49,230 --> 00:06:51,930
that you can scale very quickly.

144
00:06:51,930 --> 00:06:56,040
We also had launched AgentCore,
which handles a lot of,

145
00:06:56,040 --> 00:06:59,250
you know, plumbing in the
end, like think about runtime,

146
00:06:59,250 --> 00:07:01,800
identity, memory, observability.

147
00:07:01,800 --> 00:07:04,290
All of this can be done through AgentCore

148
00:07:04,290 --> 00:07:07,083
and by the team focuses
on the agent tech work.

149
00:07:08,370 --> 00:07:11,730
Now on top of these are our SDK agents,

150
00:07:11,730 --> 00:07:14,190
which is more like frameworks,

151
00:07:14,190 --> 00:07:15,420
which we will talk about today,

152
00:07:15,420 --> 00:07:17,460
the Strands Agents.

153
00:07:17,460 --> 00:07:22,460
And we also have our first
party model called Nova Act.

154
00:07:24,000 --> 00:07:26,700
And on top of all of
this finally is the layer

155
00:07:26,700 --> 00:07:30,900
of applications like Kiro and Quick Suite,

156
00:07:30,900 --> 00:07:32,250
which is like if you really want

157
00:07:32,250 --> 00:07:34,110
to plug it in into your application,

158
00:07:34,110 --> 00:07:35,460
you use these applications.

159
00:07:35,460 --> 00:07:37,650
So that's like a complete stack

160
00:07:37,650 --> 00:07:39,690
and we would be referring to some

161
00:07:39,690 --> 00:07:42,150
of these while we talk
through the presentation.

162
00:07:42,150 --> 00:07:46,560
So in simple terms, SageMaker
is where you build models,

163
00:07:46,560 --> 00:07:49,980
Bedrock is where you can scale safely.

164
00:07:49,980 --> 00:07:52,590
Strands is where you bring agents to life

165
00:07:52,590 --> 00:07:55,800
and your top layer applications
is where you deliver.

166
00:07:55,800 --> 00:07:59,460
So now with this in the
mind, let's move on to see

167
00:07:59,460 --> 00:08:02,253
how Slack build a story.

168
00:08:03,780 --> 00:08:06,210
One of my favorite slides

169
00:08:06,210 --> 00:08:11,210
because it shows how Slack
actually build this step by step.

170
00:08:13,200 --> 00:08:17,880
Now they, if you see this
started way back in Q2 of 2023,

171
00:08:17,880 --> 00:08:20,970
almost like two years back with SageMaker

172
00:08:20,970 --> 00:08:23,070
at this time it was all about learning.

173
00:08:23,070 --> 00:08:26,193
GenAI was picking up, you
know, everybody was so excited.

174
00:08:27,090 --> 00:08:30,090
So they started
experimenting, prototyping.

175
00:08:30,090 --> 00:08:33,633
And this is probably the reason one thing

176
00:08:33,633 --> 00:08:35,490
that the service SageMaker was Slack

177
00:08:35,490 --> 00:08:39,930
has a really strict requirement
of being FedRAMP compliant

178
00:08:39,930 --> 00:08:42,210
and SageMaker gave him that option.

179
00:08:42,210 --> 00:08:46,530
And when it came to Q3
2023, they all started

180
00:08:46,530 --> 00:08:48,210
with an Internal Hackathon.

181
00:08:48,210 --> 00:08:50,580
And this is where things
got real, you know,

182
00:08:50,580 --> 00:08:53,970
teams experimented, they built prototypes

183
00:08:53,970 --> 00:08:56,400
and they even created things
like Huddle summaries.

184
00:08:56,400 --> 00:08:58,470
I don't know if you
have seen that in Slack

185
00:08:58,470 --> 00:09:00,780
that also a part of this Hackathon.

186
00:09:00,780 --> 00:09:03,990
Now this is a phase which
was all about, you know,

187
00:09:03,990 --> 00:09:06,900
proving the art of possible
what all you can do it.

188
00:09:06,900 --> 00:09:11,040
And then Q1, 2024, Slack
moved to Amazon Bedrock

189
00:09:11,040 --> 00:09:14,490
because Bedrock was now FedRAMP compliant.

190
00:09:14,490 --> 00:09:17,910
All the latest Anthropic models
were available on Bedrock

191
00:09:17,910 --> 00:09:19,410
and infrastructure got easier.

192
00:09:19,410 --> 00:09:22,080
They really didn't have to
take care of infrastructure.

193
00:09:22,080 --> 00:09:24,240
With Bedrock, it was like everything,

194
00:09:24,240 --> 00:09:25,980
you just pull in a feature

195
00:09:25,980 --> 00:09:27,420
and it's all taken care of.

196
00:09:27,420 --> 00:09:30,330
All the undifferentiated
heavy lifting was done by them

197
00:09:30,330 --> 00:09:35,100
and they nearly saved 98% of the costs

198
00:09:35,100 --> 00:09:36,663
when they moved to Bedrock.

199
00:09:38,160 --> 00:09:41,850
Now as they got familiar
with Bedrock, you know,

200
00:09:41,850 --> 00:09:46,290
came Q2 of 2024, they came up

201
00:09:46,290 --> 00:09:48,510
with the first bot called Buddy Bot.

202
00:09:48,510 --> 00:09:50,820
And as I mentioned, this
is more like helping

203
00:09:50,820 --> 00:09:52,860
with documentation, helping, you know,

204
00:09:52,860 --> 00:09:55,230
developers find things more easily.

205
00:09:55,230 --> 00:09:58,893
And the good part is while
they were building this,

206
00:09:58,893 --> 00:10:01,170
they started using knowledge bases.

207
00:10:01,170 --> 00:10:04,110
So nobody had to manage
their Vector source anymore.

208
00:10:04,110 --> 00:10:06,660
Developers just got better on embeddings,

209
00:10:06,660 --> 00:10:10,800
they got better knowledge
bases, they got faster answers.

210
00:10:10,800 --> 00:10:14,970
Now as they build Buddy Bot by Q1 2025,

211
00:10:14,970 --> 00:10:17,460
the developers being
developers, they started asking

212
00:10:17,460 --> 00:10:20,160
for coding assistance, they
said, can we go further?

213
00:10:20,160 --> 00:10:22,140
Can we build Coding Assistance?

214
00:10:22,140 --> 00:10:26,220
And that is where Anthropic,
they started experiment

215
00:10:26,220 --> 00:10:27,330
with Cursor and Claude Code.

216
00:10:27,330 --> 00:10:30,090
And since Anthropic models
were anywhere available

217
00:10:30,090 --> 00:10:31,920
and they were the
foundation of all the things

218
00:10:31,920 --> 00:10:34,110
that they built, it was very easy for them

219
00:10:34,110 --> 00:10:36,030
to use Claude Code and Cursor.

220
00:10:36,030 --> 00:10:39,570
And they were adopted right on Bedrock.

221
00:10:39,570 --> 00:10:42,810
And then finally in Q2 of, or finally,

222
00:10:42,810 --> 00:10:46,510
but in Q2 of 2025, Slack
took a critical step

223
00:10:48,060 --> 00:10:50,400
but obvious to build agents

224
00:10:50,400 --> 00:10:53,190
because Agent Tech was
the new way to access data

225
00:10:53,190 --> 00:10:55,080
through MCP servers.

226
00:10:55,080 --> 00:10:57,150
They didn't rush into A2A

227
00:10:57,150 --> 00:11:01,260
because they just wanted to
spend time learning that.

228
00:11:01,260 --> 00:11:04,080
I said Slack didn't get
into analysis paralysis

229
00:11:04,080 --> 00:11:06,090
they wanted to take it slow.

230
00:11:06,090 --> 00:11:08,310
They built their first MCP Server

231
00:11:08,310 --> 00:11:12,780
and they got into the
foundation of building agents.

232
00:11:12,780 --> 00:11:16,420
And then in Q3, 2025,
Slack introduced Strands

233
00:11:17,490 --> 00:11:21,390
and the Escalation Bot,
which Srivani is gonna talk

234
00:11:21,390 --> 00:11:24,600
in more details, it's how
they move from Buddy Bot

235
00:11:24,600 --> 00:11:27,840
to Escalation Bot using
Strands and Agents.

236
00:11:27,840 --> 00:11:31,980
Strands is an open-source,
multi model agnostic

237
00:11:31,980 --> 00:11:34,890
and flexible framework that we have.

238
00:11:34,890 --> 00:11:37,920
And if you're on an agentic
journey, you know, we would love

239
00:11:37,920 --> 00:11:40,110
for you to use that and
we'll talk more about it.

240
00:11:40,110 --> 00:11:43,110
So I would just say the
biggest takeaway here is

241
00:11:43,110 --> 00:11:45,030
Slack did not get stuck

242
00:11:45,030 --> 00:11:47,430
in the whole analysis paralysis thing.

243
00:11:47,430 --> 00:11:50,280
They kept experimenting,
they kept shipping

244
00:11:50,280 --> 00:11:51,930
and they kept learning from it.

245
00:11:51,930 --> 00:11:54,690
So today they have scaled

246
00:11:54,690 --> 00:11:58,020
from processing a few
100,000 tokens per minute

247
00:11:58,020 --> 00:12:00,030
to millions of tokens per minute.

248
00:12:00,030 --> 00:12:03,120
It's just like basically
AI now instead of jogging,

249
00:12:03,120 --> 00:12:04,950
it's sprinting all thanks

250
00:12:04,950 --> 00:12:07,440
to Anthropics one million context window.

251
00:12:07,440 --> 00:12:09,480
They just move from a few tokens

252
00:12:09,480 --> 00:12:10,980
to million tokens in a minute.

253
00:12:14,220 --> 00:12:15,780
Now the question is,

254
00:12:15,780 --> 00:12:19,830
why did Slack ultimately
standardize on Bedrock?

255
00:12:19,830 --> 00:12:21,180
Like why Bedrock?

256
00:12:21,180 --> 00:12:22,860
I think first thing that they loved is

257
00:12:22,860 --> 00:12:25,113
that it's a unified platform across AWS.

258
00:12:25,980 --> 00:12:30,980
One, place to build, scale
and govern everything.

259
00:12:31,530 --> 00:12:33,510
Second, I think it is very important

260
00:12:33,510 --> 00:12:36,030
and it's Job Zero for us
is the built in security

261
00:12:36,030 --> 00:12:38,700
that we have within Bedrock,
the guardrails that we have

262
00:12:38,700 --> 00:12:41,040
and the governance that we have in place.

263
00:12:41,040 --> 00:12:43,980
So guardrail, security, compliance,

264
00:12:43,980 --> 00:12:47,790
it was all built in as a part of Bedrock.

265
00:12:47,790 --> 00:12:50,460
And third was the massive scalability.

266
00:12:50,460 --> 00:12:53,760
Slack isn't running one AI use cases,

267
00:12:53,760 --> 00:12:55,800
it is running multiple UI cases,

268
00:12:55,800 --> 00:12:58,590
AI cases across multiple
different organizations

269
00:12:58,590 --> 00:13:01,380
with thousand, hundreds
and thousands of employees.

270
00:13:01,380 --> 00:13:04,800
And all of this happened
without Slack needing

271
00:13:04,800 --> 00:13:06,780
to worry about the infrastructure.

272
00:13:06,780 --> 00:13:09,330
And I think that's the move from SageMaker

273
00:13:09,330 --> 00:13:11,250
to Bedrock really helped them.

274
00:13:11,250 --> 00:13:15,840
Now Bedrock led them
focus truly what matters,

275
00:13:15,840 --> 00:13:19,140
building an amazing Developer Experience

276
00:13:19,140 --> 00:13:20,733
and user experiences around it.

277
00:13:23,820 --> 00:13:25,770
Now let's bring this home like

278
00:13:25,770 --> 00:13:27,240
before I hand it over to Srivani.

279
00:13:27,240 --> 00:13:31,350
In terms of impact, like
with an AI-assisted coding

280
00:13:31,350 --> 00:13:35,130
using Cursor and Claude
Code on Amazon Bedrock,

281
00:13:35,130 --> 00:13:38,940
Slack completely changed
how fast ideas turn

282
00:13:38,940 --> 00:13:41,883
and were shipped into the actual features.

283
00:13:43,770 --> 00:13:45,150
Quick show of hands, how many

284
00:13:45,150 --> 00:13:48,983
of you think the productivity
would've gone up by 20%?

285
00:13:50,430 --> 00:13:55,380
Nobody thinks, okay,
there's mine maybe 50%.

286
00:13:55,380 --> 00:13:57,330
Is that too big of a number?

287
00:13:57,330 --> 00:14:01,590
Oh wow, I have 50% more than,
okay, so here's what we know

288
00:14:01,590 --> 00:14:05,850
for sure that it accelerated
the developer productivity.

289
00:14:05,850 --> 00:14:09,450
It empowered the teams to innovate faster

290
00:14:09,450 --> 00:14:13,680
and it massively reduced
the prototyping time.

291
00:14:13,680 --> 00:14:15,840
But instead of guessing the numbers,

292
00:14:15,840 --> 00:14:18,480
I'm going to hand it over
to Srivani who is going

293
00:14:18,480 --> 00:14:19,860
to show you the actual numbers

294
00:14:19,860 --> 00:14:22,413
and the real results
behind this infrastructure.

295
00:14:24,960 --> 00:14:26,003
- Thank you, Mani.

296
00:14:30,420 --> 00:14:33,483
I think one of the measuring impact,

297
00:14:34,590 --> 00:14:38,070
how many of you here
have some kind of metrics

298
00:14:38,070 --> 00:14:41,043
to measure AI impact on
developer productivity?

299
00:14:43,170 --> 00:14:45,390
Cool, quite a few.

300
00:14:45,390 --> 00:14:47,520
I think we are all talking about AI,

301
00:14:47,520 --> 00:14:50,490
but I think one of the hardest
problem, hardest question

302
00:14:50,490 --> 00:14:53,313
to answer is, is it actually helping?

303
00:14:55,350 --> 00:14:57,900
I think in order to answer that,

304
00:14:57,900 --> 00:15:00,483
we need to know what to
measure, how to measure.

305
00:15:01,410 --> 00:15:05,970
So we initially started with
like two foundational metrics,

306
00:15:05,970 --> 00:15:09,060
AI adoption, which means basically

307
00:15:09,060 --> 00:15:12,330
if engineers are adopting AI tooling,

308
00:15:12,330 --> 00:15:13,890
it's actually a first sign

309
00:15:13,890 --> 00:15:16,320
of like it's helping them relieve pain

310
00:15:16,320 --> 00:15:18,423
in one of their workflows.

311
00:15:19,890 --> 00:15:22,230
The other part of it is impact

312
00:15:22,230 --> 00:15:24,900
on Developer Experience metrics like DORA

313
00:15:24,900 --> 00:15:26,253
and SPACE Metrics.

314
00:15:28,380 --> 00:15:29,550
To measure these metrics,

315
00:15:29,550 --> 00:15:32,970
we needed data from multiple data sources.

316
00:15:32,970 --> 00:15:37,410
So we used Open Telemetry
Metrics, plumped into all

317
00:15:37,410 --> 00:15:41,640
of our AI tooling to get the usage metrics

318
00:15:41,640 --> 00:15:45,363
and some of the AI tool
calls and all of that.

319
00:15:46,590 --> 00:15:50,250
We also measure metrics from
GitHub, our source code,

320
00:15:50,250 --> 00:15:52,050
like pull requests and commits,

321
00:15:52,050 --> 00:15:54,660
which are co-authored by AI

322
00:15:54,660 --> 00:15:57,900
and also have some kind of AI signature.

323
00:15:57,900 --> 00:16:01,620
So these metrics helped us
get like not a perfect metric,

324
00:16:01,620 --> 00:16:03,960
but overall a good estimate of

325
00:16:03,960 --> 00:16:06,753
how developers are impacted using AI.

326
00:16:08,070 --> 00:16:10,803
Let's talk about the overall
developer impact here.

327
00:16:13,440 --> 00:16:16,080
With all of the tools we have rolled out,

328
00:16:16,080 --> 00:16:17,970
we have seen consistent

329
00:16:17,970 --> 00:16:21,630
like week over week
adoption rates increase

330
00:16:21,630 --> 00:16:24,000
and we've also seen consistent usage

331
00:16:24,000 --> 00:16:27,183
of these tools month over
month for a few months now.

332
00:16:28,470 --> 00:16:33,180
Currently 99% of our
developers are using some kind

333
00:16:33,180 --> 00:16:36,873
of AI assistance, which is huge.

334
00:16:38,250 --> 00:16:40,523
Once we got the adoption
numbers we are looking for,

335
00:16:40,523 --> 00:16:43,983
then we started looking into
developer productivity metrics.

336
00:16:44,970 --> 00:16:47,950
We started looking at PR throughput

337
00:16:49,080 --> 00:16:53,790
and observed that some of the
major repositories we have,

338
00:16:53,790 --> 00:16:57,660
we are seeing about 25% consistent
month over month increase

339
00:16:57,660 --> 00:16:58,713
in the PR throughput.

340
00:17:00,270 --> 00:17:04,833
There are also other metrics,
but this has been consistent.

341
00:17:06,810 --> 00:17:10,530
The other metrics we are looking
into is AI Bot assistance,

342
00:17:10,530 --> 00:17:12,570
which Mani just talked about.

343
00:17:12,570 --> 00:17:15,810
It's a bot we rolled out
to help our engineers

344
00:17:15,810 --> 00:17:17,790
with knowledge search and also help them

345
00:17:17,790 --> 00:17:19,710
with the escalations.

346
00:17:19,710 --> 00:17:22,620
So Escalations at Slack happen in Slack

347
00:17:22,620 --> 00:17:25,260
when users have questions,
they come into Escal channels

348
00:17:25,260 --> 00:17:28,083
and escalate it to the appropriate teams.

349
00:17:28,980 --> 00:17:32,820
This was causing a lot of on-call
fatigue for our engineers.

350
00:17:32,820 --> 00:17:34,620
So we rolled out AI assistance

351
00:17:34,620 --> 00:17:37,203
to help engineers ease the on-call pain.

352
00:17:38,070 --> 00:17:40,650
And currently our AI
assistance Bot is helping

353
00:17:40,650 --> 00:17:43,533
over 5,000 escalation requests per month.

354
00:17:45,600 --> 00:17:47,820
And the final metric

355
00:17:47,820 --> 00:17:51,780
and the most important is
the qualitative metric,

356
00:17:51,780 --> 00:17:53,853
which is the direct developer feedback.

357
00:17:54,780 --> 00:17:57,630
And the feedback we've
been receiving confirms

358
00:17:57,630 --> 00:18:00,153
that these tools are
actually helping developers.

359
00:18:02,970 --> 00:18:06,790
I think with all of those tools

360
00:18:07,740 --> 00:18:10,440
of course AI is not perfect.

361
00:18:10,440 --> 00:18:12,120
We are also seeing downsides

362
00:18:12,120 --> 00:18:14,850
of increase in peer review time.

363
00:18:14,850 --> 00:18:17,567
As AI is helping
engineers write more code,

364
00:18:17,567 --> 00:18:19,920
we are also seeing that the surface area

365
00:18:19,920 --> 00:18:21,630
for review is increasing

366
00:18:21,630 --> 00:18:23,730
and it's causing more load for developers.

367
00:18:25,179 --> 00:18:27,420
We are actively working on this area

368
00:18:27,420 --> 00:18:31,470
to reduce the review
time with AI assistance

369
00:18:31,470 --> 00:18:34,650
and we are hoping we'll implement AI

370
00:18:34,650 --> 00:18:37,050
to ease developer pain across all

371
00:18:37,050 --> 00:18:39,303
of the developer cycle.

372
00:18:43,530 --> 00:18:45,303
Learnings and experiences.

373
00:18:46,320 --> 00:18:50,640
We have seen the metrics 99% adoption

374
00:18:50,640 --> 00:18:53,460
and 25% PR throughput.

375
00:18:53,460 --> 00:18:56,073
But the path to get here,
it wasn't a straight line.

376
00:18:57,060 --> 00:19:00,030
Like many of you, we
started our AI journey

377
00:19:00,030 --> 00:19:01,170
with experimentation,

378
00:19:01,170 --> 00:19:03,210
with PR experimentation
like three years ago,

379
00:19:03,210 --> 00:19:05,043
like Mani just talked about.

380
00:19:06,300 --> 00:19:10,230
We built our initial capabilities
using SageMaker and RAG.

381
00:19:10,230 --> 00:19:12,300
This gave us maximum control,

382
00:19:12,300 --> 00:19:15,330
but it also came with a huge hidden cost

383
00:19:15,330 --> 00:19:17,223
of infrastructure maintenance.

384
00:19:18,240 --> 00:19:21,453
Our breakthrough came in
when we adopted AWS Bedrock.

385
00:19:22,800 --> 00:19:24,783
This wasn't a technology change,

386
00:19:25,950 --> 00:19:28,680
it also is a philosophy shift for us.

387
00:19:28,680 --> 00:19:33,030
Bedrock instantly simplified
our infrastructure handling all

388
00:19:33,030 --> 00:19:36,333
of the LLM scale and
infrastructure maintenance for us.

389
00:19:37,860 --> 00:19:39,760
This change immediately addressed

390
00:19:40,860 --> 00:19:43,803
our critical success factors for adoption.

391
00:19:50,880 --> 00:19:52,113
Like security,

392
00:19:53,430 --> 00:19:55,290
Bedrock allowed us to keep everything

393
00:19:55,290 --> 00:20:00,290
within our AWS accounts
secure and also adoption.

394
00:20:02,100 --> 00:20:05,250
So making LLMs available
through a proxy API,

395
00:20:05,250 --> 00:20:08,250
we were able to provide LLM
access to all of our developers

396
00:20:08,250 --> 00:20:11,553
to experiment using AI.

397
00:20:16,170 --> 00:20:19,087
And the other one.

398
00:20:19,087 --> 00:20:22,170
(indistinct chatter)

399
00:20:25,680 --> 00:20:26,513
Oops.

400
00:20:27,692 --> 00:20:30,775
(indistinct chatter)

401
00:20:42,463 --> 00:20:45,120
- Is it working?
- It's working.

402
00:20:46,440 --> 00:20:47,823
- Slides are not changing.

403
00:20:52,080 --> 00:20:54,593
- It's not working, the slides are not.

404
00:20:56,190 --> 00:20:58,110
The other advantage we also got

405
00:20:58,110 --> 00:21:01,320
with switching to
Bedrock is observability.

406
00:21:01,320 --> 00:21:03,900
So the inbuilt native
observability of Bedrock

407
00:21:03,900 --> 00:21:07,470
of CloudWatch logs and metrics
and alerts helped us get

408
00:21:07,470 --> 00:21:10,773
into some insights into our LLM usage.

409
00:21:13,050 --> 00:21:13,883
Thank you.

410
00:21:20,520 --> 00:21:21,540
Through our journey,

411
00:21:21,540 --> 00:21:24,570
one of the main challenge
we faced was experimental,

412
00:21:24,570 --> 00:21:28,353
experimentation fatigue with
different LLMs and tools.

413
00:21:29,340 --> 00:21:31,990
The AI landscape is changing so fast

414
00:21:32,850 --> 00:21:35,190
and we are struggling to keep up.

415
00:21:35,190 --> 00:21:37,230
We realize that constantly rolling

416
00:21:37,230 --> 00:21:39,550
out new competing internal features

417
00:21:40,590 --> 00:21:43,350
was only causing confusion to developers

418
00:21:43,350 --> 00:21:46,353
and also cost maintenance overhead for us.

419
00:21:47,340 --> 00:21:48,510
So to combat that,

420
00:21:48,510 --> 00:21:53,160
we doubled down on a high impact
tech stack, Amazon Bedrock

421
00:21:53,160 --> 00:21:56,130
and Anthropic models and tooling.

422
00:21:56,130 --> 00:21:59,940
We drove adoption by integrating
tools like Claude Code

423
00:21:59,940 --> 00:22:02,550
and Cursor with Bedrock.

424
00:22:02,550 --> 00:22:05,130
In fact, I think we were
one of the first teams,

425
00:22:05,130 --> 00:22:08,400
our first company to roll
out Claude Code early

426
00:22:08,400 --> 00:22:09,573
in Q2 of this year.

427
00:22:10,680 --> 00:22:13,450
The goal here was to
create seamless experience

428
00:22:14,310 --> 00:22:16,110
that maximizes throughput

429
00:22:16,110 --> 00:22:19,623
and reduces the decision
fatigue for our developers.

430
00:22:23,730 --> 00:22:26,070
Now I'm going to hand off
to my colleague Prashanth

431
00:22:26,070 --> 00:22:28,770
to talk about Agentic frameworks.

432
00:22:28,770 --> 00:22:29,920
- Thank you Srivani.

433
00:22:31,500 --> 00:22:34,560
Those were some insightful and learnings

434
00:22:34,560 --> 00:22:38,073
and some impressive
statistics right from Srivani.

435
00:22:39,000 --> 00:22:42,210
As you all saw and heard
from Srivani and Mani,

436
00:22:42,210 --> 00:22:45,630
Slack started the journey
in AI developer tools

437
00:22:45,630 --> 00:22:47,520
and using Amazon Bedrock

438
00:22:47,520 --> 00:22:50,073
and saw some impressive early success.

439
00:22:50,910 --> 00:22:53,520
But I'm here to talk about the next stage

440
00:22:53,520 --> 00:22:55,470
in the Agentic journey, right.

441
00:22:55,470 --> 00:22:58,290
This is the year of agents, gotta hear why

442
00:22:58,290 --> 00:23:00,240
and what they're doing with agents.

443
00:23:00,240 --> 00:23:02,310
So quick show of hands, how many

444
00:23:02,310 --> 00:23:06,753
of you here are exploring
agents in your organization?

445
00:23:07,830 --> 00:23:08,910
Yeah, quite a few.

446
00:23:08,910 --> 00:23:12,003
And how many of you have
agents running in production?

447
00:23:13,140 --> 00:23:16,650
Alright, some of you maybe we
should talk to later as well

448
00:23:16,650 --> 00:23:18,093
and learn from you, right.

449
00:23:20,220 --> 00:23:24,060
So the key questions are, you know,

450
00:23:24,060 --> 00:23:25,290
why agents, right?

451
00:23:25,290 --> 00:23:26,940
Besides the obvious answer,

452
00:23:26,940 --> 00:23:29,850
because everybody else is
doing it and we have to do it.

453
00:23:29,850 --> 00:23:33,090
But for Slack there were
some key questions, right.

454
00:23:33,090 --> 00:23:35,640
So as they were using these
coding assistant tools

455
00:23:35,640 --> 00:23:38,490
and using the LLMs through APIs,

456
00:23:38,490 --> 00:23:41,820
a lot of their actions were
Ad-Hoc workflows, right.

457
00:23:41,820 --> 00:23:44,880
So they would, for example,
there's a issue going on

458
00:23:44,880 --> 00:23:47,160
and would take the logs and
dump it into Claude Code

459
00:23:47,160 --> 00:23:48,420
and say what's going on

460
00:23:48,420 --> 00:23:50,400
and Claude Code would answer it, right.

461
00:23:50,400 --> 00:23:51,810
But that's an Ad-Hoc workflow.

462
00:23:51,810 --> 00:23:54,180
Now imagine on-call engineers
that are getting lots

463
00:23:54,180 --> 00:23:56,730
of these requests, they
want automated runbooks

464
00:23:56,730 --> 00:23:57,690
to be running, right.

465
00:23:57,690 --> 00:23:59,610
So they want to take that to the next step

466
00:23:59,610 --> 00:24:02,130
where agents are
processing what the ask is,

467
00:24:02,130 --> 00:24:05,130
choosing the right tools,
making those decisions,

468
00:24:05,130 --> 00:24:08,340
and then doing the, you know, analysis

469
00:24:08,340 --> 00:24:09,840
and remediation, right.

470
00:24:09,840 --> 00:24:12,480
So moving from Ad-Hoc to
Automated workflows was one

471
00:24:12,480 --> 00:24:13,950
of the reasons and they were like,

472
00:24:13,950 --> 00:24:16,980
we are already doing this,
we should just extend it.

473
00:24:16,980 --> 00:24:20,010
The second part is, you
know, with just LLM calls

474
00:24:20,010 --> 00:24:21,663
and doing ad-hoc flows,

475
00:24:22,958 --> 00:24:25,110
it's not doing any
complicated reasoning, right.

476
00:24:25,110 --> 00:24:27,150
It's doing LLM retrieval

477
00:24:27,150 --> 00:24:29,490
and then maybe some post-processing,

478
00:24:29,490 --> 00:24:31,740
but it's not doing any
complicated reasoning there.

479
00:24:31,740 --> 00:24:34,140
It's not planning, it's not adapting.

480
00:24:34,140 --> 00:24:35,940
That's another reason
to go towards agents,

481
00:24:35,940 --> 00:24:38,790
especially in their environment
where they are, you know,

482
00:24:38,790 --> 00:24:41,100
fixing things on the fly and
there are issues happening

483
00:24:41,100 --> 00:24:42,550
and they have to react to it.

484
00:24:43,680 --> 00:24:46,980
Also, Slack has built a lot of tools

485
00:24:46,980 --> 00:24:50,400
and data sources on top of AWS services,

486
00:24:50,400 --> 00:24:52,890
which they use effectively
for their data pipeline,

487
00:24:52,890 --> 00:24:54,870
for their CICD build

488
00:24:54,870 --> 00:24:57,060
for collecting logs, all of this, right.

489
00:24:57,060 --> 00:24:59,820
So in order to take
advantage of all of this

490
00:24:59,820 --> 00:25:03,600
in a dynamic fashion, they
would need to build some sort

491
00:25:03,600 --> 00:25:05,430
of standardized access to this, right.

492
00:25:05,430 --> 00:25:06,780
So agents would work

493
00:25:06,780 --> 00:25:09,390
with something like MCP,
Model Context Protocol.

494
00:25:09,390 --> 00:25:10,620
If you haven't heard of it,

495
00:25:10,620 --> 00:25:13,860
you'll most probably hear
about it in this week.

496
00:25:13,860 --> 00:25:17,310
So using a standardized protocol
to build out connections

497
00:25:17,310 --> 00:25:19,500
and being able to
dynamically use these tools

498
00:25:19,500 --> 00:25:22,830
and data sources, that's
another reason to build agents.

499
00:25:22,830 --> 00:25:24,630
So these were the key
reasons why they were like,

500
00:25:24,630 --> 00:25:26,910
we are already doing this
in an ad-hoc fashion.

501
00:25:26,910 --> 00:25:29,220
We should standardize
this and automate it.

502
00:25:29,220 --> 00:25:31,570
That was the key reason
for building agents

503
00:25:33,060 --> 00:25:34,830
like the fancy font.

504
00:25:34,830 --> 00:25:37,380
I wanted to show it for
the agents, you know,

505
00:25:37,380 --> 00:25:40,110
so how, right,

506
00:25:40,110 --> 00:25:43,320
so they were heavily using
Claude Code already, right.

507
00:25:43,320 --> 00:25:45,990
So one of the key features

508
00:25:45,990 --> 00:25:47,730
about Claude Code was
they were adding a lot

509
00:25:47,730 --> 00:25:49,890
of agent capabilities,
especially the later half

510
00:25:49,890 --> 00:25:53,820
of this year, features
like Claude Code subagents

511
00:25:53,820 --> 00:25:55,260
and planning capabilities

512
00:25:55,260 --> 00:25:56,700
and now skills has come out, right.

513
00:25:56,700 --> 00:25:58,590
So they're adding agent capabilities

514
00:25:58,590 --> 00:26:00,120
and they built an SDK, right.

515
00:26:00,120 --> 00:26:03,810
So it's an agent with an SDK,
which you can use effectively

516
00:26:03,810 --> 00:26:06,120
as subagents for various tasks.

517
00:26:06,120 --> 00:26:08,880
So instead of building, you
know, agents from scratch,

518
00:26:08,880 --> 00:26:12,030
which can do specialized
tasks, which is very complex

519
00:26:12,030 --> 00:26:15,060
and it's hard to perfect,
right in production,

520
00:26:15,060 --> 00:26:16,920
they started using Claude Code subagents

521
00:26:16,920 --> 00:26:18,420
for a lot of these specialized tasks

522
00:26:18,420 --> 00:26:19,710
that they're running into.

523
00:26:19,710 --> 00:26:22,020
That was the first part they did.

524
00:26:22,020 --> 00:26:24,570
The second part, like I said,
to access the variety of tools

525
00:26:24,570 --> 00:26:26,850
that they have and the data sources,

526
00:26:26,850 --> 00:26:29,160
they started building
out their own MCP Servers

527
00:26:29,160 --> 00:26:31,500
and they also learned
some of that from us.

528
00:26:31,500 --> 00:26:34,560
Like we built an MCP Server
for EKS, they learn how to use

529
00:26:34,560 --> 00:26:37,020
that for some of their use
cases, things like that.

530
00:26:37,020 --> 00:26:39,330
So being able to standardly
access, you know,

531
00:26:39,330 --> 00:26:42,300
access all of these tools and data sources

532
00:26:42,300 --> 00:26:43,710
without having, you know,

533
00:26:43,710 --> 00:26:45,510
think about, oh I have to use this API

534
00:26:45,510 --> 00:26:47,610
or I have to use that API, you know,

535
00:26:47,610 --> 00:26:48,570
they wanna standardize it.

536
00:26:48,570 --> 00:26:49,620
That was the idea.

537
00:26:49,620 --> 00:26:52,500
And finally they were looking
at various agent frameworks

538
00:26:52,500 --> 00:26:54,870
for integration and that's
where Amazon came in

539
00:26:54,870 --> 00:26:57,870
and we'll talk about
Strands as we go along,

540
00:26:57,870 --> 00:27:00,603
but that's how they
started exploring agents.

541
00:27:02,880 --> 00:27:05,730
And then finally, you know,

542
00:27:05,730 --> 00:27:07,260
what are they doing right now, right.

543
00:27:07,260 --> 00:27:09,810
So one is instead of taking a giant leap

544
00:27:09,810 --> 00:27:11,370
and building a super agent,

545
00:27:11,370 --> 00:27:13,290
they're taking existing workflows

546
00:27:13,290 --> 00:27:15,360
and which they built with LLM integrations

547
00:27:15,360 --> 00:27:16,830
and they're enhancing it

548
00:27:16,830 --> 00:27:19,830
to add more capabilities using
these agent tech workflows

549
00:27:19,830 --> 00:27:22,170
and then also exploring new use cases

550
00:27:22,170 --> 00:27:25,020
in their DevOps environments
as well as incident management

551
00:27:25,020 --> 00:27:26,190
and things like that, right.

552
00:27:26,190 --> 00:27:27,060
So that's what they're doing.

553
00:27:27,060 --> 00:27:30,150
So these three steps, you
can see it's small steps,

554
00:27:30,150 --> 00:27:31,290
but they're making progress

555
00:27:31,290 --> 00:27:34,255
and they're putting things
into production, right.

556
00:27:34,255 --> 00:27:35,910
Which is a very key step, right?

557
00:27:35,910 --> 00:27:38,130
A lot of times we see
customers getting stuck

558
00:27:38,130 --> 00:27:40,317
in analysis paralysis and we want,

559
00:27:40,317 --> 00:27:43,217
and they're kind of moving
forward with these small steps.

560
00:27:46,380 --> 00:27:47,610
So the key question, right.

561
00:27:47,610 --> 00:27:51,000
When I was talking to
Srivani sometime back, right,

562
00:27:51,000 --> 00:27:53,550
Claude Code and subagents are so powerful

563
00:27:53,550 --> 00:27:54,990
and you can create automations

564
00:27:54,990 --> 00:27:57,300
with it pretty easily SDK based.

565
00:27:57,300 --> 00:27:59,460
So why look beyond something like that,

566
00:27:59,460 --> 00:28:01,500
which is so powerful and it's meeting most

567
00:28:01,500 --> 00:28:02,640
of their needs today, right.

568
00:28:02,640 --> 00:28:03,840
That's a key question to ask.

569
00:28:03,840 --> 00:28:05,850
We should not just adopt a new technology

570
00:28:05,850 --> 00:28:06,840
just because it's there.

571
00:28:06,840 --> 00:28:08,407
It should serve a purpose, right.

572
00:28:08,407 --> 00:28:10,590
So we are kind of discussed that

573
00:28:10,590 --> 00:28:12,210
and this was a key reason, right?

574
00:28:12,210 --> 00:28:14,070
So one is it's great, right.

575
00:28:14,070 --> 00:28:16,920
It's a great tool, but it
can get expensive, right.

576
00:28:16,920 --> 00:28:19,110
It's got its own system prompt.

577
00:28:19,110 --> 00:28:20,580
You can, you know, prompt it

578
00:28:20,580 --> 00:28:23,580
with your own user instructions,
but it can get expensive.

579
00:28:23,580 --> 00:28:24,930
It can get expensive

580
00:28:24,930 --> 00:28:26,940
and it can be less predictable depending

581
00:28:26,940 --> 00:28:29,223
on what you ask it to
do, that's one thing.

582
00:28:30,090 --> 00:28:31,980
Also, you know, for Slack

583
00:28:31,980 --> 00:28:33,600
and for everybody it should be

584
00:28:33,600 --> 00:28:35,430
that you should be model agnostic, right.

585
00:28:35,430 --> 00:28:38,100
Today it's Anthropic, tomorrow
could be something else.

586
00:28:38,100 --> 00:28:39,900
We are so early in this journey,

587
00:28:39,900 --> 00:28:41,310
we don't know what's going to come out.

588
00:28:41,310 --> 00:28:45,240
So don't get, you know,
locked in into one technology.

589
00:28:45,240 --> 00:28:47,640
So model agnostic is another part of it.

590
00:28:47,640 --> 00:28:50,250
Right now people are
in exploratory phases,

591
00:28:50,250 --> 00:28:54,180
so cost is not so much of a
consideration, but as production

592
00:28:54,180 --> 00:28:55,620
as you roll this out into production

593
00:28:55,620 --> 00:28:57,030
and the usage goes up,

594
00:28:57,030 --> 00:29:00,270
the cost will become a big factor, right.

595
00:29:00,270 --> 00:29:03,450
And so you may want to say,
oh for this specialized task,

596
00:29:03,450 --> 00:29:05,610
why am I spending so much money?

597
00:29:05,610 --> 00:29:08,790
I want to use you know, a cheaper LLM

598
00:29:08,790 --> 00:29:10,320
and kind of pointed to that.

599
00:29:10,320 --> 00:29:13,920
So if you get, you know,
just stuck with Claude code,

600
00:29:13,920 --> 00:29:15,470
you may not be able to do that.

601
00:29:16,650 --> 00:29:19,410
The other part is one of
the ideas which we discuss,

602
00:29:19,410 --> 00:29:21,540
which Srivani will talk about is the idea

603
00:29:21,540 --> 00:29:22,950
of the orchestrator region, right.

604
00:29:22,950 --> 00:29:26,970
So Claude by itself and
Claude Code has the ability

605
00:29:26,970 --> 00:29:29,040
to have its own
orchestrator, the planning,

606
00:29:29,040 --> 00:29:32,430
the thinking capability and
then it can direct its subagent.

607
00:29:32,430 --> 00:29:35,520
But now you're all into
Claude Code, right.

608
00:29:35,520 --> 00:29:37,260
So what if you abstract it out, right?

609
00:29:37,260 --> 00:29:39,540
What if you abstract out
the orchestrator away

610
00:29:39,540 --> 00:29:42,150
from Claude Code and use
what is really good at

611
00:29:42,150 --> 00:29:45,060
which is a subagent, right,
doing specific tasks.

612
00:29:45,060 --> 00:29:47,610
So once you do that, now
this orchestrator agent,

613
00:29:47,610 --> 00:29:48,443
which you have built

614
00:29:48,443 --> 00:29:51,540
from scratch using a
open-source technology,

615
00:29:51,540 --> 00:29:55,110
you are able to then point to
Claude Code subagent today.

616
00:29:55,110 --> 00:29:58,170
But you can also point them
something else tomorrow, right.

617
00:29:58,170 --> 00:29:59,970
That's the key, to abstract it out

618
00:29:59,970 --> 00:30:02,880
and control what you're
accessing when you're accessing,

619
00:30:02,880 --> 00:30:05,160
keep that within your framework.

620
00:30:05,160 --> 00:30:06,300
That was another reason.

621
00:30:06,300 --> 00:30:08,790
So finally by doing all of this,

622
00:30:08,790 --> 00:30:11,670
you can create an agnostic agent framework

623
00:30:11,670 --> 00:30:14,250
which will future proof your
production deployment, right.

624
00:30:14,250 --> 00:30:15,420
That was the key.

625
00:30:15,420 --> 00:30:17,100
So we went through this discussion

626
00:30:17,100 --> 00:30:19,440
and then we kind of went into the journey

627
00:30:19,440 --> 00:30:22,140
of the agentic world.

628
00:30:22,140 --> 00:30:23,760
So that's where Strands comes in, right.

629
00:30:23,760 --> 00:30:26,070
Strands is, I'll talk about
Strands and what it is,

630
00:30:26,070 --> 00:30:27,960
but before we dive into Strands,

631
00:30:27,960 --> 00:30:30,480
I wanted to discuss why
Amazon builds Strands, right,

632
00:30:30,480 --> 00:30:31,860
an open-source data.

633
00:30:31,860 --> 00:30:34,770
So while the potential of
agents is exciting, right,

634
00:30:34,770 --> 00:30:36,360
everybody's wanting to build agents

635
00:30:36,360 --> 00:30:38,370
and I've tried to build agents,

636
00:30:38,370 --> 00:30:39,960
we have all been trying to build agents.

637
00:30:39,960 --> 00:30:42,270
At some point you
realize it's more complex

638
00:30:42,270 --> 00:30:43,920
than you think it is, right.

639
00:30:43,920 --> 00:30:45,300
Everybody has gone through that,

640
00:30:45,300 --> 00:30:47,580
raise up hands if you think it's resulted

641
00:30:47,580 --> 00:30:50,230
in being more complex than
you thought it was, right?

642
00:30:51,570 --> 00:30:53,370
Okay, many of you have not raised hands.

643
00:30:53,370 --> 00:30:55,570
So I guess it's simpler
than we think it is.

644
00:30:59,013 --> 00:31:01,200
So key challenges that
developers face, right,

645
00:31:01,200 --> 00:31:02,100
with reliable agents.

646
00:31:02,100 --> 00:31:03,960
One, there could be a steep learning curve

647
00:31:03,960 --> 00:31:04,950
in building agents, right.

648
00:31:04,950 --> 00:31:06,810
While we worked with
some of our customers,

649
00:31:06,810 --> 00:31:09,210
we saw that they could
make simple use cases work,

650
00:31:09,210 --> 00:31:12,300
but as it got complex and
the fact that new features

651
00:31:12,300 --> 00:31:15,270
and technologies are coming
out every week, it's very hard

652
00:31:15,270 --> 00:31:17,910
to keep up and decide, okay,
this is good enough for me

653
00:31:17,910 --> 00:31:19,680
or should I wait for that
thing to come out, right.

654
00:31:19,680 --> 00:31:21,123
That was happening a lot.

655
00:31:22,110 --> 00:31:23,880
Enterprise and production
readiness, right.

656
00:31:23,880 --> 00:31:25,920
So as you build stuff,

657
00:31:25,920 --> 00:31:28,800
most of them will work great
in POC and demos, right?

658
00:31:28,800 --> 00:31:30,990
But as soon as you take it to production,

659
00:31:30,990 --> 00:31:32,820
there are a whole other set
of criteria that you have

660
00:31:32,820 --> 00:31:36,363
to meet and that takes a much
longer cycle and we saw that.

661
00:31:38,880 --> 00:31:40,500
Complex orchestration logic, right.

662
00:31:40,500 --> 00:31:43,440
So again, a single agent or
an orchestrator calling one

663
00:31:43,440 --> 00:31:46,770
or two agents with a couple
of tools works great as long

664
00:31:46,770 --> 00:31:48,750
as soon as it goes to thousands of agents.

665
00:31:48,750 --> 00:31:52,290
You as a company, if your goal
is not to just build agents,

666
00:31:52,290 --> 00:31:53,760
it becomes much more complex.

667
00:31:53,760 --> 00:31:56,520
And we'll talk about some
multi-agent patterns, right.

668
00:31:56,520 --> 00:31:58,620
It does get complex in that stage.

669
00:31:58,620 --> 00:32:01,380
And again, for production
it can be challenging.

670
00:32:01,380 --> 00:32:04,230
Also lack of visibility, lack of controls,

671
00:32:04,230 --> 00:32:05,460
not enough flexibility.

672
00:32:05,460 --> 00:32:08,400
These are some common challenges
in most distributed systems

673
00:32:08,400 --> 00:32:10,440
and you see that with
agents as well, right.

674
00:32:10,440 --> 00:32:13,260
So there's a very early
stage in this technology

675
00:32:13,260 --> 00:32:15,630
and so a lot of this, you want to keep it

676
00:32:15,630 --> 00:32:17,790
in a framework which is open source.

677
00:32:17,790 --> 00:32:19,200
That's why you open-source Strands, right.

678
00:32:19,200 --> 00:32:21,150
So Strands is an open-source.

679
00:32:21,150 --> 00:32:22,770
Initially we released a Python SDK,

680
00:32:22,770 --> 00:32:25,680
you may hear some
announcements in re:Invent,

681
00:32:25,680 --> 00:32:27,930
but initially we released our Python SDK

682
00:32:27,930 --> 00:32:30,150
for building agents with
just a few lines of code.

683
00:32:30,150 --> 00:32:33,150
And I'll show you some
examples as we go along.

684
00:32:33,150 --> 00:32:35,250
It's simple to use, eliminates the need

685
00:32:35,250 --> 00:32:37,200
for complex agent orchestration

686
00:32:37,200 --> 00:32:40,560
and it's a code for a solution, right.

687
00:32:40,560 --> 00:32:43,380
It's built keeping builders in mind,

688
00:32:43,380 --> 00:32:45,090
developers in mind, right.

689
00:32:45,090 --> 00:32:48,390
They can define a prompt,
select a list of tools

690
00:32:48,390 --> 00:32:51,420
and then select the LLM
and then let it go, right?

691
00:32:51,420 --> 00:32:52,980
That's how easy it is.

692
00:32:52,980 --> 00:32:55,710
And by open sourcing we
aim to provide developers

693
00:32:55,710 --> 00:32:57,780
with powerful flexible tools

694
00:32:57,780 --> 00:33:01,203
to build agents in the rapidly
evolving agentic landscape.

695
00:33:03,510 --> 00:33:05,460
So now that I've introduced Strands,

696
00:33:05,460 --> 00:33:07,980
what are key features, right?

697
00:33:07,980 --> 00:33:10,410
One is, like I said, model
and deployment choice, right.

698
00:33:10,410 --> 00:33:14,910
It's open-source and while
the default LLM is Bedrock,

699
00:33:14,910 --> 00:33:17,280
you can choose any third
party custom providers

700
00:33:17,280 --> 00:33:20,460
and we have a list of them
and we keep adding more

701
00:33:20,460 --> 00:33:22,650
to be used as the LLM
as part of the agent.

702
00:33:22,650 --> 00:33:25,650
So we are not restricting
you from choosing the LLM

703
00:33:25,650 --> 00:33:26,880
of your choice, right.

704
00:33:26,880 --> 00:33:28,650
And also be able to deploy it anywhere,

705
00:33:28,650 --> 00:33:30,330
any production agentic framework, right.

706
00:33:30,330 --> 00:33:32,080
We are not restricting that either.

707
00:33:32,940 --> 00:33:35,520
Highly flexible, it's
got built-in guardrails,

708
00:33:35,520 --> 00:33:38,160
it connects to AWS's guardrail features

709
00:33:38,160 --> 00:33:42,090
but other guardrail
features externally as well.

710
00:33:42,090 --> 00:33:43,710
It's got built-in native observability

711
00:33:43,710 --> 00:33:47,190
and monitoring hotel metrics
that you can stream out

712
00:33:47,190 --> 00:33:48,150
if you use AgentCore,

713
00:33:48,150 --> 00:33:50,670
it connects into AgentCore
automatically with these metrics.

714
00:33:50,670 --> 00:33:52,230
So very easy to get visibility

715
00:33:52,230 --> 00:33:54,120
and traces of these complex agentic flows

716
00:33:54,120 --> 00:33:56,280
that happen, right.

717
00:33:56,280 --> 00:33:57,900
Third, the MCP integration, right.

718
00:33:57,900 --> 00:33:59,790
Model context protocol that sort

719
00:33:59,790 --> 00:34:02,370
of become the industry
standard as we move forward

720
00:34:02,370 --> 00:34:04,830
to connect into data sources and tools,

721
00:34:04,830 --> 00:34:07,020
we provide that as well as there are a lot

722
00:34:07,020 --> 00:34:09,210
of inbuilt tools in Strands itself

723
00:34:09,210 --> 00:34:11,100
that you can use for a lot of tasks.

724
00:34:11,100 --> 00:34:12,630
Add custom tools.

725
00:34:12,630 --> 00:34:15,090
You can see on the integrations
we have integrations

726
00:34:15,090 --> 00:34:18,600
with Mem0, Raga, stably,
Temporal, there's a Temporal

727
00:34:18,600 --> 00:34:21,750
in AWS open-source session
happening somewhere else

728
00:34:21,750 --> 00:34:24,000
in re:Invent you should
try to attend that.

729
00:34:24,000 --> 00:34:27,540
So integrating a lot of these
third party services out there

730
00:34:27,540 --> 00:34:29,523
to make it highly flexible, right.

731
00:34:30,810 --> 00:34:32,610
So these are some of
the broad capabilities

732
00:34:32,610 --> 00:34:34,323
that Strands has.

733
00:34:35,700 --> 00:34:39,720
Before we go deeper into
how Slack used Strands

734
00:34:39,720 --> 00:34:42,840
to you know, improve
their agentic workflows

735
00:34:42,840 --> 00:34:45,150
or add agentic workflows, I did want

736
00:34:45,150 --> 00:34:46,980
to talk about the multi-agent patterns

737
00:34:46,980 --> 00:34:49,800
that exist within Strands.

738
00:34:49,800 --> 00:34:50,700
You can see four of them,

739
00:34:50,700 --> 00:34:53,370
I'm gonna talk about the starting to swarm

740
00:34:53,370 --> 00:34:55,740
and the three, two to the right of them

741
00:34:55,740 --> 00:34:57,660
and then I'll come back
to agent as tools, right?

742
00:34:57,660 --> 00:35:00,630
So swarm is, as you can imagine,

743
00:35:00,630 --> 00:35:02,070
collaboration between multiple agents.

744
00:35:02,070 --> 00:35:04,980
So there are communication
patterns, shared memory systems,

745
00:35:04,980 --> 00:35:06,390
coordination mechanisms,

746
00:35:06,390 --> 00:35:08,520
and a host of agents are
talking to each other

747
00:35:08,520 --> 00:35:10,500
to solve these complex problems.

748
00:35:10,500 --> 00:35:15,030
A graph as again the name
suggests is you have the agents

749
00:35:15,030 --> 00:35:17,190
which are Nodes and then
the way they communicate

750
00:35:17,190 --> 00:35:18,990
with other agents are the edges

751
00:35:18,990 --> 00:35:21,840
and you define explicitly
how they communicate, right.

752
00:35:21,840 --> 00:35:24,930
So you can build out a
graph workflow pattern.

753
00:35:24,930 --> 00:35:26,220
And then the final is the workflow,

754
00:35:26,220 --> 00:35:28,590
which is essentially a
structured way of defining

755
00:35:28,590 --> 00:35:30,090
how one agent will do one task

756
00:35:30,090 --> 00:35:31,800
and pass it on to the next agent and so on

757
00:35:31,800 --> 00:35:33,030
and so forth, right.

758
00:35:33,030 --> 00:35:35,520
So these are three patterns that we have.

759
00:35:35,520 --> 00:35:38,790
The fourth one on the
left, Agent as tools,

760
00:35:38,790 --> 00:35:40,470
is the most interesting to us right now

761
00:35:40,470 --> 00:35:42,630
because that's what Slack is using.

762
00:35:42,630 --> 00:35:45,180
You heard me talk about
the orchestrator agent.

763
00:35:45,180 --> 00:35:49,080
So we are using the orchestrator
agent in agent as tools

764
00:35:49,080 --> 00:35:51,030
which handles the user interaction

765
00:35:51,030 --> 00:35:53,970
and it decides which
specialized tool to call.

766
00:35:53,970 --> 00:35:55,740
And these tools could be other agents,

767
00:35:55,740 --> 00:35:57,270
that's why agents as tools.

768
00:35:57,270 --> 00:35:59,580
And so the specialized
agents perform those tasks

769
00:35:59,580 --> 00:36:02,280
and then hand back the answer
to the orchestration tool

770
00:36:02,280 --> 00:36:05,580
to orchestration agent to
decide how to answer back

771
00:36:05,580 --> 00:36:07,290
to the user, right.

772
00:36:07,290 --> 00:36:09,930
So as Srivani will describe later on,

773
00:36:09,930 --> 00:36:12,990
you look at how they use Strands
as the orchestrator agent

774
00:36:12,990 --> 00:36:15,990
and our specialized agents
in Claude Code subagents

775
00:36:15,990 --> 00:36:17,553
to do the specialized tasks.

776
00:36:23,400 --> 00:36:27,570
So before we get into the
architecture discussion

777
00:36:27,570 --> 00:36:32,490
that Srivani will talk about,
I did want to also, you know,

778
00:36:32,490 --> 00:36:35,670
talk to you about what
Strands agent is, right.

779
00:36:35,670 --> 00:36:37,203
It's a very simple concept.

780
00:36:38,220 --> 00:36:41,400
Strands is what it calls
an agentic loop, right,

781
00:36:41,400 --> 00:36:43,860
that forms the core of its functionality.

782
00:36:43,860 --> 00:36:47,400
It receives a prompt and a
context along with a description

783
00:36:47,400 --> 00:36:49,140
of the available tools,

784
00:36:49,140 --> 00:36:51,600
then the model reasons about the tasks

785
00:36:51,600 --> 00:36:54,030
and decides whether to respond directly.

786
00:36:54,030 --> 00:36:55,590
Suppose it can respond directly,

787
00:36:55,590 --> 00:36:57,480
it doesn't need the tools to respond,

788
00:36:57,480 --> 00:36:59,820
otherwise it'll apply a series of steps,

789
00:36:59,820 --> 00:37:02,670
reflect on previous actions,
select the tools that it needs

790
00:37:02,670 --> 00:37:04,230
and do one of these steps

791
00:37:04,230 --> 00:37:05,550
once it gets back the response

792
00:37:05,550 --> 00:37:07,980
from the tool or whatever
it asks the task to do,

793
00:37:07,980 --> 00:37:10,290
it decides whether the
task is actually complete

794
00:37:10,290 --> 00:37:11,880
or else it'll repeat the cycle again

795
00:37:11,880 --> 00:37:13,320
until the task is complete.

796
00:37:13,320 --> 00:37:15,810
That's the basic nature of Strands,

797
00:37:15,810 --> 00:37:18,760
how you create a Strands agent
and the multi-agent pattern.

798
00:37:22,860 --> 00:37:26,520
So before I hand it back to
Srivani, I wanted to leave you

799
00:37:26,520 --> 00:37:28,710
with a couple of just simple examples

800
00:37:28,710 --> 00:37:31,410
of creating Strands agents, right,

801
00:37:31,410 --> 00:37:34,350
with model choice and then I'll
show you the tools example.

802
00:37:34,350 --> 00:37:37,500
So you can see over here
with a few lines of code,

803
00:37:37,500 --> 00:37:40,260
you're able to create an agent
which uses a default choice,

804
00:37:40,260 --> 00:37:42,570
which is Bedrock in this case

805
00:37:42,570 --> 00:37:47,430
and a Nova model to create the agent

806
00:37:47,430 --> 00:37:49,740
and ask that question.

807
00:37:49,740 --> 00:37:52,650
And then similarly, you can attach tools,

808
00:37:52,650 --> 00:37:54,090
you can see there are a whole host

809
00:37:54,090 --> 00:37:55,980
of tool categories that is available.

810
00:37:55,980 --> 00:37:59,400
And then from these tools
you can attach these tools

811
00:37:59,400 --> 00:38:01,230
to the agent and create a simple agent

812
00:38:01,230 --> 00:38:04,440
where in this case is
using the HTTP request tool

813
00:38:04,440 --> 00:38:06,450
to ask a specific question, right.

814
00:38:06,450 --> 00:38:08,250
So again, these are simple examples

815
00:38:08,250 --> 00:38:11,010
but you can see to get
started very few lines

816
00:38:11,010 --> 00:38:13,740
of code are needed and I
wanted to highlight that as to

817
00:38:13,740 --> 00:38:15,900
how easy it is to get
started with Strands.

818
00:38:15,900 --> 00:38:18,510
So hopefully you got a good
understanding of you know,

819
00:38:18,510 --> 00:38:23,460
why Slack went towards agentic workflows,

820
00:38:23,460 --> 00:38:26,580
why they selected Strands
as an exploratory area

821
00:38:26,580 --> 00:38:28,770
to move forward with
and what it is solving

822
00:38:28,770 --> 00:38:31,260
and also learn a little bit about Strands.

823
00:38:31,260 --> 00:38:34,830
That was my part of the presentation

824
00:38:34,830 --> 00:38:39,030
and now I'll hand it back
to Srivani to take it home

825
00:38:39,030 --> 00:38:41,850
with the technical deep dive
starting with the Buddy Bot,

826
00:38:41,850 --> 00:38:43,860
how they enhanced it with Strands

827
00:38:43,860 --> 00:38:46,870
and then we'll get to Q&A, thanks

828
00:38:51,840 --> 00:38:53,130
- Talk about the evolution

829
00:38:53,130 --> 00:38:56,550
of our Buddy Bot technical deep dive

830
00:38:56,550 --> 00:39:01,380
and to using Strands from
like the version zero

831
00:39:01,380 --> 00:39:02,463
which we started.

832
00:39:03,420 --> 00:39:05,790
Our story starts with
the fundamental pinpoint

833
00:39:05,790 --> 00:39:09,510
of engineers spending a
lot of time on escals.

834
00:39:09,510 --> 00:39:12,900
The initial Buddy Bot architecture
which was shown about,

835
00:39:12,900 --> 00:39:17,900
was designed to handle basic
escalations by using knowledge

836
00:39:17,910 --> 00:39:21,090
that is spread across
different data sources.

837
00:39:21,090 --> 00:39:23,040
So as you see like the data sources

838
00:39:23,040 --> 00:39:27,270
we are calling here is Slack
data, Slack messages and files

839
00:39:27,270 --> 00:39:28,800
and also some of the technic,

840
00:39:28,800 --> 00:39:30,600
some of the data is also scattered

841
00:39:30,600 --> 00:39:32,820
across our GitHub repositories

842
00:39:32,820 --> 00:39:35,523
like technical designs, documentation.

843
00:39:37,230 --> 00:39:39,990
So as you see here, like
the first thing we did is

844
00:39:39,990 --> 00:39:42,150
like we did a hybrid search.

845
00:39:42,150 --> 00:39:44,640
So we gathered the right
relevant information

846
00:39:44,640 --> 00:39:46,570
across all of these data sources

847
00:39:47,587 --> 00:39:51,050
and then we in turn rerun those data

848
00:39:51,050 --> 00:39:52,560
to get the more accurate

849
00:39:52,560 --> 00:39:55,443
or more relevant data across
the knowledge sources.

850
00:39:56,310 --> 00:39:59,940
And then we provide the
top most relevant documents

851
00:39:59,940 --> 00:40:02,100
to the LLM with the user query

852
00:40:02,100 --> 00:40:06,693
to provide a more accurate
answer back to the escalation.

853
00:40:08,940 --> 00:40:12,843
So this was our first design,
which was working great,

854
00:40:13,830 --> 00:40:16,950
but we ran into challenges
with the initial design

855
00:40:16,950 --> 00:40:20,430
with respect to maintaining
the conversational history

856
00:40:20,430 --> 00:40:24,093
and also being able to
execute external actions.

857
00:40:25,440 --> 00:40:29,070
So then we evolved into what
you see here, the newer version

858
00:40:29,070 --> 00:40:34,070
of our body which is
showing a powerful agent

859
00:40:34,080 --> 00:40:36,820
but that we've built or we are exploring

860
00:40:38,040 --> 00:40:41,250
which begins when a user sends a message,

861
00:40:41,250 --> 00:40:43,330
our backend receives an event

862
00:40:44,190 --> 00:40:48,300
and we start a Temporal
workflow orchestration

863
00:40:48,300 --> 00:40:52,380
around that, which basically
main provides durability

864
00:40:52,380 --> 00:40:55,470
as well as maintains
the conversational state

865
00:40:55,470 --> 00:41:00,030
across the entire escalation
until it is resolved,

866
00:41:00,030 --> 00:41:02,100
which releases the ease of pain

867
00:41:02,100 --> 00:41:04,200
for maintaining the conversations for all

868
00:41:04,200 --> 00:41:06,513
of the escals in our applications.

869
00:41:09,420 --> 00:41:11,040
The Temporal workflow

870
00:41:11,040 --> 00:41:14,523
which then calls the main
Strands orchestrator,

871
00:41:16,350 --> 00:41:18,690
the Strands orchestrator agent

872
00:41:18,690 --> 00:41:21,060
which we build using Anthropic as well,

873
00:41:21,060 --> 00:41:23,370
Anthropic Claude model as well,

874
00:41:23,370 --> 00:41:26,950
which then decides which subagents to call

875
00:41:27,900 --> 00:41:31,980
and the subagents have access
to the MCP servers to interact

876
00:41:31,980 --> 00:41:33,543
with our internal services.

877
00:41:35,340 --> 00:41:37,170
All of the subagent that you see here,

878
00:41:37,170 --> 00:41:39,780
we've built using Claude SDKs.

879
00:41:39,780 --> 00:41:43,680
So the subagents are Claude,
the orchestration agent is,

880
00:41:43,680 --> 00:41:45,900
so there is orchestration agent is Strands

881
00:41:45,900 --> 00:41:47,763
and the subagent are Claude Code.

882
00:41:49,080 --> 00:41:52,500
The reason we chose Strands
agent here as orchestrator is

883
00:41:52,500 --> 00:41:57,500
to explore different LLMs, not
just use Claude Code subagent

884
00:41:57,630 --> 00:42:00,180
as we're actively exploring
other competing models.

885
00:42:02,880 --> 00:42:06,090
And once all of the subagents
are finished running,

886
00:42:06,090 --> 00:42:10,290
the main agent, the orchestration
agent gets the context

887
00:42:10,290 --> 00:42:14,040
or response back, which then
synthesizes its processes

888
00:42:14,040 --> 00:42:15,480
and validates the response

889
00:42:15,480 --> 00:42:17,883
before sending it back
to the Slack channel.

890
00:42:21,390 --> 00:42:22,790
So as you see the flow here.

891
00:42:25,020 --> 00:42:27,610
So we are gonna see a live demo of like

892
00:42:28,830 --> 00:42:30,540
how it happens at Slack.

893
00:42:30,540 --> 00:42:33,060
So when a user sends a question

894
00:42:33,060 --> 00:42:35,043
or an escalation in Slack channel,

895
00:42:36,870 --> 00:42:39,400
our backend gets an event

896
00:42:41,550 --> 00:42:45,540
and then our backend then
spins off a Temporal workflow

897
00:42:45,540 --> 00:42:46,490
which you see here,

898
00:42:49,860 --> 00:42:52,830
which has the context of
all the Slack conversations

899
00:42:52,830 --> 00:42:55,863
that happen or escalations that
happen in that Slack thread.

900
00:42:57,660 --> 00:43:01,680
It then kicks off our orchestrator agent,

901
00:43:01,680 --> 00:43:03,273
which is return using Strands.

902
00:43:05,310 --> 00:43:10,170
And once the orchestrator
agent receives the request,

903
00:43:10,170 --> 00:43:15,150
it actually sponsors subagents
through the tool call,

904
00:43:15,150 --> 00:43:18,753
which Prashanth already just talked about.

905
00:43:19,650 --> 00:43:22,740
As you see here, it's actually
calling the Triage agent

906
00:43:22,740 --> 00:43:23,820
and KB agent.

907
00:43:23,820 --> 00:43:26,943
Those are all subagents we
built using Claude Code.

908
00:43:29,550 --> 00:43:30,540
And the good thing

909
00:43:30,540 --> 00:43:35,370
with the Temporal is it
also provides visibility

910
00:43:35,370 --> 00:43:38,583
into like all of the calls
and traceability as well.

911
00:43:39,540 --> 00:43:42,750
So once the main orchestrator
agents processes everything,

912
00:43:42,750 --> 00:43:45,510
its sensor response back to Slack channel.

913
00:43:45,510 --> 00:43:49,020
And when a user asks a follow-up question,

914
00:43:49,020 --> 00:43:52,470
all of the context of the
previous conversation is

915
00:43:52,470 --> 00:43:54,000
actually maintained by Temporal,

916
00:43:54,000 --> 00:43:57,540
which eases the pain on
the application itself

917
00:43:57,540 --> 00:44:00,393
to maintain the conversation
history and the states.

918
00:44:02,490 --> 00:44:05,400
So as you see Temporal
resumes the workflow,

919
00:44:05,400 --> 00:44:09,180
whenever user sends,
continues the conversation

920
00:44:09,180 --> 00:44:12,693
in Slack thread, it just
resumes the same workflow.

921
00:44:14,220 --> 00:44:15,840
So once it finishes the same flow,

922
00:44:15,840 --> 00:44:18,190
like the response is sent
back to the customer.

923
00:44:22,050 --> 00:44:25,893
So this workflow simplified,

924
00:44:26,940 --> 00:44:31,410
this architecture simplified
our Code quite a bit

925
00:44:31,410 --> 00:44:34,320
as we didn't have to maintain
the conversational history

926
00:44:34,320 --> 00:44:36,243
and durability of retries,

927
00:44:37,110 --> 00:44:38,970
which is all provided by Temporal.

928
00:44:38,970 --> 00:44:42,540
And with the Strands we
were able to experiment

929
00:44:42,540 --> 00:44:44,310
with different subagents

930
00:44:44,310 --> 00:44:47,403
and we were not had to
stack with just Claude Code.

931
00:45:03,090 --> 00:45:06,120
So as you see, as you saw our overview

932
00:45:06,120 --> 00:45:08,040
of the technical architecture,

933
00:45:08,040 --> 00:45:11,940
we upgraded our Buddy Bot
from a simple search bot

934
00:45:11,940 --> 00:45:13,503
into a powerful agent.

935
00:45:14,820 --> 00:45:16,830
And some of the things we considered

936
00:45:16,830 --> 00:45:20,553
while building it is
reliability and efficiency.

937
00:45:22,260 --> 00:45:24,690
First we built a stable foundation,

938
00:45:24,690 --> 00:45:27,130
we used Temporal for reliability

939
00:45:28,380 --> 00:45:30,870
as the bot never forgets the conversation

940
00:45:30,870 --> 00:45:34,620
even during failures, even
when the backend dies,

941
00:45:34,620 --> 00:45:37,170
Temporal maintains the state in a database

942
00:45:37,170 --> 00:45:39,333
so it resumes where it left off.

943
00:45:40,440 --> 00:45:44,700
Temporal also supports like
retries, automated retries

944
00:45:44,700 --> 00:45:47,340
so we didn't have to
retry tool call failures

945
00:45:47,340 --> 00:45:50,310
and all of that in our
application, which eased

946
00:45:50,310 --> 00:45:52,060
or simplified our code quite a bit.

947
00:45:54,720 --> 00:45:58,560
And next we solved crucial
security challenge.

948
00:45:58,560 --> 00:46:01,290
We created remote empty MCP servers

949
00:46:01,290 --> 00:46:05,610
with IoT service which
integrates to Aruba proxy,

950
00:46:05,610 --> 00:46:07,560
which is a networking system.

951
00:46:07,560 --> 00:46:09,360
This ensures the bot

952
00:46:09,360 --> 00:46:12,030
can safely access
sensitive internal systems

953
00:46:12,030 --> 00:46:14,493
like GitHub with the right permissions.

954
00:46:15,870 --> 00:46:19,650
Finally, we were focused
on making bot faster.

955
00:46:19,650 --> 00:46:22,610
So we ran all of these
subagents in parallel

956
00:46:24,060 --> 00:46:27,360
and we also optimized the
token usage management.

957
00:46:27,360 --> 00:46:29,760
So the Strands subagent

958
00:46:29,760 --> 00:46:33,180
before sending it to the LLM to summarize

959
00:46:33,180 --> 00:46:36,630
and like confirm the response.

960
00:46:36,630 --> 00:46:39,780
It summarized each of the
response from the subagents

961
00:46:39,780 --> 00:46:42,480
to reduce the token management
across when sending it

962
00:46:42,480 --> 00:46:44,220
to a very expensive LLMs.

963
00:46:46,320 --> 00:46:49,470
And also Strands provided us extensibility

964
00:46:49,470 --> 00:46:52,953
for any future being LLM agnostic.

965
00:47:02,850 --> 00:47:06,360
So the road ahead, we've
stabilized the architecture

966
00:47:06,360 --> 00:47:10,410
and solved the security problems
and optimized performance.

967
00:47:10,410 --> 00:47:12,990
But this is just the foundation.

968
00:47:12,990 --> 00:47:16,590
Our vision is much bigger
than single Escalation Bot.

969
00:47:16,590 --> 00:47:17,423
We are on a road

970
00:47:17,423 --> 00:47:20,490
to establishing fully
automated agentic workflows

971
00:47:20,490 --> 00:47:22,713
across the entire development cycle.

972
00:47:24,330 --> 00:47:26,400
We would like to experiment
StrandS use cases

973
00:47:26,400 --> 00:47:27,580
beyond escalation

974
00:47:28,860 --> 00:47:32,730
and we would like to integrate
more internal tools via MCP

975
00:47:32,730 --> 00:47:35,973
to make our bots more,
our agents more powerful.

976
00:47:36,840 --> 00:47:39,453
We also are exploring AgentCore

977
00:47:40,950 --> 00:47:44,370
and we would like to have
native integration with Temporal

978
00:47:44,370 --> 00:47:47,040
and Strands agent first,
smoother execution

979
00:47:47,040 --> 00:47:50,223
and also more granular retries.

980
00:47:51,690 --> 00:47:53,670
Our long-term goal is simple,

981
00:47:53,670 --> 00:47:57,300
but ambitious of fully
Automated Agentic workflows

982
00:47:57,300 --> 00:47:59,223
across the entire development cycle.

983
00:48:03,840 --> 00:48:05,610
Here are some of the links for you all

984
00:48:05,610 --> 00:48:08,343
to get started building agents.

985
00:48:10,536 --> 00:48:11,703
- Yeah, I can.

986
00:48:12,750 --> 00:48:13,740
Yeah, thank you again.

987
00:48:13,740 --> 00:48:16,200
And yeah, I'll keep it here a minute

988
00:48:16,200 --> 00:48:18,660
and then we can take Q&A after that.

989
00:48:18,660 --> 00:48:21,210
So if you want to get the QR codes,

990
00:48:21,210 --> 00:48:22,043
I'm sure you'll run

991
00:48:22,043 --> 00:48:24,510
into a lot of these links
throughout re:Invent.

992
00:48:24,510 --> 00:48:27,270
Please don't forget to fill out the survey

993
00:48:27,270 --> 00:48:32,220
in your mobile app and then
we will just move to Q&A.

994
00:48:32,220 --> 00:48:34,057
- Yeah, and all of these
sessions that you see,

995
00:48:34,057 --> 00:48:36,960
if we go back on the QR
code, if you think any

996
00:48:36,960 --> 00:48:38,190
of these topics are interested,

997
00:48:38,190 --> 00:48:39,810
we have multiple sessions going on

998
00:48:39,810 --> 00:48:43,470
across next two or three days,
so please feel free to look

999
00:48:43,470 --> 00:48:45,060
around the different session.

1000
00:48:45,060 --> 00:48:48,360
Their Keynote, Swami will
be making a ML Keynote,

1001
00:48:48,360 --> 00:48:49,410
definitely watch that.

1002
00:48:49,410 --> 00:48:51,900
A lot of new announcements
coming in across Asian Codes,

1003
00:48:51,900 --> 00:48:53,433
Strands, and Bedrock.

1004
00:48:54,560 --> 00:48:56,193
- [Prashanth] Yeah, thank you.

