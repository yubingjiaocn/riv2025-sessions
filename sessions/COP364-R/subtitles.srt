1
00:00:00,190 --> 00:00:02,250
- [Siva] Hello everybody.

2
00:00:02,250 --> 00:00:04,830
Thank you for coming in. Good afternoon.

3
00:00:04,830 --> 00:00:06,330
My name is Siva Guruvareddiar.

4
00:00:06,330 --> 00:00:09,750
I'm a senior specialist
architect here at AWS.

5
00:00:09,750 --> 00:00:12,060
So welcome to this session on
comprehensive observability

6
00:00:12,060 --> 00:00:16,050
with mobile real user
monitoring and application map.

7
00:00:16,050 --> 00:00:17,943
So with me, I have Alex,

8
00:00:19,080 --> 00:00:21,153
who is a principal engineer at AWS.

9
00:00:22,650 --> 00:00:25,920
And we would like to talk about
this as a code talk, right?

10
00:00:25,920 --> 00:00:28,230
We wanted to have it dive into the code

11
00:00:28,230 --> 00:00:29,640
and then talk about the various features

12
00:00:29,640 --> 00:00:31,590
and all those things, right?

13
00:00:31,590 --> 00:00:33,600
But before getting into the beats,

14
00:00:33,600 --> 00:00:35,267
how many of you here, like you know,

15
00:00:35,267 --> 00:00:36,100
just show me your hands,

16
00:00:36,100 --> 00:00:38,910
if you are using Application Signals

17
00:00:38,910 --> 00:00:42,243
in your product or in your company?

18
00:00:43,470 --> 00:00:46,980
Maybe that's a bad marketing on our side.

19
00:00:46,980 --> 00:00:49,743
How many of you have heard
about Application Signals?

20
00:00:51,060 --> 00:00:52,320
Good. Yeah.

21
00:00:52,320 --> 00:00:55,860
So Application Signals is
our own way of doing APM,

22
00:00:55,860 --> 00:00:57,900
application performance monitoring.

23
00:00:57,900 --> 00:01:00,623
And I would like to level
set the field, like you know,

24
00:01:00,623 --> 00:01:04,140
we will be taking a very short
maybe theoretical concept

25
00:01:04,140 --> 00:01:05,910
on what is it all about.

26
00:01:05,910 --> 00:01:08,100
Then we'll dive into the
coding things, right?

27
00:01:08,100 --> 00:01:10,320
So this is what our agenda is gonna be.

28
00:01:10,320 --> 00:01:12,780
We'll talk about the overview
on a very high level,

29
00:01:12,780 --> 00:01:16,260
then we'll talk about the
latest and greatest features

30
00:01:16,260 --> 00:01:17,970
including application map,

31
00:01:17,970 --> 00:01:19,590
the mobile real user monitoring,

32
00:01:19,590 --> 00:01:22,290
which we just launched
a couple of weeks back.

33
00:01:22,290 --> 00:01:25,240
And finally, like you know,
we'll get into the code things.

34
00:01:26,190 --> 00:01:28,920
So Application Signals, as I
said, it is on a high level,

35
00:01:28,920 --> 00:01:30,810
you can think of it as our own version

36
00:01:30,810 --> 00:01:33,120
of application performance monitoring.

37
00:01:33,120 --> 00:01:35,070
So we have inventory of services

38
00:01:35,070 --> 00:01:37,500
that you're running in your application

39
00:01:37,500 --> 00:01:40,290
or like, in your account
and all those, right?

40
00:01:40,290 --> 00:01:42,240
And you wanted to both
understand, like you know,

41
00:01:42,240 --> 00:01:44,220
monitor it, and observe it,

42
00:01:44,220 --> 00:01:47,820
and when things are failing,
you wanted to fix it ASAP.

43
00:01:47,820 --> 00:01:49,950
So that's what it is all about.

44
00:01:49,950 --> 00:01:51,960
So we will be showing, like you know,

45
00:01:51,960 --> 00:01:54,240
irrespective of whether
you are instrumenting it

46
00:01:54,240 --> 00:01:55,740
or not instrumenting it,

47
00:01:55,740 --> 00:01:58,050
we'll be showing you all the services

48
00:01:58,050 --> 00:02:00,750
that are available in your
account from the console.

49
00:02:00,750 --> 00:02:02,430
We'll be showing a demo.

50
00:02:02,430 --> 00:02:05,970
And also, like you know, it's
all based on golden metrics.

51
00:02:05,970 --> 00:02:08,370
In the APM world, the
golden metrics is all

52
00:02:08,370 --> 00:02:10,620
about RED metrics we call it as,

53
00:02:10,620 --> 00:02:12,630
wherein R stands for request,

54
00:02:12,630 --> 00:02:15,210
E stands for errors and the faults

55
00:02:15,210 --> 00:02:17,880
and D stands for duration or latency.

56
00:02:17,880 --> 00:02:19,140
So everywhere, like you know,

57
00:02:19,140 --> 00:02:22,440
in Application Signals console,
whatever you'll be seeing

58
00:02:22,440 --> 00:02:23,880
it's based on golden metrics,

59
00:02:23,880 --> 00:02:26,193
or the RED metrics, and
dependency tracking.

60
00:02:27,120 --> 00:02:28,290
But the beauty here is, like you know,

61
00:02:28,290 --> 00:02:30,870
you're not sending us any kind of metadata

62
00:02:30,870 --> 00:02:31,890
that says, like you know, okay,

63
00:02:31,890 --> 00:02:34,680
hey, my service is calling service B.

64
00:02:34,680 --> 00:02:36,900
We will be getting all
the tracing information

65
00:02:36,900 --> 00:02:38,970
based on the distributed tracing,

66
00:02:38,970 --> 00:02:42,180
and then we'll figure out
what is your dependency is.

67
00:02:42,180 --> 00:02:44,130
It's all based on open standards.

68
00:02:44,130 --> 00:02:47,790
We all using OpenTelemetry
as the underlying mechanism.

69
00:02:47,790 --> 00:02:48,930
And using that, like you know,

70
00:02:48,930 --> 00:02:51,390
we will be showing you all the details.

71
00:02:51,390 --> 00:02:52,470
So with that one, like you know,

72
00:02:52,470 --> 00:02:55,260
as a next level you wanna connect your,

73
00:02:55,260 --> 00:02:58,140
maybe your technical things
with your business metrics.

74
00:02:58,140 --> 00:03:00,480
So that's where you can create your SLOs,

75
00:03:00,480 --> 00:03:03,273
service level objectives,
from your services.

76
00:03:04,290 --> 00:03:06,000
And also, like you know,
the topology map will be

77
00:03:06,000 --> 00:03:08,370
showing you how these
services are interrelated

78
00:03:08,370 --> 00:03:10,860
with each other, as in
when your services are

79
00:03:10,860 --> 00:03:12,213
sending metrics to us.

80
00:03:13,170 --> 00:03:15,510
So with this one, like you
know, like we discussed,

81
00:03:15,510 --> 00:03:17,940
it is based on distributed tracing,

82
00:03:17,940 --> 00:03:21,540
and last year we introduced a
concept of transaction search.

83
00:03:21,540 --> 00:03:25,230
So what we are doing is
we are taking your traces

84
00:03:25,230 --> 00:03:27,090
and then storing as logs.

85
00:03:27,090 --> 00:03:29,730
So in that case, like you
know, any kind of transactions

86
00:03:29,730 --> 00:03:32,160
that are available in your
business applications,

87
00:03:32,160 --> 00:03:34,170
you can go ahead and then search for it.

88
00:03:34,170 --> 00:03:37,680
The typical way you'll be doing
with CloudWatch logs, right?

89
00:03:37,680 --> 00:03:39,360
So we can do that.

90
00:03:39,360 --> 00:03:41,490
And last but not least, like
you know, we have support

91
00:03:41,490 --> 00:03:44,460
for real user monitoring
as well as canneries.

92
00:03:44,460 --> 00:03:46,770
So real user monitoring
predominantly we have been

93
00:03:46,770 --> 00:03:49,260
supporting web for a pretty long time.

94
00:03:49,260 --> 00:03:51,090
And recently, like you
know, we added support

95
00:03:51,090 --> 00:03:55,200
for mobile applications
both iOS and Android.

96
00:03:55,200 --> 00:03:57,000
And as well as, like you
know, synthetic canneries,

97
00:03:57,000 --> 00:04:00,300
if you wanted to run any
synthetic testing on your APIs,

98
00:04:00,300 --> 00:04:02,673
on your endpoints, that is also supported.

99
00:04:04,230 --> 00:04:06,030
So let's talk about the newer feature

100
00:04:06,030 --> 00:04:07,620
called application map.

101
00:04:07,620 --> 00:04:10,230
So it has come, like you
know, a lot of stages.

102
00:04:10,230 --> 00:04:12,990
So we started with trace
map and service map.

103
00:04:12,990 --> 00:04:16,320
Currently it is in the
stages of application map.

104
00:04:16,320 --> 00:04:18,870
So application map it is,
so like, you're seeing

105
00:04:18,870 --> 00:04:22,830
in the upper, like you know,
right hand side picture.

106
00:04:22,830 --> 00:04:24,443
So that's how, like you
know, you will be seeing it.

107
00:04:24,443 --> 00:04:27,660
We will be showing you the demo on this.

108
00:04:27,660 --> 00:04:28,650
So here's where, like you know,

109
00:04:28,650 --> 00:04:30,510
you'll be seeing a lot of tiles.

110
00:04:30,510 --> 00:04:32,910
So these tiles are
representing your applications,

111
00:04:32,910 --> 00:04:36,180
and then we are grouping
together by related services.

112
00:04:36,180 --> 00:04:38,190
So that is our default grouping.

113
00:04:38,190 --> 00:04:39,090
But you can go ahead

114
00:04:39,090 --> 00:04:41,430
and then create your own custom grouping.

115
00:04:41,430 --> 00:04:43,800
Either, like you know, there
is a front end grouping

116
00:04:43,800 --> 00:04:45,390
and then there is a backend grouping.

117
00:04:45,390 --> 00:04:48,240
Or if you are running, like
you know, multiple BUs,

118
00:04:48,240 --> 00:04:49,073
for example, like you know,

119
00:04:49,073 --> 00:04:51,450
I might be running a
JS application, right?

120
00:04:51,450 --> 00:04:52,920
A financial application.

121
00:04:52,920 --> 00:04:54,090
So that could be, like you know,

122
00:04:54,090 --> 00:04:57,120
my BU could be a lone
BU, could be one tile,

123
00:04:57,120 --> 00:05:00,150
and then my lending could
be another BU tile, right?

124
00:05:00,150 --> 00:05:01,680
So that way you can go ahead

125
00:05:01,680 --> 00:05:05,430
and then segregate your
applications the way you wanted it,

126
00:05:05,430 --> 00:05:08,460
the way you wanted to observe it, right?

127
00:05:08,460 --> 00:05:11,850
But the thing is, if you
can't click into that one, so

128
00:05:11,850 --> 00:05:14,280
that's how, like you know, it
is going to be elaborating.

129
00:05:14,280 --> 00:05:17,100
So each and every service
with its dependencies.

130
00:05:17,100 --> 00:05:19,680
So that's a lower part of
the picture is showing.

131
00:05:19,680 --> 00:05:22,170
You can do all these
things from one place.

132
00:05:22,170 --> 00:05:24,450
Again, each and every
tile, you can click on it

133
00:05:24,450 --> 00:05:26,370
like a recursion basis.

134
00:05:26,370 --> 00:05:27,690
You can keep doing, like you know,

135
00:05:27,690 --> 00:05:29,940
the drilling down till
the way you wanted it.

136
00:05:31,860 --> 00:05:34,950
So how you do navigate the map?

137
00:05:34,950 --> 00:05:36,660
So as I said, like you know, we can group

138
00:05:36,660 --> 00:05:38,430
by the way you wanted it.

139
00:05:38,430 --> 00:05:41,010
By default the grouping
is the related services,

140
00:05:41,010 --> 00:05:42,900
how you are sending the metrics.

141
00:05:42,900 --> 00:05:44,910
But as I said, like you
know, you can go ahead

142
00:05:44,910 --> 00:05:47,790
and then group it, and then
you can zoom it and zoom out,

143
00:05:47,790 --> 00:05:49,770
and all those things, because it's a map.

144
00:05:49,770 --> 00:05:52,440
So wherever you need the
attention, you can zoom in

145
00:05:52,440 --> 00:05:54,960
and then zoom out, and
then do all those things.

146
00:05:54,960 --> 00:05:57,930
And also like you know, if you
see in the right hand drawer,

147
00:05:57,930 --> 00:06:00,210
there is a something called,
like you know, there is a lot

148
00:06:00,210 --> 00:06:02,010
of details around it, starting

149
00:06:02,010 --> 00:06:04,980
with your health metrics of your services.

150
00:06:04,980 --> 00:06:05,820
So in this case, like you know,

151
00:06:05,820 --> 00:06:08,610
I do have a pet clinic, printing,

152
00:06:08,610 --> 00:06:11,550
which is showing, like you
know, how healthy my services,

153
00:06:11,550 --> 00:06:13,860
how many faults I'm getting it,

154
00:06:13,860 --> 00:06:16,830
and then if I created any
SLOs, how they are healthy

155
00:06:16,830 --> 00:06:18,830
or unhealthy, those kind of information.

156
00:06:19,710 --> 00:06:21,060
In addition to that, as I mentioned,

157
00:06:21,060 --> 00:06:23,850
you will be seeing all your
RED metrics, the number

158
00:06:23,850 --> 00:06:26,370
of requests you're getting
at, your errors, faults,

159
00:06:26,370 --> 00:06:29,013
then latency, all that
information is available.

160
00:06:30,030 --> 00:06:32,640
And one additional thing is, the support

161
00:06:32,640 --> 00:06:34,830
that we recently added
is, there is something

162
00:06:34,830 --> 00:06:36,750
called operational audit.

163
00:06:36,750 --> 00:06:39,480
So operational audit is
something like we are proactively

164
00:06:39,480 --> 00:06:41,490
saying to you that hey,

165
00:06:41,490 --> 00:06:44,970
this x servers is having
some latency issues,

166
00:06:44,970 --> 00:06:46,260
can you take a look into it?

167
00:06:46,260 --> 00:06:49,080
So it is not, like you know, the reactive

168
00:06:49,080 --> 00:06:50,580
days allowed on and on, right?

169
00:06:50,580 --> 00:06:52,260
Like you know, now
people wanted to do more

170
00:06:52,260 --> 00:06:53,670
of proactive stuff.

171
00:06:53,670 --> 00:06:55,710
So in this case, like you
know, it will tell you,

172
00:06:55,710 --> 00:06:56,910
so not only tell you, like you know,

173
00:06:56,910 --> 00:06:58,620
there is something happening,

174
00:06:58,620 --> 00:07:01,530
but if you wanted to take
a deep dive, you just click

175
00:07:01,530 --> 00:07:03,920
on that 1.1 of the traces
that it will be showing you,

176
00:07:03,920 --> 00:07:07,350
and then it will tell you
exactly like how it is coming

177
00:07:07,350 --> 00:07:09,783
to the conclusion that
it needs some attention.

178
00:07:11,700 --> 00:07:12,780
So let's switch gears

179
00:07:12,780 --> 00:07:14,790
and then talk about real user monitoring.

180
00:07:14,790 --> 00:07:16,650
So real user monitoring
as I said, like you know,

181
00:07:16,650 --> 00:07:20,310
if you wanted to record
all your user interactions

182
00:07:20,310 --> 00:07:22,023
from browsers, like you know,

183
00:07:22,023 --> 00:07:24,840
your end user might be
using their browsers

184
00:07:24,840 --> 00:07:28,020
to get like, you know, some
insights from their browsers.

185
00:07:28,020 --> 00:07:30,300
You might be using real user monitoring.

186
00:07:30,300 --> 00:07:32,670
And we have been supporting,
like you know, this web

187
00:07:32,670 --> 00:07:36,360
for a pretty long time, and
we recently added the support

188
00:07:36,360 --> 00:07:38,037
for both Android and iOS.

189
00:07:38,037 --> 00:07:39,330
And with this one, like you know,

190
00:07:39,330 --> 00:07:42,060
you can get a lot of
information around it.

191
00:07:42,060 --> 00:07:45,750
Like for example, again, how
healthy is your application

192
00:07:45,750 --> 00:07:48,060
or, like you know, both
mobile as well as web.

193
00:07:48,060 --> 00:07:50,670
And then in terms of web,
you will be having a lot

194
00:07:50,670 --> 00:07:54,600
of details around how many
JavaScript errors I'm getting

195
00:07:54,600 --> 00:07:56,820
or, like you know, is
there any JavaScript errors

196
00:07:56,820 --> 00:07:59,190
or in the mobile world, like you know,

197
00:07:59,190 --> 00:08:01,170
it could be like in the number of crashes,

198
00:08:01,170 --> 00:08:02,490
those kind of stuff, right?

199
00:08:02,490 --> 00:08:05,160
So it'll be getting, like you
know, numerous information

200
00:08:05,160 --> 00:08:06,840
from this particular charts.

201
00:08:06,840 --> 00:08:09,480
And also like you know, when
we are extending to mobile,

202
00:08:09,480 --> 00:08:10,313
so these are all some

203
00:08:10,313 --> 00:08:12,140
of the charts you are getting it, right?

204
00:08:12,990 --> 00:08:14,850
First one is like comprehensive dashboard.

205
00:08:14,850 --> 00:08:15,900
So that's where, like
you know, you will be

206
00:08:15,900 --> 00:08:18,270
seeing both your performance metrics,

207
00:08:18,270 --> 00:08:21,750
and then your crash analytics
on all those information,

208
00:08:21,750 --> 00:08:24,150
and all these things
are coming in real time.

209
00:08:24,150 --> 00:08:26,910
So when a customer is getting a crash

210
00:08:26,910 --> 00:08:30,030
from their mobile application,
it will be recorded

211
00:08:30,030 --> 00:08:33,270
in Application Signals or
real user monitoring, so that,

212
00:08:33,270 --> 00:08:35,790
like you know, there is not
much leniency there, right?

213
00:08:35,790 --> 00:08:37,710
So the moment they are getting it,

214
00:08:37,710 --> 00:08:40,140
you are getting it in real time.

215
00:08:40,140 --> 00:08:42,660
And also, like you know,
when we are talking to many

216
00:08:42,660 --> 00:08:45,210
of the mobile app people, they wanted

217
00:08:45,210 --> 00:08:47,190
to see, like you know,
the important things

218
00:08:47,190 --> 00:08:51,390
around how much time my
app is taking to load,

219
00:08:51,390 --> 00:08:53,850
or, like you know, the
application performance index,

220
00:08:53,850 --> 00:08:55,560
those kind of things.

221
00:08:55,560 --> 00:08:58,020
Again, the mobile world is splitted,

222
00:08:58,020 --> 00:09:00,690
like, you know there is
a iOS, there is Android,

223
00:09:00,690 --> 00:09:02,700
and then here, like you
know, in Android world,

224
00:09:02,700 --> 00:09:06,030
we call it as ANR, or
application not responding.

225
00:09:06,030 --> 00:09:09,420
But in the iOS world we call
it as crash analytics, right?

226
00:09:09,420 --> 00:09:11,190
So depending on the kind

227
00:09:11,190 --> 00:09:13,290
of mobile application
we are talking about,

228
00:09:13,290 --> 00:09:16,590
we provide you both information
in the same language

229
00:09:16,590 --> 00:09:19,050
that the mobile developers
are using, right?

230
00:09:19,050 --> 00:09:20,400
So if you are using iOS,

231
00:09:20,400 --> 00:09:22,590
we'll show you all the crash analytics.

232
00:09:22,590 --> 00:09:24,030
And if you're using Android,

233
00:09:24,030 --> 00:09:25,893
we'll be showing all the ANR details.

234
00:09:26,790 --> 00:09:28,230
So with this one, like
you know, you are also

235
00:09:28,230 --> 00:09:30,660
getting, like you know,
the various information

236
00:09:30,660 --> 00:09:32,940
like, which iOS they are running

237
00:09:32,940 --> 00:09:35,130
or which version of
Android they are running,

238
00:09:35,130 --> 00:09:37,050
what type of device they're using.

239
00:09:37,050 --> 00:09:39,750
So all those kind of
information, we are capturing it,

240
00:09:39,750 --> 00:09:42,150
and then those information
are available to you.

241
00:09:43,380 --> 00:09:44,815
So we talked about, like you know,

242
00:09:44,815 --> 00:09:46,140
two different things, right?

243
00:09:46,140 --> 00:09:49,140
One is your services which
are running in the backend,

244
00:09:49,140 --> 00:09:52,350
and then the another world
is the real user monitoring,

245
00:09:52,350 --> 00:09:55,320
which could be, like you
know, web or mobile, right?

246
00:09:55,320 --> 00:09:58,080
How they are interconnected
with each other?

247
00:09:58,080 --> 00:10:00,870
So for that, like you know,
we are using correlation IDs.

248
00:10:00,870 --> 00:10:03,840
The moment, like you
know, your customer is

249
00:10:03,840 --> 00:10:07,170
doing some operation, we
will create a correlation ID,

250
00:10:07,170 --> 00:10:10,170
and then that correlation
ID is being tracked

251
00:10:10,170 --> 00:10:12,000
over multiple hops.

252
00:10:12,000 --> 00:10:15,210
So this is based on
OpenTelemetry, open standards.

253
00:10:15,210 --> 00:10:18,000
And again, like you know, the
end-to-end transaction tracing

254
00:10:18,000 --> 00:10:19,530
is available for you.

255
00:10:19,530 --> 00:10:22,680
So once there is an
error that is happening,

256
00:10:22,680 --> 00:10:24,240
you can easily track it all the way

257
00:10:24,240 --> 00:10:27,810
from your mobile application
to your backend service.

258
00:10:27,810 --> 00:10:30,780
And also with this newer
application map feature,

259
00:10:30,780 --> 00:10:33,780
you'll be having automatic
topology discovery as well

260
00:10:33,780 --> 00:10:36,600
as visualization so that
from one place you'll be able

261
00:10:36,600 --> 00:10:39,303
to see how things are
interconnected with each other.

262
00:10:40,170 --> 00:10:42,780
And also it is showing you the
service dependency as well.

263
00:10:42,780 --> 00:10:44,070
So you might be wondering, like you know,

264
00:10:44,070 --> 00:10:47,220
how my A is calling B and
all those information,

265
00:10:47,220 --> 00:10:49,680
that is also available for you.

266
00:10:49,680 --> 00:10:52,740
And also the performance
metrics overlay at each tier.

267
00:10:52,740 --> 00:10:55,320
I don't know whether you noticed it,

268
00:10:55,320 --> 00:10:57,600
every tile will be having a donut chart.

269
00:10:57,600 --> 00:10:59,640
So the donut chart is color coded.

270
00:10:59,640 --> 00:11:01,290
So every chart,

271
00:11:01,290 --> 00:11:03,090
when you are having, like
you know, some issues,

272
00:11:03,090 --> 00:11:04,440
it will be showing in red.

273
00:11:04,440 --> 00:11:05,730
So that needs, like you know,

274
00:11:05,730 --> 00:11:07,650
it needs some attention, right?

275
00:11:07,650 --> 00:11:08,850
So on a high level,

276
00:11:08,850 --> 00:11:11,070
if it is, like you know,
a thousand foot overview

277
00:11:11,070 --> 00:11:13,710
of your application, you can
easily see, like you know,

278
00:11:13,710 --> 00:11:16,590
which tile is showing you red or green,

279
00:11:16,590 --> 00:11:18,720
those kind of information,
so that it's easy

280
00:11:18,720 --> 00:11:20,733
for you to figure out what's going on.

281
00:11:21,780 --> 00:11:24,120
So it's easy for this
bottleneck identification

282
00:11:24,120 --> 00:11:27,270
and visual indicators
using that one, right?

283
00:11:27,270 --> 00:11:29,294
So with that one, like you know,

284
00:11:29,294 --> 00:11:30,600
this is how the architecture is.

285
00:11:30,600 --> 00:11:33,960
From your mobile
applications, you are sending,

286
00:11:33,960 --> 00:11:36,150
whether it is iOS or Android,

287
00:11:36,150 --> 00:11:37,680
you are sending your telemetry

288
00:11:37,680 --> 00:11:40,050
to CloudWatch real user monitoring.

289
00:11:40,050 --> 00:11:41,880
From CloudWatch real user monitoring,

290
00:11:41,880 --> 00:11:44,910
we will do the job of taking those metrics

291
00:11:44,910 --> 00:11:47,490
and then sending it to
Application Signals.

292
00:11:47,490 --> 00:11:48,900
And in that bottom side, like you know,

293
00:11:48,900 --> 00:11:50,790
you have your backend services.

294
00:11:50,790 --> 00:11:52,500
So with this backend services,

295
00:11:52,500 --> 00:11:55,020
you are sending your telemetry as well.

296
00:11:55,020 --> 00:11:59,010
Again, everywhere it is via
OpenTelemetry, open standards.

297
00:11:59,010 --> 00:12:01,680
And if you are a user, so
in this case, like you know,

298
00:12:01,680 --> 00:12:04,350
assume we are seeing
from the right hand side.

299
00:12:04,350 --> 00:12:06,150
We are seeing from the right hand side

300
00:12:06,150 --> 00:12:09,600
with this Application
Signals and application map.

301
00:12:09,600 --> 00:12:11,250
So using that, not only you're going

302
00:12:11,250 --> 00:12:15,780
to monitor your applications,
and if something is breaking,

303
00:12:15,780 --> 00:12:18,690
we are gonna see, like you
know, how you're gonna fix it.

304
00:12:18,690 --> 00:12:21,210
So that's what all about
the code we will be

305
00:12:21,210 --> 00:12:23,520
showing you from Alex.

306
00:12:23,520 --> 00:12:26,320
So with that one, like you
know, let's go with the code.

307
00:12:27,690 --> 00:12:28,790
- [Alex] Hi, everyone.

308
00:12:29,940 --> 00:12:33,183
A software engineers
and system architects,

309
00:12:34,260 --> 00:12:39,153
how many times have you looked
at the architecture diagram,

310
00:12:40,470 --> 00:12:43,980
something like this, and
thought to yourself, well,

311
00:12:43,980 --> 00:12:48,963
this is like some really ugly
spaghetti monster right there.

312
00:12:49,890 --> 00:12:54,690
And how many of you actually
build a system like that?

313
00:12:54,690 --> 00:12:57,120
I did. My name is Alex Nazarov.

314
00:12:57,120 --> 00:12:59,823
I'm a principal engineer in CloudWatch.

315
00:13:02,130 --> 00:13:07,130
Many projects start with
simple, beautiful architecture,

316
00:13:07,380 --> 00:13:11,250
but then your business
grows, you add features,

317
00:13:11,250 --> 00:13:15,060
you add redundancy, you add security,

318
00:13:15,060 --> 00:13:18,900
you add search index, you add analytics,

319
00:13:18,900 --> 00:13:21,180
this list goes on and on.

320
00:13:21,180 --> 00:13:22,530
And so you get the idea.

321
00:13:22,530 --> 00:13:27,090
Eventually the system becomes
so difficult to comprehend.

322
00:13:27,090 --> 00:13:31,470
Even people who build that
system, six months down the road,

323
00:13:31,470 --> 00:13:33,840
will have hard time
understanding what's happening

324
00:13:33,840 --> 00:13:34,673
under the hood.

325
00:13:36,570 --> 00:13:40,170
You see, the problem is not

326
00:13:40,170 --> 00:13:43,890
that distributed systems
are over-engineered.

327
00:13:43,890 --> 00:13:48,540
The reality is that real user scenarios,

328
00:13:48,540 --> 00:13:52,743
real life scenarios requires
building complex systems.

329
00:13:53,910 --> 00:13:57,630
And this system stretching
human abilities to understand

330
00:13:57,630 --> 00:14:00,423
and keep track of what's
going on in the system.

331
00:14:02,160 --> 00:14:04,650
So when we approach this challenge,

332
00:14:04,650 --> 00:14:07,050
we talked to our customers.

333
00:14:07,050 --> 00:14:09,690
And they said, "You know what?

334
00:14:09,690 --> 00:14:13,410
Instead of this, I want to have a way

335
00:14:13,410 --> 00:14:17,700
to look at all that I
have in all my accounts

336
00:14:17,700 --> 00:14:21,030
on one page, kind of like this.

337
00:14:21,030 --> 00:14:25,620
So show me on the high level what I have,

338
00:14:25,620 --> 00:14:30,390
and also help me to understand the status

339
00:14:30,390 --> 00:14:33,123
of like health status of each application.

340
00:14:34,350 --> 00:14:38,550
But when I'm interested,
I wanna dive deep,

341
00:14:38,550 --> 00:14:43,550
like, go inside and see its gut,

342
00:14:43,710 --> 00:14:46,230
see what's happening under the hood,

343
00:14:46,230 --> 00:14:50,310
but then I should be
able to go back, zoom out

344
00:14:50,310 --> 00:14:54,060
and look it up on the high level."

345
00:14:54,060 --> 00:14:58,020
So we used this as a guidance

346
00:14:58,020 --> 00:15:01,473
when we worked on this
new application map.

347
00:15:05,460 --> 00:15:08,643
What we introduced here
is dynamic grouping.

348
00:15:09,510 --> 00:15:14,190
So what Application Signals
in this map is trying to do

349
00:15:14,190 --> 00:15:19,190
at its best effort is
to discover resources

350
00:15:19,530 --> 00:15:24,507
like API gateways, load
balancers, EKS, ECS clusters,

351
00:15:25,770 --> 00:15:30,770
EC2 auto scaling groups, and
use them as a backbone that,

352
00:15:31,800 --> 00:15:36,800
or like a tip of the iceberg,
to present a structure

353
00:15:38,430 --> 00:15:42,303
that forms applications
that you're hosting on AWS.

354
00:15:43,200 --> 00:15:47,040
Previously, Application
Signals only worked

355
00:15:47,040 --> 00:15:48,270
with instrumented sources.

356
00:15:48,270 --> 00:15:50,220
You would have to instrument your code.

357
00:15:51,840 --> 00:15:56,520
But we just recently added functionality

358
00:15:56,520 --> 00:16:01,503
that like I highlighted on
this map with the dotted lines,

359
00:16:02,550 --> 00:16:05,950
these are the applications that we believe

360
00:16:07,110 --> 00:16:10,170
just entry points into
something much bigger.

361
00:16:10,170 --> 00:16:11,400
It's not instrumented

362
00:16:11,400 --> 00:16:14,640
but you still have all the benefits

363
00:16:14,640 --> 00:16:19,140
that like minimalistic PM
functionality for these services.

364
00:16:19,140 --> 00:16:22,470
So for example, I have this
ticketing lite service.

365
00:16:22,470 --> 00:16:25,113
It essentially allows
customers submit tickets.

366
00:16:26,490 --> 00:16:31,490
When I explore details
for this application,

367
00:16:31,740 --> 00:16:34,470
I see first of all there
are, like, it discovered

368
00:16:34,470 --> 00:16:36,213
four services under the hood.

369
00:16:37,590 --> 00:16:42,483
It tells me, you know,
it's bridging some SLOs.

370
00:16:43,740 --> 00:16:47,670
These are the most recent
deployments for this application.

371
00:16:47,670 --> 00:16:52,670
This is taken from CloudTrail,
and the golden signal metrics

372
00:16:54,300 --> 00:16:59,163
like availability, some latency,
server faults, user errors.

373
00:17:01,500 --> 00:17:04,473
I can go dive inside of it.

374
00:17:06,390 --> 00:17:08,400
And again, everything
is a dotted line here.

375
00:17:08,400 --> 00:17:10,980
It means it's not instrumented,

376
00:17:10,980 --> 00:17:12,840
but it's pretty straightforward.

377
00:17:12,840 --> 00:17:15,690
I have a API gateway,

378
00:17:15,690 --> 00:17:17,790
and it has three Lambda functions

379
00:17:17,790 --> 00:17:19,870
that implement some of the APIs

380
00:17:20,880 --> 00:17:25,880
backed up by this list
tickets, read tickets,

381
00:17:26,220 --> 00:17:28,533
submit tickets, pretty straightforward.

382
00:17:29,400 --> 00:17:33,540
And even from this map, I already can see

383
00:17:33,540 --> 00:17:36,510
that okay, I have issue
that my customers facing,

384
00:17:36,510 --> 00:17:38,730
because it's an API gateway,

385
00:17:38,730 --> 00:17:41,670
and then it's actually going
into the submit ticket.

386
00:17:41,670 --> 00:17:43,353
So submit ticket has issues.

387
00:17:45,630 --> 00:17:48,480
From this, you know, overall
description I can only see,

388
00:17:48,480 --> 00:17:50,820
well, it got deployed recently.

389
00:17:50,820 --> 00:17:54,480
The deployments are marked as
vertical lines on the graphs

390
00:17:54,480 --> 00:17:57,210
but I don't see any
correlation with deployments.

391
00:17:57,210 --> 00:18:01,230
So at this point, the
best idea for me would be

392
00:18:01,230 --> 00:18:03,243
to instrument this application.

393
00:18:05,010 --> 00:18:09,060
I can go and instrument each
individual Lambda separately.

394
00:18:09,060 --> 00:18:11,730
Or on the high level,

395
00:18:11,730 --> 00:18:15,240
I can just use, you
know, this context menu

396
00:18:15,240 --> 00:18:17,730
to enable Application Signals

397
00:18:17,730 --> 00:18:21,453
for all of the components
inside of this application.

398
00:18:22,320 --> 00:18:25,380
So here I can just like
click, click, enable

399
00:18:25,380 --> 00:18:26,213
on all the Lambdas.

400
00:18:26,213 --> 00:18:27,150
What's gonna happen is

401
00:18:27,150 --> 00:18:32,150
that this enablement will
add OpenTelemetry layer

402
00:18:32,730 --> 00:18:34,200
to this Lambda functions.

403
00:18:34,200 --> 00:18:38,310
It will not add the
agent, but only the SDK,

404
00:18:38,310 --> 00:18:42,573
the client side, that will
talk to OTLP endpoint.

405
00:18:43,770 --> 00:18:44,823
So the benefit of that is

406
00:18:44,823 --> 00:18:48,660
that you actually not wasting
resources on the agent,

407
00:18:48,660 --> 00:18:51,993
and it does not increase the,

408
00:18:52,980 --> 00:18:56,043
the agent does not increase
the, from the cold start.

409
00:18:58,530 --> 00:19:01,320
So I already, so the enablement
takes roughly five minutes.

410
00:19:01,320 --> 00:19:03,300
So I already have a carbon copy

411
00:19:03,300 --> 00:19:05,550
of that ticketing service over here

412
00:19:05,550 --> 00:19:07,023
that is already instrumented.

413
00:19:07,920 --> 00:19:10,860
So now when I look at instrumented version

414
00:19:10,860 --> 00:19:15,780
of that application, I
see more details, right?

415
00:19:15,780 --> 00:19:18,360
So now I can see that, okay,

416
00:19:18,360 --> 00:19:23,360
this is that problematic
submit ticket Lambda,

417
00:19:24,150 --> 00:19:28,230
but it also brought in another
Lambda and this SQS queue.

418
00:19:28,230 --> 00:19:30,270
So this is how they
communicate this synchronously

419
00:19:30,270 --> 00:19:35,270
with each other, also showing
me the tickets, DynamoDB table

420
00:19:35,760 --> 00:19:37,860
that these Lambdas are using.

421
00:19:37,860 --> 00:19:41,070
So I got much better picture
about what is actually

422
00:19:41,070 --> 00:19:43,443
happening right now with my system.

423
00:19:45,150 --> 00:19:47,703
And after instrumentation,

424
00:19:49,170 --> 00:19:53,820
what is also available to me
is this operational audit.

425
00:19:53,820 --> 00:19:57,840
On the high level,
operational audit just goes

426
00:19:57,840 --> 00:20:02,040
finds what you would do
manually just find traces,

427
00:20:02,040 --> 00:20:07,040
find exceptions, and
it just surfaces it up

428
00:20:07,260 --> 00:20:11,010
so you can actually not
diving into the logs

429
00:20:11,010 --> 00:20:15,930
or doing any complicated
research, you see exactly.

430
00:20:15,930 --> 00:20:17,420
Okay, this Lambda called SQS,

431
00:20:17,420 --> 00:20:20,700
and this is the exception message

432
00:20:20,700 --> 00:20:24,690
that says well you're trying
to submit too big of a message

433
00:20:24,690 --> 00:20:26,940
to the queue and it doesn't accept it.

434
00:20:26,940 --> 00:20:28,923
And this is how we got that exception.

435
00:20:33,120 --> 00:20:35,760
Now what's I wanna also show is

436
00:20:35,760 --> 00:20:40,760
that this audit is available
from your dev environment,

437
00:20:42,870 --> 00:20:45,180
like IDE, so in this case I'm showing Kiro

438
00:20:45,180 --> 00:20:48,483
but VS Code with client
would do exactly same thing.

439
00:20:49,560 --> 00:20:52,740
I have here pre-installed
CloudWatch Application Signals,

440
00:20:52,740 --> 00:20:56,340
MCP server, and the way
to get it is actually,

441
00:20:56,340 --> 00:21:00,873
it's available on
awslabs under mcp folder,

442
00:21:01,830 --> 00:21:05,313
and there is a
cloudWatch-applicationsignals-mcp-server.

443
00:21:06,930 --> 00:21:11,430
So what I can do now, this IDE talks

444
00:21:11,430 --> 00:21:15,660
to the telemetry that captures the state

445
00:21:15,660 --> 00:21:19,110
of my production, I
can ask questions like,

446
00:21:19,110 --> 00:21:21,033
which services are breaching SLO?

447
00:21:22,290 --> 00:21:27,290
And right now it actually
went, scanned that map,

448
00:21:27,480 --> 00:21:31,530
list of services, figured out
which ones are breaching SLO

449
00:21:31,530 --> 00:21:32,853
and reporting this to me.

450
00:21:33,990 --> 00:21:38,990
And I can also with it individual
services, like I can say,

451
00:21:39,300 --> 00:21:44,300
well, what's wrong with
that submit ticket, right?

452
00:21:44,370 --> 00:21:49,370
So submit ticket is gonna like
execute public API available

453
00:21:52,920 --> 00:21:56,523
that you can also use that,
runs the operational audit.

454
00:21:58,170 --> 00:22:01,860
And from this operational audit,

455
00:22:01,860 --> 00:22:04,770
it makes the same
conclusion that we just saw,

456
00:22:04,770 --> 00:22:07,560
that message on the screen.

457
00:22:07,560 --> 00:22:08,940
It's saying you trying

458
00:22:08,940 --> 00:22:13,200
to submit messages bigger
than the queue can accept.

459
00:22:13,200 --> 00:22:17,880
And the benefit of this is
that you can essentially

460
00:22:17,880 --> 00:22:21,813
do your root cause analysis
troubleshooting from IDE,

461
00:22:22,800 --> 00:22:27,390
and instantly connect your
code with what's happening

462
00:22:27,390 --> 00:22:30,930
with your services in production.

463
00:22:30,930 --> 00:22:33,720
And the IDE already knows, like,

464
00:22:33,720 --> 00:22:37,770
because you loaded that code base in IDE,

465
00:22:37,770 --> 00:22:42,720
it connects that stack trace
that it found in telemetry,

466
00:22:42,720 --> 00:22:45,900
and it says which line of
code is causing this problem.

467
00:22:45,900 --> 00:22:49,800
It suggests remediation or fixes,

468
00:22:49,800 --> 00:22:54,213
how you can actually
mitigate that problem.

469
00:22:55,470 --> 00:22:59,610
Okay, so now let's go back

470
00:22:59,610 --> 00:23:04,557
and talk about how to customize this map.

471
00:23:08,040 --> 00:23:13,040
So right now what you're
seeing here is best effort

472
00:23:15,600 --> 00:23:17,343
to group all services,

473
00:23:18,600 --> 00:23:20,310
what we call it, like, related services.

474
00:23:20,310 --> 00:23:24,270
Essentially many applications
have an entry point

475
00:23:24,270 --> 00:23:28,680
like a load balancer or some
front end service, API gateway,

476
00:23:28,680 --> 00:23:33,680
and this is what we're
discovering and showing.

477
00:23:34,320 --> 00:23:39,320
Yeah, like you have, you
know, this for example,

478
00:23:39,810 --> 00:23:44,760
appointment service, it has
like this microservices,

479
00:23:44,760 --> 00:23:46,563
this how they related to each other.

480
00:23:48,060 --> 00:23:52,590
There are some components that
not connected with anything,

481
00:23:52,590 --> 00:23:54,790
they have their own
like standalone version,

482
00:23:56,640 --> 00:24:01,640
but we also allow you
to customize this map.

483
00:24:02,040 --> 00:24:07,040
And so by default, you could
see also all the services

484
00:24:07,980 --> 00:24:09,870
grouped by environment.

485
00:24:09,870 --> 00:24:14,870
So by environment you
can use OTel attributes,

486
00:24:16,350 --> 00:24:21,350
and say deployment.environment.name.

487
00:24:22,200 --> 00:24:26,310
And that way, you can
differentiate your production

488
00:24:26,310 --> 00:24:29,160
versus test performance, et cetera.

489
00:24:29,160 --> 00:24:30,600
So that way, you can

490
00:24:30,600 --> 00:24:32,853
regroup all your services by environment.

491
00:24:34,140 --> 00:24:38,793
But in addition, we have
this way of custom grouping.

492
00:24:39,810 --> 00:24:41,970
So it's a little bit involving,

493
00:24:41,970 --> 00:24:44,163
but, so bear with me for a moment.

494
00:24:45,780 --> 00:24:50,780
So let's say I would like
to have different groupings

495
00:24:53,130 --> 00:24:56,820
of all the resources and
all the services I have

496
00:24:56,820 --> 00:24:58,830
across multiple accounts.

497
00:24:58,830 --> 00:25:03,330
So I would create this
groupings over here, like I want

498
00:25:03,330 --> 00:25:07,770
to actually control, myself,
what composes my application.

499
00:25:07,770 --> 00:25:12,360
So I have create a
grouping by application.

500
00:25:12,360 --> 00:25:14,670
Another part that's
important to me is tiering,

501
00:25:14,670 --> 00:25:16,260
like tier one, tier two service,

502
00:25:16,260 --> 00:25:18,690
like, how it's important to my business.

503
00:25:18,690 --> 00:25:21,780
And then team ownership.

504
00:25:21,780 --> 00:25:25,890
I can, you know, assign services

505
00:25:25,890 --> 00:25:27,813
to the teams who operate on them.

506
00:25:28,860 --> 00:25:32,100
So this on the left
side, on the right side,

507
00:25:32,100 --> 00:25:37,080
what I'm specifying here is AWS tags,

508
00:25:37,080 --> 00:25:39,360
these are the tag names.

509
00:25:39,360 --> 00:25:44,360
So if I have a name tag named
application or app.name,

510
00:25:46,770 --> 00:25:51,120
or myapp on API gateway, the value

511
00:25:51,120 --> 00:25:54,330
that this tag is carrying will be the name

512
00:25:54,330 --> 00:25:55,833
of that application.

513
00:25:57,270 --> 00:25:59,340
The same with the tier and the team.

514
00:25:59,340 --> 00:26:04,340
So these are just AWS tags
that I'm saying should be used

515
00:26:05,340 --> 00:26:06,423
to create grouping.

516
00:26:07,320 --> 00:26:09,243
In addition to AWS tags,

517
00:26:10,470 --> 00:26:13,593
we also support OTEL_RESOURCE_ATTRIBUTES.

518
00:26:15,240 --> 00:26:16,713
I brought them here.

519
00:26:18,120 --> 00:26:20,580
So OTEL_RESOURCE_ATTRIBUTES is

520
00:26:20,580 --> 00:26:23,250
when you instrument your
code, you have a chance

521
00:26:23,250 --> 00:26:25,540
to define additional key-value pairs

522
00:26:27,150 --> 00:26:30,930
for this services that get instrumented

523
00:26:30,930 --> 00:26:32,910
with OTel telemetry.

524
00:26:32,910 --> 00:26:34,460
So, and this is what you would,

525
00:26:35,370 --> 00:26:39,810
you could use alternatively to the tags.

526
00:26:39,810 --> 00:26:41,920
You could use just
OTEL_RESOURCE_ATTRIBUTES

527
00:26:41,920 --> 00:26:43,200
and pretty much do the same thing.

528
00:26:43,200 --> 00:26:46,620
Specify that this microservice now belongs

529
00:26:46,620 --> 00:26:49,233
to let's say, pet clinic application.

530
00:26:50,670 --> 00:26:53,733
So after that is configured,

531
00:26:55,650 --> 00:26:58,410
I'll, you know, give it some time,

532
00:26:58,410 --> 00:27:02,403
and when telemetry gets
ingested into CloudWatch,

533
00:27:04,230 --> 00:27:08,640
the application map will form
with these custom groupings.

534
00:27:08,640 --> 00:27:12,990
So for example, this is the
grouping by application,

535
00:27:12,990 --> 00:27:15,930
because I have annotated my telemetry,

536
00:27:15,930 --> 00:27:19,500
or I annotated resources with AWS tags

537
00:27:19,500 --> 00:27:21,273
with these values of telemetry.

538
00:27:23,340 --> 00:27:27,543
And this is example of, let's say, tiers.

539
00:27:28,530 --> 00:27:29,940
And this is how I can work.

540
00:27:29,940 --> 00:27:33,540
I actually can chain this grouping by.

541
00:27:33,540 --> 00:27:35,550
I could start with tiering.

542
00:27:35,550 --> 00:27:37,410
Like, let's say the most important to me,

543
00:27:37,410 --> 00:27:40,680
I wanna work on tier one
services, I see they all in red,

544
00:27:40,680 --> 00:27:45,030
but I'm interested in
tier one first, right?

545
00:27:45,030 --> 00:27:48,840
So I go inside and it's quite complicated.

546
00:27:48,840 --> 00:27:52,620
So I can group on for the second level,

547
00:27:52,620 --> 00:27:55,290
say well, now I just want
to see them by application.

548
00:27:55,290 --> 00:27:57,270
Well, there actually three
different application

549
00:27:57,270 --> 00:28:00,873
in tier one, payment, pet
clinic, ticketing system.

550
00:28:01,800 --> 00:28:06,390
Then I can go essentially inside of them

551
00:28:06,390 --> 00:28:09,603
and inspect that,

552
00:28:10,440 --> 00:28:13,443
let's say, this application,
pet clinic, right?

553
00:28:14,430 --> 00:28:18,600
Or I can go back completely, back up,

554
00:28:18,600 --> 00:28:21,240
and regroup by applications

555
00:28:21,240 --> 00:28:23,793
and see what's available in this account.

556
00:28:25,020 --> 00:28:29,993
So let's actually dive into
pet clinic, and what this-

557
00:28:32,700 --> 00:28:35,340
- [Siva] By the way, if you
have any questions, please

558
00:28:35,340 --> 00:28:37,770
ask it, like you know, let's
make it as interactive.

559
00:28:37,770 --> 00:28:39,090
If you have any questions,
please feel free

560
00:28:39,090 --> 00:28:40,170
to ask any questions.

561
00:28:40,170 --> 00:28:42,003
Sorry Alex.
- No worries.

562
00:28:43,290 --> 00:28:47,730
So what we try to achieve here is for,

563
00:28:47,730 --> 00:28:51,120
that's what, you know,
customer sentiment was.

564
00:28:51,120 --> 00:28:53,640
I wanna use the map to guide me

565
00:28:53,640 --> 00:28:56,490
to when I'm paged for example.

566
00:28:56,490 --> 00:29:01,233
And so what this map is
highlighting, let's say,

567
00:29:02,160 --> 00:29:03,810
four services in red,

568
00:29:03,810 --> 00:29:06,753
they breaching their
service level objectives.

569
00:29:07,770 --> 00:29:09,753
And besides that,

570
00:29:10,770 --> 00:29:15,770
every component also shows,
it's like a health circle

571
00:29:17,490 --> 00:29:22,170
that shows a breakdown between
server faults, user errors,

572
00:29:22,170 --> 00:29:24,423
and successful requests.

573
00:29:25,260 --> 00:29:29,490
And you can kind of gauge from
that where the problems are.

574
00:29:29,490 --> 00:29:31,470
First of all, what's highlighted in red.

575
00:29:31,470 --> 00:29:33,690
Second, if let's say, you didn't

576
00:29:33,690 --> 00:29:36,180
set up any service level objectives,

577
00:29:36,180 --> 00:29:38,670
you can just gauge from that circle.

578
00:29:38,670 --> 00:29:42,750
The more red means, you know,
more problems essentially.

579
00:29:42,750 --> 00:29:47,750
And you can like instantly
go and inspect each component

580
00:29:48,360 --> 00:29:52,050
and get this operational audit.

581
00:29:52,050 --> 00:29:55,140
And for example, in this
case, I get whole bunch

582
00:29:55,140 --> 00:29:58,890
of, you know, these audit
cards that tell me, you know,

583
00:29:58,890 --> 00:30:02,580
we have this problematic dependency

584
00:30:02,580 --> 00:30:07,580
and it could set like some,
you know, unhandled edge case,

585
00:30:08,749 --> 00:30:10,053
et cetera.

586
00:30:11,430 --> 00:30:16,430
And this one is interesting,
one of the auditors

587
00:30:16,560 --> 00:30:18,720
will try to find an outlier.

588
00:30:18,720 --> 00:30:22,580
And by outlier I mean some
of the resources, like a pod

589
00:30:22,580 --> 00:30:27,580
or a node or EC2 instance,
that contributing the most

590
00:30:28,140 --> 00:30:31,950
to errors or to high
latencies in your application.

591
00:30:31,950 --> 00:30:36,950
So this is, this audit card is
finding exactly this scenario

592
00:30:37,680 --> 00:30:39,750
suggesting that you would want

593
00:30:39,750 --> 00:30:43,053
to recycle this resource, right?

594
00:30:44,310 --> 00:30:45,450
But it's all good

595
00:30:45,450 --> 00:30:50,010
and great knowing what's
happening on the server side,

596
00:30:50,010 --> 00:30:54,240
but sometimes we don't
have full visibility

597
00:30:54,240 --> 00:30:59,240
into what's happening with the,
what the client experiences,

598
00:30:59,310 --> 00:31:03,420
because the server side instrumentation

599
00:31:03,420 --> 00:31:06,330
gives us so much, right?

600
00:31:06,330 --> 00:31:09,600
And for that, there are two techniques

601
00:31:09,600 --> 00:31:13,470
that CloudWatch suggests you could use.

602
00:31:13,470 --> 00:31:17,790
One is synthetic canneries.

603
00:31:17,790 --> 00:31:21,870
So this is an example of a whole bunch

604
00:31:21,870 --> 00:31:24,510
of different synthetic canneries
that continuously running,

605
00:31:24,510 --> 00:31:29,510
executing APIs, and
validating that AWS responses,

606
00:31:31,440 --> 00:31:34,260
actually match the expected results.

607
00:31:34,260 --> 00:31:36,030
And you can see like,

608
00:31:36,030 --> 00:31:38,700
well, they're actually
not always succeeding.

609
00:31:38,700 --> 00:31:42,153
There's a only 96% success rate,

610
00:31:43,140 --> 00:31:45,273
but there is a also,

611
00:31:47,880 --> 00:31:50,013
they call synthetics for a reason.

612
00:31:51,060 --> 00:31:54,693
So they not fully represent
the actual customer experience.

613
00:31:56,280 --> 00:32:01,280
And to measure that, CloudWatch
has real user monitoring.

614
00:32:02,700 --> 00:32:07,700
So real user monitoring
is essentially a set

615
00:32:10,410 --> 00:32:15,410
of APIs including the client side SDK

616
00:32:15,600 --> 00:32:19,290
that you can use to instrument a website.

617
00:32:19,290 --> 00:32:23,890
So like this example is
the app monitor that,

618
00:32:27,600 --> 00:32:29,970
it just essentially a bunch of JavaScripts

619
00:32:29,970 --> 00:32:31,980
that included with a website,

620
00:32:31,980 --> 00:32:35,370
that continuously measuring
and reporting back home

621
00:32:35,370 --> 00:32:37,950
about how these pages
are loading, how fast,

622
00:32:37,950 --> 00:32:40,173
are there any JavaScript there, et cetera.

623
00:32:41,040 --> 00:32:43,470
And what we just recently launched

624
00:32:43,470 --> 00:32:48,240
is a similar client side instrumentation

625
00:32:48,240 --> 00:32:53,240
for Android applications
and for iOS applications.

626
00:32:56,700 --> 00:33:01,170
So that way, when you look
at this application map,

627
00:33:01,170 --> 00:33:04,320
you're not only seeing how
your services are performing,

628
00:33:04,320 --> 00:33:07,623
but you're also seeing what
your customers are experiencing.

629
00:33:08,730 --> 00:33:12,810
And so from this picture I
could say that, like again,

630
00:33:12,810 --> 00:33:17,810
there's a health status
circle, it tells me that, well,

631
00:33:18,420 --> 00:33:22,500
the Android customers are
really having a bad day.

632
00:33:22,500 --> 00:33:27,500
I have too many crashes,
like also server faults,

633
00:33:27,510 --> 00:33:31,410
and these graphs, they kind
of support that, they just

634
00:33:31,410 --> 00:33:35,943
seeing how historically
those issues been happening.

635
00:33:38,100 --> 00:33:41,130
So at this point, I would
like to troubleshoot more,

636
00:33:41,130 --> 00:33:45,030
and get to the real user monitoring part

637
00:33:45,030 --> 00:33:46,773
of the AWS console.

638
00:33:47,970 --> 00:33:51,903
So in here, real user monitors
in Application Signals,

639
00:33:51,903 --> 00:33:54,630
that they connected with the service,

640
00:33:54,630 --> 00:33:58,710
that this, you know, client
applications are hitting first,

641
00:33:58,710 --> 00:34:01,233
like in this case, it's
a pet planning front end.

642
00:34:02,700 --> 00:34:06,600
And I have three different
real user monitors

643
00:34:06,600 --> 00:34:09,633
for this microservice.

644
00:34:10,860 --> 00:34:15,810
So this one is for website,
this one is for, sorry,

645
00:34:15,810 --> 00:34:18,690
this one for iOS, this one is for website

646
00:34:18,690 --> 00:34:20,460
and this one is for Android.

647
00:34:20,460 --> 00:34:24,423
And I could tell from here, from details,

648
00:34:25,470 --> 00:34:29,430
which pages or screens
actually having issues

649
00:34:29,430 --> 00:34:31,710
in Android application.

650
00:34:31,710 --> 00:34:35,100
And so like, this is a number of crashes.

651
00:34:35,100 --> 00:34:38,490
And so the owner details
activity is the one

652
00:34:38,490 --> 00:34:40,893
that has the most problems.

653
00:34:43,500 --> 00:34:47,550
To troubleshoot even
further, like first of all,

654
00:34:47,550 --> 00:34:52,550
I can go and use Android
Studio, so I have it preloaded,

655
00:34:53,970 --> 00:34:56,970
to validate like, is
this actually happening,

656
00:34:56,970 --> 00:35:01,970
so I can go check on
list of all the owners.

657
00:35:03,240 --> 00:35:06,840
So I'm running a simulation
of this, of OLAP,

658
00:35:08,787 --> 00:35:12,930
and when I click a individual owner,

659
00:35:12,930 --> 00:35:14,460
it essentially resets.

660
00:35:14,460 --> 00:35:18,270
So I do see that this
application is crashing

661
00:35:18,270 --> 00:35:19,923
on that particular screen.

662
00:35:21,120 --> 00:35:24,333
So to root cause it even further,

663
00:35:25,175 --> 00:35:30,175
I can click on any data
point on the crashes graph,

664
00:35:32,070 --> 00:35:37,070
and we'll get like
essentially a list of sessions

665
00:35:37,080 --> 00:35:41,700
that resulted in application crashes.

666
00:35:41,700 --> 00:35:46,410
So this data is transferred
from the mobile app

667
00:35:46,410 --> 00:35:49,203
to RUM service,

668
00:35:50,400 --> 00:35:53,730
and at this point I can
just, you know, spot check.

669
00:35:53,730 --> 00:35:56,970
For example, I pick a session,

670
00:35:56,970 --> 00:36:01,970
and I get transferred to RUM console,

671
00:36:02,640 --> 00:36:05,730
and then here I can look at the exception.

672
00:36:05,730 --> 00:36:09,603
So this is the stack
trace for this exception.

673
00:36:10,950 --> 00:36:15,083
I can just go and transfer it
back to the Android Studio,

674
00:36:17,760 --> 00:36:22,760
analyze this stack
trace, and essentially go

675
00:36:23,820 --> 00:36:27,120
to the line that causing the issue.

676
00:36:27,120 --> 00:36:28,830
Just help me to understand where I need

677
00:36:28,830 --> 00:36:30,573
to implement the fix.

678
00:36:31,650 --> 00:36:36,650
So enabling RUM for
mobile, and I'm gonna show

679
00:36:39,060 --> 00:36:42,210
for Android, it's very straightforward.

680
00:36:42,210 --> 00:36:45,060
So there's one more, there
is one dependency you need

681
00:36:45,060 --> 00:36:50,060
to include in your, you know, build file,

682
00:36:51,450 --> 00:36:56,450
which is OTel SDK, but
it's packaged by Amazon.

683
00:36:59,220 --> 00:37:02,220
We just picked all the
pieces needed from OTel

684
00:37:02,220 --> 00:37:04,233
to support that functionality.

685
00:37:05,160 --> 00:37:09,810
And you also need to create app monitor,

686
00:37:09,810 --> 00:37:13,710
and specified in the configuration file

687
00:37:13,710 --> 00:37:17,940
that this application will be recorded

688
00:37:17,940 --> 00:37:20,220
through this RUM monitor,

689
00:37:20,220 --> 00:37:23,463
and just specify the region
where the telemetry will flow.

690
00:37:24,510 --> 00:37:25,910
And that's how to set it up.

691
00:37:27,840 --> 00:37:32,640
And if I go back, just one
thing I wanted to summarize is

692
00:37:32,640 --> 00:37:37,200
that application map is

693
00:37:37,200 --> 00:37:41,400
acting essentially as a guiding tool.

694
00:37:41,400 --> 00:37:44,400
You can think of it as a dashboard,

695
00:37:44,400 --> 00:37:47,040
but interactive dashboard.

696
00:37:47,040 --> 00:37:48,180
From this dashboard,

697
00:37:48,180 --> 00:37:51,690
you're not only looking
just at metrics and graphs,

698
00:37:51,690 --> 00:37:53,640
you're looking at your life system,

699
00:37:53,640 --> 00:37:57,960
how it performs at the
moment or historically,

700
00:37:57,960 --> 00:38:00,630
you can go and check different time.

701
00:38:00,630 --> 00:38:02,760
Let's say you, if you're
investigating an event

702
00:38:02,760 --> 00:38:06,600
that happened last night or two weeks ago,

703
00:38:06,600 --> 00:38:09,630
you can change the timeframe
and go back to that time

704
00:38:09,630 --> 00:38:14,400
and see, it will historically
show how your system behaved

705
00:38:14,400 --> 00:38:15,303
at that time.

706
00:38:17,010 --> 00:38:21,630
And you're not only seeing
how your services performing

707
00:38:21,630 --> 00:38:26,160
or how your resources
responding to requests,

708
00:38:26,160 --> 00:38:28,530
but now you also with mobile RUM,

709
00:38:28,530 --> 00:38:32,940
you can also see end user experience.

710
00:38:32,940 --> 00:38:36,393
And essentially that way,

711
00:38:37,290 --> 00:38:42,243
oversee all your distributed
system from start to end.

712
00:38:43,140 --> 00:38:46,923
So Application Signals what it does,

713
00:38:48,082 --> 00:38:51,420
it, after you instrument it,

714
00:38:51,420 --> 00:38:55,350
it actually connects metrics,
logs, and traces together.

715
00:38:55,350 --> 00:38:59,040
So for example, in Lambda
it's pretty straightforward.

716
00:38:59,040 --> 00:39:02,640
There's Lambda logs,
and traces, and metrics.

717
00:39:02,640 --> 00:39:05,670
For let's say EKS, it's a
little bit more involving

718
00:39:05,670 --> 00:39:09,603
but it's still, you know,
relatively straightforward.

719
00:39:10,980 --> 00:39:15,540
So in fact, traces in CloudWatch,

720
00:39:15,540 --> 00:39:20,160
they do report, they connect
which log group to go

721
00:39:20,160 --> 00:39:22,380
for corresponding logs.

722
00:39:22,380 --> 00:39:27,030
And so like, I can show
one of the examples.

723
00:39:27,030 --> 00:39:30,480
So when I'm troubleshooting the service,

724
00:39:30,480 --> 00:39:34,353
let's say, this is a
microservice, could be JS or.

725
00:39:35,880 --> 00:39:40,530
And have this bunch of operations,

726
00:39:40,530 --> 00:39:43,473
and this operation is
like obviously failing.

727
00:39:44,610 --> 00:39:48,270
And at this point this
is where the sidebar

728
00:39:48,270 --> 00:39:52,830
connects all this other telemetry.

729
00:39:52,830 --> 00:39:55,350
So on the left, you see the metrics.

730
00:39:55,350 --> 00:39:58,950
Here you see correspondent
spans to the metric,

731
00:39:58,950 --> 00:40:03,720
but this is the link to application log.

732
00:40:03,720 --> 00:40:05,100
And the similar would happen

733
00:40:05,100 --> 00:40:07,650
for let's say EKS application log,

734
00:40:07,650 --> 00:40:10,920
and you can let's say,
Application Signals could not

735
00:40:10,920 --> 00:40:15,920
connect the dots, you could
customize your trace attributes

736
00:40:18,480 --> 00:40:23,470
and add which logs to look for
when that trace is emitted.

737
00:40:26,910 --> 00:40:28,530
- [Siva] And also, like
you know, we have a,

738
00:40:28,530 --> 00:40:31,080
maybe you wanna show the
transaction search feature.

739
00:40:31,080 --> 00:40:32,370
So what we do is, like you know,

740
00:40:32,370 --> 00:40:35,250
we take your transactions
in terms of traces,

741
00:40:35,250 --> 00:40:38,160
and then convert and then store as logs.

742
00:40:38,160 --> 00:40:39,750
So that way, like you
know, you can go ahead

743
00:40:39,750 --> 00:40:43,320
and then just search for it, anything.

744
00:40:43,320 --> 00:40:45,390
So an ideal use case
could be, like you know,

745
00:40:45,390 --> 00:40:48,600
if you are a, maybe a support person

746
00:40:48,600 --> 00:40:50,250
and then you're getting a call,

747
00:40:50,250 --> 00:40:51,337
and then the customer saying like,

748
00:40:51,337 --> 00:40:54,390
"Hey, my our order is not
going through," all you need

749
00:40:54,390 --> 00:40:56,580
to ask them is like, "Hey,
what is your order number?"

750
00:40:56,580 --> 00:40:59,070
Just go to the transaction search page,

751
00:40:59,070 --> 00:41:01,590
click that, like, you
know, order.id is 123,

752
00:41:01,590 --> 00:41:02,940
something like that, right?

753
00:41:02,940 --> 00:41:04,860
And then the moment you click Enter,

754
00:41:04,860 --> 00:41:08,280
it is gonna take all the
traces or all the transactions

755
00:41:08,280 --> 00:41:10,980
that has happened in the
last three hours for example.

756
00:41:10,980 --> 00:41:13,860
And then it'll show you all
the transactions in that one,

757
00:41:13,860 --> 00:41:17,310
wherever we are using
this order.id is 123.

758
00:41:17,310 --> 00:41:18,870
So this is, like you
know, finding a needle

759
00:41:18,870 --> 00:41:20,940
in the haystack kind of a situation.

760
00:41:20,940 --> 00:41:23,250
And with this transaction search feature,

761
00:41:23,250 --> 00:41:24,990
because we are taking your traces

762
00:41:24,990 --> 00:41:27,330
and then storing as
logs, you can do all kind

763
00:41:27,330 --> 00:41:28,770
of operations, typically,

764
00:41:28,770 --> 00:41:31,500
however you're doing it
with your logs, right?

765
00:41:31,500 --> 00:41:35,500
So maybe, so this is what the
transaction search feature is,

766
00:41:35,500 --> 00:41:36,990
so Alex can guide you on that.

767
00:41:36,990 --> 00:41:39,790
- [Alex] Yeah, the transaction
search already also

768
00:41:41,850 --> 00:41:44,910
getting benefit of discovered
services, it will help you.

769
00:41:44,910 --> 00:41:46,920
It will suggest, okay, you can search

770
00:41:46,920 --> 00:41:49,620
through this microservice,
through this API,

771
00:41:49,620 --> 00:41:51,300
and that will also help you

772
00:41:51,300 --> 00:41:54,660
with like which fields
you can specify in here.

773
00:41:54,660 --> 00:41:57,210
And maybe some of the
fields will be, you know,

774
00:41:57,210 --> 00:41:59,850
this is my request ID, I know the request,

775
00:41:59,850 --> 00:42:01,653
or this is my order ID,

776
00:42:02,910 --> 00:42:05,790
and you can that way nail down.

777
00:42:05,790 --> 00:42:08,370
But I think the point,
what Siva was making is

778
00:42:08,370 --> 00:42:13,370
that traces in Application
Signals, they store that as logs,

779
00:42:15,360 --> 00:42:19,380
and that way you can use
log analytics essentially

780
00:42:19,380 --> 00:42:24,380
to better reason about
your application behavior.

781
00:42:29,660 --> 00:42:33,870
- [Participant] A follow up,
if I've already instrumented

782
00:42:33,870 --> 00:42:37,582
for X-Ray, will I need to instrument again

783
00:42:37,582 --> 00:42:39,475
for OpenTelemetry?

784
00:42:39,475 --> 00:42:41,250
- No.
- Okay.

785
00:42:41,250 --> 00:42:42,990
- [Alex] There is one, you know, caveat.

786
00:42:42,990 --> 00:42:47,990
So when X-Ray originally
launched, it has its own SDK,

787
00:42:49,890 --> 00:42:51,420
which is we announced

788
00:42:51,420 --> 00:42:54,333
that's on deprecation
path quite a while back,

789
00:42:55,290 --> 00:42:58,830
and I don't know some people
still use that, right,

790
00:42:58,830 --> 00:43:01,290
that X-Rays SDK.

791
00:43:01,290 --> 00:43:06,000
But I guess starting few years back,

792
00:43:06,000 --> 00:43:09,920
we announced that moving
forward, OTel SDK is the one

793
00:43:11,784 --> 00:43:15,240
that X-Ray will support in the future,

794
00:43:15,240 --> 00:43:20,133
and we call it Amazon
Distribution of OTel, ADOT.

795
00:43:23,040 --> 00:43:26,310
And the reason for that,
actually all of that,

796
00:43:26,310 --> 00:43:28,200
you can assemble it yourself as well.

797
00:43:28,200 --> 00:43:31,110
It's all in public repo.

798
00:43:31,110 --> 00:43:33,720
We just pre-built it so it's easier

799
00:43:33,720 --> 00:43:37,353
to make sure all the necessary
pieces are in one place.

800
00:43:40,020 --> 00:43:42,720
- [Siva] So this particular
QR code has a bunch of links,

801
00:43:42,720 --> 00:43:47,550
so if you want to see that,
so whatever Igor, sorry,

802
00:43:47,550 --> 00:43:50,250
Alex has talked about, all
these things are available

803
00:43:50,250 --> 00:43:52,320
in that one observability workshop.

804
00:43:52,320 --> 00:43:54,960
So we have Application Signals demo also.

805
00:43:54,960 --> 00:43:57,750
So all these things are
interactively available,

806
00:43:57,750 --> 00:44:00,450
so that you don't have
to create any accounts

807
00:44:00,450 --> 00:44:02,310
and then try all those features.

808
00:44:02,310 --> 00:44:03,750
So, and also, like you know,

809
00:44:03,750 --> 00:44:07,560
we have a YouTube show called
"Cloud Operation Show,"

810
00:44:07,560 --> 00:44:10,320
so that runs every two weeks, Thursdays.

811
00:44:10,320 --> 00:44:13,710
So that, recorded videos
also available there, and we

812
00:44:13,710 --> 00:44:17,040
do have a separate observability
best practices guide.

813
00:44:17,040 --> 00:44:19,890
So we have been talking
to hundreds of customers,

814
00:44:19,890 --> 00:44:21,450
and we identify the patterns,

815
00:44:21,450 --> 00:44:23,670
and then we document all that information.

816
00:44:23,670 --> 00:44:25,980
So that information is also available.

817
00:44:25,980 --> 00:44:27,930
Please take a look into it.

818
00:44:27,930 --> 00:44:30,180
And then if you have any
interest, like you know,

819
00:44:30,180 --> 00:44:33,213
any follow up or anything,
please reach out to us.

820
00:44:34,200 --> 00:44:38,643
So this is our LinkedIn
handles. Please feel free.

821
00:44:41,880 --> 00:44:43,560
- Thanks everyone.
- Thank you everybody.

822
00:44:43,560 --> 00:44:46,743
Thank you.
(audience clapping)

