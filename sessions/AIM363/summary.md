# AWS re:Invent 2025 会议总结：使用 SageMaker AI 定制和扩展基础模型

## 会议概述

本次会议由 AWS SageMaker AI 产品管理负责人 Sumehas Swami 主讲，重点探讨了如何将基础模型从实验阶段推向生产环境。会议指出，许多团队在使用基础模型构建原型时表现出色，但在面对生产环境的两大核心要求——可靠的准确性和可行的经济性时遇到困难。演讲者强调，通过模型定制化可以同时实现更高的准确性和显著降低的成本，这是将通用基础模型转化为企业竞争优势的关键。

会议介绍了 SageMaker AI 如何消除模型定制化的"税收"（即复杂的基础设施配置、工具整合和部署挑战），通过三大核心原则重构定制化体验：无服务器基础设施、集成化工作流和生产就绪的技术。演讲者展示了三种主要的定制化技术（监督微调、直接偏好优化和强化学习微调），并通过实际演示展示了如何使用 SageMaker Studio 的可视化界面和代码方式来定制 Llama 3.2 模型，使其在对话中表现得更加人性化。

整个会议强调了 SageMaker AI 提供的选择性、效率和安全性，使团队能够将 80% 的时间专注于 AI 问题本身，而不是基础设施和工具配置。演示部分详细展示了从数据准备、模型训练、评估到部署的完整工作流程，所有操作都在统一的 SageMaker Studio 环境中完成。

## 详细时间线

### 开场与问题陈述 (0:00 - 5:30)
- **0:00** - 演讲者开场，询问观众有多少人在过去 6 个月实验过基础模型
- **0:30** - 指出实验与生产之间存在巨大差距，许多团队无法将演示推向生产
- **1:30** - 强调生产环境的两大不可妥协的要求：可防御的准确性和可行的经济性
- **2:30** - 说明演示中成本仅几美元的应用在生产中可能花费数千美元
- **3:30** - 介绍团队面临的困境：使用大型昂贵模型追求准确性，或使用小型模型但准确性下降
- **4:30** - 提出解决方案：通过模型定制化同时实现更高准确性和更低成本

### 演讲者介绍与定制化价值 (5:30 - 10:00)
- **5:30** - Sumehas Swami 自我介绍，担任 SageMaker AI 开发者体验产品管理负责人
- **6:00** - 说明会议将讨论如何使用 SageMaker AI 定制和扩展基础模型
- **6:30** - 预告同事 Jusupi 将进行现场产品演示
- **7:00** - 阐述为何需要定制模型：所有企业都能访问相同的基础模型（GPT、Llama、Qwen）
- **8:00** - 强调竞争优势不在于可访问的模型，而在于能教会模型什么
- **8:30** - 指出基础模型是强大的通才，但在特定领域缺乏深度
- **9:00** - 说明在生产环境中被迫选择最大最昂贵的模型以接近可接受的准确性

### 定制化的优势与挑战 (10:00 - 15:30)
- **10:00** - 讨论提示工程和 RAG 的局限性：在简单用例中有效，但在生产规模下遇到瓶颈
- **11:00** - 举例说明交易分类场景：92% 的准确率意味着 8% 的交易被错误分类
- **12:00** - 解释模型定制化的本质：将业务领域专业知识直接编码到模型权重中
- **13:00** - 展示定制化效果：80 亿参数的微调模型在特定任务上可超越 4000 亿参数的通用模型
- **14:00** - 强调小型定制模型的推理成本比大型模型低 10 到 100 倍
- **15:00** - 指出专有数据是竞争对手无法复制的资产，模型定制化将数据转化为竞争优势

### 定制化的"税收"问题 (15:30 - 20:00)
- **15:30** - 提出问题：如果定制化如此优秀，为什么不是所有人都在使用？
- **16:00** - 描述定制化的实际复杂性：配置 YAML 文件、GPU 分布式训练配置
- **17:00** - 说明需要拼接多个工具：数据准备、训练、评估工具互不兼容
- **18:00** - 指出实验可重现性问题：难以追踪哪个数据集和超参数产生了特定结果
- **19:00** - 描述部署挑战：需要从头构建基础设施、容器化、版本控制、监控
- **19:30** - 总结团队将 80% 时间花在基础设施和工具上，只有 20% 时间解决实际 AI 问题

### SageMaker AI 的解决方案 (20:00 - 25:00)
- **20:00** - 介绍如何消除定制化税收，围绕三个核心原则重构体验
- **20:30** - 第一原则：无服务器基础设施 - 无需配置集群、规划容量、选择实例
- **21:30** - 第二原则：集成化工作流 - SageMaker Studio 提供从实验到生产的一站式环境
- **22:30** - 第三原则：生产就绪技术 - 提供监督微调、直接偏好优化、强化学习等高级技术
- **23:30** - 强调支持多种模型：Amazon Nova、Llama、Qwen 等开放权重和专有模型
- **24:30** - 总结核心转变：将 80/20 比例反转，现在 80% 时间用于 AI 问题，20% 用于基础设施

### 三种定制化技术详解 (25:00 - 35:00)
- **25:00** - 介绍 SageMaker 提供的三种生产就绪技术
- **26:00** - 监督微调 (SFT) - 教授模型领域知识，通过标记示例进行模式匹配学习
- **27:30** - 说明 SFT 的局限：只能学习明确教授的内容，无法发展超越数据的判断力
- **28:30** - 直接偏好优化 (DPO) - 教授模型判断力和风格，通过响应对比学习质量标准
- **30:00** - 举例说明 DPO 适用场景：难以程序化定义但易于识别的主观偏好
- **31:30** - 强化微调 (Reinforcement Fine-tuning) - 教授模型复杂推理能力
- **32:30** - 介绍 RLAIF（AI 反馈强化学习）：模型生成输出，AI 提供反馈和奖励
- **33:30** - 介绍可验证奖励强化学习：适用于编码、数学等有明确对错的场景
- **34:30** - 强调可以根据用例需求从简单开始逐步演进

### 三种构建体验 (35:00 - 40:00)
- **35:00** - 介绍针对不同团队工作方式的三种体验
- **35:30** - SageMaker Studio UI - 可视化工作流，无需编码，适合快速实验
- **36:30** - AI 代理引导体验（预览版） - 用自然语言描述目标，代理构建规范并执行流程
- **37:30** - 举例说明代理可以生成合成数据、执行端到端流程
- **38:30** - 基于代码的 SDK - 完全程序化控制，可集成到 MLOps 流程
- **39:00** - 强调三种方式不是独立产品，而是同一服务的三个接口
- **39:30** - 说明共享同一模型注册表、版本控制和审计跟踪

### SageMaker Studio 功能介绍 (40:00 - 47:00)
- **40:00** - 介绍 SageMaker Studio 作为 AI 工作流的基于 Web 的 IDE
- **40:30** - 提供可视化表单、Jupyter 笔记本、VS Code IDE 等多种开发工具
- **41:30** - 强调整个工作流连接：从实验到训练到评估到部署到监控
- **42:00** - 宣布两项新功能：**无服务器模型评估**和**无服务器 MLflow**
- **43:00** - 详细介绍模型评估功能：支持标准基准测试（如 MMLU）、LLM 作为评判者、自定义评估器
- **44:30** - 强调评估是无服务器的，无需管理基础设施
- **45:30** - 介绍 MLflow 集成：自动记录指标、超参数、数据集、模型工件
- **46:30** - 说明可以查看完整的模型血统，且无额外费用

### 计算选项 (47:00 - 52:00)
- **47:00** - 介绍两种计算选项
- **47:30** - 无服务器模型定制化 - 提交作业，自动配置 GPU 集群，训练后拆除基础设施
- **48:30** - 强调只为实际使用的资源付费，适合快速迭代和实验（昨天刚发布）
- **49:30** - SageMaker HyperPod - 持久化集群，可跨训练、推理和交互式工作负载共享
- **50:30** - 介绍 HyperPod 的关键特性：自动从检查点恢复，节省高达 40% 的时间
- **51:30** - 宣布昨天发布的无检查点训练功能，可在几分钟内恢复故障
- **52:00** - 建议快速迭代使用无服务器训练，长期训练或需要精细控制使用 HyperPod

### 三大支柱总结 (52:00 - 55:00)
- **52:00** - 总结 SageMaker AI 模型定制化的三大支柱
- **52:30** - 选择性 - 不锁定单一模型家族或技术，支持多种模型和方法
- **53:30** - 效率 - 无服务器训练消除基础设施管理，HyperPod 提供需要时的控制
- **54:00** - 安全性 - 内置治理、血统追踪、IAM 访问控制、VPC 内安全运行
- **54:30** - 强调这就是如何消除定制化税收并将基础模型转化为竞争优势

### 演示介绍 (55:00 - 58:00)
- **55:00** - 介绍即将进行的演示，由 Jusupi 展示
- **55:30** - 说明演示目标：定制 Llama 3.2 1B 指令模型，使其在对话中更像人类
- **56:30** - 介绍数据集：包含对话问题和两种响应（人性化响应和正式响应）
- **57:00** - 预告两个演示：第一个使用 DPO 的 UI 工作流，第二个使用 RLAIF 的代码工作流
- **57:30** - 强调相同模型、相同数据集、两种不同技术，都在 SageMaker AI 上运行

### 演示部分 - 数据准备 (58:00 - 65:00)
- **58:00** - Jusupi 开始演示，展示 SageMaker AI Studio 界面
- **58:30** - 查看 Hugging Face 上的人性化 DPO 数据集结构：提示、选择响应、拒绝响应
- **59:30** - 展示 SageMaker Studio 中的"资产"部分，用于管理和版本化数据集
- **60:30** - 查看不同定制技术所需的数据格式要求
- **61:30** - 展示在托管笔记本环境中编写的数据准备代码
- **62:30** - 演示数据集转换：加载数据、观察结构、对比选择和拒绝响应
- **63:30** - 说明数据集包含约 10,000 个训练样本，使用 10% 作为评估集
- **64:30** - 展示如何将准备好的数据集上传到 S3 或保存为文件

### 演示部分 - 模型定制化 UI 工作流 (65:00 - 75:00)
- **65:00** - 在 UI 中上传训练数据集到 S3
- **66:00** - 数据集出现在目录中，可以查看样本数据
- **67:00** - 在模型中心搜索 Llama 3.2 1B 指令模型
- **68:00** - 进入模型详情页面，选择"使用 UI 定制"
- **69:00** - 配置定制化作业：命名模型、选择 DPO 技术、选择数据集
- **70:00** - 展示预配置的默认设置：输出位置、超参数配置
- **71:00** - 说明可以根据实验结果修改参数
- **72:00** - 展示高级配置部分：其他超参数和 MLflow 配置
- **73:00** - 提交作业，说明训练需要约 1 小时（3 个 epoch）
- **74:00** - 切换到预先运行的 DPO 示例，查看定制模型界面
- **74:30** - 展示训练日志和性能指标（如奖励边际）

### 演示部分 - MLflow 和模型部署 (75:00 - 82:00)
- **75:00** - 从 UI 直接打开无服务器 MLflow 界面
- **75:30** - 深入查看详细的模型训练指标
- **76:30** - 展示模型部署功能：可部署到 SageMaker 或 Bedrock 无服务器推理
- **77:30** - 说明可以选择现有端点（打包多个模型以优化成本）或创建新端点
- **78:30** - 展示预先部署的模型端点详情
- **79:30** - 解释 LoRA 技术：基础模型和适配器分别部署，可在同一端点加载多个适配器
- **80:30** - 使用 Playground 测试模型：对比基础模型和微调模型的响应
- **81:30** - 基础模型回答"How are you today?"时给出正式响应
- **82:00** - 微调模型给出更非正式、人性化的响应（包含多个感叹号）

### 演示部分 - 模型评估 (82:00 - 88:00)
- **82:00** - 介绍内置的模型评估功能
- **82:30** - 展示多种评估技术：标准基准测试、自定义评分器、LLM 作为评判者
- **83:30** - 说明 LLM 作为评判者技术：使用更大的模型评估响应质量
- **84:30** - 选择评估数据集和评估方法
- **85:30** - 配置评估作业：选择指标、设置评估参数
- **86:30** - 提交评估作业，说明这是无服务器的
- **87:00** - 查看预先运行的评估结果
- **87:30** - 展示评估指标：准确性、相关性、人性化程度等

### 演示部分 - 代码工作流 (RLAIF) (88:00 - 结束)
- **88:00** - 切换到基于代码的工作流演示
- **88:30** - 展示 Jupyter 笔记本中的 RLAIF 实现
- **89:30** - 说明 RLAIF 流程：模型生成响应，AI 提供反馈，模型优化奖励
- **90:30** - 展示如何配置奖励模型和训练参数
- **91:30** - 使用 SageMaker SDK 提交 RLAIF 训练作业
- **92:30** - 强调代码工作流提供完全的程序化控制
- **93:30** - 说明可以将其集成到 MLOps 流程中
- **94:30** - 总结演示：展示了从数据准备到训练到评估到部署的完整流程
- **95:00** - 强调所有操作都在统一的 SageMaker Studio 环境中完成
- **95:30** - 会议结束，感谢观众