1
00:00:00,300 --> 00:00:01,470
- Hi, everyone.

2
00:00:01,470 --> 00:00:02,670
Welcome and thank you

3
00:00:02,670 --> 00:00:05,820
for joining me in this lightning session.

4
00:00:05,820 --> 00:00:07,170
For the next 20 minutes,

5
00:00:07,170 --> 00:00:08,430
we are going to explore

6
00:00:08,430 --> 00:00:11,760
how you can turn siloed
enterprise system data

7
00:00:11,760 --> 00:00:13,830
into AI-driven innovation.

8
00:00:13,830 --> 00:00:16,890
My name is Angie Guemes,
and I am a senior specialist

9
00:00:16,890 --> 00:00:18,990
in the industry solutions team at MongoDB.

10
00:00:19,860 --> 00:00:23,220
What we do is that we
basically help organizations

11
00:00:23,220 --> 00:00:25,330
maximize the value of their data

12
00:00:26,190 --> 00:00:29,340
by providing industry specific solutions.

13
00:00:29,340 --> 00:00:32,160
These are either to help them
tackle specific challenges

14
00:00:32,160 --> 00:00:35,310
or improve customer experiences.

15
00:00:35,310 --> 00:00:36,143
All right...

16
00:00:39,882 --> 00:00:42,150
The agenda for today is the following:

17
00:00:42,150 --> 00:00:45,150
First, we're gonna talk
about AI innovation

18
00:00:45,150 --> 00:00:47,520
and its challenges, what it is,

19
00:00:47,520 --> 00:00:49,440
we're gonna explore some vision of that

20
00:00:49,440 --> 00:00:50,790
through a couple of demos.

21
00:00:50,790 --> 00:00:52,470
And we are also gonna talk about

22
00:00:52,470 --> 00:00:54,540
why are some of these AI initiatives

23
00:00:54,540 --> 00:00:56,370
not getting to production.

24
00:00:56,370 --> 00:00:58,230
Then we're gonna talk about

25
00:00:58,230 --> 00:01:01,140
the operational data layer as a solution,

26
00:01:01,140 --> 00:01:03,690
what it is and the layers that compose it.

27
00:01:03,690 --> 00:01:06,210
And finally, we're gonna talk about

28
00:01:06,210 --> 00:01:07,800
the benefits that you will get

29
00:01:07,800 --> 00:01:12,123
from using MongoDB Atlas as
your operational data layer.

30
00:01:13,770 --> 00:01:16,560
All right, so getting started,

31
00:01:16,560 --> 00:01:19,590
these are some AI concepts

32
00:01:19,590 --> 00:01:23,160
or capabilities that have
been broadly talked about,

33
00:01:23,160 --> 00:01:25,320
especially the last couple of years,

34
00:01:25,320 --> 00:01:26,340
and they are becoming

35
00:01:26,340 --> 00:01:29,550
increasingly fundamental
across industries,

36
00:01:29,550 --> 00:01:31,800
generating key areas of opportunities

37
00:01:31,800 --> 00:01:33,780
for many use cases.

38
00:01:33,780 --> 00:01:36,513
Let's explore them in a
little bit of more detail.

39
00:01:38,130 --> 00:01:40,020
First, we have Gen AI.

40
00:01:40,020 --> 00:01:42,810
This is what it's being allowing companies

41
00:01:42,810 --> 00:01:45,660
to streamline and automate processes.

42
00:01:45,660 --> 00:01:49,200
For example, based on
the picture of a product,

43
00:01:49,200 --> 00:01:52,290
they can generate multilingual
descriptions of it,

44
00:01:52,290 --> 00:01:54,600
but this descriptions match the tone

45
00:01:54,600 --> 00:01:56,373
and essence of the brand.

46
00:01:57,750 --> 00:02:01,560
AI-powered search is
allowing us to discover data

47
00:02:01,560 --> 00:02:03,210
in a much smarter way,

48
00:02:03,210 --> 00:02:05,010
searching through semantic meaning

49
00:02:05,010 --> 00:02:06,930
rather than just keywords.

50
00:02:06,930 --> 00:02:10,440
This is how companies are
able to match a customer

51
00:02:10,440 --> 00:02:11,970
to a specific product

52
00:02:11,970 --> 00:02:15,603
or an employee to a
specific insight instantly.

53
00:02:17,220 --> 00:02:21,150
Then we have Retrieval-Augmented
Generation, or RAG.

54
00:02:21,150 --> 00:02:25,950
This is very critical for
reducing hallucinations,

55
00:02:25,950 --> 00:02:28,080
expanding LLM capabilities

56
00:02:28,080 --> 00:02:30,930
through proprietary data as context,

57
00:02:30,930 --> 00:02:35,103
critical for trusted and
grounded AI responses.

58
00:02:36,120 --> 00:02:39,120
And well, last but not least,
agents and multi-agents:

59
00:02:39,120 --> 00:02:40,890
These have added a new layer

60
00:02:40,890 --> 00:02:43,260
of decision-making and reasoning.

61
00:02:43,260 --> 00:02:46,590
They are able to act, not just answer,

62
00:02:46,590 --> 00:02:47,700
so they are able

63
00:02:47,700 --> 00:02:50,823
to streamline processes
and workflows end to end.

64
00:02:51,720 --> 00:02:54,570
Ultimately, all of these have one goal

65
00:02:54,570 --> 00:02:56,280
that is shared across them

66
00:02:56,280 --> 00:02:59,310
and this is to improve
customer experiences

67
00:02:59,310 --> 00:03:02,373
and/or enhance their
operational efficiency.

68
00:03:03,300 --> 00:03:06,420
And there's also something
really exciting about all these

69
00:03:06,420 --> 00:03:09,390
and is that we are already
seeing these happen

70
00:03:09,390 --> 00:03:13,860
across different use cases
and customer success stories.

71
00:03:13,860 --> 00:03:16,410
And just to provide a
little bit of more insight,

72
00:03:16,410 --> 00:03:19,020
I'll go through the last two.

73
00:03:19,020 --> 00:03:22,890
Nova Nordisk is a leading
healthcare company

74
00:03:22,890 --> 00:03:27,890
and they are augmenting LLMs
with their own proprietary data

75
00:03:28,110 --> 00:03:32,190
to make the generation of
clinical study reports faster.

76
00:03:32,190 --> 00:03:35,790
It used to take them 12 weeks
to generate these reports

77
00:03:35,790 --> 00:03:38,550
and now it only takes them 10 minutes

78
00:03:38,550 --> 00:03:40,650
and only with a fraction of the resources

79
00:03:40,650 --> 00:03:42,810
that it would take them in the past.

80
00:03:42,810 --> 00:03:45,960
Thanks to this, they are able
to hit faster times to market

81
00:03:45,960 --> 00:03:47,340
for new treatments,

82
00:03:47,340 --> 00:03:49,410
and as part of these initiatives,

83
00:03:49,410 --> 00:03:54,240
they are leveraging different
AWS technologies like Bedrock,

84
00:03:54,240 --> 00:03:57,270
specifically they're
using Cloud III and Titan

85
00:03:57,270 --> 00:04:00,690
and also MongoDB Atlas Vector search.

86
00:04:00,690 --> 00:04:02,013
And then DevRev.

87
00:04:02,013 --> 00:04:04,110
Dev, DevRev, sorry,

88
00:04:04,110 --> 00:04:08,190
provides support chatbots for their teams,

89
00:04:08,190 --> 00:04:09,780
for their internal teams,

90
00:04:09,780 --> 00:04:11,430
and as part of these initiatives,

91
00:04:11,430 --> 00:04:14,640
they are also using MongoDB Atlas on AWS

92
00:04:14,640 --> 00:04:17,640
and other products like
AKS and VPC peering

93
00:04:17,640 --> 00:04:19,263
for support and connectivity.

94
00:04:21,060 --> 00:04:24,150
All right, so I brought
to you a couple of demos

95
00:04:24,150 --> 00:04:27,753
to paint a more clear picture
of these AI initiatives.

96
00:04:32,220 --> 00:04:34,470
With this first one,
we are going to explore

97
00:04:34,470 --> 00:04:39,470
how you can take advantage
of fresh purchase data

98
00:04:39,570 --> 00:04:43,290
to enhance the experience
of the customers.

99
00:04:43,290 --> 00:04:46,923
So in this case, the user
is at the E-commerce store.

100
00:04:47,850 --> 00:04:50,700
They will go to their cart,
proceed to check out...

101
00:04:50,700 --> 00:04:55,700
Oops, sorry, I have this issue
at the AV testing, so lets...

102
00:04:56,130 --> 00:04:59,820
The show must go on,
right? So second time.

103
00:04:59,820 --> 00:05:02,520
The user will be at the eCommerce store

104
00:05:02,520 --> 00:05:06,540
and here they will go to
their cart, place an order,

105
00:05:06,540 --> 00:05:08,400
and this will trigger our invoice

106
00:05:08,400 --> 00:05:10,470
and recommendation microservice.

107
00:05:10,470 --> 00:05:13,020
So when the user clicks on See Details,

108
00:05:13,020 --> 00:05:16,710
they will be given a popup with
their digital receipt here,

109
00:05:16,710 --> 00:05:20,190
encompassing relevant order transaction

110
00:05:20,190 --> 00:05:22,050
and loyalty information.

111
00:05:22,050 --> 00:05:24,630
And if they scroll down from the receipt,

112
00:05:24,630 --> 00:05:28,680
they will be able to see
a list of recommendations

113
00:05:28,680 --> 00:05:31,140
with products that they might also like

114
00:05:31,140 --> 00:05:34,890
based on the items
purchased in this order.

115
00:05:34,890 --> 00:05:37,620
And like that, every
single digital receipt

116
00:05:37,620 --> 00:05:41,250
will contain a unique and
relevant set of suggestions

117
00:05:41,250 --> 00:05:44,730
leading to a more engaging
shopping experience.

118
00:05:44,730 --> 00:05:47,370
Customers can also
download the PDF version

119
00:05:47,370 --> 00:05:49,290
at any point in time

120
00:05:49,290 --> 00:05:52,770
and leverage this for their finances.

121
00:05:52,770 --> 00:05:55,710
Ultimately, if a customer makes a purchase

122
00:05:55,710 --> 00:05:57,240
at a store physically,

123
00:05:57,240 --> 00:06:01,230
they expect to see that same
history inside their account

124
00:06:01,230 --> 00:06:04,230
so that if they then
go to the landing page,

125
00:06:04,230 --> 00:06:06,930
we are able to leverage that data as well.

126
00:06:06,930 --> 00:06:11,040
So this is how we can instantly
activate fresh purchase data

127
00:06:11,040 --> 00:06:14,790
to continue the shopping
experience beyond the checkout,

128
00:06:14,790 --> 00:06:18,870
and also leveraging that same
data to further personalize,

129
00:06:18,870 --> 00:06:21,393
for example, the landing
page, in this case.

130
00:06:22,470 --> 00:06:23,760
Awesome.

131
00:06:23,760 --> 00:06:25,560
In this next example,

132
00:06:25,560 --> 00:06:29,580
this is a financial
portfolio management system

133
00:06:29,580 --> 00:06:33,090
that continuously scans
the market for insights.

134
00:06:33,090 --> 00:06:36,810
At the top we have
performance and asset graphs,

135
00:06:36,810 --> 00:06:37,830
and at the bottom...

136
00:06:37,830 --> 00:06:42,240
Oh, and the graphs are related
to the manager's portfolio.

137
00:06:42,240 --> 00:06:43,680
At the bottom we have a table

138
00:06:43,680 --> 00:06:47,100
of diversified portfolio of ETFs.

139
00:06:47,100 --> 00:06:50,910
Each of these contain
a different indicator,

140
00:06:50,910 --> 00:06:54,363
for example, sensitivity around VIX, GDP,

141
00:06:56,010 --> 00:07:00,870
interest, unemployment rates,
and also sentiment scores.

142
00:07:00,870 --> 00:07:05,870
All of these are calculated by
three, daily scheduled agents

143
00:07:05,880 --> 00:07:09,240
that continuously scan
the market for insights.

144
00:07:09,240 --> 00:07:12,520
Additionally, agents can also interact

145
00:07:13,495 --> 00:07:15,210
with the agents (laughs)

146
00:07:15,210 --> 00:07:16,920
through this AI assistant

147
00:07:16,920 --> 00:07:19,500
so they can ask natural language questions

148
00:07:19,500 --> 00:07:23,310
and get insights from the
latest data in the market

149
00:07:23,310 --> 00:07:25,443
and plan their risk aware strategies.

150
00:07:26,550 --> 00:07:29,550
Agents have already done
all these heavy lifting

151
00:07:29,550 --> 00:07:33,060
of constantly scanning
through different unstructured

152
00:07:33,060 --> 00:07:34,770
and semi-structured sources,

153
00:07:34,770 --> 00:07:37,920
such as, financial analysis,

154
00:07:37,920 --> 00:07:40,860
financial news, and also social media.

155
00:07:40,860 --> 00:07:43,560
So portfolio managers can rest assured

156
00:07:43,560 --> 00:07:45,630
that they are actually interacting

157
00:07:45,630 --> 00:07:48,150
and getting the latest
data from the market,

158
00:07:48,150 --> 00:07:49,800
and they can use that extra time

159
00:07:49,800 --> 00:07:52,530
to leverage their plans,

160
00:07:52,530 --> 00:07:55,800
instead of having to making
this discovery themselves

161
00:07:55,800 --> 00:08:00,450
while still retaining the full
control of their operations.

162
00:08:00,450 --> 00:08:02,760
They can also see which
tools were utilized

163
00:08:02,760 --> 00:08:05,733
to generate the responses
for each of the questions.

164
00:08:08,520 --> 00:08:12,780
So, all of this looks
pretty amazing, right?

165
00:08:12,780 --> 00:08:14,910
We all wanna have something like this.

166
00:08:14,910 --> 00:08:17,340
However, I hate to break it to you,

167
00:08:17,340 --> 00:08:21,660
that many of these AI
initiatives are failing today.

168
00:08:21,660 --> 00:08:23,460
They are either being abandoned

169
00:08:23,460 --> 00:08:26,433
or they fail to meet their objectives.

170
00:08:27,900 --> 00:08:30,120
So let's understand, why is this?

171
00:08:30,120 --> 00:08:32,190
Why are some of these AI initiatives

172
00:08:32,190 --> 00:08:34,830
not being able to get to production?

173
00:08:34,830 --> 00:08:38,700
Well, the first reason is the misalignment

174
00:08:38,700 --> 00:08:41,880
with the organization's strategic goals.

175
00:08:41,880 --> 00:08:45,600
When you start planning about
designing AI initiatives,

176
00:08:45,600 --> 00:08:49,890
this should be able to create
tangible business value,

177
00:08:49,890 --> 00:08:52,590
enhance the operational efficiency,

178
00:08:52,590 --> 00:08:56,253
and create a sustained
competitive advantage.

179
00:08:57,690 --> 00:08:59,790
Another example or reason,

180
00:08:59,790 --> 00:09:00,780
and the one I would like

181
00:09:00,780 --> 00:09:02,790
to focus the most during this session,

182
00:09:02,790 --> 00:09:05,733
is incomplete and fragmented data.

183
00:09:06,630 --> 00:09:09,420
When you start building
your AI initiatives

184
00:09:09,420 --> 00:09:11,400
without first making a pause,

185
00:09:11,400 --> 00:09:14,190
taking a look at your data layer,

186
00:09:14,190 --> 00:09:16,050
at your foundational data layer,

187
00:09:16,050 --> 00:09:18,630
well, you will start
fitting your initiatives

188
00:09:18,630 --> 00:09:21,300
with data that has poor quality,

189
00:09:21,300 --> 00:09:24,360
data that is insufficient or incomplete,

190
00:09:24,360 --> 00:09:26,430
or because still many data

191
00:09:26,430 --> 00:09:29,130
is scattered across
different legacy systems,

192
00:09:29,130 --> 00:09:34,130
well, it becomes very hard
to integrate or activate.

193
00:09:34,470 --> 00:09:36,090
If you take that combo

194
00:09:36,090 --> 00:09:39,390
and you pass it to a large language model,

195
00:09:39,390 --> 00:09:42,390
you will get inaccurate outcomes,

196
00:09:42,390 --> 00:09:46,290
hallucinations and bad
business consequences,

197
00:09:46,290 --> 00:09:48,990
missed opportunities, bad user experience,

198
00:09:48,990 --> 00:09:51,810
and the worst, damaging your reputation.

199
00:09:51,810 --> 00:09:55,323
We know how hard it can be to
build a strong loyalty base,

200
00:09:56,940 --> 00:09:59,043
and here's a little data,

201
00:10:00,030 --> 00:10:03,030
more than 60% of customers
will change the brands

202
00:10:03,030 --> 00:10:05,970
after a single bad user experience.

203
00:10:05,970 --> 00:10:08,340
So that is something we want to avoid.

204
00:10:08,340 --> 00:10:11,520
So how can we guarantee complete, accurate

205
00:10:11,520 --> 00:10:12,990
and real-time data?

206
00:10:12,990 --> 00:10:15,450
Well, let me introduce to you

207
00:10:15,450 --> 00:10:18,930
the Operational Data layer, or ODL.

208
00:10:18,930 --> 00:10:22,800
This is an architectural
blueprint or approach,

209
00:10:22,800 --> 00:10:25,980
which job is to consolidate
siloed enterprise data

210
00:10:25,980 --> 00:10:29,673
into a single, reliable data layer.

211
00:10:31,290 --> 00:10:32,123
Let me walk you through

212
00:10:32,123 --> 00:10:35,400
the five layers of an audio, ODL, sorry,

213
00:10:35,400 --> 00:10:37,860
that will guide a robust implementation

214
00:10:37,860 --> 00:10:40,863
using MongoDB Atlas as
your core data layer.

215
00:10:41,850 --> 00:10:45,690
First, we have the source
systems or systems of record.

216
00:10:45,690 --> 00:10:48,240
This is where the actual
data gets originated,

217
00:10:48,240 --> 00:10:50,430
and as you can see from the examples,

218
00:10:50,430 --> 00:10:52,530
many of these systems

219
00:10:52,530 --> 00:10:55,770
were built with a single use
case in mind at the time,

220
00:10:55,770 --> 00:10:59,260
so as a result their
schema does not longer

221
00:11:00,270 --> 00:11:03,450
accommodate the modern day applications.

222
00:11:03,450 --> 00:11:06,510
An example of this, or a result of this,

223
00:11:06,510 --> 00:11:10,920
that you will struggle to see
a complete view of an entity.

224
00:11:10,920 --> 00:11:12,960
For example, a retailer that struggles

225
00:11:12,960 --> 00:11:15,390
to have a complete view of users

226
00:11:15,390 --> 00:11:17,010
throughout their shopping journey,

227
00:11:17,010 --> 00:11:19,890
because operational
sales are in one system,

228
00:11:19,890 --> 00:11:22,290
returns and refunds are
in a different system,

229
00:11:22,290 --> 00:11:25,923
their loyalty or preferences
in another system, and so on.

230
00:11:27,030 --> 00:11:28,680
Data from the source systems,

231
00:11:28,680 --> 00:11:31,680
is then ingested into the ODL layer

232
00:11:31,680 --> 00:11:33,090
through different mechanisms,

233
00:11:33,090 --> 00:11:36,030
including ETL, Change Data Capture,

234
00:11:36,030 --> 00:11:37,800
and here you can also leverage

235
00:11:37,800 --> 00:11:39,960
MongoDB Atlas Stream Processing

236
00:11:39,960 --> 00:11:42,783
for handling large stream process of data.

237
00:11:44,040 --> 00:11:46,080
I think it's a good time
to make a pause here

238
00:11:46,080 --> 00:11:48,450
and mention that if
you're interested about

239
00:11:48,450 --> 00:11:51,240
any of the products I will be
mentioning during the session,

240
00:11:51,240 --> 00:11:55,830
we have a booth right here
behind us at the Number 822

241
00:11:55,830 --> 00:11:57,870
and we have many experts on site

242
00:11:57,870 --> 00:11:59,550
and actually we brought the demo

243
00:11:59,550 --> 00:12:02,433
so you can test them yourself
if you're interested.

244
00:12:03,810 --> 00:12:07,080
All right, the third
layer is the actual ODL.

245
00:12:07,080 --> 00:12:10,740
Here it's represented by MongoDB Atlas

246
00:12:10,740 --> 00:12:13,890
and it's where we consolidate
structured, unstructured,

247
00:12:13,890 --> 00:12:15,600
and semi-structured data

248
00:12:15,600 --> 00:12:18,003
into a single flexible document.

249
00:12:19,440 --> 00:12:21,570
Then we have the processing layer.

250
00:12:21,570 --> 00:12:23,040
This layer is in charge

251
00:12:23,040 --> 00:12:26,220
of making the data from the ODL available

252
00:12:26,220 --> 00:12:27,780
to the applications.

253
00:12:27,780 --> 00:12:32,220
This layer right here is
very critical for security.

254
00:12:32,220 --> 00:12:35,820
It enforces governance through encryption,

255
00:12:35,820 --> 00:12:40,170
access control, policy-based
filtering, et cetera.

256
00:12:40,170 --> 00:12:41,400
And the last but not least,

257
00:12:41,400 --> 00:12:44,430
and I think we can all
guess what layer is next,

258
00:12:44,430 --> 00:12:46,980
are the actual applications.

259
00:12:46,980 --> 00:12:51,150
So these applications
can include operational

260
00:12:51,150 --> 00:12:53,550
and system apps.

261
00:12:53,550 --> 00:12:56,490
They can include business
intelligence tools.

262
00:12:56,490 --> 00:12:57,810
They can include, of course,

263
00:12:57,810 --> 00:13:00,000
the next generation applications

264
00:13:00,000 --> 00:13:02,013
with Gen AI and agents.

265
00:13:03,630 --> 00:13:08,010
All right, so what are some
key enablers that you will get

266
00:13:08,010 --> 00:13:10,743
from using MongoDB Atlas as your ODL?

267
00:13:11,910 --> 00:13:13,110
I really like this diagram

268
00:13:13,110 --> 00:13:17,250
because it encompasses the main benefit.

269
00:13:17,250 --> 00:13:20,220
All of these building
blocks that you see here

270
00:13:20,220 --> 00:13:23,220
would usually come from
single-purpose systems.

271
00:13:23,220 --> 00:13:26,340
For example, smart search or embeddings,

272
00:13:26,340 --> 00:13:28,860
and globally the flexible schema.

273
00:13:28,860 --> 00:13:31,830
And here they are all natively integrated,

274
00:13:31,830 --> 00:13:34,560
living with your data.

275
00:13:34,560 --> 00:13:37,860
So, actually we're actively working

276
00:13:37,860 --> 00:13:41,790
to integrate Voyage AI
embedding models and rerankers

277
00:13:41,790 --> 00:13:44,133
to make this process even more seamless.

278
00:13:45,510 --> 00:13:47,610
So this is the biggest benefit

279
00:13:47,610 --> 00:13:51,360
we bring to development teams: simplicity.

280
00:13:51,360 --> 00:13:53,190
We are reducing the complexity

281
00:13:53,190 --> 00:13:54,990
of their operational overhead

282
00:13:54,990 --> 00:13:57,630
by having all the data and capabilities

283
00:13:57,630 --> 00:14:01,563
in one single trusted,
reliable data layer.

284
00:14:02,730 --> 00:14:06,180
Some of the key enablers
that you will get from this:

285
00:14:06,180 --> 00:14:09,600
Our first, the unparalleled simplicity

286
00:14:09,600 --> 00:14:11,703
from the flexible document model.

287
00:14:13,890 --> 00:14:16,080
You can store different
complex data types,

288
00:14:16,080 --> 00:14:19,143
such as vectors, such as graphs,

289
00:14:20,520 --> 00:14:22,020
the AI embeddings.

290
00:14:22,020 --> 00:14:23,640
And in this example,

291
00:14:23,640 --> 00:14:27,180
we have operational data
living alongside AI.

292
00:14:27,180 --> 00:14:30,870
This is what it allows us to
query for relevant products

293
00:14:30,870 --> 00:14:32,490
in the digital receipt demo

294
00:14:32,490 --> 00:14:35,493
without having to move
data outside of our system.

295
00:14:37,020 --> 00:14:40,500
Then we have agents' memory capabilities.

296
00:14:40,500 --> 00:14:43,350
Memory is a key capability for agents,

297
00:14:43,350 --> 00:14:47,130
allowing them to store context
throughout interactions,

298
00:14:47,130 --> 00:14:49,140
learn from past interactions,

299
00:14:49,140 --> 00:14:52,050
and ultimately get better at their tasks.

300
00:14:52,050 --> 00:14:57,023
You can leverage Atlas as
your agent's memory layer.

301
00:14:59,280 --> 00:15:01,890
Another thing that you would get from this

302
00:15:01,890 --> 00:15:03,930
are the powerful queries.

303
00:15:03,930 --> 00:15:08,930
We have full text search,
semantic search, hybrid search,

304
00:15:09,360 --> 00:15:11,670
all natively integrated.

305
00:15:11,670 --> 00:15:14,910
You can also have other
powerful search queries,

306
00:15:14,910 --> 00:15:17,100
such as geospatial queries,

307
00:15:17,100 --> 00:15:19,320
and they're all within the same workflow.

308
00:15:19,320 --> 00:15:23,790
So this makes operational
overhead even less

309
00:15:23,790 --> 00:15:26,430
and allowing more simplicity

310
00:15:26,430 --> 00:15:28,560
for your teams to develop faster,

311
00:15:28,560 --> 00:15:29,880
focus more on innovation,

312
00:15:29,880 --> 00:15:33,600
rather than just seeing what
technologies to integrate

313
00:15:33,600 --> 00:15:35,370
to make all this happen.

314
00:15:35,370 --> 00:15:37,860
And here is an example
of SvectorSearch query

315
00:15:37,860 --> 00:15:39,000
that we are executing.

316
00:15:39,000 --> 00:15:42,453
I took it from the digital
receipt demo as well.

317
00:15:43,590 --> 00:15:46,020
Another thing, and the one
I really like the most,

318
00:15:46,020 --> 00:15:48,030
is removing friction.

319
00:15:48,030 --> 00:15:50,940
When you build AI, you really
need to start integrating

320
00:15:50,940 --> 00:15:53,310
with data from different systems,

321
00:15:53,310 --> 00:15:55,530
and you can integrate different frameworks

322
00:15:55,530 --> 00:15:57,300
for developing AI.

323
00:15:57,300 --> 00:16:01,020
Atlas reduced friction
with many, many of these.

324
00:16:01,020 --> 00:16:03,420
This is one example,
where we are leveraging,

325
00:16:03,420 --> 00:16:06,090
this is the financial demo
that I showed you earlier.

326
00:16:06,090 --> 00:16:08,610
We are using Amazon Bedrock

327
00:16:08,610 --> 00:16:12,780
to expand capabilities
and have better responses.

328
00:16:12,780 --> 00:16:16,140
We are also initializing the memory layer

329
00:16:16,140 --> 00:16:17,850
using MongoDB Atlas,

330
00:16:17,850 --> 00:16:19,590
and then we are using LangGraph

331
00:16:19,590 --> 00:16:21,090
as an orchestrated of these...

332
00:16:21,090 --> 00:16:23,490
orchestrator, sorry, of these agents.

333
00:16:23,490 --> 00:16:26,240
And you can see it's just as
simple as passing all this

334
00:16:28,200 --> 00:16:30,210
to the initializing function.

335
00:16:30,210 --> 00:16:32,460
And we are leveraging, again,

336
00:16:32,460 --> 00:16:35,790
Atlas as the memory layer for the agents.

337
00:16:35,790 --> 00:16:37,800
Another example of ease of integration

338
00:16:37,800 --> 00:16:40,323
with object storage, for
example, is this one.

339
00:16:41,220 --> 00:16:43,020
In our digital receipt demo,

340
00:16:43,020 --> 00:16:46,620
when the user first downloads
their digital receipt,

341
00:16:46,620 --> 00:16:51,090
we will generate it and store
it in Amazon S3 buckets.

342
00:16:51,090 --> 00:16:55,200
That URL is then gonna be
embedded into the document

343
00:16:55,200 --> 00:16:58,350
as metadata inside the file_url field.

344
00:16:58,350 --> 00:17:00,720
For subsequent downloading times,

345
00:17:00,720 --> 00:17:03,243
we just pull from that same URL.

346
00:17:05,490 --> 00:17:07,260
And well, last but not least,

347
00:17:07,260 --> 00:17:09,840
we have the enterprise ready factor.

348
00:17:09,840 --> 00:17:14,840
So, we run in over 30 plus AWS regions.

349
00:17:15,030 --> 00:17:16,120
We also have

350
00:17:17,680 --> 00:17:20,550
many audits at security
level, for example,

351
00:17:20,550 --> 00:17:24,030
we are able to encrypt your data

352
00:17:24,030 --> 00:17:27,900
and having it secure, not
only at rest and in transit,

353
00:17:27,900 --> 00:17:30,510
but also during use.

354
00:17:30,510 --> 00:17:33,780
So ultimately if you have
everything in one place,

355
00:17:33,780 --> 00:17:36,480
it is easier to secure,
easier to maintain,

356
00:17:36,480 --> 00:17:39,273
and easier to onboard new team members.

357
00:17:40,350 --> 00:17:44,340
So as we wrap up, here are
some of the key takeaways

358
00:17:44,340 --> 00:17:46,860
that I would like you to
take from today's session.

359
00:17:46,860 --> 00:17:49,330
The first one is to keep innovating

360
00:17:50,220 --> 00:17:51,760
and using all these

361
00:17:52,800 --> 00:17:55,620
trends and frameworks

362
00:17:55,620 --> 00:17:58,680
and technologies that come
from the AI innovation wave,

363
00:17:58,680 --> 00:18:01,260
but doing so without losing the focus

364
00:18:01,260 --> 00:18:03,900
on what business value it brings to you.

365
00:18:03,900 --> 00:18:06,510
And then last but not least, also,

366
00:18:06,510 --> 00:18:08,340
AI is just one

367
00:18:08,340 --> 00:18:11,160
of the many waves of
innovation that are to come.

368
00:18:11,160 --> 00:18:12,960
We don't know what's gonna be next

369
00:18:12,960 --> 00:18:15,090
in the next 15, 20 plus years,

370
00:18:15,090 --> 00:18:16,260
but what it is a fact,

371
00:18:16,260 --> 00:18:20,250
is that if you invest in the
right data foundation today,

372
00:18:20,250 --> 00:18:22,650
you are going to be much better equipped

373
00:18:22,650 --> 00:18:25,053
to develop whatever comes tomorrow.

374
00:18:25,920 --> 00:18:28,440
All right, so I really hope

375
00:18:28,440 --> 00:18:30,270
that you had enjoyed today's session,

376
00:18:30,270 --> 00:18:32,430
that you had learned something new.

377
00:18:32,430 --> 00:18:33,870
If you can please take a moment

378
00:18:33,870 --> 00:18:37,323
to also evaluate the
session through the app,

379
00:18:38,190 --> 00:18:39,360
I would, thank you,

380
00:18:39,360 --> 00:18:44,360
and keep enjoying this amazing
experience of AWS re:Invent.

381
00:18:44,520 --> 00:18:45,353
Thank you.

