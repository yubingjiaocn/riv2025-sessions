1
00:00:01,729 --> 00:00:02,588
Hi, good afternoon.

2
00:00:02,890 --> 00:00:04,919
Um, just a reminder for you to wear your

3
00:00:04,919 --> 00:00:07,009
headsets on and uh please

4
00:00:07,009 --> 00:00:08,130
give me a thumbs up if you can hear me.

5
00:00:09,108 --> 00:00:10,448
OK, awesome. Great. Thanks.

6
00:00:10,839 --> 00:00:13,159
Um, welcome to CMP 307,

7
00:00:13,319 --> 00:00:15,099
which is our breakout session today

8
00:00:15,478 --> 00:00:17,519
on how Graviton enables

9
00:00:17,519 --> 00:00:19,899
the best price performance for your AWS workloads.

10
00:00:20,728 --> 00:00:22,908
I'm Sudhi Rahman, director of product management

11
00:00:22,908 --> 00:00:24,989
at DC2 for Core Compute Products.

12
00:00:25,958 --> 00:00:28,199
And co-presenting with me today are Ali

13
00:00:28,199 --> 00:00:30,260
Saidi, VP and Distinguished

14
00:00:30,260 --> 00:00:31,699
Engineer at AWS,

15
00:00:32,319 --> 00:00:34,520
as well as our guest speaker for today, Thibaud Delor,

16
00:00:34,750 --> 00:00:36,319
principal engineer from Atlassian.

17
00:00:38,819 --> 00:00:41,179
Super excited today to bring you a um

18
00:00:41,179 --> 00:00:43,389
a deep agenda where we're gonna talk more about

19
00:00:43,389 --> 00:00:44,548
our Graviton journey,

20
00:00:44,899 --> 00:00:46,158
customer stories.

21
00:00:46,469 --> 00:00:48,630
We're gonna dive deeper into our latest Graviton 5

22
00:00:48,630 --> 00:00:50,908
chip that we just announced a few hours

23
00:00:50,908 --> 00:00:51,429
ago today.

24
00:00:52,359 --> 00:00:54,679
Um, Thibo is gonna walk through Atlassian's

25
00:00:54,679 --> 00:00:56,679
journey and the key practices and

26
00:00:56,679 --> 00:00:57,939
the best learnings from that,

27
00:00:58,439 --> 00:01:00,020
and we will cap this off with

28
00:01:00,399 --> 00:01:02,679
some of the knowledge base and the best practices

29
00:01:02,679 --> 00:01:04,799
for you to get started on your graviton journey as well.

30
00:01:07,138 --> 00:01:08,769
So with that, let's just dive right into it.

31
00:01:09,698 --> 00:01:11,948
At AWS we've been building custom

32
00:01:11,948 --> 00:01:12,689
silicon

33
00:01:13,069 --> 00:01:13,930
for more than a decade.

34
00:01:14,799 --> 00:01:16,969
And this includes custom chips across multiple

35
00:01:16,969 --> 00:01:18,000
different areas

36
00:01:18,448 --> 00:01:20,448
spanning, for example, our nitro

37
00:01:20,448 --> 00:01:21,230
chips

38
00:01:21,769 --> 00:01:23,808
where which are part of the overall AWS Nitro

39
00:01:23,808 --> 00:01:24,430
system

40
00:01:24,888 --> 00:01:26,969
that allows us to offload dedicated

41
00:01:26,969 --> 00:01:28,989
functions such as storage and networking

42
00:01:29,359 --> 00:01:30,250
to custom silicon.

43
00:01:31,099 --> 00:01:33,239
And allows us to enhance performance,

44
00:01:33,299 --> 00:01:35,480
security, and maximize resource efficiency.

45
00:01:37,000 --> 00:01:39,040
We're also building custom chips um to

46
00:01:39,040 --> 00:01:41,180
accelerate machine learning applications,

47
00:01:41,680 --> 00:01:43,760
so these are chips such as inferentia and ranium.

48
00:01:44,769 --> 00:01:46,989
And then we have powerful and efficient

49
00:01:47,329 --> 00:01:48,588
core compute infrastructure

50
00:01:48,969 --> 00:01:50,269
through graviton-based servers.

51
00:01:52,760 --> 00:01:54,019
So if we turn our attention to graviton,

52
00:01:54,930 --> 00:01:55,528
why gravion?

53
00:01:57,079 --> 00:01:59,159
So two key value proposition

54
00:01:59,159 --> 00:02:01,359
areas for our customers. First thing,

55
00:02:01,760 --> 00:02:03,799
it delivers the best price performance for

56
00:02:03,799 --> 00:02:05,959
a broad array of workloads in Amazon EC2.

57
00:02:06,120 --> 00:02:08,490
So really helping you run your

58
00:02:08,490 --> 00:02:10,679
applications faster and lowering costs

59
00:02:10,679 --> 00:02:12,800
overall. And

60
00:02:12,800 --> 00:02:14,939
secondly, we find that a lot of our customers

61
00:02:15,319 --> 00:02:17,399
have goals towards lowering their overall carbon

62
00:02:17,399 --> 00:02:19,558
footprint and improving sustainability.

63
00:02:20,550 --> 00:02:22,830
And graviton with its energy efficiency

64
00:02:22,830 --> 00:02:23,610
benefits

65
00:02:24,069 --> 00:02:26,229
allows our customers to make significant progress

66
00:02:26,229 --> 00:02:27,229
towards those goals.

67
00:02:28,308 --> 00:02:31,028
So when viewed in aggregate today, we have more than 90,000

68
00:02:31,028 --> 00:02:32,250
AWS customers

69
00:02:32,669 --> 00:02:33,909
that are drawing on Graviton.

70
00:02:34,599 --> 00:02:36,669
And these range from some of the

71
00:02:36,669 --> 00:02:38,679
hottest startups all the way to very

72
00:02:38,679 --> 00:02:40,800
well established Fortune 500

73
00:02:40,800 --> 00:02:41,639
enterprises.

74
00:02:43,139 --> 00:02:45,219
And our goal is to enable a

75
00:02:45,219 --> 00:02:47,219
deep and a broad portfolio of graviton

76
00:02:47,219 --> 00:02:49,080
instance types so that our customers

77
00:02:49,538 --> 00:02:51,659
can choose the right instance for the right workload.

78
00:02:52,300 --> 00:02:55,439
And today we have over 300 graviton-based

79
00:02:55,439 --> 00:02:57,838
instance types that are available globally at scale

80
00:02:58,179 --> 00:03:00,000
in over 38 AWS regions.

81
00:03:05,889 --> 00:03:08,008
And here's a look at our graviton journey over

82
00:03:08,008 --> 00:03:09,149
the last seven years.

83
00:03:09,449 --> 00:03:11,669
So when the first chip came out in 2018,

84
00:03:12,169 --> 00:03:14,169
this was more about getting the overall software

85
00:03:14,169 --> 00:03:15,389
ecosystem up and running

86
00:03:15,770 --> 00:03:17,288
on the AM 64 architecture.

87
00:03:18,319 --> 00:03:20,699
And then 1 year later, Graviton 2 came out

88
00:03:21,038 --> 00:03:23,118
and it opened up a whole array of general

89
00:03:23,118 --> 00:03:24,379
purpose applications

90
00:03:24,639 --> 00:03:25,960
to be able to run on Graviton.

91
00:03:27,179 --> 00:03:28,479
And our focus

92
00:03:28,740 --> 00:03:30,000
with each generation

93
00:03:30,460 --> 00:03:32,219
has been to improve the performance,

94
00:03:32,629 --> 00:03:34,659
push the boundaries on the capabilities as well as

95
00:03:34,659 --> 00:03:36,659
the energy efficiency benefits that we can deliver

96
00:03:36,659 --> 00:03:38,179
with each iteration of the graviton chip.

97
00:03:39,500 --> 00:03:42,439
Along with also improving capabilities

98
00:03:42,758 --> 00:03:44,419
for certain specific workloads.

99
00:03:45,550 --> 00:03:46,838
So with Graviton 3

100
00:03:47,149 --> 00:03:49,210
that delivered a 25% higher performance

101
00:03:49,210 --> 00:03:50,490
per core over Gravidon 2.

102
00:03:51,300 --> 00:03:52,229
We also

103
00:03:52,538 --> 00:03:54,538
put in optimizations in there for certain computer

104
00:03:54,538 --> 00:03:55,758
optimized workloads

105
00:03:56,139 --> 00:03:57,409
such as video encoding,

106
00:03:57,830 --> 00:03:59,939
CPU-based machine learning, as well as high performance

107
00:03:59,939 --> 00:04:02,360
computing. With

108
00:04:02,360 --> 00:04:04,580
the graviton 4 chip that came two years later.

109
00:04:05,469 --> 00:04:07,669
That built in 50% more cores

110
00:04:07,669 --> 00:04:08,288
per chip

111
00:04:08,629 --> 00:04:10,979
and that opened up the whole array of scale up workloads

112
00:04:10,979 --> 00:04:12,330
for our customers. So

113
00:04:12,669 --> 00:04:15,710
think of large databases, analytics,

114
00:04:16,108 --> 00:04:18,189
all of those scale scale up workloads that could

115
00:04:18,189 --> 00:04:18,889
benefit from

116
00:04:19,428 --> 00:04:21,369
higher compute and more instances

117
00:04:21,670 --> 00:04:22,629
uh per per core.

118
00:04:24,420 --> 00:04:26,500
Which then brings us to the latest and greatest chip that

119
00:04:26,500 --> 00:04:28,379
we just announced earlier this morning,

120
00:04:28,790 --> 00:04:29,988
the Gravidon 5 chip,

121
00:04:30,428 --> 00:04:32,750
which is the most powerful and the most

122
00:04:32,750 --> 00:04:34,250
energy efficient chip that we've built thus far.

123
00:04:35,149 --> 00:04:36,798
So we're going to talk more about that shortly.

124
00:04:42,488 --> 00:04:44,889
So just going back to the theme of enabling a broad

125
00:04:44,889 --> 00:04:46,108
and a deep portfolio

126
00:04:46,569 --> 00:04:48,790
for our customers across all their use cases,

127
00:04:49,329 --> 00:04:51,519
here is an example of our Gravidon 4 portfolio

128
00:04:51,519 --> 00:04:53,798
today. What you can see is

129
00:04:53,798 --> 00:04:55,738
that there are options available from

130
00:04:56,000 --> 00:04:58,149
384 gigs of memory all the way up to 3

131
00:04:58,149 --> 00:04:59,319
terabytes of memory

132
00:04:59,798 --> 00:05:01,920
for workloads that span compute general purpose and

133
00:05:01,920 --> 00:05:03,379
memory optimized use cases.

134
00:05:04,769 --> 00:05:07,170
And if you have workloads that benefit from fast

135
00:05:07,170 --> 00:05:08,730
access to local instant storage,

136
00:05:09,088 --> 00:05:11,199
so NVME attached instance types,

137
00:05:11,528 --> 00:05:12,970
we have a bunch of those as well,

138
00:05:13,238 --> 00:05:15,889
and some of them support a whopping 120

139
00:05:15,889 --> 00:05:18,009
terabytes of local SSDs using

140
00:05:18,009 --> 00:05:19,149
Amazon SSDs.

141
00:05:20,250 --> 00:05:22,569
And we realized customers have a diversity of workloads,

142
00:05:22,649 --> 00:05:24,670
so there are workloads that are more sensitive to

143
00:05:24,889 --> 00:05:25,959
IO performance,

144
00:05:26,250 --> 00:05:28,769
so things like more networking or more EBS,

145
00:05:29,048 --> 00:05:31,129
and we have instances for those applications

146
00:05:31,129 --> 00:05:35,959
as well. Now

147
00:05:35,959 --> 00:05:37,699
if you look at the Graviton servers,

148
00:05:38,199 --> 00:05:40,629
in addition to a lot of the hardware components

149
00:05:40,629 --> 00:05:41,980
that go into these servers.

150
00:05:42,660 --> 00:05:44,738
AWS has also integrated and

151
00:05:44,738 --> 00:05:45,629
has full ownership

152
00:05:46,139 --> 00:05:48,178
of the firmware and the software that goes along

153
00:05:48,178 --> 00:05:50,220
with it. So this means

154
00:05:50,220 --> 00:05:52,259
that it's not just a graviton host CPUs in

155
00:05:52,259 --> 00:05:52,910
the server,

156
00:05:53,238 --> 00:05:54,858
but it's also our nitrocards

157
00:05:55,259 --> 00:05:57,100
for EBS for ENA.

158
00:05:57,819 --> 00:05:59,850
And the Amazon SSDs and the software

159
00:05:59,850 --> 00:06:02,500
that goes along with these Nitro cards and the Nitro Hypervisor,

160
00:06:02,899 --> 00:06:04,278
all of these come together,

161
00:06:04,738 --> 00:06:06,778
and that allows us to tailor these servers

162
00:06:06,778 --> 00:06:08,519
to deliver the best performance

163
00:06:08,858 --> 00:06:09,980
in the Amazon environment.

164
00:06:15,250 --> 00:06:17,410
Now a most common customer question that comes

165
00:06:17,410 --> 00:06:19,769
up in several of my customer conversations is,

166
00:06:20,048 --> 00:06:21,850
what kind of workloads can run on Gravidon?

167
00:06:22,649 --> 00:06:24,879
And the answer here is really, really simple,

168
00:06:24,939 --> 00:06:26,519
is that it's a wide range

169
00:06:26,850 --> 00:06:29,079
of general purpose workloads that we see customers

170
00:06:29,259 --> 00:06:30,399
using Gravidon for.

171
00:06:30,939 --> 00:06:33,338
So everything that ranges from a web

172
00:06:33,338 --> 00:06:35,319
application to a containerized microservice,

173
00:06:35,750 --> 00:06:38,449
all the way through large databases, analytics,

174
00:06:38,949 --> 00:06:40,358
CPU based inference,

175
00:06:40,858 --> 00:06:42,540
as well as electronic design automation.

176
00:06:47,559 --> 00:06:49,879
Now with over 90,000 AWS customers using

177
00:06:49,879 --> 00:06:50,600
Gravidon,

178
00:06:50,959 --> 00:06:53,259
here is an example of some of the customer types

179
00:06:53,600 --> 00:06:55,709
that are using Graviton today, and what

180
00:06:55,709 --> 00:06:57,838
you can see here is that customers across every

181
00:06:57,838 --> 00:06:59,540
geo and every vertical

182
00:06:59,798 --> 00:07:01,459
are drawing on the graviton benefits.

183
00:07:02,588 --> 00:07:05,059
So, if you look at the top 100

184
00:07:05,059 --> 00:07:06,028
EC2 customers,

185
00:07:06,548 --> 00:07:08,910
every single one of them today is drawing on Graviton.

186
00:07:09,790 --> 00:07:12,420
And if you expand that cohort to the top 1000

187
00:07:12,420 --> 00:07:13,569
EC2 customers,

188
00:07:14,259 --> 00:07:16,389
more than 98% of them are

189
00:07:16,389 --> 00:07:17,488
drawing on Graviton today.

190
00:07:22,420 --> 00:07:24,420
And overall we've been hearing great feedback

191
00:07:24,420 --> 00:07:26,449
from customers on the cost and the performance

192
00:07:26,449 --> 00:07:29,040
improvements they're seeing, and here are some examples.

193
00:07:29,689 --> 00:07:31,928
With ClickH, they saw a 25 to 30%

194
00:07:31,928 --> 00:07:34,019
improvement on average across multiple credit

195
00:07:34,019 --> 00:07:34,540
types,

196
00:07:34,819 --> 00:07:36,928
and in some cases up to 76%

197
00:07:36,928 --> 00:07:38,040
improvement in performance.

198
00:07:39,220 --> 00:07:41,500
FreshWorks, when they ran their Ruby on Rails

199
00:07:41,500 --> 00:07:43,619
applications and Java applications pretty seamlessly,

200
00:07:44,009 --> 00:07:46,259
saw a 23% improvement in average response

201
00:07:46,259 --> 00:07:48,259
time. And with Cora, when

202
00:07:48,259 --> 00:07:50,238
they migrated from Graviton 3 to 4,

203
00:07:50,699 --> 00:07:52,730
they saw about a 20% improvement in

204
00:07:52,730 --> 00:07:53,838
query serving times.

205
00:07:57,139 --> 00:07:59,259
And it's not just about price performance.

206
00:07:59,629 --> 00:08:01,319
We're seeing a lot of customers

207
00:08:01,619 --> 00:08:03,939
benefit from the sustainability benefits of Graviton

208
00:08:03,939 --> 00:08:04,559
as well.

209
00:08:04,939 --> 00:08:06,338
And here are some examples.

210
00:08:06,750 --> 00:08:07,790
With Snowflake,

211
00:08:08,139 --> 00:08:10,278
they saw a 57% reduction

212
00:08:10,899 --> 00:08:13,259
in the carbon emissions per Snowflake virtual

213
00:08:13,259 --> 00:08:14,238
warehouse credit

214
00:08:14,540 --> 00:08:15,899
after moving to Graviton,

215
00:08:16,420 --> 00:08:18,699
while also enabling about 10%

216
00:08:18,699 --> 00:08:20,019
faster performance on average.

217
00:08:21,319 --> 00:08:23,329
And you can see a similar storyline with Adobe

218
00:08:23,329 --> 00:08:24,600
and Jay Frog here as well,

219
00:08:24,928 --> 00:08:27,009
where they were able to reduce their carbon footprint by up

220
00:08:27,009 --> 00:08:27,750
to 60%.

221
00:08:32,688 --> 00:08:34,967
No conversation today is complete without talking about

222
00:08:34,967 --> 00:08:37,087
machine learning, given the AIML era that

223
00:08:37,087 --> 00:08:39,129
we are in. And we are seeing

224
00:08:39,129 --> 00:08:41,808
a lot of customers also deploy CPU-based

225
00:08:41,808 --> 00:08:43,928
machine learning applications on graviton-based

226
00:08:43,928 --> 00:08:44,528
instance types.

227
00:08:45,168 --> 00:08:46,769
An example here is Mobbi Eye.

228
00:08:47,210 --> 00:08:49,369
When they enabled their change detection

229
00:08:49,369 --> 00:08:51,320
system to run on graviton instances,

230
00:08:51,690 --> 00:08:53,729
they saw up to a 2x improvement in overall

231
00:08:53,729 --> 00:08:54,308
performance.

232
00:08:55,690 --> 00:08:57,729
And you also have an example of Sprinkler where they ran

233
00:08:57,729 --> 00:08:59,769
their mixed inference and search workloads

234
00:08:59,928 --> 00:09:01,750
and achieved up to a 30% reduction

235
00:09:02,288 --> 00:09:04,509
along with up to a 30% cost savings.

236
00:09:12,109 --> 00:09:14,058
And it's not just external customers,

237
00:09:14,469 --> 00:09:16,450
but we at Amazon are also

238
00:09:17,109 --> 00:09:19,229
employing Graviton at scale across a wide

239
00:09:19,229 --> 00:09:20,769
array of managed services.

240
00:09:21,599 --> 00:09:23,158
So what you see here is that

241
00:09:23,460 --> 00:09:25,729
a wide set of Amazon database

242
00:09:25,729 --> 00:09:27,979
services, as well as some services like MSK

243
00:09:28,690 --> 00:09:30,259
have a pretty significant deployment

244
00:09:30,519 --> 00:09:31,940
of Graviton service today.

245
00:09:32,320 --> 00:09:34,428
For example, with Amazon Redshift services, more

246
00:09:34,428 --> 00:09:36,479
than 90% of the current deployment is

247
00:09:36,479 --> 00:09:37,029
on Graviton.

248
00:09:38,469 --> 00:09:40,950
And outside AWS and even on the Amazon.com

249
00:09:40,950 --> 00:09:43,019
side, we've been using Graviton

250
00:09:43,019 --> 00:09:44,979
for some mission critical events like Prime Day,

251
00:09:45,308 --> 00:09:47,570
where this year more than 40% of compute

252
00:09:47,989 --> 00:09:49,489
of Prime Day was powered by Graviton.

253
00:09:51,149 --> 00:09:53,178
So with that background, I will turn it over to

254
00:09:53,178 --> 00:09:55,229
Ali Saidi to tell us more about the

255
00:09:55,229 --> 00:09:56,788
latest ship that we just launched today.

256
00:10:03,298 --> 00:10:03,989
Thank you, Sudhir.

257
00:10:05,000 --> 00:10:06,969
So let's talk a bit about Graviton 5.

258
00:10:08,168 --> 00:10:10,408
With Graviton 5, we are going

259
00:10:10,408 --> 00:10:12,609
beyond Moore's Law and doubling the number

260
00:10:12,609 --> 00:10:15,298
of cores that we have um

261
00:10:15,649 --> 00:10:17,960
in our, in our chip from graviton 4 to graviton

262
00:10:17,960 --> 00:10:18,548
5.

263
00:10:19,769 --> 00:10:21,070
each of these cores

264
00:10:21,330 --> 00:10:23,479
uh is doing about 25% higher

265
00:10:23,479 --> 00:10:24,109
performance

266
00:10:24,529 --> 00:10:25,229
and

267
00:10:25,629 --> 00:10:27,729
you know we've built Graviton 5 in

268
00:10:27,729 --> 00:10:29,509
a 3 nanometer process.

269
00:10:29,808 --> 00:10:32,229
Let's zoom into the pieces that make up

270
00:10:32,450 --> 00:10:33,210
this processor.

271
00:10:34,109 --> 00:10:36,149
We've talked a while about big workloads and

272
00:10:36,149 --> 00:10:38,250
how micro benchmarks

273
00:10:38,308 --> 00:10:39,428
are very different

274
00:10:39,710 --> 00:10:41,989
from big workloads and how we like to design for

275
00:10:41,989 --> 00:10:44,009
big workloads where we're not talking about

276
00:10:44,408 --> 00:10:46,629
um you know small loops but really all the

277
00:10:46,629 --> 00:10:49,340
code and complexity of a real

278
00:10:49,340 --> 00:10:50,649
application like a database.

279
00:10:52,298 --> 00:10:54,389
This needs things like bigger branch predictors

280
00:10:54,489 --> 00:10:56,750
so you can process more instructions a cycle,

281
00:10:57,379 --> 00:10:59,330
um, and you know

282
00:10:59,609 --> 00:11:01,629
with Graviton 5 we've adopted

283
00:11:01,629 --> 00:11:02,969
the Neoverse V3 core.

284
00:11:03,418 --> 00:11:05,558
It's an AM V9.2 core. It's

285
00:11:05,558 --> 00:11:08,219
got bigger branch predictors. It's got more advanced prefectures,

286
00:11:08,609 --> 00:11:10,210
and it's generally a higher performing core.

287
00:11:14,009 --> 00:11:16,029
Then we coupled that with our cash hierarchy.

288
00:11:16,668 --> 00:11:18,729
Uh, optimizing uh a chip is

289
00:11:18,729 --> 00:11:20,808
a complex optimization problem of figuring out where are

290
00:11:20,808 --> 00:11:21,830
you going to put cash.

291
00:11:22,548 --> 00:11:24,869
You'd love to put it all as close to the processor as possible,

292
00:11:24,950 --> 00:11:26,548
but physics gets in the way.

293
00:11:27,830 --> 00:11:29,070
And so um

294
00:11:29,340 --> 00:11:31,509
you know the L2 cache is great. When we went from graviton

295
00:11:31,509 --> 00:11:33,599
3 to graviton 4, we doubled the size of

296
00:11:33,719 --> 00:11:35,359
the L2 cache to 2 megabytes.

297
00:11:35,719 --> 00:11:36,928
We've kept that here,

298
00:11:37,399 --> 00:11:39,859
but we've increased the size of the L3 cache.

299
00:11:40,379 --> 00:11:42,570
Um, we've made it 5.3x

300
00:11:42,570 --> 00:11:44,798
bigger than it was in graviton

301
00:11:44,798 --> 00:11:47,359
4. It's now 192 megabytes.

302
00:11:48,099 --> 00:11:50,489
And in total between the L2, the L3,

303
00:11:50,548 --> 00:11:52,788
and the L1 caches we have around 600

304
00:11:52,788 --> 00:11:53,529
megabytes

305
00:11:53,788 --> 00:11:54,529
of cash.

306
00:11:56,619 --> 00:11:58,820
With Graviton we've really tried to lead with DDR.

307
00:11:59,259 --> 00:12:01,119
This has meant working with DDRAM vendors.

308
00:12:01,580 --> 00:12:03,940
Graviton 2 was the first system

309
00:12:03,940 --> 00:12:06,379
where we pushed to DR 43,200.

310
00:12:06,859 --> 00:12:08,899
Graviton 3 was the first system we had with

311
00:12:08,899 --> 00:12:09,879
DDR 5.

312
00:12:10,349 --> 00:12:11,090
And

313
00:12:11,580 --> 00:12:13,678
with, um, Graviton 5

314
00:12:13,979 --> 00:12:16,038
we're working with DRAM vendors to,

315
00:12:16,099 --> 00:12:18,298
to get all the way up to DDR 8800.

316
00:12:19,678 --> 00:12:21,580
We've also reduced the GRM access latency

317
00:12:21,960 --> 00:12:24,519
in graviton down to less than 100 nanoseconds.

318
00:12:24,668 --> 00:12:26,759
That's about 15% lower than

319
00:12:26,759 --> 00:12:27,940
it was before.

320
00:12:29,979 --> 00:12:32,000
Grabtone 5 also is the first system

321
00:12:32,000 --> 00:12:32,658
in CPU

322
00:12:33,700 --> 00:12:36,000
in our fleet to support PCIE

323
00:12:36,109 --> 00:12:37,000
Gen 6

324
00:12:37,330 --> 00:12:39,739
with around half a terabyte a second

325
00:12:39,739 --> 00:12:40,960
of bioconnectivity.

326
00:12:42,820 --> 00:12:44,859
Now we've taken 96 or 192

327
00:12:44,859 --> 00:12:46,960
cores and, and put them

328
00:12:47,538 --> 00:12:48,379
in one ship.

329
00:12:49,190 --> 00:12:51,269
And in doing that we've reduced

330
00:12:51,269 --> 00:12:52,190
pneumo latency

331
00:12:52,609 --> 00:12:54,408
that we had by about 33%.

332
00:12:54,788 --> 00:12:56,210
We've increased bandwidth

333
00:12:56,690 --> 00:12:58,250
um substantially,

334
00:12:58,950 --> 00:13:01,009
but we're not getting rid of pneuma even though it's in one socket.

335
00:13:01,269 --> 00:13:02,048
We've decided to keep

336
00:13:02,359 --> 00:13:04,849
Pneuma and offer two pneuma regions

337
00:13:05,418 --> 00:13:06,509
to reduce memory latency.

338
00:13:07,190 --> 00:13:09,269
Uh, so that the cache and the DM

339
00:13:09,269 --> 00:13:11,009
controllers are closer to your course.

340
00:13:12,769 --> 00:13:15,229
So with all these pieces we have

341
00:13:16,129 --> 00:13:18,489
the ingredients for our 9th generation of

342
00:13:18,489 --> 00:13:19,590
EC2 instances.

343
00:13:20,048 --> 00:13:21,940
The M9G instance that we're previewing today,

344
00:13:22,489 --> 00:13:24,808
um, has industry leading performance up to 25%

345
00:13:24,808 --> 00:13:26,109
better than Graviton 4.

346
00:13:26,450 --> 00:13:28,489
It's the most energy efficient CPU we built,

347
00:13:29,009 --> 00:13:30,969
provides the best price performance in EC2,

348
00:13:31,408 --> 00:13:33,440
and provides us the same scale

349
00:13:33,440 --> 00:13:35,509
up capabilities that we had before.

350
00:13:37,288 --> 00:13:39,389
Now I'm gonna spend a few minutes talking a

351
00:13:39,389 --> 00:13:40,509
bit about security.

352
00:13:42,570 --> 00:13:44,599
There are many things that a hypervisor has to do. It has to

353
00:13:44,599 --> 00:13:46,649
do scheduling, it has to do resource allocation, it has to

354
00:13:46,649 --> 00:13:48,889
do IO. And when virtualization

355
00:13:48,889 --> 00:13:51,250
started, it was really about packing many of your own workloads

356
00:13:51,250 --> 00:13:53,279
together. And we've talked over the years

357
00:13:53,279 --> 00:13:54,590
about how nitro is different.

358
00:13:55,048 --> 00:13:57,210
With nitro, we've moved networking, storage

359
00:13:57,210 --> 00:13:57,830
and management

360
00:13:58,168 --> 00:13:59,250
onto dedicated silicon.

361
00:14:00,119 --> 00:14:02,288
And nitro has many jobs to do, but the most important

362
00:14:02,288 --> 00:14:04,149
one is keeping customers isolated,

363
00:14:04,570 --> 00:14:06,788
isolated from each other and isolated from us.

364
00:14:07,250 --> 00:14:08,349
With the nitro system,

365
00:14:08,849 --> 00:14:10,849
um, we have no operator access, and we

366
00:14:10,849 --> 00:14:12,918
enforce that with mechanisms, not with

367
00:14:12,918 --> 00:14:13,548
policies.

368
00:14:15,580 --> 00:14:17,558
With our nitro cards, we've been raising

369
00:14:17,820 --> 00:14:19,158
the bar and security with Graviton.

370
00:14:19,580 --> 00:14:21,599
With Graviton 2, we introduced DRM encryption.

371
00:14:22,058 --> 00:14:24,298
With Graviton 4, we introduced PCIE encryption.

372
00:14:25,019 --> 00:14:27,019
We've taken the attestation that we had

373
00:14:27,019 --> 00:14:29,080
from our nitro cards and graviton 4

374
00:14:29,219 --> 00:14:31,219
and moved it to also be

375
00:14:31,219 --> 00:14:32,080
allow us to attest

376
00:14:32,658 --> 00:14:34,960
the the CPU, the, the host CPUs

377
00:14:35,139 --> 00:14:35,739
that we have.

378
00:14:37,149 --> 00:14:38,408
With Grabs on 5,

379
00:14:39,989 --> 00:14:41,250
We're going one step further.

380
00:14:41,668 --> 00:14:43,668
The the nitro hypervisor is purpose built for one

381
00:14:43,668 --> 00:14:45,190
job, and it's an amazing hypervisor,

382
00:14:45,469 --> 00:14:46,928
but we constantly ask ourselves,

383
00:14:47,308 --> 00:14:48,369
can we raise the bar?

384
00:14:48,788 --> 00:14:50,989
So coupled with graviton, we've been building another layer

385
00:14:50,989 --> 00:14:51,849
of technology

386
00:14:52,269 --> 00:14:54,308
to increase the transparency in our virtualization stack

387
00:14:54,308 --> 00:14:55,869
that we call the nitro isolation engine.

388
00:14:56,570 --> 00:14:58,788
It sits between the graviton CPU and the nitro hypervisor.

389
00:14:59,609 --> 00:15:00,178
So what is it?

390
00:15:01,178 --> 00:15:02,599
It's really compartmentalizing

391
00:15:02,859 --> 00:15:04,940
the most critical elements of interactions

392
00:15:04,940 --> 00:15:07,178
with instant memory, devices, and access

393
00:15:07,178 --> 00:15:08,599
control. There are two

394
00:15:08,899 --> 00:15:09,619
interesting things about it.

395
00:15:10,489 --> 00:15:11,918
The first is it's written in rust,

396
00:15:12,219 --> 00:15:14,298
and so rust gives you a lot of memory

397
00:15:14,298 --> 00:15:16,340
safety and memory and concurrency properties, which

398
00:15:16,340 --> 00:15:17,080
are really cool.

399
00:15:17,820 --> 00:15:19,029
But the second one

400
00:15:19,349 --> 00:15:21,389
is that formal verification was

401
00:15:21,389 --> 00:15:22,908
a part of this code base from the start.

402
00:15:23,190 --> 00:15:24,739
We started building this,

403
00:15:25,029 --> 00:15:27,570
we had software engineers working

404
00:15:27,908 --> 00:15:30,149
in tandem with some of our applied scientists

405
00:15:30,149 --> 00:15:31,489
in our automated reasoning group.

406
00:15:33,119 --> 00:15:34,940
Um, to formally specify

407
00:15:35,359 --> 00:15:37,500
what the, how the, how the software would work

408
00:15:37,918 --> 00:15:40,000
and, and what it could and

409
00:15:40,000 --> 00:15:42,129
couldn't do. So

410
00:15:42,129 --> 00:15:44,229
what's formal verification? Let's take

411
00:15:44,529 --> 00:15:46,070
a simple function like this.

412
00:15:46,408 --> 00:15:47,750
It's got 3 inputs,

413
00:15:48,250 --> 00:15:48,889
um,

414
00:15:49,250 --> 00:15:51,450
and, you know, how can you be sure that it always

415
00:15:51,450 --> 00:15:51,969
works?

416
00:15:52,369 --> 00:15:54,408
Well, the easy way is you can try

417
00:15:54,408 --> 00:15:56,450
some test cases. You can try all 0s, you can try

418
00:15:56,450 --> 00:15:58,009
some 1s, you can try maxims.

419
00:15:58,950 --> 00:15:59,609
Um,

420
00:16:00,029 --> 00:16:01,808
but you can't exhaustively test it,

421
00:16:02,109 --> 00:16:03,529
even if you say you had.

422
00:16:04,349 --> 00:16:06,710
A CPU that could do a billion

423
00:16:06,710 --> 00:16:09,349
tests a second and you had a billion CPUs,

424
00:16:09,710 --> 00:16:11,788
you'd still need more time than the age of the universe

425
00:16:11,788 --> 00:16:13,149
to exhaustively test this function.

426
00:16:14,038 --> 00:16:16,369
So formal verification lets you mathematically prove

427
00:16:16,489 --> 00:16:18,759
that the function specification, adding numbers,

428
00:16:18,769 --> 00:16:19,808
matches the implementation.

429
00:16:22,080 --> 00:16:24,558
It's really about the application of mathematical

430
00:16:25,229 --> 00:16:26,359
logic and reasoning

431
00:16:26,639 --> 00:16:28,599
and the application of that to software systems.

432
00:16:29,649 --> 00:16:31,759
So you have a formal specification, and that

433
00:16:31,759 --> 00:16:32,710
formal specification

434
00:16:32,969 --> 00:16:34,269
tells you how it operates.

435
00:16:35,288 --> 00:16:37,619
Um, what it can do, what it must do, what

436
00:16:37,619 --> 00:16:38,609
it must never do

437
00:16:39,190 --> 00:16:41,190
for all possible inputs in all reachable

438
00:16:41,190 --> 00:16:43,519
states. For

439
00:16:43,519 --> 00:16:45,739
example, in the nitro case of the nitro isolation engine,

440
00:16:46,119 --> 00:16:47,979
it can create and manage VMs.

441
00:16:48,239 --> 00:16:50,399
It must preserve guest confidentiality

442
00:16:50,399 --> 00:16:52,558
and integrity, and it must never do things like null

443
00:16:52,558 --> 00:16:54,859
pointer to references or buffer overflows

444
00:16:55,320 --> 00:16:57,109
for all possible inputs

445
00:16:57,788 --> 00:16:58,918
in all possible states.

446
00:16:59,969 --> 00:17:00,908
So we've been proving

447
00:17:01,250 --> 00:17:03,288
functions, the core features of the

448
00:17:03,288 --> 00:17:05,529
nitro isolation engine in the VM

449
00:17:05,529 --> 00:17:06,309
life cycle

450
00:17:06,809 --> 00:17:08,009
and showing that,

451
00:17:08,608 --> 00:17:10,689
It has memory safety even in the places where

452
00:17:10,689 --> 00:17:12,108
you have unsafe rust code.

453
00:17:12,449 --> 00:17:15,229
There aren't any runtime errors. There aren't unreachable panics

454
00:17:15,410 --> 00:17:16,549
or unwraps on none.

455
00:17:17,130 --> 00:17:18,108
There's

456
00:17:18,489 --> 00:17:20,608
no logical errors that the specification

457
00:17:20,608 --> 00:17:22,068
and the implementation match,

458
00:17:22,568 --> 00:17:24,650
and then there's no unauthorized information leakage that we're

459
00:17:24,650 --> 00:17:25,910
we have confidentiality

460
00:17:26,328 --> 00:17:27,009
and integrity.

461
00:17:28,689 --> 00:17:30,439
And we're going to expand this

462
00:17:31,039 --> 00:17:31,900
to to uh

463
00:17:32,219 --> 00:17:33,059
more and more.

464
00:17:34,039 --> 00:17:35,660
Uh, parts of the system,

465
00:17:36,199 --> 00:17:38,479
every M9G instance is gonna have this enabled

466
00:17:38,479 --> 00:17:39,150
by default.

467
00:17:39,519 --> 00:17:41,920
We're gonna be engaging customers on the formal verification

468
00:17:41,920 --> 00:17:42,900
aspects of this

469
00:17:43,358 --> 00:17:44,519
in the, the coming months.

470
00:17:45,890 --> 00:17:48,000
OK, so let's talk a little bit about designing and building

471
00:17:48,000 --> 00:17:48,598
graviton.

472
00:17:48,989 --> 00:17:50,459
One of the things that

473
00:17:50,759 --> 00:17:53,239
the engineers who are working on Graviton

474
00:17:53,640 --> 00:17:55,338
are most excited about is actually

475
00:17:55,640 --> 00:17:57,930
using um a current

476
00:17:57,930 --> 00:18:00,029
generation of our processors to design the next

477
00:18:00,029 --> 00:18:02,160
generation. And when we started this,

478
00:18:02,299 --> 00:18:04,618
this, um, that wasn't a possibility,

479
00:18:04,838 --> 00:18:07,338
but over the years we've seen EDA tool vendors

480
00:18:07,640 --> 00:18:09,949
begin to support EDA flows on

481
00:18:09,949 --> 00:18:10,559
graviton.

482
00:18:13,098 --> 00:18:13,650
And

483
00:18:14,170 --> 00:18:16,348
today, Siemenscaliber

484
00:18:16,469 --> 00:18:18,549
is excited to announce support of

485
00:18:18,549 --> 00:18:20,578
Caliber on our Graviton systems.

486
00:18:20,828 --> 00:18:22,828
Caliber is the industry standard sign-off tool

487
00:18:23,000 --> 00:18:25,328
used by a majority of design companies.

488
00:18:25,588 --> 00:18:27,588
It's one of the most critical tools to run fast because it's

489
00:18:27,588 --> 00:18:29,709
coming at the end of the design process, and you're trying to

490
00:18:29,709 --> 00:18:31,868
iteratively solve all your issues and

491
00:18:31,868 --> 00:18:33,868
get to the point that you can start manufacturing design.

492
00:18:35,219 --> 00:18:36,598
And not only did Graviton

493
00:18:36,880 --> 00:18:39,299
4 show 20% higher perth and 30%

494
00:18:39,299 --> 00:18:41,239
cost reductions compared to the other instances

495
00:18:41,660 --> 00:18:43,739
that Siemens tested, they also

496
00:18:43,739 --> 00:18:45,598
saw an additional 30%

497
00:18:46,098 --> 00:18:46,920
performance boost

498
00:18:48,000 --> 00:18:49,259
when looking at Graviton 5.

499
00:18:50,170 --> 00:18:51,108
So it's super exciting

500
00:18:51,489 --> 00:18:52,608
to see caliber

501
00:18:52,930 --> 00:18:54,650
um support coming to Graviton.

502
00:18:56,759 --> 00:18:58,989
For over a decade since the inception of Annapurna Labs,

503
00:18:59,068 --> 00:19:01,348
Synopsis and AWS have collaborated to enable

504
00:19:01,348 --> 00:19:03,328
AWS's custom silicon development,

505
00:19:03,789 --> 00:19:05,489
and so we're also excited

506
00:19:05,828 --> 00:19:07,809
to announce that Synopsis is expanding support

507
00:19:08,118 --> 00:19:10,348
for their EDA tools on Graviton

508
00:19:10,348 --> 00:19:12,489
like VCS, Prime Time, and Fusion Compiler,

509
00:19:12,910 --> 00:19:14,989
where they saw 35 to 40% improvements in

510
00:19:14,989 --> 00:19:16,039
performance with Graviton 5.

511
00:19:17,729 --> 00:19:19,729
So let's dive into some of the other

512
00:19:19,729 --> 00:19:21,969
performance cases for for other use, other

513
00:19:21,969 --> 00:19:22,568
workloads.

514
00:19:23,880 --> 00:19:26,269
Sudhir mentioned uh machine learning,

515
00:19:26,588 --> 00:19:28,670
uh, customers, customers like Sprinkler and

516
00:19:28,670 --> 00:19:29,250
Mobi Eye,

517
00:19:29,868 --> 00:19:30,400
and so

518
00:19:30,670 --> 00:19:32,709
taking a variety of

519
00:19:32,709 --> 00:19:34,709
CPU-based ML workloads and running them on

520
00:19:34,709 --> 00:19:36,088
our deep learning containers

521
00:19:36,348 --> 00:19:38,568
with Graviton 5, we see a 35% improvement

522
00:19:38,989 --> 00:19:40,150
in performance on Pytorch.

523
00:19:43,170 --> 00:19:44,549
We also have companies who run Java apps

524
00:19:45,890 --> 00:19:47,969
and so we've taken a groovy Grails

525
00:19:47,969 --> 00:19:48,509
app,

526
00:19:48,890 --> 00:19:49,439
um,

527
00:19:49,848 --> 00:19:52,469
and Grails is an open source web application framework

528
00:19:53,009 --> 00:19:53,670
and

529
00:19:53,930 --> 00:19:56,088
tried it on an M8G Graviton 4-ba

530
00:19:56,088 --> 00:19:58,529
system and an M9G, uh, Graviton

531
00:19:58,529 --> 00:19:59,588
5-based system

532
00:20:00,009 --> 00:20:00,549
and here,

533
00:20:01,108 --> 00:20:03,529
um, using work to to generate load

534
00:20:03,529 --> 00:20:05,828
against the, the web server.

535
00:20:06,640 --> 00:20:08,729
We see a 32% increase in

536
00:20:08,729 --> 00:20:09,529
requests per second.

537
00:20:11,328 --> 00:20:13,568
You know, one of our big focuses has been on

538
00:20:13,568 --> 00:20:14,759
large workloads,

539
00:20:15,170 --> 00:20:17,289
and you know, while microservices are great, there still

540
00:20:17,289 --> 00:20:18,549
are monoliths in the world.

541
00:20:19,598 --> 00:20:21,949
We don't have a really good open source example here, but we took

542
00:20:21,949 --> 00:20:24,209
a large internal piece of code that does delivery

543
00:20:24,209 --> 00:20:26,170
planning. And um

544
00:20:27,660 --> 00:20:30,019
Tried that on Graviton 5 M9G

545
00:20:30,019 --> 00:20:32,068
instances. Here we saw a 47%

546
00:20:32,068 --> 00:20:32,920
performance increase.

547
00:20:35,299 --> 00:20:37,049
Hm All right.

548
00:20:38,469 --> 00:20:40,549
Um, we've also looked at Engine

549
00:20:40,549 --> 00:20:42,630
X. Engine X is a popular web server. It can also

550
00:20:42,630 --> 00:20:45,049
be a load balancer, and we've configured it as a load balancer

551
00:20:45,049 --> 00:20:46,209
in this case,

552
00:20:46,709 --> 00:20:48,750
and fixing the load generator,

553
00:20:48,910 --> 00:20:50,150
fixing a set of web servers,

554
00:20:50,630 --> 00:20:52,709
changing the instance in the middle from a graviton

555
00:20:52,709 --> 00:20:54,250
4 or a graviton 5,

556
00:20:54,539 --> 00:20:56,769
we see a 27% improvement in performance over

557
00:20:56,769 --> 00:21:00,489
generation over generation. Um,

558
00:21:00,779 --> 00:21:02,969
and lastly we've looked at databases and so

559
00:21:02,969 --> 00:21:04,670
one we've looked at is MySQL.

560
00:21:05,209 --> 00:21:06,390
We've used HammerDB

561
00:21:07,130 --> 00:21:09,130
to mimic um load against

562
00:21:09,130 --> 00:21:10,469
this, and Hammer DB

563
00:21:10,880 --> 00:21:12,920
uh mimics a company that sells

564
00:21:12,920 --> 00:21:15,118
items, keeps stock, has warehouses, receives

565
00:21:15,118 --> 00:21:15,719
orders,

566
00:21:16,049 --> 00:21:18,170
and measures performance and new orders per minute.

567
00:21:18,848 --> 00:21:20,848
And so here too comparing a graviton

568
00:21:20,848 --> 00:21:22,959
4-based M8G to a graviton 5-based

569
00:21:22,959 --> 00:21:23,568
M9G,

570
00:21:23,890 --> 00:21:25,588
we see a 40% improvement in performance.

571
00:21:26,539 --> 00:21:27,949
Now these are the workloads that we've run.

572
00:21:28,420 --> 00:21:30,519
I think the far more interesting ones are the workloads that other people

573
00:21:30,900 --> 00:21:32,939
have run, and over the last couple

574
00:21:32,939 --> 00:21:35,180
of weeks, a few customers have

575
00:21:35,180 --> 00:21:36,739
been running on Graviton 5.

576
00:21:37,729 --> 00:21:38,549
Snowflake

577
00:21:39,118 --> 00:21:39,828
has

578
00:21:40,088 --> 00:21:42,529
been running their virtual data warehouses on Graviton

579
00:21:42,529 --> 00:21:43,660
since Graviton 2.

580
00:21:44,170 --> 00:21:46,170
They recently tried an M9G instance

581
00:21:46,170 --> 00:21:48,930
and found that they saw more than 30%

582
00:21:48,930 --> 00:21:49,809
higher performance.

583
00:21:50,420 --> 00:21:51,299
In that instance type.

584
00:21:53,979 --> 00:21:56,259
Honeycomb has also been using Graviton since

585
00:21:56,259 --> 00:21:57,118
Graviton 2.

586
00:21:57,578 --> 00:22:00,078
They provide end to end observability software

587
00:22:00,459 --> 00:22:01,900
and um

588
00:22:03,219 --> 00:22:04,680
they were super excited to try

589
00:22:05,299 --> 00:22:05,818
M9G.

590
00:22:06,799 --> 00:22:09,078
Out of the box they saw 20 to 25%

591
00:22:09,078 --> 00:22:09,719
lower latency.

592
00:22:10,489 --> 00:22:12,630
And then as they kept latency

593
00:22:12,630 --> 00:22:14,939
fixed and just started to crank down the

594
00:22:14,939 --> 00:22:16,348
amount of CPU

595
00:22:16,618 --> 00:22:17,650
they were giving the workload,

596
00:22:17,979 --> 00:22:20,000
they saw 36% better throughput

597
00:22:20,259 --> 00:22:21,199
for the same latency.

598
00:22:23,930 --> 00:22:25,930
Airbnb has also been testing our

599
00:22:25,930 --> 00:22:27,328
M9G instances,

600
00:22:27,769 --> 00:22:28,289
um,

601
00:22:28,608 --> 00:22:30,608
and they found they were some of the fastest

602
00:22:30,608 --> 00:22:31,949
instances they've tested,

603
00:22:32,250 --> 00:22:33,809
um, in, in EC2,

604
00:22:34,209 --> 00:22:36,239
including 25% higher performance

605
00:22:36,239 --> 00:22:38,368
than the other than the other instances

606
00:22:38,368 --> 00:22:38,890
they tested.

607
00:22:40,630 --> 00:22:41,809
Uh, and lastly, SAP,

608
00:22:42,160 --> 00:22:44,479
uh, SAP has been running Hana Cloud

609
00:22:44,479 --> 00:22:45,318
on Graviton,

610
00:22:45,719 --> 00:22:47,920
and they found, uh, a, a stunning 35

611
00:22:47,920 --> 00:22:49,959
to 60% performance increase in

612
00:22:49,959 --> 00:22:51,660
some of the OLTP workloads

613
00:22:51,920 --> 00:22:52,979
that they think are typical

614
00:22:53,400 --> 00:22:55,680
of Hana Cloud, um, development.

615
00:22:57,039 --> 00:22:57,818
So with this,

616
00:22:58,078 --> 00:23:00,160
we have performance that varies with the workloads

617
00:23:00,160 --> 00:23:02,930
we looked at between 27 and 47%

618
00:23:03,279 --> 00:23:04,799
and what customers have told us,

619
00:23:05,118 --> 00:23:07,279
which varies from 20% to nearly

620
00:23:07,279 --> 00:23:08,519
as much as 60%.

621
00:23:09,588 --> 00:23:11,059
So now I'd like to hand it over to Thibo

622
00:23:11,358 --> 00:23:13,459
from Atlassian to talk about his experience

623
00:23:14,078 --> 00:23:14,759
with graviton.

624
00:23:16,719 --> 00:23:22,410
Thank you. Thank

625
00:23:22,410 --> 00:23:24,449
you, Eli. Um, I'm Thibaud Delors,

626
00:23:24,568 --> 00:23:26,880
principal engineer, uh, for Atlassian.

627
00:23:27,368 --> 00:23:29,439
So in Atlassian, my main focus is cost

628
00:23:29,439 --> 00:23:30,189
efficiency.

629
00:23:30,920 --> 00:23:33,000
And we went through the graviton journey,

630
00:23:33,009 --> 00:23:34,068
and I'm here to

631
00:23:34,650 --> 00:23:36,689
explain how we went about it and

632
00:23:36,689 --> 00:23:38,250
what kind of results we saw.

633
00:23:40,029 --> 00:23:42,029
A bit of context of who, what

634
00:23:42,029 --> 00:23:44,108
we are doing in Atlassian. So we have the Atlassian

635
00:23:44,108 --> 00:23:45,009
cloud platform.

636
00:23:45,519 --> 00:23:47,650
You probably know some of our products like

637
00:23:48,029 --> 00:23:50,509
Jira, which is the issue tracker, confluence

638
00:23:50,509 --> 00:23:51,900
for collaboration,

639
00:23:52,430 --> 00:23:54,068
Bitbucket, Trello.

640
00:23:54,390 --> 00:23:56,390
So all those tools are now integrated

641
00:23:56,390 --> 00:23:58,509
in our cloud platform and

642
00:23:59,068 --> 00:24:00,670
powered by our AI Brovo.

643
00:24:02,299 --> 00:24:04,500
And on our platform we have from small

644
00:24:04,500 --> 00:24:06,009
to large customer,

645
00:24:06,588 --> 00:24:09,130
um, like Roblox or

646
00:24:09,269 --> 00:24:10,309
um Amadeus.

647
00:24:11,019 --> 00:24:11,769
Um,

648
00:24:12,088 --> 00:24:14,140
and Reddit, um, and all those

649
00:24:14,140 --> 00:24:14,880
customers,

650
00:24:15,140 --> 00:24:17,219
they are on our platform, like I was saying, and

651
00:24:17,219 --> 00:24:19,118
we are heavily relying on EC2.

652
00:24:19,699 --> 00:24:22,269
So we have tens of thousands of EC2 instances,

653
00:24:22,979 --> 00:24:25,140
3000 services from big

654
00:24:25,140 --> 00:24:25,719
to small.

655
00:24:26,660 --> 00:24:28,559
Across 15 regions

656
00:24:29,059 --> 00:24:31,449
and to support 300,000

657
00:24:31,459 --> 00:24:32,279
customers,

658
00:24:32,779 --> 00:24:33,779
more than that actually,

659
00:24:34,180 --> 00:24:36,219
and we have like a sharded infrastructure, so

660
00:24:36,219 --> 00:24:36,959
that means that

661
00:24:37,219 --> 00:24:39,219
for one given customer we usually

662
00:24:39,219 --> 00:24:39,959
associate them

663
00:24:40,338 --> 00:24:42,598
to a shard in a specific region,

664
00:24:43,358 --> 00:24:44,078
um, and

665
00:24:44,578 --> 00:24:45,500
they have like

666
00:24:46,269 --> 00:24:48,348
They are sharing a shard with other customers,

667
00:24:48,430 --> 00:24:50,660
but we have many, many shards

668
00:24:50,670 --> 00:24:51,689
across the globe.

669
00:24:53,848 --> 00:24:56,170
So, why did we look at graviton?

670
00:24:56,769 --> 00:24:59,459
So, I'm doing cost efficiency.

671
00:24:59,779 --> 00:25:01,959
One of the easiest ways to

672
00:25:02,660 --> 00:25:04,739
do cost efficiency is to look at the

673
00:25:04,739 --> 00:25:06,739
CPU because it can give you the

674
00:25:06,739 --> 00:25:08,818
best price to

675
00:25:08,818 --> 00:25:09,719
performance ratio.

676
00:25:10,059 --> 00:25:12,529
We were looking at all CPU, not just Graviton,

677
00:25:12,818 --> 00:25:14,180
so Intel, AMD,

678
00:25:14,858 --> 00:25:15,459
Graviton,

679
00:25:15,900 --> 00:25:17,900
and we were looking for like the lower

680
00:25:17,900 --> 00:25:20,059
CPU utilization for the same throughput.

681
00:25:20,989 --> 00:25:23,259
And also, uh, Atlassian is committed

682
00:25:23,459 --> 00:25:25,838
as a commitment on the energy footprint.

683
00:25:26,160 --> 00:25:28,219
So we were looking at reducing our

684
00:25:29,160 --> 00:25:29,959
carbon footprint.

685
00:25:33,549 --> 00:25:35,828
We have, um, so here it's like

686
00:25:36,029 --> 00:25:38,269
a bit more specific to our big product,

687
00:25:38,529 --> 00:25:39,660
Jira and Confluence.

688
00:25:39,989 --> 00:25:40,689
We have

689
00:25:41,150 --> 00:25:41,719
3,

690
00:25:42,150 --> 00:25:44,180
the 3 biggest workloads that

691
00:25:44,180 --> 00:25:45,049
we have is

692
00:25:45,309 --> 00:25:46,309
the web servers,

693
00:25:46,789 --> 00:25:47,739
the workers,

694
00:25:48,150 --> 00:25:49,289
and the databases.

695
00:25:49,868 --> 00:25:51,989
On the web server side, it's a

696
00:25:51,989 --> 00:25:53,259
Java 17 app,

697
00:25:53,539 --> 00:25:54,049
pretty big

698
00:25:54,670 --> 00:25:56,500
scale on on CPU

699
00:25:56,789 --> 00:25:57,910
through a scaling group.

700
00:25:58,618 --> 00:26:00,739
And it's very latency sensitive,

701
00:26:01,180 --> 00:26:03,420
so we really care about performances

702
00:26:03,420 --> 00:26:04,719
and we don't like.

703
00:26:05,838 --> 00:26:08,108
Like we, we can't have like performance

704
00:26:08,108 --> 00:26:10,199
degradation from like a CPU upgrade or

705
00:26:10,199 --> 00:26:10,939
something like that.

706
00:26:11,598 --> 00:26:13,640
On the I think you worker side, it's a bit

707
00:26:13,640 --> 00:26:15,809
more flexible as we care more about

708
00:26:15,809 --> 00:26:16,380
throughput,

709
00:26:16,890 --> 00:26:18,959
but it's like the same code base as the

710
00:26:18,959 --> 00:26:21,239
web server, so that means that if we migrate

711
00:26:21,239 --> 00:26:22,880
one, we usually migrate the other.

712
00:26:24,269 --> 00:26:26,549
And its scale on queue length rather

713
00:26:26,549 --> 00:26:28,150
than CPU percentage.

714
00:26:29,029 --> 00:26:30,469
And we have the databases.

715
00:26:30,789 --> 00:26:33,259
We are on Aurora, Progress.

716
00:26:33,549 --> 00:26:35,368
We are using replicas

717
00:26:35,828 --> 00:26:37,650
and usually when

718
00:26:38,029 --> 00:26:39,250
we are only scaling

719
00:26:39,549 --> 00:26:41,989
during like the peak hours, so 9, like

720
00:26:41,989 --> 00:26:44,059
10 hours a day, we would scale

721
00:26:44,059 --> 00:26:46,130
our replica, but the rest of the time

722
00:26:46,828 --> 00:26:48,828
we are at just one replica.

723
00:26:51,160 --> 00:26:53,358
So We have this

724
00:26:53,358 --> 00:26:54,239
motto in

725
00:26:54,719 --> 00:26:56,900
Atlassian which is like if you can make it happen

726
00:26:56,900 --> 00:26:59,180
for Jira, you can make it happen for everything.

727
00:26:59,519 --> 00:27:00,979
So we started with Jira.

728
00:27:01,358 --> 00:27:03,279
Um, and the web server,

729
00:27:03,598 --> 00:27:04,750
so that was really the,

730
00:27:05,039 --> 00:27:07,039
the hard part of like adopting Graviton.

731
00:27:08,670 --> 00:27:10,939
2 years, so that's a journey that

732
00:27:10,939 --> 00:27:12,848
started like 2 years ago

733
00:27:13,269 --> 00:27:14,750
and we had a failed attempt.

734
00:27:15,150 --> 00:27:17,588
What we tried to do was just like migrate

735
00:27:17,588 --> 00:27:19,588
from Intel to Graviton

736
00:27:19,588 --> 00:27:20,449
3

737
00:27:20,709 --> 00:27:22,868
at the time that was the latest, and that

738
00:27:22,868 --> 00:27:24,828
was like beginning to be available.

739
00:27:25,719 --> 00:27:28,239
And we did some tests

740
00:27:28,239 --> 00:27:30,578
in our environment. We migrated

741
00:27:30,578 --> 00:27:31,199
up to arm.

742
00:27:32,029 --> 00:27:33,769
And it was looking good

743
00:27:34,430 --> 00:27:35,588
until we went to prod.

744
00:27:35,949 --> 00:27:37,769
So when we, we went to prod,

745
00:27:38,029 --> 00:27:40,348
like we start, we started to see like regression,

746
00:27:40,469 --> 00:27:42,130
so obviously we missed something

747
00:27:42,390 --> 00:27:43,209
in our test.

748
00:27:43,838 --> 00:27:44,549
And

749
00:27:44,959 --> 00:27:47,118
looking at like all the flame graph and the

750
00:27:47,118 --> 00:27:47,858
performances,

751
00:27:48,199 --> 00:27:51,000
it was like really looking like concurrency

752
00:27:51,000 --> 00:27:53,140
was the problem at the CPU level,

753
00:27:53,799 --> 00:27:55,828
but we didn't know much more than that,

754
00:27:55,838 --> 00:27:57,618
and we were trying to

755
00:27:58,049 --> 00:28:00,318
fix the code to be more performance with graviton,

756
00:28:00,400 --> 00:28:02,598
but like without much success, so we stopped the

757
00:28:02,598 --> 00:28:05,049
project. And like that's basically

758
00:28:05,049 --> 00:28:07,410
like 6 months of like trying to adopt

759
00:28:07,410 --> 00:28:08,479
graviton that

760
00:28:08,848 --> 00:28:10,848
we were like, OK, it doesn't look like

761
00:28:10,848 --> 00:28:12,910
it's working for us, which is weird because

762
00:28:13,209 --> 00:28:15,328
we've heard like all those stories

763
00:28:15,328 --> 00:28:15,910
of like

764
00:28:16,170 --> 00:28:17,368
way it works. So why doesn't it,

765
00:28:17,650 --> 00:28:19,709
why it wasn't working for us was still a

766
00:28:19,709 --> 00:28:21,088
mystery, but we stopped that.

767
00:28:21,828 --> 00:28:22,338
Until

768
00:28:22,799 --> 00:28:23,799
graviton 4.

769
00:28:24,239 --> 00:28:25,739
So for graviton 4.

770
00:28:26,650 --> 00:28:28,890
We were basically saying we shouldn't

771
00:28:28,890 --> 00:28:30,068
repeat the same mistake.

772
00:28:30,529 --> 00:28:32,640
We're going to engage AWS and

773
00:28:32,640 --> 00:28:34,969
some experts to have recommendations on how

774
00:28:34,969 --> 00:28:35,989
should we test

775
00:28:36,529 --> 00:28:38,689
and, and what we should be doing and

776
00:28:38,689 --> 00:28:40,930
making sure that we understand our regression.

777
00:28:42,000 --> 00:28:44,199
So the first thing is no more micro benchmarking.

778
00:28:44,318 --> 00:28:45,348
There's no point in

779
00:28:45,640 --> 00:28:47,640
like just testing uh one endpoint

780
00:28:47,640 --> 00:28:48,368
for latency cause

781
00:28:48,989 --> 00:28:51,160
like what we noticed is that in production, that's

782
00:28:51,160 --> 00:28:53,019
not what you're gonna see.

783
00:28:53,328 --> 00:28:55,059
So like those signals are useless.

784
00:28:55,729 --> 00:28:57,769
No passive benchmarking, which means

785
00:28:57,769 --> 00:28:59,969
that during our test environment

786
00:28:59,969 --> 00:29:01,189
instead of like running our

787
00:29:01,449 --> 00:29:03,489
usual path test suit and looking at

788
00:29:03,489 --> 00:29:04,180
the result,

789
00:29:04,489 --> 00:29:06,689
we we we we will try to

790
00:29:06,689 --> 00:29:07,348
be more

791
00:29:08,009 --> 00:29:10,209
have like an acceptance criteria and like

792
00:29:10,209 --> 00:29:12,250
clear metrics of like whether it's good or

793
00:29:12,250 --> 00:29:14,588
not. And this clear metric was

794
00:29:14,959 --> 00:29:16,539
throughput car braking latency.

795
00:29:16,838 --> 00:29:18,299
So what we did is

796
00:29:19,559 --> 00:29:21,858
Put a like do some load test on,

797
00:29:21,920 --> 00:29:22,920
on the

798
00:29:23,358 --> 00:29:24,368
on the web server,

799
00:29:24,959 --> 00:29:27,039
see where the latency is starting

800
00:29:27,039 --> 00:29:29,039
to become unacceptable and

801
00:29:29,039 --> 00:29:30,930
measure the throughput at this point,

802
00:29:31,279 --> 00:29:33,420
and that would give us like a good idea of like

803
00:29:33,598 --> 00:29:34,959
how performance is the CPU.

804
00:29:35,689 --> 00:29:38,189
And also digging into the low level of

805
00:29:38,449 --> 00:29:39,390
um the,

806
00:29:39,890 --> 00:29:40,779
the processor.

807
00:29:41,289 --> 00:29:43,709
So ARM has um some

808
00:29:43,709 --> 00:29:46,088
performance monitoring units that you can

809
00:29:46,519 --> 00:29:48,269
observe and check

810
00:29:49,368 --> 00:29:51,410
what is um the, the bottleneck on

811
00:29:51,410 --> 00:29:51,969
the CPU.

812
00:29:53,699 --> 00:29:55,959
What we found is graviton 4

813
00:29:56,299 --> 00:29:58,000
basically smashed

814
00:29:58,338 --> 00:29:59,189
all the results.

815
00:29:59,539 --> 00:30:02,019
Like it was more, it was outperforming C6I

816
00:30:02,019 --> 00:30:04,199
which was our preferred previous

817
00:30:04,199 --> 00:30:06,618
instance. And also C7G

818
00:30:06,618 --> 00:30:09,279
by far. And

819
00:30:09,769 --> 00:30:11,969
one of the key indicators of

820
00:30:12,250 --> 00:30:14,250
what was correlating with

821
00:30:14,250 --> 00:30:16,449
performance was L3 cache misses.

822
00:30:17,289 --> 00:30:19,640
Like we saw that the more cache misses there was,

823
00:30:19,969 --> 00:30:22,078
the worse performance is, which makes

824
00:30:22,078 --> 00:30:24,309
sense, but it was like really a good

825
00:30:24,309 --> 00:30:25,309
reflection of

826
00:30:25,809 --> 00:30:26,380
performance,

827
00:30:26,689 --> 00:30:28,269
and that can be explained by

828
00:30:28,608 --> 00:30:30,650
from Graviton 3 to Graviton

829
00:30:30,650 --> 00:30:31,309
4.

830
00:30:31,650 --> 00:30:33,769
It went from 1 megabyte

831
00:30:33,769 --> 00:30:35,459
to 2 megabytes of L2 cash

832
00:30:36,088 --> 00:30:37,088
and

833
00:30:37,519 --> 00:30:39,598
And that was what was making the difference

834
00:30:39,598 --> 00:30:42,009
here and compared to Intel,

835
00:30:42,039 --> 00:30:44,039
that was the same thing like in terms of L2

836
00:30:44,039 --> 00:30:45,118
and L3 cache,

837
00:30:45,479 --> 00:30:47,559
Graviton had more and so

838
00:30:47,559 --> 00:30:49,279
we saw like better performance.

839
00:30:50,098 --> 00:30:52,130
We also see, so, um,

840
00:30:52,979 --> 00:30:54,979
Like the table work, so the translation

841
00:30:54,979 --> 00:30:56,199
lecoside buffer,

842
00:30:56,900 --> 00:30:57,509
uh, tablework

843
00:30:58,299 --> 00:30:59,098
was

844
00:31:00,088 --> 00:31:01,539
reduced on Graviton 4,

845
00:31:01,818 --> 00:31:03,559
which basically means that

846
00:31:03,858 --> 00:31:05,118
it was using like

847
00:31:05,420 --> 00:31:07,118
memory like a bit better,

848
00:31:07,818 --> 00:31:09,588
and that's like really specific to

849
00:31:09,959 --> 00:31:12,219
to Java, and the conclusion

850
00:31:12,219 --> 00:31:14,380
of that is that we should enable

851
00:31:14,380 --> 00:31:16,338
THP, which is transparent

852
00:31:16,618 --> 00:31:17,400
huge pages.

853
00:31:18,239 --> 00:31:19,509
And um

854
00:31:20,000 --> 00:31:21,140
to try to have like

855
00:31:21,680 --> 00:31:23,858
better usage of the memory

856
00:31:24,118 --> 00:31:25,239
with the system.

857
00:31:27,930 --> 00:31:30,088
So the result of that is

858
00:31:30,568 --> 00:31:31,420
on C6I.

859
00:31:32,170 --> 00:31:34,170
So compared to C6I, which was really our

860
00:31:34,170 --> 00:31:35,989
baseline and what we were happy with,

861
00:31:36,769 --> 00:31:39,088
Graviton 4 with THP enabled

862
00:31:39,289 --> 00:31:41,209
was 32% faster.

863
00:31:42,368 --> 00:31:43,189
On the other hand,

864
00:31:43,689 --> 00:31:45,348
uh, graviton 3 was a bit

865
00:31:45,608 --> 00:31:47,650
slower. So what was the

866
00:31:47,650 --> 00:31:48,348
decision here

867
00:31:48,930 --> 00:31:50,189
was that for

868
00:31:50,489 --> 00:31:52,489
web server we would be using

869
00:31:52,489 --> 00:31:53,098
CAG.

870
00:31:53,410 --> 00:31:55,449
We always use also a fallback

871
00:31:55,449 --> 00:31:57,789
stance in case there is no capacity,

872
00:31:58,209 --> 00:32:00,430
and we were, uh, we decided

873
00:32:00,430 --> 00:32:02,549
that that was graviton 4

874
00:32:02,890 --> 00:32:04,059
as the main, um,

875
00:32:04,848 --> 00:32:07,459
main CPU and C6I

876
00:32:07,969 --> 00:32:09,420
as the fallback.

877
00:32:10,118 --> 00:32:10,750
4.

878
00:32:11,509 --> 00:32:12,750
I think workers,

879
00:32:13,068 --> 00:32:15,269
it's a bit more flexible because we were not looking

880
00:32:15,269 --> 00:32:17,309
at latency, we were looking at

881
00:32:17,309 --> 00:32:18,809
throughput and cost efficiency

882
00:32:19,150 --> 00:32:21,269
and in that instance, C7G was

883
00:32:21,269 --> 00:32:23,170
the most cost efficient one.

884
00:32:23,549 --> 00:32:25,118
So what we decided is still,

885
00:32:25,430 --> 00:32:27,430
we're still going to try to go for Graviton

886
00:32:27,430 --> 00:32:28,328
4 for

887
00:32:28,670 --> 00:32:30,689
the workers but fall back to

888
00:32:30,910 --> 00:32:31,930
Graviton 3

889
00:32:32,469 --> 00:32:34,009
instead of Intel for the workers.

890
00:32:37,479 --> 00:32:38,979
How did we roll that out?

891
00:32:39,989 --> 00:32:42,150
So for the web server, when you want

892
00:32:42,150 --> 00:32:43,939
to have Graviton

893
00:32:44,390 --> 00:32:46,529
with Intel as a fallback,

894
00:32:46,828 --> 00:32:48,868
you have to use this pattern, which is

895
00:32:48,868 --> 00:32:51,630
a very well documented pattern on AWS

896
00:32:51,630 --> 00:32:53,890
website, which is to use um

897
00:32:54,029 --> 00:32:56,348
multi-punch, multiple launch templates

898
00:32:56,348 --> 00:32:57,130
on your ASG.

899
00:32:57,549 --> 00:32:59,630
So you basically need two images, one

900
00:32:59,630 --> 00:33:00,250
for ARM,

901
00:33:00,578 --> 00:33:02,670
one for Intel, and then you can have

902
00:33:02,670 --> 00:33:05,108
like a fallback between ARM and Intel.

903
00:33:05,709 --> 00:33:07,789
So that's what we had to implement for web

904
00:33:07,789 --> 00:33:08,430
servers.

905
00:33:09,358 --> 00:33:11,400
Uh, for async workers much simpler.

906
00:33:11,519 --> 00:33:12,880
You usually in a,

907
00:33:13,838 --> 00:33:16,229
in a scaling group you can have, uh, several

908
00:33:16,229 --> 00:33:18,930
fallback instances without having several launch

909
00:33:19,279 --> 00:33:21,279
launch, um, templates. And

910
00:33:21,279 --> 00:33:23,160
so we were falling back to C7G.

911
00:33:24,578 --> 00:33:26,469
Reported all of CICD

912
00:33:26,910 --> 00:33:27,509
to arm.

913
00:33:28,459 --> 00:33:30,170
And we deployed.

914
00:33:31,309 --> 00:33:33,519
And the observed result in

915
00:33:33,519 --> 00:33:34,660
production was

916
00:33:35,000 --> 00:33:37,108
a throughput increase of 30%,

917
00:33:37,519 --> 00:33:39,559
latency reduction of 12%, and

918
00:33:39,559 --> 00:33:41,059
a cost reduction of

919
00:33:41,318 --> 00:33:42,479
25%.

920
00:33:43,390 --> 00:33:45,549
So 25% for

921
00:33:45,549 --> 00:33:47,039
Jira in confluence that's

922
00:33:47,699 --> 00:33:48,559
A lot of money.

923
00:33:51,289 --> 00:33:53,630
So on this success, we decided to

924
00:33:54,368 --> 00:33:56,209
Expand to the rest of Atlassian.

925
00:33:56,489 --> 00:33:59,140
Actually confluence a Gan confluence databases

926
00:33:59,140 --> 00:34:00,588
started like a bit earlier

927
00:34:01,689 --> 00:34:02,269
and

928
00:34:02,689 --> 00:34:04,930
we migrated all our instances to

929
00:34:04,930 --> 00:34:06,509
graviton and it was

930
00:34:07,170 --> 00:34:08,559
very smooth, very easy.

931
00:34:08,849 --> 00:34:10,889
We went from R5 to R6G to

932
00:34:10,889 --> 00:34:12,250
R7G to RIG,

933
00:34:12,688 --> 00:34:14,280
and every time we saw a game,

934
00:34:14,610 --> 00:34:16,688
like especially in R6G, which

935
00:34:16,688 --> 00:34:17,769
was like the first,

936
00:34:18,168 --> 00:34:19,148
the first.

937
00:34:20,228 --> 00:34:21,458
The first graviton option,

938
00:34:22,800 --> 00:34:24,800
um, like we saw like a big

939
00:34:24,800 --> 00:34:25,659
cost reduction,

940
00:34:26,079 --> 00:34:28,179
and then every time we saw better performance.

941
00:34:29,519 --> 00:34:30,090
So

942
00:34:31,518 --> 00:34:33,528
We have more than 3000 database

943
00:34:33,528 --> 00:34:35,309
clusters in production.

944
00:34:35,648 --> 00:34:38,489
They also went through PG 13

945
00:34:38,489 --> 00:34:40,608
and PG 17, and every time we were

946
00:34:40,608 --> 00:34:43,208
doing those upgrades, we were always comparing

947
00:34:43,208 --> 00:34:45,289
like whether Graviton was still the

948
00:34:45,289 --> 00:34:47,427
best option, and every time

949
00:34:47,427 --> 00:34:48,809
it was the best option.

950
00:34:51,000 --> 00:34:51,860
I want to

951
00:34:52,159 --> 00:34:54,659
highlight that cost efficiency depends on

952
00:34:55,500 --> 00:34:56,260
how, like

953
00:34:56,719 --> 00:34:58,918
how you deploy your app. Like in Atlassian

954
00:34:58,918 --> 00:35:00,099
we are pretty efficient

955
00:35:00,360 --> 00:35:02,958
in terms of like we know when to downgrade, downsize

956
00:35:02,958 --> 00:35:03,780
the database.

957
00:35:04,159 --> 00:35:06,409
We know how to use red replica,

958
00:35:06,719 --> 00:35:08,760
and that's why we are seeing like really

959
00:35:08,760 --> 00:35:10,878
good cost savings is because we are

960
00:35:10,878 --> 00:35:11,628
doing the thing.

961
00:35:11,918 --> 00:35:13,539
If you are just

962
00:35:13,958 --> 00:35:14,918
switching from

963
00:35:15,829 --> 00:35:18,070
Some, from one instance to another

964
00:35:18,070 --> 00:35:19,179
instance, but we don't,

965
00:35:19,550 --> 00:35:21,668
you don't um do anything out

966
00:35:21,668 --> 00:35:22,260
of that.

967
00:35:22,590 --> 00:35:23,329
You don't change

968
00:35:23,840 --> 00:35:26,458
your replica strategy or you don't downsize,

969
00:35:26,909 --> 00:35:29,320
then you might, you might not see cost, cost benefit,

970
00:35:29,469 --> 00:35:31,510
so. You have to

971
00:35:31,510 --> 00:35:33,599
be efficient to make those cost savings.

972
00:35:35,260 --> 00:35:37,500
We also migrated Jira, so

973
00:35:37,500 --> 00:35:38,599
Jira, as I was saying,

974
00:35:38,949 --> 00:35:39,849
JSM,

975
00:35:40,378 --> 00:35:42,780
Confluence, and several other

976
00:35:42,780 --> 00:35:43,918
products are following,

977
00:35:44,769 --> 00:35:45,918
um, including our Edge,

978
00:35:46,179 --> 00:35:48,599
and roughly in one year we went from

979
00:35:48,739 --> 00:35:50,860
5% adoption of graviton within

980
00:35:50,860 --> 00:35:53,188
Atlassian to more than 30%,

981
00:35:53,539 --> 00:35:54,070
and

982
00:35:54,699 --> 00:35:55,719
also I'm saving out of that.

983
00:35:58,070 --> 00:36:00,228
Thanks to a collaboration with AWS

984
00:36:00,228 --> 00:36:02,570
we were able to test Graviton 5,

985
00:36:03,110 --> 00:36:03,809
and it's

986
00:36:04,228 --> 00:36:05,289
very promising.

987
00:36:05,750 --> 00:36:06,289
Um,

988
00:36:06,719 --> 00:36:07,269
and

989
00:36:07,750 --> 00:36:10,010
what, what we believe is the reason for such

990
00:36:10,309 --> 00:36:12,510
an improvement, so the 30% throughput

991
00:36:12,510 --> 00:36:14,570
improvement is as I was saying before,

992
00:36:15,110 --> 00:36:17,110
L3 cache is very

993
00:36:17,110 --> 00:36:19,228
related to our performance because we are a

994
00:36:19,228 --> 00:36:20,409
Java shop pretty much.

995
00:36:20,909 --> 00:36:22,119
And, um,

996
00:36:22,590 --> 00:36:24,329
and Graviton 5 like

997
00:36:24,668 --> 00:36:26,708
um increase the the L3 cache,

998
00:36:26,750 --> 00:36:27,289
so.

999
00:36:28,000 --> 00:36:30,050
Not so surprising, but really good

1000
00:36:30,050 --> 00:36:31,179
news for us, and

1001
00:36:31,559 --> 00:36:33,199
we are super, super excited too.

1002
00:36:34,300 --> 00:36:36,829
Try a graviton 5 in production.

1003
00:36:37,429 --> 00:36:38,208
Thank you very much.

1004
00:36:44,849 --> 00:36:47,179
Great. Thank you, Thibo for uh

1005
00:36:47,179 --> 00:36:48,260
for those great insights.

1006
00:36:49,269 --> 00:36:51,590
So let's uh shift gears now into talking

1007
00:36:51,590 --> 00:36:53,628
about some of the best practices for transitioning

1008
00:36:53,628 --> 00:36:55,378
to graviton and uh

1009
00:36:55,708 --> 00:36:57,510
what are some of the tools available to do that.

1010
00:36:59,849 --> 00:37:01,349
So starting with the building blocks.

1011
00:37:02,369 --> 00:37:04,369
Across the Linux community there's

1012
00:37:04,369 --> 00:37:06,369
broad support for ARM 64 out of the

1013
00:37:06,369 --> 00:37:07,208
box. So

1014
00:37:07,489 --> 00:37:09,539
whether you're using commercial distributions

1015
00:37:09,809 --> 00:37:11,349
or using community armies,

1016
00:37:11,929 --> 00:37:13,929
you can find AM 64 out of

1017
00:37:13,929 --> 00:37:16,039
the box Amazon machine images that's

1018
00:37:16,039 --> 00:37:17,128
available for you to deploy.

1019
00:37:19,599 --> 00:37:21,639
Using containerized workloads, there's also a lot

1020
00:37:21,639 --> 00:37:23,050
of good news in that space.

1021
00:37:23,599 --> 00:37:25,739
There's broad support for Gravidon across

1022
00:37:25,958 --> 00:37:27,469
all the key container areas,

1023
00:37:28,030 --> 00:37:30,159
so that includes Docker and Kubernetes

1024
00:37:30,159 --> 00:37:32,320
themselves, as well as our own AWS managed

1025
00:37:32,320 --> 00:37:33,128
services

1026
00:37:33,559 --> 00:37:34,978
such as ECS and EKS.

1027
00:37:36,438 --> 00:37:38,510
There's also support across multiple container

1028
00:37:38,510 --> 00:37:39,219
registries

1029
00:37:39,918 --> 00:37:42,478
um for ARM 64 in addition to multi architecture

1030
00:37:42,478 --> 00:37:45,000
support, so you can build container images

1031
00:37:45,000 --> 00:37:47,199
for X86 and ARM 64

1032
00:37:47,199 --> 00:37:49,458
and have the right image deployed automatically

1033
00:37:49,918 --> 00:37:51,239
based on the underlying architecture.

1034
00:37:54,590 --> 00:37:56,639
And a similar story across the DevOps landscape,

1035
00:37:56,789 --> 00:37:58,789
so all the popular CICD tools and

1036
00:37:58,789 --> 00:37:59,449
software

1037
00:37:59,789 --> 00:38:01,539
include support for Graviton out of the box.

1038
00:38:01,869 --> 00:38:04,418
So that's whether it's fully managed, self-managed,

1039
00:38:04,708 --> 00:38:05,989
or hybrid deployments.

1040
00:38:09,728 --> 00:38:12,110
So in terms of partners, so we find a lot of customers

1041
00:38:12,110 --> 00:38:14,168
use third party software for various

1042
00:38:14,168 --> 00:38:17,000
needs, be it logging software, monitoring,

1043
00:38:17,438 --> 00:38:18,679
security, and things like that.

1044
00:38:19,208 --> 00:38:21,289
So what we've done is that we've created over the

1045
00:38:21,289 --> 00:38:23,449
last few years a Graviton

1046
00:38:23,449 --> 00:38:24,500
partner program

1047
00:38:24,889 --> 00:38:27,128
where we worked with many of these third party ISPs

1048
00:38:27,128 --> 00:38:28,599
to enable support on Graviton,

1049
00:38:29,050 --> 00:38:31,148
and a lot of the software companies here have

1050
00:38:31,349 --> 00:38:33,728
tested, validated, and optimized their software.

1051
00:38:34,090 --> 00:38:36,208
Which then makes it really easy for customers to

1052
00:38:36,208 --> 00:38:37,019
discover these.

1053
00:38:37,340 --> 00:38:38,659
So here's a snapshot

1054
00:38:38,978 --> 00:38:40,438
of what we currently offer,

1055
00:38:40,898 --> 00:38:43,090
and since this list is rapidly changing, we

1056
00:38:43,090 --> 00:38:44,559
highly recommend you check the

1057
00:38:44,898 --> 00:38:46,750
Graviton web page for the latest and greatest.

1058
00:38:53,389 --> 00:38:55,898
So while you can obviously deploy your workloads

1059
00:38:55,898 --> 00:38:58,188
on graviton-based instances on EC 2,

1060
00:38:58,909 --> 00:39:01,070
We've also extended the price performance

1061
00:39:01,070 --> 00:39:03,110
benefits of Graviton to our various AWS

1062
00:39:03,110 --> 00:39:04,070
managed services.

1063
00:39:05,010 --> 00:39:07,250
So this gives you the most seamless path

1064
00:39:07,250 --> 00:39:08,398
to using graviton,

1065
00:39:08,809 --> 00:39:10,969
and in many cases it's simply an instance name

1066
00:39:10,969 --> 00:39:12,429
switch, and you're up and running,

1067
00:39:12,849 --> 00:39:14,849
and a lot of the heavy lifting of the architecture is

1068
00:39:14,849 --> 00:39:15,929
handled for you under the hood.

1069
00:39:16,760 --> 00:39:19,260
So all the popular services across compute,

1070
00:39:19,840 --> 00:39:21,699
databases, analytics,

1071
00:39:21,958 --> 00:39:23,260
as well as machine learning

1072
00:39:23,639 --> 00:39:25,260
support graviton-based instances today.

1073
00:39:30,280 --> 00:39:32,360
Now this is a very common question that we deal with

1074
00:39:32,360 --> 00:39:34,659
in a lot of customer conversations, which is around

1075
00:39:35,039 --> 00:39:37,579
what is the effort involved in moving to gravidon

1076
00:39:37,958 --> 00:39:39,320
and how should we think about that?

1077
00:39:40,570 --> 00:39:42,989
So here is a basic framework that we provided

1078
00:39:42,989 --> 00:39:44,728
as a starting point, um,

1079
00:39:45,050 --> 00:39:45,829
and as I said,

1080
00:39:46,329 --> 00:39:48,329
the most seamless way is gonna be to use a managed

1081
00:39:48,329 --> 00:39:50,478
service. If you're

1082
00:39:50,478 --> 00:39:52,898
using applications

1083
00:39:53,360 --> 00:39:55,639
that are, you know, interpreted languages, say

1084
00:39:55,639 --> 00:39:58,219
Java or No JS, PHP, Ruby,

1085
00:39:58,628 --> 00:40:00,679
all of those pretty seamlessly work out of the

1086
00:40:00,679 --> 00:40:01,219
box,

1087
00:40:01,800 --> 00:40:03,800
and in many cases we have many customers who

1088
00:40:03,800 --> 00:40:06,199
have moved that to AM 64 and gravit on very easily.

1089
00:40:08,090 --> 00:40:10,648
If you're using compiled languages like C, C++,

1090
00:40:10,728 --> 00:40:12,938
Golang, those applications

1091
00:40:12,938 --> 00:40:14,148
would need to be recompiled

1092
00:40:14,688 --> 00:40:15,688
for the ARM architecture.

1093
00:40:16,398 --> 00:40:18,559
But the good news here is that all the major

1094
00:40:18,559 --> 00:40:20,639
popular compilers will allow you to do that

1095
00:40:20,639 --> 00:40:21,668
really, really easily,

1096
00:40:21,958 --> 00:40:24,010
and we have many success stories of customers that

1097
00:40:24,010 --> 00:40:25,260
have moved these applications.

1098
00:40:26,570 --> 00:40:28,728
And finally, in the sum work high reward category

1099
00:40:28,728 --> 00:40:30,639
comes around applications such as .NET,

1100
00:40:31,090 --> 00:40:33,128
which you can modernize to Linux and

1101
00:40:33,128 --> 00:40:34,789
then that puts you on an accelerated path

1102
00:40:35,050 --> 00:40:36,969
to getting to AM 64 and Graviton as well.

1103
00:40:43,559 --> 00:40:45,719
So some more steps in terms of how you can start

1104
00:40:45,719 --> 00:40:46,889
thinking about this journey.

1105
00:40:47,320 --> 00:40:49,398
So the first and foremost area that I would highly

1106
00:40:49,398 --> 00:40:50,938
recommend is getting started with our

1107
00:40:51,309 --> 00:40:52,780
technical guide on GitHub.

1108
00:40:53,438 --> 00:40:55,989
So this really provides a lot of good

1109
00:40:56,000 --> 00:40:57,500
examples and use cases

1110
00:40:57,789 --> 00:41:00,019
broken down by applications and languages

1111
00:41:00,280 --> 00:41:02,519
that allows you to get the best out of the Graviton

1112
00:41:02,519 --> 00:41:04,898
platform and the tunings for these applications.

1113
00:41:06,760 --> 00:41:09,000
And secondly, you know, inventory of your software

1114
00:41:09,000 --> 00:41:11,119
stacks, so really understanding what OS images

1115
00:41:11,119 --> 00:41:12,780
you're using as a general rule,

1116
00:41:13,280 --> 00:41:15,280
the more current your software, the easier it

1117
00:41:15,280 --> 00:41:16,918
is to get adopting on Graviton.

1118
00:41:17,780 --> 00:41:19,978
And taking a look at those container images and

1119
00:41:19,978 --> 00:41:22,050
understanding dependencies and pulling the right

1120
00:41:22,050 --> 00:41:22,639
armies.

1121
00:41:25,329 --> 00:41:27,409
Unit and functional tests as part of your testing

1122
00:41:27,409 --> 00:41:29,449
efforts are going to be important and in some cases you might

1123
00:41:29,449 --> 00:41:31,489
have to write new tests like Atlassian

1124
00:41:31,489 --> 00:41:32,260
just described,

1125
00:41:32,648 --> 00:41:34,648
and we have a lot of tools over here that can actually help

1126
00:41:34,648 --> 00:41:35,708
you do that. So

1127
00:41:35,969 --> 00:41:37,228
that includes Q Developer,

1128
00:41:37,679 --> 00:41:39,728
AWS Transform, as well as a

1129
00:41:39,728 --> 00:41:41,889
new tool that we just announced earlier this

1130
00:41:41,889 --> 00:41:44,208
week which is AWS Transform Custom.

1131
00:41:47,030 --> 00:41:49,228
And finally, measuring performance, and again we have

1132
00:41:49,228 --> 00:41:51,398
uh some QR codes there, we have a tool called

1133
00:41:51,398 --> 00:41:53,429
APERF that's available for

1134
00:41:53,429 --> 00:41:55,829
you to profile some of your applications and really

1135
00:41:55,829 --> 00:41:57,070
understand where the bottlenecks are.

1136
00:41:57,840 --> 00:41:59,938
And we see a lot of customers deploy

1137
00:41:59,938 --> 00:42:01,139
on Graviton using

1138
00:42:01,599 --> 00:42:03,579
canary or blue-green deployments

1139
00:42:03,938 --> 00:42:06,000
where once you have a production traffic and you

1140
00:42:06,000 --> 00:42:07,030
have both clusters,

1141
00:42:07,360 --> 00:42:09,559
you start redirecting a small portion of that traffic

1142
00:42:09,559 --> 00:42:11,878
to an armed production cluster on Graviton,

1143
00:42:11,918 --> 00:42:14,000
and then you can turn the knob based on the

1144
00:42:14,000 --> 00:42:14,918
performance that you observe.

1145
00:42:15,550 --> 00:42:20,269
Why So

1146
00:42:20,269 --> 00:42:22,550
just talking more about the transform custom

1147
00:42:22,550 --> 00:42:24,369
that we just announced earlier in the week,

1148
00:42:24,909 --> 00:42:26,128
so this is a capability

1149
00:42:26,469 --> 00:42:27,090
where

1150
00:42:27,628 --> 00:42:29,989
through the modern agentic AI agent

1151
00:42:29,989 --> 00:42:32,030
applications, it really allows you to crush

1152
00:42:32,030 --> 00:42:32,750
your tech debt.

1153
00:42:33,449 --> 00:42:35,489
And specifically in the case of Graviton there's an

1154
00:42:35,489 --> 00:42:36,510
early access

1155
00:42:36,969 --> 00:42:38,110
program available here

1156
00:42:38,489 --> 00:42:40,688
for for example on Java applications

1157
00:42:40,688 --> 00:42:42,869
where in most cases though it works out of the box

1158
00:42:43,208 --> 00:42:45,188
if you're not sure about the versions

1159
00:42:45,570 --> 00:42:46,269
or

1160
00:42:46,648 --> 00:42:48,929
you need you have some native applications

1161
00:42:48,929 --> 00:42:51,188
coded there that are dependent on a certain language,

1162
00:42:51,489 --> 00:42:53,708
then this gives you a chance to identify

1163
00:42:53,760 --> 00:42:55,128
and modernize those very quickly.

1164
00:42:59,079 --> 00:43:01,119
So NetNet, here's the takeaway of all

1165
00:43:01,119 --> 00:43:02,760
the resources that are available.

1166
00:43:03,320 --> 00:43:05,389
So the first and foremost one that I would highly encourage

1167
00:43:05,389 --> 00:43:07,679
and recommend bookmarking is the Graviton Technical guide.

1168
00:43:08,938 --> 00:43:10,989
And then we also offer a free trial with

1169
00:43:10,989 --> 00:43:13,898
the T4G instances that gives you up to 750

1170
00:43:13,898 --> 00:43:14,530
hours

1171
00:43:15,030 --> 00:43:16,550
to jumpstart your graviton journey.

1172
00:43:17,659 --> 00:43:19,739
And then we have the links to both

1173
00:43:19,739 --> 00:43:22,280
the Que developer and the transform capabilities.

1174
00:43:22,898 --> 00:43:25,059
And finally, there's the graviton savings dashboard

1175
00:43:25,059 --> 00:43:26,878
that helps you to provide a view of

1176
00:43:27,260 --> 00:43:28,989
the savings that you can accrue

1177
00:43:29,289 --> 00:43:30,978
based on your workloads that have moved to Graviton.

1178
00:43:33,929 --> 00:43:35,969
that So here's

1179
00:43:35,969 --> 00:43:37,978
a link if you wanna try out Grabbidon 5

1180
00:43:37,978 --> 00:43:40,478
and MGG since that's currently in preview,

1181
00:43:40,889 --> 00:43:42,070
we really encourage you to sign up.

1182
00:43:42,909 --> 00:43:44,949
And um we really hope many

1183
00:43:44,949 --> 00:43:47,148
of you will get started on your graviton journey, if not

1184
00:43:47,148 --> 00:43:49,429
already, and it's really surprising

1185
00:43:49,429 --> 00:43:51,949
what customers have been able to do with just one

1186
00:43:51,949 --> 00:43:52,648
engineer

1187
00:43:53,010 --> 00:43:54,570
in one week and with one application.

1188
00:43:56,070 --> 00:43:58,188
So with that, I just wanna thank you for your time, making

1189
00:43:58,188 --> 00:44:00,228
time to attend the session today. We really appreciate

1190
00:44:00,228 --> 00:44:02,309
it and hope you continue to have a

1191
00:44:02,309 --> 00:44:03,188
great reinvent

1192
00:44:03,510 --> 00:44:05,769
and please do take a moment to complete the

1193
00:44:05,949 --> 00:44:07,309
session survey in the mobile app.

1194
00:44:07,619 --> 00:44:07,989
Thank you.

