# AWS re:Invent 2025 工业制造会议总结

## 会议概述

本次会议（IND369）由AWS高级解决方案架构师Mural Davsari和TE Connectivity新加坡AI中心的高级软件开发经理Girish共同主讲，重点介绍了TE Connectivity如何利用代理式AI（Agentic AI）转型产品工程流程。TE Connectivity是一家领先的连接解决方案和传感器设计制造公司，拥有约100家工厂、9万名员工和1.1万名工程人员，每年在研发工程上投资7.4亿美元。

会议展示了TE Connectivity开发的内部AI平台"TellMe"的成功案例。该平台从最初计划服务8000名产品工程师，最终扩展到为全公司40000名用户提供服务，实现了99.99%的正常运行时间。最令人瞩目的是，该平台能够智能访问超过1000万条记录和50多个数据源，同时保持企业级安全性、低延迟响应（平均6秒内返回首个令牌），以及极低的每用户每月成本（不到1美元）。这在制造业AI领域是一个突破性成就，因为行业数据显示73%的企业制造AI项目无法投入生产。

TellMe平台的核心创新包括：对2D工程图纸的理解准确率超过90%（行业标准仅为40-50%）、工程部门75%的高采用率、知识图谱与生成式AI的集成、基于角色的访问控制系统，以及允许40000名用户创建和共享自己的AI代理而无需额外许可费用的能力。该平台不仅加速了产品设计和工程周期，还有效保留了退休员工的专业知识，为制造业AI的未来树立了新标杆。

## 详细时间线与关键要点

### 开场介绍（0:00-3:30）
- **0:00** - 会议开始，Mural Davsari介绍自己是AWS高级解决方案架构师
- **0:30** - 介绍会议主题：TE Connectivity如何通过代理式AI转型产品工程
- **1:00** - 强调TE Connectivity的愿景：为40000名员工提供AI平台，智能访问1000万+记录和50+数据源
- **1:30** - 提出核心挑战：同时实现企业级安全、低延迟响应和最低成本比
- **2:00** - 介绍会议议程：制造业AI现状、TE转型历程、TellMe演示、经验教训

### 制造业AI挑战（3:30-8:00）
- **3:30** - 阐述制造业面临的三大数据挑战：数量、访问和复杂性
- **4:00** - 制造商每年生成数千PB数据，技术文档分散在各个系统中
- **4:30** - 大多数数字化仍然是手动的，成本高且耗时
- **5:00** - 工程图纸、技术示意图和制造规范的复杂性是传统AI无法理解的
- **5:30** - 知识被困在非结构化内容中，传统系统无法理解
- **6:00** - 工程师花费大量时间寻找信息，经验丰富的员工退休带走关键知识
- **6:30** - 企业安全要求使关键信息在最需要时无法访问
- **7:00** - 揭示严峻现实：73%的生成式AI项目从未投入生产
- **7:30** - 在制造业情况更糟，标准GPT解决方案无法理解CAD图纸和2D工程图

### TE Connectivity的成功指标（8:00-11:00）
- **8:00** - 展示突破性成果：跨数百万文档实现15秒以下响应时间
- **8:30** - 工程师可以查询1000万+技术记录并快速获得准确响应
- **9:00** - 工程部门采用率超过75%，是行业基准的两倍以上
- **9:30** - 加速产品设计和工程周期，工程师可即时访问数十年数据
- **10:00** - 解决退休员工知识流失问题，保留专业知识
- **10:30** - 在40000用户规模下实现极低的每用户每月成本（远低于10-20美元的行业基准）

### 架构解决方案（11:00-15:00）
- **11:00** - 介绍AWS与TE的合作：AWS提供工具和AI/ML技术，TE提供行业经验和数据访问
- **11:30** - 从零开始构建现代工业数据策略，重新思考数据流、索引和AI访问
- **12:00** - 技术挑战：同时服务数千活跃用户，保持亚毫秒级延迟和高正常运行时间
- **12:30** - 使用Amazon Bedrock处理AI需求，Amazon OpenSearch实现跨1000万文档的快速向量搜索
- **13:00** - 采用分阶段方法，每个阶段都有可衡量的成果、计划发布和成功标准
- **13:30** - 突破性成就：2D模型理解准确率超过90%，而行业标准仅为40-50%
- **14:00** - 在生成式AI中集成知识图谱，理解文档之间的关系
- **14:30** - 构建复杂的基于角色的访问系统，确保用户只能看到授权内容

### TE Connectivity公司背景（15:00-17:00）
- **15:00** - Girish介绍自己：TE Connectivity新加坡AI中心高级软件开发经理
- **15:30** - TE Connectivity概况：约100家工厂、9万名员工、1.1万名工程人员
- **16:00** - 研发工程投资：7.4亿美元
- **16:30** - AI团队规模：7人（5人在新加坡，2人在印度）

### TellMe开发历程（17:00-23:00）
- **17:00** - 项目起源：召集100多位专家、主题专家、AI爱好者和领域专家
- **17:30** - 核心问题：为什么需要另一个生成式AI工具，而不是现成解决方案？
- **18:00** - 收集想法：未来2-3年生成式AI在各领域的应用
- **18:30** - 第一年目标：构建问答工具，让40000名员工提问并获得答案
- **19:00** - 发展路线：数据收集→洞察生成→工作流程生成→自动化
- **19:30** - 意外发现：生成式AI综合多个分散系统数据的能力超出预期
- **20:00** - 2025年成果：向8000人推出，获得巨大热情
- **20:30** - 下一阶段目标：执行特定功能角色（设计审查、故障模式分析、质量审计）
- **21:00** - 目标：自动化功能内任务，基于可用信息创建和生成工程内容
- **21:30** - 融合内部数据与大型语言模型的外部知识
- **22:00** - 2025年9月推出代理式平台，实现所有目标
- **22:30** - 未来愿景：完全自动化端到端任务（70-80%的角色功能）、生成式产品设计、代理网格

### TellMe核心能力（23:00-28:00）
- **23:00** - 最大认可：用户反馈"TellMe产生了影响"
- **23:30** - 销售和客户服务团队：不再需要花费大量时间与工程和产品营销沟通
- **24:00** - 所有产品目录、数据表、设计说明和技术信息都输入TellMe并持续更新
- **24:30** - 原本需要一周以上的信息收集现在不再需要
- **25:00** - 核心能力：单文件上传、多文件上传（每次最多20个文件）
- **25:30** - 访问约1000万条内部结构化和非结构化记录
- **26:00** - 外部模式：直接调用大型语言模型
- **26:30** - AI代理：40000名用户可以创建自己的GPT和代理，无需许可费用
- **27:00** - 用户创造力超出想象，构建和共享自己的代理
- **27:30** - 游戏化提示教学助手：帮助用户从Google搜索时代转向生成式AI时代

### 技术实现细节（28:00-35:00）
- **28:00** - 提示挑战：用户仍处于Google搜索思维（输入一个词期待答案）
- **28:30** - 游戏化解决方案：用户选择角色和技能水平，回答多选题获得积分
- **29:00** - 系统提供解释和提示原则建议，月末发布获胜者
- **29:30** - SharePoint集成：确保代理和用户具有正确的访问权限
- **30:00** - 性能指标：99.9%可用性，从未宕机（除升级外）
- **30:30** - 全球首个令牌时间：15秒，通常约6秒
- **31:00** - 跨1000万条记录搜索并在6秒内响应用户
- **31:30** - 每个查询分解为20-30个并行OpenSearch调用
- **32:00** - OpenSearch响应时间：1-2秒内完成所有并行调用
- **32:30** - 不使用重新排序器，OpenSearch开箱即用的准确性极高
- **33:00** - 架构左侧：安全（Azure AD单点登录、基于角色的访问控制）
- **33:30** - 用户登录后系统识别安全角色（1级、2级或3级用户）
- **34:00** - 1级用户只能看到1级文档的响应，系统会告知有30个文档但无权访问
- **34:30** - 架构右侧：数据管道（数百万文档，自动检查更新和删除）

### 技术栈与优化（35:00-42:00）
- **35:00** - 核心技术：OpenSearch向量数据、Aurora DB（日志和管道管理）
- **35:30** - Redis向量存储：用于会话中动态上传的20个文件
- **36:00** - Bedrock API标准化：一个词即可切换模型（Amazon Nova、GPT、Claude等）
- **36:30** - Amazon Titan用于嵌入
- **37:00** - Redis流式传输：重大突破，使用WebSocket而非Lambda函数
- **37:30** - Redis流式传输可同时服务100+并发用户，无任何故障
- **38:00** - 其他技术：EC2、ECS、API网关、S3、Lambda、Control-M
- **38:30** - 早期挑战：从150人扩展到8000人，仅14周交付
- **39:00** - 令牌限制挑战：每分钟仅100万令牌，需支持100+并发用户
- **39:30** - 与AWS和Anthropic合作扩展限制
- **40:00** - 用户统计：40000名用户访问权限，每周7000-8000活跃用户
- **40:30** - 每日800+活跃用户，每月10000+文件上传
- **41:00** - 用户留存率：月度60-80%（80%的上月用户会在下月登录）
- **41:30** - 工程部门采用率：74%

### TellMe界面与功能（42:00-48:00）
- **42:00** - 展示TellMe界面：提示库、标准提示建议
- **42:30** - 内部数据与静态LLM知识融合
- **43:00** - 每次对话结束时，TellMe引导用户查看外部内容
- **43:30** - TellMe 3.0功能：1000万条记录和文档索引
- **44:00** - 40000名用户、文件处理、多文件上传能力
- **44:30** - 每月10000次文件上传且持续增长
- **45:00** - 内部模式和外部模式融合
- **45:30** - 安全优先：基于角色的访问控制是企业级生成式AI的关键
- **46:00** - 读取工程文档和工程图纸：构建自己的高级模型
- **46:30** - 传统LLM对2D图纸的准确率不足30%
- **47:00** - TE自建模型：复杂图纸准确率70-80%，普通图纸90-95%
- **47:30** - 重大转型：AI能像读取PDF一样读取设计图纸

### 代理开发与GPT功能（48:00-52:00）
- **48:00** - 代理开发：用户可构建自己的GPT或代理并与他人共享
- **48:30** - 民主化：将权力赋予40000名用户
- **49:00** - GPT界面：GPT名称、代理遵循的指令（200-300页指令）
- **49:30** - 工具选择：网络搜索、内部搜索、外部搜索、自动文件生成
- **50:00** - 智能文档分析器：解决20个文件时的上下文限制问题
- **50:30** - 多重检索提高20-30个文件时的准确性
- **51:00** - 上月推出，用户创造性地构建和共享代理
- **51:30** - 无法想象带来的生产力提升

### 关键成果与成本优化（52:00-58:00）
- **52:00** - 核心成果：40000名用户以最低成本体验生成式AI
- **52:30** - 每人每月成本不到1美元，这是重大成就
- **53:00** - 揭示商业工具的真实价格
- **53:30** - 成本优化历程：最初1000万条记录、4000万向量索引的成本很高
- **54:00** - 与AWS合作6个月，将成本降至原来的1/10
- **54:30** - 原成本约5万美元，大幅降低至1/10
- **55:00** - 优化方法：嵌入减少、使用非HA基础设施、信息打包
- **55:30** - 分块策略优化：Titan嵌入支持30000个字符
- **56:00** - 发现每个向量嵌入仅包含10-15个词，网上的分块策略不是最优的
- **56:30** - 真正的优化来自工程优化，与Amazon密切合作
- **57:00** - 原始策略：80个词占用多个向量嵌入，效率低下
- **57:30** - 优化后：显著提高向量嵌入的信息密度

### 总结与未来展望（58:00-结束）
- **58:00** - 强调与AWS合作的重要性
- **58:30** - TellMe平台的成功证明了制造业AI的可行性
- **59:00** - 未来计划：继续扩展代理能力，实现更多自动化
- **59:30** - 会议结束，开放问答环节