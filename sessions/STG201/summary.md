# AWS re:Invent 2025 存储与AI工作流会议总结

## 会议概述

本次会议由Amazon S3高级技术产品经理Monica Vyavahare和Amazon FSx首席产品经理Jordan Dolman主讲，重点探讨了客户如何使用AWS存储服务构建和扩展新的AI用例。会议强调了数据在AI应用中的核心作用，展示了从简单的提示工程到复杂的AI代理工作流的完整技术栈。

演讲者详细介绍了多种AI实现方法，包括提示工程、检索增强生成(RAG)、向量存储、元数据过滤和AI代理等技术。会议特别突出了AWS新推出的S3 Vectors服务，该服务可将向量存储和查询成本降低90%。此外，还深入讨论了模型微调、蒸馏、对齐等高级技术，以及用于大规模模型训练的存储解决方案。

## 详细时间线与关键要点

### 00:00-10:00 会议开场与核心挑战
- Monica介绍会议主题：AWS存储在AI用例中的应用
- 强调数据是AI成功的关键，通用AI只能给出通用答案
- 提出核心挑战：如何让现有的大语言模型基于企业数据做出响应
- 介绍不同方法在成本、时间、复杂性和输出质量方面的权衡

### 10:00-20:00 提示工程与RAG技术
- 详细解释提示工程：通过示例、上下文和约束指导LLM响应
- Monica分享个人使用提示工程改进PRFAQ文档写作的实例
- 介绍RAG(检索增强生成)作为可扩展解决方案
- 解释向量化过程：将数据转换为数值表示以捕获语义含义
- 讨论批量摄取和实时摄取两种数据获取方式

### 20:00-30:00 S3 Vectors服务发布
- 宣布Amazon S3 Vectors正式发布，首个支持原生向量存储和查询的云对象存储
- 强调成本优势：向量上传、存储和查询成本降低90%
- 技术规格：100毫秒热查询延迟，亚秒级冷查询延迟
- 容量规格：每个索引最多20亿个向量，每个存储桶最多10,000个索引
- 介绍按使用付费的定价模型：摄取、存储、查询三个独立计费组件

### 30:00-40:00 客户案例与元数据过滤
- 分享生物技术公司使用S3 Vectors进行科学文献语义搜索的案例
- 该公司处理3000万篇科学论文，研究时间从数周缩短至几分钟
- 介绍元数据过滤技术，通过缩小搜索范围提高查询速度和准确性
- 解释元数据的三个关键作用：上下文、血缘关系、分类
- 讨论S3元数据服务，支持结构化和非结构化数据的元数据生成和搜索

### 40:00-50:00 AI代理与MCP协议
- 从RAG升级到AI代理，处理复杂的多步骤任务
- 介绍模型上下文协议(MCP)作为工具连接标准
- 解释MCP客户端和服务器的工作原理
- 展示AWS为各种服务构建的MCP服务器
- 演示如何使用自然语言查询知识库和S3表格

### 50:00-54:30 高级模型训练技术
- Jordan接手讲解更高级的工作负载
- 介绍监督微调、蒸馏、对齐三种标记数据技术
- 解释持续预训练和从头训练模型的场景
- 讨论大规模模型训练的存储性能要求
- 介绍Amazon FSx文件系统家族：OpenZFS和Lustre
- 展示FSx智能分层和S3集成功能
- 介绍S3 Express One Zone的低延迟优化
- 分享Meta使用S3 Express达到140 Tbps吞吐量的案例