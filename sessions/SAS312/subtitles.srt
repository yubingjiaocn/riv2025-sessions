1
00:00:01,048 --> 00:00:03,169
Good morning everybody. Thanks for joining our

2
00:00:03,169 --> 00:00:05,169
session about integration patterns

3
00:00:05,169 --> 00:00:06,549
for multi-tenant systems.

4
00:00:06,969 --> 00:00:09,210
I'm Alex. I'm a senior solutions architect

5
00:00:09,210 --> 00:00:11,569
at AWS from Germany working with

6
00:00:11,569 --> 00:00:12,788
European software companies

7
00:00:13,368 --> 00:00:14,788
together with my colleague here.

8
00:00:15,608 --> 00:00:18,179
Hello everyone, I'm Dirk. I'm also from Germany.

9
00:00:18,489 --> 00:00:20,760
I work with software companies too. I

10
00:00:20,760 --> 00:00:22,809
work with them on their multi-dimensional

11
00:00:22,809 --> 00:00:23,750
transformation.

12
00:00:24,489 --> 00:00:26,888
On the technical side, my focus is on

13
00:00:26,888 --> 00:00:28,708
everything around integration architecture,

14
00:00:28,969 --> 00:00:30,449
hence also this talk today.

15
00:00:30,879 --> 00:00:33,348
On the business side, I'm very much interested

16
00:00:33,490 --> 00:00:35,609
in innovation culture and

17
00:00:35,609 --> 00:00:37,689
how tech communities can

18
00:00:37,689 --> 00:00:40,109
improve fragmented techs.

19
00:00:41,200 --> 00:00:43,418
So today it's yet another talk about

20
00:00:43,418 --> 00:00:45,478
integration patterns, but this time

21
00:00:45,478 --> 00:00:46,899
with a focus on

22
00:00:47,200 --> 00:00:49,689
multi-tenant scenarios and

23
00:00:49,689 --> 00:00:51,200
SAS solutions.

24
00:00:51,679 --> 00:00:53,719
However, integration architecture

25
00:00:53,719 --> 00:00:54,700
as such

26
00:00:55,000 --> 00:00:57,118
we believe is relevant for

27
00:00:57,118 --> 00:00:57,700
everybody,

28
00:00:58,158 --> 00:00:59,500
and it really doesn't matter

29
00:01:00,039 --> 00:01:02,189
where on your integration journey you

30
00:01:02,478 --> 00:01:03,539
you currently are.

31
00:01:03,848 --> 00:01:06,010
If you operate a

32
00:01:06,010 --> 00:01:07,879
monolithic application

33
00:01:08,209 --> 00:01:10,250
or if there is one component

34
00:01:10,250 --> 00:01:12,418
that gave you a headache and you started

35
00:01:12,418 --> 00:01:14,028
carving it out already

36
00:01:14,370 --> 00:01:16,448
or if you are running and

37
00:01:16,448 --> 00:01:17,109
building

38
00:01:17,370 --> 00:01:19,569
a divide and conquer architectural style

39
00:01:19,569 --> 00:01:21,760
at home maybe with microservices,

40
00:01:22,088 --> 00:01:24,168
you will, you will always

41
00:01:24,168 --> 00:01:26,409
have to integrate with

42
00:01:26,409 --> 00:01:28,489
other systems and it

43
00:01:28,489 --> 00:01:30,599
sometimes. Depends also

44
00:01:30,859 --> 00:01:31,838
if you have

45
00:01:32,308 --> 00:01:34,338
more access to the systems that

46
00:01:34,338 --> 00:01:36,859
you need to integrate with or less

47
00:01:36,859 --> 00:01:39,219
access like the hoodoos here in the orange

48
00:01:39,219 --> 00:01:40,000
circles

49
00:01:40,808 --> 00:01:42,859
can represent your own systems where

50
00:01:42,859 --> 00:01:44,939
you certainly have more access and can

51
00:01:44,939 --> 00:01:47,459
choose different integration scenarios

52
00:01:47,459 --> 00:01:49,698
while the hoodoos in the

53
00:01:49,698 --> 00:01:51,900
blue circle might represent

54
00:01:51,900 --> 00:01:54,198
third party systems that you need to integrate

55
00:01:54,198 --> 00:01:56,040
with. Now

56
00:01:56,418 --> 00:01:58,870
with every journey, and we believe integration

57
00:01:58,870 --> 00:02:01,230
architecture is a journey, you

58
00:02:01,230 --> 00:02:02,370
want to be well

59
00:02:02,680 --> 00:02:03,230
prepared.

60
00:02:03,668 --> 00:02:05,870
If you, for instance, want to go on

61
00:02:05,870 --> 00:02:07,269
this bumpy road,

62
00:02:07,549 --> 00:02:09,550
you want to be well prepared with a high

63
00:02:09,550 --> 00:02:11,528
clearance 4x4 vehicle,

64
00:02:11,830 --> 00:02:13,118
and in the,

65
00:02:13,669 --> 00:02:15,990
in the same sense, you also want to be

66
00:02:15,990 --> 00:02:18,229
prepared for your integration architecture journey.

67
00:02:18,699 --> 00:02:19,229
And

68
00:02:19,629 --> 00:02:21,750
this brings us to two insights. The

69
00:02:21,750 --> 00:02:23,868
first is I only do these

70
00:02:23,868 --> 00:02:25,909
speaking activities because I want to

71
00:02:25,909 --> 00:02:28,129
brag with my nice vacation photos.

72
00:02:28,379 --> 00:02:30,368
And the second insight is

73
00:02:30,659 --> 00:02:33,169
that not only in modern cloud

74
00:02:33,169 --> 00:02:35,189
applications, but particularly also in modern

75
00:02:35,189 --> 00:02:36,490
cloud applications,

76
00:02:37,028 --> 00:02:39,189
integration can't be an afterthought

77
00:02:39,189 --> 00:02:41,349
because it is an integral

78
00:02:41,349 --> 00:02:42,649
part of your

79
00:02:44,020 --> 00:02:45,349
application architecture.

80
00:02:46,960 --> 00:02:47,490
Now

81
00:02:48,258 --> 00:02:50,460
There's many ways to actually design

82
00:02:50,460 --> 00:02:52,460
an integration scenario, and the

83
00:02:52,460 --> 00:02:54,500
first thing you need to make up your mind

84
00:02:54,500 --> 00:02:56,719
is what is the concept or the approach

85
00:02:56,719 --> 00:02:57,939
that you want to use.

86
00:02:59,210 --> 00:03:01,169
This already is quite ambiguous,

87
00:03:01,449 --> 00:03:03,610
and you really need to understand

88
00:03:03,610 --> 00:03:06,069
the implications of each of those

89
00:03:06,838 --> 00:03:07,419
approaches,

90
00:03:07,699 --> 00:03:10,050
but then once you have decided for

91
00:03:10,050 --> 00:03:12,288
a particular integration scenario

92
00:03:12,288 --> 00:03:13,520
which approach to follow,

93
00:03:13,808 --> 00:03:15,460
there's a ton of follow-up

94
00:03:16,210 --> 00:03:18,389
questions and design decisions that

95
00:03:18,558 --> 00:03:19,669
you need to take,

96
00:03:20,169 --> 00:03:21,508
and each of those

97
00:03:21,929 --> 00:03:24,050
can easily fill a one hour

98
00:03:24,050 --> 00:03:25,270
tech talk on its own.

99
00:03:26,050 --> 00:03:28,879
So the

100
00:03:28,879 --> 00:03:31,508
decisive part here is that you should

101
00:03:31,508 --> 00:03:33,679
understand the implications of each of

102
00:03:33,679 --> 00:03:35,538
those design decisions,

103
00:03:35,879 --> 00:03:38,118
and when you look at a

104
00:03:38,118 --> 00:03:40,830
SAS application or a multi-tenant scenario,

105
00:03:41,038 --> 00:03:43,159
you have the additional challenge that

106
00:03:43,159 --> 00:03:45,838
you also need to care about tenant

107
00:03:45,969 --> 00:03:46,808
isolation.

108
00:03:47,288 --> 00:03:49,770
So there's a whole lot of ambiguity

109
00:03:49,770 --> 00:03:51,770
involved here and this is

110
00:03:51,770 --> 00:03:54,008
why it is really, really important

111
00:03:54,008 --> 00:03:56,159
for software architects to be

112
00:03:56,159 --> 00:03:58,210
aware of the patterns and

113
00:03:58,210 --> 00:04:00,429
options at hand and also

114
00:04:00,649 --> 00:04:02,639
the implications that it has.

115
00:04:03,758 --> 00:04:05,990
So I also like to call this

116
00:04:05,990 --> 00:04:08,558
statement the beware of the face healer principle

117
00:04:08,558 --> 00:04:09,618
because there is

118
00:04:09,979 --> 00:04:12,558
really no silver bullet in software architecture.

119
00:04:12,778 --> 00:04:14,960
Every decision you take basically

120
00:04:14,960 --> 00:04:16,988
sucks in a certain way, and

121
00:04:16,988 --> 00:04:18,410
as a software architect,

122
00:04:18,678 --> 00:04:21,000
you should know which one of the

123
00:04:21,000 --> 00:04:23,338
options that are on the table sucks less

124
00:04:23,338 --> 00:04:25,040
than all the other options.

125
00:04:26,170 --> 00:04:28,600
So with that um

126
00:04:28,850 --> 00:04:30,928
we actually wanted to make it a little

127
00:04:30,928 --> 00:04:32,988
bit more tangible and fun today

128
00:04:33,209 --> 00:04:35,369
and uh illustrate everything we're

129
00:04:35,369 --> 00:04:37,649
gonna talk about with

130
00:04:37,649 --> 00:04:40,139
an example customer an example

131
00:04:40,559 --> 00:04:42,528
um technology startup actually.

132
00:04:43,048 --> 00:04:45,389
So Alex, you like unicorns I believe.

133
00:04:45,689 --> 00:04:47,730
Do you want to introduce our example

134
00:04:47,730 --> 00:04:50,238
customer? Absolutely. So there is

135
00:04:50,238 --> 00:04:52,389
a company you would like to introduce.

136
00:04:52,899 --> 00:04:55,048
We use this kind of uh fictional

137
00:04:55,048 --> 00:04:57,088
company across several uh workshops and

138
00:04:57,088 --> 00:04:59,379
formats at AWS. It's called Wild Rides,

139
00:04:59,850 --> 00:05:01,928
and I mean it's a ride sharing service, so

140
00:05:01,928 --> 00:05:03,970
nothing super special except for one thing instead of

141
00:05:03,970 --> 00:05:05,528
cars they have unicorns.

142
00:05:05,889 --> 00:05:08,199
So if you book this rides this will be wild,

143
00:05:08,369 --> 00:05:10,439
right? So I mean this has been

144
00:05:10,439 --> 00:05:12,528
hugely popular because under the hood

145
00:05:12,528 --> 00:05:14,540
though it's quite a crazy business model, it is very

146
00:05:14,540 --> 00:05:15,509
solid technology

147
00:05:15,889 --> 00:05:18,108
and with all the success they have now decided

148
00:05:18,108 --> 00:05:20,129
to move further in their journey

149
00:05:20,129 --> 00:05:21,689
and go into business.

150
00:05:22,088 --> 00:05:24,329
So now they have wild rights for business,

151
00:05:24,410 --> 00:05:26,470
and this is basically a multi-tenant

152
00:05:27,129 --> 00:05:29,488
extension of the current use case. So assume

153
00:05:29,488 --> 00:05:30,869
that you would have

154
00:05:31,410 --> 00:05:33,488
per tenant apps with their own

155
00:05:33,488 --> 00:05:35,838
branding, but you also have special

156
00:05:35,838 --> 00:05:37,850
features for each tenant. You may have a tiered

157
00:05:37,850 --> 00:05:40,358
pricing model and typical aspects

158
00:05:40,358 --> 00:05:41,819
that you would see in a SAS application.

159
00:05:42,369 --> 00:05:44,928
And now the existing infrastructure and architecture

160
00:05:44,928 --> 00:05:47,730
needs to be extended to support this multi-tenant

161
00:05:47,730 --> 00:05:49,949
business. And

162
00:05:49,949 --> 00:05:52,269
this is basically our

163
00:05:52,269 --> 00:05:54,528
sample scenario that we will look into

164
00:05:54,750 --> 00:05:56,819
when we discuss what it means to have a

165
00:05:56,819 --> 00:05:59,059
distributed architecture, but also a multi-tenant

166
00:05:59,059 --> 00:06:01,069
architecture and those complexity

167
00:06:01,069 --> 00:06:02,869
dimensions basically being combined.

168
00:06:03,858 --> 00:06:05,869
So let's look at different aspects of

169
00:06:05,869 --> 00:06:06,809
that, the first being

170
00:06:07,220 --> 00:06:09,309
the interconnection of services within such

171
00:06:09,309 --> 00:06:10,269
an architecture.

172
00:06:11,290 --> 00:06:11,869
So

173
00:06:12,569 --> 00:06:14,809
when we look at wild rides as an offering, it is

174
00:06:14,809 --> 00:06:16,939
coherent from the outside perspective.

175
00:06:16,970 --> 00:06:18,970
It might look a bit monolithic, but it's not.

176
00:06:19,449 --> 00:06:21,649
So first, it's important to understand that wild rights

177
00:06:21,649 --> 00:06:23,879
does not live in isolation. It lives

178
00:06:23,879 --> 00:06:25,889
in a context with tenants and their

179
00:06:25,889 --> 00:06:26,559
systems,

180
00:06:27,040 --> 00:06:29,250
which are the applications like a mobile

181
00:06:29,250 --> 00:06:31,488
app that we are deploying and providing to them.

182
00:06:31,738 --> 00:06:33,858
But the tenants as businesses also have

183
00:06:33,858 --> 00:06:35,899
their own, let's say finance systems

184
00:06:35,899 --> 00:06:38,298
or a federated identity management

185
00:06:38,298 --> 00:06:40,298
service that needs to be integrated with

186
00:06:40,298 --> 00:06:42,639
the wild rights core system.

187
00:06:43,420 --> 00:06:45,720
But Wi Rights doesn't want to do everything themselves

188
00:06:45,720 --> 00:06:47,738
as a smart, scalable startup,

189
00:06:47,858 --> 00:06:50,019
they have decided there are things we don't want to do

190
00:06:50,019 --> 00:06:52,059
ourselves. Obviously nobody starts building a payment

191
00:06:52,059 --> 00:06:52,879
service provider,

192
00:06:53,178 --> 00:06:55,449
but even email is something that you don't need to build

193
00:06:55,449 --> 00:06:57,488
yourself, right? So this is a commodity

194
00:06:57,488 --> 00:06:58,278
you put it

195
00:06:58,579 --> 00:06:59,720
somewhere else and

196
00:07:00,009 --> 00:07:01,178
focus on your core business.

197
00:07:01,730 --> 00:07:04,290
So this is basically the external integrations

198
00:07:04,290 --> 00:07:05,410
that this company has,

199
00:07:05,769 --> 00:07:08,209
but if you look into the wide rights architecture,

200
00:07:08,290 --> 00:07:10,329
you will see that it's also distributed, so

201
00:07:10,329 --> 00:07:12,678
it would have, let's say something like microservices,

202
00:07:12,850 --> 00:07:14,119
whatever you would

203
00:07:14,528 --> 00:07:15,269
understand that to be.

204
00:07:15,689 --> 00:07:17,069
These services talk to each other,

205
00:07:17,480 --> 00:07:19,548
but we need to make it in a way that is scalable

206
00:07:19,548 --> 00:07:20,230
and resilient.

207
00:07:21,250 --> 00:07:23,449
So how is the best way to build this?

208
00:07:25,660 --> 00:07:28,199
Right, one prominent example

209
00:07:28,778 --> 00:07:30,858
for the interconnectivity is

210
00:07:30,858 --> 00:07:33,178
that SARS applications apparently

211
00:07:33,178 --> 00:07:35,178
expose APIs. This is, and

212
00:07:35,178 --> 00:07:36,928
it is probably nothing new for you,

213
00:07:37,259 --> 00:07:39,379
the way how SARS is consumed. So

214
00:07:39,379 --> 00:07:41,379
you have tenants that consume

215
00:07:41,619 --> 00:07:43,790
APIs from your offering.

216
00:07:44,389 --> 00:07:46,480
Let's illustrate this um with a use

217
00:07:46,480 --> 00:07:48,639
case. So the use case is that an

218
00:07:48,639 --> 00:07:49,420
end user

219
00:07:50,119 --> 00:07:52,358
that belongs to a tenant books a ride

220
00:07:52,358 --> 00:07:53,040
with the app.

221
00:07:53,319 --> 00:07:55,470
We have our Wild rights

222
00:07:55,470 --> 00:07:57,519
application and it exposes the

223
00:07:57,519 --> 00:07:59,000
right bookings API.

224
00:07:59,730 --> 00:08:02,019
On the client side, we have one of our

225
00:08:02,019 --> 00:08:04,259
tenant's users, and they apparently

226
00:08:04,259 --> 00:08:06,579
want to submit the right details.

227
00:08:06,939 --> 00:08:09,059
Now the natural approach that

228
00:08:09,059 --> 00:08:11,220
most of us would probably try

229
00:08:11,220 --> 00:08:13,660
first is to use the synchronous

230
00:08:13,660 --> 00:08:15,899
request response pattern here.

231
00:08:16,470 --> 00:08:18,670
Because most of us are used to this, this

232
00:08:18,670 --> 00:08:19,928
is the way how we

233
00:08:20,189 --> 00:08:22,088
were using software,

234
00:08:22,629 --> 00:08:24,738
programming languages all of our lives

235
00:08:24,738 --> 00:08:25,369
that we send

236
00:08:25,738 --> 00:08:28,028
synchronous requests to functions

237
00:08:28,028 --> 00:08:30,028
or procedures, and this is also the

238
00:08:30,028 --> 00:08:32,029
way how most of us consume websites.

239
00:08:33,308 --> 00:08:35,590
So this would look like this. The client

240
00:08:35,590 --> 00:08:37,859
sends out a post request to wild rights.

241
00:08:38,109 --> 00:08:39,849
It takes a while to process.

242
00:08:40,327 --> 00:08:42,648
And this while might be

243
00:08:42,648 --> 00:08:43,388
also

244
00:08:43,688 --> 00:08:46,207
too much for a good user experience

245
00:08:46,207 --> 00:08:48,567
because only after all the

246
00:08:48,567 --> 00:08:50,109
processing is done under the hood,

247
00:08:50,768 --> 00:08:52,268
the client would receive the

248
00:08:52,648 --> 00:08:53,229
response

249
00:08:53,499 --> 00:08:55,869
with the details that the booking has been

250
00:08:56,207 --> 00:08:58,109
successfully, hopefully successfully

251
00:08:58,688 --> 00:09:01,259
processed. So

252
00:09:01,259 --> 00:09:03,700
why can this be not the best user

253
00:09:03,700 --> 00:09:06,099
experience because we have a lot of

254
00:09:06,099 --> 00:09:08,450
stuff to do under the hood and certainly

255
00:09:08,580 --> 00:09:10,700
Alex showed it before there's an external

256
00:09:10,700 --> 00:09:12,779
payment service provider involved. We also

257
00:09:12,779 --> 00:09:14,820
want to capture the money upfront for

258
00:09:14,820 --> 00:09:16,798
the ride. That might take a while.

259
00:09:17,229 --> 00:09:19,548
So it's not the best user

260
00:09:19,548 --> 00:09:21,590
experience. And why is that so? Because we have

261
00:09:21,590 --> 00:09:23,889
that tight coupling at runtime between

262
00:09:24,070 --> 00:09:25,408
the client on one hand

263
00:09:25,668 --> 00:09:27,869
and the back end on the

264
00:09:27,869 --> 00:09:28,450
other hand,

265
00:09:28,710 --> 00:09:31,330
and this is apparently an inherent

266
00:09:32,428 --> 00:09:34,649
characteristic of the synchronous request

267
00:09:34,649 --> 00:09:36,210
response model.

268
00:09:37,149 --> 00:09:39,690
By the way, this is also called

269
00:09:39,869 --> 00:09:42,428
a conversation pattern because it spawns

270
00:09:42,428 --> 00:09:43,450
a conversation

271
00:09:43,788 --> 00:09:45,570
between two parties.

272
00:09:45,869 --> 00:09:47,989
But what would be a better way to

273
00:09:47,989 --> 00:09:50,019
improve the user experience here?

274
00:09:50,269 --> 00:09:51,450
Well, we can

275
00:09:52,509 --> 00:09:55,428
progress and look at asynchronous

276
00:09:55,428 --> 00:09:56,570
request response,

277
00:09:57,029 --> 00:09:59,109
and in this case, the downstream

278
00:09:59,109 --> 00:10:00,629
request looks the same.

279
00:10:00,950 --> 00:10:03,440
And luckily HTTP supports

280
00:10:03,440 --> 00:10:05,918
this asynchronous behavior by

281
00:10:05,918 --> 00:10:08,158
responding with 202 accepted now and

282
00:10:08,158 --> 00:10:10,359
a representation of the task

283
00:10:10,599 --> 00:10:11,500
that we have

284
00:10:11,879 --> 00:10:14,119
created under the hood on the backhand

285
00:10:14,119 --> 00:10:16,570
side. The actual

286
00:10:16,570 --> 00:10:18,609
processing with white rights will still

287
00:10:18,609 --> 00:10:20,149
take the same amount of time,

288
00:10:20,489 --> 00:10:22,609
but the user doesn't have to

289
00:10:22,609 --> 00:10:24,690
watch that spinning hourglass all

290
00:10:24,690 --> 00:10:25,308
the time

291
00:10:25,570 --> 00:10:27,690
and can continue with

292
00:10:27,690 --> 00:10:29,469
whatever they want to do next.

293
00:10:30,639 --> 00:10:32,658
Now, in the best case,

294
00:10:32,879 --> 00:10:35,320
you are also a nice

295
00:10:35,320 --> 00:10:37,399
citizen and provide your

296
00:10:37,399 --> 00:10:39,399
customers with a representation

297
00:10:39,599 --> 00:10:41,759
of that status and a link for

298
00:10:41,759 --> 00:10:44,239
the customer to retrieve a status

299
00:10:44,239 --> 00:10:46,279
update. So that's the customer while they

300
00:10:46,279 --> 00:10:48,364
are. Waiting for the processing

301
00:10:48,533 --> 00:10:49,614
can have a look hey,

302
00:10:50,134 --> 00:10:51,413
how far are we already?

303
00:10:51,695 --> 00:10:52,754
So in this case

304
00:10:53,215 --> 00:10:55,423
they can use the link that has been

305
00:10:55,423 --> 00:10:57,445
provided with the response and

306
00:10:57,445 --> 00:10:59,565
send a get request downstream to retrieve

307
00:10:59,565 --> 00:11:01,815
a status update and if they do it very

308
00:11:01,815 --> 00:11:02,394
quickly

309
00:11:03,014 --> 00:11:05,293
there will still be the task and status

310
00:11:05,293 --> 00:11:07,913
representation hopefully with a link to retrieve

311
00:11:08,134 --> 00:11:08,933
another update.

312
00:11:09,320 --> 00:11:10,000
And

313
00:11:10,349 --> 00:11:12,908
maybe 2 minutes later or so when also

314
00:11:12,908 --> 00:11:15,029
the very slow external payment service

315
00:11:15,029 --> 00:11:17,418
provider has done its job, we will

316
00:11:17,418 --> 00:11:19,469
retrieve a representation of the

317
00:11:19,469 --> 00:11:20,609
actual successful

318
00:11:20,940 --> 00:11:22,029
ride booking,

319
00:11:22,308 --> 00:11:24,408
and that's the convenience functionality

320
00:11:24,408 --> 00:11:26,690
that I would recommend to offer your customers.

321
00:11:26,830 --> 00:11:27,489
However,

322
00:11:27,750 --> 00:11:29,940
you obviously don't want to force

323
00:11:29,940 --> 00:11:32,500
them to use this and also

324
00:11:32,509 --> 00:11:34,808
provide a push notification once

325
00:11:35,129 --> 00:11:36,029
you are done with that.

326
00:11:36,918 --> 00:11:38,979
So that's the asynchronous

327
00:11:39,359 --> 00:11:39,928
request

328
00:11:40,359 --> 00:11:41,129
response pattern

329
00:11:41,479 --> 00:11:43,558
that improves the user experience

330
00:11:43,558 --> 00:11:45,940
by reducing the runtime coupling

331
00:11:46,239 --> 00:11:47,759
between components.

332
00:11:48,158 --> 00:11:50,200
Now, looking at APIs, Alex,

333
00:11:50,519 --> 00:11:52,599
what is there that we need to

334
00:11:52,599 --> 00:11:54,879
look at in terms of multi-tenant architecture?

335
00:11:55,479 --> 00:11:57,908
That's a good question because again APIs,

336
00:11:57,918 --> 00:11:59,969
many people think would be something like RESS which is more

337
00:11:59,969 --> 00:12:00,779
synchronous,

338
00:12:01,129 --> 00:12:03,450
but in this kind of distributed architecture

339
00:12:03,450 --> 00:12:05,649
it needs to be scalable across several patterns.

340
00:12:05,928 --> 00:12:08,149
We need to introduce things that deal with the

341
00:12:08,149 --> 00:12:10,788
complexity, as I mentioned, of SARS and of

342
00:12:11,288 --> 00:12:13,489
distributed architecture. So we are going to introduce

343
00:12:13,489 --> 00:12:15,279
two more patterns that we can use,

344
00:12:15,729 --> 00:12:18,210
and when I say patterns, it's actually more concepts

345
00:12:18,210 --> 00:12:20,729
that you would have to translate into patterns implementations.

346
00:12:21,109 --> 00:12:23,469
The first one deals with multi-tenancy quite obviously

347
00:12:23,469 --> 00:12:25,590
that's a SARS identity. The other one being

348
00:12:25,590 --> 00:12:26,460
back pressure,

349
00:12:26,788 --> 00:12:29,229
which means that if you have a

350
00:12:29,229 --> 00:12:31,779
bit of your infrastructure that is at the capacity,

351
00:12:31,989 --> 00:12:34,450
you would not accept new input like messages,

352
00:12:34,460 --> 00:12:36,469
but instead fail gracefully and let

353
00:12:36,469 --> 00:12:38,950
the producer of the message know that

354
00:12:38,950 --> 00:12:40,210
you are out.

355
00:12:40,869 --> 00:12:43,029
So how does it look in practice? Let's say again

356
00:12:43,029 --> 00:12:45,210
we have this uh multi-tenant system

357
00:12:45,489 --> 00:12:47,529
and we need to um.

358
00:12:49,029 --> 00:12:51,190
Transport the information about the

359
00:12:51,190 --> 00:12:53,229
identity of that tenant

360
00:12:53,229 --> 00:12:55,269
across the interactions with tenant systems

361
00:12:55,269 --> 00:12:57,590
like mobile apps or finance systems.

362
00:12:58,960 --> 00:12:59,769
One way

363
00:13:00,070 --> 00:13:00,769
of many

364
00:13:01,029 --> 00:13:03,149
is the usage of jot

365
00:13:03,149 --> 00:13:03,710
tokens.

366
00:13:04,149 --> 00:13:06,389
So I think most people of you have heard of jot

367
00:13:06,389 --> 00:13:08,830
tokens, maybe using them in their own architectures,

368
00:13:09,109 --> 00:13:11,149
but let's recap quickly what that is. The idea of a

369
00:13:11,149 --> 00:13:12,690
jot token is a,

370
00:13:13,229 --> 00:13:15,389
well, in this case you see it, it's a, a piece

371
00:13:15,389 --> 00:13:16,899
of Jad Jason

372
00:13:17,509 --> 00:13:19,908
that you would use to transport

373
00:13:19,908 --> 00:13:22,279
information across the bits of your architecture.

374
00:13:22,548 --> 00:13:24,590
The important thing here is when you submit that

375
00:13:24,590 --> 00:13:26,908
it comes with a signature of that message.

376
00:13:27,259 --> 00:13:28,229
And that signature

377
00:13:28,649 --> 00:13:30,769
guarantees the integrity of the message.

378
00:13:31,288 --> 00:13:33,379
So you can, for instance, send a job to

379
00:13:33,399 --> 00:13:34,149
to a client.

380
00:13:34,729 --> 00:13:35,750
They can read it,

381
00:13:36,330 --> 00:13:38,820
but they can also ideally verify the signature

382
00:13:38,820 --> 00:13:40,989
and know that the message is

383
00:13:41,129 --> 00:13:43,210
true. So the veracity of the message is guaranteed

384
00:13:43,210 --> 00:13:45,359
here. And this is a very common

385
00:13:45,359 --> 00:13:47,408
pattern even outside of SARS, but they can use it

386
00:13:47,408 --> 00:13:49,529
in SARS context in combination with

387
00:13:49,529 --> 00:13:50,989
distributed architecture

388
00:13:51,330 --> 00:13:53,519
to transport information about the tenant.

389
00:13:54,009 --> 00:13:55,469
So if you have a mobile app.

390
00:13:56,219 --> 00:13:58,219
Then you can inject information like

391
00:13:58,219 --> 00:14:00,460
the SARS uh tenant ID

392
00:14:00,940 --> 00:14:03,259
or maybe their name, but even

393
00:14:03,259 --> 00:14:05,639
things like the tier of your um

394
00:14:06,340 --> 00:14:06,960
tenant

395
00:14:07,279 --> 00:14:09,369
and this will allow consuming systems to

396
00:14:09,369 --> 00:14:11,538
work with that information without going to the

397
00:14:11,538 --> 00:14:12,960
sort of truth to retrieve it again

398
00:14:13,340 --> 00:14:15,460
because again you can validate diversity

399
00:14:15,460 --> 00:14:17,580
of that. You can even do more

400
00:14:17,580 --> 00:14:20,099
than just conveying this more simple

401
00:14:20,099 --> 00:14:21,168
meta information.

402
00:14:21,538 --> 00:14:23,960
You can have even technical

403
00:14:23,960 --> 00:14:25,979
information here. So when we talk about back pressure and

404
00:14:25,979 --> 00:14:27,798
meaning that we decouple the

405
00:14:28,450 --> 00:14:30,489
producing system in terms of

406
00:14:30,489 --> 00:14:32,580
capacity and quota from our consuming

407
00:14:32,580 --> 00:14:33,139
system,

408
00:14:33,500 --> 00:14:35,700
we could convey that information to the producing

409
00:14:35,700 --> 00:14:37,700
system already so that it doesn't have to

410
00:14:37,700 --> 00:14:39,979
run into a failure, but can itself

411
00:14:39,979 --> 00:14:41,619
manage that before running into that.

412
00:14:42,250 --> 00:14:44,250
So we could say that for example a

413
00:14:44,250 --> 00:14:46,340
customer in the basic tier would have a certain

414
00:14:46,340 --> 00:14:48,379
quota, they have an amount of requests they can

415
00:14:48,379 --> 00:14:50,389
do per minute, per month, or whatever,

416
00:14:50,820 --> 00:14:53,058
and you can then say a premium

417
00:14:53,058 --> 00:14:55,619
customer or a higher tier customer

418
00:14:55,619 --> 00:14:57,099
would have a higher quota.

419
00:14:57,500 --> 00:14:59,700
Obviously you can also say that here's an enterprise

420
00:14:59,700 --> 00:15:01,798
customer does not have any limitations at all,

421
00:15:02,178 --> 00:15:03,719
and they would be able to

422
00:15:04,418 --> 00:15:05,940
submit as many messages as they want.

423
00:15:06,639 --> 00:15:08,729
So this is the way to kind of

424
00:15:08,729 --> 00:15:09,960
extend the

425
00:15:10,250 --> 00:15:12,288
functionality of jot tokens in

426
00:15:12,288 --> 00:15:14,788
order to convey the information

427
00:15:15,168 --> 00:15:17,210
to your producing systems without having

428
00:15:17,210 --> 00:15:18,469
them run into failures,

429
00:15:18,889 --> 00:15:20,889
and this will be very useful as we go further

430
00:15:20,889 --> 00:15:22,428
through this talk so keep that in mind

431
00:15:22,808 --> 00:15:24,668
as a very useful mechanism

432
00:15:25,009 --> 00:15:26,210
to transport this.

433
00:15:28,869 --> 00:15:31,119
So let's have a closer look at what happens inside

434
00:15:31,119 --> 00:15:32,399
the white rights application.

435
00:15:33,668 --> 00:15:36,308
Because right now we have been looking at the

436
00:15:36,308 --> 00:15:37,340
external systems,

437
00:15:37,629 --> 00:15:38,428
but internally,

438
00:15:38,879 --> 00:15:41,158
as Doug already said, there are things happening,

439
00:15:41,629 --> 00:15:43,649
so we expect that the

440
00:15:43,668 --> 00:15:45,710
app sends us a request, we would return with the

441
00:15:45,710 --> 00:15:47,668
HTP 202 that is established

442
00:15:48,070 --> 00:15:50,190
and we said that we will not process everything

443
00:15:50,190 --> 00:15:52,219
immediately. So what happens instead if it's not

444
00:15:52,219 --> 00:15:53,668
a full cycle?

445
00:15:54,418 --> 00:15:56,580
The way Wild Rights choose to implement

446
00:15:56,580 --> 00:15:58,940
this is through a message bus as the first

447
00:15:58,940 --> 00:16:01,099
point of decoupling the

448
00:16:01,099 --> 00:16:03,298
booking service that takes in the

449
00:16:03,298 --> 00:16:03,879
booking

450
00:16:04,139 --> 00:16:05,500
from the Downstream systems,

451
00:16:05,899 --> 00:16:07,940
and the message bus allows us to

452
00:16:07,940 --> 00:16:08,759
spread out

453
00:16:09,178 --> 00:16:11,418
the booking information into other

454
00:16:11,418 --> 00:16:13,418
services that need to work with that. So for

455
00:16:13,418 --> 00:16:15,609
example, here we have a planning service that

456
00:16:15,609 --> 00:16:17,019
does resource allocation.

457
00:16:17,418 --> 00:16:19,460
We have a payment service that will be working with

458
00:16:19,460 --> 00:16:21,200
an external payment service provider.

459
00:16:21,639 --> 00:16:23,649
And we have some loyalty services that

460
00:16:23,649 --> 00:16:25,969
would allow us to, you know, give customers

461
00:16:25,969 --> 00:16:27,750
some goodies if they're, you know,

462
00:16:28,330 --> 00:16:30,379
use more and more of our service.

463
00:16:31,090 --> 00:16:33,529
So the downstream service is external

464
00:16:33,529 --> 00:16:36,048
again and we would assume that it expects a synchronous

465
00:16:36,048 --> 00:16:38,210
HTP request. We cannot do much more

466
00:16:38,210 --> 00:16:40,349
here. We will come back to that later,

467
00:16:40,690 --> 00:16:42,710
but within our own architecture we can

468
00:16:42,710 --> 00:16:43,229
use

469
00:16:43,649 --> 00:16:45,889
decoupling mechanisms like queues.

470
00:16:46,250 --> 00:16:48,489
In order to decouple again within

471
00:16:48,489 --> 00:16:50,960
our architecture services

472
00:16:50,969 --> 00:16:52,629
from their downstream consumers.

473
00:16:53,349 --> 00:16:55,798
And these message cues is something that's not

474
00:16:55,798 --> 00:16:58,029
new but it's still very, very powerful mechanism,

475
00:16:58,320 --> 00:17:00,428
and especially in multi-tenant architectures we can

476
00:17:00,428 --> 00:17:02,058
apply specific patterns

477
00:17:02,469 --> 00:17:04,479
to use those cues in a way to

478
00:17:04,479 --> 00:17:06,660
take a load of producers and consumers.

479
00:17:08,077 --> 00:17:10,057
We can even use cues

480
00:17:10,438 --> 00:17:12,479
as we evolve our architecture. So let's say

481
00:17:12,479 --> 00:17:14,479
this loyalty service turned out to be a

482
00:17:14,479 --> 00:17:15,778
bit sluggish and slow,

483
00:17:16,077 --> 00:17:18,798
and really we don't need to process loyalty

484
00:17:18,798 --> 00:17:20,798
information in real time. So this is not very relevant to

485
00:17:20,798 --> 00:17:22,807
the booking. So we say after a time

486
00:17:22,807 --> 00:17:24,917
we introduce a message queue and refactor the

487
00:17:24,917 --> 00:17:27,097
message, sorry, the customer loyalty service

488
00:17:27,398 --> 00:17:29,269
to consume those messages afterwards.

489
00:17:29,597 --> 00:17:31,678
So this is an evolution of your architecture that

490
00:17:31,678 --> 00:17:34,519
would be more and more decoupled along these queuing

491
00:17:34,519 --> 00:17:35,159
patterns.

492
00:17:36,969 --> 00:17:39,049
Now the queues being our main

493
00:17:39,049 --> 00:17:41,229
way to create resiliency

494
00:17:41,410 --> 00:17:43,449
and scale is something worth

495
00:17:43,449 --> 00:17:45,729
looking deeper into. And so if we

496
00:17:45,729 --> 00:17:47,910
look into what the queues do here.

497
00:17:49,059 --> 00:17:51,328
Oh. Pushing the wrong button.

498
00:17:51,729 --> 00:17:53,729
We see that basically we have a producing

499
00:17:53,729 --> 00:17:55,199
system with multiple tenants.

500
00:17:55,608 --> 00:17:57,608
We have a consumer and we will not look closer

501
00:17:57,608 --> 00:17:59,709
into that, so it's just a blue box at this point,

502
00:18:00,209 --> 00:18:02,328
but we have now a queue that contains

503
00:18:02,328 --> 00:18:04,489
the messages of several

504
00:18:04,489 --> 00:18:05,088
producers.

505
00:18:06,279 --> 00:18:06,799
And

506
00:18:07,549 --> 00:18:09,959
That is a very good mechanism, so in

507
00:18:09,959 --> 00:18:12,049
stable, happy scenario there will be no problem.

508
00:18:12,160 --> 00:18:14,348
Messages will be consumed,

509
00:18:14,838 --> 00:18:16,189
processed as we go,

510
00:18:16,680 --> 00:18:19,160
but it may happen that one of those tenants

511
00:18:19,160 --> 00:18:21,279
will start a large bag of messages.

512
00:18:22,858 --> 00:18:23,400
So

513
00:18:24,140 --> 00:18:26,338
that can happen under two circumstances. One

514
00:18:26,338 --> 00:18:28,459
would be that specifically that tenant

515
00:18:28,459 --> 00:18:30,539
or the users from that tenant would create a lot of

516
00:18:30,539 --> 00:18:32,059
booking rights, like let's say

517
00:18:32,420 --> 00:18:34,618
some tech company has a large event and

518
00:18:34,618 --> 00:18:37,078
would invite everybody to use their right services,

519
00:18:37,660 --> 00:18:40,140
or it could be that the consumer has a tenant

520
00:18:40,140 --> 00:18:42,900
specific problem like a misconfiguration

521
00:18:42,900 --> 00:18:43,660
or some, you know,

522
00:18:43,939 --> 00:18:45,430
contractual thing not working right,

523
00:18:45,818 --> 00:18:47,519
and that could lead to a scenario

524
00:18:48,098 --> 00:18:49,660
where that particular tenant.

525
00:18:50,430 --> 00:18:52,430
Kind of clogs the cue for

526
00:18:52,430 --> 00:18:54,479
you. So that would

527
00:18:54,479 --> 00:18:56,009
lead to that tenant

528
00:18:56,299 --> 00:18:58,640
using up the resource of clogging it and causing

529
00:18:58,640 --> 00:19:00,920
a starvation of the

530
00:19:00,920 --> 00:19:03,019
consumption of messages from other systems

531
00:19:03,279 --> 00:19:05,318
and this is what in a multi-tenant system we

532
00:19:05,318 --> 00:19:06,818
call a noisy neighbor.

533
00:19:07,318 --> 00:19:09,439
So in this scenario, tenant one would

534
00:19:09,439 --> 00:19:10,739
be a noisy neighbor

535
00:19:11,199 --> 00:19:13,318
that impedes the business

536
00:19:13,318 --> 00:19:15,380
functionality for other tenants,

537
00:19:15,880 --> 00:19:17,959
and this is the question can we do something about

538
00:19:17,959 --> 00:19:19,140
it, Dirk? Do you have an idea?

539
00:19:19,900 --> 00:19:21,949
I have several ideas. Nice. Let's start

540
00:19:21,949 --> 00:19:23,949
with a general consideration.

541
00:19:24,949 --> 00:19:27,029
A general consideration that you can

542
00:19:27,029 --> 00:19:27,729
always

543
00:19:28,009 --> 00:19:30,108
apply in this situation and in

544
00:19:30,108 --> 00:19:32,250
other situations is load shedding

545
00:19:32,390 --> 00:19:34,519
and back pressure. We've already heard about

546
00:19:34,519 --> 00:19:36,588
back pressure on API level,

547
00:19:36,910 --> 00:19:38,949
but you can also use it

548
00:19:38,949 --> 00:19:41,189
further down the line, for instance, directly

549
00:19:41,189 --> 00:19:42,289
on your producers.

550
00:19:42,779 --> 00:19:45,108
But let's go one step back and

551
00:19:45,108 --> 00:19:47,209
have another look at the characteristics

552
00:19:47,430 --> 00:19:48,068
of cues.

553
00:19:48,588 --> 00:19:49,868
So the nice thing,

554
00:19:50,150 --> 00:19:52,670
why you would want to use cues everywhere

555
00:19:52,670 --> 00:19:54,789
in the end, I like them as you can

556
00:19:54,789 --> 00:19:55,588
imagine. is

557
00:19:56,578 --> 00:19:58,660
that they solve a lot of problems for

558
00:19:58,660 --> 00:20:01,368
you. First of all, they can buffer messages,

559
00:20:01,380 --> 00:20:03,578
and in that respect they further

560
00:20:03,578 --> 00:20:05,818
reduce the temporal coupling between

561
00:20:05,818 --> 00:20:07,838
upstream and downstream systems.

562
00:20:08,140 --> 00:20:09,489
When you use APIs,

563
00:20:09,818 --> 00:20:12,098
you cannot send a request downstream

564
00:20:12,098 --> 00:20:14,098
when the downstream system is

565
00:20:14,098 --> 00:20:16,140
not actively listening because it

566
00:20:16,140 --> 00:20:18,598
is in a struggle maybe, but with queues,

567
00:20:18,818 --> 00:20:21,439
the queue in between will buffer the messages,

568
00:20:21,578 --> 00:20:23,500
and with that it comes with a

569
00:20:24,509 --> 00:20:26,868
with a peak load flattening

570
00:20:26,868 --> 00:20:29,029
functionality that is really super

571
00:20:29,029 --> 00:20:31,299
handy, so you can protect your consumers

572
00:20:31,299 --> 00:20:32,328
downstream.

573
00:20:32,739 --> 00:20:35,029
Also, because every message that

574
00:20:35,029 --> 00:20:37,108
goes from a queue to a consumer goes

575
00:20:37,108 --> 00:20:38,189
to exactly one

576
00:20:38,630 --> 00:20:40,868
consumer, you can easily scale out

577
00:20:40,868 --> 00:20:42,489
on the consumer side if

578
00:20:43,309 --> 00:20:45,410
the number of messages in your queue

579
00:20:45,670 --> 00:20:46,750
becomes very high.

580
00:20:47,189 --> 00:20:47,729
But then,

581
00:20:48,078 --> 00:20:50,318
You probably only want to scale out

582
00:20:50,318 --> 00:20:51,019
so much

583
00:20:51,838 --> 00:20:54,559
because you have a cost cap on the

584
00:20:54,559 --> 00:20:55,479
number of compute

585
00:20:56,368 --> 00:20:58,400
that you want to add on the consumer

586
00:20:58,400 --> 00:21:00,449
side. So if

587
00:21:00,449 --> 00:21:03,219
you constantly receive more messages

588
00:21:03,400 --> 00:21:05,430
than you can actually consume,

589
00:21:05,680 --> 00:21:07,098
your queue will start

590
00:21:07,479 --> 00:21:08,299
to fill up.

591
00:21:09,309 --> 00:21:11,789
This is actually not a problem or a disadvantage

592
00:21:11,789 --> 00:21:14,309
of cues. You would have that problem

593
00:21:14,309 --> 00:21:16,509
anyway, but cues makes this

594
00:21:16,509 --> 00:21:18,890
actually visible, so you can

595
00:21:19,029 --> 00:21:20,979
then do something about it.

596
00:21:21,390 --> 00:21:23,779
So that's a very, a very positive

597
00:21:23,779 --> 00:21:24,910
characteristic here.

598
00:21:25,848 --> 00:21:26,390
So

599
00:21:27,009 --> 00:21:29,170
I said load shedding and back pressure, load

600
00:21:29,170 --> 00:21:31,729
shedding with queues sounds quite brutal.

601
00:21:32,009 --> 00:21:34,049
You can just throw away messages

602
00:21:34,049 --> 00:21:35,838
that have reached a certain age.

603
00:21:36,170 --> 00:21:38,229
You wouldn't want to do this blindly,

604
00:21:38,598 --> 00:21:41,568
but let's imagine in our ride booking scenario

605
00:21:41,890 --> 00:21:43,289
you might have an ETA

606
00:21:43,890 --> 00:21:46,088
or an SLA rather that says,

607
00:21:46,130 --> 00:21:47,420
OK, dear customer,

608
00:21:47,809 --> 00:21:50,209
we guarantee within 5 minutes your booking is

609
00:21:50,209 --> 00:21:52,519
processed. If a message

610
00:21:52,519 --> 00:21:54,709
related to that is in the queue for more than 10

611
00:21:54,709 --> 00:21:55,660
minutes already,

612
00:21:56,160 --> 00:21:57,729
you can probably throw it away

613
00:21:58,130 --> 00:22:00,160
because the customer is not interested

614
00:22:00,559 --> 00:22:02,680
anymore. But probably you don't

615
00:22:02,680 --> 00:22:05,009
want to apply this blindly. An important

616
00:22:05,009 --> 00:22:07,489
thing to mention here is also this is

617
00:22:07,489 --> 00:22:09,689
rather a business decision and

618
00:22:09,689 --> 00:22:12,130
not a technical decision, so the person

619
00:22:12,130 --> 00:22:14,209
who owns this use case, this

620
00:22:14,209 --> 00:22:14,828
feature,

621
00:22:15,088 --> 00:22:17,250
needs to decide, when can we

622
00:22:17,250 --> 00:22:19,890
consider a message stale and

623
00:22:19,890 --> 00:22:22,108
should probably throw it away.

624
00:22:23,199 --> 00:22:25,239
Now back pressure is on the other

625
00:22:25,239 --> 00:22:27,358
hand a signal that you can send to

626
00:22:27,358 --> 00:22:29,219
your producers to slow down.

627
00:22:29,979 --> 00:22:32,098
In the ideal case, you

628
00:22:32,098 --> 00:22:34,380
send it all the way up to the end user client

629
00:22:34,380 --> 00:22:35,969
and keep the end user client

630
00:22:36,299 --> 00:22:38,739
from sending more requests, but

631
00:22:38,739 --> 00:22:40,818
also the business requirements might

632
00:22:40,818 --> 00:22:41,660
not allow it.

633
00:22:42,588 --> 00:22:44,670
Alex has shared already how you can apply

634
00:22:44,670 --> 00:22:46,608
the back pressure on API level

635
00:22:47,068 --> 00:22:49,279
if you want to apply it also on the

636
00:22:49,279 --> 00:22:50,019
producer level.

637
00:22:50,309 --> 00:22:52,509
You need to have access to the producers

638
00:22:52,509 --> 00:22:54,630
and you have to add some codes that

639
00:22:54,630 --> 00:22:56,358
reacts to signals on it.

640
00:22:56,868 --> 00:22:58,719
Now, on the other hand,

641
00:22:59,269 --> 00:23:01,578
what are you doing with this

642
00:23:01,578 --> 00:23:03,670
information as a producer while still

643
00:23:03,670 --> 00:23:05,789
more requests are coming in and you get a

644
00:23:05,789 --> 00:23:08,108
signal from downstream, you should slow

645
00:23:08,108 --> 00:23:10,368
down. That alone is a

646
00:23:10,630 --> 00:23:12,989
daylong, weeklong business discussion

647
00:23:12,989 --> 00:23:13,689
probably,

648
00:23:13,989 --> 00:23:16,189
and it can fill several

649
00:23:16,189 --> 00:23:18,309
talks. Parts of it are being

650
00:23:18,309 --> 00:23:20,318
covered in the other

651
00:23:20,469 --> 00:23:21,989
patterns that we're now looking at.

652
00:23:23,640 --> 00:23:25,838
And you can combine load shedding and back

653
00:23:25,838 --> 00:23:27,920
pressure with all the other patterns that

654
00:23:27,920 --> 00:23:28,890
we are now looking at.

655
00:23:29,239 --> 00:23:31,358
Alex, I have decided I will

656
00:23:31,358 --> 00:23:33,459
make it very simple for myself

657
00:23:33,719 --> 00:23:35,959
and just create a single tenant

658
00:23:35,959 --> 00:23:37,650
queue for each of my tenants.

659
00:23:38,239 --> 00:23:40,358
With that, I only have to add some

660
00:23:40,358 --> 00:23:42,539
engineering when a new tenant is

661
00:23:42,539 --> 00:23:44,838
on boarding. I need to set up the dedicated

662
00:23:44,838 --> 00:23:46,059
infrastructure for it.

663
00:23:46,640 --> 00:23:47,479
Not only the queue,

664
00:23:47,750 --> 00:23:50,029
probably also producers and

665
00:23:50,029 --> 00:23:50,759
consumers,

666
00:23:51,150 --> 00:23:53,239
and then while I'm running my

667
00:23:53,239 --> 00:23:55,660
application, I only need to multiply

668
00:23:55,660 --> 00:23:58,009
everything I'm doing with the number of tenants.

669
00:23:58,160 --> 00:23:59,019
Does that sound great?

670
00:24:00,219 --> 00:24:02,049
I'm not sure. When I think about it

671
00:24:02,430 --> 00:24:03,449
a little bit more,

672
00:24:04,509 --> 00:24:06,650
maybe it's not the best idea.

673
00:24:06,949 --> 00:24:08,930
Also from a cost perspective,

674
00:24:09,709 --> 00:24:11,868
you want to have an insight into

675
00:24:11,868 --> 00:24:14,068
the queue. You want to make sure that messages

676
00:24:14,068 --> 00:24:15,489
are being consumed from the queue.

677
00:24:15,868 --> 00:24:17,979
If you have tenants that are not

678
00:24:17,979 --> 00:24:20,088
super busy but rather idle, you still

679
00:24:20,259 --> 00:24:22,479
have to look into the queue to pull off

680
00:24:22,479 --> 00:24:24,828
the messages. So you constantly have to operate

681
00:24:24,828 --> 00:24:25,848
on the compute,

682
00:24:26,390 --> 00:24:27,529
so that's quite wasteful.

683
00:24:28,118 --> 00:24:28,989
And

684
00:24:29,368 --> 00:24:31,430
this waste is being multiplied

685
00:24:31,729 --> 00:24:33,848
with the number of tenants that you have, with

686
00:24:33,848 --> 00:24:35,430
the scale that you have, so

687
00:24:35,848 --> 00:24:37,368
maybe not the best idea.

688
00:24:38,539 --> 00:24:40,299
Maybe we shouldn't go into extremes.

689
00:24:40,779 --> 00:24:42,939
We have a broad spectrum maybe, and

690
00:24:42,939 --> 00:24:45,019
we looked so far at the one end where we

691
00:24:45,019 --> 00:24:47,439
had one multi-tenant queue for all of the tenants

692
00:24:47,739 --> 00:24:49,779
and at the other end of the spectrum

693
00:24:49,779 --> 00:24:50,479
where we had

694
00:24:50,818 --> 00:24:53,140
multiple STQs for each of

695
00:24:53,140 --> 00:24:53,900
our tenants.

696
00:24:54,180 --> 00:24:56,068
Alex, is there something in between? Maybe?

697
00:24:56,459 --> 00:24:57,598
Let's see. It's a good question.

698
00:24:58,269 --> 00:25:00,400
Because again I mean you said it at the

699
00:25:00,400 --> 00:25:02,549
beginning, in the end it's a trade off between

700
00:25:02,549 --> 00:25:04,670
several patterns that we can apply and we can show

701
00:25:04,670 --> 00:25:06,689
some that we've seen in reality

702
00:25:06,910 --> 00:25:08,949
which are a bit more elaborate but would maybe fit in

703
00:25:08,949 --> 00:25:10,989
the middle of this spectrum.

704
00:25:11,430 --> 00:25:13,209
So let's look at some of them. One would be

705
00:25:13,670 --> 00:25:16,180
a pattern or an approach called cell shing.

706
00:25:16,670 --> 00:25:18,868
The idea here is that rather than having a

707
00:25:18,868 --> 00:25:21,150
multi-tenant queue for everybody or a single tenant

708
00:25:21,150 --> 00:25:23,309
queue for each individual tenant,

709
00:25:23,390 --> 00:25:25,469
you would share queues between several

710
00:25:25,469 --> 00:25:26,068
tenants.

711
00:25:26,559 --> 00:25:28,559
And the idea here is basically that you reduce the

712
00:25:28,559 --> 00:25:30,519
overhead of the infrastructure deployment.

713
00:25:31,318 --> 00:25:33,568
And at the same time still have the reduction

714
00:25:33,568 --> 00:25:35,588
of the blast radius. So for instance,

715
00:25:35,608 --> 00:25:38,049
if two tenants would share a queue

716
00:25:38,368 --> 00:25:40,529
and tenant 1 would become

717
00:25:40,529 --> 00:25:42,390
a noisy neighbor,

718
00:25:43,049 --> 00:25:45,088
then the only affected other tenant would

719
00:25:45,088 --> 00:25:46,189
be tenant 2.

720
00:25:46,689 --> 00:25:48,689
Still bad enough for them, but if you

721
00:25:48,689 --> 00:25:51,130
think about a, let's say operational scenario

722
00:25:51,130 --> 00:25:53,250
where you need to investigate and address

723
00:25:53,250 --> 00:25:55,279
this and reach out to customers,

724
00:25:55,650 --> 00:25:57,689
then you would have much less headache if you just

725
00:25:57,689 --> 00:25:59,910
had to talk to two tenants than everybody.

726
00:26:01,059 --> 00:26:03,549
So this is a valid approach that we've seen in practice.

727
00:26:03,989 --> 00:26:06,049
Again, it's a trade-off between

728
00:26:06,068 --> 00:26:08,068
the simplicity of a shared queue

729
00:26:08,068 --> 00:26:10,189
versus the complexity overhead here

730
00:26:10,189 --> 00:26:11,828
and the reduction of blast radius,

731
00:26:12,150 --> 00:26:13,969
but we can take this even one step further.

732
00:26:14,959 --> 00:26:17,009
Another pattern that we've seen in practice is

733
00:26:17,009 --> 00:26:18,209
called shovel sharing.

734
00:26:18,880 --> 00:26:21,039
It looks a bit similar like the one we've seen before. We

735
00:26:21,039 --> 00:26:23,309
again have tenants distributing into queues,

736
00:26:23,598 --> 00:26:25,640
but here it's a bit of the other way around. So

737
00:26:25,640 --> 00:26:26,699
rather than sharing

738
00:26:27,118 --> 00:26:29,160
one queue between 2 or 3

739
00:26:29,160 --> 00:26:31,358
or 5 tenants or however you see

740
00:26:31,358 --> 00:26:33,368
fitting. Each tenant would

741
00:26:33,368 --> 00:26:35,368
write into multiple queues, so in this

742
00:26:35,368 --> 00:26:37,689
case you would see that one tenant writes

743
00:26:37,689 --> 00:26:38,729
into two queues.

744
00:26:39,130 --> 00:26:41,449
What's important to understand here is that you need to monitor

745
00:26:41,449 --> 00:26:43,489
queues because the idea here is that

746
00:26:43,848 --> 00:26:45,920
you would monitor the size of the queue.

747
00:26:45,959 --> 00:26:47,969
You can do this with Cloudwa for

748
00:26:47,969 --> 00:26:50,049
instance, and if one queue fills

749
00:26:50,049 --> 00:26:52,049
up, the tenant would be writing into

750
00:26:52,049 --> 00:26:53,809
the other queue that they have at their disposal.

751
00:26:54,250 --> 00:26:56,289
You see here a mapping of I

752
00:26:56,289 --> 00:26:58,328
think 8 queues to 8 tenants, but of

753
00:26:58,328 --> 00:27:00,368
course you could have a higher number of tenants writing

754
00:27:00,368 --> 00:27:01,568
into fewer queues.

755
00:27:01,890 --> 00:27:04,049
That really depends on the load

756
00:27:04,049 --> 00:27:05,650
patterns that you have in the architecture.

757
00:27:06,358 --> 00:27:08,549
Now what happens if one tenant becomes noisy?

758
00:27:08,640 --> 00:27:10,818
Let's say tenant 1 starts producing

759
00:27:10,818 --> 00:27:12,959
a lot of messages and fills up both of

760
00:27:12,959 --> 00:27:14,479
the cues they're allocated to.

761
00:27:15,338 --> 00:27:17,380
The good thing in this scenario is that 10

762
00:27:17,380 --> 00:27:18,039
and 2.

763
00:27:18,759 --> 00:27:20,838
would still have another cue they can write

764
00:27:20,838 --> 00:27:23,239
into and would not be affected

765
00:27:23,239 --> 00:27:23,939
from that

766
00:27:24,279 --> 00:27:25,598
noisy neighbor as such.

767
00:27:26,299 --> 00:27:28,420
The same is true for tenant 8 who, as you

768
00:27:28,420 --> 00:27:29,400
see in this

769
00:27:29,739 --> 00:27:31,900
would also be writing into a shared queue with tenant

770
00:27:31,900 --> 00:27:34,019
1, but again they have another one they can write

771
00:27:34,019 --> 00:27:36,140
into, so they also would not be

772
00:27:36,140 --> 00:27:38,449
affected unless they themselves or other tenants

773
00:27:38,449 --> 00:27:40,500
in the shared queues would become noisy neighbors.

774
00:27:40,660 --> 00:27:42,900
But the likelihood of that happening is

775
00:27:43,420 --> 00:27:45,660
considerably small. I think we calculated it it's

776
00:27:45,660 --> 00:27:47,858
for a set of 100 tenants sharing

777
00:27:47,858 --> 00:27:50,779
them, it's in the area of 0.02%

778
00:27:50,779 --> 00:27:51,900
of likelihood happening.

779
00:27:52,180 --> 00:27:53,969
So this is a very resilient pattern.

780
00:27:54,259 --> 00:27:55,858
It comes with an overhead.

781
00:27:56,799 --> 00:27:58,959
Of having to monitor the queues of course of setting

782
00:27:58,959 --> 00:28:00,430
them up and maintaining them

783
00:28:00,809 --> 00:28:02,890
as you on board new tenants, you will have to

784
00:28:02,890 --> 00:28:05,088
review if the setup is still enough so there is

785
00:28:05,088 --> 00:28:07,289
some maintenance and

786
00:28:07,289 --> 00:28:09,309
engineering overhead involved, but it can help you

787
00:28:09,309 --> 00:28:11,328
to not run into the overhead of having

788
00:28:11,328 --> 00:28:13,368
all the consumers, all the queues for each

789
00:28:13,368 --> 00:28:15,439
tenant. Now

790
00:28:15,979 --> 00:28:18,098
this, the, the previous two patterns and

791
00:28:18,098 --> 00:28:20,199
actually also the multi-tenant single tenant queues

792
00:28:20,199 --> 00:28:22,338
assume that all tenants are treated equally.

793
00:28:23,059 --> 00:28:23,799
Which is nice,

794
00:28:24,068 --> 00:28:26,549
but in business we may have different

795
00:28:26,549 --> 00:28:28,449
pricing models, we may have tiers,

796
00:28:28,868 --> 00:28:30,949
and in that scenario we could say actually we

797
00:28:30,949 --> 00:28:33,459
combine this in a different way. So rather than

798
00:28:33,459 --> 00:28:35,910
having this kind of cell charding and shuffle charing

799
00:28:35,910 --> 00:28:36,430
approaches,

800
00:28:36,750 --> 00:28:38,009
we would say simply.

801
00:28:38,789 --> 00:28:40,789
For premium customers, we would have

802
00:28:40,789 --> 00:28:42,910
a dedicated queue and they would not be

803
00:28:42,910 --> 00:28:44,269
affected by noisy neighbors,

804
00:28:44,549 --> 00:28:45,368
whereas for

805
00:28:45,670 --> 00:28:47,828
basic tier customers you would have

806
00:28:47,828 --> 00:28:49,828
those shared infrastructure assuming also that they

807
00:28:49,828 --> 00:28:51,910
don't have that many messages to produce

808
00:28:52,140 --> 00:28:53,549
and everybody could be happy.

809
00:28:54,068 --> 00:28:56,150
So this is also a valid approach again has

810
00:28:56,150 --> 00:28:58,650
some engineering overhead, but it would scale

811
00:28:58,650 --> 00:29:00,750
with the customers that also

812
00:29:00,750 --> 00:29:01,989
pay for those services.

813
00:29:03,509 --> 00:29:04,088
So

814
00:29:04,630 --> 00:29:06,670
this is quite static approach, but it

815
00:29:06,670 --> 00:29:08,750
helps you to build this out. It would be cool

816
00:29:08,750 --> 00:29:10,689
if we could do this a bit more dynamically, right?

817
00:29:11,390 --> 00:29:11,959
Indeed,

818
00:29:12,410 --> 00:29:13,618
let me look at it. Yes, please.

819
00:29:14,439 --> 00:29:15,049
All right.

820
00:29:15,858 --> 00:29:17,900
So we can actually build on

821
00:29:17,900 --> 00:29:20,019
this approach and look

822
00:29:20,019 --> 00:29:22,160
at a dynamic version of this.

823
00:29:23,269 --> 00:29:25,650
Imagine during runtime, the

824
00:29:25,650 --> 00:29:26,489
producers

825
00:29:26,789 --> 00:29:28,989
can have an insight into the

826
00:29:28,989 --> 00:29:31,009
fact that in this case 10 and 2

827
00:29:31,348 --> 00:29:33,650
became a noisy neighbor through monitoring,

828
00:29:33,670 --> 00:29:34,348
for instance.

829
00:29:34,868 --> 00:29:37,989
Then the producers can autonomously

830
00:29:37,989 --> 00:29:38,568
decide

831
00:29:38,910 --> 00:29:41,269
to create a producer

832
00:29:41,269 --> 00:29:43,229
controlled, in this case overflow queue.

833
00:29:44,750 --> 00:29:46,969
Apparently the consumers also need to know

834
00:29:46,969 --> 00:29:49,118
about it. That means there needs to be

835
00:29:49,118 --> 00:29:51,439
a signal from the producer side

836
00:29:51,439 --> 00:29:53,618
down to the consumer side

837
00:29:53,880 --> 00:29:55,880
to indicate, hey, there is now

838
00:29:55,880 --> 00:29:57,259
this additional queue

839
00:29:57,559 --> 00:29:59,660
for this current noisy neighbor

840
00:29:59,660 --> 00:30:02,180
situation. Please also consume

841
00:30:02,439 --> 00:30:03,078
from there.

842
00:30:04,059 --> 00:30:04,920
This opens up

843
00:30:05,459 --> 00:30:06,838
a lot of questions

844
00:30:07,219 --> 00:30:08,838
again on the consumer side.

845
00:30:10,660 --> 00:30:12,739
When we when we receive the signal, hey, we

846
00:30:12,739 --> 00:30:14,959
should also now consume from that overflow

847
00:30:14,959 --> 00:30:16,588
queue, what does that mean?

848
00:30:16,939 --> 00:30:18,939
Should I do it in a round robin way with

849
00:30:18,939 --> 00:30:20,979
the main cube? Should I prefer

850
00:30:20,979 --> 00:30:23,140
one over the other? Who decides

851
00:30:23,140 --> 00:30:25,140
that? So there's several

852
00:30:25,140 --> 00:30:26,799
decisions that we need to take.

853
00:30:27,630 --> 00:30:29,910
Another thing that I personally dislike

854
00:30:29,910 --> 00:30:31,910
a little bit with this approach is

855
00:30:31,910 --> 00:30:33,769
that we now have again

856
00:30:34,068 --> 00:30:36,509
the direct connectivity between

857
00:30:36,509 --> 00:30:38,598
producers and consumers while

858
00:30:38,598 --> 00:30:40,630
we actually wanted to get

859
00:30:40,630 --> 00:30:42,689
rid of it in the first place

860
00:30:42,858 --> 00:30:44,469
by the introduction of cues.

861
00:30:45,818 --> 00:30:46,449
And then

862
00:30:46,750 --> 00:30:48,949
another question on the consumer side actually

863
00:30:48,949 --> 00:30:50,989
is, would we reuse

864
00:30:50,989 --> 00:30:52,500
the current consumer fleet or would we actually

865
00:30:54,469 --> 00:30:56,568
create some overflow consumers?

866
00:30:57,318 --> 00:30:59,400
Well, from a SAS um pricing and

867
00:30:59,400 --> 00:31:00,608
packaging perspective,

868
00:31:01,039 --> 00:31:01,699
you can

869
00:31:02,078 --> 00:31:04,588
make up your mind also in such a

870
00:31:04,588 --> 00:31:06,848
situation, would I um charge

871
00:31:06,848 --> 00:31:09,039
that particular tenant an extra

872
00:31:09,039 --> 00:31:09,578
cost

873
00:31:09,880 --> 00:31:12,239
for that because we have some effort.

874
00:31:13,640 --> 00:31:16,118
You can maybe do the same from

875
00:31:16,118 --> 00:31:18,279
the other way around, a consumer controlled

876
00:31:18,279 --> 00:31:19,338
overflow queue,

877
00:31:19,719 --> 00:31:21,900
because there are situations where

878
00:31:22,160 --> 00:31:24,439
the noisy neighbor situation isn't

879
00:31:24,439 --> 00:31:26,640
detected really from the producer

880
00:31:26,640 --> 00:31:29,078
side by a lot of requests additionally

881
00:31:29,078 --> 00:31:29,630
coming in,

882
00:31:29,959 --> 00:31:32,078
but maybe from the consumer side. If you

883
00:31:32,078 --> 00:31:34,479
run into a situation where the actual

884
00:31:34,479 --> 00:31:36,670
message processing takes more

885
00:31:36,670 --> 00:31:37,818
time than expected

886
00:31:38,118 --> 00:31:40,539
or you receive an increased error rate

887
00:31:40,989 --> 00:31:43,118
from those consumer processing parts.

888
00:31:43,650 --> 00:31:45,759
In that case, the consumers

889
00:31:45,939 --> 00:31:48,019
can actually do the similar thing

890
00:31:48,219 --> 00:31:50,459
and also trigger that

891
00:31:50,459 --> 00:31:53,039
an overflow queue is created for

892
00:31:53,219 --> 00:31:55,338
this noisy neighbor, and now

893
00:31:55,338 --> 00:31:57,338
the consumers need to send

894
00:31:57,338 --> 00:31:58,989
a signal to the producers,

895
00:31:59,259 --> 00:32:01,630
hey, please use this queue now also

896
00:32:01,858 --> 00:32:04,009
for all subsequent messages

897
00:32:04,019 --> 00:32:05,699
for tenant 2.

898
00:32:07,118 --> 00:32:07,680
Well

899
00:32:08,439 --> 00:32:09,739
then again,

900
00:32:10,160 --> 00:32:13,039
how do you balance on the consumer side with

901
00:32:13,039 --> 00:32:15,078
the two queues that you now have and maybe there's

902
00:32:15,078 --> 00:32:17,338
a third noisy neighbor and you have

903
00:32:17,489 --> 00:32:19,640
an overflow queue for that one

904
00:32:19,640 --> 00:32:21,799
too. There are tough

905
00:32:21,799 --> 00:32:24,140
decisions required here, so

906
00:32:24,680 --> 00:32:27,189
when would I use my

907
00:32:27,189 --> 00:32:29,500
consumer capacity for the main queue

908
00:32:29,759 --> 00:32:31,880
and when from the overflow queue so that

909
00:32:31,880 --> 00:32:32,699
I make sure

910
00:32:32,959 --> 00:32:35,098
I don't leave anyone back

911
00:32:35,098 --> 00:32:36,400
in starvation.

912
00:32:37,368 --> 00:32:40,118
Also, there's quite some engineering

913
00:32:40,130 --> 00:32:42,650
required here to do that dynamically

914
00:32:42,650 --> 00:32:44,650
create all that infrastructure and

915
00:32:44,650 --> 00:32:47,390
also make sure when the noisy neighbor

916
00:32:47,390 --> 00:32:49,608
situation is scaling down

917
00:32:49,608 --> 00:32:51,890
again that we don't throw away

918
00:32:51,890 --> 00:32:54,009
a queue while there are still messages in

919
00:32:54,009 --> 00:32:56,509
it. It can be quite hard to

920
00:32:56,729 --> 00:32:58,969
build this all and to

921
00:32:58,969 --> 00:33:00,699
decide on all those questions how to use my

922
00:33:02,150 --> 00:33:02,949
capacity.

923
00:33:03,608 --> 00:33:05,799
Alex, what do you think? Wouldn't it be nice

924
00:33:05,799 --> 00:33:07,809
if there was a cloud service that could

925
00:33:07,809 --> 00:33:10,029
just implement this for us

926
00:33:11,289 --> 00:33:12,229
and and leave it

927
00:33:12,729 --> 00:33:14,729
in a way that it still looks like

928
00:33:14,729 --> 00:33:16,848
one queue? Yes, it would be awesome. Not

929
00:33:16,848 --> 00:33:18,969
so much engineering effort, isn't that what the cloud is all about?

930
00:33:19,459 --> 00:33:20,618
Yes, that's right.

931
00:33:20,979 --> 00:33:23,500
So luckily this summer Amazon SQS

932
00:33:23,500 --> 00:33:24,890
Fair Ques has been launched,

933
00:33:25,180 --> 00:33:27,318
which is a feature that does exactly

934
00:33:27,318 --> 00:33:29,858
this for you. And from the standpoint

935
00:33:29,858 --> 00:33:32,529
of your producers and your consumers,

936
00:33:32,739 --> 00:33:34,739
you still work only on one

937
00:33:34,858 --> 00:33:36,900
queue under the hood. There are

938
00:33:36,900 --> 00:33:38,838
the overflow queues that

939
00:33:39,459 --> 00:33:40,479
do all the

940
00:33:41,019 --> 00:33:43,219
required engineering to solve

941
00:33:43,219 --> 00:33:45,259
this noisy neighbor problem for

942
00:33:45,259 --> 00:33:47,969
you. Looking

943
00:33:47,969 --> 00:33:50,098
at SQS, I mean, if

944
00:33:50,098 --> 00:33:53,039
you employ cues in your architecture,

945
00:33:53,689 --> 00:33:56,578
um, you shift a lot of operational responsibility

946
00:33:56,578 --> 00:33:58,180
to that messaging system, right?

947
00:33:58,539 --> 00:34:00,539
So you want to make sure that this is

948
00:34:00,539 --> 00:34:03,000
one that is highly scalable, available,

949
00:34:03,009 --> 00:34:03,699
and reliable.

950
00:34:04,180 --> 00:34:06,559
And in terms of scalability,

951
00:34:06,828 --> 00:34:08,949
I can mention a fun fact from Prime

952
00:34:08,949 --> 00:34:10,559
Day 2025.

953
00:34:10,909 --> 00:34:13,409
At peak, Amazon SQS handled

954
00:34:13,409 --> 00:34:15,429
166

955
00:34:15,429 --> 00:34:16,929
million messages

956
00:34:17,349 --> 00:34:19,978
per second, per second, exactly.

957
00:34:20,349 --> 00:34:21,708
So it is,

958
00:34:22,510 --> 00:34:24,449
it is for sure scalable.

959
00:34:25,570 --> 00:34:26,309
All right,

960
00:34:26,889 --> 00:34:27,489
now.

961
00:34:28,248 --> 00:34:30,157
We can continue with the next chapter.

962
00:34:31,168 --> 00:34:33,409
We solved the noisy neighbor problem on cues.

963
00:34:34,398 --> 00:34:36,438
Yeah, so keep that in mind again, combine the

964
00:34:36,438 --> 00:34:38,820
complexity of multi-tenant systems with

965
00:34:39,239 --> 00:34:41,820
the complexity of distributed architectures,

966
00:34:41,829 --> 00:34:43,918
and again cues are not the only way you

967
00:34:43,918 --> 00:34:46,320
can uh use different mechanisms. We have seen

968
00:34:46,320 --> 00:34:48,320
message buses. You will probably know about

969
00:34:48,320 --> 00:34:49,398
streaming systems.

970
00:34:49,789 --> 00:34:51,840
They help with decoupling and they underlie

971
00:34:51,840 --> 00:34:52,789
similar mechanisms.

972
00:34:53,280 --> 00:34:55,760
So, uh, again it could be a dedicated

973
00:34:55,760 --> 00:34:57,958
talk to talk about those as well, but this is a very

974
00:34:57,958 --> 00:34:58,719
powerful tool.

975
00:34:59,090 --> 00:35:01,179
And we can actually employ this also when we talk to

976
00:35:01,179 --> 00:35:03,500
external systems. So we have seen before

977
00:35:03,500 --> 00:35:05,500
in our example architecture

978
00:35:05,500 --> 00:35:07,760
that we call several external services

979
00:35:07,978 --> 00:35:10,449
and if you have built these types of

980
00:35:10,449 --> 00:35:12,539
applications, you probably know that dealing with payment

981
00:35:12,539 --> 00:35:14,659
service providers can be especially challenging.

982
00:35:15,090 --> 00:35:17,139
So in the next scenario, let's isolate

983
00:35:17,139 --> 00:35:19,300
some building blocks from the architecture and

984
00:35:19,300 --> 00:35:21,378
look a bit closer how the flow works here and how

985
00:35:21,378 --> 00:35:22,659
we can enhance that

986
00:35:22,929 --> 00:35:24,659
with the tooling that we have established.

987
00:35:25,550 --> 00:35:27,590
So assume that we have 3 contexts.

988
00:35:27,668 --> 00:35:30,110
One is the tenant context where we have a user app

989
00:35:30,110 --> 00:35:31,398
calling our booking flow,

990
00:35:31,869 --> 00:35:33,909
and of course at the end of this whole

991
00:35:33,909 --> 00:35:35,989
round trip we need to inform the finance system

992
00:35:35,989 --> 00:35:37,168
of a transaction being made.

993
00:35:37,949 --> 00:35:39,949
The whole thing will go through our booking flow, and we'll

994
00:35:39,949 --> 00:35:41,289
see in a second what we can do here,

995
00:35:42,228 --> 00:35:44,349
but the system we need to interact with is the

996
00:35:44,349 --> 00:35:46,239
payment processor of our PSP.

997
00:35:48,090 --> 00:35:50,340
As we have said, the PSP

998
00:35:50,340 --> 00:35:51,918
expects a synchronous call.

999
00:35:52,829 --> 00:35:55,000
We cannot do much about that. It might be that they

1000
00:35:55,000 --> 00:35:57,000
are able to send notifications, so maybe they

1001
00:35:57,000 --> 00:35:59,360
also do this 2001, 202

1002
00:35:59,360 --> 00:36:01,438
thing, um, but expect

1003
00:36:01,438 --> 00:36:03,559
that we cannot have them call from the queue.

1004
00:36:03,918 --> 00:36:06,000
But we can use queues ourselves within

1005
00:36:06,000 --> 00:36:08,219
our own context. We just need to proxy

1006
00:36:08,219 --> 00:36:09,559
the access to the queues.

1007
00:36:10,228 --> 00:36:12,519
So in this flow we would have a

1008
00:36:12,519 --> 00:36:14,668
request queue for the basically outbound

1009
00:36:14,668 --> 00:36:15,349
messages,

1010
00:36:15,719 --> 00:36:17,719
but because the payment service provider

1011
00:36:17,719 --> 00:36:19,878
doesn't even know what SQS is or our

1012
00:36:19,878 --> 00:36:21,148
dedicated cloud services,

1013
00:36:21,519 --> 00:36:23,760
we would have a little proxy service that is

1014
00:36:23,760 --> 00:36:25,918
just there to pull from our queue and

1015
00:36:25,918 --> 00:36:27,099
make a synchronous call.

1016
00:36:28,269 --> 00:36:30,429
This may seem a bit redundant, but the obvious

1017
00:36:30,429 --> 00:36:32,789
benefit here is that we don't have to implement

1018
00:36:32,789 --> 00:36:35,269
this within the booking flow and potential

1019
00:36:35,269 --> 00:36:36,250
breaks or

1020
00:36:36,668 --> 00:36:38,760
uh congestions would not affect the cure,

1021
00:36:38,769 --> 00:36:39,840
uh, booking flow,

1022
00:36:40,389 --> 00:36:42,389
but we would have a little, you know, imagine a

1023
00:36:42,389 --> 00:36:44,510
lambda that just pulls from the queue, does

1024
00:36:44,510 --> 00:36:45,739
the request,

1025
00:36:46,110 --> 00:36:48,228
and ideally would not have to wait

1026
00:36:48,228 --> 00:36:50,378
for it the whole processing time. So this is the,

1027
00:36:50,389 --> 00:36:52,550
uh, my wish scenario

1028
00:36:52,550 --> 00:36:54,708
that it could just notify me as soon as processing

1029
00:36:54,708 --> 00:36:57,079
is done. But if the payment

1030
00:36:57,079 --> 00:36:59,168
processor would say I will not only answer

1031
00:36:59,168 --> 00:37:00,059
synchronously,

1032
00:37:00,329 --> 00:37:02,809
then of course you might be using something like a container

1033
00:37:02,809 --> 00:37:04,889
and you would have of course the wait time

1034
00:37:05,478 --> 00:37:07,648
for the few seconds that the PSP needs

1035
00:37:07,648 --> 00:37:09,889
to respond to you and then of course instead of going

1036
00:37:09,889 --> 00:37:12,228
through the API gateway as in this example

1037
00:37:12,429 --> 00:37:14,489
you would just have the response

1038
00:37:14,489 --> 00:37:16,760
put in by the calling

1039
00:37:16,760 --> 00:37:18,309
service by your PSP proxy

1040
00:37:18,648 --> 00:37:20,969
and so this is a pattern where you would introduce a queue

1041
00:37:20,969 --> 00:37:23,389
on the way out to a different provider.

1042
00:37:23,789 --> 00:37:25,260
And basically

1043
00:37:25,750 --> 00:37:27,929
creating a proxy to their system

1044
00:37:28,110 --> 00:37:30,228
even though you would have to make a synchronous call

1045
00:37:30,228 --> 00:37:32,389
again. So

1046
00:37:32,389 --> 00:37:34,728
this is an example that assumes

1047
00:37:34,728 --> 00:37:36,269
that these flows always work.

1048
00:37:36,648 --> 00:37:38,168
It may be, uh, you know,

1049
00:37:39,389 --> 00:37:41,458
delays. There may be back

1050
00:37:41,458 --> 00:37:43,159
pressure coming from that other system,

1051
00:37:43,510 --> 00:37:45,789
but let's assume now that there is an outage

1052
00:37:45,789 --> 00:37:47,829
of the PSP, maybe even again a tenant

1053
00:37:47,829 --> 00:37:48,648
specific one.

1054
00:37:49,030 --> 00:37:51,070
So in that scenario we would not be able to

1055
00:37:51,070 --> 00:37:53,148
submit messages to the payment processor.

1056
00:37:54,059 --> 00:37:56,128
The way we could address this is by the

1057
00:37:56,128 --> 00:37:58,139
pattern of a dead letter queue. So the

1058
00:37:58,139 --> 00:38:00,139
idea is that you have another

1059
00:38:00,139 --> 00:38:00,780
queue

1060
00:38:01,378 --> 00:38:03,378
where messages that could not be processed

1061
00:38:03,378 --> 00:38:04,628
would land into

1062
00:38:04,969 --> 00:38:07,179
and would, for example, if it's about payments, could

1063
00:38:07,179 --> 00:38:09,300
go into a reconciliation service that once

1064
00:38:09,300 --> 00:38:11,378
daily just processes the

1065
00:38:11,378 --> 00:38:13,418
failed messages and tries to capture the payments.

1066
00:38:14,159 --> 00:38:16,599
In a multi-tenant system you could combine

1067
00:38:16,599 --> 00:38:18,619
this with the logic where you would say

1068
00:38:19,239 --> 00:38:21,309
not every tenant gets to benefit from that.

1069
00:38:21,478 --> 00:38:23,599
So let's say a user from a base tier

1070
00:38:23,599 --> 00:38:25,679
customer tries to make a booking, but

1071
00:38:25,679 --> 00:38:28,119
the payment doesn't go through for whatever reason, cannot

1072
00:38:28,119 --> 00:38:28,840
pay for the ride.

1073
00:38:29,199 --> 00:38:31,369
You might say I'm failing this, so it's

1074
00:38:31,369 --> 00:38:33,648
right now not possible, which is unfortunate for the user

1075
00:38:33,648 --> 00:38:35,688
experience, but it's the base tier, right, so you're

1076
00:38:35,688 --> 00:38:37,840
not having any large benefits from that, but

1077
00:38:37,840 --> 00:38:39,929
you could say premium customer has a bit of

1078
00:38:39,929 --> 00:38:40,708
store credit

1079
00:38:41,159 --> 00:38:43,449
and they would land in this reconciliation

1080
00:38:43,449 --> 00:38:45,449
service and you would say, OK, for now

1081
00:38:45,449 --> 00:38:47,869
you don't have to pay. I tried to capture it later

1082
00:38:48,199 --> 00:38:50,329
because you are our esteemed premium customer,

1083
00:38:50,449 --> 00:38:52,449
right, so you could have a tenant-based logic of

1084
00:38:52,449 --> 00:38:54,449
handling these kind of reconciliations.

1085
00:38:56,179 --> 00:38:58,418
Now I'm assuming we have captured the payment

1086
00:38:58,418 --> 00:39:00,559
and the last thing we need to do is get back

1087
00:39:00,559 --> 00:39:01,159
to the

1088
00:39:01,978 --> 00:39:02,760
original.

1089
00:39:03,938 --> 00:39:05,679
Or to the tenant's finance system,

1090
00:39:06,099 --> 00:39:08,219
how can we do that? So we have fulfilled the whole

1091
00:39:08,219 --> 00:39:10,418
flow, as you know, we have originally

1092
00:39:10,418 --> 00:39:12,760
established the authentication with the customer,

1093
00:39:13,369 --> 00:39:15,699
uh, but in order to find out the callback

1094
00:39:15,699 --> 00:39:18,369
to the finance system, we would have to make another database,

1095
00:39:18,418 --> 00:39:20,139
uh, call to get to the source of truth,

1096
00:39:20,458 --> 00:39:22,530
which is fine we could do that, but actually we

1097
00:39:22,530 --> 00:39:24,659
can go back to our little joint token

1098
00:39:24,659 --> 00:39:26,398
here and inject

1099
00:39:26,699 --> 00:39:28,699
the callback to our finance

1100
00:39:28,699 --> 00:39:29,760
system here as well.

1101
00:39:30,958 --> 00:39:33,039
What we do here effectively is rather than

1102
00:39:33,039 --> 00:39:35,079
convey that information to another system

1103
00:39:35,079 --> 00:39:37,418
is convey it to ourselves,

1104
00:39:37,519 --> 00:39:39,760
so we have a kind of a closed loop and a joint token

1105
00:39:39,760 --> 00:39:41,918
and just let us have this information

1106
00:39:41,918 --> 00:39:43,958
ourselves without having to retrieve it again

1107
00:39:43,958 --> 00:39:44,878
from the database.

1108
00:39:45,668 --> 00:39:48,090
And actually we can then use that to

1109
00:39:48,090 --> 00:39:49,969
access the webhook and make that call.

1110
00:39:50,349 --> 00:39:51,949
There's just one little problem here.

1111
00:39:53,099 --> 00:39:55,188
These jaw tokens are signed, and

1112
00:39:55,188 --> 00:39:57,300
we can be sure of the integrity of that

1113
00:39:57,300 --> 00:39:59,360
token. But if that

1114
00:39:59,360 --> 00:40:00,148
callback,

1115
00:40:00,639 --> 00:40:02,780
which is effectively an API call, contains

1116
00:40:02,780 --> 00:40:03,969
any kinds of tokens,

1117
00:40:04,438 --> 00:40:05,590
then this is unencrypted,

1118
00:40:06,219 --> 00:40:08,179
right? So we need to be very careful

1119
00:40:08,599 --> 00:40:10,599
if we put confidential information there.

1120
00:40:10,840 --> 00:40:12,878
Of course everything goes over HTPS and

1121
00:40:12,878 --> 00:40:14,918
whatnot, but there may be side

1122
00:40:14,918 --> 00:40:17,000
channel attacks. There may be

1123
00:40:17,000 --> 00:40:19,079
security flaws in the system of the

1124
00:40:19,079 --> 00:40:19,599
user.

1125
00:40:19,918 --> 00:40:22,079
There may be other ways to intercept that, so we need to be

1126
00:40:22,079 --> 00:40:23,159
careful what you do here.

1127
00:40:23,530 --> 00:40:25,820
And so it's important to emphasize if you

1128
00:40:25,820 --> 00:40:28,050
employ this jolt mechanism to

1129
00:40:28,050 --> 00:40:30,050
transform, transfer information

1130
00:40:30,050 --> 00:40:31,228
across your architecture

1131
00:40:31,489 --> 00:40:33,809
either within your own architecture or

1132
00:40:33,809 --> 00:40:34,750
with external

1133
00:40:35,610 --> 00:40:36,168
partners,

1134
00:40:36,489 --> 00:40:37,750
you need to not only

1135
00:40:38,188 --> 00:40:40,289
sign this message but ideally also encrypt it

1136
00:40:40,289 --> 00:40:42,429
and the good news is that there's a. Standard around

1137
00:40:42,429 --> 00:40:44,269
J, so most people know Jort,

1138
00:40:44,590 --> 00:40:46,590
but uh I'd like to show here that there's

1139
00:40:46,590 --> 00:40:48,030
a whole standard around that

1140
00:40:48,309 --> 00:40:50,449
that also has, as you see in the third line

1141
00:40:50,449 --> 00:40:52,119
encryption standard. So RFC

1142
00:40:52,708 --> 00:40:54,809
7516 allows you

1143
00:40:55,030 --> 00:40:57,128
to have encrypted J tokens, and if you employ

1144
00:40:57,128 --> 00:40:59,679
that mechanism to convey confidential

1145
00:40:59,679 --> 00:41:02,070
information and need secrecy

1146
00:41:02,070 --> 00:41:03,739
on top of veracity,

1147
00:41:04,110 --> 00:41:05,289
then you need to um.

1148
00:41:06,648 --> 00:41:08,780
Encrypted as well. The good thing is there are several

1149
00:41:08,780 --> 00:41:10,780
libraries that do that for you, so with a few lines

1150
00:41:10,780 --> 00:41:11,438
of code

1151
00:41:11,699 --> 00:41:14,119
you can build that out in your architecture.

1152
00:41:16,179 --> 00:41:18,418
Now this has been

1153
00:41:18,418 --> 00:41:20,610
several use cases where we talk about pipe,

1154
00:41:20,849 --> 00:41:23,099
sorry about cues and about draw tokens

1155
00:41:23,099 --> 00:41:24,280
to convey information,

1156
00:41:24,699 --> 00:41:27,019
but it might be that now we need to externalize

1157
00:41:27,019 --> 00:41:27,659
the state.

1158
00:41:28,559 --> 00:41:29,539
How would that work?

1159
00:41:30,039 --> 00:41:30,579
Let's see.

1160
00:41:32,320 --> 00:41:34,500
Um, to introduce that, uh, let's

1161
00:41:34,500 --> 00:41:36,668
have a look at another

1162
00:41:36,668 --> 00:41:38,708
complex integration pattern. It's

1163
00:41:38,708 --> 00:41:41,110
also a conversation pattern. It's

1164
00:41:41,110 --> 00:41:43,110
called the scatter gather pattern, one

1165
00:41:43,110 --> 00:41:44,329
of my favorite ones,

1166
00:41:44,789 --> 00:41:46,860
and, uh, it addresses the question

1167
00:41:46,860 --> 00:41:48,289
how can I distribute

1168
00:41:48,628 --> 00:41:50,728
a task to several parties

1169
00:41:50,728 --> 00:41:51,969
and afterwards

1170
00:41:52,269 --> 00:41:54,309
collect the result to find um

1171
00:41:54,309 --> 00:41:57,188
the best response or maybe aggregate those

1172
00:41:57,188 --> 00:41:57,829
responses.

1173
00:41:58,148 --> 00:42:00,769
How would that look like? We have that requester.

1174
00:42:01,289 --> 00:42:03,539
And here, since the same

1175
00:42:03,539 --> 00:42:04,719
request should go

1176
00:42:05,059 --> 00:42:07,378
to multiple downstream systems, the

1177
00:42:07,378 --> 00:42:09,579
recommendation would be to use a

1178
00:42:09,579 --> 00:42:11,739
publish subscribe messaging channel

1179
00:42:11,739 --> 00:42:14,010
here, for instance, Amazon SNS

1180
00:42:14,010 --> 00:42:16,260
topics, thinking again about shifting

1181
00:42:16,260 --> 00:42:18,398
the operational responsibility

1182
00:42:18,728 --> 00:42:20,780
to a third party system, and

1183
00:42:20,780 --> 00:42:22,958
Amazon SNS is capable

1184
00:42:22,958 --> 00:42:23,500
of that.

1185
00:42:24,128 --> 00:42:25,619
Now this message,

1186
00:42:26,079 --> 00:42:27,510
or those messages rather

1187
00:42:28,309 --> 00:42:30,409
reach all our responders. They can

1188
00:42:30,409 --> 00:42:32,668
work on their individual response

1189
00:42:32,889 --> 00:42:34,969
and send those responses

1190
00:42:34,969 --> 00:42:37,449
back to a response queue where

1191
00:42:37,449 --> 00:42:39,530
later than an aggregator in

1192
00:42:39,530 --> 00:42:41,289
the context of the requester

1193
00:42:41,610 --> 00:42:44,168
can do some aggregation and

1194
00:42:44,168 --> 00:42:46,208
there's a final processor for the

1195
00:42:46,208 --> 00:42:47,188
final processing.

1196
00:42:48,239 --> 00:42:48,840
So

1197
00:42:49,398 --> 00:42:51,559
again um this is about finding

1198
00:42:51,559 --> 00:42:53,719
the best of all responses

1199
00:42:53,719 --> 00:42:54,699
or finding

1200
00:42:55,030 --> 00:42:57,780
or creating um the accumulation

1201
00:42:57,780 --> 00:42:59,059
of all responses

1202
00:42:59,398 --> 00:43:01,530
that are coming in.

1203
00:43:02,289 --> 00:43:04,648
There's one thing, however, or actually

1204
00:43:04,648 --> 00:43:06,289
two things to help our patterns,

1205
00:43:06,648 --> 00:43:08,789
namely that we need to make sure

1206
00:43:09,090 --> 00:43:11,148
that also the responders

1207
00:43:11,148 --> 00:43:13,369
know where to send their response and

1208
00:43:13,369 --> 00:43:15,789
then also the aggregator and processor

1209
00:43:16,010 --> 00:43:18,208
systems afterwards can assign

1210
00:43:18,208 --> 00:43:19,898
those responses to a previous request,

1211
00:43:20,929 --> 00:43:23,128
which is. The correlation ID

1212
00:43:23,128 --> 00:43:25,250
and return address pattern that's

1213
00:43:25,250 --> 00:43:27,409
meta information that we inject

1214
00:43:27,409 --> 00:43:28,679
into the messages.

1215
00:43:28,969 --> 00:43:31,349
Here Message A contains an address

1216
00:43:31,349 --> 00:43:33,489
of that response queue and

1217
00:43:33,489 --> 00:43:35,489
a correlation ID that the

1218
00:43:35,489 --> 00:43:37,639
responders are asked to

1219
00:43:37,639 --> 00:43:39,188
also forward back into

1220
00:43:39,489 --> 00:43:40,530
their responses.

1221
00:43:41,208 --> 00:43:43,409
What is a practical use case for this actually?

1222
00:43:43,809 --> 00:43:45,648
So coming back to Wild Rides,

1223
00:43:46,010 --> 00:43:48,079
let's assume Wild Rides customers

1224
00:43:48,079 --> 00:43:49,070
are quite special.

1225
00:43:49,409 --> 00:43:51,708
They don't always want to just get

1226
00:43:51,728 --> 00:43:53,708
the next unicorn from around the corner.

1227
00:43:54,289 --> 00:43:56,369
Sometimes they also want to

1228
00:43:56,369 --> 00:43:58,309
ask for a quote

1229
00:43:58,570 --> 00:44:00,688
and ask the unicorns, hey, what is your

1230
00:44:00,688 --> 00:44:02,090
special offer that you have?

1231
00:44:02,449 --> 00:44:04,628
For instance, we're in Las Vegas this week.

1232
00:44:05,559 --> 00:44:08,039
Maybe there are unicorns that offer free

1233
00:44:08,039 --> 00:44:09,938
drinks during the ride or so,

1234
00:44:10,239 --> 00:44:12,398
and maybe a customer is interested

1235
00:44:12,398 --> 00:44:12,978
in that.

1236
00:44:13,438 --> 00:44:14,579
How would that look like

1237
00:44:15,159 --> 00:44:17,159
implementing the scatter gather pattern with a

1238
00:44:17,159 --> 00:44:18,539
concrete use case.

1239
00:44:18,800 --> 00:44:21,030
So again, we have the Wild Rides customers.

1240
00:44:21,199 --> 00:44:22,438
They use their app

1241
00:44:22,728 --> 00:44:25,260
and then it reaches the right booking service.

1242
00:44:25,559 --> 00:44:28,079
What happens here? So we have an intake

1243
00:44:28,079 --> 00:44:30,159
processor and now comes the state,

1244
00:44:30,320 --> 00:44:32,059
the external state into play.

1245
00:44:32,469 --> 00:44:34,639
Um, we, um, persist

1246
00:44:34,639 --> 00:44:36,539
the incoming request

1247
00:44:36,878 --> 00:44:39,438
and then we share it in

1248
00:44:39,438 --> 00:44:41,539
the right in the RFQ share topic

1249
00:44:41,878 --> 00:44:44,269
and only then we return to

1250
00:44:44,269 --> 00:44:45,559
the end user client

1251
00:44:45,840 --> 00:44:48,070
that we have accepted this

1252
00:44:48,079 --> 00:44:50,128
request. Under the hood, what

1253
00:44:50,128 --> 00:44:52,340
happens next? We have the unicorn

1254
00:44:52,340 --> 00:44:54,829
management service and then unicorn

1255
00:44:54,829 --> 00:44:57,099
management resources in there that

1256
00:44:57,099 --> 00:44:59,139
reflect each unicorn that is

1257
00:44:59,139 --> 00:45:01,378
in a certain vicinity, and they

1258
00:45:01,378 --> 00:45:03,378
receive a push notification, Hey, there's an

1259
00:45:03,378 --> 00:45:05,530
RFQ running. Are you interested to

1260
00:45:05,530 --> 00:45:06,280
participate?

1261
00:45:07,139 --> 00:45:08,559
They can make up their minds

1262
00:45:08,849 --> 00:45:11,099
about their individual um response,

1263
00:45:11,300 --> 00:45:13,378
send it back to the RFQ

1264
00:45:13,378 --> 00:45:15,500
response queue and where the response

1265
00:45:15,500 --> 00:45:17,760
aggregator stuffs it into

1266
00:45:17,760 --> 00:45:19,119
the RFQ store.

1267
00:45:19,579 --> 00:45:21,800
And then again we have the usual scenario

1268
00:45:22,188 --> 00:45:23,840
for end users how to track

1269
00:45:24,579 --> 00:45:25,849
the current status.

1270
00:45:26,179 --> 00:45:27,878
They can refresh

1271
00:45:29,019 --> 00:45:31,099
the current task status,

1272
00:45:31,378 --> 00:45:32,360
get an update

1273
00:45:32,780 --> 00:45:34,780
again with a link to refresh another time,

1274
00:45:34,860 --> 00:45:37,079
and eventually they will see

1275
00:45:37,340 --> 00:45:39,398
that the result is

1276
00:45:39,579 --> 00:45:41,958
ready with status done and can

1277
00:45:42,090 --> 00:45:43,800
retrieve it from the system.

1278
00:45:44,728 --> 00:45:47,369
And again this is a convenience functionality

1279
00:45:47,369 --> 00:45:49,429
that you want to add but of course,

1280
00:45:49,809 --> 00:45:51,969
you want to send a push notification

1281
00:45:51,969 --> 00:45:54,239
too. Now we

1282
00:45:54,239 --> 00:45:56,478
externalize the state in this

1283
00:45:56,478 --> 00:45:57,648
RFQ store.

1284
00:45:58,159 --> 00:46:00,280
So what do we need to take into account here,

1285
00:46:00,360 --> 00:46:00,938
Alex?

1286
00:46:01,478 --> 00:46:03,719
So first, I'm learning a lot about unicorns today. That's

1287
00:46:03,719 --> 00:46:05,019
really amazing what they can do,

1288
00:46:05,320 --> 00:46:06,829
very technical animals apparently.

1289
00:46:07,199 --> 00:46:09,438
So the important thing from an architectural perspective

1290
00:46:09,438 --> 00:46:11,519
is that we need to store it somewhere in a

1291
00:46:11,519 --> 00:46:12,719
highly scalable manner, right?

1292
00:46:13,119 --> 00:46:15,239
And for that, as you maybe have guessed by

1293
00:46:15,239 --> 00:46:17,438
the icon you see in the middle here, we are using a

1294
00:46:17,438 --> 00:46:19,478
key value database, in this case Dynamo DB.

1295
00:46:19,898 --> 00:46:22,099
And we will have a look at how we can do this

1296
00:46:22,099 --> 00:46:22,800
in a

1297
00:46:23,300 --> 00:46:25,340
single table design, which is the preferred

1298
00:46:25,340 --> 00:46:27,860
pattern to work with Dynamo DB databases,

1299
00:46:28,099 --> 00:46:29,800
but also in a multi-tenant way.

1300
00:46:30,570 --> 00:46:32,280
So first let's look at

1301
00:46:32,579 --> 00:46:34,809
an approach where you would have each tenant

1302
00:46:34,809 --> 00:46:37,019
with their own database, so it's not really multi-tenant

1303
00:46:37,019 --> 00:46:37,648
at this point,

1304
00:46:37,978 --> 00:46:40,199
but really just to simply recap

1305
00:46:40,199 --> 00:46:42,418
how you would do single table design with

1306
00:46:42,418 --> 00:46:43,099
Dynamo DB.

1307
00:46:44,590 --> 00:46:46,708
If you haven't worked with DynamoDB yet or

1308
00:46:46,708 --> 00:46:48,938
designed these kind of single table approaches, there

1309
00:46:48,938 --> 00:46:51,030
are a few concepts that you need to understand. So

1310
00:46:51,030 --> 00:46:52,570
unlike in a

1311
00:46:53,070 --> 00:46:55,148
relation database, we would normalize the

1312
00:46:55,148 --> 00:46:57,340
data and have several tables for each entity,

1313
00:46:57,668 --> 00:46:59,708
you would put all the data

1314
00:46:59,708 --> 00:47:01,050
objects into one table

1315
00:47:01,628 --> 00:47:03,668
and have them identified by a

1316
00:47:03,668 --> 00:47:05,929
combination of a partition key

1317
00:47:06,269 --> 00:47:07,168
and a sort key.

1318
00:47:07,760 --> 00:47:10,219
So these are the identifiers for your entries

1319
00:47:10,219 --> 00:47:12,418
and then of course you would have the

1320
00:47:12,429 --> 00:47:14,579
attributes or the key value pairs

1321
00:47:14,579 --> 00:47:16,599
in this entity or

1322
00:47:16,599 --> 00:47:18,750
entry. So this is

1323
00:47:18,750 --> 00:47:21,168
basically when we talk about unicorns

1324
00:47:21,168 --> 00:47:22,659
submitting their offer,

1325
00:47:23,030 --> 00:47:25,228
we could have the RFQ itself as

1326
00:47:25,228 --> 00:47:27,289
one row, so we store here

1327
00:47:27,289 --> 00:47:29,648
as an ID for the request for a quote

1328
00:47:29,869 --> 00:47:31,750
and then each unicorn would submit it.

1329
00:47:32,429 --> 00:47:34,750
Technically speaking, what we are doing here in this

1330
00:47:34,750 --> 00:47:36,750
design is we put the ID of the

1331
00:47:36,750 --> 00:47:38,789
RFQ into a partition key.

1332
00:47:39,699 --> 00:47:41,969
And we put the type of

1333
00:47:41,969 --> 00:47:44,000
the message or the entry

1334
00:47:44,000 --> 00:47:46,090
into the sort key and if it is

1335
00:47:46,090 --> 00:47:48,168
an offer we separate it through a

1336
00:47:48,168 --> 00:47:49,148
hash symbol

1337
00:47:49,438 --> 00:47:51,489
and then we add the idea of unicorn

1338
00:47:51,489 --> 00:47:52,628
submitting that offer

1339
00:47:53,019 --> 00:47:55,090
and this allows us to use

1340
00:47:55,090 --> 00:47:57,260
the query patterns that we need for the scatter

1341
00:47:57,260 --> 00:47:59,489
uh um gather scatter gather

1342
00:47:59,489 --> 00:48:00,219
approach sorry

1343
00:48:00,918 --> 00:48:03,050
uh in order to work. So these are typically two

1344
00:48:03,050 --> 00:48:05,239
requests we need to get a single RFQ in

1345
00:48:05,239 --> 00:48:07,429
order to represent that in a user context

1346
00:48:07,769 --> 00:48:09,228
and as soon as offers come in.

1347
00:48:10,000 --> 00:48:11,418
We may need to get all

1348
00:48:12,110 --> 00:48:14,519
um offers that belong to one RFQ

1349
00:48:14,519 --> 00:48:15,458
and you see here

1350
00:48:15,958 --> 00:48:18,079
that if this is for a single RFQ we

1351
00:48:18,079 --> 00:48:20,628
just call by the identity of the

1352
00:48:20,628 --> 00:48:22,139
partition key and the sort key

1353
00:48:22,559 --> 00:48:24,639
and you see that we can use the

1354
00:48:24,639 --> 00:48:26,639
begins with syntax that we start

1355
00:48:26,639 --> 00:48:27,699
to request

1356
00:48:28,409 --> 00:48:30,119
to get all offers for one RFQ.

1357
00:48:30,918 --> 00:48:33,000
So this is very nice, it works quite nicely. This would

1358
00:48:33,000 --> 00:48:34,099
be the

1359
00:48:34,599 --> 00:48:37,030
kind of a similar thing like a

1360
00:48:37,128 --> 00:48:38,159
per tenant queue.

1361
00:48:38,809 --> 00:48:40,949
But again it doesn't scale very well when we need

1362
00:48:40,949 --> 00:48:43,030
to onboard customers and create new

1363
00:48:43,030 --> 00:48:43,878
tables every time.

1364
00:48:44,349 --> 00:48:46,429
So ideally we can apply this single table

1365
00:48:46,429 --> 00:48:47,889
design in multi-tenant way

1366
00:48:48,228 --> 00:48:50,269
and actually that's not super difficult because we

1367
00:48:50,269 --> 00:48:52,269
don't need to change much. We just need to

1368
00:48:52,269 --> 00:48:54,030
add the tenant ID

1369
00:48:54,429 --> 00:48:55,849
to the partition key here

1370
00:48:56,188 --> 00:48:58,188
and this would work quite nicely so problem

1371
00:48:58,188 --> 00:48:58,869
solved forever.

1372
00:48:59,269 --> 00:49:01,269
I don't know. There's one problem with that. So

1373
00:49:01,269 --> 00:49:03,550
it would technically work you see here that the

1374
00:49:03,550 --> 00:49:05,590
access patterns are not very different from the queries

1375
00:49:05,590 --> 00:49:06,289
we had before.

1376
00:49:06,989 --> 00:49:07,659
One thing

1377
00:49:08,000 --> 00:49:10,079
that is still important in a multi-tenant

1378
00:49:10,079 --> 00:49:12,280
environment is tenant isolation for

1379
00:49:12,280 --> 00:49:13,688
security reasons or for others.

1380
00:49:14,159 --> 00:49:14,860
So what we

1381
00:49:15,199 --> 00:49:17,320
lose here as a trade-off with this approach

1382
00:49:17,320 --> 00:49:19,739
is the data isolation.

1383
00:49:20,050 --> 00:49:22,340
So when a tenant

1384
00:49:22,559 --> 00:49:23,458
would go rogue

1385
00:49:23,878 --> 00:49:25,958
and it would maybe breach the security

1386
00:49:25,958 --> 00:49:27,958
of the querying system, it could

1387
00:49:27,958 --> 00:49:29,360
access data from other tenants.

1388
00:49:29,918 --> 00:49:32,599
So we could, and again this is an architectural

1389
00:49:32,599 --> 00:49:33,519
decision we have to make.

1390
00:49:34,708 --> 00:49:36,708
Also built this in a slightly different way, and

1391
00:49:36,708 --> 00:49:38,789
this would be we put the tenant ID as

1392
00:49:38,789 --> 00:49:40,789
the sole partition key and would

1393
00:49:40,789 --> 00:49:43,050
have all other information about the RFQ

1394
00:49:43,050 --> 00:49:45,489
ID, about the unicorns and their offers

1395
00:49:45,750 --> 00:49:46,708
into the sort key.

1396
00:49:47,659 --> 00:49:49,958
This would work almost there as well.

1397
00:49:50,648 --> 00:49:52,809
And you could now use identity

1398
00:49:52,809 --> 00:49:54,889
access management as you see on the right hand side of

1399
00:49:54,889 --> 00:49:56,889
the table in order to have a role

1400
00:49:56,889 --> 00:49:58,949
level isolation of these entries,

1401
00:49:59,039 --> 00:50:01,289
and now you could say each tenant only

1402
00:50:01,289 --> 00:50:03,610
gets to see their data based on the assumption

1403
00:50:03,610 --> 00:50:05,349
that the request would be made with this

1404
00:50:05,849 --> 00:50:06,570
identity.

1405
00:50:08,239 --> 00:50:10,179
There's however, another problem here,

1406
00:50:10,878 --> 00:50:12,918
especially when you use different types of

1407
00:50:12,918 --> 00:50:15,280
key value stores, and this is called hot partitions.

1408
00:50:16,019 --> 00:50:18,309
A hot partition um is

1409
00:50:18,309 --> 00:50:20,708
when, as you see here we have the uh partition

1410
00:50:20,708 --> 00:50:22,909
key. If a lot of entries

1411
00:50:22,909 --> 00:50:25,030
go into one partition key and create

1412
00:50:25,030 --> 00:50:27,289
because in the end it's stored physically somewhere,

1413
00:50:27,820 --> 00:50:30,070
um there are certain limitations. So first

1414
00:50:30,070 --> 00:50:31,809
there is a maximum partition size.

1415
00:50:32,889 --> 00:50:34,958
That is 10 gigabytes if I'm not

1416
00:50:34,958 --> 00:50:36,719
mistaken. And

1417
00:50:36,978 --> 00:50:38,079
it used to be

1418
00:50:38,579 --> 00:50:40,860
that if you have a lot of queries into

1419
00:50:40,860 --> 00:50:42,119
one partition key

1420
00:50:42,438 --> 00:50:44,539
that you would exceed your request

1421
00:50:44,539 --> 00:50:46,619
resources. The good thing is if you ever heard of

1422
00:50:46,619 --> 00:50:48,659
hot partitions, it's not that much of an

1423
00:50:48,659 --> 00:50:50,418
issue in Dynamo DB anymore

1424
00:50:50,699 --> 00:50:52,699
because Dynamo DB has a mechanism called

1425
00:50:52,699 --> 00:50:53,809
split for heat,

1426
00:50:54,208 --> 00:50:56,500
so it would automatically repartition

1427
00:50:56,500 --> 00:50:58,780
based on the frequency and volume of

1428
00:50:58,780 --> 00:50:59,599
requests coming in.

1429
00:51:00,128 --> 00:51:02,449
There may still be edge cases if you scale

1430
00:51:02,449 --> 00:51:04,809
very rapidly in new entries that the scaling

1431
00:51:04,809 --> 00:51:06,849
of the splitting mechanism takes a while to

1432
00:51:06,849 --> 00:51:07,889
do the partitioning.

1433
00:51:08,329 --> 00:51:10,639
So depending on your multi tenancy use case,

1434
00:51:10,648 --> 00:51:12,228
you may run into

1435
00:51:12,809 --> 00:51:14,849
aspects of hot partitions

1436
00:51:14,849 --> 00:51:16,969
and then you may need to go to the

1437
00:51:16,969 --> 00:51:18,250
design we've seen in previous slide

1438
00:51:18,519 --> 00:51:20,389
which would create much smaller partitions

1439
00:51:20,969 --> 00:51:23,059
so. This again leads

1440
00:51:23,059 --> 00:51:25,179
us to the realization that no

1441
00:51:25,179 --> 00:51:26,820
architecture is without trade-offs.

1442
00:51:27,179 --> 00:51:29,280
We showed you how to introduce

1443
00:51:29,280 --> 00:51:30,159
patterns

1444
00:51:30,489 --> 00:51:32,610
that are exchangeable at

1445
00:51:32,610 --> 00:51:34,090
several parts of architecture,

1446
00:51:34,378 --> 00:51:36,739
but in the end, each of these introductions

1447
00:51:36,739 --> 00:51:38,739
needs to be a conscious decision. You need to weigh

1448
00:51:38,739 --> 00:51:40,458
the trade-offs, the pros and cons,

1449
00:51:40,800 --> 00:51:42,860
ideally create an architecture decision record

1450
00:51:42,860 --> 00:51:45,000
so afterwards you know what has been done there,

1451
00:51:45,389 --> 00:51:47,458
and then you will choose the least painful

1452
00:51:47,458 --> 00:51:49,579
option. So we hoped that we were

1453
00:51:49,579 --> 00:51:51,659
able to give you some options when you design

1454
00:51:51,659 --> 00:51:53,739
those rather complex systems, the multi-tenant

1455
00:51:53,739 --> 00:51:54,760
distributed way.

1456
00:51:55,610 --> 00:51:57,739
And uh would like to uh thank you

1457
00:51:57,739 --> 00:51:58,958
so far,

1458
00:51:59,659 --> 00:52:01,780
but before that we would like to ask you

1459
00:52:01,780 --> 00:52:04,000
if you like this talk please rate it in the app that's very

1460
00:52:04,000 --> 00:52:04,829
important for us

1461
00:52:05,179 --> 00:52:07,699
and we have collected several more resources

1462
00:52:07,699 --> 00:52:09,820
for this session. So if you would like to learn more

1463
00:52:09,820 --> 00:52:11,840
about how to build SARS on AWS

1464
00:52:12,119 --> 00:52:14,179
with AWS services or maybe with uh

1465
00:52:14,179 --> 00:52:16,378
open source tools, there's a lot of talks

1466
00:52:16,378 --> 00:52:18,378
that we had at this reinvent at previous

1467
00:52:18,378 --> 00:52:19,030
sessions.

1468
00:52:19,539 --> 00:52:20,378
Thank you very much.

1469
00:52:20,699 --> 00:52:21,320
Thanks a lot.

