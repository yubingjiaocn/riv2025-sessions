# AWS re:Invent 2025 S3 Metadata 会议总结

## 会议概述

本次会议由 Amazon S3 产品经理 Ruhi Sud 和软件开发经理 Claire 共同主讲，重点介绍了 S3 Metadata（S3 元数据）这一创新功能如何解决企业面临的数据发现挑战。

随着数据呈指数级增长，Amazon S3 目前存储超过 500 万亿个对象（半个千万亿），加上生成式 AI 革命的到来，非结构化数据的价值急剧上升。然而，企业在快速识别、分类和访问数据集方面面临巨大挑战。传统的元数据解决方案通常存在同步问题、构建复杂、难以维护等痛点。

S3 Metadata 提供了一个全新的解决方案：自动从 S3 对象中提取元数据，并支持通过简单的 SQL 语句进行查询。该功能基于 Apache Iceberg 格式，存储在 S3 Table Buckets 中，完全自动化且始终保持最新状态。会议通过多个实际演示展示了如何使用 S3 Metadata 进行审计分析、存储管理、合规检查以及 AI 训练数据准备等场景，并介绍了如何通过自然语言（使用 Kiro CLI 和 MCP）查询元数据表。

## 详细时间线

### 开场与问题定义 (00:00 - 05:30)

00:00 - 会议开始，Ruhi Sud 欢迎参会者并介绍演讲主题

00:30 - 提出典型场景：数据科学家 Alice 需要在 2300 万个对象中查找已标记和处理的图像；安全团队需要列出所有包含敏感信息的对象以应对审计请求

01:45 - 明确核心问题：这不是数据问题，而是数据发现问题

02:00 - 介绍演讲者：Ruhi Sud（产品经理）和 Claire（软件开发经理）

02:30 - 概述会议议程：深入探讨数据发现挑战、展示 S3 Metadata 如何解决这些挑战、通过演示展示实际用例

### 数据发现挑战分析 (05:30 - 10:00)

05:30 - 讨论数据增长现状：数据增长速度超过 5 年前的想象，S3 现存储超过 500 万亿个对象

06:45 - 强调生成式 AI 革命改变了数据价值方程：非结构化数据（视频、图像、日志）成为价值数百万美元的潜在训练数据

07:30 - 指出核心挑战：无论是训练模型、微调还是构建 RAG 用例，都需要快速识别、分类和访问数据集

08:15 - 提出根本问题：如何大规模查找或访问可操作的数据集？答案是元数据

09:00 - 分析传统元数据解决方案的三大问题：存在于存储之外导致同步问题、构建和维护复杂、元数据必须保持最新（过时的元数据比没有元数据更糟糕）

### S3 Metadata 功能介绍 (10:00 - 18:00)

10:00 - 引入核心理念：如果元数据像 S3 一样工作会怎样？简单、可靠、可扩展

10:30 - 介绍 S3 Metadata：自动从 S3 对象提取元数据，可通过简单 SQL 语句查询

11:00 - 强调三大优势：捕获系统和自定义元数据、基于 Apache Iceberg 格式存储在 S3 Table Buckets、完全自动化

12:00 - 解释工作原理：在通用存储桶上添加配置，S3 自动设置托管的 S3 Table Bucket 并填充元数据表

13:00 - Claire 接管演讲，介绍两种元数据表类型

13:30 - Journal Table（日志表）：记录每个 PUT、DELETE、修改操作，像存储桶的审计日志和时间机器，几分钟内刷新，支持自动过期旧记录

15:00 - Live Inventory Table（实时清单表）：提供存储桶内容的详细视图，每个对象版本一行，每小时刷新，适合分析和报告

16:30 - 演示数据流：用户操作对象时，Journal Table 实时捕获；每小时运行作业将 Journal Table 的新行应用到 Inventory Table，生成新快照

### 元数据表架构详解 (18:00 - 25:00)

18:00 - 介绍元数据表架构：总共记录 21 种元数据类型

18:30 - 请求元数据（仅在 Journal Table 中）：记录类型、请求时间戳、请求者、源 IP

19:30 - 系统元数据（两个表中都有）：存储桶、键、对象大小、存储类、加密状态、多部分上传信息、加密算法

20:30 - 自定义元数据（两个表中都有）：用户定义的元数据或对象标签

21:00 - 解释表的三个关键特性：Apache Iceberg 格式、S3 Tables（存储在 S3 Table Buckets 中）、由 AWS 托管

22:00 - Apache Iceberg 优势：支持 SQL 查询、是 S3 中增长最快的数据类型之一、允许用户选择查询引擎、支持 PB 级数据和数十亿文件、支持时间旅行和模式演进

23:30 - S3 Tables 优势：性能提升 10 倍（相比存储在通用存储桶中的 Iceberg 表）、与 AWS Lake Formation 深度集成，提供行列级细粒度访问控制

24:30 - AWS 托管的含义：只有 S3 可以写入元数据表（确保准确性）、AWS 配置和控制维护操作（压缩、快照管理、未引用文件清理）

### 新功能发布与查询方式 (25:00 - 30:00)

25:00 - 宣布三种新的托管表类型：AWS CloudWatch Logs、SageMaker Unified Studio 资产元数据、S3 Lens 数据

26:00 - 介绍查询元数据表的三种方式：
  - AWS 分析服务（Athena、Redshift、SageMaker Unified Studio）
  - 支持 Iceberg REST Catalog 端点的开源引擎（DuckDB、Apache Spark、Flink、Trino）
  - MCP for S3 Tables（使用自然语言查询）

27:30 - 展示使用 Amazon QuickSight 可视化元数据的示例

### 用例 1：请求元数据 (30:00 - 38:00)

30:00 - 开始介绍三种元数据类型的用例

30:30 - 请求元数据用例：检查存储桶上的变化

31:00 - 场景：多个用户操作共享数据集，所有者想了解过去一天的变化

32:00 - 演示 SQL 查询：按源 IP 和请求者分组，了解谁在进行操作

33:30 - 深入场景：了解谁在删除数据
  - 未版本化存储桶：按记录类型过滤
  - 版本化存储桶：添加删除标记过滤器

35:00 - 展示如何查询被删除的具体数据（存储桶、键、版本 ID）

36:00 - 介绍恢复功能：对于启用版本控制的存储桶，可以通过删除删除标记来回滚删除请求

37:00 - 宣布上周发布的工具：使用 S3 Metadata 大规模回滚变更，通过查询元数据了解特定时间存在的版本，使用 S3 Batch Operations 恢复存储桶状态

### 用例 2：系统元数据 (38:00 - 45:00)

38:00 - 系统元数据用例：了解数据格局

38:30 - 场景：遗留存储桶包含数百万个对象，由不同部门多年上传

39:00 - 合规挑战：去年合规团队要求所有对象使用 SSE-KMS 加密，但不确定政策实施前创建的对象是否符合要求

40:00 - 展示解决方案：通过简单 SQL 查询查找仍使用明文的对象

41:30 - 进一步操作：将查询输出传递给 Batch Operations，对这些对象执行就地复制并指定所需的加密类型

42:30 - 组合用例：结合系统元数据和请求元数据，查询谁向哪些存储类上传了多少数据

44:00 - 强调优势：传统上访问日志和存储数据存储在不同位置、不同格式、不同访问控制，需要大量开发工作；S3 Metadata 将所有数据集中在一个地方，随时可查询

### 用例 3：自定义元数据 (45:00 - 55:00)

45:00 - 自定义元数据用例：使用业务上下文增强元数据

45:30 - 介绍三种添加自定义元数据的方式

46:00 - 用户元数据：在 PUT 请求中以键值对形式提供，不可变，适合存储不应改变的信息（如来源、出处）

47:30 - 对象标签：使用对象标记 API 附加，自动在 Journal 和 Inventory Table 中可见

48:30 - 重要特性：用户元数据和对象标签与对象一起存在，复制或复制时会随对象移动，删除对象时自动清理

49:30 - 自管理 S3 表：第三种选项，适用于元数据超过标签和用户定义元数据大小限制的情况（如缩略图、文本文档或视频文件摘要）

51:00 - 权衡：自管理表的更新不会自动从存储桶传播，可能需要与托管 S3 元数据表连接以了解元数据是否最新

52:00 - AI 生成数据用例：随着合成数据爆炸式增长，需要区分 AI 生成与非 AI 生成的数据，跟踪 AI 数据的血统

53:00 - 案例：去年 re:Invent 发布 NOVA 时，Bedrock 开始使用用户元数据注释上传到 S3 的视频和图像，指示对象来自 Bedrock 及使用的模型

54:00 - 传感器数据用例：传感器和监控设备数据呈指数增长（安全摄像头、车辆传感器、飞机/船舶传感器、科学研究数据）

54:45 - 挑战：数据本身缺乏分析所需的上下文信息，特别是首次上传到云时

55:30 - 解决方案：通过对象标签添加上下文元数据（记录时间、传感器位置、传感器配置），标签附加后自动流入元数据表，可通过查询上下文信息找到数据

### 实际演示 (55:00 - 75:00)

55:00 - Ruhi 开始演示环节，强调所有功能当前可用

55:30 - 演示分为三部分：设置元数据配置、查询元数据表、基于元数据查询结果采取存储管理操作

56:00 - 第一部分：设置元数据配置

56:30 - 演示在通用存储桶（Starwatcher bucket）上启用元数据，不到一分钟完成

57:00 - 配置选项：启用 Journal 和 Live Inventory 表、选择加密类型、设置记录过期时间（如 365 天后过期）

58:30 - 说明表状态变化：配置创建后，Journal Table 几秒内变为活动状态（前瞻性捕获 PUT 和 DELETE）；Live Inventory Table 先进入回填阶段（捕获所有现有对象元数据）

59:30 - 指出表存储位置：AWS S3 Table Bucket，区域和账户的所有元数据表都托管在此单一存储桶中

60:00 - 第二部分：查询元数据表

60:30 - 使用 SageMaker Unified Studio 查询 Journal Table（一键集成）

61:00 - 展示表拓扑结构：AWS S3 Table Bucket → 命名空间（b_存储桶名称）→ Journal 和 Live Inventory 表

62:00 - 查看 Journal Table 架构：包含请求者、请求 ID、源 IP 地址等特殊字段

62:30 - 演示查询场景：显示过去 7 天特定前缀中删除的所有内容

63:30 - 查询结果：几秒内获得已删除对象列表及删除者信息

64:00 - 使用 Athena 查询 Live Inventory Table

64:30 - 演示场景：查找具有特定标签类型（天气和训练类别）且在特定存储类中的所有对象

65:30 - 重要发现：所有对象都在 Glacier 存储类中，但元数据可查询（无需恢复对象即可获取元数据）

66:00 - 第三部分：基于元数据采取存储管理操作

66:30 - 场景：数据科学家 Alice 训练雨天停车辅助模型，需要从 Glacier 恢复原始数据

67:00 - 执行查询：获取符合特定标签条件且在 Glacier 存储类中的对象列表（仅返回存储桶和键）

68:00 - 准备 Batch Operations 清单：将查询结果转换为逗号分隔格式，存储为清单文件

69:00 - 获取清单文件 URI 并传递给 Batch Operations 作业

70:00 - 配置 Batch Operations：选择恢复操作、设置可用天数（5 天）、选择优先级、指定完成报告位置

71:30 - 查看作业详情：显示清单中有 88 个对象将被恢复

72:00 - 强调优势：不再花费数小时准备数据，只需获取查询输出、处理并传递给 Batch Operations

72:30 - 使用自然语言查询

73:00 - 使用 Kiro CLI 和 MCP for S3 Tables 进行自然语言查询

73:30 - 初始化 Kiro，加载 S3 Tables MCP 服务器

74:00 - 提交自然语言提示：分析存储、查看对象计数、存储类分布、前缀

74:30 - Kiro 自动解释请求并执行分析，请求权限运行查询数据库工具

75:00 - 展示查询过程：连接 S3 Tables、优化 SQL 查询、查找计数、大小、分布、前缀

76:00 - 生成执行摘要：存储总量、对象数量、存储类分布、前缀分布，并提供可操作的建议

77:00 - 强调优势：业务团队可以与元数据表对话，无需成为 SQL 专家

### 区域可用性与总结 (77:00 - 结束)

77:00 - 宣布区域可用性：目前在 28 个区域可用，其中 22 个在过去一周内发布，将继续扩展区域覆盖

78:00 - 会议结束

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


关键要点：
1. S3 Metadata 通过自动化元数据提取和 SQL 查询能力，彻底解决了大规模数据发现难题
2. 基于 Apache Iceberg 和 S3 Tables 的架构提供了开放性、高性能和深度 AWS 集成
3. 支持多种查询方式（AWS 服务、开源引擎、自然语言），适应不同用户需求和技能水平