# AWS re:Invent 2025 OpenSearch 向量数据库扩展会议总结

## 会议概述

本次会议由 Dylan Tong(OpenSearch 产品团队 AI 和向量工作负载负责人)和 Swami Vijay Akita(Amazon OpenSearch 服务高级软件经理)主讲,重点介绍了在 AWS re:Invent 2025 上发布的两项重要功能:**GPU 向量加速**和**自动优化(Auto-Optimize)**。

会议聚焦于如何构建大规模向量数据库,解决客户在扩展向量搜索时面临的核心挑战。随着生成式 AI 和智能体应用的兴起,越来越多的企业需要处理数十亿规模的向量数据。传统方法在构建和维护这些大规模向量索引时面临着时间长(通常需要数天)、成本高、运维复杂等问题。AWS OpenSearch 通过 GPU 加速技术将索引构建速度提升 6-14 倍,成本降低 6-12 倍;同时推出的自动优化框架能够在一小时内自动生成最优索引配置建议,大幅降低了技术门槛和实验成本。

这两项创新使得企业能够更快速、更经济地构建和维护亿级规模的向量数据库,为智能体应用、语义搜索、推荐系统等 AI 原生应用提供了强大的基础设施支持。

## 详细时间线与关键要点

### **开场介绍 (0:00-2:30)**
- **0:00** - 会议在 Mandalay Bay 举行,同时在 Wynn 和 Venetian 设有远程会场
- **0:30** - 演讲者自我介绍:Dylan Tong 负责 OpenSearch AI 和向量工作负载,Swami Vijay Akita 负责搜索功能
- **1:00** - 宣布两项 re:Invent 重要发布:GPU 向量加速和自动优化
- **1:30** - 现场调查:部分观众正在使用 OpenSearch,少数有向量搜索经验

### **OpenSearch 基础介绍 (2:30-5:00)**
- **2:30** - OpenSearch 是 Apache 开源的搜索和分析引擎,属于 Linux 基金会
- **3:00** - AWS 提供两种部署方式:托管集群(完全控制实例)和无服务器版本(自动扩展)
- **3:30** - 周边服务包括 OpenSearch Ingestion(数据处理和加载)和 OpenSearch Dashboards(可视化)
- **4:00** - 两大主要用例:日志分析/可观测性(50%)和搜索功能(50%)
- **4:30** - 向量搜索的核心价值:提升搜索质量、支持多模态搜索(文本/音频/图像)、支持多样化应用场景

### **OpenSearch 向量搜索发展历程 (5:00-8:30)**
- **5:00** - 2020年2月:开始向量搜索之旅,向 Elasticsearch OpenDistro 贡献 K-NN 插件
- **5:30** - 2021年:OpenSearch 1.0 发布(从 Elasticsearch 7.10 分叉),集成 Facebook FAISS 库以提升性能和规模
- **6:00** - 早期大规模用户包括 Amazon 内部团队(零售、音乐、Rekognition)
- **6:30** - 2023年:生成式 AI 元年,向量数据库成为热点
- **7:00** - 成为 Amazon Bedrock 知识库的默认选择,支持 RAG(检索增强生成)和智能体
- **7:30** - 推出混合搜索功能,结合传统关键词搜索和向量搜索
- **8:00** - 构建 AI 原生搜索引擎,集成第三方服务(OpenAI、Cohere、SageMaker、Bedrock)

### **成本优化与 AI 原生功能 (8:30-10:00)**
- **8:30** - 2023年重点:成本优化成为首要任务
- **9:00** - 推出磁盘优化、分层存储、自动量化(压缩)功能
- **9:30** - 增强易用性和 AI 原生功能:语言检测、翻译、自动元数据提取
- **10:00** - 2025年:继续成本优化,新增智能体和 AI 搜索流程,集成 MCP

### **客户案例:Amazon Brand Protection (10:00-11:30)**
- **10:00** - Amazon 品牌保护团队使用案例
- **10:30** - 将整个产品目录编码为 68 亿个向量
- **11:00** - 用于检测 IP 侵权和异常,在 99% 的滥用行为被报告之前就能检测到

### **客户案例:DevRev AI (11:30-13:00)**
- **11:30** - DevRev 是一家初创公司,提供 AI 团队协作产品
- **12:00** - 解决企业数据孤岛问题,使用 AI 智能体统一数据源
- **12:30** - 目前管理**数亿个向量**,每天更新**数百万个向量**
- **13:00** - 成果:85% 的支持工单无需人工干预,客户支持成本降低 30%

### **智能体系统架构 (13:00-15:30)**
- **13:00** - 以旅行系统为例说明智能体工作流程
- **13:30** - 用户通过对话界面提出请求(如"帮我规划 re:Invent 2025 行程")
- **14:00** - AI 智能体(通常是大语言模型)创建执行计划
- **14:30** - 从知识库(酒店、场馆、航班)检索上下文信息
- **15:00** - 编译自动化任务(如生成旅行行程)
- **15:30** - 关键点:**垃圾进,垃圾出** - 高质量检索是智能体成功的关键

### **向量搜索优势演示 (15:30-17:00)**
- **15:30** - 在 Wiki 数据集上搜索"wild west"的对比实验
- **16:00** - 关键词搜索返回"West Virginia 篮球队"(匹配"west"关键词)
- **16:30** - 向量搜索返回"牛仔"和"竞技表演"(语义相似性匹配)
- **17:00** - 结论:向量搜索是构建高质量智能体功能的必要条件

### **向量搜索基础原理 (17:00-21:00)**
- **17:00** - 工作流程:内容 → 嵌入模型 → 向量 → 索引 → 搜索查询
- **17:30** - 向量本质:与物理学中的向量相同,但维度通常超过 1000 维
- **18:00** - 向量距离代表相似度(余弦距离或欧几里得距离)
- **18:30** - 音乐推荐示例:相似歌曲在向量空间中距离较近
- **19:00** - 暴力搜索:将查询向量与所有向量比较,找出 Top-K 最近邻
- **19:30** - 问题:十亿规模数据集需要数分钟才能完成查询
- **20:00** - 索引算法:HNSW(分层导航小世界图)等算法预处理向量
- **20:30** - 索引优势:毫秒级查询响应,代价是前期构建成本高和近似结果
- **21:00** - 近似精度通常可达 0.99 或更高

### **OpenSearch 扩展架构 (21:00-23:30)**
- **21:00** - OpenSearch 通过集群跨多台服务器分布数据
- **21:30** - 十亿向量数据集被分区到多个服务器上
- **22:00** - 并行遍历所有索引实现毫秒级查询
- **22:30** - 托管集群 vs 无服务器:无服务器分离搜索/索引工作负载和存储/计算
- **23:00** - 两种架构的扩展原理相同:跨服务器分布
- **23:30** - 无服务器提供更强的自动扩展能力

### **大规模索引构建挑战 (23:30-27:00)**
- **23:30** - 向量索引比传统数据库索引需要更多内存和计算资源
- **24:00** - 现场互动:构建 10 亿规模索引需要多长时间?
- **24:30** - 答案:**通常需要数天时间**
- **25:00** - 这不是一次性任务,索引需要定期重建
- **25:30** - HNSW 索引退化:数据变化时搜索质量下降
- **26:00** - 更换嵌入模型需要重新生成向量和重建索引
- **26:30** - 模型供应商(OpenAI、Anthropic、Cohere)每年发布 1-4 个新版本

### **个性化搜索案例:Amazon Music (27:00-29:00)**
- **27:00** - Amazon Music 使用向量搜索提供个性化推荐
- **27:30** - 推荐模型将歌曲编码为**超过 10 亿个向量**
- **28:00** - 为保持最佳推荐质量,需要**每天重新训练**模型
- **28:30** - 如果索引构建需要数天,将无法满足 SLA 要求
- **29:00** - 托管集群的额外挑战:搜索和索引工作负载争夺资源

### **GPU 加速解决方案探索 (29:00-32:00)**
- **29:00** - 识别问题:大规模向量系统构建和维护困难,影响创新速度
- **29:30** - GPU 潜力:擅长向量数学运算(与计算机图形和 AI 相同)
- **30:00** - 与 Nvidia 合作,使用 cuVS 库(GPU 优化的向量算法)
- **30:30** - 探索 Cagra 算法(Nvidia 的 GPU 优化算法)
- **31:00** - 定制增强:在 Cagra 上构建,但在 RAM 中运行索引
- **31:30** - 集成 FAISS:在 Cagra 上构建,转移到 RAM,在 Meta 的 FAISS 库中运行
- **32:00** - 目标:既利用 GPU 构建速度,又能运行其他工作负载

### **GPU 加速性能测试结果 (32:00-36:00)**
- **32:00** - 测试数据集:100万、1000万、1亿、10亿向量,不同维度
- **32:30** - 基准测试(CPU):包括索引构建和合并操作
- **33:00** - 大规模数据集(1亿-10亿)在合理规模集群上需要**超过一天**
- **33:30** - GPU 加速结果:速度提升 6-14 倍
- **34:00** - 成本节省:6-12 倍(尽管增加了 GPU 基础设施)
- **34:30** - 原因:GPU 效率极高,任务完成速度快,总体成本更低
- **35:00** - 无服务器成本更易理解:账单显示索引成本和搜索成本的独立行项
- **35:30** - 计费单位:**OCU 小时**(OpenSearch 计算单元)

### **无服务器成本对比详解 (36:00-38:30)**
- **36:00** - 测试案例:1.13 亿向量,1024 维
- **36:30** - CPU 基准:**2721 OCU 小时**
- **37:00** - GPU 加速(转换为 OCU):**104.5 OCU 小时**
- **37:30** - 成本降低:**8.9 倍**
- **38:00** - 美国北弗吉尼亚定价:每 OCU 小时 $0.24
- **38:30** - 实际成本对比:**$853 降至 $73**

### **混合工作负载测试 (38:30-40:30)**
- **38:30** - 模拟智能体应用:并发用户同时搜索和更新内容
- **39:00** - Y 轴:索引客户端数量(写入负载),X 轴:CPU 利用率
- **39:30** - CPU 基准:随着写入增加,CPU 利用率上升,搜索延迟增加
- **40:00** - GPU 加速:将索引工作负载卸载到 GPU,降低 CPU 利用率
- **40:30** - 结果:搜索延迟保持在可管理水平,用户体验更好

### **GPU 集成架构挑战 (40:30-43:00)**
- **40:30** - GPU 潜力已证实,但如何集成到 OpenSearch?
- **41:00** - 简单方案:直接支持 GPU 实例 - 但会导致经济问题
- **41:30** - 示例:10 亿向量,1024 维,使用二进制量化(32 倍压缩)
- **42:00** - CPU 集群:需要 3 个 R8 实例(内存绑定,需要 1TB+ RAM)
- **42:30** - GPU 方案:需要 6 个 G6 实例(成本效益高但 RAM 容量不足)
- **43:00** - 问题:GPU 实例成本是 CPU 的 2.4 倍,但并非始终需要索引

### **无服务器 GPU 解决方案 (43:00-46:00)**
- **43:00** - 理想场景:继续使用现有 CPU 集群,仅在需要时添加 GPU
- **43:30** - 设计原则:相同 API,无需更改工作流程
- **44:00** - 按价值付费:仅在受益于 GPU 加速时付费
- **44:30** - 架构:用户使用标准索引 API(index、reindex、bulk)
- **45:00** - 自动检测:高写入吞吐量(如每秒 10,000 个向量)触发 GPU 分配
- **45:30** - 后台管理:AWS 管理 GPU 实例的热池,多租户共享,单租户安全分配
- **46:00** - 自动扩展:任务完成后 GPU 返回池中

### **GPU 加速使用方式 (46:00-48:00)**
- **46:00** - 用户体验:像电灯开关一样简单
- **46:30** - 启用方式:通过 API、CLI 或控制台启用
- **47:00** - 定价:**无服务器 GPU**,每 OCU 小时 $0.24(美国北弗吉尼亚)
- **47:30** - 与标准索引 OCU 价格相同
- **48:00** - 适用于托管集群和无服务器部署

### **索引配置优化的重要性 (48:00-51:00)**
- **48:00** - Swami 接手讲解:除了快速构建索引,还需要优化配置
- **48:30** - 索引配置决定:**搜索质量、成本和速度**
- **49:00** - 优化可将成本降低 三分之一
- **49:30** - 规模越大,优化效果越明显
- **50:00** - 内存占用对比:1000 万向量节省 300GB,10 亿向量节省 3TB
- **50:30** - 10 亿规模时内存占用减少 75%
- **51:00** - 结论:优化索引配置至关重要

### **索引配置参数详解 (51:00-54:00)**
- **51:00** - OpenSearch 提供丰富的索引配置和可调参数
- **51:30** - 权衡三角:搜索质量(召回率)vs 延迟 vs 成本
- **52:00** - 三类可调参数:
  - **算法类型**:HNSW(基于图)vs IVF(基于桶)
  - **压缩技术**:二进制量化、标量量化、乘积量化(2-64 倍压缩)
  - **运行模式**:内存、磁盘或远程存储(S3)
- **53:00** - 客户喜欢这些权衡选项,可充分利用硬件资源
- **53:30** - 挑战:需要 K-NN 和向量搜索算法专业知识
- **54:00** - 过程耗时:选择配置 → 构建索引 → 评估质量/延迟/成本 → 调整 → 重复

### **配置优化实例 (54:00-57:00)**
- **54:00** - 示例:构建需要 95% 准确率的应用
- **54:30** - 第一次尝试:32 倍压缩(二进制量化),结果只有 90% 准确率
- **55:00** - 第二次尝试:降至 16 倍压缩,结果 93% 准确率(仍不够)
- **55:30** - 第三次尝试:降至 8 倍压缩,继续迭代
- **56:00** - 关键点:**没有通用的最优配置**
- **56:30** - 配置取决于数据集和业务需求
- **57:00** - 电商推荐系统:需要高质量 + 个位数毫秒延迟(内存 + HNSW)

### **不同场景的配置需求 (57:00-58:30)**
- **57:00** - 企业内部搜索:需要质量,但 100-200 毫秒延迟可接受
- **57:30** - 根据需求选择不同的超参数配置
- **58:00** - 找到最优配置需要时间和专业知识
- **58:30** - AWS 目标:简化入门体验,无论是 POC 还是大规模工作负载

### **自动优化框架 (58:30-61:00)**
- **58:30** - AWS 构建**自动优化框架**
- **59:00** - 框架学习所有技术、算法、参数和调优配置
- **59:30** - 客户只需提供:**可接受的搜索质量**和**可接受的搜索延迟**
- **60:00** - 后台处理:分析数据、分析业务需求、运行超参数优化任务
- **60:30** - 输出:配置建议
- **61:00** - 透明度:提供详细报告,包括性能指标、算法参数、压缩级别等

### **自动优化的优势 (61:00-63:00)**
- **61:00** - 客户可查看每个建议的详细信息
- **61:30** - 性能指标:召回率、内存占用
- **62:00** - 技术细节:算法、超参数、压缩级别
- **62:30** - 客户专注于选择最佳建议,无需管理基础设施
- **63:00** - 无服务器自动优化框架:构建在无服务器集群上,并行化所有优化任务

### **自动优化的三大优势 (63:00-64:30)**
- **63:00** - 降低专业知识要求:只需关注业务需求
- **63:30** - 节省时间:一小时内提供建议(而非数天迭代)
- **64:00** - 降低成本:无需管理实验和 POC 所需的基础设施
- **64:30** - 过渡到实际演示

### **实际演示开始 (64:30-67:00)**
- **64:30** - 登录 OpenSearch 服务控制台
- **65:00** - 左侧导航栏新增**"Vector Injection"(向量注入)**入口
- **65:30** - 演示角色:搜索工程师,将应用从词法搜索升级到语义搜索
- **66:00** - 工作流程四步骤:
  1. 准备数据集(文档 → 嵌入模型 → 向量 → S3)
  2. 提供业务需求(X% 搜索质量 + Y 延迟)
  3. 获取建议
  4. 选择建议并构建索引(使用 GPU 加速)
- **66:30** - 开始创建注入任务
- **67:00** - 配置数据源:S3 存储桶(US East 1 区域)

### **演示继续(会话在此处结束)**
- **67:00+** - 演示者正在选择 S3 数据文件夹...
- 会话字幕在演示过程中结束

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


## 总结

本次会议展示了 AWS OpenSearch 在向量数据库领域的重大创新,通过 GPU 加速和自动优化两项技术,将大规模向量索引构建从"数天"缩短到"数小时",成本降低 6-12 倍,同时大幅降低了技术门槛。这些创新为企业构建智能体应用、语义搜索和个性化推荐系统提供了强大而经济的基础设施支持。