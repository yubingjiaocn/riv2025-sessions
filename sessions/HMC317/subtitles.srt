1
00:00:00,000 --> 00:00:01,077
- [Karim] My name is Karim Akhnoukh.

2
00:00:01,077 --> 00:00:03,690
I'm a senior solutions architect at AWS.

3
00:00:03,690 --> 00:00:06,540
I've been with the company
since almost three years,

4
00:00:06,540 --> 00:00:07,710
and I've worked with many

5
00:00:07,710 --> 00:00:09,390
of the big manufacturers in Germany,

6
00:00:09,390 --> 00:00:11,280
help them navigating the complexity

7
00:00:11,280 --> 00:00:14,190
of deploying gen AI applications.

8
00:00:14,190 --> 00:00:15,480
- [Mohamed] Okay, perfect.

9
00:00:15,480 --> 00:00:16,650
My name is Mohamed Salah,

10
00:00:16,650 --> 00:00:19,260
working as a solution architect at AWS,

11
00:00:19,260 --> 00:00:21,813
looking after public
sector in the Middle East.

12
00:00:23,790 --> 00:00:25,110
My job at AWS

13
00:00:25,110 --> 00:00:27,330
is solving the similar problem.

14
00:00:27,330 --> 00:00:29,100
Not Karim's (indistinct) problem,

15
00:00:29,100 --> 00:00:31,683
but real manufacturer problems.

16
00:00:33,330 --> 00:00:35,010
Picture this.

17
00:00:35,010 --> 00:00:36,760
The same silence

18
00:00:41,100 --> 00:00:42,363
inside your factory.

19
00:00:43,530 --> 00:00:46,980
And you have machines stopped.

20
00:00:46,980 --> 00:00:49,500
Your production line paused.

21
00:00:49,500 --> 00:00:53,730
Everyone starts running around.

22
00:00:53,730 --> 00:00:57,363
Every minute your products are not made,

23
00:00:58,770 --> 00:01:00,960
your orders get delayed

24
00:01:00,960 --> 00:01:02,973
and costs pile up.

25
00:01:04,110 --> 00:01:06,250
Simply, this is what we are calling

26
00:01:07,110 --> 00:01:09,753
this silence, unplanned downtime.

27
00:01:11,520 --> 00:01:14,580
The top 500 manufacturers globally,

28
00:01:14,580 --> 00:01:17,250
they are paying for this.

29
00:01:17,250 --> 00:01:20,220
1.4 trillion US dollars due

30
00:01:20,220 --> 00:01:22,353
to this unplanned downtime.

31
00:01:23,760 --> 00:01:26,460
They are losing around 11%

32
00:01:26,460 --> 00:01:28,953
of their revenues every year.

33
00:01:30,690 --> 00:01:32,250
To make this more clear,

34
00:01:32,250 --> 00:01:33,670
we are talking about

35
00:01:35,190 --> 00:01:37,680
this is equivalent to the GDP

36
00:01:37,680 --> 00:01:39,063
of the nation like Spain.

37
00:01:40,410 --> 00:01:42,630
When we take a closer look about this,

38
00:01:42,630 --> 00:01:46,020
we found four different challenges.

39
00:01:46,020 --> 00:01:48,210
First is the data silos.

40
00:01:48,210 --> 00:01:49,890
You have a production line,

41
00:01:49,890 --> 00:01:51,810
and as part of this production line,

42
00:01:51,810 --> 00:01:53,550
you have multiple machines.

43
00:01:53,550 --> 00:01:56,670
Each machine has own alarms

44
00:01:56,670 --> 00:01:58,110
and telemetry data,

45
00:01:58,110 --> 00:02:00,210
but each machine has

46
00:02:00,210 --> 00:02:02,250
its own separate database.

47
00:02:02,250 --> 00:02:03,990
It will end up, you don't have

48
00:02:03,990 --> 00:02:07,170
this kind of view, end-to-end view,

49
00:02:07,170 --> 00:02:09,810
to understand exactly the relations

50
00:02:09,810 --> 00:02:12,000
between the machine inside

51
00:02:12,000 --> 00:02:14,010
the same production line.

52
00:02:14,010 --> 00:02:16,740
The idea here is you have the data,

53
00:02:16,740 --> 00:02:18,813
but the data is disconnected.

54
00:02:19,710 --> 00:02:22,290
Second problem, which is a skill gap.

55
00:02:22,290 --> 00:02:23,850
It's all about people.

56
00:02:23,850 --> 00:02:25,770
For each manufacturer,

57
00:02:25,770 --> 00:02:27,580
you have this senior expert

58
00:02:28,920 --> 00:02:30,570
who can tell you, from the sound

59
00:02:30,570 --> 00:02:32,580
of the mixer, there is a problem.

60
00:02:32,580 --> 00:02:34,443
This is over-mixed dough.

61
00:02:35,880 --> 00:02:37,470
Can tell you from the oven,

62
00:02:37,470 --> 00:02:41,160
the right side of the
oven is much more heated

63
00:02:41,160 --> 00:02:42,843
than the left side.

64
00:02:43,710 --> 00:02:45,960
This kind of expertise,

65
00:02:45,960 --> 00:02:47,970
if they are not there,

66
00:02:47,970 --> 00:02:49,860
and you have a junior receive

67
00:02:49,860 --> 00:02:51,300
this kind of a warning,

68
00:02:51,300 --> 00:02:53,160
they will not be able to act.

69
00:02:53,160 --> 00:02:55,380
And this is the second idea.

70
00:02:55,380 --> 00:02:56,520
You have the knowledge,

71
00:02:56,520 --> 00:02:58,533
but knowledge is not shared.

72
00:03:00,150 --> 00:03:01,740
Third is the production delays,

73
00:03:01,740 --> 00:03:03,910
and this is when this silence

74
00:03:05,280 --> 00:03:06,930
feasible for everyone.

75
00:03:06,930 --> 00:03:09,450
You have the junior, you
don't have those seniors.

76
00:03:09,450 --> 00:03:11,760
You have the data, but the data scattered.

77
00:03:11,760 --> 00:03:14,250
And they are not able to act

78
00:03:14,250 --> 00:03:16,920
because they don't have the expertise,

79
00:03:16,920 --> 00:03:18,300
they don't have the knowledge,

80
00:03:18,300 --> 00:03:20,163
and that data is disconnected.

81
00:03:21,420 --> 00:03:23,910
Last one is the operational disruption.

82
00:03:23,910 --> 00:03:24,850
I know this is

83
00:03:26,910 --> 00:03:29,100
very important for every factory

84
00:03:29,100 --> 00:03:30,390
because most of the factories

85
00:03:30,390 --> 00:03:32,910
are in remote areas.

86
00:03:32,910 --> 00:03:34,290
When we are talking about the factory,

87
00:03:34,290 --> 00:03:36,690
they are not having, most of the time,

88
00:03:36,690 --> 00:03:39,840
stable internet connectivity,

89
00:03:39,840 --> 00:03:41,643
and they don't have cloud access.

90
00:03:42,690 --> 00:03:45,540
If you have a smart manufacturer

91
00:03:45,540 --> 00:03:48,300
and this disconnected, under any reason,

92
00:03:48,300 --> 00:03:49,630
this means

93
00:03:51,030 --> 00:03:52,770
your manufacturer will be blind.

94
00:03:52,770 --> 00:03:54,330
You will not have this kind

95
00:03:54,330 --> 00:03:58,770
of data-driven decisions and insights.

96
00:03:58,770 --> 00:04:01,203
That's why we thought
about simple solution.

97
00:04:02,280 --> 00:04:04,500
Let's put all the data together,

98
00:04:04,500 --> 00:04:07,020
in one single data link

99
00:04:07,020 --> 00:04:09,183
inside AWS Outpost.

100
00:04:10,140 --> 00:04:11,250
But when we did this,

101
00:04:11,250 --> 00:04:13,560
we found a different challenge.

102
00:04:13,560 --> 00:04:15,870
Each machine has

103
00:04:15,870 --> 00:04:18,450
its own integration type.

104
00:04:18,450 --> 00:04:20,640
I bought this machine from OEM X,

105
00:04:20,640 --> 00:04:22,800
OEM Y, and OEM Z.

106
00:04:22,800 --> 00:04:24,870
However, each OEM has

107
00:04:24,870 --> 00:04:27,330
its own integration, even technology.

108
00:04:27,330 --> 00:04:30,570
If we are talking about
modern IoT integration,

109
00:04:30,570 --> 00:04:32,820
MQTT, or even LoRaWAN,

110
00:04:32,820 --> 00:04:35,040
or we are talking about REST APIs

111
00:04:35,040 --> 00:04:38,280
for POST HTTP and GET HTTP.

112
00:04:38,280 --> 00:04:40,470
And most important part

113
00:04:40,470 --> 00:04:42,060
about your manufacturer

114
00:04:42,060 --> 00:04:43,263
is the documents.

115
00:04:44,790 --> 00:04:48,510
Those kind of standard
operation procedure document,

116
00:04:48,510 --> 00:04:50,910
manual documents, you can get it

117
00:04:50,910 --> 00:04:53,190
using a legacy SFTP.

118
00:04:53,190 --> 00:04:54,810
We thought about why not

119
00:04:54,810 --> 00:04:58,590
to have this Outpost
underlying infrastructure

120
00:04:58,590 --> 00:05:01,500
over EKS local cluster doing

121
00:05:01,500 --> 00:05:05,340
this unified API deployment to absorb

122
00:05:05,340 --> 00:05:07,653
those kind of different integrations?

123
00:05:08,670 --> 00:05:10,860
And, accordingly, integrate this

124
00:05:10,860 --> 00:05:14,403
with one consolidated data lake.

125
00:05:15,900 --> 00:05:18,900
And then, to get the consumer

126
00:05:18,900 --> 00:05:21,600
of those data lakes, will be an AI.

127
00:05:21,600 --> 00:05:23,700
In our case, will be Bedrock.

128
00:05:23,700 --> 00:05:25,890
And also to get much more insight

129
00:05:25,890 --> 00:05:28,623
with a dashboard, using Amazon QuickSight.

130
00:05:30,090 --> 00:05:31,620
This would be the result.

131
00:05:31,620 --> 00:05:33,240
You have, on the left side,

132
00:05:33,240 --> 00:05:34,410
you have a production line.

133
00:05:34,410 --> 00:05:35,820
You understand everything.

134
00:05:35,820 --> 00:05:37,770
You have the full details

135
00:05:37,770 --> 00:05:40,620
and full understanding
about your production line.

136
00:05:40,620 --> 00:05:42,360
And you can see the inspector

137
00:05:42,360 --> 00:05:46,260
is telling you, you have cracked cookies.

138
00:05:46,260 --> 00:05:48,300
The machine state is down

139
00:05:48,300 --> 00:05:49,593
for five minutes.

140
00:05:51,210 --> 00:05:52,270
Second problem

141
00:05:53,880 --> 00:05:56,250
is the resiliency,

142
00:05:56,250 --> 00:05:58,530
what we are calling always on.

143
00:05:58,530 --> 00:05:59,880
Have to stay always on.

144
00:05:59,880 --> 00:06:02,370
If you got disconnected,

145
00:06:02,370 --> 00:06:04,290
Outpost disconnected from the cloud,

146
00:06:04,290 --> 00:06:06,090
under any reason,

147
00:06:06,090 --> 00:06:08,040
you will not be able to act

148
00:06:08,040 --> 00:06:09,840
as a smart manufacturer anymore.

149
00:06:09,840 --> 00:06:10,920
You will not be able to have

150
00:06:10,920 --> 00:06:14,310
this kind of data-driven decisions.

151
00:06:14,310 --> 00:06:17,850
You will not get automated
AI recommendations.

152
00:06:17,850 --> 00:06:20,850
That's why we thought, why not

153
00:06:20,850 --> 00:06:24,000
to add this intelligency at the edge

154
00:06:24,000 --> 00:06:27,090
by deploying multiple
small language model?

155
00:06:27,090 --> 00:06:30,750
We'll go through this later
as part of the sessions.

156
00:06:30,750 --> 00:06:33,180
And to have two different features.

157
00:06:33,180 --> 00:06:34,013
First,

158
00:06:35,280 --> 00:06:38,790
to provide intelligence

159
00:06:38,790 --> 00:06:41,220
for the operators, using text

160
00:06:41,220 --> 00:06:44,610
and even voice, to chat with the data.

161
00:06:44,610 --> 00:06:47,820
Second is to apply this
kind of an automation.

162
00:06:47,820 --> 00:06:50,010
You are digesting your data,

163
00:06:50,010 --> 00:06:53,130
and telemetry data every five minutes,

164
00:06:53,130 --> 00:06:56,280
understanding the insights,
getting recommendations.

165
00:06:56,280 --> 00:06:58,390
And if you feel this recommendations

166
00:06:59,700 --> 00:07:02,340
require a notification,
notify the operator

167
00:07:02,340 --> 00:07:04,413
with the required actions.

168
00:07:07,350 --> 00:07:09,480
- [Karim] So before we jump
into the coding session,

169
00:07:09,480 --> 00:07:11,850
which I know you're so much
looking forward by now,

170
00:07:11,850 --> 00:07:13,455
please allow me two more minutes

171
00:07:13,455 --> 00:07:15,870
to explain the big picture
so you understand how

172
00:07:15,870 --> 00:07:18,510
the end-to-end workflow looks like.

173
00:07:18,510 --> 00:07:21,660
We imagine having a cookie
factory which produces

174
00:07:21,660 --> 00:07:23,910
the best-in-class cookies here in Vegas.

175
00:07:23,910 --> 00:07:24,930
And for simplicity,

176
00:07:24,930 --> 00:07:28,200
this cookie factory
has three big machines,

177
00:07:28,200 --> 00:07:29,760
which are the cookie former,

178
00:07:29,760 --> 00:07:31,290
followed by the freezer tunnel,

179
00:07:31,290 --> 00:07:33,660
and lastly, the cookie inspector.

180
00:07:33,660 --> 00:07:36,240
Now imagine the situation
when the cookie inspector,

181
00:07:36,240 --> 00:07:38,520
which does the visual quality inspection,

182
00:07:38,520 --> 00:07:40,770
detects a cookie which is cracked,

183
00:07:40,770 --> 00:07:44,343
misshapen, or a cookie
with some air pockets.

184
00:07:45,930 --> 00:07:49,170
Then we have our agentic
AI application running

185
00:07:49,170 --> 00:07:53,370
inside AWS Outpost for the
always-on connectivity thing.

186
00:07:53,370 --> 00:07:55,320
This agentic AI application has access

187
00:07:55,320 --> 00:07:56,520
to different data sources,

188
00:07:56,520 --> 00:07:58,380
including the machine manuals,

189
00:07:58,380 --> 00:07:59,910
the standard operating procedures,

190
00:07:59,910 --> 00:08:03,060
and real-time telemetry data and alarms.

191
00:08:03,060 --> 00:08:07,380
And then operators inside
the production site

192
00:08:07,380 --> 00:08:12,210
can chat or voice chat with the agent

193
00:08:12,210 --> 00:08:15,060
to understand what is
the underlying problem.

194
00:08:15,060 --> 00:08:17,550
And then it can finally instruct the agent

195
00:08:17,550 --> 00:08:19,680
to itself take some actions

196
00:08:19,680 --> 00:08:21,510
to correct the problem

197
00:08:21,510 --> 00:08:24,030
inside the production site.

198
00:08:24,030 --> 00:08:25,530
And, finally, we move from the state

199
00:08:25,530 --> 00:08:27,600
where we had a cracked cookie

200
00:08:27,600 --> 00:08:30,270
to a state where we are
producing delicious cookies

201
00:08:30,270 --> 00:08:31,893
and everyone is happy again.

202
00:08:32,790 --> 00:08:34,290
But you know what the problem is

203
00:08:34,290 --> 00:08:36,030
with what I'm showing here?

204
00:08:36,030 --> 00:08:39,240
I wish that the solution was as simple

205
00:08:39,240 --> 00:08:42,630
as plugging in the icon of AWS Outpost.

206
00:08:42,630 --> 00:08:45,300
Under the hood, there is a little bit

207
00:08:45,300 --> 00:08:47,640
of a more complex architecture.

208
00:08:47,640 --> 00:08:49,053
So on the right-hand side,

209
00:08:52,770 --> 00:08:55,170
we have the pipeline for data preparation

210
00:08:55,170 --> 00:08:56,400
and model fine tuning,

211
00:08:56,400 --> 00:08:59,400
which we'll go into very details

212
00:08:59,400 --> 00:09:00,570
at the rest of the session.

213
00:09:00,570 --> 00:09:01,830
And on the left-hand side, we have

214
00:09:01,830 --> 00:09:03,660
our agentic AI application

215
00:09:03,660 --> 00:09:05,760
deployed on AWS Outpost.

216
00:09:05,760 --> 00:09:06,960
And then we have different

217
00:09:06,960 --> 00:09:09,180
specialized small language models.

218
00:09:09,180 --> 00:09:11,160
We have GPT OSS model,

219
00:09:11,160 --> 00:09:13,110
which will be the routing model

220
00:09:13,110 --> 00:09:16,650
to navigate the different
tasks from the users

221
00:09:16,650 --> 00:09:18,090
to the different tools.

222
00:09:18,090 --> 00:09:22,530
We have the fine-tuned Llama
3.2 billion parameter model,

223
00:09:22,530 --> 00:09:25,560
which will be specialized
into the RAG application.

224
00:09:25,560 --> 00:09:28,080
And we finally have the SmolVLM

225
00:09:28,080 --> 00:09:30,030
for visual quality inspection.

226
00:09:30,030 --> 00:09:30,990
For sake of time,

227
00:09:30,990 --> 00:09:34,110
we will not be implementing the SmolVLM,

228
00:09:34,110 --> 00:09:36,810
but we will go through every other details

229
00:09:36,810 --> 00:09:38,460
of the implementations.

230
00:09:38,460 --> 00:09:39,393
So let's code.

231
00:09:44,970 --> 00:09:45,803
I switch one.

232
00:09:48,330 --> 00:09:50,730
Okay, so I hope you are seeing my screen.

233
00:09:50,730 --> 00:09:52,650
You do? All right.

234
00:09:52,650 --> 00:09:55,560
So I will start with setting up

235
00:09:55,560 --> 00:09:57,813
the infrastructure deployment.

236
00:09:59,460 --> 00:10:01,110
And I will be mimicking this

237
00:10:01,110 --> 00:10:03,750
with a couple of EC2 machines.

238
00:10:03,750 --> 00:10:06,420
I will be mimicking the
AWS Outpost environment

239
00:10:06,420 --> 00:10:09,570
with couple of EC2 machines.

240
00:10:09,570 --> 00:10:11,910
So let me navigate

241
00:10:11,910 --> 00:10:13,560
to the first method here that we have,

242
00:10:13,560 --> 00:10:15,260
which is the _create_ec2_instance.

243
00:10:16,350 --> 00:10:17,970
And here, as you can see,

244
00:10:17,970 --> 00:10:21,330
I'm using the g4dn.xlarge instance,

245
00:10:21,330 --> 00:10:24,690
which is relatively small,
but capable instance.

246
00:10:24,690 --> 00:10:26,310
It can be capable of running

247
00:10:26,310 --> 00:10:27,960
a small language model.

248
00:10:27,960 --> 00:10:29,610
I'm selecting a specific AMI,

249
00:10:29,610 --> 00:10:31,560
which is the Nvidia one.

250
00:10:31,560 --> 00:10:33,600
And then I'm creating
some security groups,

251
00:10:33,600 --> 00:10:36,660
some VPCs, some IM role,
and so on, so forth.

252
00:10:36,660 --> 00:10:38,820
But the most important
part that I would like

253
00:10:38,820 --> 00:10:41,850
to stress on here and grab your attention

254
00:10:41,850 --> 00:10:44,880
is this part, the user data script

255
00:10:44,880 --> 00:10:48,090
which will be uploaded
to the EC2 instances,

256
00:10:48,090 --> 00:10:50,730
because this is the one
that will be installing

257
00:10:50,730 --> 00:10:53,700
the actual dependencies that is needed

258
00:10:53,700 --> 00:10:56,220
to run the agentic AI application.

259
00:10:56,220 --> 00:10:59,130
So if we take a look at, for example,

260
00:10:59,130 --> 00:11:01,110
this EC2 machine, the user data script

261
00:11:01,110 --> 00:11:02,760
of this EC2 machine, you will find

262
00:11:02,760 --> 00:11:06,030
that it's 148 lines.

263
00:11:06,030 --> 00:11:07,920
So it's not very realistic

264
00:11:07,920 --> 00:11:09,930
to go through this line by line.

265
00:11:09,930 --> 00:11:12,090
But, instead, what I would like to do

266
00:11:12,090 --> 00:11:16,710
is I would like to use here your brains

267
00:11:16,710 --> 00:11:18,390
to brainstorm together

268
00:11:18,390 --> 00:11:22,020
what should be the dependencies
that should be added

269
00:11:22,020 --> 00:11:23,220
to this EC2 machine.

270
00:11:23,220 --> 00:11:26,010
So please take a moment, scan the QR code,

271
00:11:26,010 --> 00:11:29,910
and think as if you are
deploying this application,

272
00:11:29,910 --> 00:11:31,440
what dependencies do you need

273
00:11:31,440 --> 00:11:33,420
on the EC2 machine in order

274
00:11:33,420 --> 00:11:35,460
to host an AI agent

275
00:11:35,460 --> 00:11:36,900
and a small language model,

276
00:11:36,900 --> 00:11:39,960
which is that router small language model?

277
00:11:39,960 --> 00:11:41,940
Please think about it, and in a moment,

278
00:11:41,940 --> 00:11:43,923
I will be showing some results.

279
00:11:48,810 --> 00:11:49,710
- [Mohamed] Karim?

280
00:11:51,270 --> 00:11:52,193
This one. Okay.

281
00:11:54,000 --> 00:11:56,223
- [Karim] Okay, so,

282
00:11:57,540 --> 00:11:59,463
we are still collecting the votes.

283
00:12:07,050 --> 00:12:08,913
So you guys almost nailed it, right?

284
00:12:11,130 --> 00:12:13,653
Yeah, so, of course,
we need the agent code.

285
00:12:14,730 --> 00:12:16,440
That goes without saying.

286
00:12:16,440 --> 00:12:17,580
We need Docker runtime

287
00:12:17,580 --> 00:12:18,870
because we will use Docker

288
00:12:18,870 --> 00:12:21,690
to pull the container of Ollama,

289
00:12:21,690 --> 00:12:24,000
which will be our software for hosting

290
00:12:24,000 --> 00:12:25,250
the small language model.

291
00:12:26,130 --> 00:12:27,540
We don't need the fine-tuned model

292
00:12:27,540 --> 00:12:29,070
for this specific EC2 machine

293
00:12:29,070 --> 00:12:31,240
because we are having another EC2 machine

294
00:12:32,285 --> 00:12:34,800
where we will be deploying
the fine-tuned model.

295
00:12:34,800 --> 00:12:37,980
We need the Nvidia Toolkit
for the CUDA software.

296
00:12:37,980 --> 00:12:40,470
We need a custom Python version, indeed,

297
00:12:40,470 --> 00:12:43,680
because the SDK that we will be using

298
00:12:43,680 --> 00:12:46,380
for installing the AI agent is Strands,

299
00:12:46,380 --> 00:12:50,280
and Strands works with a
minimum Python version of 3.10.

300
00:12:50,280 --> 00:12:53,610
And the default Python
version in the G4dn instance

301
00:12:53,610 --> 00:12:56,250
is Python 3.9, which
why we need to install

302
00:12:56,250 --> 00:12:57,840
a custom Python version.

303
00:12:57,840 --> 00:13:00,330
And the one who said Ollama,
that's actually correct

304
00:13:00,330 --> 00:13:03,153
because we will be running
Ollama as a Docker container.

305
00:13:04,980 --> 00:13:07,260
Okay, so that was for
the first EC2 machine,

306
00:13:07,260 --> 00:13:09,780
for running the agent.

307
00:13:09,780 --> 00:13:12,120
Now, please, again,

308
00:13:12,120 --> 00:13:13,320
scan the QR code

309
00:13:13,320 --> 00:13:15,780
and think what the dependencies do we need

310
00:13:15,780 --> 00:13:17,550
for the EC2 machine

311
00:13:17,550 --> 00:13:20,997
that will hold that
fine-tuned EC2 instance,

312
00:13:20,997 --> 00:13:24,153
the fine-tuned small language model?

313
00:13:34,890 --> 00:13:37,320
Okay, so let me view

314
00:13:37,320 --> 00:13:41,130
the results.

315
00:13:41,130 --> 00:13:43,473
Yes, yes, yes.

316
00:13:45,420 --> 00:13:48,020
We need Docker, we need
the fine-tuned model.

317
00:13:48,020 --> 00:13:49,350
In that case, we don't need

318
00:13:49,350 --> 00:13:50,760
a custom Python version anymore

319
00:13:50,760 --> 00:13:53,520
because it works with the default version

320
00:13:53,520 --> 00:13:55,260
of the g4dn.xlarge.

321
00:13:55,260 --> 00:13:57,213
That was a tricky question.

322
00:13:58,470 --> 00:13:59,670
We don't need the agent code.

323
00:13:59,670 --> 00:14:02,943
That was deployed on
the first EC2 machine.

324
00:14:04,260 --> 00:14:05,850
And we need Ollama

325
00:14:05,850 --> 00:14:07,400
and we need the SLM, of course.

326
00:14:08,730 --> 00:14:11,850
Okay, so I'm happy that we

327
00:14:11,850 --> 00:14:14,400
well-brainstormed the dependencies.

328
00:14:14,400 --> 00:14:18,510
Now, after we write

329
00:14:18,510 --> 00:14:21,030
the user data script, like I said,

330
00:14:21,030 --> 00:14:23,310
we create a VPC, we
create security groups,

331
00:14:23,310 --> 00:14:26,190
we create an IM role with access to S3.

332
00:14:26,190 --> 00:14:28,560
And when we are happy with that,

333
00:14:28,560 --> 00:14:31,413
we need to deploy our application.

334
00:14:33,990 --> 00:14:34,823
Okay.

335
00:14:40,230 --> 00:14:41,820
- [Mohamed] Perfect.

336
00:14:41,820 --> 00:14:46,110
Now we have infrastructure
starting to deploy.

337
00:14:46,110 --> 00:14:49,560
Karim will debug for
sure what is going on.

338
00:14:49,560 --> 00:14:50,820
But during this time,

339
00:14:50,820 --> 00:14:53,280
let give you some tips and tricks,

340
00:14:53,280 --> 00:14:55,750
how to do a deployment

341
00:14:57,270 --> 00:15:00,813
for a small language
model over AWS Outpost.

342
00:15:02,310 --> 00:15:03,810
We'll take a closer look here.

343
00:15:05,241 --> 00:15:07,657
The GPU instance that we have over Outpost

344
00:15:07,657 --> 00:15:08,703
is the G4dn.

345
00:15:09,630 --> 00:15:11,940
And to deploy any model,

346
00:15:11,940 --> 00:15:13,800
you have to consider two things.

347
00:15:13,800 --> 00:15:15,993
First is the hardware constraint.

348
00:15:16,890 --> 00:15:19,770
We are talking about g4dn.12xlarge,

349
00:15:19,770 --> 00:15:23,820
which is four T4 Nvidia instance,

350
00:15:23,820 --> 00:15:28,530
each one of them powered by 16 giga

351
00:15:28,530 --> 00:15:30,573
of memory, gigabytes of memory.

352
00:15:32,100 --> 00:15:33,060
At the same time,

353
00:15:33,060 --> 00:15:34,680
and this is the second consideration,

354
00:15:34,680 --> 00:15:36,870
is the model itself.

355
00:15:36,870 --> 00:15:39,663
We are taking an example
of a open AI model OSS,

356
00:15:40,710 --> 00:15:42,543
around 20 billion parameters.

357
00:15:43,680 --> 00:15:45,570
But here, I mentioned different parameter,

358
00:15:45,570 --> 00:15:48,990
which is very important
to consider while doing

359
00:15:48,990 --> 00:15:51,240
a deployment over the Outpost.

360
00:15:51,240 --> 00:15:54,090
One of them is if this is a mixture

361
00:15:54,090 --> 00:15:56,250
of expert or not?

362
00:15:56,250 --> 00:15:58,380
How many layers

363
00:15:58,380 --> 00:16:01,293
and the active parameters per token?

364
00:16:02,490 --> 00:16:05,730
Now, let's focus on the first strategy

365
00:16:05,730 --> 00:16:08,580
to do the deployment, is a quantization.

366
00:16:08,580 --> 00:16:10,503
Quantization, in a nutshell,

367
00:16:11,400 --> 00:16:13,240
is reducing

368
00:16:15,240 --> 00:16:17,430
the number of bits

369
00:16:17,430 --> 00:16:20,400
presenting your weights

370
00:16:20,400 --> 00:16:23,583
in order to reduce the memory footprint.

371
00:16:26,550 --> 00:16:29,640
This model, trained by using

372
00:16:29,640 --> 00:16:31,740
the precision of FP16.

373
00:16:31,740 --> 00:16:32,823
This is a base model.

374
00:16:34,110 --> 00:16:36,420
However, we can have another quantization,

375
00:16:36,420 --> 00:16:39,423
which is MXFP4.

376
00:16:40,920 --> 00:16:43,770
We are talking about how
to present each weight.

377
00:16:43,770 --> 00:16:47,010
We are talking about how
to present each parameter.

378
00:16:47,010 --> 00:16:49,380
And instead of presenting each weight

379
00:16:49,380 --> 00:16:52,890
with 16 bit, you can
present the same weight

380
00:16:52,890 --> 00:16:54,750
with four bits.

381
00:16:54,750 --> 00:16:57,840
This will make a significance reduction

382
00:16:57,840 --> 00:16:59,580
in the memory footprint.

383
00:16:59,580 --> 00:17:01,830
Instead of having the full position,

384
00:17:01,830 --> 00:17:05,310
which is a base model, 40 gigabyte,

385
00:17:05,310 --> 00:17:08,340
you can get only 13 gigabytes.

386
00:17:08,340 --> 00:17:10,560
But everything came with a cost.

387
00:17:10,560 --> 00:17:13,740
The cost here is accuracy.

388
00:17:13,740 --> 00:17:15,840
For the baseline,

389
00:17:15,840 --> 00:17:18,480
you don't have an accuracy impact.

390
00:17:18,480 --> 00:17:21,033
However, for mixture of MXFP4,

391
00:17:22,590 --> 00:17:24,450
because you are going to reduce the number

392
00:17:24,450 --> 00:17:27,420
of bits presenting your weights,

393
00:17:27,420 --> 00:17:31,020
you will have 1 to 2% accuracy impact.

394
00:17:31,020 --> 00:17:33,670
This means that you can save

395
00:17:34,920 --> 00:17:38,040
65% of your memory,

396
00:17:38,040 --> 00:17:39,600
trading this by 1

397
00:17:39,600 --> 00:17:41,763
to 2% of accuracy loss.

398
00:17:43,530 --> 00:17:46,590
By doing this, you will have,

399
00:17:46,590 --> 00:17:48,960
the full model can be deployed

400
00:17:48,960 --> 00:17:52,080
with the 13 gigabyte in your memory.

401
00:17:52,080 --> 00:17:54,360
Do you remember the hardware constraint?

402
00:17:54,360 --> 00:17:56,700
We have 16 gigabytes.

403
00:17:56,700 --> 00:17:57,533
Now you can have

404
00:17:57,533 --> 00:18:02,010
the full model deployed inside GPU.

405
00:18:02,010 --> 00:18:04,170
One of the deployment strategy

406
00:18:04,170 --> 00:18:06,630
is to deploy the full model in one GPU,

407
00:18:06,630 --> 00:18:07,833
as you can see here.

408
00:18:08,730 --> 00:18:11,490
We are going to replicate the same model

409
00:18:11,490 --> 00:18:13,380
across the GPUs.

410
00:18:13,380 --> 00:18:15,630
And the significance of doing this

411
00:18:15,630 --> 00:18:16,960
is to have

412
00:18:18,480 --> 00:18:21,840
latency-sensitive workload implementing

413
00:18:21,840 --> 00:18:24,150
by doing parallel processing

414
00:18:24,150 --> 00:18:26,670
for multiple clients at the same time.

415
00:18:26,670 --> 00:18:28,980
Your application will not have any kind

416
00:18:28,980 --> 00:18:30,930
of a tolerance for the latency.

417
00:18:30,930 --> 00:18:32,430
You are going to do processing

418
00:18:32,430 --> 00:18:35,823
in a separate GPU for each client.

419
00:18:37,080 --> 00:18:38,950
Second strategy is

420
00:18:42,960 --> 00:18:44,250
this.

421
00:18:44,250 --> 00:18:46,410
You have one single model,

422
00:18:46,410 --> 00:18:49,713
weights shorted across GPUs,

423
00:18:50,610 --> 00:18:54,660
where for each GPU, you
will have 3.2 gigabytes

424
00:18:54,660 --> 00:18:56,043
for the model weights.

425
00:18:57,390 --> 00:18:59,850
And the remaining will
be for the KV cache.

426
00:18:59,850 --> 00:19:01,770
KV cache is simply,

427
00:19:01,770 --> 00:19:06,150
this is how to cache the tokens

428
00:19:06,150 --> 00:19:08,580
as part of your session in order not

429
00:19:08,580 --> 00:19:11,430
to let the model recalculate the token

430
00:19:11,430 --> 00:19:14,133
every time, generating new content.

431
00:19:14,970 --> 00:19:17,910
If you have a larger KV cache, this means

432
00:19:17,910 --> 00:19:19,630
that you can get

433
00:19:22,140 --> 00:19:23,400
large number of users,

434
00:19:23,400 --> 00:19:25,690
and the same time, you can get

435
00:19:27,960 --> 00:19:29,640
a larger context window.

436
00:19:29,640 --> 00:19:32,613
And this is important for your session.

437
00:19:35,040 --> 00:19:37,860
Let me show you

438
00:19:37,860 --> 00:19:39,663
the foundational part of this.

439
00:19:40,530 --> 00:19:42,840
We started to, with the architecture,

440
00:19:42,840 --> 00:19:44,640
high-level architecture,

441
00:19:44,640 --> 00:19:48,660
where we can start with
the data preparation.

442
00:19:48,660 --> 00:19:51,423
Let me show you something
with the data here.

443
00:19:53,370 --> 00:19:56,763
As you can see, those
are the data sources.

444
00:20:01,530 --> 00:20:03,060
You have different types of data source.

445
00:20:03,060 --> 00:20:06,120
You have CSV files, you have text files,

446
00:20:06,120 --> 00:20:08,100
and you have PDF files.

447
00:20:08,100 --> 00:20:10,200
This is a normal data source,

448
00:20:10,200 --> 00:20:11,250
how it look like.

449
00:20:11,250 --> 00:20:12,630
You have different files,

450
00:20:12,630 --> 00:20:13,950
you have a different format

451
00:20:13,950 --> 00:20:15,810
because you have, in your production line,

452
00:20:15,810 --> 00:20:17,280
you have different OEMs,

453
00:20:17,280 --> 00:20:20,910
and each one of them has its own structure

454
00:20:20,910 --> 00:20:21,743
to do this.

455
00:20:22,800 --> 00:20:25,830
What we need to do is
to fine tune the model,

456
00:20:25,830 --> 00:20:27,570
but what is the objective

457
00:20:27,570 --> 00:20:29,430
of fine tuning the model?

458
00:20:29,430 --> 00:20:32,580
The objective here is to give an assistant

459
00:20:32,580 --> 00:20:34,080
for your operators.

460
00:20:34,080 --> 00:20:37,620
This assistant will help your operator

461
00:20:37,620 --> 00:20:41,200
to have detailed, instructed steps

462
00:20:42,360 --> 00:20:45,630
considering the severity of each problem,

463
00:20:45,630 --> 00:20:47,490
considering the compliance,

464
00:20:47,490 --> 00:20:50,403
considering the safety,
and so on and so forth.

465
00:20:51,600 --> 00:20:52,890
The most important part

466
00:20:52,890 --> 00:20:57,420
is to let the model
understand the skills needed

467
00:20:57,420 --> 00:20:59,610
and let the model talk

468
00:20:59,610 --> 00:21:02,010
with the same tone needed.

469
00:21:02,010 --> 00:21:04,650
That's why we decided to use

470
00:21:04,650 --> 00:21:06,300
a fine-tuned model,

471
00:21:06,300 --> 00:21:09,093
using instructed fine tuning.

472
00:21:10,530 --> 00:21:13,803
Let's start with what exactly
happening under the hood.

473
00:21:15,690 --> 00:21:17,250
I will show you here, in the right side,

474
00:21:17,250 --> 00:21:20,580
as you can see, this is a data pipeline

475
00:21:20,580 --> 00:21:24,090
where you can read the
different documents,

476
00:21:24,090 --> 00:21:26,910
PDF file, text file, and document files.

477
00:21:26,910 --> 00:21:30,390
And then you can invoke a larger model

478
00:21:30,390 --> 00:21:34,200
in order to generate structured data

479
00:21:34,200 --> 00:21:35,880
to fine tune your model.

480
00:21:35,880 --> 00:21:38,430
The most important question here,

481
00:21:38,430 --> 00:21:42,360
why to not through the
data to the model directly

482
00:21:42,360 --> 00:21:44,010
to fine tune the model?

483
00:21:44,010 --> 00:21:45,240
The answer, simply,

484
00:21:45,240 --> 00:21:48,180
is if you are throwing
your data right away

485
00:21:48,180 --> 00:21:50,370
at your model, you are training

486
00:21:50,370 --> 00:21:51,753
a hallucination machine.

487
00:21:52,890 --> 00:21:54,720
The important part here,

488
00:21:54,720 --> 00:21:56,220
reading the document,

489
00:21:56,220 --> 00:21:57,930
invoking the model

490
00:21:57,930 --> 00:22:00,900
to return structured data,

491
00:22:00,900 --> 00:22:03,900
accordingly validate those data,

492
00:22:03,900 --> 00:22:06,510
and then you are happy

493
00:22:06,510 --> 00:22:10,170
to have full structure documents

494
00:22:10,170 --> 00:22:12,240
in order to fine tune the model.

495
00:22:12,240 --> 00:22:13,570
Let's start with

496
00:22:15,720 --> 00:22:16,803
running this.

497
00:22:20,790 --> 00:22:22,500
As you can see,

498
00:22:22,500 --> 00:22:24,900
the pipeline start reading this,

499
00:22:24,900 --> 00:22:26,310
and at the same time,

500
00:22:26,310 --> 00:22:28,770
start invoking the Bedrock

501
00:22:28,770 --> 00:22:31,500
to generate questions and answers.

502
00:22:31,500 --> 00:22:33,450
Why to generate the questions and answers?

503
00:22:33,450 --> 00:22:38,250
In order to have an instructed dataset

504
00:22:38,250 --> 00:22:40,470
in order to fine tune your model.

505
00:22:40,470 --> 00:22:42,093
Let me show you something here.

506
00:22:49,410 --> 00:22:52,050
This is the data preparation class

507
00:22:52,050 --> 00:22:55,200
that we are using to invoke the model.

508
00:22:55,200 --> 00:22:58,660
As you can see, here,
we are using this model

509
00:23:00,840 --> 00:23:04,233
to generate the structured data.

510
00:23:05,580 --> 00:23:09,480
And the most important part of this is,

511
00:23:09,480 --> 00:23:11,643
let me show you something very important,

512
00:23:12,660 --> 00:23:14,430
is the converse API.

513
00:23:14,430 --> 00:23:15,990
As you can see here,

514
00:23:15,990 --> 00:23:18,093
we are using the converse API.

515
00:23:18,960 --> 00:23:22,140
Converse API is giving you the flexibility

516
00:23:22,140 --> 00:23:25,230
of changing any model,
at any point of time,

517
00:23:25,230 --> 00:23:27,660
because it's using, for different models,

518
00:23:27,660 --> 00:23:30,573
same API signature.

519
00:23:31,470 --> 00:23:33,750
At the same time, and
the most important part,

520
00:23:33,750 --> 00:23:36,390
is the inference configurations.

521
00:23:36,390 --> 00:23:38,250
If you are configuring the maximum number

522
00:23:38,250 --> 00:23:41,520
of tokens correctly, you will be able

523
00:23:41,520 --> 00:23:43,260
to get your answer correctly,

524
00:23:43,260 --> 00:23:44,640
without having any kind

525
00:23:44,640 --> 00:23:47,343
of data split or something.

526
00:23:48,750 --> 00:23:50,400
The most important part here

527
00:23:50,400 --> 00:23:53,190
is the system prompt.

528
00:23:53,190 --> 00:23:55,560
This is an instructed prompt

529
00:23:55,560 --> 00:23:58,200
with only one shot.

530
00:23:58,200 --> 00:24:00,810
I'm giving the model a clear

531
00:24:00,810 --> 00:24:04,230
and detailed instruction to generate

532
00:24:04,230 --> 00:24:06,600
the realistic information,

533
00:24:06,600 --> 00:24:08,940
to include the severity

534
00:24:08,940 --> 00:24:11,490
to answer the safety questions correctly

535
00:24:11,490 --> 00:24:16,110
and include the needed information.

536
00:24:16,110 --> 00:24:17,310
By doing this,

537
00:24:17,310 --> 00:24:19,213
you will be able to have

538
00:24:19,213 --> 00:24:21,750
a full dataset

539
00:24:21,750 --> 00:24:23,640
with your structure,

540
00:24:23,640 --> 00:24:25,350
with your structured data.

541
00:24:25,350 --> 00:24:27,213
Second, and this is very important,

542
00:24:28,590 --> 00:24:30,540
why do we need to trust the LLM?

543
00:24:30,540 --> 00:24:33,660
Maybe the LLM itself will hallucinate.

544
00:24:33,660 --> 00:24:37,380
In this case, if your
LLM is hallucinating,

545
00:24:37,380 --> 00:24:40,470
you have to apply what we are calling

546
00:24:40,470 --> 00:24:43,110
deterministic validations.

547
00:24:43,110 --> 00:24:45,450
Yes, the LLM generated the content,

548
00:24:45,450 --> 00:24:47,310
but if this content is correct,

549
00:24:47,310 --> 00:24:49,290
if this is a right question and answer,

550
00:24:49,290 --> 00:24:50,790
if this is following

551
00:24:50,790 --> 00:24:54,300
what the standard operation
procedure is telling you,

552
00:24:54,300 --> 00:24:58,330
if this is following
even the needed structure

553
00:24:59,583 --> 00:25:02,310
for your response in adjacent way,

554
00:25:02,310 --> 00:25:03,690
why this is important?

555
00:25:03,690 --> 00:25:06,960
Because, again, we need to make sure

556
00:25:06,960 --> 00:25:08,670
that we are not having

557
00:25:08,670 --> 00:25:12,360
a single record in your structured data

558
00:25:12,360 --> 00:25:13,743
for fine tuning the model.

559
00:25:16,050 --> 00:25:18,300
Second is shorting.

560
00:25:18,300 --> 00:25:20,820
If you are starting to short your data,

561
00:25:20,820 --> 00:25:24,510
you have to short your
data in a smart way.

562
00:25:24,510 --> 00:25:26,160
If you have a very long paragraph,

563
00:25:26,160 --> 00:25:29,490
you cannot cut the paragraph in between.

564
00:25:29,490 --> 00:25:30,930
If you have a large section,

565
00:25:30,930 --> 00:25:32,880
you have to make sure that this section

566
00:25:34,719 --> 00:25:35,940
is split in a correct way.

567
00:25:35,940 --> 00:25:40,650
You cannot cut or split
a sentence in the middle.

568
00:25:40,650 --> 00:25:41,880
Why this is important?

569
00:25:41,880 --> 00:25:43,710
Again, same objective,

570
00:25:43,710 --> 00:25:46,230
structured data implemented correctly.

571
00:25:46,230 --> 00:25:48,360
As we can see on the right side,

572
00:25:48,360 --> 00:25:49,803
the job is done.

573
00:25:51,480 --> 00:25:55,590
And we have generated Q and A, done,

574
00:25:55,590 --> 00:25:57,150
validation, done.

575
00:25:57,150 --> 00:26:00,690
And as you can see, we
have some statistics here.

576
00:26:00,690 --> 00:26:03,720
We have 50 pair of questions

577
00:26:03,720 --> 00:26:07,530
and the answers requested, 45 generated,

578
00:26:07,530 --> 00:26:10,560
and we have five rejected.

579
00:26:10,560 --> 00:26:12,423
We can check here the output file.

580
00:26:14,070 --> 00:26:15,900
And from the output file,

581
00:26:15,900 --> 00:26:17,920
you can see this is rejected

582
00:26:19,890 --> 00:26:23,940
because of the frozen
belt misalignment section.

583
00:26:23,940 --> 00:26:25,050
This is the content,

584
00:26:25,050 --> 00:26:28,860
and this is the critical
information which is wrong.

585
00:26:28,860 --> 00:26:29,693
Why?

586
00:26:29,693 --> 00:26:30,690
Because the model itself

587
00:26:30,690 --> 00:26:34,290
or the pipeline itself
is doing this validations

588
00:26:34,290 --> 00:26:36,570
across the needed structure

589
00:26:36,570 --> 00:26:39,213
and across even the data inside the SOP.

590
00:26:40,200 --> 00:26:44,250
Accordingly, now we uploaded the data

591
00:26:44,250 --> 00:26:47,230
inside S3 in order to start

592
00:26:48,378 --> 00:26:49,478
fine tuning the model.

593
00:26:52,560 --> 00:26:54,690
I'm not sure if you
are familiar with this.

594
00:26:54,690 --> 00:26:59,690
This is AWS SageMaker AI Studio,

595
00:27:00,150 --> 00:27:03,120
where you can start to
fine tune the model.

596
00:27:03,120 --> 00:27:04,650
If you go on the left,

597
00:27:04,650 --> 00:27:06,813
you can see this is Jumpstart.

598
00:27:08,220 --> 00:27:09,510
Inside the Jumpstart,

599
00:27:09,510 --> 00:27:10,893
you can select the model.

600
00:27:11,910 --> 00:27:13,860
Here, the model family is Meta.

601
00:27:13,860 --> 00:27:15,270
This is a model family.

602
00:27:15,270 --> 00:27:16,103
Perfect.

603
00:27:18,240 --> 00:27:20,667
Llama 3.2

604
00:27:23,610 --> 00:27:25,470
billion instruct.

605
00:27:25,470 --> 00:27:26,613
This is our model.

606
00:27:27,990 --> 00:27:31,050
Here, you will find the
three different options,

607
00:27:31,050 --> 00:27:33,900
either to evaluate, deploy, and train.

608
00:27:33,900 --> 00:27:36,270
In our case, we are
going to train the model.

609
00:27:36,270 --> 00:27:38,433
I'm going to select training the model.

610
00:27:41,640 --> 00:27:42,930
After selecting the model,

611
00:27:42,930 --> 00:27:45,130
you have to select the dataset

612
00:27:48,390 --> 00:27:50,790
we did as part of the data preparation

613
00:27:50,790 --> 00:27:52,053
for the dataset.

614
00:27:59,280 --> 00:28:01,440
Here is the dataset.

615
00:28:01,440 --> 00:28:04,020
Here is the data we just uploaded.

616
00:28:04,020 --> 00:28:05,400
We select the data.

617
00:28:05,400 --> 00:28:07,410
And then we need, this
fine tuning will be,

618
00:28:07,410 --> 00:28:09,480
there is an output of this fine tuning

619
00:28:09,480 --> 00:28:12,960
or updated weights of your model

620
00:28:12,960 --> 00:28:14,520
based on your dataset.

621
00:28:14,520 --> 00:28:17,680
You are going to set the S3 bucket

622
00:28:27,000 --> 00:28:29,670
to get your updated model.

623
00:28:29,670 --> 00:28:32,250
Accordingly, you can go through this.

624
00:28:32,250 --> 00:28:34,590
I think it is normal

625
00:28:34,590 --> 00:28:36,300
to have five (indistinct).

626
00:28:36,300 --> 00:28:37,710
And this is very important.

627
00:28:37,710 --> 00:28:40,530
This is AWS recommended recipe

628
00:28:40,530 --> 00:28:42,030
to do the fine tuning,

629
00:28:42,030 --> 00:28:44,430
using this G5 instance.

630
00:28:44,430 --> 00:28:47,370
If you want to select a
different instance, it is fine.

631
00:28:47,370 --> 00:28:48,750
This is fully flexible,

632
00:28:48,750 --> 00:28:51,150
but this is what we are
recommending as part

633
00:28:51,150 --> 00:28:52,770
of fine tuning the model.

634
00:28:52,770 --> 00:28:54,090
Accordingly, we are going to use

635
00:28:54,090 --> 00:28:56,430
the same identity access management,

636
00:28:56,430 --> 00:28:59,490
same VPC, same encryption keys.

637
00:28:59,490 --> 00:29:03,510
And then we'll submit the model.

638
00:29:03,510 --> 00:29:05,673
We have to agree on those things.

639
00:29:10,470 --> 00:29:12,480
And then job started

640
00:29:12,480 --> 00:29:14,943
to do the fine tuning for the model.

641
00:29:15,840 --> 00:29:18,900
- [Karim] Okay, so now
I bet that many of you

642
00:29:18,900 --> 00:29:20,820
is asking themselves one question,

643
00:29:20,820 --> 00:29:22,080
which is, in my opinion,

644
00:29:22,080 --> 00:29:24,150
very valid if you are asking it.

645
00:29:24,150 --> 00:29:27,450
And the question is,
why are you guys doing

646
00:29:27,450 --> 00:29:30,900
this model fine tuning
and data preparation

647
00:29:30,900 --> 00:29:33,240
when you will anyways be using

648
00:29:33,240 --> 00:29:36,180
a RAG task in the edge?

649
00:29:36,180 --> 00:29:37,770
Maybe you are asking yourself

650
00:29:37,770 --> 00:29:39,720
if we just added this
piece of architecture

651
00:29:39,720 --> 00:29:41,910
in order to make our architecture look

652
00:29:41,910 --> 00:29:43,620
a little bit more fancy.

653
00:29:43,620 --> 00:29:46,200
Well, while we may love doing so,

654
00:29:46,200 --> 00:29:49,200
but, in fact, we have done
extensive experimentation

655
00:29:49,200 --> 00:29:52,230
in order to prove that this approach

656
00:29:52,230 --> 00:29:53,910
is, indeed, valid.

657
00:29:53,910 --> 00:29:55,500
And in order to prove that,

658
00:29:55,500 --> 00:29:56,580
we have used the technique

659
00:29:56,580 --> 00:29:59,910
which is called LLM-as-a-judge evaluation.

660
00:29:59,910 --> 00:30:02,883
And let me show you how
this technique works.

661
00:30:31,916 --> 00:30:33,840
(indistinct)
- Hmm?

662
00:30:33,840 --> 00:30:35,063
- [Karim] I'm gonna try something.

663
00:30:36,420 --> 00:30:38,673
Okay, please allow me a moment.

664
00:30:43,028 --> 00:30:46,861
(Mohamed speaks indistinctly)

665
00:30:49,020 --> 00:30:50,620
- [Karim] Yeah, for some reason,

666
00:30:51,870 --> 00:30:53,700
the aspect ratio is not working well.

667
00:30:53,700 --> 00:30:55,533
- [Mohamed] Put a different browser.

668
00:30:55,533 --> 00:30:57,783
(mumbles)

669
00:31:01,920 --> 00:31:03,090
- [Karim] Okay, so let me explain

670
00:31:03,090 --> 00:31:05,490
how LLM-as-a-judge evaluation works.

671
00:31:05,490 --> 00:31:09,000
I had some fancy animation, but, anyways.

672
00:31:09,000 --> 00:31:12,450
So we have our fine-tuned model

673
00:31:12,450 --> 00:31:14,730
and we have our base model,

674
00:31:14,730 --> 00:31:16,020
that Llama-based model

675
00:31:16,020 --> 00:31:18,360
that is produced by Meta,

676
00:31:18,360 --> 00:31:20,430
and we want to compare the performance

677
00:31:20,430 --> 00:31:23,700
of both models on direct task.

678
00:31:23,700 --> 00:31:26,280
So how it works, at the very first step,

679
00:31:26,280 --> 00:31:29,700
what we provide to both
models is the question

680
00:31:29,700 --> 00:31:32,820
and the context from the test dataset.

681
00:31:32,820 --> 00:31:35,580
And we ask both models
to generate an answer

682
00:31:35,580 --> 00:31:37,590
based on those question and context

683
00:31:37,590 --> 00:31:40,210
because usually this is how

684
00:31:42,051 --> 00:31:43,533
we do it in RAG applications.

685
00:31:46,290 --> 00:31:48,630
And then, as a next step,

686
00:31:48,630 --> 00:31:52,980
we have our three
LLM-as-a-judge evaluators.

687
00:31:52,980 --> 00:31:55,410
We have Claude 4.5 Sonnet,

688
00:31:55,410 --> 00:31:57,390
we have Claude 4.5 Haiku,

689
00:31:57,390 --> 00:32:01,320
and we have Amazon Nova Pro as judges.

690
00:32:01,320 --> 00:32:02,850
And we pass to each

691
00:32:02,850 --> 00:32:06,000
of those three judges

692
00:32:06,000 --> 00:32:07,470
five different inputs.

693
00:32:07,470 --> 00:32:09,150
We pass the question and the context

694
00:32:09,150 --> 00:32:10,410
from the test dataset

695
00:32:10,410 --> 00:32:12,540
that Salah has generated.

696
00:32:12,540 --> 00:32:14,790
We pass the answer from
the fine-tuned model

697
00:32:14,790 --> 00:32:17,400
from the previous step that I just showed,

698
00:32:17,400 --> 00:32:20,010
and we pass the answer from the base model

699
00:32:20,010 --> 00:32:21,570
based on the question and context.

700
00:32:21,570 --> 00:32:24,630
And, finally, we also pass
the ground truth answer

701
00:32:24,630 --> 00:32:25,923
from the test dataset.

702
00:32:27,270 --> 00:32:31,710
And we ask each of those three models

703
00:32:31,710 --> 00:32:34,950
to evaluate the result,

704
00:32:34,950 --> 00:32:36,930
the result generated
from the fine-tuned model

705
00:32:36,930 --> 00:32:37,920
and the base model,

706
00:32:37,920 --> 00:32:41,130
based on three evaluation criteria,

707
00:32:41,130 --> 00:32:44,550
which are, number one,
accuracy, which measures

708
00:32:44,550 --> 00:32:47,400
how well the result from
the fine-tuned model

709
00:32:47,400 --> 00:32:48,750
and the base model agrees

710
00:32:48,750 --> 00:32:50,430
with the ground truth answer

711
00:32:50,430 --> 00:32:52,110
from the test dataset.

712
00:32:52,110 --> 00:32:54,180
Number two evaluation criteria

713
00:32:54,180 --> 00:32:58,020
is the completeness, which
measures how well the answer

714
00:32:58,020 --> 00:33:01,440
is addressing all the different aspects

715
00:33:01,440 --> 00:33:02,910
of the question.

716
00:33:02,910 --> 00:33:04,950
And number three evaluation criteria

717
00:33:04,950 --> 00:33:08,310
is the relevance, which is, in my opinion,

718
00:33:08,310 --> 00:33:11,280
the most important metric
in the RAG application

719
00:33:11,280 --> 00:33:14,400
because this one measures
how well the answer

720
00:33:14,400 --> 00:33:17,130
is following the context given to it,

721
00:33:17,130 --> 00:33:20,163
because this is how RAG works.

722
00:33:22,140 --> 00:33:24,810
And then we ask the three judges

723
00:33:24,810 --> 00:33:26,490
to evaluate the performance

724
00:33:26,490 --> 00:33:28,640
of the base model and
the fine-tuned model.

725
00:33:30,960 --> 00:33:32,860
And here we have the results

726
00:33:34,407 --> 00:33:38,043
of our LLM-as-a-judge evaluation.

727
00:33:39,570 --> 00:33:42,480
In my opinion, this is
really great results

728
00:33:42,480 --> 00:33:47,250
because this shows that
the different evaluators,

729
00:33:47,250 --> 00:33:49,500
this different evaluator models,

730
00:33:49,500 --> 00:33:52,350
shows that the fine-tuned
model is outperforming

731
00:33:52,350 --> 00:33:54,510
the base model in the RAG task

732
00:33:54,510 --> 00:33:56,550
for all the dataset aggregated

733
00:33:56,550 --> 00:33:59,700
for all the three different
evaluator criteria.

734
00:33:59,700 --> 00:34:02,640
So, for example, Claude 4.5 Haiku says

735
00:34:02,640 --> 00:34:05,190
that the fine-tuned model is outperforming

736
00:34:05,190 --> 00:34:08,063
the base model by 17%.

737
00:34:09,060 --> 00:34:11,190
And Claude 4.5 Sonnet says

738
00:34:11,190 --> 00:34:15,360
that the fine-tuned model
is outperforming by 15%.

739
00:34:15,360 --> 00:34:18,420
And Nova Pro says it outperforms

740
00:34:18,420 --> 00:34:19,890
the base model by 10%.

741
00:34:19,890 --> 00:34:20,880
So, on average,

742
00:34:20,880 --> 00:34:25,260
we have 14 percentage point improvements

743
00:34:25,260 --> 00:34:28,590
for adding the fine-tuned
model on the RAG application

744
00:34:28,590 --> 00:34:30,813
for our agentic AI application.

745
00:34:32,100 --> 00:34:34,050
So now let me quickly recap

746
00:34:34,050 --> 00:34:36,303
before jumping to the next step.

747
00:34:37,200 --> 00:34:40,440
We started with deploying
the infrastructure

748
00:34:40,440 --> 00:34:42,840
to our EC2 machines

749
00:34:42,840 --> 00:34:46,410
in order to replicate or mimic

750
00:34:46,410 --> 00:34:48,420
the environment of AWS Outpost

751
00:34:48,420 --> 00:34:51,090
to have our agentic AI application.

752
00:34:51,090 --> 00:34:53,250
Then Salah thankfully showed us how

753
00:34:53,250 --> 00:34:55,903
to prepare the data, and fine tuned

754
00:34:55,903 --> 00:34:58,530
a small language model for the RAG task.

755
00:34:58,530 --> 00:35:00,600
And I just showed you how important

756
00:35:00,600 --> 00:35:04,020
this is in our architecture.

757
00:35:04,020 --> 00:35:06,180
Now we need to put this together

758
00:35:06,180 --> 00:35:08,220
into an agentic AI application

759
00:35:08,220 --> 00:35:11,130
that runs on the edge on AWS Outpost.

760
00:35:11,130 --> 00:35:13,440
And this agentic AI
application will have access

761
00:35:13,440 --> 00:35:14,760
to direct tool

762
00:35:14,760 --> 00:35:16,710
and also the telemetry data tool.

763
00:35:16,710 --> 00:35:18,543
So let's start doing that.

764
00:35:23,370 --> 00:35:24,540
Okay, as you can see,

765
00:35:24,540 --> 00:35:27,150
that our two EC2 machines are up

766
00:35:27,150 --> 00:35:29,520
and running now, the
factory agent instance

767
00:35:29,520 --> 00:35:33,000
and the fine-tuned small
language model instance.

768
00:35:33,000 --> 00:35:34,690
So what I would like to do

769
00:35:39,660 --> 00:35:41,530
is to log in

770
00:35:42,990 --> 00:35:46,980
to the factory agent instance.

771
00:35:46,980 --> 00:35:48,690
So I would use Kiro?? for that.

772
00:35:49,641 --> 00:35:52,080
I installed a plugin for remote SSH.

773
00:35:52,080 --> 00:35:53,463
I connect to the host.

774
00:35:56,160 --> 00:35:58,740
And now it's opening an SSH session

775
00:35:58,740 --> 00:36:00,690
inside the EC2 machine,

776
00:36:00,690 --> 00:36:03,603
which we instantiated at the beginning.

777
00:36:05,280 --> 00:36:07,680
So now we are in the EC2 machine.

778
00:36:07,680 --> 00:36:08,790
I need to go inside

779
00:36:08,790 --> 00:36:10,140
the factory agent directory,

780
00:36:10,140 --> 00:36:12,903
which I copied in my user data script.

781
00:36:22,590 --> 00:36:23,943
I zoom in a little bit.

782
00:36:28,131 --> 00:36:30,866
Hmm.

783
00:36:30,866 --> 00:36:32,673
Zoom in is not working.

784
00:36:35,250 --> 00:36:37,195
- Oh-
- During this time-

785
00:36:37,195 --> 00:36:38,375
- [Karim] Now I get the problem. (laughs)

786
00:36:38,375 --> 00:36:39,810
- [Mohamed] Explain
something very important.

787
00:36:39,810 --> 00:36:42,780
We used two different approaches here.

788
00:36:42,780 --> 00:36:45,450
We used fine-tuned model,

789
00:36:45,450 --> 00:36:47,403
and the same time, we used RAG.

790
00:36:48,450 --> 00:36:53,070
Anyone have an impression why we did both?

791
00:36:53,070 --> 00:36:55,583
Because most of the time,
you are using one of them.

792
00:36:58,320 --> 00:36:59,163
Any answers?

793
00:37:03,756 --> 00:37:05,034
Huh?

794
00:37:05,034 --> 00:37:06,132
- [Audience Member] The
information that it's showing

795
00:37:06,132 --> 00:37:08,245
on the right database
(speaks faintly) updated

796
00:37:08,245 --> 00:37:10,279
in the future (speaks faintly)

797
00:37:10,279 --> 00:37:11,520
fine-tuned model where
it can support that.

798
00:37:11,520 --> 00:37:12,660
- Exactly.
- Yeah.

799
00:37:12,660 --> 00:37:15,570
- [Mohamed] And let me
dive deep into this.

800
00:37:15,570 --> 00:37:16,980
The most important part here

801
00:37:16,980 --> 00:37:19,740
is to have the knowledge

802
00:37:19,740 --> 00:37:21,420
about your document

803
00:37:21,420 --> 00:37:23,790
and the skills needed.

804
00:37:23,790 --> 00:37:25,280
To fine tune the model

805
00:37:25,280 --> 00:37:27,990
as you are gaining the skill needed,

806
00:37:27,990 --> 00:37:31,800
you are setting the tone of your agent

807
00:37:31,800 --> 00:37:33,363
to respond correctly.

808
00:37:34,320 --> 00:37:36,510
By having a RAG, you are retrieving

809
00:37:36,510 --> 00:37:38,760
up-to-date information

810
00:37:38,760 --> 00:37:40,620
from your knowledge base.

811
00:37:40,620 --> 00:37:42,990
That's why we combine both

812
00:37:42,990 --> 00:37:47,610
to achieve this LLM-as-a-judge
evaluation results.

813
00:37:47,610 --> 00:37:50,580
We are talking about 15% increase

814
00:37:50,580 --> 00:37:51,843
from the base model.

815
00:37:53,520 --> 00:37:54,353
- [Karim] Cool.

816
00:37:54,353 --> 00:37:57,360
So now, as Salah is
talking about the RAG tool,

817
00:37:57,360 --> 00:37:59,760
I would like to start with showing you how

818
00:37:59,760 --> 00:38:02,400
to develop that RAG tool
that I will be using

819
00:38:02,400 --> 00:38:04,710
for my agent application.

820
00:38:04,710 --> 00:38:07,020
And I pre-created this class,

821
00:38:07,020 --> 00:38:08,790
which is called RAG retriever.

822
00:38:08,790 --> 00:38:11,430
Previously, I also, in my environment,

823
00:38:11,430 --> 00:38:14,940
I pre-ingested the
documents inside Chroma DB

824
00:38:14,940 --> 00:38:16,980
as a vector restore.

825
00:38:16,980 --> 00:38:18,900
And I created a very simple method,

826
00:38:18,900 --> 00:38:20,850
which is a search method,

827
00:38:20,850 --> 00:38:24,510
that you can provide it with a query

828
00:38:24,510 --> 00:38:26,490
and the number of results,

829
00:38:26,490 --> 00:38:28,530
and then it uses this query

830
00:38:28,530 --> 00:38:30,150
to look up the information

831
00:38:30,150 --> 00:38:31,860
inside the vector store,

832
00:38:31,860 --> 00:38:34,950
and retrieves the most
relevant information

833
00:38:34,950 --> 00:38:36,663
from within your vector store.

834
00:38:37,920 --> 00:38:41,070
And then I use that tool decorator

835
00:38:41,070 --> 00:38:45,280
from Strands SDK in order to have

836
00:38:46,950 --> 00:38:49,290
this search documents method.

837
00:38:49,290 --> 00:38:51,900
And here, I'm providing some docstring

838
00:38:51,900 --> 00:38:54,840
which will be used by the
agent to understand what

839
00:38:54,840 --> 00:38:56,070
this tool is doing

840
00:38:56,070 --> 00:38:58,230
and how it can actually be used.

841
00:38:58,230 --> 00:39:00,600
And then, as you can see,

842
00:39:00,600 --> 00:39:02,850
we are iterating over the results

843
00:39:02,850 --> 00:39:05,160
of the retrieval

844
00:39:05,160 --> 00:39:06,600
from the vector store,

845
00:39:06,600 --> 00:39:09,933
and we are printing
them in a noise format.

846
00:39:10,830 --> 00:39:14,250
So this is a tool for RAG retrieval,

847
00:39:14,250 --> 00:39:16,380
augmented and generation.

848
00:39:16,380 --> 00:39:19,200
Do you think, in this implementation here,

849
00:39:19,200 --> 00:39:21,153
anything is missing here?

850
00:39:22,800 --> 00:39:24,660
Again, we have retrieval,

851
00:39:24,660 --> 00:39:26,730
augmented, and generation.

852
00:39:26,730 --> 00:39:30,750
Anything you see missing in
this tool implementation?

853
00:39:30,750 --> 00:39:32,283
- [Mohamed] A major thing.

854
00:39:32,283 --> 00:39:34,410
(Karim and Mohamed laugh)

855
00:39:34,410 --> 00:39:35,970
- [Karim] Okay, just to save your time,

856
00:39:35,970 --> 00:39:37,290
we have the G missing,

857
00:39:37,290 --> 00:39:38,940
the generation missing.

858
00:39:38,940 --> 00:39:40,170
If you remember, the model

859
00:39:40,170 --> 00:39:43,050
that Salah spent some time fine tuning,

860
00:39:43,050 --> 00:39:45,060
we're not using that model here, right?

861
00:39:45,060 --> 00:39:48,270
And what I would like to
show you is how to use

862
00:39:48,270 --> 00:39:51,360
that model in order to
enhance the results,

863
00:39:51,360 --> 00:39:54,210
like I showed in the
LLM-as-a-judge evaluation.

864
00:39:54,210 --> 00:39:56,340
So what I will do,

865
00:39:56,340 --> 00:39:59,560
we will be instantiating Ollama client

866
00:40:00,450 --> 00:40:02,760
using the IP address of the machine

867
00:40:02,760 --> 00:40:04,560
which has the fine-tuned model

868
00:40:04,560 --> 00:40:07,320
with the port that opens up

869
00:40:07,320 --> 00:40:09,210
the Ollama connection.

870
00:40:09,210 --> 00:40:11,160
And then I need to just copy

871
00:40:11,160 --> 00:40:14,913
and paste couple of code parts.

872
00:40:17,310 --> 00:40:19,023
I will just paste it here.

873
00:40:29,760 --> 00:40:30,593
Yeah.

874
00:40:30,593 --> 00:40:33,873
And then I change this to response.

875
00:40:35,580 --> 00:40:38,550
Okay, so now we have
our RAG tool complete,

876
00:40:38,550 --> 00:40:40,590
at least in my eyes.

877
00:40:40,590 --> 00:40:42,060
We have the retrieval part

878
00:40:42,060 --> 00:40:44,010
and we have the generation part,

879
00:40:44,010 --> 00:40:46,830
asking Ollama to invoke the endpoint

880
00:40:46,830 --> 00:40:48,690
of our fine-tuned model,

881
00:40:48,690 --> 00:40:52,140
passing with the query and the result.

882
00:40:52,140 --> 00:40:54,000
So this was the first tool,

883
00:40:54,000 --> 00:40:55,800
and this tool was to retrieve

884
00:40:55,800 --> 00:40:57,990
the standard operating procedures

885
00:40:57,990 --> 00:41:00,090
and the manuals from
the different machines

886
00:41:00,090 --> 00:41:01,653
inside your production line.

887
00:41:02,850 --> 00:41:05,340
Now, the second tool
is that telemetry tool.

888
00:41:05,340 --> 00:41:07,590
And this telemetry tool is to retrieve

889
00:41:07,590 --> 00:41:10,410
real-time telemetry data and alarms

890
00:41:10,410 --> 00:41:13,440
from your machines inside
your production line.

891
00:41:13,440 --> 00:41:15,480
And I have marked this real-time data

892
00:41:15,480 --> 00:41:17,670
by a very simple CSV file,

893
00:41:17,670 --> 00:41:19,410
as you can see.

894
00:41:19,410 --> 00:41:20,460
I'm not sure if you're seeing.

895
00:41:20,460 --> 00:41:22,110
Let me zoom in a little bit.

896
00:41:22,110 --> 00:41:25,320
As you can see, the CSV
file has a device name,

897
00:41:25,320 --> 00:41:28,530
the sensor type of that
specific device, the reading,

898
00:41:28,530 --> 00:41:30,810
and the timestamp for that reading.

899
00:41:30,810 --> 00:41:32,430
And we have two devices.

900
00:41:32,430 --> 00:41:33,900
If you remember from my first slide,

901
00:41:33,900 --> 00:41:36,030
we have freezer tunnel machine

902
00:41:36,030 --> 00:41:37,740
and the cookie former machine.

903
00:41:37,740 --> 00:41:39,570
And for each of those two devices,

904
00:41:39,570 --> 00:41:41,520
we have two different sensors,

905
00:41:41,520 --> 00:41:43,110
the temperature and the speed.

906
00:41:43,110 --> 00:41:44,190
And then we have the reading

907
00:41:44,190 --> 00:41:47,100
for those different sensors.

908
00:41:47,100 --> 00:41:48,540
And, finally, the timestamp

909
00:41:48,540 --> 00:41:50,883
at that specific reading.

910
00:41:52,530 --> 00:41:53,880
So for the telemetry tool,

911
00:41:53,880 --> 00:41:55,500
I also pre-created a class,

912
00:41:55,500 --> 00:41:56,910
which is the telemetry reader

913
00:41:56,910 --> 00:42:00,390
that reads this CSV file.

914
00:42:00,390 --> 00:42:03,960
And then I also created
another helper method,

915
00:42:03,960 --> 00:42:08,370
which converts this CSV into a timeframe.

916
00:42:08,370 --> 00:42:12,450
And we pass to this method three things,

917
00:42:12,450 --> 00:42:15,450
the device name that we want to look for,

918
00:42:15,450 --> 00:42:18,120
that we want to look the telemetry for.

919
00:42:18,120 --> 00:42:20,640
The current time where we are standing.

920
00:42:20,640 --> 00:42:22,710
And the number of minutes back in time

921
00:42:22,710 --> 00:42:23,880
where we want to look at.

922
00:42:23,880 --> 00:42:25,100
So, for example, if we want to look

923
00:42:25,100 --> 00:42:27,600
at the telemetry data for
the last five minutes,

924
00:42:27,600 --> 00:42:29,823
we set the minutes back here to five.

925
00:42:30,930 --> 00:42:33,240
And here, if we, for example, provided

926
00:42:33,240 --> 00:42:35,040
as an input the device name corresponds

927
00:42:35,040 --> 00:42:37,170
to freezer tunnel, this is how

928
00:42:37,170 --> 00:42:38,550
the output can look like.

929
00:42:38,550 --> 00:42:39,930
So the freezer tunnel

930
00:42:39,930 --> 00:42:42,390
has temperature and speed sensors,

931
00:42:42,390 --> 00:42:43,860
and those are the readings

932
00:42:43,860 --> 00:42:46,140
for the different timestamps.

933
00:42:46,140 --> 00:42:48,420
Now I want to create a Strands tool

934
00:42:48,420 --> 00:42:50,220
out of that one.

935
00:42:50,220 --> 00:42:52,980
So let me create it as we go.

936
00:42:52,980 --> 00:42:57,630
If you remember, I would
use that tool decorator.

937
00:42:57,630 --> 00:42:59,920
I would create a method called

938
00:43:01,839 --> 00:43:02,922
get_telemetry

939
00:43:07,906 --> 00:43:08,760
_data.

940
00:43:08,760 --> 00:43:11,760
And for that method, I need a device name,

941
00:43:11,760 --> 00:43:14,160
which is of type string.

942
00:43:14,160 --> 00:43:17,253
And I need minutes back,

943
00:43:18,120 --> 00:43:20,043
which is of type integer.

944
00:43:22,170 --> 00:43:25,440
And the return should be here,

945
00:43:25,440 --> 00:43:27,663
a formatted string.

946
00:43:30,600 --> 00:43:32,820
Again, for any tool, we need

947
00:43:32,820 --> 00:43:36,260
to have a well-structured docstring.

948
00:43:36,260 --> 00:43:39,753
So I will be copying the
docstring from my notes here.

949
00:43:47,070 --> 00:43:49,800
And then we need to code the tool.

950
00:43:49,800 --> 00:43:52,170
So this method here instantiates

951
00:43:52,170 --> 00:43:53,400
the class telemetry reader.

952
00:43:53,400 --> 00:43:54,543
We need to have it.

953
00:43:59,528 --> 00:44:01,590
get_telemetry_reader.

954
00:44:01,590 --> 00:44:04,500
And in order to call the method

955
00:44:04,500 --> 00:44:08,400
which I showed you before,
which is this one here,

956
00:44:08,400 --> 00:44:09,480
we need the device name,

957
00:44:09,480 --> 00:44:10,830
which is passed as an input.

958
00:44:10,830 --> 00:44:13,350
We need the minutes back, which
is also passed as an input.

959
00:44:13,350 --> 00:44:15,960
And we need the current time string.

960
00:44:15,960 --> 00:44:18,630
Luckily enough, Strands
has its own implementation

961
00:44:18,630 --> 00:44:21,663
of current time, so we
will be using that one.

962
00:44:28,232 --> 00:44:29,342
current_time_str

963
00:44:29,342 --> 00:44:33,120
= current_time_ class from Strands.

964
00:44:33,120 --> 00:44:35,820
And, finally, now we
need to call the method

965
00:44:35,820 --> 00:44:37,830
that I just showed you,

966
00:44:37,830 --> 00:44:39,233
data frame =

967
00:44:41,004 --> 00:44:41,921
tel_reader.

968
00:44:50,383 --> 00:44:53,490
Get_device_sensors_in_timeframe.

969
00:44:53,490 --> 00:44:55,710
And we passed with the device name

970
00:44:55,710 --> 00:44:57,030
that we have as an input.

971
00:44:57,030 --> 00:45:00,510
We passed with the current time string

972
00:45:00,510 --> 00:45:01,560
and we passed

973
00:45:01,560 --> 00:45:04,743
with the minutes back.

974
00:45:06,690 --> 00:45:09,660
And now we just need to formulate

975
00:45:09,660 --> 00:45:11,973
our results in a nice F string,

976
00:45:15,210 --> 00:45:17,927
Readings for device,

977
00:45:20,377 --> 00:45:21,460
{device_name}

978
00:45:22,470 --> 00:45:24,100
for the last

979
00:45:26,752 --> 00:45:28,752
{minutes_back,} minutes:

980
00:45:33,720 --> 00:45:36,000
And then we just need to
concatenate the results

981
00:45:36,000 --> 00:45:38,250
that we get from the method,

982
00:45:38,250 --> 00:45:40,003
result +=

983
00:45:41,370 --> 00:45:43,650
json.dumps.

984
00:45:43,650 --> 00:45:46,080
And then we have the data frame,

985
00:45:46,080 --> 00:45:48,993
and we set the indentation to two.

986
00:45:50,580 --> 00:45:53,703
And, finally, we return the results.

987
00:45:55,320 --> 00:45:56,153
Cool.

988
00:45:56,153 --> 00:45:57,810
So as any good software engineer,

989
00:45:57,810 --> 00:45:59,793
I wrote a tool, I just need to test it.

990
00:46:00,630 --> 00:46:04,290
Let me do that very quickly, in order

991
00:46:04,290 --> 00:46:06,243
for the application to work at the end.

992
00:46:08,188 --> 00:46:09,771
get_telemetry_data.

993
00:46:11,790 --> 00:46:14,790
And we need to have one device

994
00:46:14,790 --> 00:46:16,500
from our CSV file,

995
00:46:16,500 --> 00:46:18,550
which is, for example, the freezer tunnel

996
00:46:19,920 --> 00:46:21,543
for the last five minutes.

997
00:46:40,500 --> 00:46:41,333
Okay, yeah.

998
00:46:41,333 --> 00:46:42,603
I always do this problem.

999
00:46:44,400 --> 00:46:46,773
It should be only return result,

1000
00:46:49,440 --> 00:46:50,273
and now it works.

1001
00:46:50,273 --> 00:46:52,230
So now you can see

1002
00:46:52,230 --> 00:46:57,150
that we have our readings

1003
00:46:57,150 --> 00:46:58,230
for the freezer tunnel

1004
00:46:58,230 --> 00:46:59,910
for the last five minutes

1005
00:46:59,910 --> 00:47:02,403
structured in a nice JSON format.

1006
00:47:04,650 --> 00:47:07,790
So the final thing that
I would like to add here

1007
00:47:07,790 --> 00:47:09,480
is a very simple tool inside

1008
00:47:09,480 --> 00:47:13,080
this telemetry tool, which is a tool

1009
00:47:13,080 --> 00:47:16,500
that can be used as a
lookup for the agent,

1010
00:47:16,500 --> 00:47:20,880
to understand which devices
that it has access to.

1011
00:47:20,880 --> 00:47:22,860
Think about the situation here.

1012
00:47:22,860 --> 00:47:25,380
For example, I type freezer_tunnel,

1013
00:47:25,380 --> 00:47:27,210
which is the name that I just copied

1014
00:47:27,210 --> 00:47:30,140
and pasted as-is from the CSV file.

1015
00:47:30,140 --> 00:47:32,820
In real-life scenario,
users don't know how

1016
00:47:32,820 --> 00:47:35,520
the exact name is written
inside your database.

1017
00:47:35,520 --> 00:47:37,140
So we need to have some sort of a lookup

1018
00:47:37,140 --> 00:47:41,310
so that if, for example,
the user had a typo

1019
00:47:41,310 --> 00:47:43,260
or type it without the underscore

1020
00:47:43,260 --> 00:47:45,720
or had a capital, small
letter or so on, so forth,

1021
00:47:45,720 --> 00:47:46,620
this should work.

1022
00:47:46,620 --> 00:47:48,310
So let me just copy and paste

1023
00:47:49,350 --> 00:47:52,133
the last tool, list_available_devices.

1024
00:47:54,930 --> 00:47:57,390
And that should be it.

1025
00:47:57,390 --> 00:48:00,270
And now the last fun part,

1026
00:48:00,270 --> 00:48:03,120
which is the agent

1027
00:48:03,120 --> 00:48:06,630
which puts all those things together.

1028
00:48:06,630 --> 00:48:09,000
And so I pre-created this class,

1029
00:48:09,000 --> 00:48:10,770
which is called FactoryAgent.

1030
00:48:10,770 --> 00:48:13,860
It uses the GPT OSS model, the edge model

1031
00:48:13,860 --> 00:48:16,830
that I deployed at the
beginning of the session.

1032
00:48:16,830 --> 00:48:19,530
And here, it uses

1033
00:48:19,530 --> 00:48:21,870
this big system prompt.

1034
00:48:21,870 --> 00:48:24,300
I would like to walk
you through the prompt

1035
00:48:24,300 --> 00:48:25,380
and how I structured it

1036
00:48:25,380 --> 00:48:28,380
because it might be relevant to you.

1037
00:48:28,380 --> 00:48:29,910
So the first thing that I pass

1038
00:48:29,910 --> 00:48:32,160
to the prompt is some orientation

1039
00:48:32,160 --> 00:48:34,560
to how the tools look like,

1040
00:48:34,560 --> 00:48:36,780
what tools does it has access to.

1041
00:48:36,780 --> 00:48:39,360
And the second thing is some scenarios,

1042
00:48:39,360 --> 00:48:41,610
some possible scenarios and examples

1043
00:48:41,610 --> 00:48:43,230
of users' interaction.

1044
00:48:43,230 --> 00:48:46,200
And based on those user
interactions, what tools

1045
00:48:46,200 --> 00:48:49,290
that the agent should be
using one after the other.

1046
00:48:49,290 --> 00:48:52,293
So it's some sort of a
few short prompting here.

1047
00:48:54,120 --> 00:48:54,953
Right.

1048
00:48:54,953 --> 00:48:57,090
And then we have the system
prompt, we have the model,

1049
00:48:57,090 --> 00:48:59,490
and we have the tools I
imported from the class.

1050
00:48:59,490 --> 00:49:02,340
We instantiate the Strands
agent, and we are good to go.

1051
00:49:02,340 --> 00:49:06,450
Finally, we need to test our agent

1052
00:49:06,450 --> 00:49:08,523
and see how the result looks like.

1053
00:49:09,810 --> 00:49:12,030
Before the session, I
asked my best friend Kiro

1054
00:49:12,030 --> 00:49:14,250
to create a nice UI

1055
00:49:14,250 --> 00:49:17,040
that I will be using to test my agent.

1056
00:49:17,040 --> 00:49:20,703
So I will be just invoking
this agent, this UI.

1057
00:49:29,130 --> 00:49:31,803
Yep. And here we have our UI.

1058
00:49:32,970 --> 00:49:35,250
So now, since we have our agent,

1059
00:49:35,250 --> 00:49:37,410
I would like you to put yourself

1060
00:49:37,410 --> 00:49:39,990
into the shoes of the operator

1061
00:49:39,990 --> 00:49:41,520
inside the cookie factory.

1062
00:49:41,520 --> 00:49:43,380
Remember, my first slide.

1063
00:49:43,380 --> 00:49:45,660
When the visual inspector has detected

1064
00:49:45,660 --> 00:49:47,490
a problem inside the cookie.

1065
00:49:47,490 --> 00:49:50,370
Now you are a junior operator inside

1066
00:49:50,370 --> 00:49:51,600
this cookie factory

1067
00:49:51,600 --> 00:49:53,340
and you want to understand
what is the problem.

1068
00:49:53,340 --> 00:49:57,030
You know that the visual
quality inspection

1069
00:49:57,030 --> 00:50:00,180
has two devices in front of
it, which is the freezer tunnel

1070
00:50:00,180 --> 00:50:02,010
and the cookie former machine.

1071
00:50:02,010 --> 00:50:03,960
So as a junior operator now,

1072
00:50:03,960 --> 00:50:06,090
what I would do is ask

1073
00:50:06,090 --> 00:50:08,740
a very simple question, debug

1074
00:50:10,470 --> 00:50:12,723
freezer tunnel.

1075
00:50:14,790 --> 00:50:15,810
That's a very simple,

1076
00:50:15,810 --> 00:50:20,490
but it's a powerful enough prompt

1077
00:50:20,490 --> 00:50:22,680
in order for the agent to understand

1078
00:50:22,680 --> 00:50:25,020
or try to resonate what is wrong

1079
00:50:25,020 --> 00:50:26,373
with this freezer tunnel.

1080
00:50:27,570 --> 00:50:29,430
And as you can see,

1081
00:50:29,430 --> 00:50:30,840
it used the listing devices

1082
00:50:30,840 --> 00:50:35,250
because I didn't use the 100% correct name

1083
00:50:35,250 --> 00:50:37,350
of the device inside my CSV file.

1084
00:50:37,350 --> 00:50:40,020
It used the get telemetry
data tool that I just coded

1085
00:50:40,020 --> 00:50:42,960
and it used the search documentations tool

1086
00:50:42,960 --> 00:50:45,480
that we also have written for the RAG.

1087
00:50:45,480 --> 00:50:46,683
Let's see why that.

1088
00:50:53,010 --> 00:50:54,300
And as you can see in the results,

1089
00:50:54,300 --> 00:50:57,120
I will make it bigger in a second,

1090
00:50:57,120 --> 00:51:00,510
what it did is it retrieved
the telemetry data,

1091
00:51:00,510 --> 00:51:02,730
and it compared the telemetry data

1092
00:51:02,730 --> 00:51:04,620
with the correct results

1093
00:51:04,620 --> 00:51:06,390
from the documentations

1094
00:51:06,390 --> 00:51:10,230
to see if those measurements
make sense or not.

1095
00:51:10,230 --> 00:51:12,000
And in our case, it detected

1096
00:51:12,000 --> 00:51:15,930
that the temperature is
not in the correct range.

1097
00:51:15,930 --> 00:51:17,730
And here, it also suggested

1098
00:51:17,730 --> 00:51:20,370
some follow-up actions in order

1099
00:51:20,370 --> 00:51:22,950
to debug this machine
in order to restore it

1100
00:51:22,950 --> 00:51:26,853
to the operating state.

1101
00:51:29,160 --> 00:51:30,723
- [Mohamed] Okay, perfect.

1102
00:51:31,680 --> 00:51:33,720
This is what happens when

1103
00:51:33,720 --> 00:51:36,393
you have a factory start listening.

1104
00:51:37,530 --> 00:51:42,270
Everyone and everything
inside your factory

1105
00:51:42,270 --> 00:51:45,363
are now talking with the same language,

1106
00:51:46,260 --> 00:51:49,620
which means machines, IoT sensors,

1107
00:51:49,620 --> 00:51:53,460
systems, are fully integrated together.

1108
00:51:53,460 --> 00:51:57,480
Where you can have a AI system

1109
00:51:57,480 --> 00:52:01,860
that can give you, gives
you different types

1110
00:52:01,860 --> 00:52:05,280
of recommendations, explanations,

1111
00:52:05,280 --> 00:52:09,450
insights about your factory.

1112
00:52:09,450 --> 00:52:10,770
The important part here,

1113
00:52:10,770 --> 00:52:12,330
and this is a key take-away,

1114
00:52:12,330 --> 00:52:15,810
is we connected the operations

1115
00:52:15,810 --> 00:52:18,390
by having a full deployment

1116
00:52:18,390 --> 00:52:21,990
over Outpost EKS local cluster.

1117
00:52:21,990 --> 00:52:23,940
In case of any disconnection,

1118
00:52:23,940 --> 00:52:26,670
you still have access
to your control plane,

1119
00:52:26,670 --> 00:52:28,740
you still have access to your data plane,

1120
00:52:28,740 --> 00:52:32,550
and you can manage your
infrastructure completely

1121
00:52:32,550 --> 00:52:34,800
in case of any disruption.

1122
00:52:34,800 --> 00:52:37,110
Second is deploying

1123
00:52:37,110 --> 00:52:39,990
a small language model at the edge,

1124
00:52:39,990 --> 00:52:43,140
which makes this kind of intelligence

1125
00:52:43,140 --> 00:52:44,970
real-time intelligence.

1126
00:52:44,970 --> 00:52:48,900
You understanding what exactly
you are deploying the agents,

1127
00:52:48,900 --> 00:52:51,510
getting the insights, and then giving

1128
00:52:51,510 --> 00:52:54,090
a recommendation on the fly.

1129
00:52:54,090 --> 00:52:57,030
Third, and this is very important part,

1130
00:52:57,030 --> 00:52:59,940
is you are still generating

1131
00:52:59,940 --> 00:53:02,070
more data every day,

1132
00:53:02,070 --> 00:53:05,880
and you have to stay continuously learning

1133
00:53:05,880 --> 00:53:08,760
and continuously understanding

1134
00:53:08,760 --> 00:53:11,340
because the data is your gold.

1135
00:53:11,340 --> 00:53:14,130
Once you got this data,

1136
00:53:14,130 --> 00:53:16,080
update your model,

1137
00:53:16,080 --> 00:53:17,850
trigger the pipeline again,

1138
00:53:17,850 --> 00:53:19,650
and fine tune the model.

1139
00:53:19,650 --> 00:53:23,640
I encourage you to scan
those three QR codes

1140
00:53:23,640 --> 00:53:27,270
to do the full end-to-end deployment

1141
00:53:27,270 --> 00:53:31,050
of agentic AI, a small language model

1142
00:53:31,050 --> 00:53:31,983
at the edge.

1143
00:54:12,420 --> 00:54:15,570
Okay, now it's your turn

1144
00:54:15,570 --> 00:54:18,120
to start with the one single process.

1145
00:54:18,120 --> 00:54:21,090
Get some data, start to understand

1146
00:54:21,090 --> 00:54:23,310
your manufacturing production line

1147
00:54:23,310 --> 00:54:24,873
in a more detailed way.

1148
00:54:26,010 --> 00:54:29,940
Start small, fail fast,
understand your data,

1149
00:54:29,940 --> 00:54:33,750
structure the data in a
correct and proper way,

1150
00:54:33,750 --> 00:54:36,120
and then fine tune the model.

1151
00:54:36,120 --> 00:54:38,190
Get the fine-tuned model,

1152
00:54:38,190 --> 00:54:39,303
speak your language,

1153
00:54:40,140 --> 00:54:43,170
generating the correct information,

1154
00:54:43,170 --> 00:54:44,640
and then doing the deployment

1155
00:54:44,640 --> 00:54:46,090
on the edge over the Outpost.

1156
00:54:47,310 --> 00:54:50,700
Thank you, and it was
really a pleasure having you

1157
00:54:50,700 --> 00:54:51,900
as part of this session.

1158
00:54:51,900 --> 00:54:55,410
And I encourage you to take the survey

1159
00:54:55,410 --> 00:54:57,990
and give us the (indistinct).

1160
00:54:57,990 --> 00:54:59,495
Thank you. Thank you.

1161
00:54:59,495 --> 00:55:00,377
(audience applauds)

