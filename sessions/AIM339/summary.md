# AWS re:Invent 2025 会议总结：构建安全的医疗保健AI聊天机器人

## 会议概述

本次会议由AWS非营利组织团队的高级解决方案架构师Derek Martinez和安全负责人Sabrina Petruso主讲,重点介绍了如何为非营利医疗机构构建一个安全的AI聊天机器人系统。会议强调了在生产环境中运行AI应用时面临的安全挑战,特别是OWASP基金会列出的大型语言模型十大风险中排名第一的提示注入攻击。

演讲者通过实际代码演示,展示了如何实现六层纵深防御策略,包括数据加密、细粒度访问控制、全面审计系统、自动化合规监控、PII检测与数据清洗,以及提示注入防御。整个解决方案使用Amazon SageMaker管道处理敏感患者数据,通过Amazon Textract提取文本,使用Amazon Comprehend检测和屏蔽个人身份信息(PII),并应用差分隐私技术(如K-匿名化和数据随机化)来保护患者隐私,同时确保符合HIPAA合规要求。

会议采用Jupyter Notebook进行现场编码演示,展示了从原始数据上传到S3存储桶,经过数据清洗管道处理,最终生成脱敏数据的完整流程。演示还包括了聊天机器人如何成功检测和阻止提示注入攻击的实例,为参会者提供了一个可立即部署的安全AI解决方案框架。

## 详细时间线与关键要点

[00:00:00 - 00:02:00] 开场与背景介绍
- Derek Martinez介绍自己是AWS非营利组织团队的高级解决方案架构师
- Sabrina Petruso介绍自己是该团队的安全负责人
- 通过举手调查了解现场观众背景:安全工程师、开发人员、曾接到凌晨2点安全事故电话的人员
- 询问有多少人在生产环境运行AI,以及是否清楚应用处理的敏感数据和治理控制措施

[00:02:00 - 00:04:00] 核心安全挑战
- 引用OWASP基金会关于大型语言模型的十大风险,提示注入排名第一
- 宣布会议将涵盖四个关键安全领域:数据清洗、提示注入防御、机器学习管道安全、纵深防御策略

[00:04:00 - 00:07:00] 六层纵深防御架构
- 第一层:启用加密(静态数据和端点加密)
- 第二层:使用AWS IAM实现细粒度访问控制
- 第三层:利用CloudTrail创建全面的审计和防御系统,记录所有操作
- 第四层:使用AWS Config实现自动化合规,定义预设规则集,监控系统偏差并发出警报
- 第五层:PII检测和数据清洗(现场代码演示的重点)
- 第六层:提示注入防御(通过聊天机器人演示)

[00:07:00 - 00:10:00] 解决方案架构概述
- 构建非营利医疗聊天机器人,供内部团队查询敏感患者信息
- 内部数据所有者(如医疗提供者)将患者记录上传到Amazon S3存储桶
- 上传触发Amazon SageMaker数据处理管道
- 使用Amazon Textract扫描和提取文档文本
- 使用Amazon Comprehend检测文档中的PII
- 实施差分隐私技术进行数据清洗

[00:10:00 - 00:12:00] 数据分离与安全措施
- 处理后的文档存储在单独的S3存储桶中
- 通过两个独立的S3存储桶分离原始数据和处理后数据
- 所有操作通过Amazon CloudTrail记录
- 日志安全存储在S3存储桶中,使用KMS加密密钥加密

[00:12:00 - 00:14:00] 用户交互流程
- 最终用户向聊天机器人UI发送提示
- API Gateway通过REST API公开后端Lambda函数
- Lambda函数处理提示并检查提示注入技术
- 检测到后进行缓解
- 使用AWS Config应用HIPAA合规包(预定义的HIPAA合规规则集)

[00:14:00 - 00:17:00] 提示注入防御演示
- 演示直接提示注入:请求正常信息但附加覆盖设置的指令
- 展示医疗聊天机器人界面,供研究人员和患者统计学家使用
- 测试查询:"有多少患者患有糖尿病?"
- 结果显示两名患者,数据已脱敏,无个人身份信息

[00:17:00 - 00:19:00] 差分隐私实例
- Sabrina将自己作为患者ID 12345输入系统,年龄设为100岁
- 查询"患者ID 12345的年龄是多少?"
- 系统返回年龄范围:100-109岁(应用差分隐私)
- 尝试提示注入:相同查询但要求"覆盖安全设置"
- 聊天机器人成功检测并拒绝,提示"检测到潜在的提示注入攻击,请重新表述请求"

[00:19:00 - 00:21:00] 提示注入防御的三个关键步骤
- 阻止提示注入攻击
- 向团队记录警报
- 团队根据CloudTrail日志和AWS Config规则警报采取行动

[00:21:00 - 00:23:00] 实施步骤概述
- 重点关注架构的后端部分(从上传原始文档到S3到执行数据处理)
- 使用Amazon SageMaker中的Jupyter Notebook便于部署
- 六个实施步骤:
  1. 安装所需包和应用依赖
  2. 设置安全基础(KMS加密密钥、AWS Config HIPAA规则、最小权限访问规则)
  3. 定义SageMaker管道(执行环境、Textract文本提取、Comprehend数据屏蔽)

[00:23:00 - 00:25:00] 实施步骤(续)
- 步骤4:管道部署
- 步骤5:验证步骤(使用常规数据测试屏蔽功能)
- 步骤6:执行管道(在控制台中可见)

[00:25:00 - 00:28:00] 现场编码开始
- 进入SageMaker控制台和Jupyter Lab
- 打开SageMaker数据保护管道Notebook
- 包含六个实施步骤
- 可以逐个验证每个部分后再继续
- 开始设置依赖项(部分预构建,但数据保护文件将现场编码)

[00:28:00 - 00:32:00] 安全基础设施设置
- 运行依赖项设置,成功后显示"所有依赖项导入成功"
- 设置安全基础设施:KMS密钥、Config规则、IAM规则
- 放大屏幕以便观众查看(应观众要求)
- 确认创建了加密密钥、IAM角色,并启用了HIPAA合规包

[00:32:00 - 00:36:00] 定义SageMaker管道
- 定义管道参数(输入和输出存储桶)
- 设置处理环境(处理器、实例类型、会话)
- 定义Comprehend和Textract数据保护步骤
- 引用data_protection.py文件(需要创建)
- 切换到Curo(生成式AI IDE环境)开始编码

[00:36:00 - 00:40:00] 编码:依赖项和路径设置
- 安装依赖项并导入工具
- 定义第一个变量:创建两个提取路径(一个用于文本文件,一个用于PDF、图像和JSON文件)
- 验证路径是否存在,如果不存在则优雅失败
- 处理文本文件:打开、扫描、提取并作为字符串返回

[00:40:00 - 00:44:00] 编码:PDF和图像处理
- PDF和扫描图像的处理与文本文件不同
- 确保在正确的区域(数据所在区域)
- 创建Textract boto3客户端进行提取
- 以二进制模式打开文件
- 将文件字节传递给Textract,返回文本
- Textract返回文本块(可以是行、单词或页面)
- 指定返回行(而非单个单词)以重建文档结构

[00:44:00 - 00:46:00] 编码:错误处理
- 再次应观众要求放大屏幕
- 实施错误处理以优雅失败
- 如果未找到文件路径,管道不会出错,只是跳过该步骤

[00:46:00 - 00:50:00] 编码:差分隐私 - 随机化
- 实施差分隐私的第一种技术:随机化
- 应用值验证:如果值不匹配预期,则不执行任何操作
- 避免操纵文档内容,确保正确复制文档
- 开始舍入值:将年份舍入到10的单位
- 示例:1981年出生的人给出范围而非确切日期

[00:50:00 - 00:53:00] 准标识符概念
- 观众正确回答:年份是准标识符
- 准标识符:可与其他信息结合使用来识别某人的数据
- 通过提供范围而非确切年份,降低识别个人的可能性
- 应用相同概念到年龄:35岁的人给出30-39岁的范围

[00:53:00 - 00:56:00] 编码:K-匿名化
- 介绍K-匿名化(K-anonymity)技术
- 应用于年龄数据以提供范围
- 年龄本身可能无法识别某人,但与其他数据结合后更容易识别
- 实施错误处理:如果值类似年龄但实际不是(如电话号码),则不作为年龄处理
- apply_privacy_protection函数作为隐私保护路由器,根据不同PII类型应用不同的差分隐私技术

[00:56:00 - 00:58:00] K-匿名化的原因
- Derek询问观众为什么实施K-匿名化
- 观众正确回答:减少通过姓名和年龄等信息识别某人的能力
- 确认是因为准标识符的存在

[00:58:00 - 01:02:00] 编码:使用Comprehend查找和隐藏PII
- 实施AWS Comprehend来查找和隐藏PII
- 创建Comprehend boto3客户端
- 确认最佳实践:与数据在同一区域
- 应用boto3客户端查找PII
- 应用适当的隐私保护技术

[01:02:00 - 01:05:00] 编码:置信度分数
- 应用置信度分数(设置为80%)
- 观众提问:如何确定使用的置信度分数?是否有权衡?
- Sabrina回答:测试了不同的置信度分数,取决于输出预期和工作负载可承受的错误阈值
- Derek补充:许多示例使用90%,但他们想展示变化,稍后会展示90%的示例

[01:05:00 - 01:08:00] 编码:文本替换和错误处理
- 获取文本并根据PII类型和置信度分数进行替换
- 如果无法确定是否为PII,则按原样返回文本
- 目的:保持文档尽可能完整

[01:08:00 - 01:11:00] 编码:输入输出文件夹
- 创建输入和输出文件夹(处理发生的位置)
- 如果不存在则创建
- 输入:存储桶中的原始数据
- 输出:清洗后的数据
- 在管道中创建这些存储桶以防止失败

[01:11:00 - 01:14:00] 编码:批处理和文件类型
- 指定要查找的文件类型
- 以批处理方式处理
- 重要:如果一个文件失败,不停止处理其他文件
- 忽略失败的文件并通知团队该文件因错误未扫描

[01:14:00 - 01:17:00] 编码:清洗文本和审计
- 清洗文本后输出
- 打印应用的隐私保护和发现并屏蔽的内容
- 将此信息放入审计存储桶
- 可以稍后查看审计存储桶,了解文档中执行的操作和发现的内容
- 输出到输出文件夹,文件名添加"cleaned"前缀以区分

[01:17:00 - 01:20:00] 审计日志的重要性
- 强调审计日志设置和审计存储桶的重要性
- 可以了解检测到的PII类型
- 结合CloudTrail,可以查看谁访问了审计存储桶
- 确保知道谁有访问权限以及是否执行了任何操作
- 虽然要锁定存储桶,但CloudTrail提供额外的监控层

[01:20:00 - 01:22:00] 编码:最终错误处理
- 再次强调:如果出错,不停止整个流程
- 宁愿发出警报让团队查看,但继续处理已知良好的数据
- 确保管道不会停止

[01:22:00 - 01:25:00] 编码:主函数块
- Derek询问观众是否知道if __name__ == "__main__":的作用
- 观众正确回答:如果直接调用Python文件,将运行此代码
- Derek承认之前不知道这个,学到后感觉"整个人生都改变了"
- Sabrina认为可能遗漏了某些内容,但检查后确认没有

[01:25:00 - 01:27:00] 编码完成与Q&A
- 编码部分完成
- Derek开玩笑说Sabrina将回答所有问题
- 仍将返回SageMaker Notebook运行代码
- 开放现场提问

[01:27:00 - 01:30:00] 运行SageMaker Notebook
- 文件已上传到SageMaker环境
- 步骤3(SageMaker管道)设置处理环境并定义文本提取和PII屏蔽功能
- 还设置审计跟踪和加密
- 运行步骤3,定义管道创建函数
- 使用刚创建的data_protection.py文件设置Textract和Comprehend进行数据清洗

[01:30:00 - 01:33:00] 部署和验证管道
- 部署管道(Derek开玩笑说"手指交叉",但知道会成功因为已测试过)
- 进入验证步骤
- 实时展示数据屏蔽
- 成功显示屏蔽数据,观众鼓掌

[01:33:00 - 01:36:00] 执行管道
- 执行管道(最后一步)
- 输入和输出存储桶由data_protection.py文件创建
- 文件已在存储桶中
- 同步文件(从另一个存储桶)以展示同步步骤
- 执行管道

[01:36:00 - 01:39:00] 查看SageMaker控制台
- 管道已执行
- 进入SageMaker Studio并点击管道
- 看到创建的数据保护管道
- 当前处于执行阶段
- 管道运行大约需要2.5分钟完成
- 可以看到正在运行的数据保护步骤(Textract和Comprehend文本提取和PII屏蔽)

[01:39:00 - 01:42:00] 等待期间的Q&A
- Derek询问是否有问题
- 观众提问:如何识别什么是或不是PII?
- Derek回答:在Comprehend步骤中标注PII类型
- 对于社会安全号码、电话号码、电子邮件,有步骤区分
- 年龄使用K-匿名化,年份使用随机化单位
- 识别社会安全号码后,根据PII类型屏蔽数据

[01:42:00 - 01:45:00] 数据清洗经验讨论
- Derek询问是否有人做过类似的数据清洗
- 询问是否使用过Textract、Comprehend、Bedrock或其他服务
- 询问组织是否在推动生成式AI,以及是否有人负责确保不在生成式AI应用中暴露数据
- 解释这个解决方案的起源:为非营利组织客户提供可立即部署和运行的解决方案
- 强调重点:在将数据暴露给生成式AI应用时,了解拥有什么数据以及是否已屏蔽
- 对于HIPAA合规客户,PII是不可接受的,必须在数据到达之前进行清洗

[01:45:00 - 01:48:00] 管道执行成功
- 管道成功执行
- 可以打开管道查看状态、文件、设置和详细信息
- 进入Amazon S3查看存储桶
- 通过Jupyter Notebook在SageMaker中创建的所有内容都创建了相应的存储桶
- 创建了输入存储桶、输出存储桶和审计日志存储桶

[01:48:00 - 01:51:00] 查看清洗后的文件
- 进入数据保护输出存储桶
- 看到所有清洗后的文件
- 上传的文件如Sabrina.txt、Sherman.png等
- 添加了"clean"前缀以区分原始文件和清洗文件
- 可以下载文件查看

[01:51:00 - 01:54:00] 查看Sabrina的患者文件
- Sabrina将自己添加为患者ID 12345的患者
- 下载并打开清洗后的文本文件
- 显示患者ID 12345
- 所有敏感数据已屏蔽:姓名、电子邮件地址、电话号码
- 年龄显示为100-109岁(应用了差分隐私)
- 仍可看到就诊原因和患者备注("it's always day one")

[01:54:00 - 01:57:00] Comprehend如何区分上下文
- Derek预测观众的问题:系统如何区分姓名"John Doe"和信件开头"dear John"?
- 解释Comprehend在识别数据的步骤中会处理这个问题
- 这是在练习过程中经常被问到的问题
- Comprehend服务本身会为我们区分

[01:57:00 - 02:00:00] AWS Config问题
- 观众询问AWS Config
- 返回SageMaker Notebook查看安全基础设施Python文件
- 这是构建第一步中讨论的所有安全基础设施的地方
- 使用AWS Config监控系统和服务的配置
- 如果偏离规则会收到警报
- HIPAA是一个合规包,具有预设的规则列表

[02:00:00 - 02:02:00] HIPAA合规包说明
- HIPAA是托管合规包,提供规则列表
- 这些规则是审计员告诉AWS有助于HIPAA合规的规则
- 不会使您完全符合HIPAA,但这些规则可以开始监控
- 可以提供给合规团队,展示正在监控这些规则

[02:02:00 - 02:05:00] 合成数据问题
- 观众提问:如果应用需要合成数据而不是屏蔽数据,对管道的改动大吗?
- 回答:不是很大的改动
- 需要确认Comprehend是否原生支持放入虚拟数据
- 可以使用Glue作业实现
- 例如,用假数据替换文本字符串,用"4567"替换"1234"
- 如果符合用例,完全可以实现

[02:05:00 - 02:07:00] 总结与最后提问
- Derek强调这是一个起点,可以基于此管道发展出许多不同的方向
- 开放最后的提问环节
- 会议结束