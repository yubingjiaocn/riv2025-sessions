1
00:00:00,000 --> 00:00:04,080
- This is COP 326, "Elevating Application

2
00:00:04,080 --> 00:00:07,110
and Generative AI Observability".

3
00:00:07,110 --> 00:00:08,250
My name is Matheus Arrais.

4
00:00:08,250 --> 00:00:10,645
I'm a worldwide tech lead for CloudOps,

5
00:00:10,645 --> 00:00:12,150
based of Dallas, Texas.

6
00:00:12,150 --> 00:00:13,170
This is my sixth re:Invent.

7
00:00:13,170 --> 00:00:15,720
I'm very excited to be
here. I have Peter with me.

8
00:00:15,720 --> 00:00:16,620
- Hi, I'm Peter Geng.

9
00:00:16,620 --> 00:00:20,340
I'm product manager in
CloudWatch, my first re:Invent.

10
00:00:20,340 --> 00:00:22,380
We're very excited to meet you as well.

11
00:00:22,380 --> 00:00:27,030
- Awesome. So, let's
start with this picture.

12
00:00:27,030 --> 00:00:29,550
So, imagine if you were in a store,

13
00:00:29,550 --> 00:00:33,000
like if you're driving
down the unfamiliar highway

14
00:00:33,000 --> 00:00:36,510
and you have very limited
visibility, so it's quite

15
00:00:36,510 --> 00:00:39,480
nervous-racking and dangerous as well.

16
00:00:39,480 --> 00:00:42,330
You don't know what exactly
what's the roads are gonna do

17
00:00:42,330 --> 00:00:44,520
or what's gonna appear in front of you

18
00:00:44,520 --> 00:00:46,020
and you're just starting to grip

19
00:00:46,020 --> 00:00:48,090
the steering wheel even harder.

20
00:00:48,090 --> 00:00:49,170
Your palms are sweating.

21
00:00:49,170 --> 00:00:52,380
You just wanna make sure
they're drive safe home.

22
00:00:52,380 --> 00:00:55,830
We all be in, you know,
this familiar situation,

23
00:00:55,830 --> 00:00:58,560
driving with limited visibility

24
00:00:58,560 --> 00:01:01,140
and we don't wish it to repeat it again.

25
00:01:01,140 --> 00:01:04,590
So, this is like operating
in today's complex

26
00:01:04,590 --> 00:01:07,170
applications powered by AI.

27
00:01:07,170 --> 00:01:10,890
We often lack of visibility
and observability

28
00:01:10,890 --> 00:01:13,050
and you just wanted to understand

29
00:01:13,050 --> 00:01:14,820
how the systems are driving forward

30
00:01:14,820 --> 00:01:17,490
and without it, it's quite dangerous.

31
00:01:17,490 --> 00:01:22,360
Even our CTO Verna Vogues, he once said

32
00:01:23,790 --> 00:01:28,790
that you needed to have observability

33
00:01:28,860 --> 00:01:31,860
because without it, you are just guessing.

34
00:01:31,860 --> 00:01:34,560
You are guessing what the
system's gonna do next,

35
00:01:34,560 --> 00:01:38,190
how the systems will react to the dynamics

36
00:01:38,190 --> 00:01:39,693
of your end users.

37
00:01:40,770 --> 00:01:45,150
So, in this presentation,
we're gonna help with that.

38
00:01:45,150 --> 00:01:47,650
First of all, I'm gonna understand how

39
00:01:48,780 --> 00:01:51,750
application observability
monitoring is today.

40
00:01:51,750 --> 00:01:54,240
What are the challenge that you have now

41
00:01:54,240 --> 00:01:57,330
that we have generative AI
in place and how that comes

42
00:01:57,330 --> 00:02:01,680
and play Along with that,
how to gain visibility

43
00:02:01,680 --> 00:02:04,710
and observability to
AI power applications.

44
00:02:04,710 --> 00:02:07,920
So, our commitment, myself and Peter,

45
00:02:07,920 --> 00:02:09,970
that you're gonna walk from this session,

46
00:02:11,190 --> 00:02:14,340
going back to your places, your homes

47
00:02:14,340 --> 00:02:18,480
with actionable insights for
how you elevate application,

48
00:02:18,480 --> 00:02:22,650
but also generative observability
in a single pane of glass.

49
00:02:22,650 --> 00:02:27,000
Let's start with John. So,
John, here is our persona.

50
00:02:27,000 --> 00:02:29,190
So, he's a SRE, he's a developer.

51
00:02:29,190 --> 00:02:33,630
He's someone that is using
CloudWatch in a daily basis.

52
00:02:33,630 --> 00:02:34,890
And as you can see,

53
00:02:34,890 --> 00:02:38,370
his application right
there is quite complex.

54
00:02:38,370 --> 00:02:39,480
There is many layers.

55
00:02:39,480 --> 00:02:43,710
That's backhand, database,
infrastructure layer.

56
00:02:43,710 --> 00:02:46,980
So, John's using just
the simple monitoring,

57
00:02:46,980 --> 00:02:50,010
like CPU metric, stuff like that.

58
00:02:50,010 --> 00:02:52,500
There is many layers on that application

59
00:02:52,500 --> 00:02:56,820
that John can leverage, as
you can see on this diagram.

60
00:02:56,820 --> 00:02:59,406
So, each layer that you see on the screen

61
00:02:59,406 --> 00:03:02,820
is a possible layer
that it can be observed.

62
00:03:02,820 --> 00:03:06,300
So, networking,
infrastructure, application,

63
00:03:06,300 --> 00:03:09,680
database, users and so on.

64
00:03:09,680 --> 00:03:11,438
From the bottom up,

65
00:03:11,438 --> 00:03:15,000
AWS offers many choice
for you, for instance,

66
00:03:15,000 --> 00:03:16,560
on the infrastructure.

67
00:03:16,560 --> 00:03:19,710
So, you can observe on
the ECU perspective,

68
00:03:19,710 --> 00:03:23,970
containers perspective,
serverless, on-prems, and so on.

69
00:03:23,970 --> 00:03:27,510
Application layer, which
is one of the crucial ones

70
00:03:27,510 --> 00:03:30,750
because you can use
application logs to understand

71
00:03:30,750 --> 00:03:33,870
how the application
traces the interconnection

72
00:03:33,870 --> 00:03:36,090
between your applications,

73
00:03:36,090 --> 00:03:39,120
moving from the CPU metric perspective

74
00:03:39,120 --> 00:03:43,860
to a service-level, objective
perspective, time backed

75
00:03:43,860 --> 00:03:46,170
to your business outcome.

76
00:03:46,170 --> 00:03:49,380
Last but not least, you
have the user perspective

77
00:03:49,380 --> 00:03:53,580
where you can create understanding

78
00:03:53,580 --> 00:03:55,800
of your user behavior

79
00:03:55,800 --> 00:03:59,580
and using CloudWatch for that.

80
00:03:59,580 --> 00:04:02,700
So, what John have asked for us,

81
00:04:02,700 --> 00:04:05,350
it is I wanted a native integration

82
00:04:06,210 --> 00:04:08,280
because he's using AWS today.

83
00:04:08,280 --> 00:04:12,570
He wanted faster time to attack problems

84
00:04:12,570 --> 00:04:14,310
and also to resolve them.

85
00:04:14,310 --> 00:04:17,220
You want it to cost
optimize, doesn't want it

86
00:04:17,220 --> 00:04:20,430
to move data from here to there.

87
00:04:20,430 --> 00:04:23,763
You know, doing deduplication,
this is quite complex.

88
00:04:25,080 --> 00:04:27,360
And also, it should be
a single pane of glass.

89
00:04:27,360 --> 00:04:30,690
Should be a simple service to use

90
00:04:30,690 --> 00:04:32,550
that has actionable inside.

91
00:04:32,550 --> 00:04:33,630
It is smart.

92
00:04:33,630 --> 00:04:36,000
It's using, for instance, machine learning

93
00:04:36,000 --> 00:04:37,203
to understand anomaly.

94
00:04:38,340 --> 00:04:40,770
And for each one of those layers,

95
00:04:40,770 --> 00:04:44,190
Amazon CloudWatch offers
John a perspective

96
00:04:44,190 --> 00:04:49,190
and an option to monitor his
application cover to cover.

97
00:04:49,560 --> 00:04:53,190
So, from the bottom up in the internet,

98
00:04:53,190 --> 00:04:56,100
in network perspective,
we have for instance,

99
00:04:56,100 --> 00:05:00,870
internet monitoring, can
analyze internet performance

100
00:05:00,870 --> 00:05:04,350
understanding if it is also your

101
00:05:04,350 --> 00:05:07,980
internet provider has problems on outages.

102
00:05:07,980 --> 00:05:10,830
You have the infrastructure
level, the blue one,

103
00:05:10,830 --> 00:05:14,520
where you can have a CPU
container service, some prints

104
00:05:14,520 --> 00:05:17,340
and you can leverage containers
insights, lambda insights

105
00:05:17,340 --> 00:05:20,020
to understand the system level

106
00:05:20,885 --> 00:05:23,790
of that particular infrastructure choice.

107
00:05:23,790 --> 00:05:25,770
We have database insights, too

108
00:05:25,770 --> 00:05:28,950
to collect monitor database
performance in the real time

109
00:05:28,950 --> 00:05:32,220
so you can leverage,
understand which SQL queries

110
00:05:32,220 --> 00:05:34,023
is taking longer than others.

111
00:05:35,280 --> 00:05:37,440
The green one, which is
the application leverage

112
00:05:37,440 --> 00:05:40,680
is the most crucial
one like I said before,

113
00:05:40,680 --> 00:05:44,910
because you can automatically
detect your KPIs,

114
00:05:44,910 --> 00:05:46,710
your application KPIs

115
00:05:46,710 --> 00:05:51,240
and use SLOs to maintain
server quality commitments

116
00:05:51,240 --> 00:05:53,610
that you have with your customers.

117
00:05:53,610 --> 00:05:56,700
Last but not least, the top level,

118
00:05:56,700 --> 00:06:00,780
which the user's perspective
you can use run real user

119
00:06:00,780 --> 00:06:05,780
monitoring and synthetics to
produce canaries to simulate

120
00:06:06,030 --> 00:06:08,970
what the user's behavior in an alert,

121
00:06:08,970 --> 00:06:12,060
if you have any availability issues

122
00:06:12,060 --> 00:06:15,900
or performance degradation,
all that in a single tool,

123
00:06:15,900 --> 00:06:17,313
which is Amazon CloudWatch.

124
00:06:18,810 --> 00:06:23,393
So, going to the three
pillars of observability,

125
00:06:23,393 --> 00:06:27,750
everyone might be familiar with this,

126
00:06:27,750 --> 00:06:32,370
but that's the journey that
we wanted to discuss here.

127
00:06:32,370 --> 00:06:36,000
Every monitor observability strategy

128
00:06:36,000 --> 00:06:39,570
will come along with
metrics, logs and traces.

129
00:06:39,570 --> 00:06:43,230
This is a call as a three
pillars of observability.

130
00:06:43,230 --> 00:06:47,220
Metrics, it is, I wanted to understand,

131
00:06:47,220 --> 00:06:48,330
I have the information

132
00:06:48,330 --> 00:06:52,470
that my application response
latest increased 35%.

133
00:06:52,470 --> 00:06:57,470
Logs, I have the information
in the data structure

134
00:06:57,810 --> 00:06:59,760
or not a structure that, you know,

135
00:06:59,760 --> 00:07:03,323
my authentication user just
authentication my application.

136
00:07:03,323 --> 00:07:06,480
And trace, I can ask questions

137
00:07:06,480 --> 00:07:10,420
or answer questions about
distribution processing time

138
00:07:10,420 --> 00:07:13,290
of my microservice across the board.

139
00:07:13,290 --> 00:07:17,620
So, as you saw it in the
beginning, John has a quite

140
00:07:18,720 --> 00:07:20,820
complex architecture.

141
00:07:20,820 --> 00:07:24,183
And then, of course some
challenge also arises with that.

142
00:07:25,110 --> 00:07:30,110
Microservice, like a complex
architecture needs constantly

143
00:07:30,240 --> 00:07:34,470
performancy over time
to satisfy the end user.

144
00:07:34,470 --> 00:07:37,230
You have also John needs

145
00:07:37,230 --> 00:07:41,400
to manually teach together telemetry data

146
00:07:41,400 --> 00:07:44,730
with the service to
understand the degradation

147
00:07:44,730 --> 00:07:47,370
of availability and high latency.

148
00:07:47,370 --> 00:07:51,510
Also, it's very hard to
understand what is the priority

149
00:07:51,510 --> 00:07:52,920
for the business, right?

150
00:07:52,920 --> 00:07:56,490
Understand those anomaly,
which ones matter most

151
00:07:56,490 --> 00:07:59,970
to the business and how he
should prioritize with that.

152
00:07:59,970 --> 00:08:03,600
Last, but not least, this joint experience

153
00:08:03,600 --> 00:08:06,370
because correlating that telemetry data

154
00:08:07,440 --> 00:08:09,840
from the perspective of metrics, logs

155
00:08:09,840 --> 00:08:11,490
and traces, you also needed

156
00:08:11,490 --> 00:08:15,090
to put in place real user monitoring,

157
00:08:15,090 --> 00:08:17,220
synthetics monitoring.

158
00:08:17,220 --> 00:08:20,400
If you put it that all
together, that can extend it

159
00:08:20,400 --> 00:08:23,643
in a very long time to
attack the real issue.

160
00:08:24,540 --> 00:08:29,540
Now, in order to offer a
technical perspective how John

161
00:08:31,357 --> 00:08:34,020
should use and what he should use

162
00:08:34,020 --> 00:08:36,180
and look specifically

163
00:08:36,180 --> 00:08:40,590
for elevate his monitoring,
it is the golden signals.

164
00:08:40,590 --> 00:08:43,830
So, the golden signals
are volume requests,

165
00:08:43,830 --> 00:08:46,860
which is directly impact
the demand in place

166
00:08:46,860 --> 00:08:50,550
of your application directly
impact also in latency.

167
00:08:50,550 --> 00:08:52,740
Latency is speed, right?

168
00:08:52,740 --> 00:08:57,740
How much time a specific
request expand to be resolved.

169
00:08:58,440 --> 00:09:00,330
And for that, if you have high latency

170
00:09:00,330 --> 00:09:03,540
or you also have the directly impacting

171
00:09:03,540 --> 00:09:04,983
the user's experience,

172
00:09:04,983 --> 00:09:09,660
The two in the bottom,
you have fault and errors.

173
00:09:09,660 --> 00:09:11,910
This is a tieback to requests.

174
00:09:11,910 --> 00:09:14,640
There are mold form or application issues.

175
00:09:14,640 --> 00:09:16,950
So, you needed to
understand those in order

176
00:09:16,950 --> 00:09:21,950
to understand your application
monitor as another level.

177
00:09:22,050 --> 00:09:24,733
Now, this is a technical perspective.

178
00:09:24,733 --> 00:09:28,680
What John needed to do
here, it is also to connect

179
00:09:28,680 --> 00:09:31,680
that from the business perspective, right?

180
00:09:31,680 --> 00:09:34,620
So, for instance,
business impacts directly

181
00:09:34,620 --> 00:09:36,300
to revenue per minute

182
00:09:36,300 --> 00:09:41,300
or if you have a car abdomen,
what is the level of that?

183
00:09:41,610 --> 00:09:44,010
What is the user experience signal?

184
00:09:44,010 --> 00:09:49,010
For instance, page load time,
what is the API errors code

185
00:09:49,170 --> 00:09:51,480
and session duration, so on and so forth?

186
00:09:51,480 --> 00:09:56,307
You have service health
indicators like latency, P90, P95.

187
00:09:57,493 --> 00:10:01,080
You wanted to understand
that particular piece

188
00:10:01,080 --> 00:10:03,840
to understand the overall health.

189
00:10:03,840 --> 00:10:06,970
And last but not least,
connecting with availability

190
00:10:08,610 --> 00:10:12,270
objectives, tying back each signal

191
00:10:12,270 --> 00:10:16,440
with an SLO, a service
level object to ensure

192
00:10:16,440 --> 00:10:18,300
that you're maintaining the optimal

193
00:10:18,300 --> 00:10:19,893
level of the application.

194
00:10:20,910 --> 00:10:23,310
So, in order to answer those questions,

195
00:10:23,310 --> 00:10:26,640
you know, John should focus
on that particular layer

196
00:10:26,640 --> 00:10:30,810
because on that layer it's
where John can tie back

197
00:10:30,810 --> 00:10:34,503
all those knots, all those
dots, the application level.

198
00:10:35,520 --> 00:10:39,900
And, Amazon offer an APM solution

199
00:10:39,900 --> 00:10:42,423
called Amazon CloudWatch
Application Signals.

200
00:10:43,290 --> 00:10:45,480
From using Application Signals,

201
00:10:45,480 --> 00:10:48,180
John can elevate his
application monitoring

202
00:10:48,180 --> 00:10:49,650
because, first of all,

203
00:10:49,650 --> 00:10:53,460
that is Application Signals
automatically discover

204
00:10:53,460 --> 00:10:56,970
which applications you
have in your account,

205
00:10:56,970 --> 00:10:59,190
using OpenTelemetry SDK.

206
00:10:59,190 --> 00:11:01,020
You don't need it to do anything, right?

207
00:11:01,020 --> 00:11:06,020
It's already automatically
discover for you by CloudWatch.

208
00:11:06,420 --> 00:11:09,730
Second of all, there
is pre-built dashboards

209
00:11:10,660 --> 00:11:14,070
with standard metrics,
including those golden

210
00:11:14,070 --> 00:11:16,020
signals will have that,

211
00:11:16,020 --> 00:11:20,910
so we can understand the technical metrics

212
00:11:20,910 --> 00:11:24,000
that I just mentioned a few seconds ago.

213
00:11:24,000 --> 00:11:26,580
Third, you have easy understanding

214
00:11:26,580 --> 00:11:31,170
with a few clicks the root
cause if you have a HTTP

215
00:11:31,170 --> 00:11:34,380
malform, if you have a
deception, you can understand

216
00:11:34,380 --> 00:11:38,763
where's the deception, which
line of code and so on.

217
00:11:39,660 --> 00:11:43,050
Last but not least, SLO,
service link object.

218
00:11:43,050 --> 00:11:47,820
So, this is related to
goals on your reliability

219
00:11:47,820 --> 00:11:49,710
and tying back to the business object.

220
00:11:49,710 --> 00:11:54,453
This is crucial for any
application monitoring strategy.

221
00:11:55,380 --> 00:11:59,610
And that's why, when we talk
about application monitoring,

222
00:11:59,610 --> 00:12:01,860
we talk about the SLOs,

223
00:12:01,860 --> 00:12:04,740
because it is a
comprehensive understanding

224
00:12:04,740 --> 00:12:07,650
of application health
from the user perspective,

225
00:12:07,650 --> 00:12:09,630
and this is how it works.

226
00:12:09,630 --> 00:12:14,163
You have an application or an
API called Gap Research API,

227
00:12:15,270 --> 00:12:20,270
and I have a particular internal
goal of 99.9% of up uptime

228
00:12:22,110 --> 00:12:24,150
of this particular API.

229
00:12:24,150 --> 00:12:26,430
Well, in order to have that,

230
00:12:26,430 --> 00:12:29,010
I already select a particular SLI,

231
00:12:29,010 --> 00:12:33,540
which is service link
indicator, to measure that goal.

232
00:12:33,540 --> 00:12:38,540
In this case it is uptime,
but as you see there is a 0.1%

233
00:12:40,920 --> 00:12:43,740
that can create something
called error budget,

234
00:12:43,740 --> 00:12:47,353
which meaning if I'm
evaluating this particular SLO

235
00:12:48,200 --> 00:12:53,200
in a 30-days period, I
still have 43 minutes

236
00:12:53,250 --> 00:12:56,970
of downtime and still meet my SLO.

237
00:12:56,970 --> 00:12:58,230
Why is this important?

238
00:12:58,230 --> 00:13:01,830
Because you can tie all
this back with your SLA

239
00:13:01,830 --> 00:13:05,550
and SLA, everyone know,
is agreement that you do

240
00:13:05,550 --> 00:13:07,200
with your customers.

241
00:13:07,200 --> 00:13:09,180
So, when you put it in the perspective,

242
00:13:09,180 --> 00:13:10,380
what are you gonna have?

243
00:13:10,380 --> 00:13:12,570
You're gonna have happy customers

244
00:13:12,570 --> 00:13:15,840
because if you are looking
for all those APIs,

245
00:13:15,840 --> 00:13:20,100
establishing all those SLOs,
tying back to the SLIs,

246
00:13:20,100 --> 00:13:22,170
customers are able to understand

247
00:13:22,170 --> 00:13:24,360
that you take care of the application.

248
00:13:24,360 --> 00:13:25,950
In this particular case,

249
00:13:25,950 --> 00:13:30,110
John will achieve happy end users, too.

250
00:13:32,970 --> 00:13:36,093
Okay, so let's go for the
demo. Let's go to the fun part.

251
00:13:37,220 --> 00:13:41,700
In this demo I'm gonna show
specifically two scenarios

252
00:13:41,700 --> 00:13:46,440
of fault and also latency problems

253
00:13:46,440 --> 00:13:47,940
that I have in my application

254
00:13:47,940 --> 00:13:50,820
and how we can use Application Signals

255
00:13:50,820 --> 00:13:55,110
to monitor my entire
application observability

256
00:13:55,110 --> 00:13:57,573
in a single console.

257
00:14:00,570 --> 00:14:04,410
So, first of all, what I'm
gonna do it is to show SLOs.

258
00:14:04,410 --> 00:14:08,250
So, I have multiple SLOs,
as you can see here,

259
00:14:08,250 --> 00:14:10,680
and some of them, of
course, are unhealthy.

260
00:14:10,680 --> 00:14:12,723
I wanted to show how to create an SLO.

261
00:14:13,620 --> 00:14:14,760
SLO can be...

262
00:14:14,760 --> 00:14:17,460
I needed to choose first the SLI.

263
00:14:17,460 --> 00:14:20,070
SLI can be a service operation

264
00:14:20,070 --> 00:14:24,030
and CloudWatch metric
or a service dependency.

265
00:14:24,030 --> 00:14:27,150
And again, that service
means that, you know,

266
00:14:27,150 --> 00:14:28,350
is automatically discovered

267
00:14:28,350 --> 00:14:31,080
by OpenTelemetry SDK in this case I'm,

268
00:14:31,080 --> 00:14:35,220
I'm gonna use my frontend,
PetClinic frontend

269
00:14:35,220 --> 00:14:38,160
and a specific operation of posts.

270
00:14:38,160 --> 00:14:39,210
And the interesting part,

271
00:14:39,210 --> 00:14:43,110
right now I can select
the calculation method

272
00:14:43,110 --> 00:14:46,560
for this particular SLO,
which can be by request

273
00:14:46,560 --> 00:14:50,550
or by period and I can
select also the condition

274
00:14:50,550 --> 00:14:52,800
of the particular calculation method,

275
00:14:52,800 --> 00:14:55,290
that can be either by
latency, I'm choosing

276
00:14:55,290 --> 00:14:59,790
100 milliseconds right
now and also availability.

277
00:14:59,790 --> 00:15:01,740
One of the cool things
it is CloudWatch put

278
00:15:01,740 --> 00:15:04,800
that little phrase over there,
which is exactly the terms

279
00:15:04,800 --> 00:15:08,730
what I'm doing, you know
in the configuration.

280
00:15:08,730 --> 00:15:12,180
From that, I select what is my SLO.

281
00:15:12,180 --> 00:15:15,960
I define my interval of period

282
00:15:15,960 --> 00:15:20,960
that will be assessed by this
SLO, the attainment goal.

283
00:15:21,060 --> 00:15:23,610
And also I have the
little phrase over there.

284
00:15:23,610 --> 00:15:25,380
Of course, none of this makes sense

285
00:15:25,380 --> 00:15:27,870
if I don't tie backs alarms.

286
00:15:27,870 --> 00:15:31,740
Alarms can be directly related to the SLI

287
00:15:31,740 --> 00:15:33,990
or the SLO attainment goal

288
00:15:33,990 --> 00:15:37,170
and the overall health of this SLO.

289
00:15:37,170 --> 00:15:41,790
Everything there, it makes
sense for that particular API.

290
00:15:41,790 --> 00:15:44,250
Now, I wanted to show also something

291
00:15:44,250 --> 00:15:45,990
beyond which is application mac.

292
00:15:45,990 --> 00:15:48,510
We launched this like
a couple of weeks ago.

293
00:15:48,510 --> 00:15:52,540
This is what I mentioned
related to auto discovery

294
00:15:53,610 --> 00:15:57,360
from the OpenTelemetry
perspective, not just instrumented

295
00:15:57,360 --> 00:15:59,820
but also uninstrumented application

296
00:15:59,820 --> 00:16:03,450
capable to be discovered
by application map.

297
00:16:03,450 --> 00:16:06,180
I can filter by groups.

298
00:16:06,180 --> 00:16:08,640
There's multiple filters
that I can select over here.

299
00:16:08,640 --> 00:16:10,290
And then, all the applications

300
00:16:10,290 --> 00:16:13,320
that I have in this account
will automatically be select

301
00:16:13,320 --> 00:16:15,840
on those little boxes
on the right hand side.

302
00:16:15,840 --> 00:16:20,340
Even if I wanted to create
my own custom attribute,

303
00:16:20,340 --> 00:16:24,270
I can use configurations
directly on OpenTelemetry config

304
00:16:24,270 --> 00:16:27,690
file and will show up directly
here on the console, too.

305
00:16:27,690 --> 00:16:32,430
Now, going a little bit
deeper on the PetClinic

306
00:16:32,430 --> 00:16:35,490
that I mentioned, when
I click double click,

307
00:16:35,490 --> 00:16:36,990
I see the total polish.

308
00:16:36,990 --> 00:16:39,480
So, this is my total
polish from my application.

309
00:16:39,480 --> 00:16:42,780
All the connections that
I have with the frontend,

310
00:16:42,780 --> 00:16:45,810
with the backend, all
the, the microservice

311
00:16:45,810 --> 00:16:47,910
that I have connections I can see.

312
00:16:47,910 --> 00:16:50,340
And if I click on the fin line, I'm able

313
00:16:50,340 --> 00:16:54,120
to see the interconnection
between one server to the other

314
00:16:54,120 --> 00:16:58,350
and understand the top
path with fault rate

315
00:16:58,350 --> 00:17:02,220
with high latency, so on and so forth.

316
00:17:02,220 --> 00:17:06,510
If I click in that particular
frontend back again,

317
00:17:06,510 --> 00:17:10,050
what I have on the right end
signs, it is the golden signals

318
00:17:10,050 --> 00:17:11,700
that I mentioned before.

319
00:17:11,700 --> 00:17:15,540
So, requests, volume
requests, latency, arrows

320
00:17:15,540 --> 00:17:17,940
and faults are out out of the gate for me.

321
00:17:17,940 --> 00:17:22,920
Over there I can enlarge
to see this over the time

322
00:17:22,920 --> 00:17:26,340
and select P90, P99 or P50.

323
00:17:26,340 --> 00:17:28,110
And, one of the cool things

324
00:17:28,110 --> 00:17:31,470
that I believe here
that CloudWatch gives it

325
00:17:31,470 --> 00:17:34,740
is this operational auditing.

326
00:17:34,740 --> 00:17:37,890
So, as you can see, I have
some drops, some spikes,

327
00:17:37,890 --> 00:17:40,770
so CloudWatch already
given to me over there.

328
00:17:40,770 --> 00:17:44,490
What did the indication
that the problem should be?

329
00:17:44,490 --> 00:17:47,250
So, what exactly happen
in that period of time

330
00:17:47,250 --> 00:17:49,493
and exactly what's gonna happen,

331
00:17:49,493 --> 00:17:52,740
you know, needed to assess even further.

332
00:17:52,740 --> 00:17:57,120
So, to assess even further,
when I click in the dashboard,

333
00:17:57,120 --> 00:18:00,840
I can see the overall metrics

334
00:18:00,840 --> 00:18:03,360
for this particular application.

335
00:18:03,360 --> 00:18:06,240
And again, metrics,

336
00:18:06,240 --> 00:18:11,070
all the golden signals
are here, as you can see,

337
00:18:11,070 --> 00:18:14,430
but one of the things that I
mentioned in the SLO creation,

338
00:18:14,430 --> 00:18:16,380
it is the service operation.

339
00:18:16,380 --> 00:18:19,920
So, using OpenTelemetry, I'm able

340
00:18:19,920 --> 00:18:23,550
to understand all the
posts, the gaps, the puts

341
00:18:23,550 --> 00:18:26,130
that these applications
using behind the things

342
00:18:26,130 --> 00:18:27,660
and understand, as you can see,

343
00:18:27,660 --> 00:18:29,643
I have SLIs that are unhealthy.

344
00:18:30,600 --> 00:18:33,600
If I double click in the dashboard

345
00:18:33,600 --> 00:18:36,270
because I have a spike of a fault,

346
00:18:36,270 --> 00:18:39,480
it will automatically show
the correlation of spans

347
00:18:39,480 --> 00:18:44,250
that it's necessary for
that request to be served.

348
00:18:44,250 --> 00:18:47,100
And if I click in one of those spans,

349
00:18:47,100 --> 00:18:50,850
it will show me exactly
what is the trace map

350
00:18:50,850 --> 00:18:54,390
from the frontend to the backend,

351
00:18:54,390 --> 00:18:56,400
what exactly the whole trace

352
00:18:56,400 --> 00:19:01,380
and the spans for this
request to be resolved.

353
00:19:01,380 --> 00:19:03,930
And, I can even see
the same visualization,

354
00:19:03,930 --> 00:19:05,960
but now in a timeline perspective,

355
00:19:05,960 --> 00:19:10,410
in a span timeline perspective,
where is this host?

356
00:19:10,410 --> 00:19:13,920
And as you can see, there is
a fault in the visit service.

357
00:19:13,920 --> 00:19:16,230
Java is throwing an exception

358
00:19:16,230 --> 00:19:20,250
and exception, it is a
DynamoDB throughput problem.

359
00:19:20,250 --> 00:19:21,720
I can see the message

360
00:19:21,720 --> 00:19:24,780
and also the line, specifically the line

361
00:19:24,780 --> 00:19:28,710
that in my code I needed to
go back and fix the problem.

362
00:19:28,710 --> 00:19:31,740
And, even in the DynamoDB perspective,

363
00:19:31,740 --> 00:19:35,733
I can see the message on
the right hand side, too.

364
00:19:37,330 --> 00:19:41,100
One of the interesting part, if I go back

365
00:19:41,100 --> 00:19:44,550
to the previous dashboard, I can also see

366
00:19:44,550 --> 00:19:48,210
because this is the EKS
cluster, where is the node

367
00:19:48,210 --> 00:19:52,720
that is having most problems
with this particular fault

368
00:19:54,180 --> 00:19:58,590
and what exactly are the pods
that are having this pod?

369
00:19:58,590 --> 00:20:00,060
And then, I can prioritize

370
00:20:00,060 --> 00:20:02,673
by looking to these nodes and pods.

371
00:20:02,673 --> 00:20:06,690
Even if I click to container insights

372
00:20:06,690 --> 00:20:10,440
on this little button is is
gonna guide me to a console

373
00:20:10,440 --> 00:20:13,050
where I can see my container insights

374
00:20:13,050 --> 00:20:14,823
performance across the board.

375
00:20:15,660 --> 00:20:18,390
This is in the single pane of glass.

376
00:20:18,390 --> 00:20:21,600
So, dependencies is
another tab on on, again,

377
00:20:21,600 --> 00:20:25,230
same application that I can
see all the dependence related

378
00:20:25,230 --> 00:20:28,323
to this application and also, of course,

379
00:20:28,323 --> 00:20:32,160
the dependence related to the service.

380
00:20:32,160 --> 00:20:34,170
So, this is the second use case

381
00:20:34,170 --> 00:20:35,940
that I talk about latency.

382
00:20:35,940 --> 00:20:39,780
So, as you can see there is
a spike in this specific time

383
00:20:39,780 --> 00:20:41,160
and I'm just gonna click on one

384
00:20:41,160 --> 00:20:44,460
of the traces using the same
methodology on the previous

385
00:20:44,460 --> 00:20:48,060
use case, but now looking for latency.

386
00:20:48,060 --> 00:20:50,040
And, you're gonna see that now,

387
00:20:50,040 --> 00:20:53,103
because it's a different API
that I have high latency,

388
00:20:53,103 --> 00:20:55,740
it's being served for
different service including,

389
00:20:55,740 --> 00:20:57,093
for instance, Bedrock.

390
00:20:58,320 --> 00:21:00,930
I have the same visualization trace map

391
00:21:00,930 --> 00:21:04,200
and also the timeline with all the Spans`.

392
00:21:04,200 --> 00:21:05,280
And as you can see,

393
00:21:05,280 --> 00:21:09,090
the Bedrock runtime has an
arrow, specifically when I click

394
00:21:09,090 --> 00:21:12,810
into view, it will show me exactly

395
00:21:12,810 --> 00:21:15,780
what the section is being
throw in the MyCode.

396
00:21:15,780 --> 00:21:19,740
In this case, the problem is
the Bedrock foundation model

397
00:21:19,740 --> 00:21:21,000
is being deprecated.

398
00:21:21,000 --> 00:21:22,980
So, that's why I have high latency

399
00:21:22,980 --> 00:21:24,180
because it's been deprecated.

400
00:21:24,180 --> 00:21:27,720
So, it's taking too much
time to be resolved back

401
00:21:27,720 --> 00:21:31,500
to my user and even if I click
in the event, I'll be able

402
00:21:31,500 --> 00:21:34,320
to see that more properly.

403
00:21:34,320 --> 00:21:36,090
Now, this is the application level.

404
00:21:36,090 --> 00:21:41,090
I wanted to also show the
user that top level layer.

405
00:21:41,370 --> 00:21:46,080
You can use synthetics canaries to create

406
00:21:46,080 --> 00:21:48,480
and simulate user's behavior.

407
00:21:48,480 --> 00:21:52,020
In this case of our percentage
on you can create to simulate

408
00:21:52,020 --> 00:21:56,160
what exactly steps that needs to be used

409
00:21:56,160 --> 00:21:59,760
and simulate what is what a user will use

410
00:21:59,760 --> 00:22:01,260
his applications for.

411
00:22:01,260 --> 00:22:03,270
And we'll take little screenshots

412
00:22:03,270 --> 00:22:06,243
as well if you determine to do so.

413
00:22:07,140 --> 00:22:09,210
You can also use the user experience,

414
00:22:09,210 --> 00:22:11,880
the run that I mentioned before,

415
00:22:11,880 --> 00:22:15,840
to understand page load
if there any arrows.

416
00:22:15,840 --> 00:22:19,500
You can see when I increase the time

417
00:22:19,500 --> 00:22:23,220
on the right hand side, I
can see the arrows over time,

418
00:22:23,220 --> 00:22:25,740
understand what exactly the page

419
00:22:25,740 --> 00:22:27,600
that I have from the user perspective

420
00:22:27,600 --> 00:22:31,910
that are having the problems
with load specifically,

421
00:22:31,910 --> 00:22:34,500
and when I click one of this,

422
00:22:34,500 --> 00:22:36,780
that's giving me the entire
information regarding

423
00:22:36,780 --> 00:22:38,040
that particular error.

424
00:22:38,040 --> 00:22:39,840
And, this is a user perspective,

425
00:22:39,840 --> 00:22:44,700
so, I need, and I can see
when the session happened,

426
00:22:44,700 --> 00:22:45,930
when this happened,

427
00:22:45,930 --> 00:22:50,370
which type of browser
CloudWatch used to simulate

428
00:22:50,370 --> 00:22:51,840
the user behavior

429
00:22:51,840 --> 00:22:53,460
and I can, you know, understand

430
00:22:53,460 --> 00:22:56,763
my user experience across the board.

431
00:22:57,900 --> 00:23:01,050
Now, this is the application part

432
00:23:01,050 --> 00:23:04,200
and now I wanted to move over to the genAI

433
00:23:04,200 --> 00:23:05,940
because now John, Peter needs

434
00:23:05,940 --> 00:23:07,890
to include genAI in his application.

435
00:23:07,890 --> 00:23:09,260
Yes, thank you so much, Matheus.

436
00:23:09,260 --> 00:23:12,660
- I'm so excited here to talk to you about

437
00:23:12,660 --> 00:23:16,320
how observability has changed
to monitored AI workloads.

438
00:23:16,320 --> 00:23:19,230
So, raise your hand if
you are currently building

439
00:23:19,230 --> 00:23:22,233
an AI application or
workload in your company.

440
00:23:23,460 --> 00:23:26,763
Okay, wow, most of the room,
so you're in the right place.

441
00:23:27,840 --> 00:23:32,430
So, looking back this
crazy year, this 2025,

442
00:23:32,430 --> 00:23:34,410
we all know that AI-powered application

443
00:23:34,410 --> 00:23:37,380
is gonna transform the
way that your business

444
00:23:37,380 --> 00:23:40,260
and your end users interact
with your business.

445
00:23:40,260 --> 00:23:43,980
Every tech leader here is
seeing in real time how easy

446
00:23:43,980 --> 00:23:47,013
and powerful it is to build
these AI workloads on AWS.

447
00:23:47,880 --> 00:23:49,590
So, I'm here to help you navigate

448
00:23:49,590 --> 00:23:51,780
through this time in a
lens from observability

449
00:23:51,780 --> 00:23:52,890
and showing you three things.

450
00:23:52,890 --> 00:23:55,830
Number one, how observability has changed

451
00:23:55,830 --> 00:23:57,660
and the new tools that you can use.

452
00:23:57,660 --> 00:24:00,120
And second, how
observability is still some

453
00:24:00,120 --> 00:24:02,910
of the same things that
you're already familiar with

454
00:24:02,910 --> 00:24:04,950
and show you the existing
tools that you can use.

455
00:24:04,950 --> 00:24:08,010
And lastly, showing all
that together with a demo

456
00:24:08,010 --> 00:24:09,663
of that workload.

457
00:24:10,890 --> 00:24:15,630
So, walking back in memory
lane, so we started this AI talk

458
00:24:15,630 --> 00:24:20,220
back when we had these
question and answer chat bots,

459
00:24:20,220 --> 00:24:22,560
but that is so 2023.

460
00:24:22,560 --> 00:24:24,930
What we then had, these are AI assistants,

461
00:24:24,930 --> 00:24:29,160
or what kind of the AI entity
that walks the user step

462
00:24:29,160 --> 00:24:33,690
by step, step through a
particular business process.

463
00:24:33,690 --> 00:24:37,470
But now today, what we have is AI agents.

464
00:24:37,470 --> 00:24:41,460
These entities are more autonomous
that can do certain tasks

465
00:24:41,460 --> 00:24:44,340
by themselves and make
decisions independently

466
00:24:44,340 --> 00:24:47,190
to achieve specific goals.

467
00:24:47,190 --> 00:24:51,180
What we think in the future
will be is fully agentic systems

468
00:24:51,180 --> 00:24:54,330
where the entire systems
behave independently,

469
00:24:54,330 --> 00:24:57,660
achieve open-ended requests and goals

470
00:24:57,660 --> 00:25:01,050
and help the entire business
make its own decision

471
00:25:01,050 --> 00:25:03,150
and drive those outcomes.

472
00:25:03,150 --> 00:25:08,150
And how do you even build
these AI applications?

473
00:25:08,550 --> 00:25:11,430
In AWS we offer a full
stack of tools for you

474
00:25:11,430 --> 00:25:13,320
to build those workloads.

475
00:25:13,320 --> 00:25:16,230
And, monitoring is
across the entire stack.

476
00:25:16,230 --> 00:25:20,880
Starting from the bottom, can
help you build, run, train

477
00:25:20,880 --> 00:25:23,580
and deploy those AI models on SageMaker

478
00:25:23,580 --> 00:25:26,790
and also on our infrastructure.

479
00:25:26,790 --> 00:25:29,430
And the middle layer I think
is gonna be the meat of it,

480
00:25:29,430 --> 00:25:31,830
it's gonna be first is the Amazon Bedrock,

481
00:25:31,830 --> 00:25:35,100
which is a fully managed
service that offers you

482
00:25:35,100 --> 00:25:37,860
direct access to a slew
of foundation models

483
00:25:37,860 --> 00:25:38,693
through a single API.

484
00:25:38,693 --> 00:25:41,610
So, you can scale up your
application really easily.

485
00:25:41,610 --> 00:25:44,610
And then the more recently
launched AgentCore,

486
00:25:44,610 --> 00:25:46,380
where's the place for you to build

487
00:25:46,380 --> 00:25:50,670
and deploy highly scalable
and capable AI agents.

488
00:25:50,670 --> 00:25:55,170
It comes with a suite of
tools to augment those agent

489
00:25:55,170 --> 00:25:58,770
with memory so the agent knows
the context, with gateway

490
00:25:58,770 --> 00:26:00,840
so the agent has control over what kind

491
00:26:00,840 --> 00:26:02,520
of third party APIs it calls

492
00:26:02,520 --> 00:26:04,673
and identity for
authentication and control.

493
00:26:04,673 --> 00:26:07,290
And going higher, even in AWS

494
00:26:07,290 --> 00:26:09,840
we've used these things
to build up those fully

495
00:26:09,840 --> 00:26:14,820
agentic systems with
Kiro, the agentic IDE,

496
00:26:14,820 --> 00:26:16,920
Q, agentic business intelligence

497
00:26:16,920 --> 00:26:18,060
and also Amazon connected

498
00:26:18,060 --> 00:26:20,160
with agentic contact
center have been loved

499
00:26:20,160 --> 00:26:22,050
with millions of customers.

500
00:26:22,050 --> 00:26:23,790
So, wherever, however you're building AI,

501
00:26:23,790 --> 00:26:25,260
we've got you covered.

502
00:26:25,260 --> 00:26:29,523
And again, in every layer
observability is there with you.

503
00:26:31,200 --> 00:26:35,520
Now, here comes the question is how do you

504
00:26:35,520 --> 00:26:39,450
have the right observability
on these AI applications?

505
00:26:39,450 --> 00:26:43,410
How do you see, how do you
track what the AI is doing?

506
00:26:43,410 --> 00:26:45,240
And then what's new, what's different?

507
00:26:45,240 --> 00:26:46,770
So, let me help you navigate

508
00:26:46,770 --> 00:26:48,873
through this rapidly changing time.

509
00:26:51,300 --> 00:26:54,180
With these AI application,

510
00:26:54,180 --> 00:26:55,710
what we've talked to customers

511
00:26:55,710 --> 00:26:58,290
and they've unanimously come back to us

512
00:26:58,290 --> 00:27:00,360
with some common challenges.

513
00:27:00,360 --> 00:27:04,170
Number one, these agents
can be indeterministic.

514
00:27:04,170 --> 00:27:07,170
Their actions can defer from time to time,

515
00:27:07,170 --> 00:27:10,650
even from similar past
scenarios is very unexpected.

516
00:27:10,650 --> 00:27:12,180
They're like teenagers.

517
00:27:12,180 --> 00:27:13,890
Sometimes they say brilliant things,

518
00:27:13,890 --> 00:27:16,890
sometimes you wish they
didn't say anything at all.

519
00:27:16,890 --> 00:27:21,510
And second, root cause
analysis is focused on tracking

520
00:27:21,510 --> 00:27:23,370
the sequence of calls
that the agents made,

521
00:27:23,370 --> 00:27:26,370
but it's very difficult to trace.

522
00:27:26,370 --> 00:27:30,600
Analyzing those invocations
at scale is very difficult

523
00:27:30,600 --> 00:27:33,630
because every model provider
has a slightly different

524
00:27:33,630 --> 00:27:36,090
format and tracking that volume

525
00:27:36,090 --> 00:27:38,820
across different regions
accounts is harder than

526
00:27:38,820 --> 00:27:40,530
it's supposed to be.

527
00:27:40,530 --> 00:27:43,860
Now, so lastly is assessing system health.

528
00:27:43,860 --> 00:27:46,140
It's still the same goal
that Matheus talked about,

529
00:27:46,140 --> 00:27:49,500
but what's new is this
word quality, right?

530
00:27:49,500 --> 00:27:50,910
Now, you need to answer

531
00:27:50,910 --> 00:27:54,630
why did the agent do the thing it did?

532
00:27:54,630 --> 00:27:56,400
Why did it route itself in that way?

533
00:27:56,400 --> 00:27:58,020
What context did it have?

534
00:27:58,020 --> 00:28:00,420
Well, sort of the
traditional monitoring tools

535
00:28:00,420 --> 00:28:01,803
can tell you the performance,

536
00:28:01,803 --> 00:28:06,480
surfacely performance
parameters like latency errors,

537
00:28:06,480 --> 00:28:09,180
but it doesn't tell
you that the reasoning,

538
00:28:09,180 --> 00:28:13,470
doesn't explain to you the
AI decision making process.

539
00:28:13,470 --> 00:28:16,410
So, you are no longer just
observing whether your AI

540
00:28:16,410 --> 00:28:19,440
is working or not going up or down,

541
00:28:19,440 --> 00:28:22,080
but you're trying to observe
reasoning and intent.

542
00:28:22,080 --> 00:28:26,790
And we believe this will be
your new operational reality.

543
00:28:26,790 --> 00:28:28,680
Observability is going
to be the control plane

544
00:28:28,680 --> 00:28:30,873
for trust, safety and quality.

545
00:28:33,270 --> 00:28:35,670
Now, going back to the same stack layer

546
00:28:35,670 --> 00:28:36,540
that Matheus showed you,

547
00:28:36,540 --> 00:28:38,430
we believe that AI workload is gonna ride

548
00:28:38,430 --> 00:28:39,990
on top of all of this.

549
00:28:39,990 --> 00:28:42,840
And, observability is there is going

550
00:28:42,840 --> 00:28:45,060
to be operating at the highest
level with you as well,

551
00:28:45,060 --> 00:28:48,750
connecting from all the way
from the infrastructure signals,

552
00:28:48,750 --> 00:28:51,330
stitching the telemetry
throughout, throughout the stack

553
00:28:51,330 --> 00:28:54,870
and coalescing from those
different models, agent actions

554
00:28:54,870 --> 00:28:58,593
to observe the entire
end-to-end interaction for you.

555
00:28:59,910 --> 00:29:02,730
That's why from those
challenges we worked,

556
00:29:02,730 --> 00:29:04,500
that was introduced to you,

557
00:29:04,500 --> 00:29:09,420
Amazon genAI observability
already in GA has a slew

558
00:29:09,420 --> 00:29:10,860
of capabilities.

559
00:29:10,860 --> 00:29:15,090
Number one is a 360-degree
view of your agent no matter

560
00:29:15,090 --> 00:29:18,210
what model they're using on frameworks

561
00:29:18,210 --> 00:29:20,940
such as Strands, Strands,
CrewAI, LangChain

562
00:29:20,940 --> 00:29:24,120
and with out of the box dashboards

563
00:29:24,120 --> 00:29:26,850
on those performance parameters.

564
00:29:26,850 --> 00:29:31,150
Second is very simple to
instrument your your AI workload

565
00:29:32,010 --> 00:29:35,580
as long as using OTel, which
is OpenTelemetry format.

566
00:29:35,580 --> 00:29:37,800
We'll touch on that a little bit later.

567
00:29:37,800 --> 00:29:41,110
And, very importantly is the
end-to-end prompt tracing

568
00:29:42,140 --> 00:29:44,220
which traces across the LLM calls,

569
00:29:44,220 --> 00:29:46,107
the agent actions, the tools,

570
00:29:46,107 --> 00:29:48,180
the memory calls it makes for you

571
00:29:48,180 --> 00:29:50,580
to quickly identify issues.

572
00:29:50,580 --> 00:29:53,880
And, in the data protection world,

573
00:29:53,880 --> 00:29:57,090
now, in these AI interactions,
it is very likely

574
00:29:57,090 --> 00:29:59,160
that what the AI receives

575
00:29:59,160 --> 00:30:02,550
or the AI outputs can contain PI content

576
00:30:02,550 --> 00:30:03,900
and those are stored in the logs

577
00:30:03,900 --> 00:30:06,180
and we have data
protection features to mask

578
00:30:06,180 --> 00:30:07,710
that content and protect it.

579
00:30:07,710 --> 00:30:09,840
And lastly is the evaluations feature

580
00:30:09,840 --> 00:30:12,120
for you to monitor the quality.

581
00:30:12,120 --> 00:30:16,830
And these are using LLM as
a judge to constantly assess

582
00:30:16,830 --> 00:30:18,600
how your AI is responding,

583
00:30:18,600 --> 00:30:20,010
whether it's saying the right things,

584
00:30:20,010 --> 00:30:21,510
whether it's routing itself correctly

585
00:30:21,510 --> 00:30:24,423
and solving your customer problems.

586
00:30:25,410 --> 00:30:28,470
And, to build these agents is fairly easy

587
00:30:28,470 --> 00:30:29,973
on AWS AgentCore.

588
00:30:30,997 --> 00:30:34,650
AgentCore allows you to deploy,

589
00:30:34,650 --> 00:30:39,180
operate highly capable AI
agents securely at scale.

590
00:30:39,180 --> 00:30:41,220
It offers infrastructure purpose built

591
00:30:41,220 --> 00:30:43,500
for these dynamic agent workloads.

592
00:30:43,500 --> 00:30:47,280
As you can tell, it coalesced
from different aspects

593
00:30:47,280 --> 00:30:48,630
of what the agent would use.

594
00:30:48,630 --> 00:30:52,920
For example, any model, LLM
model offered on Bedrock

595
00:30:52,920 --> 00:30:54,810
and they will use AgentCore memory,

596
00:30:54,810 --> 00:30:56,160
which is the context of polls,

597
00:30:56,160 --> 00:31:01,160
and uses to operate identity,
controls the security,

598
00:31:03,270 --> 00:31:06,870
and also gateway, which
is a central place for it

599
00:31:06,870 --> 00:31:09,690
to make third party API
tool calls and all that.

600
00:31:09,690 --> 00:31:11,640
And as you can see all the tools

601
00:31:11,640 --> 00:31:14,580
and the primitives around
the agent sent telemetry

602
00:31:14,580 --> 00:31:16,260
to the observability platform,

603
00:31:16,260 --> 00:31:18,510
which is CloudWatch observability.

604
00:31:18,510 --> 00:31:20,520
So, you can have that single pane of glass

605
00:31:20,520 --> 00:31:22,023
to monitor all of this.

606
00:31:24,090 --> 00:31:26,160
One thing I do wanna
highlight has been resonating

607
00:31:26,160 --> 00:31:28,950
with a lot of our customers
is that you can host

608
00:31:28,950 --> 00:31:33,950
your agents on AgentCore runtime service

609
00:31:34,050 --> 00:31:35,637
and that telemetry comes
through CloudWatch.

610
00:31:35,637 --> 00:31:38,640
You can get all the features
that talked about out the box.

611
00:31:38,640 --> 00:31:42,690
Also if you're coasting your
agents elsewhere, EC2, AKS,

612
00:31:42,690 --> 00:31:44,910
on-prem or other clouds, as long

613
00:31:44,910 --> 00:31:48,150
as your data is in an OTel
format, we can also accept it

614
00:31:48,150 --> 00:31:50,560
and you'll get very similar capabilities

615
00:31:50,560 --> 00:31:52,350
in CloudWatch as well.

616
00:31:52,350 --> 00:31:56,343
So, giving you that flexibility
wherever fits your needs.

617
00:31:59,010 --> 00:32:01,470
Going to a little bit
deeper on the agents running

618
00:32:01,470 --> 00:32:04,560
on AgentCore runtime, when creating

619
00:32:04,560 --> 00:32:06,020
and running these agents,

620
00:32:06,020 --> 00:32:09,300
we provide even more flexibility
on how you create them.

621
00:32:09,300 --> 00:32:13,590
We support Gentech frameworks
like very popular ones,

622
00:32:13,590 --> 00:32:17,550
Strands Agents, CrewAI, LangChain,

623
00:32:17,550 --> 00:32:20,880
and support of instrumentation libraries

624
00:32:20,880 --> 00:32:23,100
are already brought are all open source,

625
00:32:23,100 --> 00:32:24,780
open inference, trace loop.

626
00:32:24,780 --> 00:32:27,570
And once you've been
instrumented connected

627
00:32:27,570 --> 00:32:30,840
with the Amazon distro
for OpenTelemetry, ADOT

628
00:32:30,840 --> 00:32:33,420
and we collect that
instrumentations, send it

629
00:32:33,420 --> 00:32:35,820
to the CloudWatch OTel endpoint,

630
00:32:35,820 --> 00:32:38,520
and we will be powering those
screens that I talked about

631
00:32:38,520 --> 00:32:43,380
before or specifically
agents hosted on runtime,

632
00:32:43,380 --> 00:32:45,000
remember that ADOT I talked about?

633
00:32:45,000 --> 00:32:48,060
Plus once all of that
telemetry is coming in,

634
00:32:48,060 --> 00:32:50,667
in a CloudWatch telemetry
config with a single click,

635
00:32:50,667 --> 00:32:52,650
you can turn on all of the telemetry

636
00:32:52,650 --> 00:32:54,840
from those individual primitives
like AgentCore memory,

637
00:32:54,840 --> 00:32:57,780
AgentCore gateway in a single click

638
00:32:57,780 --> 00:32:59,370
from entire account.

639
00:32:59,370 --> 00:33:02,520
All that comes to CloudWatch
and power those views

640
00:33:02,520 --> 00:33:05,700
and for agents have hosted elsewhere,

641
00:33:05,700 --> 00:33:07,980
Still the ADOT, but I need to emphasize

642
00:33:07,980 --> 00:33:12,060
that as long as in the OTel
format, we also accept it

643
00:33:12,060 --> 00:33:17,060
and turn on CloudWatch Transaction
Search to stitch together

644
00:33:17,190 --> 00:33:22,170
those actions and tool calls
it talked about in there.

645
00:33:22,170 --> 00:33:24,420
And, here's a very, very
easy quick start guide.

646
00:33:24,420 --> 00:33:25,950
You can even start it working on it

647
00:33:25,950 --> 00:33:27,783
right now on your laptop.

648
00:33:29,220 --> 00:33:32,700
So, with all that groundwork
we laid, let's focus

649
00:33:32,700 --> 00:33:35,610
on what John's doing
with his genAI workloads

650
00:33:35,610 --> 00:33:37,743
in more practical terms.

651
00:33:38,790 --> 00:33:42,180
Here, I think this slide
looks very similar to you

652
00:33:42,180 --> 00:33:44,307
of what you saw before,

653
00:33:44,307 --> 00:33:47,490
and you already know it,
it's the metrics, the logs

654
00:33:47,490 --> 00:33:50,130
and the traces and that's still powering

655
00:33:50,130 --> 00:33:51,870
the genAI observability.

656
00:33:51,870 --> 00:33:54,360
That's the same old
tools you've using today.

657
00:33:54,360 --> 00:33:58,530
So with metrics, these things
are like the token consumption

658
00:33:58,530 --> 00:33:59,758
and you're tracking
how those have changed,

659
00:33:59,758 --> 00:34:01,433
the volume of work the AI has done.

660
00:34:01,433 --> 00:34:05,580
Well, the logs is where you
keep those verbose inputs

661
00:34:05,580 --> 00:34:07,920
and outputs from the user

662
00:34:07,920 --> 00:34:12,000
and from the outputs of the
LLM models and the agents.

663
00:34:12,000 --> 00:34:14,340
And lastly, tracing, very important.

664
00:34:14,340 --> 00:34:16,920
The traces now can understand
how the response propagates

665
00:34:16,920 --> 00:34:19,890
through the entire system

666
00:34:19,890 --> 00:34:22,440
and you can analyze it
at the aggregate level

667
00:34:22,440 --> 00:34:23,490
and you have the capability

668
00:34:23,490 --> 00:34:26,073
to drill down on every single interaction.

669
00:34:29,065 --> 00:34:33,240
Okay, little bit more detail
on how it really works.

670
00:34:33,240 --> 00:34:35,310
Metrics, these are some common metrics

671
00:34:35,310 --> 00:34:39,330
you'll be able to monitor
on is number of invocations,

672
00:34:39,330 --> 00:34:42,360
how fast these invocations
are completing itself,

673
00:34:42,360 --> 00:34:47,360
any throttles and the volume
work like InputTokenCounts,

674
00:34:47,490 --> 00:34:50,100
OutputTokenCounts, and the logs

675
00:34:50,100 --> 00:34:52,740
coming from the model invocation, logging,

676
00:34:52,740 --> 00:34:56,190
and also the span logs which
contain each individual step

677
00:34:56,190 --> 00:34:59,280
and the contents of any tool
calls and the agent's actions.

678
00:34:59,280 --> 00:35:01,260
And lastly, the trace, as long

679
00:35:01,260 --> 00:35:04,920
as it contains the same
session ID or trace ID

680
00:35:04,920 --> 00:35:07,070
and stitch together
will be able to surface

681
00:35:08,430 --> 00:35:10,020
the end-to-end interaction

682
00:35:10,020 --> 00:35:11,720
that I talked to you about before.

683
00:35:12,780 --> 00:35:14,850
And with those, on the metrics,

684
00:35:14,850 --> 00:35:16,980
we've put it into the
same set of golden metrics

685
00:35:16,980 --> 00:35:18,797
that we believe you should be monitoring.

686
00:35:18,797 --> 00:35:22,620
In the first bucket is the
token usage, the volume of work

687
00:35:22,620 --> 00:35:26,657
that AI is doing and help
you to not only forecast

688
00:35:26,657 --> 00:35:30,480
the demand that you'll have and also cost.

689
00:35:30,480 --> 00:35:33,600
And then, latency, how fast is your AI

690
00:35:33,600 --> 00:35:35,100
responding to your needs?

691
00:35:35,100 --> 00:35:36,930
Throttles to keep a track

692
00:35:36,930 --> 00:35:40,800
about how close you're going
against your limits and quotas.

693
00:35:40,800 --> 00:35:42,420
And, errors, seeing anything

694
00:35:42,420 --> 00:35:44,673
that's going wrong in your request.

695
00:35:46,590 --> 00:35:49,590
And we'd be able to show
surface all these things

696
00:35:49,590 --> 00:35:52,470
in a prebuilt automatic dashboard
without any configuration.

697
00:35:52,470 --> 00:35:55,530
So, you can diagnose,
troubleshoot from here.

698
00:35:55,530 --> 00:35:59,670
Additional filters include
filtering by the model itself

699
00:35:59,670 --> 00:36:02,310
so you can deep down into any
specific model you're using,

700
00:36:02,310 --> 00:36:03,780
anything going wrong there.

701
00:36:03,780 --> 00:36:05,970
And also is definitely fully integrated

702
00:36:05,970 --> 00:36:07,890
with existing CloudWatch capabilities,

703
00:36:07,890 --> 00:36:09,750
like alerting if you wanted

704
00:36:09,750 --> 00:36:12,603
to keep track of your
total consumption patterns.

705
00:36:14,730 --> 00:36:17,850
Now, here's something that's
going to be a very different,

706
00:36:17,850 --> 00:36:20,820
relatively new concept to
the world of observability

707
00:36:20,820 --> 00:36:22,830
that is relevant in AI.

708
00:36:22,830 --> 00:36:27,830
Now, like I said before,
the new operational reality

709
00:36:27,930 --> 00:36:30,120
for you is going to be
looking at the quality

710
00:36:30,120 --> 00:36:33,390
of those AI responses and agent actions.

711
00:36:33,390 --> 00:36:35,580
So, often these LLMs hallucinates

712
00:36:35,580 --> 00:36:36,900
or the agents take on a path

713
00:36:36,900 --> 00:36:38,850
all of its own that's not desired.

714
00:36:38,850 --> 00:36:42,030
And in the past, how teams
have kept an eye on this,

715
00:36:42,030 --> 00:36:44,400
on this qualitative issue
is the science teams

716
00:36:44,400 --> 00:36:47,340
take a very small sample
of the AI workloads,

717
00:36:47,340 --> 00:36:49,740
manually look at it and assess it,

718
00:36:49,740 --> 00:36:51,333
and only when that's as good,

719
00:36:52,260 --> 00:36:55,590
they're just okay with deploying

720
00:36:55,590 --> 00:36:59,310
the AI out in the real
world, almost hesitating

721
00:36:59,310 --> 00:37:01,380
and timid about what
it's really going to do.

722
00:37:01,380 --> 00:37:05,790
So, these lack trust
and also very burdensome

723
00:37:05,790 --> 00:37:07,320
in the entire process.

724
00:37:07,320 --> 00:37:11,460
So, that's why with evaluations,
well you can leverage LLM

725
00:37:11,460 --> 00:37:14,850
as a judge to assess how faithful an agent

726
00:37:14,850 --> 00:37:17,670
is adhering to his context,

727
00:37:17,670 --> 00:37:20,280
how well it follows
instructions you've given it

728
00:37:20,280 --> 00:37:24,270
and how helpful it was
in helping your customers

729
00:37:24,270 --> 00:37:27,150
achieve their tasks and questions.

730
00:37:27,150 --> 00:37:29,980
And, this is done continuously

731
00:37:29,980 --> 00:37:32,755
automatically on the entire
traffic of your AI workload

732
00:37:32,755 --> 00:37:37,110
and you have the ability
to sample on full sampling

733
00:37:37,110 --> 00:37:39,090
or only a proportion of the samples.

734
00:37:39,090 --> 00:37:42,810
So, really removes the labor intensive

735
00:37:42,810 --> 00:37:44,400
and manual assessment process

736
00:37:44,400 --> 00:37:47,700
that our customer teams used to do.

737
00:37:47,700 --> 00:37:50,820
So, evaluations metrics
was just launched yesterday

738
00:37:50,820 --> 00:37:52,710
and it's available now in CloudWatch,

739
00:37:52,710 --> 00:37:55,443
powered by AgentCore evaluations.

740
00:37:56,550 --> 00:37:59,040
We talked about the metrics side of things

741
00:37:59,040 --> 00:38:00,870
coming back into the logs.

742
00:38:00,870 --> 00:38:03,420
Some of my favorite because
this is the most densely packed

743
00:38:03,420 --> 00:38:05,730
information they'll be using.

744
00:38:05,730 --> 00:38:07,500
I'm going to be talking
about the invocation logs,

745
00:38:07,500 --> 00:38:10,530
how to query on them and
protecting that data.

746
00:38:10,530 --> 00:38:12,150
So, the invocation logs can come

747
00:38:12,150 --> 00:38:17,150
from both the LLM model
itself and also the agents.

748
00:38:17,350 --> 00:38:21,900
You can choose to come
to a CloudWatch or S3

749
00:38:21,900 --> 00:38:24,810
and once it's in CloudWatch
it's stored in the familiar

750
00:38:24,810 --> 00:38:27,250
CloudWatch log groups
concept that you can use

751
00:38:27,250 --> 00:38:30,183
integrated with your existing workflows.

752
00:38:32,490 --> 00:38:33,750
And once those logs are in CloudWatch,

753
00:38:33,750 --> 00:38:35,880
you can use the CloudWatch log insights

754
00:38:35,880 --> 00:38:39,560
to drill down deeper, which
is a powerful querying tool.

755
00:38:39,560 --> 00:38:44,560
We support powerful languages
like SQL, OpenSearch, PPL

756
00:38:44,580 --> 00:38:48,690
and launching powerful
query commands regularly.

757
00:38:48,690 --> 00:38:53,190
And you can use pattern analysis

758
00:38:53,190 --> 00:38:56,670
to detect common text
structures within the log events

759
00:38:56,670 --> 00:38:59,370
for faster insights and
also automated real-time

760
00:38:59,370 --> 00:39:02,670
anomaly detection to identify changes

761
00:39:02,670 --> 00:39:05,793
in these agent behaviors
and performance changes.

762
00:39:07,500 --> 00:39:08,650
And then I said before,

763
00:39:09,650 --> 00:39:13,320
these inter-customer interaction
can contain PII information

764
00:39:13,320 --> 00:39:17,030
and we've got you covered when
those logs are in CloudWatch.

765
00:39:17,030 --> 00:39:20,730
The CloudWatch data protection
feature can identify

766
00:39:20,730 --> 00:39:23,700
and mask sensitive customer information,

767
00:39:23,700 --> 00:39:26,820
like credit cards, names, addresses,

768
00:39:26,820 --> 00:39:30,810
and put basically redacted for you.

769
00:39:30,810 --> 00:39:35,130
Also, we offer granular
IAM role-based controls

770
00:39:35,130 --> 00:39:38,490
so that if a super user needs
to see the content, they can,

771
00:39:38,490 --> 00:39:40,770
but most users won't be able to.

772
00:39:40,770 --> 00:39:42,912
And, we generate automatic audit reports

773
00:39:42,912 --> 00:39:47,643
for compliance and reporting.

774
00:39:50,130 --> 00:39:53,280
Now, coming back to the last
part, we talked about metrics,

775
00:39:53,280 --> 00:39:56,460
we've talked about logs and
we're talking about traces now.

776
00:39:56,460 --> 00:39:58,350
This is probably the most important part

777
00:39:58,350 --> 00:40:01,020
in the genAI observability.

778
00:40:01,020 --> 00:40:03,510
With tracing, the first
thing we'll be able to do

779
00:40:03,510 --> 00:40:05,760
for you is show you the
detailed information

780
00:40:05,760 --> 00:40:07,797
of the every single individual API call

781
00:40:07,797 --> 00:40:08,683
and the function calls that agents made

782
00:40:08,683 --> 00:40:11,940
in a very neat list view.

783
00:40:11,940 --> 00:40:14,940
You no longer need to query
on them on multiple databases

784
00:40:14,940 --> 00:40:16,350
to stitch them together.

785
00:40:16,350 --> 00:40:18,150
It's done for you.

786
00:40:18,150 --> 00:40:21,990
And second, we'll show you
those actions in a timeline view

787
00:40:21,990 --> 00:40:24,450
so you can know, hey, which
one's taking the longest,

788
00:40:24,450 --> 00:40:26,880
so which one's taking
longer than I expect for you

789
00:40:26,880 --> 00:40:28,740
to troubleshoot faster.

790
00:40:28,740 --> 00:40:31,200
And, a trajectory map

791
00:40:31,200 --> 00:40:34,890
showing you all those
different interactions,

792
00:40:34,890 --> 00:40:38,310
API calls tool calls for
this particular trace.

793
00:40:38,310 --> 00:40:43,310
And, each step here is a span
and aggregated to this trace.

794
00:40:43,350 --> 00:40:46,140
This map is automatically
visualized for you.

795
00:40:46,140 --> 00:40:50,790
So, you can easily understand
the hierarchy and the sequence

796
00:40:50,790 --> 00:40:55,383
of those tool calls in a very
easy to understand fashion.

797
00:40:56,220 --> 00:41:01,020
Now, I talked about what's
different, what's the same,

798
00:41:01,020 --> 00:41:03,750
the logs, metrics, and traces.

799
00:41:03,750 --> 00:41:04,583
So, it's a lot.

800
00:41:04,583 --> 00:41:07,473
Let's tie it all back
together with a short demo.

801
00:41:10,500 --> 00:41:13,410
- Okay, let's go to the demo part, then.

802
00:41:13,410 --> 00:41:18,058
So, in this demo now
we're gonna see kind of

803
00:41:18,058 --> 00:41:19,560
the PetClinic that I showed before,

804
00:41:19,560 --> 00:41:22,830
but now in the general
observability use case.

805
00:41:22,830 --> 00:41:26,370
And, this is a perspective
of an agile administrator

806
00:41:26,370 --> 00:41:28,590
or a manager that is, you know, using

807
00:41:28,590 --> 00:41:33,590
a fully SHAFT agent that
is hosted by AgentCore.

808
00:41:38,850 --> 00:41:41,610
And then behind the scenes
there is multiple microservice

809
00:41:41,610 --> 00:41:43,230
that you saw that before.

810
00:41:43,230 --> 00:41:47,673
This is the same old John's application,

811
00:41:48,570 --> 00:41:50,757
so you have database
and so on and so forth.

812
00:41:50,757 --> 00:41:54,450
So, here I'm just typing a
couple of prompts related

813
00:41:54,450 --> 00:41:56,520
to this PetClinic.

814
00:41:56,520 --> 00:41:59,220
And, this particular
prompt here, you know,

815
00:41:59,220 --> 00:42:02,730
it is showing me like information
related to the owner ID.

816
00:42:02,730 --> 00:42:04,560
As you can see there will be

817
00:42:04,560 --> 00:42:07,290
some PI information as Peter before.

818
00:42:07,290 --> 00:42:09,540
This, of course, is an
agent that's been used

819
00:42:10,620 --> 00:42:12,690
for administrator perspective.

820
00:42:12,690 --> 00:42:15,300
And in this last prompt it is related

821
00:42:15,300 --> 00:42:20,300
to a billing information for
this patient ID number one.

822
00:42:20,760 --> 00:42:23,220
And, what you're gonna see is

823
00:42:23,220 --> 00:42:26,730
the agent will not be able
to capture that information

824
00:42:26,730 --> 00:42:30,300
to flash that information
for some reasons.

825
00:42:30,300 --> 00:42:33,300
Now this is of course, it is the frontend.

826
00:42:33,300 --> 00:42:36,510
Let's go and actually see in the console.

827
00:42:36,510 --> 00:42:37,710
So, first of all,

828
00:42:37,710 --> 00:42:39,870
in the left front side
on Amazon CloudWatch,

829
00:42:39,870 --> 00:42:43,560
you're gonna see a new section
called genAI observability.

830
00:42:43,560 --> 00:42:48,560
And, this is the modeling
vocation that Peter showed before.

831
00:42:48,840 --> 00:42:52,020
You have that genAI golden signals

832
00:42:52,020 --> 00:42:54,240
for invocation, latency, and so on.

833
00:42:54,240 --> 00:42:55,710
And all the invocations

834
00:42:55,710 --> 00:42:58,560
that you have in the foundation
model, you'll be able

835
00:42:58,560 --> 00:43:02,190
to either filter, query them
in CloudWatch logging site

836
00:43:02,190 --> 00:43:06,000
and also, see the whole JSON file.

837
00:43:06,000 --> 00:43:08,550
You can even filter by model IDs

838
00:43:08,550 --> 00:43:11,250
that probably are using multiple different

839
00:43:11,250 --> 00:43:13,380
foundation model that you can also see.

840
00:43:13,380 --> 00:43:16,980
Now, going to the Bedrock
AgentCore, not just

841
00:43:16,980 --> 00:43:21,870
for the runtime, but
CloudWatch, also observe

842
00:43:21,870 --> 00:43:23,970
other parts of AgentCore, too.

843
00:43:23,970 --> 00:43:27,090
So, a memory, a gate and so on.

844
00:43:27,090 --> 00:43:30,660
Here, focus on the agent
runtime, specifically.

845
00:43:30,660 --> 00:43:32,010
I have three agents.

846
00:43:32,010 --> 00:43:35,580
I see all the overall information
regarding these agents,

847
00:43:35,580 --> 00:43:37,890
how many sessions, how many traces.

848
00:43:37,890 --> 00:43:40,350
Going deeper in the PetClinic

849
00:43:40,350 --> 00:43:42,240
because it's the one that I'm using,

850
00:43:42,240 --> 00:43:44,730
I wanted to show a couple
of informations here.

851
00:43:44,730 --> 00:43:46,440
In this Overview tab,

852
00:43:46,440 --> 00:43:49,410
I have out of the gate information related

853
00:43:49,410 --> 00:43:50,520
to the evaluation.

854
00:43:50,520 --> 00:43:52,710
So, I'm using evaluations

855
00:43:52,710 --> 00:43:55,290
and I can see the evaluations score

856
00:43:55,290 --> 00:43:57,000
and also configuration metric.

857
00:43:57,000 --> 00:44:01,830
I can see the arrow in
latent by span specifically,

858
00:44:01,830 --> 00:44:03,150
and I have this table.

859
00:44:03,150 --> 00:44:07,290
As you can see, there is many
errors related to the DynamoDB

860
00:44:07,290 --> 00:44:09,690
and I can, you know, see that information,

861
00:44:09,690 --> 00:44:12,363
of course, double click it if I need it.

862
00:44:13,380 --> 00:44:16,650
Scrolling a little bit down,
see still on the overview page

863
00:44:16,650 --> 00:44:20,190
I see the how many sessions
this agent had, how many traces,

864
00:44:20,190 --> 00:44:23,040
and also token consumption, very important

865
00:44:23,040 --> 00:44:26,160
for cost optimization
and how AWS charge you,

866
00:44:26,160 --> 00:44:28,890
it's information that is useful.

867
00:44:28,890 --> 00:44:33,570
Again, how many (indistinct)
determines has and the latency,

868
00:44:33,570 --> 00:44:34,650
everything that you're seeing,

869
00:44:34,650 --> 00:44:36,750
it is already prebuilt for you.

870
00:44:36,750 --> 00:44:41,750
Last but not least was the
CPU and memory utilization.

871
00:44:41,920 --> 00:44:45,240
Now, each interaction with the agent,

872
00:44:45,240 --> 00:44:48,060
it creates sessions and
session contained traces

873
00:44:48,060 --> 00:44:50,220
and traces contains spans.

874
00:44:50,220 --> 00:44:54,300
So, going deeper on the session part,

875
00:44:54,300 --> 00:44:56,640
just reduce the time for five minutes.

876
00:44:56,640 --> 00:44:59,730
So, capture the last prompt that I did

877
00:44:59,730 --> 00:45:02,310
and what I can see it is kind of

878
00:45:02,310 --> 00:45:04,170
the same information that I have.

879
00:45:04,170 --> 00:45:06,465
But now looking for just
for this particular session.

880
00:45:06,465 --> 00:45:11,190
So, it's allow you to go deeper
on this particular prompt.

881
00:45:11,190 --> 00:45:13,630
If I click one of those
traces, what I can see

882
00:45:13,630 --> 00:45:18,390
out of the gate, it is
how many spans latency,

883
00:45:18,390 --> 00:45:20,880
token consumption. if I have any errors,

884
00:45:20,880 --> 00:45:22,680
I already see one of the errors.

885
00:45:22,680 --> 00:45:25,410
Remember that I was not
able to flash that data.

886
00:45:25,410 --> 00:45:27,270
I also see the trajectory

887
00:45:27,270 --> 00:45:30,930
of this whole prompt cover took cover,

888
00:45:30,930 --> 00:45:33,210
what exactly the agent had to do in order

889
00:45:33,210 --> 00:45:35,160
to produce the information backed

890
00:45:35,160 --> 00:45:39,330
and all the tools that the
agent have to call on my behalf.

891
00:45:39,330 --> 00:45:42,000
I'm able to see also the expense

892
00:45:42,000 --> 00:45:46,560
in the format of a timeline
tree and also in the timeline,

893
00:45:46,560 --> 00:45:48,600
here I'm showing the token consumption

894
00:45:48,600 --> 00:45:52,410
on that particular
invocation input and output.

895
00:45:52,410 --> 00:45:54,390
And this is this same visualization,

896
00:45:54,390 --> 00:45:56,460
but now in a timeline perspective.

897
00:45:56,460 --> 00:45:59,190
So, as you can see, I have
multiple ways to understand

898
00:45:59,190 --> 00:46:01,530
how this particular session's doing.

899
00:46:01,530 --> 00:46:04,740
Looking for the event itself, here is

900
00:46:04,740 --> 00:46:08,580
where I will be able to see
the prompt that I did, right?

901
00:46:08,580 --> 00:46:12,930
It is trying to get
information regarding payment

902
00:46:12,930 --> 00:46:17,070
and then a two internally
will be a trigger.

903
00:46:17,070 --> 00:46:18,360
And then what is gonna happen,

904
00:46:18,360 --> 00:46:21,990
because that information
is in a DynamoDB table,

905
00:46:21,990 --> 00:46:25,290
the agent doesn't have permission.

906
00:46:25,290 --> 00:46:27,420
So, it is throwing an exception,

907
00:46:27,420 --> 00:46:29,700
access denied exception over there

908
00:46:29,700 --> 00:46:33,240
because the agent itself
doesn't have a permission

909
00:46:33,240 --> 00:46:34,590
to flash that information.

910
00:46:34,590 --> 00:46:36,990
That's why I was not able to see

911
00:46:36,990 --> 00:46:39,450
that information on the agent.

912
00:46:39,450 --> 00:46:42,360
So, here, in order to fix it, I needed to,

913
00:46:42,360 --> 00:46:45,930
of course go in the IAM role of the agent

914
00:46:45,930 --> 00:46:47,823
and give her permission to do so.

915
00:46:49,530 --> 00:46:51,510
Now, I wanted to show,

916
00:46:51,510 --> 00:46:55,110
because we mentioned related
to evaluations, right?

917
00:46:55,110 --> 00:46:59,539
I have a elements, a
judge in front of this

918
00:46:59,539 --> 00:47:03,840
particular agent and then just
gonna change the time here

919
00:47:03,840 --> 00:47:08,840
to 12 hours to cover how many
sampling information was used

920
00:47:09,780 --> 00:47:11,850
to analyze by this LLM.

921
00:47:11,850 --> 00:47:15,000
And first of all, I can see the evaluation

922
00:47:15,000 --> 00:47:17,070
configuration across the board.

923
00:47:17,070 --> 00:47:20,400
So, filtering, it is available

924
00:47:20,400 --> 00:47:24,273
and I can see like
related to stereotyping,

925
00:47:25,270 --> 00:47:28,260
to session and so on and so forth.

926
00:47:28,260 --> 00:47:30,480
So, each evaluation is offered

927
00:47:30,480 --> 00:47:34,500
that same granularity
session, trace and spans, too.

928
00:47:34,500 --> 00:47:37,380
So, as you can see, all the tracings

929
00:47:37,380 --> 00:47:40,440
that I have in this particular
agents, it is right there,

930
00:47:40,440 --> 00:47:42,690
and I can filter by many, many options

931
00:47:42,690 --> 00:47:45,360
that is being used by the evaluator.

932
00:47:45,360 --> 00:47:47,880
I also have the dashboards, right?

933
00:47:47,880 --> 00:47:51,810
Dashboards, building dashboards
created by CloudWatch.

934
00:47:51,810 --> 00:47:55,620
So, each one of those
elements, those metrics

935
00:47:55,620 --> 00:48:00,510
that is being used by the
evaluator, it is right here.

936
00:48:00,510 --> 00:48:02,820
So, instruction follow,

937
00:48:02,820 --> 00:48:06,060
if the LLM used the
instruction that I gave,

938
00:48:06,060 --> 00:48:10,890
if it's harmful, if it is
helpful, if it is stereotyping,

939
00:48:10,890 --> 00:48:13,680
all that information, it is right here.

940
00:48:13,680 --> 00:48:18,680
So, I can understand the
agent behavior itself,

941
00:48:19,410 --> 00:48:21,780
and of course I have
that as in a log format

942
00:48:21,780 --> 00:48:24,720
to using CloudWatch logs.

943
00:48:24,720 --> 00:48:27,420
I just wanna go back to the demo

944
00:48:27,420 --> 00:48:31,140
and to the session specifically

945
00:48:31,140 --> 00:48:35,550
to show one last case, one
last use case going back

946
00:48:35,550 --> 00:48:37,530
to the same session,

947
00:48:37,530 --> 00:48:41,160
but now one of the prompts
that I did, if you remember,

948
00:48:41,160 --> 00:48:43,740
was related to getting information

949
00:48:43,740 --> 00:48:48,740
for an specific honor.

950
00:48:48,780 --> 00:48:51,570
And again, I'm gonna have

951
00:48:51,570 --> 00:48:54,690
all their information
related to the trace,

952
00:48:54,690 --> 00:48:58,740
but I wanted to show, because
I have data protection rule in

953
00:48:58,740 --> 00:49:01,950
place for my CloudWatch

954
00:49:01,950 --> 00:49:05,560
and that that specific rule is masking

955
00:49:06,690 --> 00:49:09,120
birth dates and also telephone numbers.

956
00:49:09,120 --> 00:49:13,410
As you can see it will be
masked in the logs too,

957
00:49:13,410 --> 00:49:15,903
right, directly here on the console.

958
00:49:18,720 --> 00:49:23,720
So, we're closing to our session today,

959
00:49:24,120 --> 00:49:29,120
so I wanted to make sure you
leave with a few key takeaways.

960
00:49:29,220 --> 00:49:32,790
So, first of all, getting started today,

961
00:49:32,790 --> 00:49:35,160
enhancing like your observability stack.

962
00:49:35,160 --> 00:49:38,670
as you saw in the first demo
and also in the first part,

963
00:49:38,670 --> 00:49:40,737
we talk about application monitoring.

964
00:49:40,737 --> 00:49:44,370
You can use APM to help you

965
00:49:44,370 --> 00:49:47,370
enhance your overall application,

966
00:49:47,370 --> 00:49:51,270
understanding more the
interconnection, the dependencies

967
00:49:51,270 --> 00:49:52,430
that you have in application.

968
00:49:52,430 --> 00:49:55,800
Can use a application map, for instance,

969
00:49:55,800 --> 00:49:58,800
to see the topology of your application

970
00:49:58,800 --> 00:50:02,460
and is automatically
discovered using OpenTelemetry.

971
00:50:02,460 --> 00:50:05,190
Second of all, you are building agents.

972
00:50:05,190 --> 00:50:07,290
You should build agents and use CloudWatch

973
00:50:07,290 --> 00:50:12,290
and genAI observability
to overall understand

974
00:50:12,780 --> 00:50:14,430
and observe your agents.

975
00:50:14,430 --> 00:50:18,750
If they are hosted by AgentCore or not,

976
00:50:18,750 --> 00:50:21,900
you can still use CloudWatch
genAI observability

977
00:50:21,900 --> 00:50:24,690
and fully integrate it
with Amazon CloudWatch.

978
00:50:24,690 --> 00:50:27,990
And use the assessor,
the evaluators assess

979
00:50:27,990 --> 00:50:30,840
programmatically your
agents using the evaluator.

980
00:50:30,840 --> 00:50:33,900
We just launched that two days ago.

981
00:50:33,900 --> 00:50:35,430
So, set up the evaluation

982
00:50:35,430 --> 00:50:37,740
in order to understand your overall

983
00:50:37,740 --> 00:50:40,110
instruction following for your agents.

984
00:50:40,110 --> 00:50:42,993
And, you have all that in
the single pane of class.

985
00:50:44,100 --> 00:50:46,440
Last but not least, I
wanted to give a couple

986
00:50:46,440 --> 00:50:50,760
of resource QR codes here that is useful.

987
00:50:50,760 --> 00:50:54,330
The first one it is demos, demo codes.

988
00:50:54,330 --> 00:50:57,480
We have demos in the GitHub available,

989
00:50:57,480 --> 00:50:59,610
not just on on BedRock AgentCore,

990
00:50:59,610 --> 00:51:04,610
but also agents hosted in EKS, ECS, EC2.

991
00:51:04,680 --> 00:51:05,970
The QR code in the middle

992
00:51:05,970 --> 00:51:10,500
has all the links related
to AWS Observability

993
00:51:10,500 --> 00:51:13,573
So, we host a show in a YouTube channel

994
00:51:13,573 --> 00:51:15,600
called "The Cloud Operations Show"

995
00:51:15,600 --> 00:51:19,170
that we talk about observability
collaboration as a whole.

996
00:51:19,170 --> 00:51:22,110
We have workshop, best practice.

997
00:51:22,110 --> 00:51:23,190
Everything that I mentioned,

998
00:51:23,190 --> 00:51:26,250
it is in that single
QR code in the middle.

999
00:51:26,250 --> 00:51:28,920
The last, but not the
least, the third one,

1000
00:51:28,920 --> 00:51:32,820
it is a blog post of
this particular launch

1001
00:51:32,820 --> 00:51:34,650
that I just mentioned related

1002
00:51:34,650 --> 00:51:37,200
to generative AI observability.

1003
00:51:38,460 --> 00:51:42,000
If you're interested in this
topic, I wanted to invite you.

1004
00:51:42,000 --> 00:51:45,300
We we have a lot of kiosks

1005
00:51:45,300 --> 00:51:49,590
on CloudOps in the village,
in the AWS village.

1006
00:51:49,590 --> 00:51:53,430
And just, you know, swing
by, we have one-on-one demos,

1007
00:51:53,430 --> 00:51:56,040
we have SMEs across the globe.

1008
00:51:56,040 --> 00:52:00,360
So, if you're interested to
ask a question, you know,

1009
00:52:00,360 --> 00:52:02,580
myself and Peter is
gonna be there outside.

1010
00:52:02,580 --> 00:52:04,620
We also can answer your question,

1011
00:52:04,620 --> 00:52:07,403
but if you wanted to go to
the kiosk, please do so.

1012
00:52:07,403 --> 00:52:11,160
We have swags, we have
stickers, we can do demos.

1013
00:52:11,160 --> 00:52:15,123
So, just go there and
we're gonna help you.

1014
00:52:18,270 --> 00:52:20,700
Last, but least, I wanted to thank you,

1015
00:52:20,700 --> 00:52:22,380
thank you for your time.

1016
00:52:22,380 --> 00:52:24,870
Appreciate you come to this presentation.

1017
00:52:24,870 --> 00:52:28,590
I really wanted to ask you to
please complete the survey.

1018
00:52:28,590 --> 00:52:32,190
We use that data every year
to improve our sessions.

1019
00:52:32,190 --> 00:52:37,190
So, if you go to your AWS
Event app in your cell phone,

1020
00:52:37,590 --> 00:52:41,010
you'll be able to go to More
and then Surveys on the top.

1021
00:52:41,010 --> 00:52:46,010
This is COP326, so please
give your data points related

1022
00:52:47,340 --> 00:52:50,970
to this session so we
can improve next year.

1023
00:52:50,970 --> 00:52:54,900
So, with that, I wish the
best of luck to the rest

1024
00:52:54,900 --> 00:52:58,170
of the re:Invent and thank
you very much for being here.

1025
00:52:58,170 --> 00:52:59,633
Thank you.

1026
00:52:59,633 --> 00:53:02,716
(audience applauds)

