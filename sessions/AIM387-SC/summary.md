# AWS re:Invent 2025 会议总结

## 会议概述

本次会议面向数据科学家和AI开发者，重点介绍如何定制模型并大规模部署以构建高质量且具有成本效益的智能体应用。会议由AWS SageMaker团队的高级经理Amit Modi主持，世界级GenAI专家Dan和SGLang联合创始人Ying共同参与演示。

会议指出了当前行业的两大趋势：首先，智能体AI在企业软件应用中的快速采用，预计将从2024年的1%增长到2028年的33%，这是4年内33倍的增长。其次，客户越来越依赖开放权重模型来构建这些应用。然而，尽管机会巨大，大多数应用仍然无法投入生产。会议深入分析了客户面临的五大核心挑战：缺乏标准化的模型定制工具、难以找到合适的推理堆栈配置、可观测性工具碎片化、实验代码难以生产化，以及缺乏企业级治理能力。

为解决这些挑战，AWS展示了SageMaker的完整能力套件，包括训练和微调、推理部署、MLflow可观测性、Pipeline编排以及模型注册表。会议通过一个医疗保健场景的完整演示，展示了如何使用这些工具构建一个临床诊断智能体，从模型微调、部署到与Bedrock Agent Core集成的全流程。

## 详细时间线

### 开场介绍 (00:00 - 02:30)
- **00:00** - 会议开始，介绍目标受众：数据科学家和AI开发者
- **00:15** - 强调会议重点：定制模型、大规模部署、构建高质量且具有成本效益的智能体应用
- **00:30** - 介绍行业两大趋势：智能体AI快速采用和开放权重模型的使用
- **00:45** - 关键数据：智能体AI采用率将从2024年的1%增长到2028年的33%
- **01:00** - 指出核心问题：尽管机会巨大，大多数应用仍无法投入生产

### 客户面临的核心挑战 (02:30 - 05:00)
- **02:30** - 挑战一：缺乏标准化工具来使用不同技术定制模型
- **03:00** - 挑战二：需要合适的推理堆栈来托管模型，找到正确的实例和容器配置需要大量努力
- **03:30** - 挑战三：可观测性工具碎片化，难以追踪模型和智能体行为
- **04:00** - 挑战四：实验工作流难以扩展到生产环境，通常需要重建管道
- **04:30** - 挑战五：缺乏企业级治理实践，难以跟踪、审计和版本化模型

### 演讲嘉宾介绍 (05:00 - 06:00)
- **05:00** - Amit Modi自我介绍：SageMaker模型操作和推理高级经理
- **05:15** - 介绍Dan：全球GenAI专家
- **05:30** - 介绍Ying：SGLang联合创始人
- **05:45** - 会议结构预告：SageMaker能力概述、实际演示、SGLang关键特性

### SageMaker训练和微调能力 (06:00 - 10:00)
- **06:00** - 介绍SageMaker训练和微调能力
- **06:30** - 强调提供最广泛的模型选择，包括开源模型和Amazon Nova模型
- **07:00** - 介绍多种微调配方（recipes）供选择
- **07:30** - 训练基础设施选项：临时计算的完全托管训练作业或SageMaker Hyperpod持久集群
- **08:00** - 关键能力一：自动检查点和自我修复集群
- **08:30** - 详细说明：节点故障时自动替换并从最后检查点恢复
- **09:00** - 关键能力二：微调配方，支持最常用的模型和技术
- **09:30** - 使用方法：准备数据、选择配方、在训练作业或Hyperpod集群上启动

### SageMaker AI推理能力 (10:00 - 15:00)
- **10:00** - 介绍SageMaker AI推理能力
- **10:30** - 可以通过UI或SDK快速部署开源或微调模型
- **11:00** - 支持在任何框架和基础设施上托管任何模型
- **11:30** - 开箱即用提供高吞吐量和低延迟
- **12:00** - 多模型端点：在同一端点上部署多个模型
- **12:30** - 智能路由确保无性能损失，可扩展到数百个模型
- **13:00** - 每个模型独立的自动扩展策略
- **13:30** - 推测解码（Speculative Decoding）：使用草稿模型预测，基础模型验证
- **14:00** - 推测解码效果：延迟降低，吞吐量提高2.5倍，不影响准确性
- **14:30** - 支持的框架：vLLM、SGLang、TensorRT-LLM等

### MLflow集成和可观测性 (15:00 - 18:00)
- **15:00** - 宣布推出Serverless MLflow on SageMaker
- **15:30** - 完全托管、无需管理基础设施、自动扩展
- **16:00** - 可记录实验、评估结果、智能体追踪，全部集中在一处
- **16:30** - Serverless MLflow免费，无额外费用
- **17:00** - 实验追踪界面展示：可比较不同训练运行，识别最佳候选模型
- **17:30** - 与Agent Core集成：自动发送追踪数据到MLflow，符合OpenTelemetry规范

### 智能体追踪和调试 (18:00 - 20:00)
- **18:00** - 展示完整的追踪树结构
- **18:30** - 从invoke agent开始，深入到工作流构建过程
- **19:00** - 捕获LangChain操作的每个步骤，包括工具调用和助手交互
- **19:30** - 层次化视图提供完整可见性，便于根因分析

### SageMaker Pipelines (20:00 - 22:00)
- **20:00** - 介绍SageMaker Pipelines：将实验工作流生产化
- **20:30** - 通过@step注解或拖放UI将代码转换为管道步骤
- **21:00** - 提供训练、评估、部署的内置步骤
- **21:30** - 无服务器编排，无需管理基础设施
- **21:45** - 内置缓存：失败后重新触发时跳过已成功步骤

### 模型注册表和治理 (22:00 - 24:00)
- **22:00** - 介绍SageMaker模型注册表
- **22:30** - 所有模型版本的单一真实来源
- **23:00** - 跨账户访问：在一处追踪所有环境的模型
- **23:30** - 捕获训练作业详细信息，提供端到端血缘关系

### 演示开始 - 医疗场景介绍 (24:00 - 26:00)
- **24:00** - Dan接手演示
- **24:30** - 场景设定：医疗保健提供商，使用ML/AI加速患者诊疗
- **25:00** - 演示目标：托管语言模型、微调、使用Pipelines编排
- **25:30** - 集成MLflow可观测性和追踪
- **25:45** - 部署到模型注册表，构建智能体

### 演示架构概览 (26:00 - 28:00)
- **26:00** - 展示演示架构图
- **26:30** - 训练Llama 3.2 3B Instruct模型，使用LoRA适配
- **27:00** - 使用SGLang容器部署到SageMaker端点
- **27:30** - 介绍ML Container Creator：新的开源仓库，用于构建自定义容器
- **27:45** - 鼓励社区贡献

### 演示 - Pipeline定义 (28:00 - 32:00)
- **28:00** - 展示Notebook导入部分
- **28:30** - 导入Pipeline定义文件：各个步骤的执行指令
- **29:00** - 设置环境：boto3客户端、计时器等
- **29:30** - 初始化MLflow环境：设置追踪URI和实验名称
- **30:00** - 定义容器资产位置：S3上的Docker文件和服务文件
- **30:30** - 指定模型：Llama 3.2 3B Instruct，从Hugging Face获取
- **31:00** - 展示Pipeline定义代码墙
- **31:30** - 展示有向无环图（DAG）：构建容器、预处理数据、LoRA微调、部署、注册

### 演示 - Pipeline执行 (32:00 - 35:00)
- **32:00** - 使用SageMaker Pipeline对象拼接步骤
- **32:30** - 执行pipeline.start()启动Pipeline运行
- **33:00** - 成功后各步骤显示绿色勾选标记
- **33:30** - 可双击查看每个步骤的详细信息和CloudWatch日志
- **34:00** - 在SageMaker控制台查看Pipeline运行历史
- **34:30** - 在MLflow中查看相同的Pipeline步骤列表

### 演示 - Pipeline步骤详解 (35:00 - 38:00)
- **35:00** - 深入查看LoRA微调编排步骤
- **35:30** - @step注解：允许单独定义步骤
- **36:00** - 传递MLflow追踪服务器信息
- **36:30** - 定义训练数据集、测试数据集、模型ID
- **37:00** - 设置MLflow上下文和自动系统指标记录
- **37:30** - 配置训练参数并启动训练作业
- **38:00** - 在MLflow中查看系统指标和标记的指标

### 演示 - 模型卡和端点测试 (38:00 - 41:00)
- **38:00** - 展示模型注册步骤中设置的模型卡
- **38:30** - 强调医疗场景中模型卡的重要性，用于治理
- **39:00** - 测试已部署的端点
- **39:30** - 创建标准预测器
- **40:00** - 运行基本提示：45岁男性，发烧咳嗽，体温101.3°F，心率98
- **40:30** - 展示模型输出：患者详情、初步评估、疑似肺炎症状

### 演示 - MLflow模型注册表 (41:00 - 42:00)
- **41:00** - 在MLflow中查看模型注册表
- **41:30** - 展示版本1，说明新版本会添加到版本列表
- **41:45** - 模型卡可能会随版本更新

### 演示 - 构建智能体 (42:00 - 45:00)
- **42:00** - 第二部分：为模型添加更多能力
- **42:30** - 构建智能体：上传诊断报告到S3、查询患者数据库
- **43:00** - 展示架构：使用Bedrock Agent Core部署Strands智能体
- **43:30** - Strands SDK：轻量级开源工具，快速构建智能体
- **44:00** - 使用Agent Core遥测捕获请求数据
- **44:30** - Agent Core遥测补充MLflow可观测性

### 演示 - 智能体代码结构 (45:00 - 50:00)
- **45:00** - 展示导入列表
- **45:30** - 设置环境，硬编码端点名称和推理组件
- **46:00** - 说明模型部署在推理组件上，可独立扩展
- **46:30** - 构建Strands智能体：使用Python f-string注入变量
- **47:00** - 传入区域、端点名称、S3存储桶、推理组件
- **47:30** - 定义患者数据类：患者信息和症状
- **48:00** - 跳转到关键部分：调用SageMaker端点
- **48:30** - invoke_sagemaker_endpoint_async方法
- **49:00** - 定义提示：相同的临床查询
- **49:30** - 将提示包装在超级提示中：临床培训场景

### 演示 - 追踪和遥测 (50:00 - 53:00)
- **50:00** - 定义追踪器：Agent Core可观测性捕获追踪数据
- **50:30** - 硬编码属性：SageMaker端点、推理组件
- **51:00** - 记录超参数：max_tokens、temperature、实际提示
- **51:30** - 定义payload：使用messages API，系统提示和用户提示
- **52:00** - 调用端点
- **52:30** - 在span对象上设置额外信息：响应持续时间、响应长度、成功元数据

### 演示 - 配置Strands智能体 (53:00 - 56:00)
- **53:00** - 配置实际智能体
- **53:30** - 设置本地模式和Agent Core运行时上下文
- **54:00** - Agent Core运行时使用FastAPI
- **54:30** - 定义SageMaker AI模型类：Strands SDK用于定义托管在SageMaker端点上的LLM
- **55:00** - 该功能于8月推出，允许使用非API提供商的语言模型
- **55:30** - 展示追踪信息示例

### 演示 - Agent Core部署 (56:00 - 58:00)
- **56:00** - 非本地模式：创建Bedrock Agent Core应用
- **56:30** - 创建FastAPI服务器
- **57:00** - 调用create_medical_agent创建Strands智能体
- **57:30** - 定义入口点：仅在部署到Bedrock Agent Core时运行
- **58:00** - 本地运行时执行相同逻辑但在本地上下文

### 演示 - 本地测试 (58:00 - 60:00)
- **58:00** - 将f-string写入Python文件
- **58:30** - 使用shell magic运行Python代码，带local标志
- **59:00** - 传入相同的友好提示
- **59:30** - 在Python运行时中启动文件，将消息传递给语言模型端点
- **60:00** - 这与部署到Agent Core运行时后的行为完全相同，只是尚未通过运行时API访问

### 演示结果展示 (60:00 - 结束)
- **60:00** - 展示返回结果：基于提供的临床场景...
- **60:15** - 演示继续（字幕在此处截断）