# AWS re:Invent 2025 会议总结：AI 先锋在生产环境中构建变革性生成式架构

## 会议概述

本次会议由 AWS SMB 业务的首席解决方案架构师 Pranav Sharma 和 Jay 共同主持,并邀请了 Misraj AI 的 CEO Safwan 作为客户代表。会议深入探讨了 AI 先锋组织如何在生产环境中构建和部署变革性的生成式 AI 架构。

AI 先锋组织通常是使用 AI 技术构建面向客户的变革性架构的企业,这些组织往往团队规模较小但极具敏捷性,怀有颠覆所在行业的雄心壮志。与通过 API 简单消费 AI 服务的普通用户不同,这些组织更接近 AI 基础设施本身,他们是模型构建者、模型定制者,或者在大规模运行 LLM 推理和其他基础模型推理。

会议重点介绍了三个核心 AI 先锋架构模式:构建 LLM 服务平台、创意内容生成,以及阿拉伯语视觉语言模型的文档处理应用。这些架构模式展示了从托管服务到自管理基础设施,从云端到本地部署的完整解决方案路径,为不同规模和需求的组织提供了可参考的实践指南。

## 详细时间线

### 开场介绍 (00:00 - 02:30)
- **00:00** - 会议开始,Pranav Sharma 介绍自己和团队成员
- **00:30** - 介绍会议议程:AI 先锋概述、三个核心架构模式(LLM 服务平台、创意内容生成、文档处理)
- **01:45** - 预告将讨论 2026 年新兴架构模式

### AI 先锋定义与特征 (02:30 - 04:00)
- **02:30** - 定义 AI 先锋:使用 AI 构建变革性客户端架构的组织
- **03:00** - 描述 AI 先锋的典型特征:小团队、高敏捷性、大志向
- **03:30** - 说明 AI 先锋的技术特点:模型构建者、定制者、大规模推理运营者

### LLM 服务平台架构 (04:00 - 25:00)

#### LLM 服务平台概述 (04:00 - 06:30)
- **04:00** - 介绍 LLM 推理已成为现代架构的基础构建块
- **04:45** - 解释 LLM 推理的复杂性:模型规模巨大、需要多 GPU/多节点
- **05:30** - 说明推理模型的思考预算(thinking budgets)特性
- **06:00** - 强调请求响应的多样性使 LLM 推理成为"极限工程问题"

#### LLM 服务平台五大需求 (06:30 - 09:00)
- **06:30** - 需求一:模型选择 - 快速访问基础模型和开源创新
- **07:00** - 需求二:支持服务 - 向量数据库、护栏、安全性、可观测性
- **07:30** - 需求三:SaaS 能力 - 速率限制、成本归因、使用报告
- **08:00** - 需求四:自管理模型 - 访问加速计算实例、快速网络、快速存储
- **08:30** - 需求五:任意位置部署 - 支持本地和云端部署

#### 托管架构模式 (09:00 - 13:00)
- **09:00** - 介绍最简单的托管架构:直接使用 Amazon Bedrock
- **09:30** - 零售购物助手用例:使用 Anthropic Claude Sonnet 4.5
- **10:30** - Bedrock Knowledge Bases:文档向量化和查询
- **11:15** - Bedrock Guardrails:PII 识别、有毒内容过滤、上下文基础验证
- **12:00** - 会话管理:聊天日志分析和会话跟踪
- **12:30** - 提示管理:版本控制和提示重用

#### SaaS 架构模式 (13:00 - 17:30)
- **13:00** - 引入 LLM 网关组件实现 SaaS 能力
- **13:45** - 代码助手用例:支持多种工具(Claude Code、Cursor、GitHub Copilot)
- **14:30** - 速率限制:防止单个开发者消耗所有令牌
- **15:00** - 成本归因和使用报告功能
- **15:45** - 弹性能力:跨多个 AWS 账户负载均衡
- **16:30** - LLM 网关技术细节:基于 LiteLLM 的容器化应用,部署在 Amazon EKS
- **17:00** - CloudFront + ALB + EKS 的请求路由架构

#### 混合架构模式 (17:30 - 21:30)
- **17:30** - 介绍 Amazon SageMaker HyperPod 支持自管理基础设施
- **18:00** - 加速计算实例:Nvidia、AWS 定制芯片、AMD
- **18:45** - 灵活训练计划(Flexible Training Plans)快速访问实例
- **19:15** - 单一主干网络(Single Spine)部署:节点间低延迟
- **19:45** - 预配置弹性网络适配器(EFA):超快网络连接和 OS 旁路
- **20:15** - 一键可观测性:通过 CloudWatch、Prometheus、Grafana 监控 TTFT 和 TBT 指标
- **21:00** - 自动修复能力:预配置健康检查和自动节点替换

#### 混合架构技术细节 (21:30 - 24:00)
- **21:30** - SageMaker HyperPod 由 Amazon EKS 编排
- **22:00** - 模型部署来源:S3、FSx for Lustre、SageMaker JumpStart
- **22:45** - 多角色支持:管理员使用 kubectl,数据科学家使用 Python SDK,HyperPod CLI
- **23:30** - 可观测性堆栈:CloudWatch + Prometheus + Grafana

#### 完整混合架构 (24:00 - 25:00)
- **24:00** - 介绍 EKS Hybrid Nodes 实现本地部署
- **24:30** - Node ADM CLI 配置本地节点
- **24:45** - 本地节点在 EKS 集群中显示为普通节点

### 创意内容生成架构 (25:00 - 42:00)

#### 用例介绍 (25:00 - 27:30)
- **25:00** - Jay 接手演讲,介绍创意内容生成挑战
- **25:30** - 核心挑战:大规模生成一致的视觉内容
- **26:00** - 展示通用模型的局限性:相同提示生成不同角色
- **26:45** - 应用场景:儿童读物、教育内容、营销活动
- **27:15** - 真实案例:AWS 工作室的短片《Pichu》

#### 定制化技术层次 (27:30 - 30:00)
- **27:30** - 提示工程:低成本但无法保证视觉一致性
- **28:00** - 上下文工程:通过数据源提供额外上下文
- **28:45** - Bedrock 微调:参数高效微调(PEFT)、蒸馏、持续预训练(CPT)
- **29:30** - SageMaker 完全微调:最大灵活性和控制,需要 ML 专业知识

#### Bedrock 微调工作流程 (30:00 - 32:00)
- **30:00** - 三个输入:基础模型(Nova Canvas)、输入数据、超参数
- **30:45** - 数据准备流程概述
- **31:30** - 从视频中提取帧作为训练数据

#### 数据准备管道 (32:00 - 38:00)
- **32:00** - 阶段一:原始数据提取
  - 从视频采样提取帧
  - 使用 Amazon Rekognition 识别人脸
  - 面部集合功能识别特定角色
- **33:30** - 阶段二:预处理
  - 图像格式转换
  - 移除低质量图像
  - 使用 Nova 多模态嵌入模型识别重复图像
  - 通过语义相似度阈值去重
- **35:00** - 阶段三:图像描述生成
  - 使用视觉能力模型(Claude Sonnet、Nova Pro)生成描述
  - 批量推理优化成本
  - 引入人工审核流程
- **36:00** - Amazon Augmented AI (A2I) 人工审核
  - 使用 Kiro 生成 Liquid HTML 模板
  - 并排显示图像和 AI 生成的描述
  - 人工审核员验证和编辑描述
- **37:30** - 最终输出:符合 Bedrock 微调要求的数据格式

#### 超参数配置 (38:00 - 40:00)
- **38:00** - 批量大小(Batch Size):模型调整参数前处理的样本数
- **38:45** - 步数/轮次(Steps/Epochs):平衡训练速度和过拟合风险
- **39:30** - 学习率(Learning Rate):最关键参数,类比驾驶速度
- **39:50** - 展示默认值、支持范围和经验法则指导

#### 微调执行与评估 (40:00 - 42:00)
- **40:00** - Bedrock 使微调变得易于访问
- **40:30** - 微调作业启动和监控
- **41:00** - 模型评估:视觉质量检查
- **41:30** - 迭代优化:调整超参数和数据质量

### 阿拉伯语文档处理案例 (42:00 - 结束)
- **42:00** - Safwan(Misraj AI CEO)上台
- **42:30** - 介绍阿拉伯语视觉语言模型
- **43:00** - 文档处理用例的特殊挑战
- **43:30** - 在 AWS 上构建先锋模型的经验分享

### 总结与展望 (结束前)
- 回顾四种架构模式:托管、SaaS、混合、完整混合
- 强调架构的渐进式构建方法
- 预告 2026 年新兴架构趋势
- 提供 QR 码和资源链接供进一步学习