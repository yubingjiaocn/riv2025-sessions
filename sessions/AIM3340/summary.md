# AWS re:Invent 2025 - SageMaker MLflow 会议总结

## 会议概述

本次会议重点介绍了 AWS SageMaker 中 MLflow 的最新发展，特别是本周刚刚发布的无服务器（Serverless）版本。会议由 AWS 团队成员主讲，并邀请了 Intuit 公司的工程师 Rohan 分享客户实践经验。

MLflow 是一个开源的机器学习生命周期管理工具，AWS 提供的托管版本解决了自托管带来的运维复杂性、版本升级负担和总体拥有成本高等问题。新推出的无服务器 MLflow 进一步简化了基础设施管理，实现了自动扩缩容、自动版本升级，并且完全免费。这使得数据科学家可以专注于模型开发，而无需担心基础设施配置。

Intuit 的案例展示了从自托管 MLflow 到 AWS 托管服务的演进历程。他们在生产环境中运行超过 400 个预测性 AI 模型，每天产生 600 亿次预测。随着生成式 AI 和智能代理的爆发式增长，实验和评估的规模急剧扩大，在 2024 年第三季度就创建了超过 43,000 次运行。迁移到托管 MLflow 后，模型开发时间从 3-4 个月缩短到不到 2 周，显著提升了团队生产力。

## 详细时间线与关键要点

### 开场与背景介绍
[00:00:00 - 00:03:00]
- 会议开始，主持人询问现场观众对 MLflow 的熟悉程度
- 介绍会议议程：MLflow 现有功能、本周新发布的无服务器版本，以及 Intuit 的客户案例分享

### AI 治理的重要性
[00:03:00 - 00:06:30]
- 强调 AI 模型失败的根本原因往往不是模型本身，而是缺乏治理
- 介绍 ML/GenAI 模型的五步流程：数据准备、训练/微调、注册、部署、监控
- 指出客户面临的挑战：缺乏标准化基础设施、协作困难、模型可解释性和可重复性问题

### MLflow 的核心价值
[00:06:30 - 00:09:00]
- MLflow 解决四大关键挑战：可追溯性和可重复性、CI/CD 集成、模型注册管理、与 SageMaker 生态系统的深度集成
- 对比自托管 MLflow 的三大痛点：运维复杂性、版本升级频繁、集成开发成本高

### SageMaker 托管 MLflow 的演进
[00:09:00 - 00:12:00]
- 一年半前推出完全托管的 MLflow 实例
- 展示从版本 2.13 到最新 3.4 版本的演进
- 介绍典型工作流：提供 ARN 标识符、记录指标、查看 UI、注册和部署模型

### 无服务器 MLflow 重磅发布
[00:12:00 - 00:16:00]
- **本周二发布的无服务器版本核心特性：**
  - 无需基础设施管理，自动扩缩容
  - 自动就地版本升级
  - 支持通过 RAM（资源访问管理器）进行跨账户集中式实验跟踪
  - **完全免费**
  - 改进的导入导出工具，便于迁移

### 无服务器 MLflow 的架构优势
[00:16:00 - 00:19:00]
- 与 SageMaker 生态系统的原生集成：Studio IDE、Pipeline、Model Customization
- 支持自动注册到 SageMaker 模型注册表
- 可部署到 SageMaker 推理或其他目标环境

### 对数据科学家的价值
[00:19:00 - 00:22:00]
- 域创建时自动配置默认 MLflow 应用，无需等待管理员
- 加速实验迭代
- Pipeline 和 Model Customization 自动使用 MLflow
- 始终在线，零成本，自动扩缩容
- 支持跨团队跨账户协作

### 工作流对比
[00:22:00 - 00:24:00]
- **传统流程：** 登录 Studio → 创建跟踪服务器（20-25 分钟）→ 复制 ARN → 配置到 Pipeline 和 Model Customization
- **无服务器流程：** 登录即可使用默认应用，Pipeline 和 Model Customization 自动检测和使用

### 客户案例：野生动物保护协会
[00:24:00 - 00:25:00]
- 使用托管 MLflow 加速珊瑚礁照片分析项目
- 小团队通过无服务器方案控制成本，科学家专注核心工作

### 产品演示
[00:25:00 - 00:35:00]
- **管理员视角：** 创建域时 SageMaker MLflow 默认启用，自动配置权限和角色
- **数据科学家视角：** 
  - 默认 MLflow 应用已创建，可直接使用
  - 可查看详情、复制 ARN
  - 可自定义名称或创建额外应用
  - 新应用配置时间约 2 分钟（相比之前的 20-25 分钟）
- **Pipeline 集成：** 自动检测 MLflow 应用，支持拖拽式 DAG 框架
- **Model Customization 集成：** 高级配置中自动集成 MLflow
- **新版 UI 展示：** 
  - 支持传统 ML 和生成式 AI/智能代理用例
  - IT 支持代理示例：显示工单类型、解决方案、正确性评分、代理执行轨迹
  - 内置可视化工具比较多次运行的指标
  - 版本跟踪和模型注册
  - 提示词比较功能（3.0 版本新增）
- **跨账户共享：** 通过 RAM 选择 MLflow 应用、设置权限、指定目标账户
- **导入导出工具：** 支持从自托管或旧版本迁移到无服务器 MLflow

### Intuit 客户案例分享
[00:35:00 - 00:50:00]

#### Intuit 公司介绍
[00:35:00 - 00:37:00]
- 使命：为全球提供繁荣动力
- 战略：AI 驱动的专家平台
- 服务超过 1 亿消费者和中小企业客户

#### Intuit AI 智能代理展示
[00:37:00 - 00:39:00]
- 财务代理：主动提醒费用变化
- 会计代理：自动分类交易和费用
- 支付代理：准备发票
- 项目管理代理：创建新项目
- 客户代理：寻找潜在客户、起草个性化邮件、安排会议、跟踪销售机会

#### 第一幕：预测性 AI 时代
[00:39:00 - 00:43:00]
- 生产环境运行超过 400 个预测性 AI 模型
- 每天产生 600 亿次预测
- 每天分类 200 万笔交易
- 通过 NLP 处理超过 2500 万次客户互动
- 应用场景：欺诈检测、交易分类、税务处理等
- **面临的挑战：** 实验无组织、缺乏中心化跟踪、可重复性问题、团队协作困难、领导层缺乏可见性

#### 采用 MLflow 的转折点
[00:43:00 - 00:45:00]
- 2023 年第一季度评估多个供应商方案
- 选择开源 MLflow 作为中心化实验跟踪平台
- **成果：** 团队生产力显著提升，模型开发时间从 3-4 个月缩短到不到 2 周
- 实现 AI 民主化，不仅服务数据科学家，也服务开发者

#### 第二幕：生成式 AI 革命
[00:45:00 - 00:48:00]
- 新增组件：LLM 评估排行榜、LLM 应用质量评估服务、AI 智能代理性能评估
- 不再只关注 F1 分数，跟踪更多 LLM 和智能代理指标
- **规模爆炸：** 
  - 每天超过 1600 万次 LLM 调用
  - 2024 年最后三个季度创建超过 1000 个新实验
  - 仅 2024 年第三季度就有超过 43,000 次运行
- **标准化评估流程：** 开发者在 IDE/Notebook 编写代码 → 本地测试或 CI/CD 管道运行评估 → 结果存储到中心化存储（可观测性工具 + MLflow 指标存储）→ 质量仪表板统一视图

#### 迁移到托管 MLflow
[00:48:00 - 00:49:00]
- 为应对超大规模需求，重新架构 MLflow 设置
- 与 AWS ProServe 团队合作加速迁移
- 托管 MLflow 提供质量、准确性和安全性保障，增强交付信心

#### 未来展望
[00:49:00 - 00:50:00]
- 实验和运行量持续垂直增长
- 正在积极探索无服务器 MLflow 方案
- 目标：实现真正的无服务器架构，自动扩展，更具成本效益

### 总结与三大要点
[00:50:00 - 00:52:00]
1. 基础设施简化： 无服务器 MLflow 消除了服务器规模选择、启停管理、版本升级、用户配置等所有运维负担
2. 专注核心工作： 数据科学家可以立即开始工作，Pipeline 和 Model Customization 的默认集成让用户无需了解 MLflow 底层细节
3. AWS 基础设施优势： 构建在 AWS 之上，实现无缝扩展、安全集成、与 SageMaker 生态系统的深度整合

[00:52:00] 会议结束，欢迎会后提问