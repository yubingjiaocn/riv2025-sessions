# AWS re:Invent 2025 - S3 Tables 技术分享会总结

## 会议概述

本次技术分享会由 AWS 的 Brett Cy 和 Indeed 公司的数据湖团队技术负责人 Venitesh Mandalapa 共同主讲。会议重点介绍了 Amazon S3 Tables 这一专为表格数据存储而设计的新型 AWS 资源,以及 Indeed 公司如何利用 S3 Tables 来优化其大规模数据湖架构。

S3 Tables 于一年前的 re:Invent 大会上首次发布,旨在解决客户在使用 Iceberg 表格式时面临的三大核心问题:简化安全管理、提升查询性能以及降低大规模维护的复杂度。该服务通过自动化压缩(compaction)和表维护操作,将原本需要客户自行编写 Spark 作业和管理计算资源的繁重工作转移到了 AWS 平台侧,大幅减少了运维负担。

Indeed 作为全球最大的求职网站,拥有 87 PB 的数据湖规模,每天摄入 550 TB 数据,服务超过 15,000 张表和每日 170,000+ 次查询。通过采用 S3 Tables,Indeed 预计每年可节省约 10% 的 AWS 成本,并将开发团队从维护工作中解放出来,投入到产品开发中。公司正在执行分阶段迁移策略,采用双写管道(dual-write pipeline)方式,确保在迁移过程中不影响全球用户的数据访问。

## 详细时间线与关键要点

00:00:00 - 会议开场与 S3 Tables 介绍
- Brett Cy 介绍会议议程,将讲解 S3 Tables 的高层概念和客户价值
- 随后由 Indeed 的 Venitesh 分享实际应用案例

00:00:30 - S3 Tables 的三大核心价值
- 简化安全管理:允许客户在表级别而非对象级别编写安全策略
- 提升性能:通过自动化压缩减少查询时的 API 调用次数
- 降低维护复杂度:自动处理 Iceberg 表的维护操作

00:01:00 - 安全管理的改进
- 传统方式:需要为数据湖中的每个对象编写安全策略,难以扩展
- S3 Tables 方式:直接针对表资源编写策略,大幅简化管理

00:01:30 - 自动化压缩功能
- 问题背景:数据湖中多个小对象导致查询需要多次 API 调用,增加延迟
- 传统解决方案:客户需自行编写 Spark 作业或管理计算资源进行压缩
- S3 Tables 解决方案:服务自动执行压缩,无需客户管理计算资源

00:02:00 - 自动化表维护
- 问题:数据更新和删除产生未引用文件和快照,浪费存储空间并增加成本
- 解决方案:S3 Tables 自动清理未引用文件,同时保留时间旅行和回滚能力

00:02:30 - Indeed 公司背景介绍
- Venitesh Mandalapa 介绍 Indeed:全球第一大求职网站
- 6.35 亿求职者档案,330 万雇主,覆盖 60 多个国家,11,000 名员工
- 使命:帮助人们找到工作,数据是驱动这一使命的核心引擎

00:03:00 - Indeed 数据湖架构概览
- 使用 AWS Glue Data Catalog 作为中央目录
- 数据存储在 S3 标准存储中,混合使用 Hive(ORC 格式)和 Iceberg(Parquet 格式)
- Hive 数据约 68 PB,Iceberg 数据约 20 PB
- 查询引擎包括 Athena、Snowflake 和 Spark

00:03:30 - Indeed 数据湖规模统计
- 总数据量:87 PB
- 每日摄入量:550 TB
- 表数量:15,000+ 张(分布在不同 schema 中)
- 6 种数据摄入模式
- 每日查询量:170,000+ 次
- 数据类型:分析型、机器学习、运营数据
- 数据模式:流式、批处理、ETL

00:04:30 - 迁移目标与决策
- 初始目标:将所有数据迁移到 Iceberg 格式,使用 S3 标准存储
- 评估 S3 Tables 后的决策:经过成本收益分析,决定将 100% 数据湖迁移到 S3 Tables
- 额外收益:6 种摄入模式可简化为 1 种,大幅简化代码库

00:05:00 - 使用标准 S3 存储的 Iceberg 面临的挑战
- 维护负担:每年需要 200+ 开发小时管理 Iceberg 表的压缩和删除文件
- 需要在 Kubernetes 上运行自定义 Spark 作业进行维护

00:05:30 - 数据摄入复杂度
- 6 种摄入模式导致客户团队平均需要 1 天时间才能将数据导入数据湖

00:06:00 - S3 速率限制问题
- 不同表的访问模式差异大(有的每季度查询一次,有的每天查询)
- 标准 S3 存储桶的速率限制导致严重事故,影响数据可用性

00:06:30 - 对象标签管理挑战
- 使用对象级标签进行访问控制
- 6 亿个对象,每个都有标签
- 更改对象标签或评估安全性非常困难

00:07:00 - S3 Tables 带来的收益
- 简化数据治理:从管理 6 亿个对象标签变为管理表级资源策略
- 示例:将表访问权限从全公司改为仅 Glassdoor(姊妹公司),从需要数周变为一次操作

00:07:30 - 成本节省
- 综合评估存储、维护、压缩和摄入成本
- 相比标准 S3 存储桶的 Iceberg 表,每年节省约 10% 的 AWS 成本
- 维护操作成本大幅降低,使方案更具吸引力

00:08:00 - 摄入体验改进
- 过去:需要 1 天时间完成数据摄入
- 现在:通过 API 调用在几分钟内完成数据摄入
- 生产团队可以快速、灵活且经济高效地开始摄入数据

00:08:30 - 开发资源释放
- 节省 4 个开发月的维护工作
- 团队可以专注于产品开发和为客户构建功能

00:09:00 - 迁移策略:分阶段方法
- 87 PB 数据无法采用"大爆炸"式迁移
- 分析服务器访问日志和查询日志
- 将工作负载分类为不同的群组(cohorts)、批次(batches)和阶段(phases)

00:09:30 - 双写管道策略
- 采用增量迁移方式
- 保持现有生产管道写入标准 S3
- 建立独立的管道写入 S3 Tables
- 标准的迁移方法

00:10:00 - 自动化工具开发
- 开发工具和 API 自动化数据摄入到 S3 Tables
- 简化迁移过程,减少一个步骤

00:10:30 - 迁移阶段规划
- 阶段 1:将所有 Hive 数据迁移到 S3 Tables
- 阶段 2:将 Iceberg S3 标准数据迁移到 S3 Tables
- 阶段 3:数据生产者更新
- 每个阶段内按工作负载(Spark、Trino、Athena)分组
- 进一步细分为 TB 或 PB 级别的批次

00:11:30 - 双写管道详细流程
- 当前架构:生产者 → 摄入管道(6 种模式)→ S3 标准存储 → AWS Glue Catalog
- 双写阶段:分叉管道,同时写入标准 S3 和 S3 Tables(有独立 catalog)
- 切换阶段:将 S3 Tables catalog 链接到默认 Glue catalog
- 清理阶段:删除旧的 S3 标准数据和对应的写入管道

00:12:30 - 对消费者的透明性
- 消费者始终访问默认 Glue catalog
- 后端存储变更对消费者完全透明
- 查询和应用程序无需任何修改

00:13:00 - 迁移过程中的经验教训
- Lake Formation 集成:S3 Tables 与 Lake Formation 紧密集成
- Indeed 不使用 Lake Formation,需要理解身份权限和资源策略的交互
- 需要 AWS 团队的大量帮助才能解决

00:13:30 - 查询性能差异
- Hive 使用 ORC 格式,Iceberg 有不同的查询规划机制
- 必须针对 S3 Tables 测试所有工作负载,确保性能相当或更好

00:14:00 - 分区策略变更
- 迁移过程中调整分区策略
- 确保 Hive 的旧分区方式在 Iceberg 中仍然有效且更快

00:14:30 - S3 Tables 限制
- 每个区域每个账户:10,000 个表存储桶
- 每个存储桶:10,000 张表
- 总计:100,000 个资产
- Indeed 当前有 15,000 张表,线性增长可能达到 20,000-25,000
- 需要尽可能减少存储桶数量以便于管理

00:15:00 - 备份恢复挑战
- S3 Tables 的备份恢复功能有限
- 需要自行开发备份恢复策略
- 依赖未引用文件功能和相关策略

00:15:30 - 并发写入限制
- Iceberg 的固有问题:并发写入者越多,越容易出问题
- 需要控制每张表的写入者数量

00:16:00 - 服务器访问日志差异
- S3 标准存储桶:提供详细的服务器访问日志(显示 AWS 角色、区域等)
- S3 Tables:使用 CloudWatch 和 CloudTrail 记录日志
- 需要更新日志处理管道以适应新的日志格式

00:16:30 - Snowflake 集成
- Indeed 广泛使用 Snowflake
- S3 Tables 提供两种 REST catalog:Glue REST catalog 和 Iceberg REST catalog
- 可以在 Snowflake 中注册这些 catalog,暴露所有 S3 Tables 数据
- 对 Snowflake 用户来说是重大利好

00:17:00 - 迁移进展总结
- 计划迁移 50 PB 数据到 S3 Tables
- 当前正在进行金丝雀测试:2.5 PB(感恩节和 12 月第一周进行中)
- 随时准备回滚双写管道,确保零影响
- 消费者、查询和生产者均不受影响

00:17:30 - 双写管道的成本权衡
- 双写管道会增加成本,但这是可接受的
- 更重要的是保护消费者不受影响
- 数据被全球用户使用,包括政策制定者和媒体

00:18:00 - 总结与展望
- Indeed 正朝着统一、现代化、成本高效的数据湖目标前进
- 对 S3 Tables 满足所有需求表示满意
- 会议结束