1
00:00:00,609 --> 00:00:01,758
Good morning and welcome.

2
00:00:02,039 --> 00:00:04,049
My name is Mike Neville O'Neill and I'm the head of

3
00:00:04,049 --> 00:00:06,150
product at Bronto, and today I'll be joined by

4
00:00:06,150 --> 00:00:07,328
AO Mahoney,

5
00:00:07,679 --> 00:00:10,470
uh, engineering manager from Teamwork.com.

6
00:00:10,810 --> 00:00:12,929
Benoit is currently occupied with booth duty,

7
00:00:12,989 --> 00:00:15,329
so you can check him out over at 1757.

8
00:00:15,689 --> 00:00:17,839
And today we're going to be talking about logs

9
00:00:17,839 --> 00:00:19,548
at scale without compromise.

10
00:00:21,908 --> 00:00:24,179
So picture this, it's 3 a.m.,

11
00:00:24,250 --> 00:00:26,298
something's on fire, and you need to figure out which

12
00:00:26,298 --> 00:00:28,469
of the seven logging systems your company uses

13
00:00:28,469 --> 00:00:29,658
the data resides in.

14
00:00:29,989 --> 00:00:32,548
Is it in Cloudwatch? Is it in Elastic

15
00:00:32,548 --> 00:00:34,590
or Greylog, or is it in the S3

16
00:00:34,590 --> 00:00:36,959
bucket with all the Athena queries that nobody

17
00:00:36,959 --> 00:00:38,389
remembers how to run?

18
00:00:38,750 --> 00:00:40,829
Uh, if any of this sounds familiar to you,

19
00:00:40,908 --> 00:00:42,810
you're not alone, and it's a symptom

20
00:00:43,139 --> 00:00:45,189
of what we call the 3C flywheel of

21
00:00:45,189 --> 00:00:47,048
compromises, and it starts with cost.

22
00:00:47,700 --> 00:00:50,509
Uh, legacy logging solutions are prohibitively

23
00:00:50,509 --> 00:00:51,539
expensive at scale.

24
00:00:51,829 --> 00:00:53,908
Whether you're running a data dog or a new relic or

25
00:00:53,908 --> 00:00:55,978
you're running something on-prem like a gray log

26
00:00:55,978 --> 00:00:56,899
or elastic,

27
00:00:57,189 --> 00:00:58,700
as soon as you hit scale,

28
00:00:58,990 --> 00:01:01,450
cost becomes the major constraint

29
00:01:01,590 --> 00:01:03,668
for every subsequent decision that you're able

30
00:01:03,668 --> 00:01:04,189
to make.

31
00:01:04,709 --> 00:01:06,870
Uh, the first thing that you're likely to do is to start

32
00:01:06,870 --> 00:01:08,989
cutting retention of your data sources from

33
00:01:08,989 --> 00:01:11,088
30 days to 7 days,

34
00:01:11,349 --> 00:01:12,969
uh, maybe then to 3 days,

35
00:01:13,230 --> 00:01:15,349
and once you've shortened retention as much as you can,

36
00:01:15,430 --> 00:01:17,019
you start cutting data sources,

37
00:01:17,349 --> 00:01:18,150
CDN data,

38
00:01:18,430 --> 00:01:20,510
debug logs, anything that's remotely

39
00:01:20,510 --> 00:01:21,689
considered noisy ends up

40
00:01:22,019 --> 00:01:23,319
on the cutting room floor.

41
00:01:24,469 --> 00:01:26,469
This invariably leads to coverage

42
00:01:26,469 --> 00:01:28,629
gaps across your infrastructure, uh,

43
00:01:28,709 --> 00:01:30,808
where it's essentially like trying to understand

44
00:01:30,808 --> 00:01:32,909
a novel with several chapters torn out

45
00:01:32,909 --> 00:01:35,239
of it. Um, teams notice

46
00:01:35,239 --> 00:01:37,379
these coverage gaps and visibility is

47
00:01:37,379 --> 00:01:38,939
still required into this data.

48
00:01:39,260 --> 00:01:41,299
Just because it doesn't fit into your budget doesn't

49
00:01:41,299 --> 00:01:43,338
make it any less business critical and

50
00:01:43,338 --> 00:01:45,959
so teams invariably will spin up workarounds,

51
00:01:46,180 --> 00:01:48,260
uh, in order to get visibility into this data

52
00:01:48,260 --> 00:01:50,338
which leads to a proliferation of tools in

53
00:01:50,338 --> 00:01:51,299
your environments,

54
00:01:51,579 --> 00:01:53,605
uh, and increases. Cost not

55
00:01:53,605 --> 00:01:55,674
just in terms of the cost of total

56
00:01:55,674 --> 00:01:57,584
cost of ownership of the products,

57
00:01:57,924 --> 00:02:00,204
um, but the cost of the friction as engineers

58
00:02:00,204 --> 00:02:02,403
are trying to move across different tools with different

59
00:02:02,403 --> 00:02:04,784
query languages, different retention policies,

60
00:02:05,084 --> 00:02:07,284
uh, different access controls to stitch

61
00:02:07,284 --> 00:02:09,524
together a cohesive picture of what actually

62
00:02:09,524 --> 00:02:10,985
occurred in their environment.

63
00:02:12,389 --> 00:02:14,588
This is the exact cycle that Bronto was

64
00:02:14,588 --> 00:02:15,389
built to break.

65
00:02:17,439 --> 00:02:18,939
So, what is Bronto?

66
00:02:19,319 --> 00:02:21,439
Bronto is a logs first observability

67
00:02:21,439 --> 00:02:23,538
platform where you can retain all of your data

68
00:02:23,538 --> 00:02:25,860
for 12 months hot by default.

69
00:02:26,240 --> 00:02:28,479
Um, we've been tested at petabyte scale

70
00:02:28,479 --> 00:02:30,580
and although most of our customers are operating

71
00:02:30,580 --> 00:02:32,758
in the multi-terabyte range, we're more

72
00:02:32,758 --> 00:02:35,169
than ready for what's coming down the pike.

73
00:02:35,719 --> 00:02:37,960
Um, we, the entry point is cents, not

74
00:02:37,960 --> 00:02:40,659
dollars per gigabyte, and it's our efficient architecture

75
00:02:41,000 --> 00:02:43,179
that enables this cost efficiency that I'll be talking

76
00:02:43,179 --> 00:02:44,778
about a little bit down the line.

77
00:02:45,338 --> 00:02:47,580
Um, we have exceptionally transparent usage and

78
00:02:47,580 --> 00:02:49,639
billing. One of the biggest problems when

79
00:02:49,639 --> 00:02:51,939
a bill is spiked in a logging platform

80
00:02:51,939 --> 00:02:54,139
or an observability tool is understanding why

81
00:02:54,139 --> 00:02:55,258
that spike occurred.

82
00:02:55,580 --> 00:02:57,399
With Bronto, you always know why.

83
00:02:57,860 --> 00:02:59,979
We can integrate with any agent. We do not

84
00:02:59,979 --> 00:03:02,139
have a proprietary agent of our own,

85
00:03:02,258 --> 00:03:04,379
so any telemetry agent you care to name

86
00:03:04,379 --> 00:03:06,699
can be used to send data to Bronto,

87
00:03:06,778 --> 00:03:08,778
whether that's a proprietary agent like a

88
00:03:08,778 --> 00:03:10,979
new relic or a data dog, or it's an open

89
00:03:10,979 --> 00:03:13,189
source collector like Otel or Fluent Bit.

90
00:03:13,500 --> 00:03:15,538
Uh, if it speaks HTTP you can send logs

91
00:03:15,538 --> 00:03:17,729
up to Bronto. You can even curl up parallel

92
00:03:17,729 --> 00:03:19,758
world in your terminal if you so desire.

93
00:03:20,770 --> 00:03:21,349
Um,

94
00:03:21,729 --> 00:03:23,929
in terms of AI powered log management, the

95
00:03:23,929 --> 00:03:26,088
AI features we have are available in shipping

96
00:03:26,088 --> 00:03:28,349
and production today. This is not roadmap

97
00:03:28,349 --> 00:03:30,439
theater. Everything that we're going to be seeing in the

98
00:03:30,439 --> 00:03:32,610
presentation and the slides is on

99
00:03:32,610 --> 00:03:34,110
product and ready for you to use.

100
00:03:34,939 --> 00:03:37,270
Lastly, we're able to deliver subsecond

101
00:03:37,270 --> 00:03:39,300
search against multi-terabyte sized

102
00:03:39,300 --> 00:03:40,118
data sets

103
00:03:40,379 --> 00:03:42,500
and our, our efficient search architecture

104
00:03:42,500 --> 00:03:44,599
enables that capability, which I'll be talking

105
00:03:44,599 --> 00:03:46,360
about in more detail in just a bit.

106
00:03:51,538 --> 00:03:54,020
Here you can see a couple of aspects of our interface

107
00:03:54,020 --> 00:03:56,020
on the left side of the

108
00:03:56,020 --> 00:03:58,020
screen you'll see our dashboard which is providing

109
00:03:58,020 --> 00:03:58,800
some visibility

110
00:03:59,139 --> 00:04:01,258
into CDN data where we can see

111
00:04:01,258 --> 00:04:02,618
cache hits by Pop,

112
00:04:02,939 --> 00:04:04,939
uh, requests by geocountry, the sorts

113
00:04:04,939 --> 00:04:07,254
of operational visibility that you would. Expect

114
00:04:07,254 --> 00:04:08,413
from a tool like this

115
00:04:08,814 --> 00:04:10,835
on the right we see the usage explorer

116
00:04:10,974 --> 00:04:13,254
and this is what I was talking about earlier with transparent

117
00:04:13,254 --> 00:04:15,294
billing and ensuring that you're no

118
00:04:15,294 --> 00:04:17,295
surprises in terms of uh the

119
00:04:17,295 --> 00:04:18,975
drivers of cost in your account.

120
00:04:19,254 --> 00:04:21,363
So the usage Explorer is primarily designed

121
00:04:21,363 --> 00:04:22,375
to help you answer

122
00:04:23,014 --> 00:04:25,095
three questions. Number 1, how much

123
00:04:25,095 --> 00:04:26,334
data am I ingesting?

124
00:04:26,613 --> 00:04:27,403
Number 2,

125
00:04:27,694 --> 00:04:29,694
what teams are ingesting that data? And number

126
00:04:29,694 --> 00:04:31,795
3, is anybody actually using

127
00:04:31,795 --> 00:04:33,173
the data that we ingest?

128
00:04:33,569 --> 00:04:35,738
Uh, we give you visibility granularly

129
00:04:35,738 --> 00:04:37,858
into search and ingestion metrics so you can figure

130
00:04:37,858 --> 00:04:39,980
out, am I actually using the things that I'm

131
00:04:39,980 --> 00:04:40,959
sending to Bronto

132
00:04:41,220 --> 00:04:43,269
and make more informed decisions about the data

133
00:04:43,269 --> 00:04:44,920
that you're choosing to keep in the platform.

134
00:04:48,369 --> 00:04:50,649
Next, let's talk about features and capabilities.

135
00:04:50,730 --> 00:04:52,889
Uh, here at Bronto we are obsessed

136
00:04:52,889 --> 00:04:55,048
with reducing MTTR and removing

137
00:04:55,048 --> 00:04:57,230
toil. Uh, we think that there are a number

138
00:04:57,230 --> 00:04:59,608
of problems that LLMs can be applied

139
00:04:59,608 --> 00:05:01,649
to, uh, to reduce the amount of work that

140
00:05:01,649 --> 00:05:04,250
you have to do to make your data and your observability

141
00:05:04,250 --> 00:05:06,519
tool of value, uh, starting

142
00:05:06,519 --> 00:05:08,608
with AI dashboard creation where one of the

143
00:05:08,608 --> 00:05:10,629
biggest pain points of. Using or

144
00:05:10,629 --> 00:05:12,850
migrating to any new observability platform

145
00:05:13,189 --> 00:05:15,269
is creating new dashboards, creating new widgets,

146
00:05:15,629 --> 00:05:17,629
understanding the query language and how the platform

147
00:05:17,629 --> 00:05:18,149
works.

148
00:05:18,500 --> 00:05:20,588
Uh, we have a natural language dashboard

149
00:05:20,588 --> 00:05:22,670
creation feature that gives you the ability

150
00:05:22,670 --> 00:05:24,709
to, uh, specify a prompt

151
00:05:24,709 --> 00:05:26,778
to get what you need. So it's really just as simple as

152
00:05:26,778 --> 00:05:27,428
typing in,

153
00:05:27,750 --> 00:05:29,790
show me all of my 500 errors across all

154
00:05:29,790 --> 00:05:31,829
of my services and you're off to the races.

155
00:05:32,759 --> 00:05:35,009
Speaking of reducing toil, we've also implemented

156
00:05:35,009 --> 00:05:36,470
AI generated parsers.

157
00:05:36,850 --> 00:05:39,048
Uh, we're able to automatically identify the

158
00:05:39,048 --> 00:05:41,088
format of your data, create a parser for

159
00:05:41,088 --> 00:05:42,209
it, and then apply it.

160
00:05:42,569 --> 00:05:44,569
So there's really no more need for you

161
00:05:44,569 --> 00:05:47,048
to be writing regular expressions or grok patterns,

162
00:05:47,088 --> 00:05:49,129
uh, unless it's something that you want to

163
00:05:49,129 --> 00:05:51,209
do. With pronto, it's no longer something that you

164
00:05:51,209 --> 00:05:51,869
have to do.

165
00:05:53,338 --> 00:05:53,970
AI

166
00:05:54,439 --> 00:05:56,569
investigations are where we're bringing LLMs to bear along

167
00:05:56,569 --> 00:05:59,009
with our context engineering and domain knowledge

168
00:05:59,009 --> 00:06:01,540
to shorten the time that it takes to investigate

169
00:06:01,730 --> 00:06:03,769
uh errors in your log data. Uh, we

170
00:06:03,769 --> 00:06:06,088
go a lot further beyond than just explaining

171
00:06:06,088 --> 00:06:08,088
what a particular error is. We

172
00:06:08,088 --> 00:06:10,220
go towards understanding what. The source format

173
00:06:10,220 --> 00:06:12,220
of that is what the key fields are, for

174
00:06:12,220 --> 00:06:13,970
example, if we see a 500 error,

175
00:06:14,259 --> 00:06:16,540
then the key fields might be something like client IP

176
00:06:16,540 --> 00:06:17,338
endpoint,

177
00:06:17,619 --> 00:06:20,059
uh, customer ID, and more. We'll automatically

178
00:06:20,059 --> 00:06:22,139
launch queries across your data set in order

179
00:06:22,139 --> 00:06:24,298
to build a coherent timeline of

180
00:06:24,298 --> 00:06:25,278
what occurred.

181
00:06:25,750 --> 00:06:28,028
Uh, suggest an RCA and also generate

182
00:06:28,028 --> 00:06:30,670
additional queries for you to run to continue your

183
00:06:30,670 --> 00:06:32,709
investigation to understand what the blast radius

184
00:06:32,709 --> 00:06:33,410
is. So

185
00:06:33,790 --> 00:06:36,269
with the error, uh, with the brontoscope

186
00:06:36,269 --> 00:06:38,428
or the error explanation feature, you can

187
00:06:38,428 --> 00:06:40,588
cut down your investigation time from 15

188
00:06:40,588 --> 00:06:42,470
to 30 minutes to 15 seconds.

189
00:06:43,569 --> 00:06:45,769
Statement IDs is something that is brand new

190
00:06:45,769 --> 00:06:47,769
and is unique to Bronto, and it is

191
00:06:47,769 --> 00:06:49,928
a technology that allows us to associate

192
00:06:49,928 --> 00:06:52,088
a unique fingerprint, uh, with every log

193
00:06:52,088 --> 00:06:53,428
message that you send to the platform.

194
00:06:53,850 --> 00:06:55,809
This allows us to do a couple of different things.

195
00:06:56,139 --> 00:06:58,170
One of the things that we can do is give you the ability to go

196
00:06:58,170 --> 00:07:00,250
directly from a log line to

197
00:07:00,250 --> 00:07:02,178
the code that generated it in GitHub.

198
00:07:02,769 --> 00:07:04,809
Uh, this is incredibly powerful from going

199
00:07:04,809 --> 00:07:06,809
from a monitor notification directly

200
00:07:06,809 --> 00:07:08,970
to your code so that you can go straight from

201
00:07:08,970 --> 00:07:10,250
finding to fixing.

202
00:07:10,798 --> 00:07:12,798
The other piece where this becomes interesting is

203
00:07:12,798 --> 00:07:15,170
if you're familiar with something called log patterns,

204
00:07:15,439 --> 00:07:17,798
uh, where with statement IDs we can understand

205
00:07:17,798 --> 00:07:20,329
which of those messages occur with the most frequency

206
00:07:20,329 --> 00:07:22,439
and perhaps more interestingly which happened

207
00:07:22,439 --> 00:07:24,920
with the least frequency. Where are my outliers?

208
00:07:25,040 --> 00:07:27,178
Where are the new messages that I've never seen before?

209
00:07:27,639 --> 00:07:30,028
Uh, why are messages changing in a sequence

210
00:07:30,028 --> 00:07:32,278
or transaction, uh, where it's almost always

211
00:07:32,278 --> 00:07:34,278
the same type of logs? All these

212
00:07:34,278 --> 00:07:36,350
types of outliers can be, uh, identified

213
00:07:36,350 --> 00:07:38,079
rapidly using statement ID.

214
00:07:39,369 --> 00:07:41,790
This quarter we've also released distributed tracing,

215
00:07:42,040 --> 00:07:44,329
uh, particularly around cross-service

216
00:07:44,329 --> 00:07:46,488
correlation. Um, although we are logs

217
00:07:46,488 --> 00:07:48,488
first, we are not logs only, we're not

218
00:07:48,488 --> 00:07:50,540
zealots, and we believe that there is a place

219
00:07:50,540 --> 00:07:52,769
for telemetry signals to live, uh, in our

220
00:07:52,769 --> 00:07:53,509
platform

221
00:07:53,809 --> 00:07:55,889
to kind of assist in getting to the log

222
00:07:55,889 --> 00:07:57,230
data. Traces are exceptional

223
00:07:57,528 --> 00:07:59,689
for understanding where something has broken,

224
00:07:59,928 --> 00:08:01,928
and with the log data automatically correlated,

225
00:08:01,970 --> 00:08:04,088
you can very easily understand why.

226
00:08:04,778 --> 00:08:06,939
Um, this is a smaller thing, uh, but maybe

227
00:08:06,939 --> 00:08:09,059
less small if you're trying to understand

228
00:08:09,059 --> 00:08:11,100
a monitor definition at 3 a.m. with

229
00:08:11,100 --> 00:08:13,420
bleary eyes, which is that we'll use AI

230
00:08:13,420 --> 00:08:14,939
to automatically name,

231
00:08:15,259 --> 00:08:17,358
uh, things like alerts, parsers,

232
00:08:17,420 --> 00:08:18,699
dashboards, etc.

233
00:08:18,980 --> 00:08:21,139
so that you're not required to come up with those convention

234
00:08:21,139 --> 00:08:24,678
yourself. Next,

235
00:08:24,759 --> 00:08:27,220
let's talk a little bit about how we built Bronto.

236
00:08:27,519 --> 00:08:30,000
Uh, the first thing that's worth noting is that we built Bronto

237
00:08:30,000 --> 00:08:31,838
entirely on AWS

238
00:08:32,158 --> 00:08:34,320
and that our architecture decouples storage

239
00:08:34,320 --> 00:08:36,359
for compute, which is really the key to

240
00:08:36,359 --> 00:08:37,700
our cost efficiency.

241
00:08:37,969 --> 00:08:40,538
Uh, I'll kind of take you through the diagram starting with ingest,

242
00:08:40,658 --> 00:08:42,739
and we can see that data comes in over

243
00:08:42,739 --> 00:08:45,000
HTTP via any of the agents

244
00:08:45,000 --> 00:08:46,879
that you care to name that I discussed earlier,

245
00:08:47,340 --> 00:08:49,418
uh, before streaming the EC2 instances

246
00:08:49,418 --> 00:08:51,609
behind load balancers. From there we

247
00:08:51,609 --> 00:08:53,639
stream the data to MSK where it's written

248
00:08:53,639 --> 00:08:55,779
to S3 in a proprietary format.

249
00:08:55,859 --> 00:08:57,879
I'll discuss in more detail in just a bit.

250
00:08:58,379 --> 00:09:00,649
In terms of the web UI, uh,

251
00:09:00,700 --> 00:09:02,759
and API, we're using a combination

252
00:09:02,759 --> 00:09:04,038
of EC2

253
00:09:04,298 --> 00:09:06,379
and Cloudfront to make those things available

254
00:09:06,379 --> 00:09:07,440
to our customers.

255
00:09:07,859 --> 00:09:09,859
Um, in terms of storage, we're obviously

256
00:09:09,859 --> 00:09:12,058
using S3, but the way in which we're

257
00:09:12,058 --> 00:09:14,500
using it is where we really start to diverge

258
00:09:14,500 --> 00:09:16,759
from the other solutions that you see in the space.

259
00:09:17,408 --> 00:09:20,019
Um, we actually write to S3 in a proprietary

260
00:09:20,019 --> 00:09:22,219
format that's been optimized specifically

261
00:09:22,219 --> 00:09:23,320
for log data,

262
00:09:23,658 --> 00:09:25,700
uh, and this format makes use of all

263
00:09:25,700 --> 00:09:28,340
of the techniques that you would expect from a modern analytics

264
00:09:28,340 --> 00:09:30,349
engine, aggressive compression, columnar

265
00:09:30,349 --> 00:09:32,418
storage, bloom filters, data

266
00:09:32,418 --> 00:09:34,580
partitions, all built from the ground up

267
00:09:34,580 --> 00:09:37,139
to return your logs to you as fast as they possibly

268
00:09:37,139 --> 00:09:37,658
can be.

269
00:09:38,200 --> 00:09:38,820
Um,

270
00:09:39,279 --> 00:09:41,320
it's kind of this emphasis on, on,

271
00:09:41,389 --> 00:09:43,440
uh, the proprietary format that

272
00:09:43,440 --> 00:09:45,710
allows us to deliver speed in a way that, uh,

273
00:09:45,719 --> 00:09:47,019
other tools cannot,

274
00:09:47,399 --> 00:09:49,629
but storage isn't quite where it stops.

275
00:09:49,759 --> 00:09:51,840
Uh, we, when we're talking about search, we have

276
00:09:51,840 --> 00:09:53,879
to mention lambda as well, which in

277
00:09:53,879 --> 00:09:55,960
many ways is the backbone of our query

278
00:09:55,960 --> 00:09:58,158
experience in the sense that it allows us to

279
00:09:58,158 --> 00:10:00,190
deliver incredible power but also

280
00:10:00,190 --> 00:10:02,519
maintain exceptional cost efficiency by

281
00:10:02,519 --> 00:10:03,678
avoiding overprovisioning.

282
00:10:04,009 --> 00:10:06,038
So for example, when you run a query that needs

283
00:10:06,038 --> 00:10:08,129
to scan a very large volume of data,

284
00:10:08,479 --> 00:10:10,590
we have the ability to spin up lambdas in

285
00:10:10,590 --> 00:10:12,099
parallel to process it.

286
00:10:12,519 --> 00:10:14,519
Um, on the other hand, we are only

287
00:10:14,519 --> 00:10:17,178
paying to use that compute when it is actually,

288
00:10:17,239 --> 00:10:19,580
uh, being used or when the lambda is

289
00:10:19,590 --> 00:10:20,609
actually active,

290
00:10:20,879 --> 00:10:22,940
uh, and that gives us the ability to, uh,

291
00:10:22,950 --> 00:10:24,859
be exceptionally cost efficient as well.

292
00:10:25,279 --> 00:10:27,599
So. Essentially if you're running a query with

293
00:10:27,599 --> 00:10:29,619
a large volume of data, we can

294
00:10:29,619 --> 00:10:31,918
spin up hundreds of lambdas if needed

295
00:10:31,918 --> 00:10:34,019
to query S3 concurrently

296
00:10:34,239 --> 00:10:36,340
and get you those results as fast as we can

297
00:10:36,599 --> 00:10:38,639
and because we're only paying for the compute that

298
00:10:38,639 --> 00:10:41,109
we're using, uh, we can run a cost efficient

299
00:10:41,109 --> 00:10:43,239
platform and maintain that cost advantage

300
00:10:43,239 --> 00:10:44,320
and pass it on to you.

301
00:10:46,168 --> 00:10:48,308
Uh, in terms of security,

302
00:10:48,408 --> 00:10:51,210
uh, we're using Cognito for A verified

303
00:10:51,210 --> 00:10:52,200
permissions for our back,

304
00:10:53,048 --> 00:10:55,330
uh, and on the vulnerability management side of things

305
00:10:55,330 --> 00:10:57,408
we're using inspector, uh,

306
00:10:57,529 --> 00:10:59,849
as well as AWS guard duty,

307
00:11:00,239 --> 00:11:02,298
um, in terms of kind of the, the cost model

308
00:11:02,298 --> 00:11:04,950
that we've come up with, it's going to be a bit challenging

309
00:11:04,950 --> 00:11:07,570
we think for other tools in this space to replicate

310
00:11:07,570 --> 00:11:09,690
that, um, because the cost models

311
00:11:09,690 --> 00:11:12,090
kind of inherently assume an expensive indexing

312
00:11:12,090 --> 00:11:14,090
cost for every gigabyte that you send to them.

313
00:11:14,440 --> 00:11:16,798
And we're built fundamentally differently, um,

314
00:11:16,808 --> 00:11:19,149
to assume that the, the price for that should be,

315
00:11:19,168 --> 00:11:20,830
uh, cents rather than dollars.

316
00:11:23,168 --> 00:11:25,210
So what does this ultimately unlock?

317
00:11:25,408 --> 00:11:27,719
Uh, what does it do for our customers?

318
00:11:27,928 --> 00:11:29,969
I want to draw your attention to the lines that you see on

319
00:11:29,969 --> 00:11:32,090
the graph here where the X axis represents

320
00:11:32,090 --> 00:11:34,590
the size of the data set being queried in gigabytes

321
00:11:34,808 --> 00:11:37,070
and the Y axis represents the duration

322
00:11:37,070 --> 00:11:39,330
of the query in milliseconds and just

323
00:11:39,330 --> 00:11:41,340
check out all of these lines. It really does. It doesn't matter what

324
00:11:41,340 --> 00:11:43,379
you're doing, whether you're trying to count log

325
00:11:43,379 --> 00:11:45,619
events, uh, detect a sequel injection

326
00:11:45,619 --> 00:11:47,820
attack, find a rare UUID, that

327
00:11:47,820 --> 00:11:49,759
classic needle in a haystack use case,

328
00:11:50,340 --> 00:11:52,639
or list all the events with slow response times,

329
00:11:52,979 --> 00:11:55,019
ultimately all these queries complete in under

330
00:11:55,019 --> 00:11:57,320
500 milliseconds against a 5 terabyte

331
00:11:57,460 --> 00:11:58,479
size data set.

332
00:11:58,859 --> 00:12:00,899
This is the kind of performance and experience that our

333
00:12:00,899 --> 00:12:02,979
architecture unlocks for you.

334
00:12:03,308 --> 00:12:05,308
Um, but given where we are in the talk, I think

335
00:12:05,308 --> 00:12:06,009
it's probably

336
00:12:06,308 --> 00:12:07,668
better to hear directly from

337
00:12:08,349 --> 00:12:10,369
what the benefits of bringing Bronto to teamwork

338
00:12:10,369 --> 00:12:11,308
have been for him.

339
00:12:11,788 --> 00:12:12,389
Thank you, Mike.

340
00:12:12,840 --> 00:12:15,769
Morning, everybody. So,

341
00:12:15,849 --> 00:12:18,190
uh, my name's E O'Mahony. I'm an engineering manager

342
00:12:18,190 --> 00:12:19,029
at Teamwork.com.

343
00:12:19,330 --> 00:12:21,750
Uh, we're based and then, we're founded

344
00:12:21,808 --> 00:12:23,359
and headquartered in Cork in Ireland,

345
00:12:23,639 --> 00:12:24,908
founded in 2007.

346
00:12:25,330 --> 00:12:27,739
Uh, our founders, uh, Peter and Dan

347
00:12:27,889 --> 00:12:30,009
ran an agency for several years

348
00:12:30,009 --> 00:12:30,808
before that, so

349
00:12:31,168 --> 00:12:33,168
they saw the need in the market for a project

350
00:12:33,168 --> 00:12:34,190
management solution.

351
00:12:34,609 --> 00:12:35,210
Um,

352
00:12:35,570 --> 00:12:37,649
and they built out, uh, the teamwork suite, which

353
00:12:37,649 --> 00:12:40,080
is easy to use project management with streamlined

354
00:12:40,080 --> 00:12:42,509
operations. Uh, we were

355
00:12:42,658 --> 00:12:44,750
very proud of being self-funded for years, but

356
00:12:44,750 --> 00:12:46,879
the last few years we took on a big 70 million

357
00:12:46,879 --> 00:12:47,788
investment to help us,

358
00:12:48,109 --> 00:12:50,109
uh, scale the growth of the product and add really cool

359
00:12:50,109 --> 00:12:51,129
new features into it.

360
00:12:51,710 --> 00:12:53,899
And as of recently, we have over, uh,

361
00:12:53,940 --> 00:12:55,729
20,000 customers worldwide,

362
00:12:56,190 --> 00:12:56,808
and

363
00:12:57,229 --> 00:12:59,548
having that many daily users is, uh,

364
00:12:59,558 --> 00:13:01,599
the reason why we have logging challenges which

365
00:13:01,739 --> 00:13:03,869
Bronto have been very helpful to help us solve.

366
00:13:05,629 --> 00:13:07,700
Uh, so just another quick, uh, rundown what teamwork

367
00:13:07,700 --> 00:13:10,349
is. So we're a project and resource management

368
00:13:10,349 --> 00:13:12,428
product, uh, powered by AI built

369
00:13:12,428 --> 00:13:13,570
for service teams,

370
00:13:13,950 --> 00:13:16,190
or, um, it's to

371
00:13:16,190 --> 00:13:18,379
help teams adopt quickly and get value from their,

372
00:13:18,590 --> 00:13:20,590
uh, the work that they do in their business and make

373
00:13:20,590 --> 00:13:21,690
sure that managers have,

374
00:13:22,349 --> 00:13:22,928
sorry, yeah,

375
00:13:23,538 --> 00:13:25,629
uh, make sure managers have, uh, key insights

376
00:13:25,629 --> 00:13:27,668
into their financial performance. So it's all about getting work

377
00:13:27,668 --> 00:13:29,950
done and getting paid to get the work done and leaving the friction

378
00:13:29,950 --> 00:13:31,048
of the product to one side.

379
00:13:31,700 --> 00:13:33,320
Uh, the, the main areas that we cover,

380
00:13:33,739 --> 00:13:36,029
uh, project management was always the core of, uh,

381
00:13:36,038 --> 00:13:38,219
of the product when launched, but over the years we've also

382
00:13:38,219 --> 00:13:40,710
added in resource management and financial management,

383
00:13:41,099 --> 00:13:43,129
uh, which when put together give real value to

384
00:13:43,129 --> 00:13:43,798
customers.

385
00:13:44,298 --> 00:13:46,418
And then we have some supporting features to the side. We have

386
00:13:46,418 --> 00:13:48,038
reporting, we have integrations,

387
00:13:48,700 --> 00:13:50,779
deep automations. More recently, AI

388
00:13:50,779 --> 00:13:53,048
is a fundamental part, uh, of our product stack,

389
00:13:53,058 --> 00:13:55,460
and we're shortly releasing a, a new gente

390
00:13:55,460 --> 00:13:57,239
feature called Teammates, which will really help,

391
00:13:57,619 --> 00:13:59,639
uh, give customers extra value with the product.

392
00:14:00,190 --> 00:14:02,450
And dashboarding as well then for insights into

393
00:14:02,450 --> 00:14:03,308
their usage.

394
00:14:03,769 --> 00:14:06,038
And then as well we have uh Teamwork

395
00:14:06,038 --> 00:14:08,168
desk, which is our help desk product and

396
00:14:08,168 --> 00:14:10,070
it, it supports client communications,

397
00:14:10,369 --> 00:14:11,330
B2B comms,

398
00:14:11,729 --> 00:14:13,029
uh, spaces, is our

399
00:14:13,599 --> 00:14:16,129
knowledge base and help and, uh, documentation

400
00:14:16,129 --> 00:14:18,168
store. And a recent product we added as well is

401
00:14:18,168 --> 00:14:20,288
Teamwork Connect, which is a way for customers to integrate

402
00:14:20,288 --> 00:14:21,099
their own. Uh,

403
00:14:21,849 --> 00:14:24,048
BI tooling directly into our teamwork data

404
00:14:24,048 --> 00:14:25,259
again to get better insights.

405
00:14:25,649 --> 00:14:26,950
And the overall aim is to give,

406
00:14:27,250 --> 00:14:29,750
uh, insights into increased billable utilization

407
00:14:29,889 --> 00:14:31,269
and improved profitability,

408
00:14:31,729 --> 00:14:33,729
helping customers to get the work done, to

409
00:14:33,729 --> 00:14:35,090
get the team's, uh,

410
00:14:35,529 --> 00:14:37,849
work build, and then to, er, iterate

411
00:14:37,849 --> 00:14:38,428
on that,

412
00:14:38,879 --> 00:14:40,369
er, each month through the rest of the year.

413
00:14:42,369 --> 00:14:44,729
So, uh, our logging challenges before Bronto

414
00:14:44,729 --> 00:14:47,389
came along, uh, we have a conflict infrastructure.

415
00:14:48,700 --> 00:14:50,808
It's a mix of self-hosted open source, uh,

416
00:14:50,849 --> 00:14:53,279
cloud-based and custom solutions,

417
00:14:53,658 --> 00:14:56,048
uh, with a lot of difficult query, structured and unstructured

418
00:14:56,048 --> 00:14:56,678
data,

419
00:14:57,178 --> 00:14:58,918
indexing issues. We

420
00:14:59,340 --> 00:15:01,538
roughly have about 33 terabytes

421
00:15:01,538 --> 00:15:03,739
of logs a day, uh, sorry, a month, uh, being

422
00:15:03,739 --> 00:15:05,820
ingested, billions of logs from different

423
00:15:05,820 --> 00:15:06,639
systems.

424
00:15:07,178 --> 00:15:07,840
Um,

425
00:15:08,379 --> 00:15:10,500
that require, that causes over operational

426
00:15:10,500 --> 00:15:11,139
overheads.

427
00:15:11,629 --> 00:15:13,678
Uh, we operate in 3 AWS

428
00:15:13,678 --> 00:15:15,678
regions, so we're a big AWS customer,

429
00:15:16,000 --> 00:15:18,038
uh, 2 production regions in the US

430
00:15:18,038 --> 00:15:21,070
and the EU region, and then, uh, replicated,

431
00:15:21,239 --> 00:15:23,298
um, staging set up,

432
00:15:23,320 --> 00:15:24,479
uh, for testing.

433
00:15:25,200 --> 00:15:27,558
Uh, so that requires a lot of ongoing maintenance

434
00:15:27,558 --> 00:15:29,558
when you have a lot of self-hosted systems. So

435
00:15:29,558 --> 00:15:31,678
things like Greylog, having to replicate Greylog

436
00:15:31,678 --> 00:15:33,989
configurations into all these different accounts is,

437
00:15:34,080 --> 00:15:34,700
is

438
00:15:35,279 --> 00:15:36,259
time consuming.

439
00:15:36,798 --> 00:15:38,538
Uh, we had limited coverage.

440
00:15:39,479 --> 00:15:40,058
So,

441
00:15:40,359 --> 00:15:42,558
uh, the two main systems we were using were

442
00:15:42,558 --> 00:15:44,558
for our customer traffic

443
00:15:44,558 --> 00:15:45,418
that was coming in,

444
00:15:45,719 --> 00:15:47,879
traffic logs. We were using uh

445
00:15:47,879 --> 00:15:48,538
CloudWatch,

446
00:15:49,190 --> 00:15:51,399
but we had retention rules and Cloudwatch which only retained

447
00:15:51,399 --> 00:15:53,590
about 2 weeks' worth of data for cost reasons,

448
00:15:53,759 --> 00:15:56,109
which is a challenge and because you just don't have a long-term

449
00:15:56,109 --> 00:15:58,239
view. On the developer's side, everything was

450
00:15:58,239 --> 00:16:00,418
going into a giant grey log store which was

451
00:16:00,418 --> 00:16:01,719
backed up by open search.

452
00:16:02,119 --> 00:16:04,239
Again, because of costs, you have to set a limit

453
00:16:04,239 --> 00:16:06,519
on your open search node sizes,

454
00:16:06,599 --> 00:16:08,599
which effectively turns it into a first in, first out

455
00:16:08,599 --> 00:16:09,369
log store.

456
00:16:09,918 --> 00:16:11,538
Very noisy teams would end up

457
00:16:12,259 --> 00:16:14,359
er expiring logs, so you could never really

458
00:16:14,359 --> 00:16:16,418
rely on having a long-term view of your logs.

459
00:16:17,029 --> 00:16:17,619
Um,

460
00:16:18,119 --> 00:16:20,418
and you just had no real insight into which team was using

461
00:16:20,759 --> 00:16:21,639
the log allocation.

462
00:16:22,658 --> 00:16:24,808
Cost inefficiency then, operating all this stuff was

463
00:16:24,808 --> 00:16:26,859
very expensive, even though it was very, it wasn't

464
00:16:26,859 --> 00:16:28,889
very heavily customer facing, so it wasn't giving

465
00:16:28,889 --> 00:16:30,899
sort of direct value to customers, but it was costing

466
00:16:30,899 --> 00:16:32,899
a lot of money to run it. So it was good for operating

467
00:16:32,899 --> 00:16:34,940
the business but not for customer er

468
00:16:34,940 --> 00:16:35,558
features.

469
00:16:36,099 --> 00:16:38,178
And it was inefficient and it, it was just brittle.

470
00:16:39,038 --> 00:16:40,250
So that's where Bronto came along.

471
00:16:41,109 --> 00:16:43,288
So, what we have now with Bronto, simplicity,

472
00:16:43,830 --> 00:16:45,950
um, the unified logging solution has

473
00:16:45,950 --> 00:16:47,989
replaced a ton of legacy tools like Grey log

474
00:16:47,989 --> 00:16:50,460
and the cloudwatch logs, custom solutions.

475
00:16:50,710 --> 00:16:51,769
We've no index management.

476
00:16:52,629 --> 00:16:54,710
We don't have breaking open search indexes

477
00:16:54,710 --> 00:16:56,869
anymore. Uh, we have a much longer

478
00:16:56,869 --> 00:16:59,269
retention, so standard 90 day retention, 12

479
00:16:59,269 --> 00:17:01,389
month retention for our customer traffic logs, so we get

480
00:17:01,389 --> 00:17:02,808
really good detail of our,

481
00:17:03,070 --> 00:17:04,608
uh, long-term customer behavior.

482
00:17:05,398 --> 00:17:07,489
Uh, we've been able to save

483
00:17:07,489 --> 00:17:10,009
42% just in software costs

484
00:17:10,009 --> 00:17:11,749
by switching to Bronto. So that doesn't include

485
00:17:12,327 --> 00:17:14,528
the maintenance effort, but, uh, freeing up our sys

486
00:17:14,528 --> 00:17:16,368
ops engineers who have to maintain these,

487
00:17:16,688 --> 00:17:18,028
these custom solutions.

488
00:17:18,608 --> 00:17:20,549
Um. And

489
00:17:20,930 --> 00:17:22,390
when we were doing comparisons

490
00:17:22,729 --> 00:17:24,949
of Bronto to other SAS solutions,

491
00:17:25,689 --> 00:17:27,949
some of the other providers, their ingest cost alone

492
00:17:28,250 --> 00:17:29,430
was gonna cost more than

493
00:17:29,729 --> 00:17:31,989
the entire operational cost of Bronto for the year.

494
00:17:32,410 --> 00:17:34,529
So they're, they're, from a price point, it was very,

495
00:17:34,689 --> 00:17:37,029
uh, a very positive experience.

496
00:17:37,650 --> 00:17:39,689
And then some of the new features we have now with Bronto we

497
00:17:39,689 --> 00:17:41,430
never had before, so the Team Explorer,

498
00:17:41,809 --> 00:17:43,949
uh, the usage Explorer, it gives us very good detail

499
00:17:43,949 --> 00:17:46,039
into what teams are actually creating the logs and where

500
00:17:46,039 --> 00:17:48,029
the, the usage actually is in the system.

501
00:17:48,608 --> 00:17:50,729
And the bigger one as well is we can actually

502
00:17:50,729 --> 00:17:51,640
put the logging.

503
00:17:52,588 --> 00:17:54,709
UX in front of teams and staff that

504
00:17:54,709 --> 00:17:55,809
are not very technically,

505
00:17:56,660 --> 00:17:58,729
er, er experienced or

506
00:17:58,818 --> 00:18:00,939
or confident, so support teams,

507
00:18:01,269 --> 00:18:03,289
uh, product managers can now interrogate logs

508
00:18:03,289 --> 00:18:05,509
in a much easier way and it, it reduces the burden on

509
00:18:05,509 --> 00:18:07,509
engineers to have to do all that preparatory work,

510
00:18:07,789 --> 00:18:09,939
uh, to provide, uh, logging outputs.

511
00:18:10,239 --> 00:18:12,390
So all in all, it's a great experience. And as well, the other

512
00:18:12,390 --> 00:18:14,729
quick thing is just the customer experience of dealing with the guys.

513
00:18:15,299 --> 00:18:17,430
Any changes, we've asked for feature additions. They've been very

514
00:18:17,430 --> 00:18:18,469
responsive to make them.

515
00:18:18,769 --> 00:18:20,949
They've they've just been a dream to deal with, so it's been a really great

516
00:18:20,949 --> 00:18:23,059
experience. Back

517
00:18:23,059 --> 00:18:25,250
to Mike Thanks

518
00:18:25,250 --> 00:18:26,400
very much, Ay. Uh,

519
00:18:26,660 --> 00:18:28,739
appreciate your time and attention today. If you've liked what

520
00:18:28,739 --> 00:18:30,939
you've heard, come over and talk to us over at booth

521
00:18:30,939 --> 00:18:32,500
1757.

522
00:18:32,858 --> 00:18:34,858
Uh, you can also sign up for a free trial

523
00:18:34,858 --> 00:18:37,049
at Bronto.io. No credit card

524
00:18:37,049 --> 00:18:37,559
required.

525
00:18:37,900 --> 00:18:38,858
Thanks again. Have a good day.

