# AWS re:Invent 2025 会议总结：Netflix 数据库迁移实践

## 会议概述

本次会议由 Netflix 数据平台团队工程师 Omar 主讲，分享了 Netflix 如何将数十个运行在第三方 Postgres 兼容分布式数据库上的应用迁移到 Amazon Aurora PostgreSQL 的实践经验。这是一次由平台团队主导的大规模数据库迁移项目，涉及超过 100 个应用程序，目标是减少运维负担、降低成本并提升性能。

迁移的主要驱动因素包括：自管理数据库带来的高运维成本、Postgres 兼容性问题（"通常兼容，但并非总是"）、以及分布式数据库在大多数场景下过于强大而昂贵。随着 Aurora PostgreSQL 在功能、可靠性和成本方面的持续改进，Netflix 决定进行这次全面迁移。项目从 2024 年 12 月开始编写自动化工具，2025 年 4 月完成首次迁移，目前已完成超过 90% 的迁移工作。

整个迁移策略的核心理念是：由平台团队承担尽可能多的工作，最小化应用团队的参与，实现读操作零停机、写操作最小停机的平滑迁移。团队大量使用 AWS Database Migration Service (DMS) 作为基础工具，并在此之上构建了完善的验证、监控和自动化系统。

## 详细时间线与关键要点

### 项目背景与挑战 [00:00 - 03:30]
- **00:00** - Omar 介绍自己是 Netflix 数据平台团队工程师
- **00:30** - 说明迁移目标：将数十个第三方 Postgres 兼容分布式数据库迁移到 Aurora PostgreSQL
- **01:00** - 强调这是平台团队为所有应用团队做出的决策，需要平台团队承担主要工作
- **01:30** - 指出理论上数据库迁移是已解决的问题：复制 schema 和数据、验证、重新指向应用
- **02:00** - 介绍 AWS DMS 可以处理 schema 转换、数据迁移和验证
- **02:30** - 说明实际挑战：超过 100 个应用、不同数据大小、不同数据形态和访问模式
- **03:00** - 应用使用不同编程语言，有不同的停机时间要求（从 4 小时到 30 秒不等）
- **03:30** - 数据库周边有流式连接器、分析连接器等依赖系统

### 预检查阶段 [03:30 - 07:00]
- **03:30** - 介绍预检查工作：在涉及应用团队之前完成的准备工作
- **04:00** - 使用 AWS DMS Schema Conversion Tool 生成兼容性报告
- **04:30** - AWS 为 Netflix 的第三方数据库源添加了支持（原本不支持）
- **05:00** - 发现问题示例：索引不兼容、隐藏列变为可见列等
- **05:30** - 采样应用的 SQL 语句并在 PostgreSQL 上测试执行
- **06:00** - 根据源集群流量模式预先配置目标 Aurora 集群大小
- **06:30** - 复制所有权元数据和授权信息，确保应用可以连接数据库
- **07:00** - 创建临时集群供应用团队测试，发现隐式类型转换等问题

### Schema 和数据复制 [07:00 - 10:30]
- **07:00** - Schema 复制包括表、视图、序列等数据库对象
- **07:30** - 展示 schema 转换示例（因为切换数据库引擎，不是一对一映射）
- **08:00** - 构建自定义验证工具，因为 DMS 对第三方源的支持不完善
- **08:30** - 发现边缘案例：varchar(3) 被错误转换为 varchar(1)，影响国家代码存储
- **09:00** - 数据复制使用 DMS 的全量加载（Full Load）功能
- **09:30** - 使用 CDC（Change Data Capture）实现实时复制，在应用运行时同步数据
- **10:00** - 构建监控工具，及早发现复制任务失败（避免在切换时才发现问题）
- **10:30** - 强调这是在线迁移：应用持续运行，源数据库和目标数据库同时运行

### 数据验证 [10:30 - 13:30]
- **10:30** - 数据验证的重要性：确保源和目标数据一致
- **11:00** - DMS 的验证功能不适用：不支持第三方源，且会对生产数据库造成压力
- **11:30** - 创新方案：将源和目标数据库连接到数据流（Kafka）
- **12:00** - 将数据导入数据仓库，使用分布式 SQL join 进行批量验证
- **12:30** - 批量验证：对比 5 分钟前的数据快照，避免验证正在变化的数据
- **13:00** - 在线验证：使用 Flink 作业实时对比源和目标的数据流
- **13:30** - 双重验证策略：批量验证历史数据 + 在线验证实时数据

### 切换流程 [13:30 - 18:00]
- **13:30** - 切换目标：读操作零停机，写操作最小停机
- **14:00** - 关键策略：将应用从切换流程中移除，在代理层处理切换
- **14:30** - Netflix 在数据存储前使用代理进行认证授权
- **15:00** - 确保应用同时兼容源和目标数据库，通过 schema 和 SQL 检查
- **15:30** - 切换步骤 1：测量复制延迟（写入记录到源，等待出现在目标）
- **16:00** - 大多数情况下复制延迟为 15-16 秒（设定阈值为 1 分钟）
- **16:30** - 切换步骤 2：运行批量验证确保数据准确
- **17:00** - 切换步骤 3：验证用户通过代理连接，移除直接访问权限
- **17:30** - 切换步骤 4：将流式和批处理基础设施从源复制到目标

### 关键切换阶段 [18:00 - 20:30]
- **18:00** - 进入关键阶段：通过修改源数据库权限关闭写操作
- **18:30** - 读操作继续工作，应用仍在运行但写入被阻止
- **19:00** - 同步序列（Sequence）值：从源复制到目标（不通过复制传输）
- **19:30** - 等待复制追上：推送最后一条记录，等待其出现在目标
- **20:00** - 验证在线数据一致性（之前已验证批量数据）
- **20:30** - 更新代理指向 Aurora PostgreSQL，终止源数据库连接

### 项目成果与经验 [20:30 - 23:00]
- **20:30** - 项目时间线：2024 年 12 月开始，2025 年 4 月首次迁移
- **21:00** - 首次迁移较为简陋（笔记本电脑运行代码、Jupyter notebooks），但成功完成
- **21:30** - 当前进度：超过 90% 完成，剩余少量需要特殊处理的大数据集
- **22:00** - 性能提升：许多案例中延迟降低（不再需要分布式共识，Aurora 内存读取）
- **22:30** - 从延迟图表可以清晰看到切换时间点
- **23:00** - 发现并修复约 10 个数据损坏 bug

### 关键经验总结 [23:00 - 25:00]
- **23:00** - 数据损坏问题：null 值处理、编码错误、生成列未正确复制、数据截断、列丢失
- **23:30** - CDC 相关问题：事务中的语句在复制时顺序不同
- **24:00** - 零回滚：所有迁移都成功，少数需要向前修复（集群规模不足、元数据问题）
- **24:30** - 最重要经验：全量预演节省了数月时间
- **25:00** - 基于现有工具构建（DMS + 内部工具），重点投入验证
- **25:30** - 针对常见技术栈（如 Java Flyway）构建专用工具
- **25:45** - 会议结束，Omar 表示可以在会后回答更多问题