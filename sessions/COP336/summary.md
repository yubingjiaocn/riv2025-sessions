# AWS re:Invent 2025 会议总结：构建弹性系统与可观测性

## 会议概述

本次AWS re:Invent 2025分组会议深入探讨了系统停机的成本及如何通过弹性架构和有效的可观测性来应对这一挑战。会议由来自悉尼的高级解决方案架构师Mat Canela和来自印度的高级云支持工程师Jay共同主讲。

会议开篇即指出了系统故障的严重影响：根据IT情报咨询数据，9%的企业每小时停机损失超过30万美元，41%的企业每小时损失在100万至500万美元之间。这不仅仅是IT问题，更关乎业务生存、客户关系、生产力损失和品牌声誉。演讲者通过一个生动的家庭自动化系统故障案例，将技术概念与实际场景相结合，说明了弹性设计的重要性。

会议内容涵盖了弹性架构的基础和最佳实践、可观测性的三大支柱（指标、日志、追踪）、服务水平目标(SLO)的重要性，以及如何使用AWS CloudWatch Application Signals和CloudWatch Investigation等AI驱动工具来快速检测和解决问题。最后，演讲者展示了两个使用生成式AI进行故障排查的实际演示。

## 详细时间线与关键要点

### 00:00 - 开场：停机成本的现实

- **停机成本统计**：9%企业每小时损失30万美元以上，41%企业每小时损失100-500万美元
- **影响范围**：不仅是IT问题，涉及错失商机、客户关系受损、生产力下降和品牌声誉受损
- **会议议程预告**：弹性基础、最佳实践、可观测性、检测与调查，以及生成式AI演示

### 03:30 - 弹性架构基础：家庭自动化案例

- **个人案例分享**：Mat讲述了凌晨1点部署家庭自动化系统更新后发生故障的经历
- **故障场景**：服务器崩溃导致无线开关网络失效，妻子早上5点无法开灯
- **SLA概念引入**：通过"灯光SLA为5小时"的对话，说明客户期望与实际服务水平的差距

### 08:00 - 从个人案例到AWS架构原则

单点故障问题：
- 家庭控制器是单点故障，对应AWS的多可用区(Multi-AZ)设计
- **解决方案**：使用Elastic Load Balancing和RDS Multi-AZ实现冗余

配置管理问题：
- 手动点击操作(Click Ops)难以回滚，人为错误是主要故障源
- **解决方案**：基础设施即代码(IaC)，使用AWS CDK、CloudFormation或Terraform，配合代码仓库管理

告警与自动恢复：
- 告警本可在用户发现前触发恢复
- **解决方案**：使用Auto Scaling应对负载激增，包括EC2 Auto Scaling和应用层Auto Scaling（Aurora、Lambda、DynamoDB）

灾难恢复演练：
- 从未测试过恢复手册，直到凌晨5点才发现问题
- **解决方案**：定期进行Game Day演练，使用AWS Fault Injection Service和AWS Resilience Hub

### 15:00 - AWS Fault Injection Service演示

- **功能展示**：可以注入可用区故障、EC2 CPU压力测试等受控故障
- **目的**：在受控环境中测试应用程序在故障情况下的行为表现

### 16:30 - AWS Resilience Hub案例

- **测试场景**：单可用区架构，包含单个RDS实例
- **设置目标**：RPO和RTO均设为5分钟
- **评估结果**：系统被判定为"不可恢复"，因为单个数据库无法在5分钟内恢复
- **价值**：帮助评估和改进弹性态势

### 19:00 - 权衡与风险考量

- **成本效益分析**：并非所有应用都需要最高级别的弹性
- **关键应用**：投入工程时间确保弹性
- **非关键应用**：理解风险并做出权衡决策

### 20:00 - 可靠性改进循环

1. 从基础架构开始构建弹性
2. 观察：收集指标和信息
3. 检测：设置告警机制
4. 调查：找到根本原因
5. 解决：恢复正常状态
6. 持续改进，形成闭环

### 21:00 - 可观测性概念介绍（Jay主讲）

- **微服务挑战**：分布式系统中多个服务相互通信，依赖关系复杂
- **无可观测性状态**：像盲飞一样，只能猜测问题所在（服务、依赖、网络、DNS）
- **有可观测性状态**：清晰看到应用形态、服务交互和依赖关系，快速定位故障

### 24:00 - 关键信号监控

业务指标：
- 收入影响、交易数量、订单数量
- 示例：结账服务故障时，明确知道损失的订单数和收入影响
- 用于驱动服务水平协议(SLA)

用户体验指标：
- 核心Web指标：最大内容绘制(LCP)、交互到下一次绘制(INP)、累积布局偏移(CLS)
- 示例：LCP从2秒增加到5秒，意味着用户可能放弃会话

服务健康指标：
- 请求数、错误率、延迟（使用P50、P95、P99百分位，避免使用平均值）
- 百分位数能更好地反映用户体验，平均值会掩盖问题

### 28:00 - 服务水平目标(SLO)

- **SLA（服务水平协议）**：对客户的承诺，如99.5%可用性
- **SLO（服务水平目标）**：内部目标，通常高于SLA，如99.9%
- **错误预算**：SLO与SLA之间的差值，用于部署新功能和版本
- **SLI（服务水平指标）**：实际测量的指标（延迟、错误、正常运行时间）

### 32:00 - Amazon CloudWatch Application Signals

开箱即用功能：
1. 自动检测：使用OpenTelemetry自动插桩，无需修改应用代码，几分钟内即可开始
2. 服务发现：自动发现所有服务和依赖关系，以图形化方式可视化
3. 预构建仪表板：显示服务健康状况、性能、故障等信息
4. 黄金信号：延迟、错误、故障，支持分布式追踪，原生支持SLO跟踪

### 35:00 - Application Signals实际演示

- **服务发现**：自动发现5个服务
- **故障检测**：前端服务显示2.5%的故障率
- **深入分析**：点击服务查看详细健康仪表板，显示请求激增和故障峰值
- **追踪关联**：自动关联到相关追踪ID，无需手动关联
- **应用地图**：可视化服务间的连接和通信方式

### 40:00 - SLO监控仪表板

- 显示哪些SLO达到目标
- 显示剩余错误预算
- 团队可持续跟踪，在错误预算即将耗尽时与开发团队协作

### 42:00 - 故障检测方法

滞后指标（Lagging Indicators）：
- 问题已经发生，客户已受影响
- 示例：错误率从0.5%激增至20%，新代码部署导致关键服务崩溃
- 特点：处于救火状态

领先指标（Leading Indicators）：
- 在影响客户前预警问题
- 示例：API延迟从100ms逐渐增加到200ms、300ms；磁盘使用率每天增长5%
- 优势：有足够时间采取行动（扩容、性能调优）
- **关键要点**：从滞后指标开始，逐步向领先指标演进

### 46:00 - CloudWatch异常检测功能

日志异常检测：
- 持续扫描日志，发现新的异常模式
- 自动运行，无需手动配置

指标异常检测：
- 基于历史数据学习并预测未来值和基线行为
- 超出阈值时标记为异常
- 支持季节性趋势，无需设置静态阈值
- 减少告警疲劳

### 49:00 - 日志异常检测实例

- 检测到3个异常
- 示例：检测到意外模式，严重程度为错误，优先级为中等
- 显示异常趋势和发生频率

### 50:00 - 指标异常检测实例

- 示例：目标响应时间指标
- 灰色带显示基线性能和预期值
- 超出范围的峰值被标记为异常
- 可基于异常检测创建告警

### 51:30 - 客户案例：建筑物监控

- **场景**：管理建筑物，安装多个摄像头，检测运动并上传文件到S3
- **需求**：检测建筑物内是否有聚会（异常人流）
- **解决方案**：为每个摄像头创建指标，使用异常检测识别异常上传频率
- **结果**：在非正常时间（如下午）检测到聚会时触发告警

### 53:00 - 滞后指标检测工具

日志模式与比较：
- 将相似日志事件分组为模式
- 比较不同时间范围内的模式变化
- 示例：比较当前与过去1天或1周的差异

贡献者洞察（Contributor Insights）：
- 查找Top贡献者
- 示例：哪些实例性能下降、哪些网络用户消耗最多带宽、哪些API端点错误最多

### 55:00 - 日志模式与比较演示

- 示例：检测到27个模式
- 重点模式：数据库连接超时错误
- 对比结果：增量为+252，表示新部署后新增的错误事件
- 价值：快速了解变更的影响

### 56:00 - 贡献者洞察演示

- **场景**：跟踪客户支付失败
- **结果**：12个唯一客户遇到故障，显示Top 10
- **发现**：特定客户ID的支付失败次数最多
- **可视化**：自动将日志转换为时间序列，显示错误趋势

### 58:00 - 调查挑战与AI解决方案

传统调查问题：
- 大量告警，多数是噪音
- 团队需要在多个工具间切换（指标、追踪、日志）
- 手动拼凑信息，耗时数小时
- 凌晨3点值班时尤其困难

Amazon CloudWatch Investigation：
- AI助手，内置于CloudWatch控制台
- 自动扫描和关联所有遥测数据（指标、日志、追踪、CloudTrail事件）
- 生成AI驱动的发现和根本原因分析
- 将数小时的调查缩短至几分钟
- 专注于修复问题而非查找问题

### 61:00 - CloudWatch Investigation工作原理

1. 构建服务拓扑：形成相关服务的关联图
2. 关联遥测数据：扫描所有服务的指标、日志、追踪和CloudTrail事件
3. 检测异常：识别峰值、异常模式等
4. 生成分析：AI代理提供根本原因分析和修复建议

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


会议总结：本次会议强调了在现代云环境中构建弹性系统和实施有效可观测性的重要性，展示了AWS提供的一系列工具和最佳实践，特别是AI驱动的自动化功能如何显著缩短故障检测和解决时间，最终帮助企业降低停机成本并提升客户体验。