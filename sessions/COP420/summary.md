# AWS re:Invent 2025 会议总结：使用生成式 AI 和 AWS 故障注入服务进行韧性测试

## 会议概述

本次会议由 Narita Woo 和 Hans Nisit 主讲，重点介绍了如何将生成式 AI 与 AWS 故障注入服务（FIS）相结合，以革新云应用的韧性测试方法。演讲者通过一个凌晨 2:37 被 CEO 电话惊醒的场景开场，强调了系统宕机带来的严重后果——不仅是收入损失，更是客户信任、领导层信心和投资者信任的崩溃。

会议核心思想源于 Amazon.com 副总裁兼 CTO Werner Vogels 的名言："一切都会失败"。基于这一理念，AWS 提出了共同责任模型：AWS 确保云的可靠性，而客户负责在云中构建可靠的架构。演讲者展示了如何使用 AI 代理自动发现潜在故障场景、生成测试文档，并将过去的事故转化为自动化测试，从而将数月的工作缩短为数周。整个解决方案结合了 AWS Systems Manager Inventory、Bedrock 支持的 AI 代理和故障注入服务，为韧性测试提供了一套完整且可立即实施的方法论。

## 详细时间线与关键要点

### 开场与问题陈述 (0:00 - 3:30)

0:00 - 会议以一个灾难场景开场：凌晨 2:37 接到 CEO 电话，应用已宕机 3 小时，造成数百万美元损失

1:15 - 提出核心问题：这种场景能否被预防？能否使用 AI 在故障发生前识别和测试故障点？

2:00 - 介绍演讲者和会议主题：在接下来的 60 分钟内展示如何结合生成式 AI 和 AWS 故障注入服务节省测试时间和精力

### 韧性的重要性 (3:30 - 6:00)

3:45 - 披露关键数据：过去一年中，50% 的公司在云中经历了超过 10 小时的宕机时间

4:20 - 强调系统故障的连锁反应：客户流失、领导层失去信心、投资者失去信任、收入消失

5:10 - 引用 Werner Vogels 的核心理念："一切都会一直失败，我们需要构建将故障视为自然现象的系统"

5:45 - 解释 AWS 共同责任模型：AWS 确保云的可靠性，客户在云中构建可靠的架构

### 会议路线图 (6:00 - 8:30)

6:15 - 第一部分：如何使用生成式 AI 作为早期检测系统，发现未曾想象的故障场景

6:45 - 第二部分：深入技术实现，展示实际工作原理

7:10 - 第三部分：使用 AI 验证已知故障

7:40 - 第四部分：实际操作演示，提供可在明天就能实施的实用代码和方案

### 韧性生命周期框架 (8:30 - 12:00)

8:45 - 介绍 AWS 韧性生命周期框架（2023 年 10 月发布）

9:20 - 框架包含五个阶段：设定目标、设计实施、评估测试、运营、响应

10:00 - 重点关注"评估测试"阶段：如何使用 AI 代理发现故障模式并构建验证测试

10:45 - 提及其他阶段的 AI 应用：设计实施阶段的 Kira 和 Kiro CLI，运营阶段的 DevOps 代理和 CloudWatch Investigator

11:30 - 强调响应阶段：将根因分析（RCA）转化为自动化测试场景

### 演示应用架构 (12:00 - 14:30)

12:15 - 介绍演示应用：经典三层架构，包含应用负载均衡器、Windows EC2 实例和 MySQL 数据库

13:00 - 说明两个核心 AI 代理：库存分析代理（发现实例上的内容并确定故障模式）和文档生成器代理（创建 Systems Manager 自动化文档）

13:45 - 区分 Resilience Hub 和当前方案：Resilience Hub 关注基础设施，而此方案深入到 EC2 实例内部运行的应用程序

### 实时演示 (14:30 - 18:00)

14:45 - 启动代理，开始识别环境中安装的内容

15:20 - 代理发现一个在线实例，识别出 IIS 应用程序

15:50 - 代理理解数据库连接配置

16:15 - 代理开始创建混沌工程假设，排除非应用相关的服务（如 Microsoft Edge）

16:45 - 数据传递给文档编写器代理

17:20 - 生成 Systems Manager 文档以在该实例上模拟 IIS 故障

### 代码实现解析 (18:00 - 20:30)

18:15 - 展示代理构建代码：仅需几行代码即可使用 AWS Strands 框架

18:45 - 关键组件：指定模型、提供工具（use_aws_tool）、设置提示和回调处理程序

19:20 - 强调 use_aws_tool 的重要性：让代理理解 AWS API 和服务上下文

19:50 - 介绍标签工具：帮助代理理解跨环境的资源关系

### 代理发现结果分析 (20:30 - 25:00)

20:45 - 代理发现 Web 应用服务器及相关服务

21:20 - 识别 ODBC 驱动程序，推断存在外部数据库依赖

22:00 - 建议使用原生 FIS 操作，如延迟注入（几周前刚发布的功能）

23:00 - 代理综合分析：理解实例在自动扩展组中，配置了健康检查，如果服务中断，实例将被替换

24:15 - 强调价值：即使支持团队不完全了解应用代码，也能快速构建故障假设

### 文档生成示例 (25:00 - 27:30)

25:15 - 展示非原生操作的文档示例

25:45 - 数据库 SQL 端口阻塞：操纵安全组以阻止 Web 服务器与数据库通信

26:20 - 可以阻塞所有服务器或特定实例 IP，测试可观测性平台是否能识别问题实例

27:00 - IIS 服务或应用池故障：测试客户端重试行为和服务恢复机制

### 提示工程详解 (27:30 - 35:00)

27:45 - 提示工程如同为代理编写详细的职位描述

28:15 - 库存代理提示：明确关注应用和服务器，忽略补丁和更新

28:50 - 解释为何忽略补丁：与韧性测试无关，是常规维护工作

29:30 - 自动化代理提示：永不触碰受保护的服务，专注于韧性测试而非破坏

30:15 - 提示结构：定义代理角色、能做什么、不能做什么、输出格式

31:00 - 平衡智能性和约束性：既要有效又要有边界

### 库存分析流程 (35:00 - 40:00)

35:20 - 介绍 AWS Systems Manager Inventory 作为"蓝图阅读器"

36:00 - 五步发现流程：
  1. 编目已安装软件
  2. 检查配置和包
  3. 记录服务及其版本
  4. 映射网络配置
  5. 打包库存报告供其他代理使用

37:30 - 强调版本检查的重要性：确保运行时与安装版本匹配

38:45 - 仅关注在线且向 Systems Manager 报告的 EC2 实例

### 关键分析维度 (40:00 - 44:00)

40:15 - 业务关键应用：Java、Python、Node.js、.NET 框架等

40:50 - 数据层：数据库客户端和连接

41:25 - Web 服务器：Apache、Tomcat 等面向客户的前线服务

42:00 - 自定义应用：内部构建或第三方工具

42:40 - 核心问题：是否有直接业务影响？

43:20 - 四个关键问题：
  1. 服务器的主要角色是什么？
  2. 哪些服务正在主动运行并提供业务功能？
  3. 服务依赖关系是什么？
  4. 故障如何影响业务？

### 保护服务与边界 (44:00 - 47:00)

44:20 - 保护服务代表代理的护栏

44:50 - 为不同资源创建隔离边界

45:25 - 核心理念：混沌工程不是随机测试，而是有选择性的测试

46:00 - 保护列表可根据用例修改

46:40 - 示例：Systems Manager 本身是受保护的服务，因为它用于恢复节点

### 文档编写最佳实践 (47:00 - 51:00)

47:20 - 优秀 Systems Manager 文档的特征

47:50 - 服务状态恢复：实验结束后必须恢复资源状态

48:30 - 模块化设计：在失败或取消时回滚更改

49:10 - 展示 CloudFront 故障文档示例：每个步骤都有失败回滚机制

49:50 - 幂等性：确保不会同时运行多个相同操作

50:25 - 前置条件：例如 PowerShell 脚本仅在 Windows 实例上运行

### 总结与行动建议 (51:00 - 60:00)

51:15 - 回顾整体方案：从发现到测试的完整流程

52:00 - 强调可立即实施性：提供的代码和方法可在明天就开始使用

53:00 - 将月度工作缩短为周度工作的价值主张

54:00 - 结合 Resilience Hub 使用以获得完整视图

55:30 - 鼓励参会者扫描 QR 码获取更多资源

57:00 - 问答环节准备

60:00 - 会议结束