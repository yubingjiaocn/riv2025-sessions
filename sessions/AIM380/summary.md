# AWS re:Invent 2025 - 定制化 Amazon Nova 模型以增强工具调用能力 (AIM380)

## 会议概述

本次会议由 AWS 全球生成式 AI 专家 Hershani 和 Nova 团队高级解决方案架构师 Anupam 主讲，重点介绍了如何通过定制化技术增强 Amazon Nova 模型的工具调用能力。会议以一个证券协议法律助手代理为实际用例，展示了从数据生成、模型微调到部署的完整流程。

演讲者首先介绍了模型定制化的技术谱系，从轻量级的提示工程和 RAG（检索增强生成）到需要修改模型权重的预训练和后训练技术。针对 Nova 模型，AWS 提供了两种训练方案：SageMaker 完全托管训练作业和 SageMaker Hyperpod。会议特别强调了 AWS re:Invent 2025 发布的重要更新，包括第二代 Nova 模型（Nova 2 Light、Nova 2 Pro 和 Nova Omni）以及 Nova Forge 开放训练概念，后者提供了中间检查点和 Nova 数据混合能力。

在实际演示环节，团队展示了如何使用合成数据生成器创建训练数据，然后通过监督微调（SFT）和强化微调（RFT）逐步提升模型性能。基础模型的整体得分为 44%，经过 SFT 后提升至 75%，最终通过 RFT 达到 88-89%。整个演示强调了参数高效微调（LoRA）的优势，它只需调整 1-2% 的模型权重即可达到接近全量微调 90% 的性能。

## 详细时间线

### 开场介绍 (00:00 - 03:30)
- **00:00** - 会议开始，Hershani 介绍会议主题：AIM380 定制化 Amazon Nova 模型以增强工具调用
- **00:30** - Hershani 自我介绍为 AWS 全球生成式 AI 专家
- **00:45** - Anupam 介绍自己是 Nova 团队的高级解决方案架构师
- **01:00** - 会议议程概览：模型定制化概念、关键考虑因素、可用技术、re:Invent 发布内容和代码演示

### 模型定制化基础概念 (03:30 - 07:00)
- **03:30** - 介绍模型定制化技术谱系：从不修改权重到修改权重的方法
- **04:00** - 轻量级技术：提示工程和 RAG（检索增强生成）
- **04:45** - 重量级技术：后训练和预训练方法
- **05:30** - AWS 提供的定制化方案：SageMaker 完全托管训练作业和 SageMaker Hyperpod
- **06:30** - SageMaker 训练作业的声明式语法和 Python SDK 特性

### AWS re:Invent 2025 发布内容 (07:00 - 11:30)
- **07:00** - Anupam 介绍 Nova 模型系列的演进
- **07:30** - 第一代模型：Micro、Light 和 Pro
- **08:00** - 第二代模型发布：Nova 2 Light（从头构建，改进多语言能力、代理用例和编码能力）
- **08:45** - 早期访问模型：Nova 2 Pro 和 Nova Omni（任意到任意的多模态模型）
- **09:15** - Nova Forge 开放训练概念：提供中间检查点和训练配方
- **09:45** - Nova 数据混合功能：将专有数据与 Amazon Nova 策划数据混合
- **10:15** - 自带环境的强化学习支持
- **10:45** - 一键式配方和负责任 AI 工具包

### 可用的微调技术对比 (11:30 - 13:30)
- **11:30** - Nova 1.0 和 2.0 支持的技术对比表
- **11:45** - 参数高效微调（PEFT）：仅修改模型适配器
- **12:00** - 全秩微调：修改模型实际权重
- **12:15** - DPO（直接偏好优化）：基于点赞/点踩反馈
- **12:30** - PPO（近端策略优化）：另一类 RLHF 技术
- **12:45** - RFT（强化微调）：最先进的 RLHF 技术，仅在 Nova 2.0 中可用
- **13:15** - RFT 在推理模型上效果更好，Nova Light 2 是推理模型

### 用例架构介绍 (13:30 - 16:00)
- **13:30** - 演示用例：证券协议法律助手代理
- **14:00** - 代理功能：查看多个文档、选择正确工具、提供正确参数
- **14:30** - 演示模块概览：合成数据生成、基础模型评估、SFT、RFT 和部署到 Bedrock
- **15:00** - 预计涵盖所有模块，时间紧凑
- **15:30** - 强调会议为代码演示而非 PPT 演示

### SFT 技术原理 (16:00 - 18:30)
- **16:00** - SFT 基于适配器训练器的工作原理
- **16:30** - LoRA 技术：最轻量级的 SFT 方法，资源需求有限
- **17:00** - 适配器训练流程：从数据库获取数据，加载基础模型，前向后向传播
- **17:30** - 适配器与基础模型融合生成最终模型
- **18:00** - 使用有限资源快速获得良好结果

### RFT 技术原理 (18:30 - 21:00)
- **18:30** - RFT 架构：训练 VPC 和客户 VPC
- **19:00** - 两个主要模块：Rollout（推出）和 Trainer（训练器）
- **19:30** - 客户账户中的 Lambda 函数作为奖励函数
- **20:00** - Rollout 生成 n 个预测，Lambda 计算奖励分数
- **20:30** - 训练器根据奖励更新权重，循环迭代
- **21:00** - 循环持续进行用户定义的步数

### 数据准备和合成数据生成 (21:00 - 28:00)
- **21:00** - 切换到代码演示环节
- **21:30** - 数据准备步骤：从零生成训练数据
- **22:00** - 三个数据源：Edgar 备案文件、SEC 正式语言法规、司法解释
- **22:45** - 用例说明：律师或法律助理确保证券交易符合 SEC 法规
- **23:15** - 免责声明：在法律和医疗用例中谨慎使用
- **24:00** - 数据爬取功能：从开源网站下载数据
- **24:45** - 合成数据生成器：将原始数据转换为 Nova 可消费格式
- **25:30** - 提示工程的重要性：指导模型生成正确格式
- **26:15** - 数据生成工具包动画演示
- **27:00** - 数据分块：根据模型上下文窗口限制分块
- **27:30** - 重叠字符参数 n：保持语义连续性

### 合成数据生成详细流程 (28:00 - 35:00)
- **28:00** - 每个分块输入提示，调用教师模型（Nova Premier）
- **28:30** - 100 个分块产生 100 次调用
- **29:00** - 生成学生模型（Nova Light）可消费的格式
- **29:30** - Nova SFT 数据格式：系统提示、用户提示、助手响应
- **30:00** - 系统提示示例："你是一个有用的法律助手"
- **30:45** - JSON 对象格式：系统、用户、助手角色
- **31:15** - 验证循环：确保数据可被底层模型消费
- **32:00** - 目标：模型选择正确工具
- **32:30** - 评估指标：工具选择正确性、多工具序列、参数正确性
- **33:00** - 指标可自定义
- **33:30** - 提示最佳实践：双井号标记、大写指南
- **34:00** - 告诉模型可用工具和所需参数
- **34:30** - 查询分类为八个预定类别

### 工具映射和数据格式 (35:00 - 40:00)
- **35:00** - 类别到工具的映射表
- **35:30** - 法规定义类别使用特定工具
- **36:00** - 法规合规分析使用两个工具的序列
- **36:30** - 要求严格的 JSON 模式
- **37:00** - 提供少样本示例定义
- **37:30** - 在提示末尾插入生成的分块
- **38:00** - 使用 Meta 的开源合成数据工具包
- **38:30** - 修改工具包以支持 Bedrock 和 SageMaker 模型
- **39:00** - 系统检查：使用 Bedrock 中的 Nova 模型
- **39:30** - 测试提示"hi"，模型准备就绪

### 数据生成和验证 (40:00 - 45:00)
- **40:00** - 文件解析和提示生成
- **40:30** - 合并为 JSON Lines 文件（Nova SFT 所需格式）
- **41:00** - 数据分为三个集合：训练、验证、测试
- **41:30** - 查询和答案示例展示
- **42:00** - Nova 生成的查询和适当答案格式
- **42:30** - 学生模型学习如何响应实际用户查询
- **43:00** - 暂停提问环节
- **43:30** - 问题：GitHub 是否公开？答：今天会公开，在 Nova samples GitHub
- **44:15** - 问题：能否对 Nova Sonic 应用类似流程？答：目前不可用

### SFT 训练流程 (45:00 - 52:00)
- **45:00** - 进入 SFT notebook
- **45:30** - LoRA 和 SFT 的优势：仅调整 1-2% 模型权重
- **46:00** - 减少基础设施、训练时间和成本
- **46:30** - 使用相关数据可达到全量微调 90% 的准确率
- **47:00** - 适配器是提取的 1-2% 权重
- **47:30** - 训练适配器，添加到基础模型，生成微调后的 Nova Light 模型
- **48:00** - 设置 SageMaker 会话
- **48:30** - 选择实例类型：四个实例用于分布式训练
- **49:00** - 选择 ECR 中的 Docker 镜像 URI
- **49:30** - 使用配方：超参数的抽象配置
- **50:00** - 配方内容：训练步数、学习率调度器、LoRA 适配器
- **50:30** - 选择 PyTorch estimator（Nova 使用 PyTorch Lightning）
- **51:00** - 提供配方、镜像 URI 和生成的数据
- **51:30** - 开始训练

### SFT 训练结果 (52:00 - 57:00)
- **52:00** - 完成的 notebook 展示
- **52:30** - 控制台中的基础设施利用率指标
- **53:00** - 每个实例一个日志流，状态码 200 表示成功
- **53:30** - 训练时间：20-40 分钟
- **54:00** - 下载模型 tarball，提取训练损失文件
- **54:30** - 训练曲线：100 步从 70 降至 10
- **55:00** - 训练损失与实际评估指标的区别
- **55:30** - 训练损失仅衡量文本匹配
- **56:00** - 实际评估：工具选择、序列、JSON 可解析性
- **56:30** - 评估指标：精确率、召回率、F1 分数

### 评估流程和指标 (57:00 - 63:00)
- **57:00** - 工具选择的准确率指标
- **57:30** - 整体加权分数：基于参数、工具和序列
- **58:00** - 指标可自定义
- **58:30** - 评估循环与训练循环的区别
- **59:00** - 测试集发送到基础模型和微调模型
- **59:30** - Lambda 函数评估每次调用
- **60:00** - 评估架构图：基础模型和微调模型并行评估
- **60:30** - Lambda 计算自定义函数的指标
- **61:00** - 比较基础模型和微调模型的评估结果
- **61:30** - 评估作业配置：实例类型、镜像 URI、配方
- **62:00** - 配方指向 Lambda ARN
- **62:30** - 定义 PyTorch estimator，提供测试集

### SFT 评估结果 (63:00 - 68:00)
- **63:00** - 启动评估作业，约 20 分钟
- **63:30** - 下载 tarball 查看结果
- **64:00** - 基础模型指标可视化
- **64:30** - 微调模型指标显著提升
- **65:00** - 整体分数从 44% 提升至 75%
- **65:30** - SFT 循环结束
- **66:00** - 使用 SFT 微调模型进行 RFT
- **66:30** - RFT 进一步提高准确率
- **67:00** - 过渡到 RFT notebook
- **67:30** - RFT 是"第二部分的酷炫内容"

### RFT 训练准备 (68:00 - 74:00)
- **68:00** - RFT 原理回顾：Rollout 和 Trainer
- **68:30** - Rollout 生成 n 个响应
- **69:00** - Trainer 从奖励函数获取反馈
- **69:30** - 使用反馈更新权重，循环多次
- **70:00** - 循环次数在配方中定义
- **70:30** - Rollout 数量也是配方参数
- **71:00** - 基础设置：IAM 角色、导入
- **71:30** - 从 SFT notebook 检索 SFT 检查点
- **72:00** - 检索评估结果数据框
- **72:30** - RFT 数据格式：系统、用户、参考答案
- **73:00** - 参考答案可以是任何内容，不仅是真实答案
- **73:30** - 可以包含思考笔记或其他信息

### RFT 奖励函数 (74:00 - 81:00)
- **74:00** - RFT 从传递的内容学习，不仅记忆真实答案
- **74:30** - 创建数据集并存储到 S3
- **75:00** - 创建 Lambda 函数作为奖励函数
- **75:30** - 奖励函数是获得良好 RFT 的关键
- **76:00** - 警告：有偏见或易被破解的奖励函数会导致模型寻找漏洞
- **76:30** - Lambda handler 和 Lambda grader
- **77:00** - 输入：用户提示、助手响应、参考答案
- **77:30** - 传递所需信息类型、工具、参数和推理
- **78:00** - 返回聚合奖励分数
- **78:30** - RFT 需要数值奖励函数
- **79:00** - 聚合奖励函数：所有关注指标的加权平均
- **79:30** - 指标：正确工具、正确参数、正确序列、JSON 可解析
- **80:00** - 通过加权平均聚合
- **80:30** - 默认值为零（错误时），正确时为更高值

### RFT 奖励函数设计 (81:00 - 86:00)
- **81:00** - 捕获所有指标和最终聚合分数
- **81:30** - 返回结果
- **82:00** - 关键：奖励函数应该是梯度的
- **82:30** - 不应该是二元的（正/负或真/假）
- **83:00** - 应该有梯度：好、平均、接近好
- **83:30** - 使用信息优化从"接近好"到"最佳答案"
- **84:00** - 创建 Lambda 并部署到 AWS
- **84:30** - 启动 RFT 训练
- **85:00** - 传递训练的检查点
- **85:30** - 传递配方、镜像 URI

### RFT 训练执行 (86:00 - 92:00)
- **86:00** - 使用 P5.48xlarge 实例
- **86:30** - 最少需要四个实例运行 RFT
- **87:00** - 使用 Nova Light 2 作为基础模型
- **87:30** - 启动 RFT 作业
- **88:00** - PyTorch estimator 调用，类似 SFT
- **88:30** - 定义训练数据和验证数据
- **89:00** - 启动 fit 命令开始训练
- **89:30** - 可以在 notebook 中打印日志或在控制台查看
- **90:00** - 日志显示训练步骤和捕获的指标
- **90:30** - 控制台截图展示
- **91:00** - 训练开始、下载镜像、开始训练
- **91:30** - 捕获训练结果

### RFT 训练结果分析 (92:00 - 98:00)
- **92:00** - 需要查看 RFT 后的指标
- **92:30** - 获取逐步训练指标
- **93:00** - 之前运行的截图：150 步而非 5 步
- **93:30** - 查看训练奖励函数指标
- **94:00** - 训练奖励是 RFT 的关键指标
- **94:30** - 期望看到奖励逐渐增加
- **95:00** - 从低值增加到接近 1
- **95:30** - 表明模型在循环中学习
- **96:00** - 奖励从 0.81-0.82 提升到 0.85-0.86
- **96:30** - 逐渐增加，某些情况达到 0.9
- **97:00** - 与评估指标密切相关
- **97:30** - SFT 约 74-75%，RFT 后达到 88-89%

### RFT 进一步分析 (98:00 - 结束)
- **98:00** - 奖励函数增加带来信心
- **98:30** - 熵减少（截断）

注：会议在此处字幕截断，完整内容可能包含部署到 Bedrock 和最终问答环节