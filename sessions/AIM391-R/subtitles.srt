1
00:00:04,059 --> 00:00:05,070
Welcome everyone.

2
00:00:05,349 --> 00:00:07,509
Uh, thank you for joining this session on

3
00:00:07,509 --> 00:00:09,448
mastering model choice in Amazon Bedrock.

4
00:00:10,148 --> 00:00:10,829
We're glad you're here.

5
00:00:12,118 --> 00:00:14,358
Uh, how many of you, uh, are

6
00:00:14,358 --> 00:00:16,559
overwhelmed by the number of AI

7
00:00:16,559 --> 00:00:17,510
models available

8
00:00:17,809 --> 00:00:19,329
when building AI applications?

9
00:00:21,250 --> 00:00:23,318
Great, uh, and how many of your

10
00:00:23,318 --> 00:00:24,030
organizations have a

11
00:00:24,559 --> 00:00:26,908
systematic framework for picking out

12
00:00:27,208 --> 00:00:28,568
models for AI applications?

13
00:00:30,179 --> 00:00:31,739
All right, fewer hands there, great.

14
00:00:32,508 --> 00:00:34,008
Well, we're here to help, uh.

15
00:00:35,279 --> 00:00:37,340
We're gonna talk through a simple framework

16
00:00:37,340 --> 00:00:37,978
that

17
00:00:38,759 --> 00:00:41,069
you and your organization can use to identify

18
00:00:41,069 --> 00:00:43,298
models, evaluate those models, and optimize them

19
00:00:43,560 --> 00:00:45,598
for production based on the work we're doing with our

20
00:00:45,598 --> 00:00:46,289
customers,

21
00:00:46,609 --> 00:00:47,779
uh, at AWS.

22
00:00:48,770 --> 00:00:50,630
I'm Scott Munson, principal worldwide

23
00:00:50,969 --> 00:00:53,189
AI specialist with Amazon Bedrock team.

24
00:00:53,848 --> 00:00:55,668
Along with me today are John Liu,

25
00:00:56,009 --> 00:00:58,130
principal product manager with Amazon Bedrock,

26
00:00:58,329 --> 00:00:59,490
and Brian Coe,

27
00:00:59,810 --> 00:01:01,228
senior AI product manager

28
00:01:01,609 --> 00:01:02,459
with Coin Market Cap.

29
00:01:04,707 --> 00:01:06,418
So quick agenda, uh, we're gonna

30
00:01:07,078 --> 00:01:09,138
start off by just an overview, kind of set the context. What

31
00:01:09,138 --> 00:01:11,087
are the challenges that our customers are seeing

32
00:01:11,447 --> 00:01:13,337
and, uh, how are we helping them

33
00:01:13,679 --> 00:01:15,748
and then talk through the framework itself. So how do

34
00:01:15,748 --> 00:01:17,018
we identify and evaluate

35
00:01:17,438 --> 00:01:18,528
and optimize models

36
00:01:18,837 --> 00:01:20,138
and then we'll have a chance to hear

37
00:01:20,399 --> 00:01:21,289
from Brian

38
00:01:21,808 --> 00:01:23,878
to uh how he's using this framework and his

39
00:01:23,878 --> 00:01:24,578
with his team

40
00:01:25,399 --> 00:01:27,477
to, uh, deploy AI applications

41
00:01:27,477 --> 00:01:29,587
that are serving over 65 million monthly

42
00:01:29,587 --> 00:01:30,378
active users.

43
00:01:33,219 --> 00:01:33,730
So

44
00:01:34,448 --> 00:01:37,019
Get a sense of the landscape. Uh, 2.19

45
00:01:37,019 --> 00:01:39,099
million public models available in hugging Face

46
00:01:39,099 --> 00:01:41,260
today. Uh, chatted with

47
00:01:41,260 --> 00:01:43,879
the chief product officer of Hugging Face

48
00:01:43,879 --> 00:01:46,439
yesterday. He said there's a new model every 10 seconds,

49
00:01:46,939 --> 00:01:47,448
uh,

50
00:01:47,819 --> 00:01:50,138
incredible pace, right? That adds up to about 4000

51
00:01:50,138 --> 00:01:51,319
models per day.

52
00:01:51,778 --> 00:01:52,439
That's just

53
00:01:52,739 --> 00:01:55,219
publicly available open weight models. Uh,

54
00:01:55,338 --> 00:01:57,500
add to that all the proprietary model

55
00:01:57,500 --> 00:01:59,609
makers, Anthropic, Amazon, OpenAI,

56
00:01:59,680 --> 00:02:00,379
all the rest.

57
00:02:00,689 --> 00:02:02,769
Uh, we have so much choice. This

58
00:02:02,769 --> 00:02:04,079
is in every modality.

59
00:02:04,510 --> 00:02:05,510
Uh, text,

60
00:02:05,829 --> 00:02:06,430
image,

61
00:02:06,790 --> 00:02:08,830
video, audio, new modalities, there's

62
00:02:08,830 --> 00:02:09,788
so much innovation,

63
00:02:10,139 --> 00:02:11,770
um, it's an exciting time

64
00:02:12,308 --> 00:02:14,349
to be building these applications

65
00:02:14,349 --> 00:02:15,028
with AI

66
00:02:15,308 --> 00:02:16,569
models, but

67
00:02:17,069 --> 00:02:19,189
there's a little bit of a bottleneck. I mean, we're hearing from customers

68
00:02:19,189 --> 00:02:21,649
that picking the model itself is actually a challenging,

69
00:02:21,830 --> 00:02:22,669
uh, task.

70
00:02:24,569 --> 00:02:26,740
So why is it challenging? What's the consequence of this?

71
00:02:26,808 --> 00:02:29,189
What we're hearing is that the POCs matter

72
00:02:29,490 --> 00:02:31,689
when you're building out an AI application for the first

73
00:02:31,689 --> 00:02:33,849
time with your organization. You wanna make

74
00:02:33,849 --> 00:02:35,110
sure that that's a successful

75
00:02:35,379 --> 00:02:37,569
trial run. They're not all guaranteed to to be successful,

76
00:02:37,649 --> 00:02:39,889
but it matters to our customers that they have

77
00:02:40,169 --> 00:02:42,360
a a good win early on in this process.

78
00:02:42,649 --> 00:02:44,770
And so, uh, this matters for the time

79
00:02:44,770 --> 00:02:47,118
and labor spent, but also just the momentum and

80
00:02:47,118 --> 00:02:48,379
organizational kind of reputational impact.

81
00:02:49,050 --> 00:02:51,250
So it, it can be a tough loss if they pick the wrong

82
00:02:51,250 --> 00:02:53,330
model for the job and build around that.

83
00:02:54,210 --> 00:02:55,229
We're also hearing this

84
00:02:55,490 --> 00:02:57,808
specific problem of no selection framework

85
00:02:57,808 --> 00:02:59,028
to to work

86
00:02:59,569 --> 00:03:01,689
through all the models uh with and so we're gonna

87
00:03:01,689 --> 00:03:02,990
talk through that today of course

88
00:03:03,409 --> 00:03:05,409
and the pace of innovation is challenging. If

89
00:03:05,409 --> 00:03:07,069
it takes 4 weeks to

90
00:03:07,429 --> 00:03:09,800
test out your models and pick the the one you like

91
00:03:10,129 --> 00:03:12,129
and a better model came out yesterday, it's sort

92
00:03:12,129 --> 00:03:13,588
of a challenging, uh,

93
00:03:14,008 --> 00:03:16,229
environment to work in, so pace is important

94
00:03:16,229 --> 00:03:17,028
to our customers.

95
00:03:17,490 --> 00:03:19,520
And then of course uh any

96
00:03:19,740 --> 00:03:22,028
customer facing application, any large organization

97
00:03:22,028 --> 00:03:24,099
application needs to function at scale. So sometimes our

98
00:03:24,099 --> 00:03:24,979
POCs aren't,

99
00:03:25,460 --> 00:03:27,500
uh, optimized for the big production workloads and we

100
00:03:27,500 --> 00:03:29,508
wanna make sure that our customers are successful

101
00:03:29,508 --> 00:03:30,599
in that arena as well.

102
00:03:32,699 --> 00:03:34,710
So Amazon Bedrock is uh

103
00:03:34,740 --> 00:03:36,319
AWS's solution to provide

104
00:03:36,819 --> 00:03:38,979
uh developers what they need

105
00:03:38,979 --> 00:03:41,088
to focus on their developing of

106
00:03:41,088 --> 00:03:42,960
applications and, and we can kind of provide the rest,

107
00:03:43,300 --> 00:03:45,038
uh, you know, Bedrock has

108
00:03:45,500 --> 00:03:47,740
a great selection of top models

109
00:03:47,740 --> 00:03:50,069
uh that are kind of coming out continuously

110
00:03:50,069 --> 00:03:51,800
and we're committed to providing great

111
00:03:52,219 --> 00:03:52,960
model choices.

112
00:03:53,699 --> 00:03:56,469
We optimize uh our inference

113
00:03:56,469 --> 00:03:58,099
to make sure that our customers can

114
00:03:58,659 --> 00:04:00,899
use this inference in a serverless manner so they can scale

115
00:04:00,899 --> 00:04:03,179
up and scale down they can use different modes

116
00:04:03,179 --> 00:04:05,300
of inference, um, they can balance the

117
00:04:05,300 --> 00:04:07,860
requirements of their application without having to do all the deployment

118
00:04:08,179 --> 00:04:09,679
of AI models themselves.

119
00:04:10,689 --> 00:04:12,199
A lot of our customers are seeing success

120
00:04:12,740 --> 00:04:14,338
by leveraging their data, so

121
00:04:14,618 --> 00:04:16,619
that could be in the form of a rag knowledge-based

122
00:04:16,619 --> 00:04:19,230
solution or it could be in, uh, model distillation,

123
00:04:19,579 --> 00:04:21,660
uh, or fine tuning, uh, according

124
00:04:21,660 --> 00:04:23,639
to their, their specific proprietary data.

125
00:04:24,059 --> 00:04:25,720
And, um, of course

126
00:04:25,980 --> 00:04:28,059
safety and responsibility are critical. So Amazon

127
00:04:28,059 --> 00:04:29,290
Bedrock provides guardrails,

128
00:04:29,660 --> 00:04:31,899
uh, along with other features that help our

129
00:04:31,899 --> 00:04:34,250
customers ship their products with,

130
00:04:34,259 --> 00:04:37,000
uh, with kind of confidence in the reliability

131
00:04:37,259 --> 00:04:39,358
and, uh, responsibility of their AI

132
00:04:39,358 --> 00:04:41,649
applications. And we're doing a lot with gentic

133
00:04:41,649 --> 00:04:43,309
work. uh, this week we launched

134
00:04:43,608 --> 00:04:44,759
a number of agent cop,

135
00:04:45,170 --> 00:04:47,329
uh, capabilities that are very exciting to help you

136
00:04:47,329 --> 00:04:49,369
seamlessly deploy and operate agents at

137
00:04:49,369 --> 00:04:52,048
scale. To

138
00:04:52,048 --> 00:04:53,920
go a bit further on, uh,

139
00:04:54,379 --> 00:04:55,559
model, uh,

140
00:04:56,298 --> 00:04:58,379
options themselves, we really do work with

141
00:04:58,379 --> 00:05:00,420
top model providers and continue to expand

142
00:05:00,420 --> 00:05:01,588
that number over time.

143
00:05:01,939 --> 00:05:04,059
Uh, we think that's important. We're hearing

144
00:05:04,059 --> 00:05:05,928
from our customers they want that choice of models,

145
00:05:06,220 --> 00:05:07,959
so we're committed to, to giving them that

146
00:05:08,500 --> 00:05:10,619
model evaluation tools are a critical

147
00:05:10,619 --> 00:05:12,899
kind of counterpart with that to make sure that

148
00:05:12,899 --> 00:05:15,040
customers know what the right model is

149
00:05:15,338 --> 00:05:17,689
and. We also allow people

150
00:05:17,689 --> 00:05:19,730
to import their own models. So if you fine tune

151
00:05:19,730 --> 00:05:21,970
a model or have another model that you're interested in using,

152
00:05:22,269 --> 00:05:23,149
um, we can

153
00:05:23,689 --> 00:05:25,928
import that and through custom model import and

154
00:05:25,928 --> 00:05:27,928
provide that inference, uh, along with the other

155
00:05:27,928 --> 00:05:28,759
models available,

156
00:05:29,048 --> 00:05:31,389
which is a big kind of convenience factor again letting us

157
00:05:31,528 --> 00:05:33,759
handle that, uh, inference task for

158
00:05:33,769 --> 00:05:34,290
customers.

159
00:05:36,009 --> 00:05:38,238
And again, Bedrock has, uh,

160
00:05:38,250 --> 00:05:40,290
this slide shows 13. We added 4

161
00:05:40,290 --> 00:05:42,809
additional model providers this week. We launched models

162
00:05:42,809 --> 00:05:43,389
from Google,

163
00:05:43,778 --> 00:05:44,689
from Minimax,

164
00:05:44,970 --> 00:05:46,608
from Nvidia, and from Moonshot,

165
00:05:46,899 --> 00:05:49,048
uh, very exciting. We're over 80 models now

166
00:05:49,048 --> 00:05:50,350
available on Amazon Bedrock.

167
00:05:50,678 --> 00:05:51,850
Uh, we

168
00:05:52,230 --> 00:05:54,369
really do, uh, hear from our customers and

169
00:05:54,369 --> 00:05:55,709
are convinced that

170
00:05:56,290 --> 00:05:58,369
us providing this inference for them,

171
00:05:58,488 --> 00:06:00,970
this Bedrock service gives them the simplicity,

172
00:06:01,250 --> 00:06:01,949
the scale.

173
00:06:02,730 --> 00:06:04,769
And security that they need so they can just

174
00:06:04,769 --> 00:06:05,509
focus on

175
00:06:05,769 --> 00:06:07,850
their domain and their application development.

176
00:06:09,850 --> 00:06:10,358
So

177
00:06:12,559 --> 00:06:14,829
Great to have all those models. You still have to pick, uh,

178
00:06:14,838 --> 00:06:17,119
some to use for your application and so this

179
00:06:17,119 --> 00:06:18,410
is the model selection framework.

180
00:06:19,119 --> 00:06:21,119
Uh, we've kind of pulled this from working with a lot

181
00:06:21,119 --> 00:06:23,278
of customers and, and trying to simplify

182
00:06:23,278 --> 00:06:25,500
it down so you can work with your stakeholders and kind of,

183
00:06:25,838 --> 00:06:27,939
uh, understand easily what stage you're in.

184
00:06:28,439 --> 00:06:30,769
Uh, this, the process itself is, is relatively

185
00:06:30,769 --> 00:06:33,170
simple if you, uh, think about it in these terms.

186
00:06:33,480 --> 00:06:35,480
First up, you identify candidate models so you look

187
00:06:35,480 --> 00:06:36,100
at all these.

188
00:06:36,920 --> 00:06:39,149
Options and filter them down. We'll go into

189
00:06:39,149 --> 00:06:40,298
exactly how to do that in a moment.

190
00:06:41,528 --> 00:06:43,910
Then you evaluate those models on your data

191
00:06:43,910 --> 00:06:46,439
on your use case. This is really critical. Generalized

192
00:06:46,439 --> 00:06:47,230
benchmarks

193
00:06:47,569 --> 00:06:49,069
are not the greatest indicator

194
00:06:49,369 --> 00:06:51,569
of what model is gonna be most performant to meet your

195
00:06:51,569 --> 00:06:52,389
application's requirements.

196
00:06:53,069 --> 00:06:55,309
And then we have another step to optimize

197
00:06:55,309 --> 00:06:56,459
those models that might be

198
00:06:57,048 --> 00:06:59,480
through breaking up the AI workload into multiple

199
00:06:59,480 --> 00:07:00,088
models,

200
00:07:00,439 --> 00:07:02,439
uh, to meet the performance requirements you

201
00:07:02,439 --> 00:07:04,619
need or potentially through fine tuning,

202
00:07:04,838 --> 00:07:06,920
uh, as well. So we'll talk through all that

203
00:07:06,920 --> 00:07:08,928
today. Um,

204
00:07:09,009 --> 00:07:11,040
and to help kind of keep us grounded, we're gonna

205
00:07:11,040 --> 00:07:13,028
use this, uh, use case to help

206
00:07:13,528 --> 00:07:16,269
understand the process. So we've got a financial crimes

207
00:07:16,278 --> 00:07:17,088
investigation agent

208
00:07:17,369 --> 00:07:18,738
scenario. This is one that our

209
00:07:19,009 --> 00:07:20,920
customers have built that we've talked, uh,

210
00:07:21,290 --> 00:07:22,250
know what this looks like.

211
00:07:23,329 --> 00:07:25,488
Um, in this case, uh, you know, a

212
00:07:25,488 --> 00:07:26,428
financial institution,

213
00:07:26,889 --> 00:07:28,750
something gets flagged for potential financial crime,

214
00:07:29,329 --> 00:07:31,488
uh, they still are a human review

215
00:07:31,488 --> 00:07:32,389
process required,

216
00:07:32,730 --> 00:07:34,769
so these analysts are manually reviewing a

217
00:07:34,769 --> 00:07:36,588
lot of documents, transaction data.

218
00:07:37,548 --> 00:07:39,670
It's time intensive work and they

219
00:07:39,670 --> 00:07:41,778
want to accelerate this workflow

220
00:07:41,778 --> 00:07:43,920
for them. The requirements we're looking

221
00:07:43,920 --> 00:07:45,660
at for this application would be to

222
00:07:46,199 --> 00:07:48,269
process structured and unstructured data.

223
00:07:48,639 --> 00:07:49,290
We wanna generate

224
00:07:49,759 --> 00:07:51,738
really accurate, concise summaries.

225
00:07:52,028 --> 00:07:54,269
Um, this is a large scale, uh,

226
00:07:54,399 --> 00:07:56,519
and so we're looking at about 5 billion tokens per day.

227
00:07:56,639 --> 00:07:57,699
So we wanna make sure we're

228
00:07:57,959 --> 00:07:59,579
keeping that in mind as we're picking out

229
00:07:59,959 --> 00:08:02,079
the models we wanna use. And then of course security is

230
00:08:02,079 --> 00:08:02,639
essential.

231
00:08:03,079 --> 00:08:05,139
Um, the goal here would be to hit 20%

232
00:08:05,139 --> 00:08:06,858
efficiency for these humans

233
00:08:07,238 --> 00:08:09,358
workload and, and be able to work more quickly.

234
00:08:12,028 --> 00:08:12,629
So,

235
00:08:13,069 --> 00:08:15,329
the identification stage, um, I'll kinda

236
00:08:15,750 --> 00:08:17,488
go into more detail on this.

237
00:08:17,949 --> 00:08:20,019
Put simply, we're gonna filter out all the models

238
00:08:20,019 --> 00:08:22,069
that are relevant by modality and just consider

239
00:08:22,069 --> 00:08:23,709
the ones that are relevant for our use case.

240
00:08:24,619 --> 00:08:26,829
Next up we'll look at all those benchmarks. They are valuable.

241
00:08:26,869 --> 00:08:28,949
There is utility there, especially the

242
00:08:28,949 --> 00:08:30,569
more detailed benchmarks, and then

243
00:08:30,829 --> 00:08:32,830
considering benchmarks alongside other metrics that you

244
00:08:32,830 --> 00:08:33,509
care about.

245
00:08:33,989 --> 00:08:36,229
And finally we'll look at some differentiated capabilities.

246
00:08:36,308 --> 00:08:37,570
There's so much innovation.

247
00:08:38,019 --> 00:08:40,109
There's a lot of categories of models, but there's a few

248
00:08:40,109 --> 00:08:42,048
that I wanna highlight that really we're seeing

249
00:08:42,308 --> 00:08:44,029
matter for application success.

250
00:08:46,590 --> 00:08:48,769
So first up, modality. This one's relatively simple.

251
00:08:48,989 --> 00:08:51,029
What's the input type that the model

252
00:08:51,029 --> 00:08:53,190
can ingest and what's the output type

253
00:08:53,190 --> 00:08:54,690
that it, uh, that it

254
00:08:54,960 --> 00:08:55,570
provides?

255
00:08:55,950 --> 00:08:58,070
Um, huge amount of text data, of course,

256
00:08:58,109 --> 00:08:58,979
in business.

257
00:08:59,239 --> 00:09:01,308
A lot of these models were initially started there, so

258
00:09:01,308 --> 00:09:03,168
we've got some great options within text,

259
00:09:03,548 --> 00:09:05,830
but we're seeing, uh, you know, a lot of great use cases

260
00:09:05,830 --> 00:09:07,168
developed with an image input,

261
00:09:07,710 --> 00:09:09,830
video, audio, as well as the outputs,

262
00:09:09,840 --> 00:09:11,408
uh, of all of those modalities. So

263
00:09:11,668 --> 00:09:12,259
step one,

264
00:09:12,548 --> 00:09:14,690
just look at the models that are relevant for your use case.

265
00:09:16,599 --> 00:09:19,090
And here's a little view on what's available in Bedrock,

266
00:09:19,408 --> 00:09:21,479
uh, bi-modality this can be helpful, right?

267
00:09:21,529 --> 00:09:22,190
A lot of

268
00:09:22,509 --> 00:09:24,308
great models available within the text category,

269
00:09:24,769 --> 00:09:27,090
uh, multimodal input, so those are often text plus

270
00:09:27,090 --> 00:09:28,369
image, uh,

271
00:09:28,649 --> 00:09:30,548
also some video understanding available,

272
00:09:30,869 --> 00:09:32,869
um, multi-modal output, and then

273
00:09:32,869 --> 00:09:35,090
embeddings, a lot of growth in those

274
00:09:35,090 --> 00:09:36,798
areas. We're launching new models,

275
00:09:37,090 --> 00:09:38,168
uh, all the time and,

276
00:09:38,479 --> 00:09:40,090
uh, meeting more of our customers' needs that way.

277
00:09:43,058 --> 00:09:45,178
So we've got it filtered by modality. Now let's think

278
00:09:45,178 --> 00:09:46,349
about uh.

279
00:09:47,080 --> 00:09:48,960
A way to kind of compare quickly.

280
00:09:49,440 --> 00:09:51,558
Artificial analysis is a very popular third

281
00:09:51,558 --> 00:09:52,210
party resource.

282
00:09:52,798 --> 00:09:55,279
They provide an index and metrics

283
00:09:55,279 --> 00:09:55,859
for

284
00:09:56,200 --> 00:09:58,279
a huge range of models as

285
00:09:58,279 --> 00:09:59,918
well as, uh, inference providers,

286
00:10:00,320 --> 00:10:02,580
and it's nice to be able to go here and consider,

287
00:10:02,678 --> 00:10:04,058
you know, top intelligence,

288
00:10:04,599 --> 00:10:06,719
uh, and price or latency or whatever

289
00:10:06,719 --> 00:10:07,830
your, uh,

290
00:10:08,200 --> 00:10:09,580
metrics you care most about,

291
00:10:09,840 --> 00:10:10,500
um,

292
00:10:11,038 --> 00:10:13,119
side by side to kind of quickly evaluate what's

293
00:10:13,119 --> 00:10:14,099
the one that I might care about.

294
00:10:14,599 --> 00:10:16,719
Uh, they also provide this capability to do both X

295
00:10:16,719 --> 00:10:17,580
and Y axis.

296
00:10:18,320 --> 00:10:20,359
Find kind of the, the sweet spot quadrant where

297
00:10:20,359 --> 00:10:22,070
you've got, um, you know,

298
00:10:22,359 --> 00:10:24,460
optimal price, uh, to intelligence

299
00:10:24,460 --> 00:10:25,229
ratios.

300
00:10:25,519 --> 00:10:27,759
Uh, in this example we see a few of our bedrock models,

301
00:10:27,869 --> 00:10:29,158
uh, Claude Haiku,

302
00:10:29,678 --> 00:10:31,940
Deep Seek, as well as the GPT OSS models

303
00:10:32,200 --> 00:10:34,558
really standing out in, uh, really high intelligence,

304
00:10:34,678 --> 00:10:36,798
uh, but, but really considerably lower

305
00:10:36,798 --> 00:10:37,509
prices. So,

306
00:10:37,798 --> 00:10:39,178
uh, important to take note of that.

307
00:10:42,139 --> 00:10:44,178
I think the other thing I wanna make sure that we call out is

308
00:10:44,178 --> 00:10:46,558
that within uh benchmarks

309
00:10:46,940 --> 00:10:49,279
often we talk about just a single kind of

310
00:10:49,500 --> 00:10:52,000
combined intelligence score which is really valuable

311
00:10:52,000 --> 00:10:53,590
for rapid comparison

312
00:10:54,058 --> 00:10:56,099
but there are really detailed benchmarks and if

313
00:10:56,099 --> 00:10:58,178
you know you have something in your use case that's

314
00:10:58,178 --> 00:11:00,288
relevant for example long context

315
00:11:00,288 --> 00:11:00,840
reasoning

316
00:11:01,219 --> 00:11:03,489
uh. That's something that's really relevant

317
00:11:03,489 --> 00:11:05,808
in this use case we're talking about. You can look at specific

318
00:11:05,808 --> 00:11:08,168
benchmarks for that. In this case we've got Claude,

319
00:11:08,570 --> 00:11:10,500
uh, standing out alongside Deep Seek,

320
00:11:10,769 --> 00:11:13,048
uh, as some really good contenders for long context

321
00:11:13,048 --> 00:11:14,090
reasoning capabilities.

322
00:11:15,269 --> 00:11:17,869
This is also a an agentic

323
00:11:17,869 --> 00:11:19,519
application. So, um,

324
00:11:19,869 --> 00:11:21,869
I, I've highlighted here as well, uh, you

325
00:11:21,869 --> 00:11:24,190
know, we've got agentic tool use listed. This is an artificial

326
00:11:24,190 --> 00:11:25,450
analysis resource here,

327
00:11:25,869 --> 00:11:27,989
but Galileo is another agent leaderboard that's

328
00:11:27,989 --> 00:11:29,428
available. It's also Berkeley,

329
00:11:29,788 --> 00:11:30,889
uh, within Agenic.

330
00:11:31,879 --> 00:11:32,940
Leader boards you've got some,

331
00:11:33,440 --> 00:11:35,440
uh, a lot of variety, you know how is

332
00:11:35,440 --> 00:11:37,879
it as an orchestration or managing level

333
00:11:37,879 --> 00:11:39,940
model and how is it as kind of an executor,

334
00:11:40,399 --> 00:11:42,558
uh, worker, uh, model? How is the tool

335
00:11:42,558 --> 00:11:43,369
use selection?

336
00:11:43,678 --> 00:11:45,139
There's a lot of meaningful

337
00:11:45,440 --> 00:11:47,519
benchmarks that are available when you're trying to pick

338
00:11:47,519 --> 00:11:49,519
out the models and which role they should play within

339
00:11:49,519 --> 00:11:50,599
an agentic application.

340
00:11:52,619 --> 00:11:54,649
So this again filters down to kind

341
00:11:54,649 --> 00:11:56,729
of consider hey what's a couple of top models we should

342
00:11:56,729 --> 00:11:57,609
we should think about

343
00:11:57,889 --> 00:11:59,969
uh modalities done we're thinking about metrics

344
00:11:59,969 --> 00:12:00,759
where does the

345
00:12:01,129 --> 00:12:03,129
price performance or other kind of combined

346
00:12:03,129 --> 00:12:04,979
ratios, what benchmarks are really strong.

347
00:12:05,489 --> 00:12:07,029
I also wanna talk about a few other.

348
00:12:07,408 --> 00:12:09,408
Uh, categories of models, and these

349
00:12:09,408 --> 00:12:11,509
are ones that I decided to highlight because

350
00:12:11,509 --> 00:12:13,149
I'd see a lot of our customers,

351
00:12:13,460 --> 00:12:15,729
uh, drive a lot of success with these.

352
00:12:16,090 --> 00:12:18,288
Uh, there are others, but I really think these are the ones to focus

353
00:12:18,288 --> 00:12:20,330
on. First up is reasoning. Uh, you

354
00:12:20,330 --> 00:12:21,869
know, Deep Sek landed in January.

355
00:12:22,369 --> 00:12:24,489
Uh, there was reasoning models before then, but a lot of

356
00:12:24,489 --> 00:12:26,369
attention, a lot of major model providers,

357
00:12:26,729 --> 00:12:28,969
uh, adopted reasoning models as part of

358
00:12:28,969 --> 00:12:30,428
their even hybrid architecture.

359
00:12:30,798 --> 00:12:32,960
Uh, so there's a lot available, um,

360
00:12:33,109 --> 00:12:35,200
you know, reasoning models can do more complex

361
00:12:35,200 --> 00:12:37,229
step by step roles. Often again playing

362
00:12:37,229 --> 00:12:39,279
that orchestration role can be valuable in agentic

363
00:12:39,279 --> 00:12:40,099
use cases.

364
00:12:40,440 --> 00:12:41,899
They can explain the rationale,

365
00:12:42,639 --> 00:12:44,658
very, uh, useful,

366
00:12:45,000 --> 00:12:47,239
uh, when you need to kind of understand why

367
00:12:47,239 --> 00:12:50,019
the, the model made a choice. Uh, traceability,

368
00:12:50,080 --> 00:12:52,139
uh, is very, very nice to have through that

369
00:12:52,359 --> 00:12:54,000
method, of course, science, math, and coding.

370
00:12:54,308 --> 00:12:56,408
Within this category we have a variety available.

371
00:12:56,788 --> 00:12:58,908
The cloud models are good examples.

372
00:12:58,950 --> 00:13:01,109
The GPT OSS models. We've got models

373
00:13:01,109 --> 00:13:02,460
from Deep Seek from Quinn,

374
00:13:02,750 --> 00:13:04,788
and a number of others that are all, uh, reasoning

375
00:13:04,788 --> 00:13:07,369
models. Again,

376
00:13:07,408 --> 00:13:10,029
agentic, uh, you know, autonomous task completion,

377
00:13:10,450 --> 00:13:12,678
very exciting. I think the best practices are being

378
00:13:12,678 --> 00:13:15,070
developed, new offerings are being developed every day,

379
00:13:15,450 --> 00:13:16,250
uh, and.

380
00:13:17,000 --> 00:13:19,048
These are important to consider, you know, what's the tool

381
00:13:19,048 --> 00:13:21,389
selection capabilities, orchestration of multiple,

382
00:13:21,609 --> 00:13:23,509
uh, tools, uh, all the rest there.

383
00:13:24,950 --> 00:13:26,979
Customization is worth, uh, kind of pausing and

384
00:13:26,979 --> 00:13:29,048
considering as well. This tends to be dominated by

385
00:13:29,048 --> 00:13:31,359
open weight models. There are some abilities

386
00:13:31,359 --> 00:13:33,298
to customize proprietary models,

387
00:13:33,820 --> 00:13:36,279
but this is the category where we see the most popularity

388
00:13:36,619 --> 00:13:38,739
for open weight models where the, uh, models

389
00:13:38,739 --> 00:13:40,558
can be used to

390
00:13:40,899 --> 00:13:42,969
fine tune. And the, I'll say from

391
00:13:42,969 --> 00:13:45,210
our experience we're seeing customers

392
00:13:45,210 --> 00:13:47,340
fine tune when they have a very specific performance

393
00:13:47,340 --> 00:13:49,379
requirement they're having a hard time hitting in any other

394
00:13:49,379 --> 00:13:51,418
way. Nothing off the shelf is getting them.

395
00:13:51,928 --> 00:13:54,269
Uh, to the goal they need, and often it's latency

396
00:13:54,269 --> 00:13:56,489
sensitive. So if you have a user experience

397
00:13:56,489 --> 00:13:57,509
that requires a really quick

398
00:13:58,009 --> 00:13:59,989
model response time, uh,

399
00:14:00,389 --> 00:14:02,408
often we'll, we'll see a customer take a

400
00:14:02,408 --> 00:14:03,070
smaller model,

401
00:14:03,369 --> 00:14:05,609
distill from a larger, or really have a very specific

402
00:14:05,609 --> 00:14:06,250
use case.

403
00:14:06,548 --> 00:14:08,798
We're also seeing this grow in gentic applications.

404
00:14:09,090 --> 00:14:10,269
So if you've got a worker

405
00:14:10,529 --> 00:14:12,529
model that does a very specific task every

406
00:14:12,529 --> 00:14:14,570
time, you can fine tune a model and get really

407
00:14:14,570 --> 00:14:15,428
strong results

408
00:14:15,759 --> 00:14:17,389
hitting the latency and cost needs that you might

409
00:14:17,729 --> 00:14:19,840
require. So it's

410
00:14:19,840 --> 00:14:22,519
worth considering these open weight models, these customizable

411
00:14:22,519 --> 00:14:25,279
models as a candidate in your first identification

412
00:14:25,279 --> 00:14:25,820
stage

413
00:14:26,479 --> 00:14:27,918
in case you need to,

414
00:14:28,200 --> 00:14:30,320
uh, fine tune or want to have the option to fine tune

415
00:14:30,320 --> 00:14:32,359
later, uh, and we're seeing this also within

416
00:14:32,359 --> 00:14:34,779
a specific domain. Terminology may be relevant.

417
00:14:36,139 --> 00:14:38,259
And last, this domain specificity. This is

418
00:14:38,259 --> 00:14:39,269
something that's important.

419
00:14:39,619 --> 00:14:41,619
Uh, we're seeing a lot of models

420
00:14:41,619 --> 00:14:43,519
develop in this, uh,

421
00:14:44,340 --> 00:14:46,349
space. This, uh, I'd say finance,

422
00:14:46,460 --> 00:14:48,279
healthcare are two that really stand out.

423
00:14:48,808 --> 00:14:49,330
Um,

424
00:14:49,700 --> 00:14:51,700
this is, uh, driving more success if

425
00:14:51,700 --> 00:14:53,820
you have specific domains where the language is

426
00:14:53,820 --> 00:14:55,899
very relevant for that domain, you can

427
00:14:55,899 --> 00:14:58,259
sometimes get higher performance, higher intelligence in the model

428
00:14:58,259 --> 00:14:59,599
itself, uh.

429
00:14:59,928 --> 00:15:02,090
You know, Bedrock Marketplace has a lot of offerings

430
00:15:02,090 --> 00:15:02,690
in this,

431
00:15:02,969 --> 00:15:05,048
uh, area. Uh, a couple

432
00:15:05,048 --> 00:15:07,489
examples. Upstage is a really good model for

433
00:15:07,489 --> 00:15:08,529
Korean language translation.

434
00:15:09,229 --> 00:15:10,609
Uh, there's also

435
00:15:10,989 --> 00:15:13,369
from writer there's a Palmyra, uh, financial

436
00:15:13,830 --> 00:15:15,149
model as well as a healthcare model.

437
00:15:15,428 --> 00:15:17,668
So a few to consider, uh, as

438
00:15:17,668 --> 00:15:18,969
additional options to,

439
00:15:19,469 --> 00:15:21,590
um, that maybe if your, if your domain

440
00:15:21,590 --> 00:15:22,908
has some offering in that space.

441
00:15:24,788 --> 00:15:26,158
So back to our use case,

442
00:15:26,509 --> 00:15:28,950
let's look at the financial crimes investigation agent.

443
00:15:29,308 --> 00:15:31,750
Um, first step there, filter by modality.

444
00:15:31,830 --> 00:15:33,950
We just, these are just text problems that we're solving

445
00:15:33,950 --> 00:15:35,009
right now. So text to text,

446
00:15:35,440 --> 00:15:37,048
document analysis summarization.

447
00:15:37,428 --> 00:15:39,548
Um, we'd wanna look at those benchmarks. We, we considered

448
00:15:39,548 --> 00:15:42,210
summarization specifically long context reasoning,

449
00:15:42,538 --> 00:15:44,750
uh, some of these agentic capabilities

450
00:15:44,750 --> 00:15:46,158
as well, uh,

451
00:15:46,629 --> 00:15:48,629
down to the differentiated capabilities, and then I think it would

452
00:15:48,629 --> 00:15:50,769
be in this case because of the financial crimes

453
00:15:50,908 --> 00:15:53,298
there's some terminology we probably wanna include a customizable

454
00:15:53,298 --> 00:15:53,928
model as well.

455
00:15:54,440 --> 00:15:56,788
So that gives us a result, right? We're kinda going from

456
00:15:57,408 --> 00:15:59,408
all the models in the world down to a short list that we

457
00:15:59,408 --> 00:16:01,450
think could be really strong for this. This would

458
00:16:01,450 --> 00:16:02,889
include Cloud Sonnet,

459
00:16:03,210 --> 00:16:05,288
OpenAI, uh, GPTOSS in this

460
00:16:05,288 --> 00:16:06,139
case, and Deepeek

461
00:16:06,570 --> 00:16:08,129
V3.1. So,

462
00:16:08,408 --> 00:16:09,899
uh, that's the identify stage.

463
00:16:10,308 --> 00:16:12,330
Uh, I'm gonna now hand off to my colleague John

464
00:16:12,330 --> 00:16:14,649
Liu who's gonna talk through evaluation and optimization.

465
00:16:18,440 --> 00:16:19,000
Thank you.

466
00:16:20,619 --> 00:16:21,389
All right,

467
00:16:21,859 --> 00:16:23,859
so now we get to go into

468
00:16:23,859 --> 00:16:25,320
the evaluation stage,

469
00:16:25,658 --> 00:16:27,000
and when it comes to evaluation,

470
00:16:27,820 --> 00:16:29,820
as Scott mentioned earlier, it's

471
00:16:29,820 --> 00:16:32,038
important to have a framework in place to do this, right?

472
00:16:32,288 --> 00:16:34,918
Some of our customers have put in place frameworks

473
00:16:35,099 --> 00:16:37,298
that let them evaluate a model and

474
00:16:37,298 --> 00:16:39,820
decide whether they want to include that in their production workload

475
00:16:39,820 --> 00:16:41,558
within 24 to 48 hours,

476
00:16:42,058 --> 00:16:44,099
and today we're gonna present a framework that'll help

477
00:16:44,099 --> 00:16:46,259
you hopefully set something similar in

478
00:16:46,259 --> 00:16:48,418
place. When it comes to evaluation,

479
00:16:48,460 --> 00:16:50,619
the first step is always create your golden data set,

480
00:16:50,820 --> 00:16:53,359
which is that source of truth that you wanna benchmark

481
00:16:53,538 --> 00:16:55,279
all your models that you're trying

482
00:16:55,658 --> 00:16:57,479
against to see how well it performs.

483
00:16:58,269 --> 00:17:00,279
And then when you benchmark these models, you want

484
00:17:00,279 --> 00:17:02,279
to make sure you're continuously benchmarking

485
00:17:02,279 --> 00:17:04,279
the models because even if you don't change

486
00:17:04,279 --> 00:17:05,618
the model themselves,

487
00:17:06,160 --> 00:17:08,160
the incoming context might change

488
00:17:08,160 --> 00:17:10,098
which could lead to unexpected results.

489
00:17:11,880 --> 00:17:14,289
So let's go into our sample

490
00:17:14,289 --> 00:17:16,479
golden data set and see what that actually is

491
00:17:16,479 --> 00:17:18,500
about. The golden

492
00:17:18,500 --> 00:17:21,029
this data set is really just made up of two pieces,

493
00:17:21,219 --> 00:17:22,219
right? One

494
00:17:22,500 --> 00:17:24,098
is going to be the prompt.

495
00:17:24,420 --> 00:17:25,000
In this case,

496
00:17:25,500 --> 00:17:27,500
it describes out a particular use case we

497
00:17:27,500 --> 00:17:29,779
want to measure in our financial crimes agent.

498
00:17:30,689 --> 00:17:31,868
And the second part

499
00:17:32,289 --> 00:17:33,689
is the source of truth.

500
00:17:34,170 --> 00:17:34,828
This is

501
00:17:35,130 --> 00:17:37,318
why we call it the golden data set, the ground truth.

502
00:17:37,598 --> 00:17:39,029
This is what you want to measure

503
00:17:39,568 --> 00:17:41,809
your the models that you want to try against

504
00:17:41,809 --> 00:17:43,848
and see how close they come to

505
00:17:43,848 --> 00:17:44,890
this source of truth.

506
00:17:47,519 --> 00:17:49,608
When you create a golden data set, first you

507
00:17:49,608 --> 00:17:51,848
start with the basics. You want to have a

508
00:17:51,848 --> 00:17:54,049
comprehensive data set, about 100 use

509
00:17:54,049 --> 00:17:55,568
cases, right, of which,

510
00:17:55,890 --> 00:17:58,269
you know, you wanna choose. They're very specific

511
00:17:58,269 --> 00:18:00,108
to your particular terminology,

512
00:18:00,729 --> 00:18:02,868
the way that you're thinking of designing your workflow,

513
00:18:03,250 --> 00:18:05,068
because only by creating this

514
00:18:05,380 --> 00:18:06,650
tailored data set

515
00:18:07,009 --> 00:18:09,449
do you know whether the model that you selected

516
00:18:09,449 --> 00:18:11,630
is going to be useful for you, right? The,

517
00:18:11,769 --> 00:18:14,108
the. The generic benchmarks that Scott

518
00:18:14,108 --> 00:18:15,160
presented first,

519
00:18:15,439 --> 00:18:17,519
they're a very good starting point, but you want to

520
00:18:17,519 --> 00:18:19,559
see how much of that actually translates to the

521
00:18:19,559 --> 00:18:20,759
use case you have in mind.

522
00:18:22,338 --> 00:18:24,420
You also don't wanna just live in what we call the

523
00:18:24,420 --> 00:18:26,809
easy mode, right? You don't, you wanna also

524
00:18:26,809 --> 00:18:29,059
select cases that are adversarial, right?

525
00:18:29,140 --> 00:18:31,170
You wanna trip up the models because you're trying to

526
00:18:31,170 --> 00:18:31,959
define

527
00:18:32,489 --> 00:18:34,578
where the limits of your model is going to

528
00:18:34,578 --> 00:18:37,189
be. And typically

529
00:18:37,189 --> 00:18:39,348
these adversarial use cases, these tricky use

530
00:18:39,348 --> 00:18:41,250
cases, they make up about 5%

531
00:18:41,549 --> 00:18:43,328
of the 100 use cases that I mentioned earlier.

532
00:18:44,420 --> 00:18:45,318
And a good way to start,

533
00:18:45,759 --> 00:18:47,318
you set up 10 use cases

534
00:18:47,578 --> 00:18:49,858
and then you get an internal feedback loop

535
00:18:49,858 --> 00:18:52,019
with your subject matter experts and build that up

536
00:18:52,019 --> 00:18:52,640
to 100.

537
00:18:53,759 --> 00:18:56,170
But then as you're rolling out the production, you're introducing

538
00:18:56,170 --> 00:18:58,608
more models you're now thinking about 200-300

539
00:18:58,608 --> 00:19:00,368
use cases and

540
00:19:00,699 --> 00:19:02,920
potentially there's a better way to scale these golden

541
00:19:02,920 --> 00:19:05,269
data sets than continuously lean

542
00:19:05,489 --> 00:19:07,650
on human resources, right? Subject matter

543
00:19:07,650 --> 00:19:08,989
experts are expensive.

544
00:19:09,939 --> 00:19:12,078
So let's take a look if we can do that.

545
00:19:14,539 --> 00:19:16,578
What humans are not so

546
00:19:16,578 --> 00:19:18,739
great at or not very efficient at doing,

547
00:19:19,019 --> 00:19:21,368
you know, is all these detailed tasks,

548
00:19:21,459 --> 00:19:23,699
right, these detailed low level tasks

549
00:19:23,699 --> 00:19:25,848
or trying to create multiple iterations

550
00:19:25,848 --> 00:19:26,930
of data sets

551
00:19:27,219 --> 00:19:29,529
or reading detailed SOPs, standard

552
00:19:29,529 --> 00:19:31,640
operating procedures, and translating that

553
00:19:31,640 --> 00:19:33,880
and making sure that's captured in your golden data set.

554
00:19:34,729 --> 00:19:35,519
We can do it,

555
00:19:35,848 --> 00:19:36,759
but it's not efficient.

556
00:19:38,838 --> 00:19:40,920
And what humans are quite good at doing, a

557
00:19:40,920 --> 00:19:41,828
good use of our

558
00:19:42,279 --> 00:19:43,410
intuition, right,

559
00:19:43,719 --> 00:19:45,578
is the high level judgment that we have.

560
00:19:46,338 --> 00:19:47,598
And we're also quite good

561
00:19:47,979 --> 00:19:50,219
at looking at total frameworks

562
00:19:50,219 --> 00:19:52,219
and seeing hey what works well and what

563
00:19:52,219 --> 00:19:53,199
doesn't work well.

564
00:19:54,848 --> 00:19:56,920
So you see here there are 3 things

565
00:19:56,920 --> 00:19:57,769
high level judgment,

566
00:19:58,049 --> 00:19:59,809
setting rules and standards through rubrics,

567
00:20:00,088 --> 00:20:02,368
and then looking for ways to improve solutions.

568
00:20:03,858 --> 00:20:05,900
So if there's a way that we can leverage the

569
00:20:05,900 --> 00:20:06,930
strength of humans

570
00:20:07,259 --> 00:20:09,259
and then delegate we're called the low level

571
00:20:09,259 --> 00:20:10,578
tasks to agents,

572
00:20:10,900 --> 00:20:13,358
then we've got a pretty good solution to help us scale

573
00:20:13,539 --> 00:20:15,539
our golden data set from that 100 to the

574
00:20:15,539 --> 00:20:17,338
200, 300 type of use cases.

575
00:20:18,250 --> 00:20:20,368
And now let's look what that actually looks like.

576
00:20:21,439 --> 00:20:22,459
We start with

577
00:20:23,199 --> 00:20:25,199
the first agent, right? This is the

578
00:20:25,199 --> 00:20:26,299
user simulator,

579
00:20:26,680 --> 00:20:29,170
and this you can think of that is actually the KYC

580
00:20:29,170 --> 00:20:30,858
expert. He's doing work

581
00:20:31,160 --> 00:20:33,239
to find out whether there's a potential

582
00:20:33,239 --> 00:20:35,269
financial crime associated or fraudulent

583
00:20:35,269 --> 00:20:35,838
detection,

584
00:20:36,118 --> 00:20:38,160
fraudulent activity associated with this,

585
00:20:38,199 --> 00:20:39,539
uh, particular transaction.

586
00:20:41,439 --> 00:20:44,150
You have a very descriptive mission

587
00:20:44,150 --> 00:20:46,170
for the agent and a persona and

588
00:20:46,170 --> 00:20:47,630
then some example questions

589
00:20:48,009 --> 00:20:49,750
because the more descriptive you are

590
00:20:50,130 --> 00:20:52,130
with your agents, the more accurate they're going

591
00:20:52,130 --> 00:20:54,519
to be. You

592
00:20:54,519 --> 00:20:56,650
pair this user simulator with

593
00:20:56,650 --> 00:20:57,729
your task agent,

594
00:20:58,209 --> 00:21:00,209
and this is the agent that actually goes through and does

595
00:21:00,209 --> 00:21:02,449
all the work, you know, looks through all the documents,

596
00:21:02,568 --> 00:21:03,348
looks through the

597
00:21:03,809 --> 00:21:05,828
online offline credit cards, for example,

598
00:21:06,068 --> 00:21:08,130
synthesize that information and comes

599
00:21:08,130 --> 00:21:10,420
back with a recommendation to the user

600
00:21:10,729 --> 00:21:12,848
saying, hey, is this a fraudulent or

601
00:21:12,848 --> 00:21:14,009
not fraudulent activity?

602
00:21:15,029 --> 00:21:17,390
Here you can see again mission persona

603
00:21:17,390 --> 00:21:19,868
described and they have an action

604
00:21:20,229 --> 00:21:22,348
they have tool calls because they're actually going

605
00:21:22,348 --> 00:21:23,930
through and pulling in this information.

606
00:21:25,229 --> 00:21:27,509
Finally, you pair this with the critique

607
00:21:27,509 --> 00:21:28,118
agent,

608
00:21:29,108 --> 00:21:30,568
and this is the actual

609
00:21:30,910 --> 00:21:32,930
um agent that looks through

610
00:21:33,150 --> 00:21:35,269
how close the task agent is

611
00:21:35,269 --> 00:21:37,289
or how well the task agent performs

612
00:21:37,709 --> 00:21:39,650
against a set of rubrics or rules

613
00:21:39,949 --> 00:21:41,930
that the subject matter expert, the human,

614
00:21:42,229 --> 00:21:43,170
set in place earlier.

615
00:21:43,660 --> 00:21:45,809
Here you see the mission and your job is

616
00:21:45,809 --> 00:21:47,900
to go and evaluate the task agent, make sure it does a

617
00:21:47,900 --> 00:21:50,259
good job, and your persona, you're an expert

618
00:21:50,259 --> 00:21:52,259
teacher and you've got some tools

619
00:21:52,259 --> 00:21:54,420
as well. Your, your actions are, you

620
00:21:54,420 --> 00:21:57,019
have some global rec global like evaluation

621
00:21:57,019 --> 00:21:59,049
methods, and you have some relative evaluation

622
00:21:59,049 --> 00:22:00,759
methods that you call dynamically

623
00:22:01,019 --> 00:22:03,459
when you're actually evaluating the task agent

624
00:22:03,459 --> 00:22:05,529
itself. Let's

625
00:22:05,529 --> 00:22:06,348
put that together

626
00:22:07,910 --> 00:22:09,920
We have our user simulator agent.

627
00:22:10,279 --> 00:22:12,318
It passed through a request over to the

628
00:22:12,318 --> 00:22:13,118
task agent.

629
00:22:13,939 --> 00:22:16,229
Now paired with this of course is our critique agent

630
00:22:16,459 --> 00:22:18,529
which is reading rules from this rubric that was

631
00:22:18,529 --> 00:22:20,000
defined by the humans.

632
00:22:21,209 --> 00:22:22,430
The critique agent

633
00:22:22,848 --> 00:22:24,930
continuously iterates what the results

634
00:22:24,930 --> 00:22:26,209
are from the task agent

635
00:22:26,729 --> 00:22:29,108
until the critique agent says yes.

636
00:22:29,689 --> 00:22:31,729
The response that you gave meets the

637
00:22:31,729 --> 00:22:33,269
rubrics that were set in place,

638
00:22:33,529 --> 00:22:34,588
and at that point,

639
00:22:34,848 --> 00:22:36,890
the critique agent of course passes the correct answer

640
00:22:36,890 --> 00:22:37,670
back to

641
00:22:37,930 --> 00:22:40,009
the, the task agent, and the task agent now

642
00:22:40,009 --> 00:22:42,420
sends it to user simulator, but also the critique

643
00:22:42,420 --> 00:22:44,640
critique agent passes that to the golden

644
00:22:44,640 --> 00:22:46,769
data set. So now you're automatically scaling your

645
00:22:46,769 --> 00:22:47,489
golden data set.

646
00:22:48,588 --> 00:22:49,489
Now where's the human,

647
00:22:49,828 --> 00:22:52,029
right? The human

648
00:22:52,489 --> 00:22:54,630
is actually evaluating this entire system

649
00:22:54,630 --> 00:22:57,019
at this time, right? They're not in the detailed

650
00:22:57,019 --> 00:22:59,189
weeds of like looking at every single one of these,

651
00:22:59,489 --> 00:23:01,709
these, um, responses. They look at how

652
00:23:01,709 --> 00:23:03,729
the overall framework behaves, and

653
00:23:03,729 --> 00:23:05,848
they can make suggestions that says how can I

654
00:23:05,848 --> 00:23:08,309
improve how the critique agent is actually

655
00:23:08,309 --> 00:23:10,328
guiding the task agent. Maybe we

656
00:23:10,328 --> 00:23:12,568
need to have more tables that are coming

657
00:23:12,568 --> 00:23:13,828
through so it's easier for

658
00:23:14,130 --> 00:23:16,130
our, our cus our customers to

659
00:23:16,130 --> 00:23:18,578
read. So they update the rubric

660
00:23:18,838 --> 00:23:21,059
and now this entire golden disk set

661
00:23:21,059 --> 00:23:23,239
gets stronger and the rubric gets stronger

662
00:23:23,239 --> 00:23:23,858
as well.

663
00:23:25,930 --> 00:23:26,989
Now to build this,

664
00:23:27,689 --> 00:23:29,799
customers can benefit from AWS's

665
00:23:29,799 --> 00:23:30,809
Agentic stack.

666
00:23:31,368 --> 00:23:33,489
Customers can start with the open source

667
00:23:33,489 --> 00:23:35,689
framework strands and very

668
00:23:35,689 --> 00:23:37,910
quickly build, deploy locally

669
00:23:38,250 --> 00:23:38,848
agents.

670
00:23:39,469 --> 00:23:41,130
And as they're ready to scale,

671
00:23:41,549 --> 00:23:43,469
they can now lean on agent core

672
00:23:43,910 --> 00:23:45,989
and benefit from enterprise grade

673
00:23:45,989 --> 00:23:48,348
security and also dedicated runtime

674
00:23:48,348 --> 00:23:49,809
environments and memory management

675
00:23:50,269 --> 00:23:52,549
and there were lots of announcements this reinvents

676
00:23:53,309 --> 00:23:54,390
around our agent core.

677
00:23:57,559 --> 00:23:58,338
So we've gone through,

678
00:23:58,640 --> 00:24:00,098
we've created our golden data set.

679
00:24:01,118 --> 00:24:03,439
Now we get into the metrics that we want to evaluate

680
00:24:03,439 --> 00:24:05,739
against. The operational metrics

681
00:24:05,739 --> 00:24:07,930
are the foundational piece,

682
00:24:08,309 --> 00:24:10,150
cost, latency, and scalability.

683
00:24:11,049 --> 00:24:12,640
Just like almost any software, right?

684
00:24:13,469 --> 00:24:15,630
Um, some things to keep in mind, of course, is

685
00:24:15,630 --> 00:24:17,709
when you're actually measuring these operational

686
00:24:17,709 --> 00:24:19,910
metrics, make sure you're sending in inference

687
00:24:19,910 --> 00:24:22,170
requests that cover a variety

688
00:24:22,170 --> 00:24:24,269
of, um, patterns, right? You wanna look

689
00:24:24,269 --> 00:24:26,509
for your P95, your P99

690
00:24:26,789 --> 00:24:28,789
type of response context window lens so

691
00:24:28,789 --> 00:24:29,489
you can find out

692
00:24:29,789 --> 00:24:31,910
what the latency is, and you also want

693
00:24:31,910 --> 00:24:34,150
to send a variety of different workloads

694
00:24:34,150 --> 00:24:36,608
so you can see where the model or the model serving

695
00:24:36,608 --> 00:24:37,328
solution you're using

696
00:24:37,750 --> 00:24:38,809
runs into errors.

697
00:24:40,318 --> 00:24:41,130
Once you have your

698
00:24:41,858 --> 00:24:44,009
operational metrics covered, you can move into

699
00:24:44,309 --> 00:24:46,709
the comprehensive evaluation metrics

700
00:24:46,709 --> 00:24:48,989
around semantics knowledge, right?

701
00:24:49,348 --> 00:24:50,410
So you've probably seen

702
00:24:50,789 --> 00:24:53,279
the quality and accuracy, the style and usability,

703
00:24:53,449 --> 00:24:55,509
responsible AI. This is

704
00:24:55,509 --> 00:24:56,289
pretty much again,

705
00:24:56,828 --> 00:24:57,809
um, ground.

706
00:24:58,890 --> 00:25:00,920
Foundational aspects that customers are

707
00:25:00,920 --> 00:25:01,650
now used to.

708
00:25:03,328 --> 00:25:05,328
However, as customers have been rolling these

709
00:25:05,328 --> 00:25:07,479
into production over the last year, they've

710
00:25:07,479 --> 00:25:10,029
also introduced their own custom metrics,

711
00:25:10,650 --> 00:25:12,890
because what these custom metrics actually

712
00:25:12,890 --> 00:25:14,920
measure, just like any software, there are

713
00:25:14,920 --> 00:25:16,979
KPIs that you wanna bring in. For example,

714
00:25:17,049 --> 00:25:19,088
it could be click through rates of a

715
00:25:19,088 --> 00:25:20,289
particular task you wanna get done,

716
00:25:21,328 --> 00:25:23,029
or it could be, you know, the

717
00:25:23,328 --> 00:25:25,809
type of overrides any time a, a

718
00:25:25,809 --> 00:25:28,170
particular user decides to override what the agent does,

719
00:25:28,309 --> 00:25:30,229
maybe that's another KPI you wanna bring in.

720
00:25:30,660 --> 00:25:32,670
So keep these in mind as

721
00:25:32,670 --> 00:25:34,809
you're evaluating your model. Don't just

722
00:25:34,809 --> 00:25:35,949
lean on the

723
00:25:36,368 --> 00:25:38,650
tried and true quality and accuracy. These are important,

724
00:25:38,890 --> 00:25:41,009
but bring in the actual custom metrics from your

725
00:25:41,009 --> 00:25:41,949
workload as well.

726
00:25:44,348 --> 00:25:46,029
Some other metrics to keep in mind,

727
00:25:46,608 --> 00:25:48,650
and, you know, it's a temporal consistency I mentioned a little

728
00:25:48,650 --> 00:25:50,750
bit earlier, you have to consistently look

729
00:25:50,750 --> 00:25:53,189
and evaluate your model. You don't wanna make sure you want tech

730
00:25:53,189 --> 00:25:54,529
model drift early on.

731
00:25:55,068 --> 00:25:57,328
And as you're introducing more modalities,

732
00:25:57,588 --> 00:25:59,739
you wanna make sure you're measuring the modality not just

733
00:25:59,739 --> 00:26:01,750
in isolation but also as they interact

734
00:26:01,750 --> 00:26:02,449
with each other.

735
00:26:03,380 --> 00:26:05,509
And finally agentic capabilities, right? How

736
00:26:05,509 --> 00:26:07,549
well is your entire system or

737
00:26:07,549 --> 00:26:09,769
your entire model behaving when it's calling

738
00:26:09,769 --> 00:26:11,880
tools or when it's actually orchestrating across

739
00:26:11,880 --> 00:26:12,739
different agents.

740
00:26:15,279 --> 00:26:17,469
So we've gone through, we've got our metrics.

741
00:26:17,828 --> 00:26:19,828
Let's look at what methods are used to

742
00:26:19,828 --> 00:26:20,519
evaluate

743
00:26:20,989 --> 00:26:21,769
these models

744
00:26:22,189 --> 00:26:23,509
and really break down into 3,

745
00:26:23,828 --> 00:26:25,959
right. We start with the benchmarks,

746
00:26:26,009 --> 00:26:26,868
the programmatic

747
00:26:27,130 --> 00:26:28,390
type of evaluations,

748
00:26:28,680 --> 00:26:30,689
and these are really good when it has like a true

749
00:26:30,689 --> 00:26:32,880
right or wrong answer. You can think of, uh,

750
00:26:32,890 --> 00:26:34,779
benchmarks like the MMLU,

751
00:26:35,400 --> 00:26:37,269
which measures how good a model

752
00:26:37,650 --> 00:26:39,689
behaves for translation, or you could

753
00:26:39,689 --> 00:26:41,689
GM 8 SK, which measures how good

754
00:26:41,689 --> 00:26:43,769
a model is for mathematic calculations,

755
00:26:43,858 --> 00:26:45,368
right? Very good starting point.

756
00:26:46,449 --> 00:26:48,959
But if you wanna pick up the nuances of

757
00:26:49,140 --> 00:26:51,328
like summarization or how people talk,

758
00:26:51,660 --> 00:26:53,699
how people think, right, then you start leaning

759
00:26:53,699 --> 00:26:55,818
on humans, right? That's this is where human

760
00:26:55,818 --> 00:26:57,818
evaluation comes in. Your subject matters have

761
00:26:57,818 --> 00:26:59,818
to come in and look for those nuanced

762
00:26:59,818 --> 00:27:01,818
semantic type of evaluation.

763
00:27:02,930 --> 00:27:04,269
Now to help us scale

764
00:27:04,848 --> 00:27:05,989
we can now lean on

765
00:27:06,489 --> 00:27:08,608
models as well because they've got much deeper

766
00:27:08,608 --> 00:27:10,689
reasoning capabilities that's been developed over

767
00:27:10,689 --> 00:27:12,828
the last year. So customers are now using

768
00:27:12,828 --> 00:27:15,049
powerful models whether it's a single powerful

769
00:27:15,049 --> 00:27:17,088
model as a judge to evaluate the output of

770
00:27:17,088 --> 00:27:19,170
other models, or they put in

771
00:27:19,170 --> 00:27:19,709
place

772
00:27:20,170 --> 00:27:22,630
maybe 10 to 12 lightweight models

773
00:27:22,769 --> 00:27:24,890
and as as a jury evaluate

774
00:27:24,890 --> 00:27:27,130
the output of the model that's being

775
00:27:27,130 --> 00:27:27,809
evaluated.

776
00:27:30,078 --> 00:27:32,279
Amazon Bedrock model evaluation supports all

777
00:27:32,279 --> 00:27:34,549
three of these, right? We've got our programmatic

778
00:27:34,549 --> 00:27:35,140
evaluation,

779
00:27:35,479 --> 00:27:37,519
the human evaluation, and also

780
00:27:37,519 --> 00:27:38,618
LM is a judge.

781
00:27:39,118 --> 00:27:39,858
Importantly,

782
00:27:40,279 --> 00:27:41,880
we also support custom metrics.

783
00:27:42,818 --> 00:27:44,910
And if you want to evaluate

784
00:27:44,910 --> 00:27:47,219
models that are not directly within Bedrock,

785
00:27:47,229 --> 00:27:49,949
you can do that too. You can bring the responses

786
00:27:49,949 --> 00:27:51,989
from those models and run them through Amazon

787
00:27:51,989 --> 00:27:53,269
Bedrock model evaluation.

788
00:27:56,009 --> 00:27:58,130
So let's dive a little bit under EM as

789
00:27:58,130 --> 00:28:00,170
a judge because that's what we're gonna use for our

790
00:28:00,170 --> 00:28:02,289
financial crimes agent that we've been using

791
00:28:02,289 --> 00:28:03,309
as our reference case.

792
00:28:04,338 --> 00:28:06,338
Under the hood, what actually happens is

793
00:28:06,338 --> 00:28:08,640
we've optimized the prompts

794
00:28:08,650 --> 00:28:10,769
for a variety, a variety of our evaluator

795
00:28:10,769 --> 00:28:12,739
models which include the anthropic models,

796
00:28:13,019 --> 00:28:15,209
some of the meta models, and Nova models

797
00:28:15,209 --> 00:28:15,719
as well.

798
00:28:16,900 --> 00:28:18,439
We tell it how to behave

799
00:28:18,739 --> 00:28:21,059
and we tell it what type of response to give.

800
00:28:22,009 --> 00:28:24,209
And what gets passed in is the Jason

801
00:28:24,209 --> 00:28:25,750
online file of

802
00:28:26,170 --> 00:28:28,729
the golden data set, right? Here's all my prompts,

803
00:28:29,009 --> 00:28:31,088
here's my reference answer, and

804
00:28:31,088 --> 00:28:33,088
here's also the response from

805
00:28:33,088 --> 00:28:35,180
the model that you're gonna evaluate against.

806
00:28:37,068 --> 00:28:39,150
And to set this up with Amazon

807
00:28:39,150 --> 00:28:40,539
Bedrock model evaluation,

808
00:28:40,900 --> 00:28:43,019
you start with selecting the models. There are two

809
00:28:43,019 --> 00:28:43,848
things you want to select

810
00:28:44,229 --> 00:28:46,130
the model you want to be the evaluator.

811
00:28:46,729 --> 00:28:48,809
And the model you want to evaluate in this

812
00:28:48,809 --> 00:28:51,328
case we're picking the Sona 37

813
00:28:51,539 --> 00:28:54,309
as the evaluator and then we're gonna evaluate the GPTOS

814
00:28:54,598 --> 00:28:55,209
120B.

815
00:28:57,009 --> 00:28:58,588
You select the metrics, right?

816
00:28:59,098 --> 00:29:01,098
Um, Amazon Bedrock model evaluation has

817
00:29:01,098 --> 00:29:03,259
12 metrics, and of course you can also

818
00:29:03,259 --> 00:29:05,479
import your custom metrics as mentioned earlier.

819
00:29:05,930 --> 00:29:06,719
And now you run

820
00:29:07,009 --> 00:29:08,219
the model evaluation

821
00:29:08,539 --> 00:29:10,739
and you get a result and you can compare different models

822
00:29:10,739 --> 00:29:13,939
against each other. In this case I've run a simple evaluation

823
00:29:13,939 --> 00:29:16,059
against the GPT OSS as mentioned earlier and

824
00:29:16,059 --> 00:29:17,670
also Deep Seek V3.1,

825
00:29:17,930 --> 00:29:20,059
and you can see a radar chart of how well

826
00:29:20,059 --> 00:29:20,719
they perform.

827
00:29:23,259 --> 00:29:25,489
You can dive deep a little bit as well, like

828
00:29:25,868 --> 00:29:28,250
into each of the prompts that you're evaluating,

829
00:29:28,549 --> 00:29:30,250
it gives you a score. Did it

830
00:29:30,588 --> 00:29:32,949
from 0 to 1, or 1 being the best score.

831
00:29:33,818 --> 00:29:35,900
And if I want to dive in and understand

832
00:29:35,900 --> 00:29:38,059
why I got a score as such, I can do that too.

833
00:29:38,259 --> 00:29:40,279
I click in and it have an explanation.

834
00:29:40,618 --> 00:29:42,779
In this case it got a one because guess

835
00:29:42,779 --> 00:29:45,160
what? The valdo that you're evaluating

836
00:29:45,420 --> 00:29:46,880
matched very well

837
00:29:47,140 --> 00:29:49,180
with the ground truth that you actually gave in.

838
00:29:53,348 --> 00:29:55,719
Now we can move into the optimized

839
00:29:55,719 --> 00:29:58,219
state, and we've gone through, we've evaluated,

840
00:29:58,549 --> 00:30:00,858
we have a set of models that we want to choose against.

841
00:30:02,680 --> 00:30:03,949
And when we think about optimizing,

842
00:30:04,328 --> 00:30:06,489
we wanna start by thinking it's not just optimizing

843
00:30:06,489 --> 00:30:08,729
a single model, you optimize the entire

844
00:30:08,729 --> 00:30:09,269
system,

845
00:30:09,890 --> 00:30:12,049
so you can choose single models to

846
00:30:12,049 --> 00:30:14,170
replace and you can also introduce multiple

847
00:30:14,170 --> 00:30:16,170
models you can optimize the entire end

848
00:30:16,170 --> 00:30:17,068
to end workflow.

849
00:30:18,078 --> 00:30:20,410
You can further customize individual models

850
00:30:20,410 --> 00:30:22,598
through fine tuning and distillation

851
00:30:22,920 --> 00:30:25,358
and then you can optimize how you're sending your inference

852
00:30:25,358 --> 00:30:27,259
requests for cost and latency

853
00:30:27,598 --> 00:30:28,338
as an example,

854
00:30:28,640 --> 00:30:29,779
you know, we announced.

855
00:30:30,358 --> 00:30:32,019
The inference tiers

856
00:30:32,818 --> 00:30:33,979
that was in today's

857
00:30:34,400 --> 00:30:36,549
today's the Dave Brown keynote actually he's talking

858
00:30:36,549 --> 00:30:37,969
about the inference tiers around that

859
00:30:38,239 --> 00:30:39,618
and there that's where you actually

860
00:30:40,039 --> 00:30:42,239
pay a little premium, for example, to

861
00:30:42,239 --> 00:30:44,239
access the priority tiers to make sure that your inference

862
00:30:44,239 --> 00:30:45,219
are at the top of the line

863
00:30:45,519 --> 00:30:47,598
or you maybe for the less time sensitive

864
00:30:47,598 --> 00:30:49,598
ones you can pay up to a 50% discount

865
00:30:49,838 --> 00:30:51,838
and use the flex tier, and this is how

866
00:30:51,838 --> 00:30:52,900
you start optimizing

867
00:30:53,279 --> 00:30:55,838
cost and versus the kind of latency.

868
00:30:58,368 --> 00:31:00,368
And when it comes to optimizing these multiple

869
00:31:00,368 --> 00:31:02,809
models, you have to consider the routing strategies

870
00:31:02,809 --> 00:31:04,930
you have, and they're really just 4 things

871
00:31:04,930 --> 00:31:06,390
I'd like to share with you today.

872
00:31:06,769 --> 00:31:08,489
You can start with rule-based routing. You can

873
00:31:08,930 --> 00:31:10,670
go through, look at the queries,

874
00:31:10,930 --> 00:31:12,848
single, simple queries, use light model,

875
00:31:13,150 --> 00:31:15,328
complex queries, use the heavier models. Private

876
00:31:15,328 --> 00:31:17,368
queries, if it's highly sensitive ones, and

877
00:31:17,368 --> 00:31:19,410
maybe I wanna use a model that I'm hosting

878
00:31:19,410 --> 00:31:21,489
myself. But that

879
00:31:21,489 --> 00:31:23,689
has a challenge too. This means that someone's

880
00:31:23,689 --> 00:31:25,269
always writing these rules,

881
00:31:25,979 --> 00:31:28,009
so we can benefit from machine learning

882
00:31:28,009 --> 00:31:28,828
based routing

883
00:31:29,608 --> 00:31:32,088
using classic machine learning. You can train classifiers

884
00:31:32,088 --> 00:31:34,368
around the data set that you have and then route

885
00:31:34,368 --> 00:31:36,809
these incoming inference requests to the proper model.

886
00:31:37,348 --> 00:31:39,489
Of course the challenge there is you need a training data

887
00:31:39,489 --> 00:31:41,489
set. So

888
00:31:41,489 --> 00:31:42,828
you can further benefit

889
00:31:43,170 --> 00:31:45,229
from using the LLMs themselves, right? The

890
00:31:45,229 --> 00:31:47,250
LMs themselves can look at the incoming data and say,

891
00:31:47,328 --> 00:31:49,529
well, based on this, we think the profile matches,

892
00:31:49,650 --> 00:31:52,009
we should send it to what type of model light,

893
00:31:52,328 --> 00:31:53,108
medium, heavy.

894
00:31:53,920 --> 00:31:56,029
And then you can further fine tune that as

895
00:31:56,029 --> 00:31:56,809
you get more data.

896
00:31:58,259 --> 00:32:00,318
The best way, of course, combine all three of them,

897
00:32:00,420 --> 00:32:02,618
right, that gives you a very robust way to route

898
00:32:02,618 --> 00:32:04,799
these inference requests to the different models.

899
00:32:07,939 --> 00:32:10,189
When you look at the individual models themselves,

900
00:32:10,348 --> 00:32:12,430
you can customize them through a variety of methods

901
00:32:12,430 --> 00:32:13,729
through Amazon Bedrock.

902
00:32:14,390 --> 00:32:16,489
You can do straight fine tuning

903
00:32:16,910 --> 00:32:19,509
and you can also do distillation

904
00:32:19,509 --> 00:32:21,709
where you take a teacher model and then

905
00:32:21,709 --> 00:32:23,189
bring the knowledge of that

906
00:32:23,469 --> 00:32:24,809
into a lighter model,

907
00:32:25,670 --> 00:32:27,250
or you can do some advanced

908
00:32:27,549 --> 00:32:30,289
customization on your own through maybe SageMaker

909
00:32:30,430 --> 00:32:32,509
and bring those models into Bedrock

910
00:32:32,509 --> 00:32:34,809
through Amazon Bedrock's custom model import.

911
00:32:36,059 --> 00:32:37,739
And we just announced Nova Forge,

912
00:32:38,019 --> 00:32:40,578
um, about two days ago, and that further

913
00:32:40,578 --> 00:32:42,699
helps customers customize their

914
00:32:43,059 --> 00:32:44,279
models because now

915
00:32:44,578 --> 00:32:46,739
you can not just benefit from

916
00:32:46,739 --> 00:32:48,920
your own data set, you can benefit from

917
00:32:49,170 --> 00:32:51,299
Nova's pre-trained data set as well. You can

918
00:32:51,299 --> 00:32:53,410
bring these two data sets together and train the

919
00:32:53,410 --> 00:32:56,900
models. So

920
00:32:56,900 --> 00:32:59,209
looking at our financial crimes

921
00:32:59,209 --> 00:33:01,229
investigation agent after these two steps, what are we looking

922
00:33:01,229 --> 00:33:04,618
at? Well, we've got the GBTOSS

923
00:33:04,618 --> 00:33:06,779
120 for fast classification tasks,

924
00:33:07,059 --> 00:33:09,880
and then now we've got the sonnet for the complex analysis

925
00:33:10,459 --> 00:33:12,578
and we fine tuned the

926
00:33:12,578 --> 00:33:13,959
GBTOSS model

927
00:33:14,699 --> 00:33:16,699
and then we optimize our inference through the different

928
00:33:16,699 --> 00:33:19,078
inference tiers that I mentioned, which leads us

929
00:33:19,858 --> 00:33:21,318
to an 80% reduction

930
00:33:21,939 --> 00:33:24,259
while scaling the workload from 500 million inference

931
00:33:24,259 --> 00:33:25,680
requests to 5 billion per day.

932
00:33:26,459 --> 00:33:28,509
And we've not talked about

933
00:33:28,509 --> 00:33:30,709
the customer behind this, but this is a real customer use

934
00:33:30,709 --> 00:33:32,009
case that we've seen in production.

935
00:33:32,779 --> 00:33:34,078
Benefiting from

936
00:33:34,380 --> 00:33:36,459
model choice, the optimizations,

937
00:33:36,618 --> 00:33:38,479
the framework that we've talked about so far.

938
00:33:40,789 --> 00:33:42,650
Now let's review and just put it all together.

939
00:33:43,559 --> 00:33:45,529
In our three step framework in action,

940
00:33:45,959 --> 00:33:48,299
we start with the identify state.

941
00:33:48,799 --> 00:33:50,959
You have a library of models that you wanna look at.

942
00:33:51,279 --> 00:33:53,318
You review the general benchmarks that are out there,

943
00:33:53,400 --> 00:33:54,380
the modalities,

944
00:33:54,880 --> 00:33:56,779
and then you select from there

945
00:33:57,039 --> 00:33:59,549
the models you want and you evaluate these models

946
00:33:59,549 --> 00:34:01,680
against your specific use case, against the

947
00:34:01,680 --> 00:34:03,180
golden data set that you've created.

948
00:34:05,180 --> 00:34:07,259
You then optimize the setup that

949
00:34:07,259 --> 00:34:09,458
you have and you can have single model

950
00:34:09,458 --> 00:34:11,458
type of workloads you can have multiple model type

951
00:34:11,458 --> 00:34:12,300
of workloads.

952
00:34:12,958 --> 00:34:15,320
And importantly, you wanna get all this

953
00:34:15,320 --> 00:34:17,478
information and bring that feedback so you can

954
00:34:17,478 --> 00:34:19,478
improve your particular framework,

955
00:34:19,559 --> 00:34:21,918
including monitoring for latency, cost,

956
00:34:22,119 --> 00:34:23,208
and accuracy.

957
00:34:24,018 --> 00:34:24,958
And also

958
00:34:25,458 --> 00:34:27,748
getting the real-time user feedback

959
00:34:28,018 --> 00:34:30,128
and having that information improve that

960
00:34:30,128 --> 00:34:31,039
golden data set.

961
00:34:32,570 --> 00:34:34,610
Another benefit of having a strong golden data

962
00:34:34,610 --> 00:34:37,050
set doesn't just power up the model evaluation

963
00:34:37,050 --> 00:34:37,679
that you have,

964
00:34:38,000 --> 00:34:40,659
you can also use it to fine tune

965
00:34:40,929 --> 00:34:41,530
models,

966
00:34:41,889 --> 00:34:44,250
so you get almost like 2 for the price of 1.

967
00:34:45,250 --> 00:34:47,530
And that's how this 3 step framework works. You

968
00:34:47,530 --> 00:34:48,840
put something like this in place,

969
00:34:49,128 --> 00:34:50,070
you can

970
00:34:50,550 --> 00:34:52,610
be able to evaluate a model for your

971
00:34:52,610 --> 00:34:54,809
workload within 24 to 48 hours

972
00:34:54,809 --> 00:34:55,570
of it dropping.

973
00:34:56,699 --> 00:34:58,780
So with that said, I'd like to bring

974
00:34:58,780 --> 00:35:00,860
on Brian who can show you how Coin

975
00:35:00,860 --> 00:35:01,878
Market Cap has done

976
00:35:02,500 --> 00:35:03,599
similar type of framework

977
00:35:03,898 --> 00:35:06,139
and enabled Gen AI workloads

978
00:35:06,139 --> 00:35:08,019
for millions of users daily.

979
00:35:13,188 --> 00:35:13,889
Thanks, John.

980
00:35:14,239 --> 00:35:16,429
Hi everyone. My name is Brian and I manage AI

981
00:35:16,429 --> 00:35:17,728
products in Coin Market Cap.

982
00:35:18,139 --> 00:35:20,228
In the next roughly 20 minutes, I'll be walking

983
00:35:20,228 --> 00:35:21,168
you through how

984
00:35:21,478 --> 00:35:23,110
CoinMarket Cap selects models.

985
00:35:24,079 --> 00:35:25,869
The analogy I like to use is,

986
00:35:26,208 --> 00:35:28,329
although you can use an F1 car to

987
00:35:28,329 --> 00:35:30,530
deliver groceries, you wouldn't want to do that.

988
00:35:31,728 --> 00:35:33,878
You can use the strongest models, the most

989
00:35:33,878 --> 00:35:36,159
advanced models to do the simplest task.

990
00:35:36,489 --> 00:35:38,398
You wouldn't want to do that for different reasons,

991
00:35:38,728 --> 00:35:39,610
cost being one of them.

992
00:35:41,199 --> 00:35:43,800
Before I continue, how many of you know about CoinMticcap?

993
00:35:45,688 --> 00:35:46,849
OK. Not many,

994
00:35:47,289 --> 00:35:48,978
not many people here know about CoinMarchitect.

995
00:35:49,269 --> 00:35:50,530
So this slide will be useful.

996
00:35:52,079 --> 00:35:54,090
Coin Market Cap is a cryptocurrency data

997
00:35:54,090 --> 00:35:55,458
platform and

998
00:35:55,878 --> 00:35:57,519
we've been around since 2013.

999
00:35:58,039 --> 00:35:59,619
For reference, Bitcoin,

1000
00:35:59,918 --> 00:36:02,469
one Bitcoin at that time cost roughly $100.

1001
00:36:02,840 --> 00:36:04,958
When I checked this morning, a Bitcoin was roughly

1002
00:36:04,958 --> 00:36:06,179
$93,000.

1003
00:36:07,559 --> 00:36:09,909
But more than a decade later, we're at the home of crypto

1004
00:36:09,909 --> 00:36:12,168
with over 65 million active monthly

1005
00:36:12,168 --> 00:36:14,250
active users and more than 1 billion

1006
00:36:14,250 --> 00:36:15,010
page views.

1007
00:36:16,800 --> 00:36:18,918
If you're more if you're more familiar with traditional finance, we're

1008
00:36:18,918 --> 00:36:21,269
often referred to as the Bloomberg of crypto.

1009
00:36:21,639 --> 00:36:23,820
We have more than 1 million API users

1010
00:36:24,079 --> 00:36:26,360
with institutions like Google, Yahoo

1011
00:36:26,360 --> 00:36:27,079
Finance,

1012
00:36:27,559 --> 00:36:29,639
Coinbase, and central banks around the world using

1013
00:36:29,639 --> 00:36:30,519
our crypto data.

1014
00:36:32,090 --> 00:36:33,119
Our gen AI

1015
00:36:33,458 --> 00:36:35,809
journey started in Q3 2023,

1016
00:36:36,059 --> 00:36:38,179
and since then, we have more than 10

1017
00:36:38,179 --> 00:36:39,918
user facing products in production.

1018
00:36:41,239 --> 00:36:43,280
Our AI products are used by millions around

1019
00:36:43,280 --> 00:36:44,458
the world, and

1020
00:36:44,760 --> 00:36:46,780
since 2023, we have consumed trillions

1021
00:36:46,780 --> 00:36:48,898
of LLM tokens, and today,

1022
00:36:49,030 --> 00:36:51,030
we consume more than 10 billion LLM

1023
00:36:51,030 --> 00:36:52,260
tokens every single day.

1024
00:36:53,000 --> 00:36:55,360
This scale is exactly why we are rigorous

1025
00:36:55,360 --> 00:36:56,619
about our model selection

1026
00:36:57,000 --> 00:36:59,099
and why Amazon Bedrock matters in our stack.

1027
00:37:00,750 --> 00:37:02,750
So, what do we use these more than

1028
00:37:02,750 --> 00:37:04,849
10 billion tokens for every single day?

1029
00:37:05,179 --> 00:37:06,128
Four main things.

1030
00:37:06,590 --> 00:37:07,128
First,

1031
00:37:07,550 --> 00:37:09,708
users come to our site to find alphas,

1032
00:37:09,869 --> 00:37:11,030
to find signals.

1033
00:37:11,510 --> 00:37:13,918
With more than 27 million cryptocurrencies

1034
00:37:13,918 --> 00:37:16,179
tracked by coin market cap and thousands

1035
00:37:16,179 --> 00:37:17,539
more created every single day,

1036
00:37:17,909 --> 00:37:19,429
there is a lot of noise.

1037
00:37:19,750 --> 00:37:21,869
LLM compresses this noise into

1038
00:37:21,869 --> 00:37:24,010
signals and users use

1039
00:37:24,168 --> 00:37:25,688
our AI products to find these

1040
00:37:26,070 --> 00:37:26,688
signals.

1041
00:37:27,469 --> 00:37:28,070
Second,

1042
00:37:28,539 --> 00:37:30,590
explain. Users come to our site to

1043
00:37:30,590 --> 00:37:32,789
try to understand why did, why is Bitcoin

1044
00:37:32,789 --> 00:37:34,829
price up, why is Bitcoin price down, what

1045
00:37:34,829 --> 00:37:37,010
is Bitcoin, what is proof of work,

1046
00:37:37,228 --> 00:37:39,228
and as we all know, AI does a

1047
00:37:39,228 --> 00:37:40,849
great job explaining all of these.

1048
00:37:41,389 --> 00:37:42,958
Third, forecasts.

1049
00:37:43,269 --> 00:37:45,429
Users want price predictions so that they can make

1050
00:37:45,429 --> 00:37:46,728
money. They want

1051
00:37:47,039 --> 00:37:49,128
potential scenarios and

1052
00:37:49,429 --> 00:37:51,550
although nobody has a crystal ball, AI can help

1053
00:37:51,550 --> 00:37:53,668
lay out those options and give reasoning behind

1054
00:37:53,668 --> 00:37:54,369
each of them.

1055
00:37:54,989 --> 00:37:55,590
4th,

1056
00:37:55,849 --> 00:37:58,349
act. Insight is only useful

1057
00:37:58,349 --> 00:37:59,340
if you can act on it.

1058
00:37:59,708 --> 00:38:01,869
We turn AI outputs into watchlists,

1059
00:38:01,949 --> 00:38:04,030
alerts and automations, so users can

1060
00:38:04,030 --> 00:38:05,188
act on these insights.

1061
00:38:06,099 --> 00:38:08,260
Let me show you one of our use cases, what

1062
00:38:08,260 --> 00:38:09,559
we call CMCAI.

1063
00:38:10,139 --> 00:38:12,320
This is essentially a chatbot. So imagine,

1064
00:38:13,369 --> 00:38:15,398
You wake up one day, like today, Bitcoin

1065
00:38:15,398 --> 00:38:17,519
is up and you, you wonder why Bitcoin

1066
00:38:17,519 --> 00:38:18,050
is up.

1067
00:38:18,360 --> 00:38:20,398
Instead of having to open 10 different tabs,

1068
00:38:20,610 --> 00:38:22,688
you just go to CMC and ask

1069
00:38:22,688 --> 00:38:23,489
CMC AI.

1070
00:38:23,969 --> 00:38:26,289
Using live crypto data, on chain

1071
00:38:26,289 --> 00:38:28,128
data, and social sentiment data,

1072
00:38:28,409 --> 00:38:29,628
it gives you an answer.

1073
00:38:30,010 --> 00:38:31,208
And then you, you're wondering,

1074
00:38:31,530 --> 00:38:33,769
you read about this hack that just happened and you're

1075
00:38:33,769 --> 00:38:34,918
wondering why did it happen.

1076
00:38:35,208 --> 00:38:36,829
Instead of having to deep dive into

1077
00:38:37,128 --> 00:38:39,250
many news articles, many social posts, you just

1078
00:38:39,250 --> 00:38:40,250
ask CMCAI.

1079
00:38:40,750 --> 00:38:41,418
And of course,

1080
00:38:41,708 --> 00:38:43,739
this experience is also on our app.

1081
00:38:44,309 --> 00:38:46,469
Millions of users use CMC's

1082
00:38:46,469 --> 00:38:48,610
portfolio feature to track their portfolio

1083
00:38:48,840 --> 00:38:50,909
and because we have this data, we

1084
00:38:50,909 --> 00:38:53,059
can personalize the answers for users.

1085
00:38:53,389 --> 00:38:55,469
The same question by a different user would

1086
00:38:55,469 --> 00:38:56,820
yield different results,

1087
00:38:57,179 --> 00:38:58,469
personalized results.

1088
00:39:00,119 --> 00:39:02,128
Of course, we didn't start from that chatbot that

1089
00:39:02,128 --> 00:39:03,019
you just saw.

1090
00:39:03,449 --> 00:39:04,619
Back in 2023,

1091
00:39:05,289 --> 00:39:07,360
we, when we started our AI journey, our aim

1092
00:39:07,360 --> 00:39:09,769
was to minimize risk and maximize

1093
00:39:09,769 --> 00:39:10,309
learning.

1094
00:39:10,889 --> 00:39:13,128
We needed 22 critical components

1095
00:39:13,128 --> 00:39:14,728
before we scale to the AI chatbot.

1096
00:39:15,010 --> 00:39:17,090
First is stakeholder buy-in, and

1097
00:39:17,090 --> 00:39:19,208
the second is a deep understanding on

1098
00:39:19,208 --> 00:39:21,208
how to build on top of the non-deterministic

1099
00:39:21,208 --> 00:39:22,409
nature of LLMs.

1100
00:39:23,188 --> 00:39:25,648
The image you see on the screen is

1101
00:39:25,789 --> 00:39:28,128
AIFEQs, one of our earlier products.

1102
00:39:28,469 --> 00:39:30,869
And when we, when creating this AIFEQs,

1103
00:39:30,898 --> 00:39:33,378
the reason we chose this is because it's on a less trafficked

1104
00:39:33,378 --> 00:39:34,168
part of the page,

1105
00:39:34,469 --> 00:39:36,969
so the risk is lower and whenever,

1106
00:39:37,110 --> 00:39:39,389
for all the AIFEQs we generate, a

1107
00:39:39,389 --> 00:39:41,550
human would thoroughly review them to make

1108
00:39:41,550 --> 00:39:43,550
sure that it is correct, it is accurate

1109
00:39:43,550 --> 00:39:44,679
before we go, go live with them.

1110
00:39:45,148 --> 00:39:47,219
And this manual review process, although,

1111
00:39:47,429 --> 00:39:49,610
although tedious and although it took a long time,

1112
00:39:49,820 --> 00:39:50,329
it was

1113
00:39:50,708 --> 00:39:52,789
very important because we learned the limitations

1114
00:39:52,789 --> 00:39:54,228
and strengths of LLMs.

1115
00:39:55,610 --> 00:39:57,148
With this product, we,

1116
00:39:57,849 --> 00:39:59,010
and with more organization,

1117
00:39:59,820 --> 00:40:00,849
organizational buying over time,

1118
00:40:01,168 --> 00:40:03,320
we build AI products are more prominent

1119
00:40:03,320 --> 00:40:05,530
part of, parts of our product and more deeply

1120
00:40:05,530 --> 00:40:07,030
integrated AI within our product.

1121
00:40:09,039 --> 00:40:11,159
So, as we moved from simple use

1122
00:40:11,159 --> 00:40:13,280
cases like AI FAQs to what we have

1123
00:40:13,280 --> 00:40:15,918
now, which is the AI chatbot and many other integrations

1124
00:40:15,918 --> 00:40:16,628
across the site,

1125
00:40:17,039 --> 00:40:18,478
one thing we realized is that

1126
00:40:19,039 --> 00:40:21,039
we cannot have the same model do many different

1127
00:40:21,039 --> 00:40:21,760
tasks.

1128
00:40:22,769 --> 00:40:25,050
The example I gave earlier is you don't want to use an F1

1129
00:40:25,050 --> 00:40:27,168
car to deliver groceries, and I'll give another

1130
00:40:27,168 --> 00:40:27,789
analogy.

1131
00:40:28,969 --> 00:40:31,010
In an F1 pit crew, you have different

1132
00:40:31,010 --> 00:40:33,148
people for different tasks and speed

1133
00:40:33,148 --> 00:40:35,208
and efficiency

1134
00:40:35,208 --> 00:40:37,010
comes because of that specialization.

1135
00:40:37,289 --> 00:40:39,369
I'll highlight 5 different tasks that we do

1136
00:40:39,369 --> 00:40:41,320
within CMC using AI.

1137
00:40:41,929 --> 00:40:44,409
First, a sentiment extractor. Every

1138
00:40:44,409 --> 00:40:46,570
day, we process millions of social

1139
00:40:46,570 --> 00:40:48,458
posts, millions of news articles.

1140
00:40:49,429 --> 00:40:51,478
And in order, and we want to extract

1141
00:40:51,478 --> 00:40:52,219
the sentiment

1142
00:40:52,570 --> 00:40:54,780
within these social posts and news articles.

1143
00:40:55,079 --> 00:40:57,239
Is it positive? Is it very positive,

1144
00:40:57,269 --> 00:40:58,228
or is it the opposite?

1145
00:40:58,719 --> 00:41:01,000
The LLM we select here needs to be cheap

1146
00:41:01,000 --> 00:41:03,079
because I just mentioned the scale. We process millions

1147
00:41:03,079 --> 00:41:04,659
of social posts and news articles,

1148
00:41:04,918 --> 00:41:06,070
and it needs to be fast.

1149
00:41:06,360 --> 00:41:08,579
So, the most advanced models typically don't do,

1150
00:41:09,070 --> 00:41:10,579
typically don't suit this that well.

1151
00:41:11,070 --> 00:41:12,628
The second is planning.

1152
00:41:12,909 --> 00:41:15,550
This is about taking the user's query, however

1153
00:41:15,550 --> 00:41:16,449
complex or ambiguous,

1154
00:41:16,750 --> 00:41:19,059
and transforming them into a list of to do lists.

1155
00:41:19,469 --> 00:41:21,530
This LLM needs to be very good at reasoning

1156
00:41:21,530 --> 00:41:23,208
and understanding a user's query

1157
00:41:23,550 --> 00:41:25,250
and converting that into a to do list.

1158
00:41:25,708 --> 00:41:27,708
The third is data retrieval.

1159
00:41:27,938 --> 00:41:29,769
This is about taking the data,

1160
00:41:30,110 --> 00:41:32,148
the, the to do list from the 2nd step and

1161
00:41:32,148 --> 00:41:34,369
converting that into a list of tool calls.

1162
00:41:34,789 --> 00:41:36,938
What are tools? Tools that you can think of tools

1163
00:41:36,938 --> 00:41:38,989
as API calls that LLMs

1164
00:41:38,989 --> 00:41:41,179
can make in order to retrieve context.

1165
00:41:41,550 --> 00:41:43,750
This is context, this context can be the latest

1166
00:41:43,750 --> 00:41:45,938
data, the latest news that the LLM

1167
00:41:45,938 --> 00:41:48,128
doesn't have access to within its training data.

1168
00:41:49,139 --> 00:41:51,219
This the model that we select here needs

1169
00:41:51,219 --> 00:41:53,429
to be good at choosing the right tools

1170
00:41:53,429 --> 00:41:55,469
and the right parameters within those tools.

1171
00:41:56,128 --> 00:41:57,969
The fourth is summarization.

1172
00:41:58,329 --> 00:42:00,570
Now that we have retrieved all that data

1173
00:42:00,570 --> 00:42:01,918
for the large language model,

1174
00:42:02,449 --> 00:42:04,648
this large in this step, the

1175
00:42:04,648 --> 00:42:06,728
LLM needs to take hundreds of pages of

1176
00:42:06,728 --> 00:42:08,739
data and news articles and convert

1177
00:42:08,739 --> 00:42:10,849
that into one single page of data for the user

1178
00:42:10,849 --> 00:42:13,228
to read. And the 5th is

1179
00:42:13,228 --> 00:42:15,239
translating natural language into

1180
00:42:15,239 --> 00:42:16,280
CMCIDs

1181
00:42:16,679 --> 00:42:18,898
because we track more than 27 million

1182
00:42:18,898 --> 00:42:20,090
cryptocurrencies

1183
00:42:20,849 --> 00:42:23,659
with the same name can represent many different cryptocurrencies.

1184
00:42:24,000 --> 00:42:26,039
What we found here is that we don't

1185
00:42:26,039 --> 00:42:27,978
need the strongest model to do this conversion.

1186
00:42:28,239 --> 00:42:30,398
A simple chat model generally works very

1187
00:42:30,398 --> 00:42:31,099
good for this.

1188
00:42:33,349 --> 00:42:35,469
How do, so we, we care about three main

1189
00:42:35,469 --> 00:42:37,250
things when selecting models for the,

1190
00:42:37,510 --> 00:42:39,340
the different use cases I mentioned earlier.

1191
00:42:39,668 --> 00:42:40,780
One is quality.

1192
00:42:41,188 --> 00:42:43,579
Quality looks different for each use case.

1193
00:42:44,070 --> 00:42:46,110
So, metrics like factual

1194
00:42:46,110 --> 00:42:47,510
accuracy, relevance,

1195
00:42:47,829 --> 00:42:49,829
proper evidence usage, groundedness

1196
00:42:49,829 --> 00:42:51,898
matter to us depending on the use case.

1197
00:42:52,469 --> 00:42:53,909
Second is speed.

1198
00:42:54,469 --> 00:42:55,590
Time to first token,

1199
00:42:55,849 --> 00:42:57,989
time tokens per second, and time to last

1200
00:42:57,989 --> 00:42:59,688
token matters a lot to us.

1201
00:43:00,199 --> 00:43:02,668
And the third is cost efficiency.

1202
00:43:03,000 --> 00:43:05,079
We don't care about, we don't care

1203
00:43:05,079 --> 00:43:07,110
very much about the raw token, raw

1204
00:43:07,110 --> 00:43:07,929
cost per token.

1205
00:43:08,199 --> 00:43:10,500
What we care more about is the cost to quality ratio.

1206
00:43:12,519 --> 00:43:14,559
So, with so many models coming out, I think

1207
00:43:14,559 --> 00:43:16,030
Scott previously shared that there are,

1208
00:43:16,398 --> 00:43:18,239
there's one model coming out every 10 seconds.

1209
00:43:18,559 --> 00:43:20,559
How do we choose which models to test? We can't,

1210
00:43:20,619 --> 00:43:21,938
we can't possibly test

1211
00:43:22,199 --> 00:43:24,019
every single model every 10 seconds.

1212
00:43:24,360 --> 00:43:26,559
So, in CMC we have 3 main

1213
00:43:26,559 --> 00:43:27,898
categories of models.

1214
00:43:28,280 --> 00:43:28,969
The first,

1215
00:43:29,478 --> 00:43:31,949
at least the way we think about it, there are 3 main categories of models.

1216
00:43:32,239 --> 00:43:33,918
The first is full reasoning.

1217
00:43:34,239 --> 00:43:36,280
These are your top tier models. They are very good

1218
00:43:36,280 --> 00:43:37,519
at complex tasks.

1219
00:43:37,958 --> 00:43:40,119
Using the cloud family of models as

1220
00:43:40,119 --> 00:43:41,079
examples in this slide,

1221
00:43:41,360 --> 00:43:42,260
this would be your

1222
00:43:43,059 --> 00:43:45,570
Sonnet 4.5 and your Opus 4.5.

1223
00:43:46,539 --> 00:43:48,739
Under the light reasoning models, these are mid-tier

1224
00:43:48,739 --> 00:43:50,780
models deal with reasoning and are

1225
00:43:50,780 --> 00:43:52,619
generally faster and more cost efficient.

1226
00:43:52,949 --> 00:43:54,889
This would be your Haiku 4.5.

1227
00:43:55,429 --> 00:43:56,188
And then the third,

1228
00:43:56,469 --> 00:43:58,869
fast and low cost, these are lightweight models, typically

1229
00:43:58,869 --> 00:44:00,590
chat models without any reasoning

1230
00:44:00,869 --> 00:44:03,099
that are used for simple and high volume tasks.

1231
00:44:03,389 --> 00:44:05,369
This would be your Haiku 3.5.

1232
00:44:06,840 --> 00:44:08,719
John talked quite a bit about golden data set

1233
00:44:09,000 --> 00:44:10,918
and that's what I'm gonna be talking about within this slide.

1234
00:44:11,360 --> 00:44:13,599
So, in order to prepare the golden data

1235
00:44:13,599 --> 00:44:15,978
set, we always start by setting the scope.

1236
00:44:16,478 --> 00:44:18,719
We need to make clear what is being tested and

1237
00:44:18,719 --> 00:44:20,878
with over the next couple of slides, we will use

1238
00:44:20,878 --> 00:44:22,938
to calling to as an example.

1239
00:44:24,050 --> 00:44:26,179
If a model has access to 10

1240
00:44:26,179 --> 00:44:28,179
tools, we want to make sure that it is calling

1241
00:44:28,179 --> 00:44:30,378
the right tools to retrieve the right data

1242
00:44:30,378 --> 00:44:31,860
to generate the answer for the users.

1243
00:44:32,500 --> 00:44:34,500
Say a user's query only requires 2 of the

1244
00:44:34,500 --> 00:44:36,300
tools because it doesn't need that much data.

1245
00:44:36,579 --> 00:44:38,739
The model should not go and fetch data

1246
00:44:38,739 --> 00:44:39,878
from 5 of the tools

1247
00:44:40,139 --> 00:44:41,699
and be excessive about 2 calling.

1248
00:44:42,019 --> 00:44:43,119
So, that is the scope,

1249
00:44:43,570 --> 00:44:44,760
2 calling accuracy.

1250
00:44:45,179 --> 00:44:47,079
The second is ground truth.

1251
00:44:47,378 --> 00:44:49,539
Humans will prepare the golden data set.

1252
00:44:49,958 --> 00:44:51,958
Say we have 1000 user queries that we know

1253
00:44:51,958 --> 00:44:52,760
users care about.

1254
00:44:53,079 --> 00:44:55,280
For each of these user queries, we will,

1255
00:44:55,570 --> 00:44:57,800
we will think about, hey, which tool

1256
00:44:57,800 --> 00:44:59,820
do you need to call to retrieve the data to answer

1257
00:45:00,478 --> 00:45:01,159
the question.

1258
00:45:01,438 --> 00:45:03,760
So, say for question one, we select 4 different

1259
00:45:03,760 --> 00:45:05,898
tools, that is the ground truth.

1260
00:45:06,809 --> 00:45:09,119
Third step is we run checks.

1261
00:45:09,418 --> 00:45:11,418
We call the LLM API and we give

1262
00:45:11,418 --> 00:45:13,860
it the 10 tools and we see what it actually

1263
00:45:13,860 --> 00:45:14,610
returns to us.

1264
00:45:15,099 --> 00:45:17,139
Then we compare what they returned to us

1265
00:45:17,139 --> 00:45:18,159
with our ground truth.

1266
00:45:18,579 --> 00:45:20,610
If the LLM selected 4 tools, when

1267
00:45:20,610 --> 00:45:22,300
our ground truth has 2 tools,

1268
00:45:22,679 --> 00:45:23,840
then we know something is wrong.

1269
00:45:24,179 --> 00:45:26,599
There are 3 metrics we care about here, precision,

1270
00:45:26,728 --> 00:45:29,019
recall, and F1, and I'll talk more

1271
00:45:29,019 --> 00:45:30,059
about these shortly.

1272
00:45:30,539 --> 00:45:32,889
And the last is update. This step is super important.

1273
00:45:33,260 --> 00:45:35,300
Your ground truth will shift over

1274
00:45:35,300 --> 00:45:37,500
time. Your ground truth needs to

1275
00:45:37,500 --> 00:45:39,500
reflect what users care about and what

1276
00:45:39,500 --> 00:45:41,340
your users care about changes over time.

1277
00:45:41,679 --> 00:45:43,780
So, using the same set of 1000

1278
00:45:43,780 --> 00:45:46,458
questions, maybe 100 of 1000

1279
00:45:46,458 --> 00:45:48,418
questions will not matter 3 months from now.

1280
00:45:48,739 --> 00:45:50,780
So, you need to remove those 3 100

1281
00:45:50,780 --> 00:45:52,478
questions and change it with something new.

1282
00:45:53,809 --> 00:45:55,639
Let's dive a bit deeper into tool use.

1283
00:45:56,398 --> 00:45:58,668
Precision is the first metric we care about,

1284
00:45:58,840 --> 00:46:00,059
and what it tells us is

1285
00:46:00,398 --> 00:46:02,559
amongst the tools that the model actually

1286
00:46:02,559 --> 00:46:04,869
called, how many of them were correct,

1287
00:46:05,000 --> 00:46:06,539
how many of them were necessary.

1288
00:46:07,199 --> 00:46:09,239
Recall tells us out of all

1289
00:46:09,239 --> 00:46:11,188
the tools the models should have called,

1290
00:46:11,559 --> 00:46:13,418
how many did it indeed call.

1291
00:46:14,418 --> 00:46:16,438
And F1 score combines both of them.

1292
00:46:17,059 --> 00:46:19,139
So, F1 score is essentially a formula between the

1293
00:46:19,139 --> 00:46:21,260
two of them and it's what we use to compare between

1294
00:46:21,260 --> 00:46:23,300
models. And the reason why F1 score

1295
00:46:23,300 --> 00:46:24,579
is important is because,

1296
00:46:24,938 --> 00:46:26,978
say there are 10 tools and the

1297
00:46:26,978 --> 00:46:28,639
model calls all 10 tools.

1298
00:46:28,898 --> 00:46:30,938
In this case, recall is full

1299
00:46:30,938 --> 00:46:32,929
because it called all the tools it needed to call.

1300
00:46:33,219 --> 00:46:33,739
However,

1301
00:46:34,059 --> 00:46:36,059
precision is extremely low, and the F1

1302
00:46:36,059 --> 00:46:37,378
score will reflect that.

1303
00:46:37,949 --> 00:46:39,679
So, if model A has an

1304
00:46:40,090 --> 00:46:42,148
F1 score of 0.7 and model

1305
00:46:42,148 --> 00:46:44,590
B has the F1 score of 0.4,

1306
00:46:44,989 --> 00:46:47,110
then model A is better and we will choose that

1307
00:46:47,110 --> 00:46:48,570
for the two calling use case.

1308
00:46:49,688 --> 00:46:52,329
Let's dive into another use case, summarization.

1309
00:46:52,728 --> 00:46:54,769
Summarization, like I mentioned earlier, is about taking

1310
00:46:54,769 --> 00:46:57,090
hundreds of pages of content and

1311
00:46:57,090 --> 00:46:59,289
converting that into a single page or maybe two pages

1312
00:46:59,289 --> 00:47:00,668
of content for the user to read.

1313
00:47:01,500 --> 00:47:03,780
The model needs to have very good ability

1314
00:47:03,780 --> 00:47:05,289
to understand large context,

1315
00:47:05,619 --> 00:47:07,708
and there are a few, there are many different metrics we care about here. I'll

1316
00:47:07,708 --> 00:47:08,458
mention 4.

1317
00:47:08,860 --> 00:47:10,938
1st, is the answer relevant to the

1318
00:47:10,938 --> 00:47:11,898
user's question.

1319
00:47:12,179 --> 00:47:12,728
2,

1320
00:47:13,019 --> 00:47:14,579
is it readable? 3,

1321
00:47:15,050 --> 00:47:16,449
is the answer well structured?

1322
00:47:16,820 --> 00:47:17,500
And 4,

1323
00:47:17,820 --> 00:47:19,938
groundedness. Is the final answer

1324
00:47:19,938 --> 00:47:22,039
grounded in the context it was provided?

1325
00:47:22,820 --> 00:47:24,938
We all know LLMs hallucinate. So, what

1326
00:47:24,938 --> 00:47:26,079
we found is that sometimes

1327
00:47:26,500 --> 00:47:28,500
LLMs in the final answer will come up with

1328
00:47:28,500 --> 00:47:30,840
facts that we did not provide it within the context

1329
00:47:31,260 --> 00:47:33,039
and groundedness is super important.

1330
00:47:34,050 --> 00:47:35,219
The chart you see

1331
00:47:35,659 --> 00:47:37,769
is our is our test of

1332
00:47:37,769 --> 00:47:39,889
seven different LLMs for

1333
00:47:39,889 --> 00:47:40,679
groundedness.

1334
00:47:41,250 --> 00:47:43,309
The orange line represents median,

1335
00:47:43,599 --> 00:47:45,599
the box represents the inter quartile range,

1336
00:47:45,648 --> 00:47:47,889
which means the 50% the the

1337
00:47:47,889 --> 00:47:49,929
middle 50% of the results, and the

1338
00:47:49,929 --> 00:47:51,610
dots represent outliers.

1339
00:47:52,590 --> 00:47:54,590
You see that the first result has a

1340
00:47:54,590 --> 00:47:56,628
tight inter quoile range and a decent

1341
00:47:56,628 --> 00:47:57,449
median score.

1342
00:47:57,840 --> 00:48:00,079
The second result has a very

1343
00:48:00,079 --> 00:48:02,320
big inter quota range and

1344
00:48:03,039 --> 00:48:05,280
the highest median result, so it has the potential

1345
00:48:05,280 --> 00:48:07,320
for the highest result and it has also potential

1346
00:48:07,320 --> 00:48:08,239
for low results.

1347
00:48:08,559 --> 00:48:10,840
And then the other, all the other results just are generally

1348
00:48:10,840 --> 00:48:11,539
not so good

1349
00:48:11,878 --> 00:48:12,820
looking metrics.

1350
00:48:13,119 --> 00:48:15,280
So, in this particular test, we

1351
00:48:15,280 --> 00:48:17,438
selected model one because although

1352
00:48:17,438 --> 00:48:18,579
model 2 had a

1353
00:48:18,978 --> 00:48:20,639
potential for very good results,

1354
00:48:20,918 --> 00:48:23,019
it was too unpredictable. So, we cannot

1355
00:48:23,019 --> 00:48:23,599
go with that.

1356
00:48:25,519 --> 00:48:27,760
Internally, we have this system called GLAS,

1357
00:48:27,849 --> 00:48:28,750
which stands for

1358
00:48:29,090 --> 00:48:31,590
generic LLM as a Judge evaluation Service.

1359
00:48:32,010 --> 00:48:34,199
What this does is it allows us to use

1360
00:48:34,199 --> 00:48:36,199
LLM as judge very easily. It

1361
00:48:36,199 --> 00:48:37,789
allows any team member to

1362
00:48:38,050 --> 00:48:40,349
call LLM as judge and to get the results

1363
00:48:40,349 --> 00:48:42,010
in hours instead of in days.

1364
00:48:42,780 --> 00:48:44,780
And if anybody wants to use LLM as a

1365
00:48:44,780 --> 00:48:45,659
judge internally,

1366
00:48:45,938 --> 00:48:47,949
the main thing they have to do is to define the JSON

1367
00:48:47,949 --> 00:48:48,478
input.

1368
00:48:48,780 --> 00:48:49,918
They define the goal

1369
00:48:50,260 --> 00:48:52,500
of the test, they define the dimensions

1370
00:48:52,500 --> 00:48:54,619
that they care about, and they define the candidates

1371
00:48:54,619 --> 00:48:55,719
that they are testing.

1372
00:48:56,300 --> 00:48:58,378
After they have this JSON input, they simply call the

1373
00:48:58,378 --> 00:48:58,938
API

1374
00:48:59,219 --> 00:49:01,289
and underneath the hood of the API we

1375
00:49:01,289 --> 00:49:03,539
actually call many different leading models, and

1376
00:49:03,539 --> 00:49:05,969
all of these models combined together to

1377
00:49:05,978 --> 00:49:08,260
produce a PDF output that contains

1378
00:49:08,260 --> 00:49:10,099
charts like what you saw earlier,

1379
00:49:10,458 --> 00:49:11,958
and also AI insights.

1380
00:49:12,708 --> 00:49:14,909
Using these AI insights combined

1381
00:49:14,909 --> 00:49:16,409
with more human evaluation,

1382
00:49:16,708 --> 00:49:18,708
we can decide which model is good

1383
00:49:18,708 --> 00:49:19,289
for the job.

1384
00:49:21,280 --> 00:49:23,280
Model evaluation is not a one-off

1385
00:49:23,280 --> 00:49:25,659
event. New models come out very frequently,

1386
00:49:25,878 --> 00:49:28,320
and there are typically 32 triggers

1387
00:49:28,320 --> 00:49:30,320
that make us want to

1388
00:49:30,320 --> 00:49:31,628
do a model evaluation.

1389
00:49:32,079 --> 00:49:33,519
One is a product insight,

1390
00:49:33,800 --> 00:49:36,000
second is a new model coming out that we think it's worth

1391
00:49:36,000 --> 00:49:38,019
testing. The first step of

1392
00:49:38,019 --> 00:49:40,728
model evaluation is always human evaluation.

1393
00:49:41,090 --> 00:49:43,090
A lot of models get filtered out

1394
00:49:43,090 --> 00:49:44,119
simply in this step.

1395
00:49:44,458 --> 00:49:46,398
So, humans, our team,

1396
00:49:46,739 --> 00:49:48,739
myself or my colleagues will go in and test the

1397
00:49:48,739 --> 00:49:51,280
model on a few important use cases.

1398
00:49:51,820 --> 00:49:53,898
If it passes this stage, we will run the

1399
00:49:53,898 --> 00:49:56,280
glass system, which is what I mentioned in the previous slide.

1400
00:49:56,659 --> 00:49:58,659
And then combined with AI insights and

1401
00:49:58,659 --> 00:49:59,878
more human evaluation,

1402
00:50:00,139 --> 00:50:02,179
we will know whether this model is suitable for

1403
00:50:02,179 --> 00:50:03,039
the use case,

1404
00:50:03,300 --> 00:50:05,378
and if it's suitable, we will push it to production.

1405
00:50:06,949 --> 00:50:07,898
In production,

1406
00:50:08,188 --> 00:50:09,250
every single answer.

1407
00:50:10,228 --> 00:50:12,148
is run through an LLMS judge.

1408
00:50:12,429 --> 00:50:14,750
So we know the quality of all answers generated

1409
00:50:14,750 --> 00:50:16,840
in production and we have alerts

1410
00:50:16,840 --> 00:50:18,010
if something goes wrong.

1411
00:50:18,469 --> 00:50:20,510
This step is very important because we have gained many

1412
00:50:20,510 --> 00:50:22,289
insights just from this step.

1413
00:50:24,228 --> 00:50:26,280
Of course, I need to have a slide talking about how

1414
00:50:26,280 --> 00:50:28,418
amazing AWS and Amazon Bedrock is

1415
00:50:28,510 --> 00:50:29,079
and to be fair,

1416
00:50:29,360 --> 00:50:31,050
they have been great partners. So,

1417
00:50:31,438 --> 00:50:32,849
I think they fully deserve this.

1418
00:50:33,398 --> 00:50:34,969
The first is inference.

1419
00:50:35,398 --> 00:50:37,719
Many models in the latest models

1420
00:50:37,719 --> 00:50:40,239
are all available on on Amazon Bedrock.

1421
00:50:40,530 --> 00:50:42,780
Whenever Claude come comes out with a new model,

1422
00:50:43,478 --> 00:50:45,219
Amazon Bedrock has it the same day.

1423
00:50:46,179 --> 00:50:46,969
To us,

1424
00:50:47,628 --> 00:50:49,750
calling LLM APIs is

1425
00:50:49,750 --> 00:50:51,909
just an LLM APIs. We don't deal with infra,

1426
00:50:52,070 --> 00:50:53,289
we don't deal with scaling,

1427
00:50:53,590 --> 00:50:55,340
and we are very grateful for that.

1428
00:50:55,708 --> 00:50:57,849
So, That's, that's

1429
00:50:57,849 --> 00:50:59,918
the main thing that AWS Bedrock helps us with.

1430
00:51:00,409 --> 00:51:02,168
Amazon Bedrock helps, helps us with.

1431
00:51:02,559 --> 00:51:05,090
The second thing is rack. We use Amazon's

1432
00:51:05,090 --> 00:51:07,438
open search service and their coherent with ranker.

1433
00:51:07,769 --> 00:51:09,909
This helps us to fetch the right content

1434
00:51:10,128 --> 00:51:12,168
for the model to use to answer the user's question.

1435
00:51:12,849 --> 00:51:15,110
The 3rd is security. Built-in

1436
00:51:15,110 --> 00:51:17,239
features like zero data retention is super

1437
00:51:17,239 --> 00:51:19,070
important because we process

1438
00:51:19,530 --> 00:51:21,728
the portfolio data of millions of users.

1439
00:51:22,010 --> 00:51:24,530
So we need to have this for our, for our inference

1440
00:51:24,530 --> 00:51:25,070
provider.

1441
00:51:25,449 --> 00:51:27,449
And the 4th is hands-on partnership.

1442
00:51:27,809 --> 00:51:28,708
Since the beginning,

1443
00:51:29,340 --> 00:51:31,458
Amazon hasn't been just an

1444
00:51:31,458 --> 00:51:33,820
influence provider. They have always been very helpful,

1445
00:51:33,860 --> 00:51:35,898
offering deep technical support and

1446
00:51:35,898 --> 00:51:38,219
in fact, we are working together on, on a crypto

1447
00:51:38,219 --> 00:51:40,300
AI benchmark and this benchmark will

1448
00:51:40,300 --> 00:51:42,579
compare general purpose chatbots

1449
00:51:42,579 --> 00:51:44,599
with CMC AI's ability for

1450
00:51:44,599 --> 00:51:45,898
crypto use cases.

1451
00:51:47,679 --> 00:51:49,179
So, to sum, to sum up,

1452
00:51:49,679 --> 00:51:50,550
4 points.

1453
00:51:50,918 --> 00:51:52,958
First is the use case drives

1454
00:51:52,958 --> 00:51:53,820
model choice.

1455
00:51:54,199 --> 00:51:56,208
The best model, a Ferrari car,

1456
00:51:56,239 --> 00:51:58,269
isn't always suitable for every job, isn't

1457
00:51:58,269 --> 00:52:00,000
always suitable for delivering groceries.

1458
00:52:00,398 --> 00:52:01,309
Specialists

1459
00:52:01,719 --> 00:52:04,239
usually beats generalists for for

1460
00:52:04,239 --> 00:52:05,320
different use cases.

1461
00:52:06,030 --> 00:52:06,878
The second

1462
00:52:07,148 --> 00:52:09,188
is that evaluation is not a

1463
00:52:09,188 --> 00:52:10,849
side project. It is a product.

1464
00:52:11,269 --> 00:52:13,208
It's never set and forget and

1465
00:52:13,869 --> 00:52:15,418
through continuous evaluation,

1466
00:52:15,800 --> 00:52:17,289
can you then can you convert

1467
00:52:17,668 --> 00:52:20,070
what may be a fun demo into a production-ready

1468
00:52:20,070 --> 00:52:22,110
product. The third is

1469
00:52:22,110 --> 00:52:24,228
humans matter. As much as we try

1470
00:52:24,228 --> 00:52:25,708
to automate everything away,

1471
00:52:26,188 --> 00:52:28,228
what we found is that humans

1472
00:52:28,228 --> 00:52:30,289
alone or humans combined with AI brings us

1473
00:52:30,289 --> 00:52:31,429
the best insights.

1474
00:52:32,059 --> 00:52:34,219
And the 4th is the right partner multiplies

1475
00:52:34,219 --> 00:52:34,800
output.

1476
00:52:35,090 --> 00:52:37,139
A AWS has been super helpful. Amazon

1477
00:52:37,139 --> 00:52:39,199
Bedrock has been super helpful, and

1478
00:52:39,458 --> 00:52:40,958
you need to pick the right inference partners.

1479
00:52:43,280 --> 00:52:44,619
What's next for CMC?

1480
00:52:45,000 --> 00:52:46,320
There are three things that we,

1481
00:52:46,639 --> 00:52:48,719
we, we will be focusing on in 2026. The

1482
00:52:48,719 --> 00:52:50,840
first is reducing the cost of inference

1483
00:52:50,840 --> 00:52:52,219
and the speed of inference.

1484
00:52:53,019 --> 00:52:55,119
And there are a couple of ways we are thinking of doing this.

1485
00:52:55,320 --> 00:52:57,418
First is through fine tuning models for

1486
00:52:57,418 --> 00:52:59,530
different use cases, and the second is

1487
00:52:59,530 --> 00:53:01,539
model distillation model distillation, which

1488
00:53:01,539 --> 00:53:03,260
is available on Amazon Bedrock.

1489
00:53:03,820 --> 00:53:05,579
The second is B2B opportunities.

1490
00:53:06,019 --> 00:53:08,099
So, many enterprises have indicated interest

1491
00:53:08,099 --> 00:53:10,239
in integrating AI within their products,

1492
00:53:10,300 --> 00:53:12,050
and instead of building it from the ground up,

1493
00:53:12,378 --> 00:53:14,320
they come to us and ask us for it.

1494
00:53:14,739 --> 00:53:16,489
So, if any of you are in crypto and you want it,

1495
00:53:16,780 --> 00:53:17,559
reach out to me.

1496
00:53:17,978 --> 00:53:20,199
And the third is better AI UX

1497
00:53:20,500 --> 00:53:22,840
and expanded CMC AI capabilities.

1498
00:53:23,329 --> 00:53:25,398
Users mainly interact with large language

1499
00:53:25,398 --> 00:53:27,719
models through a chat interface right now, and

1500
00:53:27,719 --> 00:53:29,800
in order to get the best from that,

1501
00:53:30,119 --> 00:53:32,119
users need to be expert prompters and

1502
00:53:32,119 --> 00:53:34,478
they need to be, they need to understand the limitations

1503
00:53:34,478 --> 00:53:35,780
of a chat interface.

1504
00:53:36,239 --> 00:53:38,418
I don't think that is the future of AI

1505
00:53:38,418 --> 00:53:40,619
and I think that that AI needs to be more proactive,

1506
00:53:41,039 --> 00:53:43,478
it needs to be easier to use, it needs to be more

1507
00:53:43,478 --> 00:53:45,639
personalized, and that's what we will be focusing

1508
00:53:45,639 --> 00:53:46,800
on in 2026.

1509
00:53:47,349 --> 00:53:48,050
So I hope

1510
00:53:48,469 --> 00:53:50,469
now 20 minutes later you are better at choosing

1511
00:53:50,469 --> 00:53:51,050
models

1512
00:53:51,309 --> 00:53:53,349
and if any of you are in crypto, try

1513
00:53:53,349 --> 00:53:54,989
out CMC AI and let me know what you think.

1514
00:53:55,269 --> 00:53:56,590
I'll hand the time back to Scott.

1515
00:54:03,958 --> 00:54:05,739
Thank you so much, Brian. Uh, the work

1516
00:54:06,000 --> 00:54:08,079
that Brian and his teams are doing is

1517
00:54:08,079 --> 00:54:09,579
really fantastic, uh,

1518
00:54:09,878 --> 00:54:12,000
exciting to see the level of maturity and

1519
00:54:12,000 --> 00:54:13,750
the scale of production they're working at.

1520
00:54:14,070 --> 00:54:16,360
I really appreciate you sharing all that with our audience

1521
00:54:16,360 --> 00:54:18,769
today. Uh, quick recap, uh,

1522
00:54:18,889 --> 00:54:21,099
we've got, uh, just, you know, wanted to kind of

1523
00:54:21,519 --> 00:54:22,949
reconsider what we talked about today.

1524
00:54:23,489 --> 00:54:25,128
Uh, 3 steps identifying,

1525
00:54:25,438 --> 00:54:26,688
uh, models,

1526
00:54:27,010 --> 00:54:29,369
look at the general benchmarks, consider modalities,

1527
00:54:29,449 --> 00:54:31,648
and pick good candidate models that are relevant

1528
00:54:31,648 --> 00:54:32,590
for your use case.

1529
00:54:33,090 --> 00:54:35,090
Uh, next step is evaluate,

1530
00:54:35,570 --> 00:54:37,728
run those models in your environment, uh,

1531
00:54:37,809 --> 00:54:38,909
on your data,

1532
00:54:39,570 --> 00:54:41,719
on your use case, and, and, and generate that golden

1533
00:54:41,719 --> 00:54:43,128
data set so that you can,

1534
00:54:43,409 --> 00:54:45,429
uh, verify and know that you're picking the right models for

1535
00:54:45,429 --> 00:54:46,070
your use case.

1536
00:54:46,429 --> 00:54:47,489
And then optimize

1537
00:54:47,789 --> 00:54:50,478
uh those models through model combinations

1538
00:54:50,750 --> 00:54:53,139
or through fine tuning to make sure that you're achieving

1539
00:54:53,139 --> 00:54:54,369
uh the benchmarks

1540
00:54:54,628 --> 00:54:56,728
in the performance requirements that you need and

1541
00:54:56,728 --> 00:54:59,148
uh great to hear uh from

1542
00:54:59,148 --> 00:55:00,250
Coin Maret Cap as well

1543
00:55:00,668 --> 00:55:02,909
to understand what that looks like in production uh

1544
00:55:02,909 --> 00:55:03,489
for them today.

1545
00:55:04,458 --> 00:55:06,648
I wanna close with a few uh

1546
00:55:06,679 --> 00:55:08,530
resources that I think could be helpful for you all.

1547
00:55:08,820 --> 00:55:10,949
The first is an article written by

1548
00:55:10,949 --> 00:55:13,019
one of our VPs talking about the value of

1549
00:55:13,019 --> 00:55:13,820
model choice,

1550
00:55:14,139 --> 00:55:15,500
nice kind of general purpose,

1551
00:55:15,829 --> 00:55:18,099
uh, explanation of why we're committed

1552
00:55:18,099 --> 00:55:19,599
to that at Amazon Bedrock.

1553
00:55:20,019 --> 00:55:21,469
We've also got a model

1554
00:55:21,820 --> 00:55:23,918
choice page for the Amazon Bedrock

1555
00:55:23,918 --> 00:55:25,929
website. On that is all those

1556
00:55:25,929 --> 00:55:28,059
new models we launched, uh, 18 new

1557
00:55:28,059 --> 00:55:28,619
models,

1558
00:55:28,978 --> 00:55:30,938
uh, in the openweight category to over 20.

1559
00:55:31,280 --> 00:55:33,030
Uh, this week and, uh,

1560
00:55:33,329 --> 00:55:35,340
we've also got those new model providers, so

1561
00:55:35,610 --> 00:55:37,869
lots more coming, uh, we, uh,

1562
00:55:37,889 --> 00:55:40,250
keep stay tuned, keep watching more models are on the way.

1563
00:55:40,728 --> 00:55:41,750
Uh, we've also got

1564
00:55:42,329 --> 00:55:45,079
a few GitHub resources. There's a model evaluation

1565
00:55:45,079 --> 00:55:47,148
application. This is downloadable. You can run it locally

1566
00:55:47,449 --> 00:55:49,489
in tandem with the Bedrock tools for

1567
00:55:49,489 --> 00:55:51,050
evaluation. This is one that you can use,

1568
00:55:51,570 --> 00:55:54,239
uh, generates a nice visual, just a streamlet

1569
00:55:54,239 --> 00:55:56,269
application. That you can compare, uh, you

1570
00:55:56,269 --> 00:55:58,340
know, intelligence as well as accuracy,

1571
00:55:58,628 --> 00:55:59,329
uh, latency,

1572
00:55:59,590 --> 00:56:01,628
performance side by side. It's a nice one to

1573
00:56:01,628 --> 00:56:03,750
kinda share with stakeholders, help them understand why you're

1574
00:56:03,750 --> 00:56:04,889
picking the model you're picking

1575
00:56:05,269 --> 00:56:07,610
and then if you wanna go even further, there's a model evaluation

1576
00:56:07,789 --> 00:56:10,010
workshop available also on GitHub. So

1577
00:56:10,199 --> 00:56:12,349
take a shot of those, uh, great resources

1578
00:56:12,349 --> 00:56:14,349
to, uh, get whatever level you want to

1579
00:56:14,349 --> 00:56:15,389
kinda understand,

1580
00:56:15,668 --> 00:56:17,168
uh, what's available

1581
00:56:17,429 --> 00:56:18,570
within Amazon Bedrock.

1582
00:56:19,148 --> 00:56:21,188
I wanna thank you all for being here. Uh,

1583
00:56:21,228 --> 00:56:23,128
it was, uh, great getting to talk through this with you.

1584
00:56:23,458 --> 00:56:24,239
There is a

1585
00:56:24,820 --> 00:56:26,898
little uh survey if you, if you don't mind

1586
00:56:26,898 --> 00:56:28,929
filling that out, that does help us out. We do read

1587
00:56:28,929 --> 00:56:29,659
those surveys.

1588
00:56:29,938 --> 00:56:31,070
We're really committed to trying to

1589
00:56:31,378 --> 00:56:33,469
uh deliver great presentations for you all.

1590
00:56:33,579 --> 00:56:34,159
Uh,

1591
00:56:34,699 --> 00:56:36,739
thank you again for being here today and enjoy the rest

1592
00:56:36,739 --> 00:56:37,219
of reinvent.

