# AWS re:invent 2025 - Capital One 平台弹性架构实践总结

## 会议概述

本次会议由 AWS 客户解决方案经理 Enrique Bastante 主持,Capital One 企业平台组织的两位领导者 Soan 和 Arun 分享了他们在构建高弹性业务关键平台方面的实践经验。

Capital One 在 2019 年宣布转型为平台型组织,通过构建可复用、可扩展且高度可靠的基础平台能力,解决了此前各业务线重复建设、架构不统一、数据冗余等问题。他们将平台视为"数字乐高积木",用于构建各种客户功能。会议重点讨论了可靠性这一核心支柱,包括可用性(uptime)、成功率(success rate)、容错能力(fault tolerance)和平均恢复时间(MTTR)等关键指标。

演讲深入探讨了从早期反模式到现代架构的演进历程,包括多区域部署、领域驱动设计、无服务器架构采用、分片技术(sharding 和 shuffle sharding)等先进模式。此外还涵盖了零停机部署、弹性测试框架、可观测性标准等非架构层面的可靠性保障措施,为构建五个九(99.999%)可用性的关键业务系统提供了完整的方法论。

## 详细时间线

### 开场与背景介绍
- **00:00:00** - Enrique Bastante 欢迎参会者,介绍自己作为 AWS 战略客户解决方案经理的角色,强调弹性是跨行业的重要话题
- **00:01:15** - 介绍 Capital One 在弹性实践方面被 AWS 视为世界级组织,今天将分享企业平台组织的两位领导者的经验
- **00:02:00** - 会议议程预告:讨论如何构建高弹性平台、面临的挑战、做出的决策、最佳实践以及未来方向

### Capital One 平台化转型
- **00:02:45** - Soan 开场,询问现场有多少人使用 Capital One 的应用和服务
- **00:03:10** - 介绍 Capital One 的平台化旅程,将平台比喻为"数字乐高积木"
- **00:03:45** - 回顾 2019 年之前的问题:各业务线重复建设能力、架构模式不标准、数据重复存储、开发成本高、上市速度慢
- **00:05:00** - 2019 年宣布成为平台型组织,投资构建可复用、可扩展、可靠的基础平台
- **00:05:30** - 介绍构建的平台类型:开发者平台(CI/CD)、核心业务平台(交易处理、支付处理)、客户交互平台(身份、消息)

### 可靠性的七大支柱
- **00:06:30** - 介绍现代平台的七大基础支柱,今天重点讨论第一支柱:可靠性(Reliability)
- **00:07:00** - 通过客户支付失败的例子说明可靠性的重要性
- **00:07:45** - 定义可用性指标:正常运行时间(uptime)和成功率(success rate)
- **00:08:30** - 介绍弹性(Resiliency)的重要性:系统从故障中恢复的能力
- **00:09:00** - 强调容错能力(Fault Tolerance),用桥梁结构类比冗余设计
- **00:09:30** - 介绍平均恢复时间(MTTR):快速识别、隔离和自动恢复故障的能力
- **00:10:15** - 将可靠性定义为"信任引擎",确保平台能力长期按预期运行

### 架构反模式分析
- **00:11:00** - Arun 接手,开始深入技术内容,介绍两大重点领域:架构策略和非架构因素
- **00:12:00** - 反模式一:All-in-One 方法 - 单体应用部署在单区域、单可用区,无自动扩展和数据库复制
- **00:12:45** - 强调 Capital One 从云迁移第一天就决定不使用单区域部署,始终部署在两个区域
- **00:13:15** - 提到 2025 年 10 月 US-East-1 故障,Capital One 系统通过自动故障转移快速恢复
- **00:14:00** - 反模式二:微服务过度增殖 - 大量紧密耦合的微服务,零容错能力,一个服务故障导致级联失败
- **00:15:00** - 反模式三:共享集群部署 - Web、移动和批处理流量共享同一集群,导致数据库超时和实时用户体验受损
- **00:16:00** - 反模式四:共享数据库 - 分析负载和实时客户负载共享同一数据库,分析任务占用资源导致超时和限流

### 企业架构标准
- **00:17:00** - 介绍 Capital One 的架构标准:始终部署到两个区域,CI/CD 管道部署相同版本到两个区域
- **00:17:45** - 服务横向扩展,单个区域随时能够承载全部负载
- **00:18:15** - 架构依赖原则:单个区域不应与跨区域有紧密耦合,所有服务应具有区域亲和性(regional affinity)
- **00:19:00** - 数据一致性:选择支持自动复制的数据库
- **00:19:30** - 故障恢复管理:单区域故障不应影响服务能力,所有服务配备自动故障转移,定义严格的 RTO 和 RPO

### 领域驱动设计模式
- **00:20:30** - 介绍领域驱动设计(Domain-Driven Design)模式,将大领域划分为多个子域
- **00:21:15** - 每个子域有自己的实体、聚合、数据库和层,在有界上下文(bounded context)中运行
- **00:22:00** - 以银行为例:将银行领域划分为交易处理、报告、客户管理、账户服务等子域
- **00:22:45** - DDD 的优势:模块化、易维护、高度解耦、容错、独立扩展、SLA 灵活性
- **00:23:30** - 客户可以选择需要的能力模块,如财务部门使用报告模块,卡和银行使用交易处理

### 最小部署架构要求
- **00:24:15** - 展示 Capital One 最小部署架构图:两区域、多可用区、DDD 有界上下文服务、自动扩展、数据库自动复制
- **00:25:00** - 介绍 Route 53 记录集:基于地理位置路由(请求到最近数据中心)和故障转移记录集(自动故障转移机制)
- **00:26:00** - 故障转移记录集有主路由和辅助路由,监控区域健康状态,自动切换到健康区域
- **00:26:45** - 此架构保证 3 个 9 到 4 个 9 的可用性,但关键任务应用需要 5 个 9

### 毒丸请求问题与解决方案
- **00:27:30** - 引入"毒丸请求"(Poison Pill Request)概念:每次处理都会导致服务崩溃的请求
- **00:28:15** - 演示毒丸请求如何逐个击垮服务任务,触发自动故障转移到第二区域,但问题依然存在
- **00:29:30** - 解决方案一:熔断器(Circuit Breaker) - 在路由器层面实现客户级别的熔断器,追踪毒丸请求并打开熔断器
- **00:30:30** - 路由器还配备限流器(Rate Limiter),防止客户请求压垮系统
- **00:31:00** - 承认熔断器和限流器是被动措施,对于 5 个 9 可用性(年度停机预算仅 5 分钟)不够

### 分片技术演进
- **00:32:00** - 标准分片(Standard Sharding) - 将客户分为三组,使用一致性哈希算法创建粘性会话
- **00:33:00** - 标准分片将爆炸半径从 100% 降低到 33%,但对于 5 个 9 可用性仍不够
- **00:34:00** - 洗牌分片(Shuffle Sharding) - 用扑克牌类比:创建多个分片组合,每个客户分配唯一的分片组合
- **00:35:15** - 展示洗牌分片示例:客户 1 和客户 3 共享分片 30,但各有其他健康分片可用
- **00:36:30** - 即使共享分片故障,客户仍可通过重试使用其他健康分片
- **00:37:00** - 介绍二项式系数数学公式:100 个分片、100 万客户、每客户 3 个分片,可生成 161,700 个唯一组合
- **00:38:00** - 洗牌分片将爆炸半径降低到 0.7%,对于关键任务应用达到 5 个 9 可用性非常有效

### 洗牌分片实现细节
- **00:39:00** - 展示 Python 示例代码,输入客户数、节点数、每客户分片数,输出分片组合
- **00:40:00** - 逻辑位于路由器中,客户入驻时路由器创建洗牌组合并存储在持久化数据库中
- **00:41:00** - 路由器使用轮询算法,根据客户的分片组合设置请求头,负载均衡器基于头路由到相应分片
- **00:42:00** - 分片可视为 ECS 目标组,每个分片内可独立扩展
- **00:42:45** - 提到另一种方法:将分片逻辑左移到 SDK,但维护 SDK 版本更新困难,倾向于路由器方法

### 架构建议总结
- **00:43:30** - 架构建议:多区域、多可用区、领域驱动设计、自动扩展、避免重试风暴、使用快速失败超时
- **00:44:15** - 使用适合用例的分片技术,但要注意管理分片基础设施的挑战
- **00:44:45** - 注意不同故障模式,并非所有平台能力都需要 5 个 9,只有关键任务能力需要

### 无服务器架构采用
- **00:45:00** - Capital One 是无服务器公司,解释为何转向无服务器
- **00:45:30** - EC2 实例的问题:特定实例类型不可用、IP 耗尽、扩展时间长、启动慢
- **00:46:30** - 运维问题:管理数千个 EC2 节点、补丁管理、手动错误导致故障
- **00:47:15** - 无服务器优势:无手动操作、可靠扩展、运维开销降低
- **00:48:00** - 关键任务平台运行在 ECS Fargate 上
- **00:48:30** - AWS Lambda 用于非关键异步路径,强调设置最大并发限制以创建隔离模式,避免占用账户级并发限制
- **00:49:30** - 列举使用的无服务器服务,称其为最大的游戏规则改变者,运维效率大幅提升

### 故障模式分析
- **00:50:00** - 持续审查不同故障模式:云提供商故障、内部平台依赖故障、外部供应商故障、客户毒丸请求、平台工程师 bug
- **00:51:00** - 不可信代码(Untrusted Code) - 特殊场景:平台执行来自不同业务单元的业务逻辑代码
- **00:51:45** - V1 设计问题:服务和不可信代码共享相同 VM 资源,不可信代码可能包含 system.exit、无限循环、递归导致栈溢出
- **00:53:00** - 沙箱安全模型 - 创建多个微 JVM,服务 VM 与微 VM 隔离,为不可信代码分配固定容量(如 10MB)
- **00:53:45** - 设置严格执行超时,禁止 IO 访问路径

### 零停机部署
- **00:54:30** - 部署是常见故障原因,介绍零停机部署策略
- **00:55:00** - 使用 AWS CodeDeploy 实现蓝绿部署和金丝雀部署
- **00:55:45** - 金丝雀部署:逐步增加流量(10%、25%、50%、100%),每个阶段监控指标
- **00:56:30** - 如果检测到错误率上升或延迟增加,自动回滚到之前版本
- **00:57:00** - 强调自动化回滚机制的重要性,减少人为干预

### 基础设施即代码
- **00:57:45** - 使用 AWS CDK 构建可靠基础设施
- **00:58:15** - CDK 优势:类型安全、可重用组件、版本控制、自动化测试
- **00:59:00** - 通过 CDK 标准化基础设施模式,确保一致性和最佳实践

### 弹性测试框架
- **00:59:30** - 使用 AWS Fault Injection Simulator (FIS) 构建弹性测试框架
- **01:00:00** - 定期进行混沌工程实验:模拟 AZ 故障、网络延迟、CPU 压力、内存耗尽
- **01:01:00** - 测试自动故障转移、自动扩展、熔断器等机制是否按预期工作
- **01:01:45** - 在生产环境进行受控实验,验证系统真实弹性能力

### 可观测性标准
- **01:02:30** - 可观测性是可靠性的关键,实施三大支柱:指标、日志、追踪
- **01:03:00** - 关键指标:错误率、延迟、饱和度、流量(Google SRE 四大黄金信号)
- **01:03:45** - 使用 CloudWatch、X-Ray 等 AWS 服务实现全面可观测性
- **01:04:30** - 设置智能告警,基于异常检测而非静态阈值
- **01:05:00** - 强调可观测性驱动的故障响应和持续改进

### 总结与建议
- **01:05:45** - 回顾关键要点:多区域架构、领域驱动设计、无服务器采用、分片技术、零停机部署
- **01:06:30** - 强调可靠性不是事后考虑,应从架构设计之初就融入
- **01:07:00** - 建议设定明确的可靠性目标(RTO、RPO、SLA),持续测试和改进
- **01:07:30** - 会议结束,感谢参会者