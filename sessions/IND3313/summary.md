# AWS re:Invent 2025 技术会议总结：Visa 基于 AWS 构建 AI 驱动的反欺诈系统

## 会议概述

本次会议主题为"毫秒级安全防护"，重点介绍了 Visa 如何在 AWS 上构建 AI 驱动的反欺诈防御系统，用于保护账户到账户(A2A)支付安全。会议由 AWS 客户解决方案经理 Sured Sajo 主持，Visa 工程高级总监 Himma Zuchi 和 Visa Protect A2A 产品首席架构师 Arvinda Nagala 共同分享了技术实现细节。

Visa Protect A2A 是专门为非卡支付场景设计的欺诈防护解决方案。随着账户到账户支付的快速增长，预计到 2029 年全球 A2A 交易量将增长 83%，达到 1 万亿笔年交易量；到 2030 年交易价值将增长 113%，达到 195 万亿美元。然而，欺诈损失也预计将增长 153%，达到 580 亿美元。Visa 通过利用 AWS 的先进技术，在满足严格的安全性、低延迟、高可用性和数据本地化要求的同时，成功构建了这一大规模反欺诈系统。

该解决方案的核心亮点包括：使用 AWS Nitro Enclaves 实现内存数据保护，通过 Amazon EKS 优化实现低延迟处理，利用 Amazon MemoryDB 和 ElastiCache 实现快速数据访问，以及构建跨区域主-主架构实现 99.99% 的高可用性。整个系统能够在 250 毫秒内完成端到端的欺诈评分处理，并成功测试了高达 10,000 TPS 的突发流量。

## 详细时间线与关键要点

### 开场与背景介绍 (0:00-5:30)

0:00-1:30 - 会议开场
- Sured Sajo 介绍自己是 AWS 客户解决方案经理，专注于全球金融服务客户的企业转型
- 介绍会议主题：Visa 如何构建 AI 驱动的反欺诈防御系统保护账户到账户支付
- 介绍演讲嘉宾：Visa 工程高级总监 Himma Zuchi 和首席架构师 Arvinda Nagala

1:30-3:00 - 会议议程概览
- 支付领域的发展趋势，重点关注账户到账户支付及其风险增长
- Visa Protect A2A 解决方案如何应对这些风险
- 技术实现的高标准要求
- 深入探讨 AWS Nitro Enclaves、Amazon EKS 优化和 MemoryDB 的应用
- 高可用性架构设计

### 支付行业演变与 A2A 支付 (3:00-8:45)

3:00-5:00 - 支付方式的演进
- 传统信用卡支付：数十年来一直是商业交易的支柱
- 数字钱包的兴起：通过手机轻触实现无缝非接触式支付
- A2A 支付的出现：更加简化、成本优化的支付方式

5:00-6:30 - A2A 支付的定义与类型
- A2A 支付是安全、可靠、即时的支付方式，资金直接从发送方银行账户转移到接收方银行账户
- 无需信用卡网络等中间机构
- 两种类型：
  - 推送支付：由发送方发起（如朋友间转账还款）
  - 拉取支付：由接收方发起（如订阅和定期付款）

6:30-8:45 - A2A 支付流程与市场增长
- 支付流程：消费者/企业请求 → 发送方金融机构 → 实时支付网络(RTP) → 接收方金融机构 → 接收方
- RTP 网络示例：巴西的 Pix、印度的 UPI、英国的 Faster Payments
- 市场预测数据：
  - 到 2029 年交易量增长 83%，达到 1 万亿笔/年
  - 到 2030 年交易价值增长 113%，达到 195 万亿美元
  - 欺诈相关损失预计增长 153%，达到 580 亿美元

### Visa Protect A2A 解决方案介绍 (8:45-15:00)

8:45-10:30 - Visa 的核心原则与解决方案
- Himma Zuchi 介绍 Visa 的核心原则：高可用性、网络安全、低延迟
- Visa Protect A2A 专门为非卡支付设计，旨在增强安全性
- 支持所有类型的非卡支付：B2B、B2C、C2C、C2B

10:30-12:00 - 欺诈防护机制
- 在支付流程中集成 Visa Protect A2A 调用
- 发送方金融机构可以根据风险评分决定是否阻止支付
- 如果发送方未能阻止，接收方金融机构还有第二次机会拒绝欺诈支付
- 在英国等地区，欺诈责任由发送方和接收方共同承担

12:00-15:00 - 系统架构需求概述
- 需要满足与本地数据中心相同的严格标准
- 四大核心要求：网络安全、数据本地化、低延迟、高可用性

### 网络安全要求 (15:00-18:30)

15:00-16:30 - 严格的网络安全标准
- Visa 对网络安全要求极为严格，因为客户信任 Visa 处理其 PII（个人身份信息）
- 除了常规的设计安全要求(DSR)和技术安全要求外，还需要解决独特的云端挑战

16:30-18:30 - 内存数据保护挑战
- 数据在传输和存储时是加密的，但在内存中处理时是未加密的
- 威胁向量包括：核心转储、交换文件、暴露的数据端点、内存抓取硬件
- 解决方案：采用零信任架构和 AWS Nitro Enclaves
- Nitro Enclaves 如同主服务器内的安全保险库，即使 AWS 或 Visa 账户也无法访问

### 数据本地化与低延迟要求 (18:30-24:00)

18:30-20:00 - 区域合规要求
- 为欧洲市场构建解决方案需要遵守 GDPR 要求
- 虽然 GDPR 不强制要求数据本地化，但本地化有助于更好地满足合规要求
- 银行客户也要求数据保留在本地
- 解决方案：在 AWS 欧洲区域部署交易和模型推理引擎

20:00-24:00 - 低延迟要求
- 金融行业对延迟要求极为严格，任何延迟都会破坏用户体验
- 目标：端到端响应时间必须在 250 毫秒以内
- 这意味着必须在 250 毫秒内完成：接收交易、处理、运行模型、返回响应
- 解决方案：
  - 区域共置：避免网络延迟
  - 使用 Amazon MemoryDB with Valkey：结合缓存的快速读取和数据库的持久性
  - TLS 连接池机制

### 高可用性与弹性要求 (24:00-27:30)

24:00-26:00 - Tier 0 应用标准
- Visa 将应用分为不同层级，交易类应用被归类为 Tier RT 或 Tier 0
- Tier 0 要求：99.99% 的正常运行时间
- 这意味着全年停机时间不能超过 52 分钟 35 秒

26:00-27:30 - 灾难恢复要求
- 必须在至少两个区域构建冗余
- 区域之间必须相距 60 英里以上
- 解决方案：在伦敦和爱尔兰区域部署，每个区域使用三个可用区(Multi-AZ)

### 功能架构 (27:30-31:00)

27:30-29:30 - 实时组件
- 评分 API：处理外部客户端请求，执行数据处理、安全检查
- 决策服务：决定调用哪个模型进行推理
- 模型推理 API：包含聚合服务、编排服务、长期配置文件

29:30-31:00 - 近实时离线系统
- 评分 API：接收每日文件和状态文件
- 数据消费者：接收客户端数据
- 客户入职：获取历史数据构建特征
- 特征工程平台：生成长期和短期配置文件
- 包含计费、报告等其他组件

### 技术架构深入解析 (31:00-42:00)

31:00-35:00 - 实时评分 API 工作负载
- Arvinda Nagala 详细介绍技术架构
- 客户请求流程：
  - DMZ VPC：面向互联网的安全边界，使用 Amazon Network Firewall 检查每个数据包
  - 负载均衡器：使用双向 TLS 进行身份验证
  - Transit Gateway VPC 端点
  - Amazon API Gateway：在私有 VPC 中，执行使用计划和限流
  - 通过 NLB 发送到 Nitro Enclaves 中的 A2A 网关应用

35:00-38:00 - A2A 网关处理流程
- 在 Enclave 内终止 TLS 连接
- 执行验证和二次身份验证（令牌验证）
- 使用 KMS 加密敏感 PII 数据
- 将 REST 请求转换为 gRPC 协议
- 发送到决策服务应用（运行在 Amazon EKS 上）

38:00-42:00 - 决策服务与模型推理
- 决策服务转换请求，通过查询 ElastiCache for Valkey 进行重复检查
- 通过查询 ElastiCache 丰富数据
- 调用模型推理平台（部署在 Ray 集群上，运行在 EKS 上）
- 模型推理包含三个服务：
  - LT Profile 服务：从 MemoryDB 获取长期配置文件特征
  - 聚合服务：从 MemoryDB 获取短期配置文件特征执行实时聚合
  - AI Serve：运行模型生成风险评分
- 评分返回决策服务，应用规则引擎，转换响应
- 将 gRPC 响应转换为 REST 返回客户端
- 选择 ElastiCache for Valkey 和 MemoryDB：比 Redis 便宜约 20%，性能相同

### 离线流程管道 (42:00-47:00)

42:00-44:00 - 文件上传流程
- 客户端通过 AWS Transfer Family 服务上传文件
- 使用 SFTP 协议上传 PGP 加密文件
- 文件存储在 S3 存储桶
- 扫描流程使用 AWS GuardDuty 进行恶意软件检测
- 成功扫描的文件移动到另一个 S3 存储桶并生成 SNS 通知

44:00-47:00 - 数据注入与处理
- 数据注入进程（运行在 Nitro Enclaves 中）消费 SNS 通知
- 将文件拉入 Enclave 内存并在 Enclave 内解密
- 解析文件、执行验证、加密 PII 数据
- 将加密记录写入 Amazon MSK (Managed Streaming for Kafka)
- 文件级元数据存储在 Aurora DB 用于报告
- Kafka 数据流被多个应用消费：
  - Data Firehose 将数据写入 S3
  - EMR 作业聚合数据用于特征工程和模型验证
  - 消费者应用将权限和分支代码数据写入 ElastiCache
  - 相同数据写入 Aurora DB 用于长期存储

### AWS Nitro Enclaves 深入解析 (47:00-52:00)

47:00-49:00 - Nitro Enclaves 特性
- 在 EC2 实例内运行的安全、加固、隔离环境
- 无外部连接、无 SSH 访问、无持久存储
- 即使父 EC2 的 root 用户也无法登录 Enclave
- 只有父 EC2 可以通过 VSOCK 协议的安全本地通道连接
- 适合处理敏感数据：银行账号、信用卡号、客户数据

49:00-52:00 - A2A 网关应用技术设计
- 启动时通过代理连接 Secrets Manager 和 KMS
- 获取信封加密的数据加密密钥到 Enclave
- 使用 KMS 客户管理密钥解密并缓存在 Enclave 内存中
- 请求到达时：
  - NLB 发送到父 EC2 上的网关代理
  - 代理将 TCP 转换为 VSOCK 协议发送到 Enclave
  - Enclave 内的 A2A 网关终止 TLS 连接
  - 验证负载并使用缓存的密钥加密明文 PII 数据
  - 将 REST 转换为 gRPC 通过 VSOCK 通道发送到下游决策服务
- 确保敏感数据处理完全在 Nitro Enclave 内进行，避免内存暴露威胁

### Nitro Enclaves 最佳实践 (52:00-55:00)

52:00-53:30 - 资源分配与配置
- 使用 allocator.yaml 文件进行 Enclave 资源分配
- 声明 vCPU 和内存配置
- 最佳实践：使用用户数据脚本进行分配
- 原因：Nitro Enclaves 需要连续的大页内存，如果不在启动时预留，内存可能会碎片化

53:30-55:00 - 性能优化
- 仔细调优代理以获得更好的吞吐量
- 使用 socat 代理进行 TCP 到 VSOCK 的转换
- 调优选项：并发连接、地址重用、fork
- 健康检查端点应检查应用和代理的健康状态
- 在 Enclave 内缓存加密密钥以避免每次请求的延迟
- 单个 M5A 2xlarge EC2 实例可实现 150-200 TPS 的吞吐量

### 延迟优化策略 (55:00-59:00)

55:00-56:30 - 协议优化
- 在整个堆栈中使用 TLS 1.3 和 HTTP/2.0
- TLS 1.3 减少一次往返，HTTP/2.0 提供多路复用连接
- AWS 负载均衡器和应用都支持这些协议
- 建议客户端也使用 TLS 1.3 和 HTTP/2.0 以获得更好的端到端延迟和吞吐量

56:30-59:00 - 网络优化
- API Gateway 入站流量使用 VPC 端点
- 后端集成使用 VPC Link
- 确保流量完全在 Amazon 骨干网络上，提供一致的低延迟性能
- NLB 启用客户端路由策略亲和性：流量保持在客户端发起请求的可用区内
- 启用跨区域负载均衡以提供高可用性
- 网关应用在启动时获取密钥并缓存在内存中，后台线程按需刷新

### Amazon EKS 优化 (59:00-66:00)

59:00-61:00 - 负载均衡器控制器
- 使用 AWS Load Balancer Controller 配置和管理负载均衡器
- 为 Kubernetes Ingress 资源配置 ALB
- 为 Kubernetes LoadBalancer 资源配置 NLB
- NLB 可以使用实例或 IP 目标类型
- 使用 IP 目标类型：Pod 直接从 VPC 子网获取 IP 地址，避免额外的网络跳转，提供更好的性能

61:00-64:00 - Pod 调度策略
- 三种控制 Pod 调度的方式：
  1. 节点亲和性(Node Affinity)：将 Pod 放置在具有特定特征的节点上（如启用 Enclave 的节点）
  2. Pod 亲和性和反亲和性：
     - Pod 亲和性：将协同工作负载放在一起（如 Web 服务器和缓存 Pod）
     - Pod 反亲和性：将 Pod 分布在故障域中以提供高可用性（如三个副本不在同一可用区）
  3. 拓扑分布约束：确保单个服务的 Pod 副本在不同故障域中均匀分布

64:00-66:00 - 拓扑感知路由
- 将网络流量保持在发起请求的可用区内
- 有助于提高可靠性、性能并降低成本（跨区域流量收费）
- 使用 auto 模式：自动将流量保持在同一可用区
- 智能默认：如果该可用区没有健康的 Pod，自动路由到其他可用区
- 通过向端点切片添加提示来工作
- 建议每个可用区至少运行三个副本
- 结合所有优化，实现了 250 毫秒的延迟目标
- P99.5 延迟比目标低约 40%
- 成功测试了高达 10,000 TPS 的突发流量

### 多区域主-主架构 (66:00-69:00)

66:00-68:00 - 架构设计
- 使用 Cloudflare Akamai DNS 将流量路由到最近的区域
- 每个区域在三个可用区部署计算和数据服务
- 负载均衡器在三个可用区之间分配流量
- 应用层写入本地和远程区域的 ElastiCache 用于实时重复检查
- Amazon MSK 数据使用 MSK Replicator 复制，用于近实时特征工程流程

68:00-69:00 - 数据复制
- S3 跨区域复制用于离线流程管道存储桶
- Aurora DB 用于文件处理管道
- 使用 Aurora Global DB 从主区域复制到次区域
- MSK Replicator、S3 跨区域复制和 Aurora Global DB 复制减少了运维复杂性
- AWS 负责复制开销
- 提供全球高可用性、灾难恢复能力和一致的性能

### 总结与关键收获 (69:00-结束)

69:00-71:00 - 项目里程碑
- Himma Zuchi 总结关键收获
- 这是 Visa 首次将内部系统迁移到云端
- Visa 在构建混合云解决方案上投入了大量时间和精力
- Visa Protect A2A 是首批使用混合云解决方案的应用之一

71:00-73:00 - 技术成就
- 构建了符合 Visa 严格运营和网络安全指导的解决方案
- 在混合云上实现 10,000 TPS、99.99% 可用性和亚秒级延迟
- 该解决方案被视为蓝图，已在英国区域全面运行，客户正在使用评分服务

73:00-结束 - 全球扩展与合作伙伴关系
- 使用该蓝图快速扩展到其他区域
- 使用 IaC 脚本根据区域需求进行微调
- 正在将解决方案扩展到南美市场，巴西圣保罗区域即将上线
- 与 AWS 团队（Suraj 团队）建立了强大的合作伙伴关系
- 过去两年半与 Visa 内部多个团队（运营、网络安全等）合作构建该解决方案
- 强调了团队合作和 AWS 技术支持的重要性