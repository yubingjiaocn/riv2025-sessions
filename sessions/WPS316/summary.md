# AWS re:Invent 2025 会议总结：康奈尔大学 AI 沙盒平台案例

## 一、会议概述

本次 AWS re:Invent 2025 分会场由 AWS 高级解决方案架构师 Mike Bernoni 以及康奈尔大学的 Marty Sullivan 和 Ferman Romero 共同主讲，重点介绍了康奈尔大学如何构建中央化 AI 沙盒平台来解决全校范围内的 AI 应用需求。

在 ChatGPT 于 2022 年发布后，康奈尔大学面临着与许多组织相同的挑战：各个学院和部门都在独立寻求 AI 解决方案，导致管理混乱、成本失控、数据隐私无法保障。康奈尔大学没有选择建立一个集中式 AI 团队来垄断所有 AI 项目，而是采取了一种创新方法——构建一个让所有人都能使用的 AI 平台，将 AI 工具交到真正了解问题的人手中。这个平台基于 Amazon Bedrock 和 AWS 无服务器架构构建，使教授、学生、教职员工和 IT 人员都能在一个安全、可控的环境中进行 AI 实验和创新。

该平台的核心理念是降低使用门槛，让 AI 成为像电子邮件或 Slack 一样的日常工具，而不是需要专门团队才能使用的专业项目。通过这种方式，康奈尔大学成功地将 AI 创新的权力下放给了最了解实际问题的个人贡献者，实现了快速的实验和部署周期。会议中展示了三个具体的成功案例，证明了这种平台化方法的有效性。

## 二、详细时间线与关键要点

### **00:00 - 开场介绍**
- Mike Bernoni 介绍会议主题和面临的普遍问题
- 描述组织中常见的 AI 应用困境：员工想使用 AI 改进流程，但不知从何开始

### **01:30 - 问题定义**
- 员工面临的挑战：AI 服务和模型选择困难、不知道向谁申请批准
- 常见的错误做法：建立影子 IT、将敏感数据发送到公共 AI 服务、或者干脆放弃创新

### **02:45 - 康奈尔大学的解决方案**
- 构建了一个中央化 AI 沙盒平台
- 基于 Amazon Bedrock 和无服务器架构
- 为全校提供统一的 AI 实验起点

### **03:30 - 演讲嘉宾介绍**
- Mike Bernoni：AWS 高级解决方案架构师
- Marty Sullivan 和 Ferman Romero：康奈尔大学技术团队成员

### **04:15 - 传统方法的局限性**
- ChatGPT 2022 年发布后，各学院独立联系 OpenAI 和 Anthropic
- 缺乏安全实验环境、无法集成现有工作流、没有成本和数据保护控制

### **05:30 - 康奈尔的创新思路**
- 核心问题："如果我们不为用户构建解决方案，而是让他们自己构建会怎样?"
- 让教授和一线员工成为问题的解决者
- AI 应该是日常工具，而不是专业项目

### **06:45 - 关键 AWS 服务介绍**
- CloudFormation：管理基础设施部署
- CodeBuild 和 CodePipeline：编排 CI/CD 工作流
- ECS Fargate：部署容器化应用，自动处理扩展
- Amazon Bedrock：提供基础模型访问

### **07:30 - 模型更新的便利性**
- Anthropic 发布新版 Claude 模型时，康奈尔可以立即访问
- 无需供应商谈判或 API 重写
- 只需更新配置中的一行代码即可切换模型

### **08:45 - Ferman Romero 介绍平台架构**
- 平台由三个核心组件组成
- LiteLLM：作为 AI 网关，位于 Bedrock 之上
- N8N：自动化平台，称为"代理工作室"，低代码环境
- LibreChat：类似 ChatGPT 的聊天界面

### **10:00 - Marty Sullivan 详细技术架构**
- AI Commons：面向最终用户的第一层
- 重点构建对话式界面（Slack、Teams、邮件）而非传统 Web 应用
- 将 AI 代理视为同事而非应用程序

### **11:30 - 代理工作室 (Agent Studio)**
- 使用 N8N 作为可视化低代码工作流构建服务
- 整合技术债务到统一平台
- 让校园内的多个专家能够快速理解和协作

### **12:45 - AI 网关的优势**
- 使用开源的 LiteLLM 软件
- 可以控制对 AI 模型、MCP 服务器的访问
- IT 组织可以管理数据访问权限和代理访问控制

### **14:00 - 平台的重要性**
- 不锁定单一 AI 模型提供商
- 用户可以根据任务切换不同模型
- 可以配置备用模型确保高可用性
- 可以选择最便宜的模型

### **15:15 - 规模和使用情况**
- 需要支持数千甚至数百万请求
- 已有 24 个内部项目每天使用网关
- 招募了 70 名硕士研究生参与项目
- 来自不同部门的技术负责人加入团队

### **16:30 - 监控和审计能力**
- 监控 AI 使用情况和支出
- 可以轻松生成审计报告
- 了解康奈尔大学如何使用 AI

### **17:45 - 共享责任模型**
- 类似 AWS 的方法
- 为非 IT 人员提供工具
- 与用户达成使用协议：允许使用的数据类型、敏感数据处理方式

### **19:00 - 安全措施**
- 创建护栏和监控
- 自动化检查用户构建的代理
- 对不当使用凭证发出警报

### **20:15 - DevOps 和快速发布周期**
- 使用 AWS CodePipeline
- 代码存储在 GitHub
- 容器镜像存储在 ECR
- 使用 CodeBuild 构建容器
- 通过 CloudFormation 部署到 ECS

### **21:30 - 高可用性架构**
- 集成单点登录 (SSO)
- 使用应用负载均衡器实现高可用性
- 跨可用区提供服务
- 使用 Fargate 简化基础设施管理

### **22:45 - 模型更新速度**
- LiteLLM 和 N8N 对新模型提供零日支持
- 通常在 1-2 周内提供新 API 功能的稳定版本
- 过去 6 个月，每次新模型发布都能在当天或几天内提供

### **24:00 - 用例一：VERA (价值观探索与反思助手)**
- 问题：每年 900 名工程新生需要明确自己的价值观和目标
- 传统方法：雇佣约 70 名专业教练进行一对一辅导

### **25:30 - VERA 的实现**
- 副院长 Erica Dawson 使用 Claude for Desktop 花费数周编写复杂的系统提示
- 包含研究信息的 PDF 和详细的行为指导
- 团队将其数据集和系统提示集成到 N8N 代理中

### **27:00 - VERA 的技术细节**
- 使用与 Claude for Desktop 相同的模型确保一致性
- 配置自动故障转移
- 使用 Bedrock 护栏防止提示注入和不当对话
- 工作流程相对简单，包含共享对话历史

### **28:45 - VERA 的成功指标**
- 2025 年 6 月开始讨论，7 月即上线
- 向 900 多名学生开放
- 零支持请求
- 超过 40,000 次学生互动
- 副院长完成了大部分工作，IT 团队只需几天时间

### **30:00 - VERA 的用户反馈**
- 收集了学生、教练和员工的反馈
- 反馈压倒性地积极
- 展示的引用并非精心挑选

### **31:15 - 用例二：苏格拉底式聊天机器人**
- 问题：大型课堂（300+ 学生）难以评估学生理解程度
- 教授 Toby Alt 的气候与能源课程
- 学生多为非理科专业，需要满足理科要求

### **32:30 - 评估挑战**
- 教授只能通过学生的面部表情判断理解程度
- 需要更好的方法评估学生是否真正理解课程内容
- 区分理解和死记硬背

### **33:45 - 产品需求**
- 与教授合作制定用户故事和验收标准
- 与教学创新中心合作
- 必须集成到现有的 Canvas 学习管理系统中
- 设置时间不能超过 10-15 分钟

### **35:00 - 布鲁姆分类法 (Bloom's Taxonomy)**
- 使用经过验证的教学框架
- 金字塔式结构：从回忆基本事实到创造新解决方案
- 本课程目标是达到第三级（应用知识）

### **36:30 - 学生体验设计**
- 需要明确的完成标准
- 不能只是无休止的聊天
- 实现透明的进度条引导学生通过布鲁姆分类法
- 目标是达到第三级理解

### **38:00 - 苏格拉底式聊天机器人的价值**
- 学生可以随时回顾主题
- 批判性思考而非多选题
- 模拟与助教或教授的办公时间对话
- 提供即时反馈

### **39:15 - 教师洞察**
- 分析对话后获得见解
- 如果 20 名学生都达到应用级别，说明班级整体理解
- 如果 20 名学生中有 5 名在某主题上挣扎，提示需要在下次课程中重新讲解

### **40:30 - 演示邀请**
- 可以在展会的公共部门展位查看苏格拉底式聊天应用的演示

### **41:00 - 用例三：费用报销自动化 (Ferman Romero)**
- 问题：校园组织费用报销流程复杂且耗时
- 1,500 个校园团体，每学期约 10,000 个报销请求

### **42:15 - 传统流程的复杂性**
- 从简单的披萨销售到复杂的活动（AV 公司、餐饮公司）
- 每个请求可能需要 30 分钟处理
- 需要检查多个系统和规则（不能购买酒精、礼品卡等）
- 学生经常丢失详细收据

### **44:00 - AI 解决方案：上下文提示**
- 通过 API 访问各种系统以编程方式收集数据
- 查找预算信息和各种项目
- 将收据发送到 LLM 并提问

### **45:30 - 关键问题识别**
- 最大痛点：详细收据 vs 普通收据
- 学生不理解两种收据的区别
- LLM 擅长回答简单的是/否问题

### **46:45 - 工作流程设计**
- 数据收集过程：下载指南和审计说明
- 存储在 S3 存储桶中以便修改（非硬编码）
- 调用校园团体信息系统
- 学生通过调查流程提交信息

### **48:00 - 自动化分析**
- 询问 LLM："这是详细收据吗？"
- 询问："有酒精吗？"
- 要求 JSON 格式的明确是/否答案
- LLM 不需要推测，只需分析图像上的文本

### **49:15 - 技术实现细节**
- 工作流程包含数据收集、API 调用、LLM 分析
- 使用 Markdown 文件存储规则，便于更新
- 多个处理步骤构建最终提示

### **50:30 - 会议总结**
- 三个用例展示了平台的多样性和灵活性
- 从一次性活动（VERA）到日常工具（苏格拉底式聊天）再到后台自动化（费用报销）
- 证明了将 AI 工具交给最了解问题的人的价值
- 平台化方法实现了快速创新和规模化部署

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


核心技术栈总结：
- Amazon Bedrock（基础模型访问）
- LiteLLM（AI 网关）
- N8N（低代码自动化平台）
- LibreChat（聊天界面）
- AWS CodePipeline、CodeBuild、CloudFormation
- ECS Fargate、ECR、Application Load Balancer
- S3（存储配置和文档）