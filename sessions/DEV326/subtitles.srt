1
00:00:01,528 --> 00:00:02,610
(audience chattering)

2
00:00:02,610 --> 00:00:03,610
- Let's get started.

3
00:00:06,840 --> 00:00:09,510
Every day, people are on the move,

4
00:00:09,510 --> 00:00:11,910
whether jet sitting across the continents,

5
00:00:11,910 --> 00:00:13,800
or raising through the ranks,

6
00:00:13,800 --> 00:00:16,743
or savoring their
unforgettable experiences,

7
00:00:17,940 --> 00:00:19,830
but out of all this,

8
00:00:19,830 --> 00:00:24,000
every financial institutions
have one common mission.

9
00:00:24,000 --> 00:00:25,860
That is to ensure that

10
00:00:25,860 --> 00:00:29,790
your funds flow in the right directions,

11
00:00:29,790 --> 00:00:33,843
slowly, safely and smoothly,

12
00:00:35,130 --> 00:00:38,700
and ensure that every single
transaction checks out,

13
00:00:38,700 --> 00:00:43,020
stays compliant and
keeps us all protected.

14
00:00:43,020 --> 00:00:45,750
Because the world moves so fast

15
00:00:45,750 --> 00:00:48,720
that the right flow of fund

16
00:00:48,720 --> 00:00:51,693
and the airtight compliance is crucial.

17
00:00:52,860 --> 00:00:56,160
This lets us run without a glitch.

18
00:00:56,160 --> 00:00:58,290
This is Bhuvaneswari Subramani here,

19
00:00:58,290 --> 00:01:00,917
Chief Evangelist at Intuitive.ai,

20
00:01:00,917 --> 00:01:03,420
AWS Hero and AWS Ambassador

21
00:01:03,420 --> 00:01:07,770
joining hands with two amazing
machine learning heroes,

22
00:01:07,770 --> 00:01:10,680
Ayyanar Jeyakrishnan and Vivek Raja PS

23
00:01:10,680 --> 00:01:12,900
from AWS India community,

24
00:01:12,900 --> 00:01:17,900
joining here to talk
about AWS Strands power.

25
00:01:18,630 --> 00:01:20,670
That is we are gonna
talk about the use case,

26
00:01:20,670 --> 00:01:23,970
anti-money laundering,
multi-agent orchestration

27
00:01:23,970 --> 00:01:26,910
with AWS Strands and this will prepare you

28
00:01:26,910 --> 00:01:29,680
to help the financial institutions

29
00:01:30,870 --> 00:01:33,780
maintain compliance with confidence.

30
00:01:33,780 --> 00:01:35,530
That's what we are gonna see today.

31
00:01:38,610 --> 00:01:40,950
So we'll be focusing on the global impact

32
00:01:40,950 --> 00:01:44,970
of anti-money laundering
and the evolving compliance.

33
00:01:44,970 --> 00:01:48,330
We are gonna see how
the Agentic AI workflow

34
00:01:48,330 --> 00:01:52,080
implemented using AWS Strands
is going to solve this problem

35
00:01:52,080 --> 00:01:54,240
against the financial crime.

36
00:01:54,240 --> 00:01:59,070
And we will also take you
through the demo in detail

37
00:01:59,070 --> 00:02:00,753
with a real life solution.

38
00:02:03,450 --> 00:02:06,827
So, financial crime is a global crisis.

39
00:02:07,853 --> 00:02:12,697
Around 3.1 trillion illicit
funds (audience applauds)

40
00:02:12,697 --> 00:02:17,310
flowed in 2023 and the
similar pattern got repeated

41
00:02:17,310 --> 00:02:20,414
in 2024 as well.

42
00:02:20,414 --> 00:02:22,320
Where are these funds coming from?

43
00:02:22,320 --> 00:02:27,300
Majority of these things,
majority of the causes

44
00:02:27,300 --> 00:02:32,300
are from drug trafficking,
human trafficking,

45
00:02:32,490 --> 00:02:35,703
terrorism, and fraud.

46
00:02:37,980 --> 00:02:40,680
So all of these things constitutes

47
00:02:40,680 --> 00:02:45,330
towards millions of dollars loss.

48
00:02:45,330 --> 00:02:47,580
It's a huge financial impact, right?

49
00:02:47,580 --> 00:02:50,550
So much of these things goes undetected.

50
00:02:50,550 --> 00:02:52,680
That's why we say that
anti-money laundering

51
00:02:52,680 --> 00:02:54,660
is very, very crucial.

52
00:02:54,660 --> 00:02:57,720
So financial organizations like FinCEN

53
00:02:57,720 --> 00:03:02,700
have started working on
regulations for a quite long time

54
00:03:02,700 --> 00:03:05,130
and no one can solve this alone.

55
00:03:05,130 --> 00:03:07,800
That's why we are here to talk about

56
00:03:07,800 --> 00:03:11,060
how Agentic AI solutions
powered by Strands SDK

57
00:03:11,060 --> 00:03:12,963
is gonna help fight against this.

58
00:03:14,100 --> 00:03:15,450
And when we are talking about this,

59
00:03:15,450 --> 00:03:17,370
if we go on little bit of history,

60
00:03:17,370 --> 00:03:20,130
I'm not a much of a
history person, but still,

61
00:03:20,130 --> 00:03:22,230
let's take a quick step back and see

62
00:03:22,230 --> 00:03:25,230
how the AML standards have evolved.

63
00:03:25,230 --> 00:03:29,740
It started with the
Bank Secrecy Act in 1970

64
00:03:30,990 --> 00:03:35,990
followed by creation of FATF

65
00:03:36,060 --> 00:03:40,320
which had 40 specific
standards as a recommendations

66
00:03:40,320 --> 00:03:42,840
that the institutions have to follow.

67
00:03:42,840 --> 00:03:45,990
And 1992 was the year

68
00:03:45,990 --> 00:03:48,990
where Suspicious Activity
Report came into existence.

69
00:03:48,990 --> 00:03:51,090
That is, if there is any deviation

70
00:03:51,090 --> 00:03:52,830
in the financial transaction,

71
00:03:52,830 --> 00:03:55,710
the financial organization has to

72
00:03:55,710 --> 00:03:59,130
file the Suspicious Activity Report.

73
00:03:59,130 --> 00:04:02,220
It could be a real legitimate risk

74
00:04:02,220 --> 00:04:03,570
or it could be a potential risk,

75
00:04:03,570 --> 00:04:06,510
but it's the duty of the
financial institution

76
00:04:06,510 --> 00:04:09,040
to file the Suspicious Activity Report

77
00:04:10,470 --> 00:04:12,420
and also it continue to evolve.

78
00:04:12,420 --> 00:04:15,690
In 2020 is what we had this
anti-money laundering act

79
00:04:15,690 --> 00:04:17,460
that came into picture.

80
00:04:17,460 --> 00:04:21,480
So this is the history of
how these things evolved

81
00:04:21,480 --> 00:04:24,420
and each milestone have only increased

82
00:04:24,420 --> 00:04:26,490
the responsibility and vigilance

83
00:04:26,490 --> 00:04:28,140
for the financial institutions,

84
00:04:28,140 --> 00:04:30,900
how we can fight against
this financial crime.

85
00:04:30,900 --> 00:04:33,500
So why are we talking about
all these things, right?

86
00:04:34,589 --> 00:04:38,460
So we have to deal with
diverse set of data

87
00:04:38,460 --> 00:04:41,970
when we are talking about
anti-money laundering.

88
00:04:41,970 --> 00:04:43,923
So in today's enterprise world,

89
00:04:45,120 --> 00:04:47,490
we operate a mix of legacy applications

90
00:04:47,490 --> 00:04:50,370
combined with modern technologies.

91
00:04:50,370 --> 00:04:54,150
So justice, goods and capitals flow freely

92
00:04:54,150 --> 00:04:55,830
across the borders.

93
00:04:55,830 --> 00:04:58,320
It is the responsibility of
the financial institutions

94
00:04:58,320 --> 00:05:03,240
to ensure that the money
flows the right way

95
00:05:03,240 --> 00:05:04,770
without a glitch.

96
00:05:04,770 --> 00:05:06,840
That is very, very essential, right?

97
00:05:06,840 --> 00:05:09,630
So here the organizations,

98
00:05:09,630 --> 00:05:11,760
the financial institutions
deal with diverse data.

99
00:05:11,760 --> 00:05:15,570
It could be your financial
transactions, customer profiles

100
00:05:15,570 --> 00:05:19,110
or it could be the KYC
data, even newsfeeds, right?

101
00:05:19,110 --> 00:05:20,640
There could be some newsfeeds,

102
00:05:20,640 --> 00:05:22,140
there was some issue they raised

103
00:05:22,140 --> 00:05:24,030
or standards that got published.

104
00:05:24,030 --> 00:05:27,540
So they love to keep track
of all of these diverse data

105
00:05:27,540 --> 00:05:32,540
and you have the high volume
data, high velocity of data

106
00:05:32,790 --> 00:05:35,010
coming from different data sets,

107
00:05:35,010 --> 00:05:38,163
all of these things have to
be taken through our system.

108
00:05:39,030 --> 00:05:43,293
That system is like a legacy
traditional rule-based system.

109
00:05:44,460 --> 00:05:45,850
This rule-based system

110
00:05:46,800 --> 00:05:50,040
actually had too many false alarms.

111
00:05:50,040 --> 00:05:52,920
These are a false positive up to 95%.

112
00:05:52,920 --> 00:05:55,440
For example, if there is an enterprise

113
00:05:55,440 --> 00:05:58,710
which has the business sending alerts

114
00:05:58,710 --> 00:06:00,810
about the legitimate transactions,

115
00:06:00,810 --> 00:06:04,320
maybe report anything about 10,000 USD,

116
00:06:04,320 --> 00:06:07,350
if it's going to report about 10,000 USD,

117
00:06:07,350 --> 00:06:10,080
there could be hundreds
of legitimate transactions

118
00:06:10,080 --> 00:06:11,340
happening in that month.

119
00:06:11,340 --> 00:06:14,940
If it ends up prompting
and reporting for all that

120
00:06:14,940 --> 00:06:17,220
and later the compliance personnel,

121
00:06:17,220 --> 00:06:19,800
the human was to sit and review this,

122
00:06:19,800 --> 00:06:22,980
it takes a lot of time, lot of energy,

123
00:06:22,980 --> 00:06:26,430
waste of resources costing
all of that, right?

124
00:06:26,430 --> 00:06:30,210
So, this slows down the
real threat detection.

125
00:06:30,210 --> 00:06:31,560
So what do we need?

126
00:06:31,560 --> 00:06:35,160
We need real context aware methods

127
00:06:35,160 --> 00:06:38,760
which can cut down the false
alarms, increase the focus,

128
00:06:38,760 --> 00:06:43,290
and then helps us to detect
the real risk quickly

129
00:06:43,290 --> 00:06:44,430
at a lower cost.

130
00:06:44,430 --> 00:06:45,813
That is what we need.

131
00:06:47,730 --> 00:06:51,210
Before we get into the actual solution

132
00:06:51,210 --> 00:06:53,460
and agentic AI implementation,

133
00:06:53,460 --> 00:06:55,980
I wanna talk a little
bit about the technology

134
00:06:55,980 --> 00:06:57,873
that is powering the implementation.

135
00:06:59,670 --> 00:07:03,150
So let me say something.

136
00:07:03,150 --> 00:07:06,780
All of us might have used
talking to either Siri

137
00:07:06,780 --> 00:07:10,830
or your Alexa, a bank chatbot,
something or the other,

138
00:07:10,830 --> 00:07:12,930
even in the middle of night.

139
00:07:12,930 --> 00:07:17,400
Many times we would've felt
that it is far more better

140
00:07:17,400 --> 00:07:21,720
and easier to talk to these
bots than your close friend

141
00:07:21,720 --> 00:07:24,780
or even your spouse for the matter, right?

142
00:07:24,780 --> 00:07:28,860
So I see a lot of smiles.
So this is a fact.

143
00:07:28,860 --> 00:07:33,860
So when you have a bot which
is so powerful in responding,

144
00:07:34,110 --> 00:07:38,670
let's see, what is the
tech powering the bots?

145
00:07:38,670 --> 00:07:40,200
Imagine you have an agent

146
00:07:40,200 --> 00:07:42,390
which is so powerful implemented for this.

147
00:07:42,390 --> 00:07:45,420
So what is this agent basically built out?

148
00:07:45,420 --> 00:07:49,170
We also had lot of things
that Dr. Swami covered

149
00:07:49,170 --> 00:07:52,920
as part of our morning Agentic
AI keynote about the agents

150
00:07:52,920 --> 00:07:54,960
and the latest launches.

151
00:07:54,960 --> 00:07:57,510
So when you talk about an agent in simple,

152
00:07:57,510 --> 00:08:00,270
you have a prompt which
is sent to the agent,

153
00:08:00,270 --> 00:08:02,190
that is the question
that you wanted to ask.

154
00:08:02,190 --> 00:08:05,400
Maybe you have diverse
set of data coming in,

155
00:08:05,400 --> 00:08:08,190
you're defining an agent which
is going to take your data,

156
00:08:08,190 --> 00:08:09,023
process it.

157
00:08:10,260 --> 00:08:12,540
So when the prompt is sent to the agent,

158
00:08:12,540 --> 00:08:16,080
the agent is capable of invoking any tool.

159
00:08:16,080 --> 00:08:17,820
It could be the code interpreter

160
00:08:17,820 --> 00:08:20,430
or it could talk to
your database, anything.

161
00:08:20,430 --> 00:08:22,290
It could invoke your tool.

162
00:08:23,247 --> 00:08:25,020
The tool will process the information

163
00:08:25,020 --> 00:08:27,540
and return the data through the agent.

164
00:08:27,540 --> 00:08:30,330
And the agent is also
capable of invoking the LLMs,

165
00:08:30,330 --> 00:08:33,390
it could be Ollama, GPT, anything.

166
00:08:33,390 --> 00:08:36,510
So this again fetches the
results back to the agent.

167
00:08:36,510 --> 00:08:38,550
So both the results are
available in the agent

168
00:08:38,550 --> 00:08:41,280
and the agent is going to
process that and create

169
00:08:41,280 --> 00:08:44,460
or curate a human readable content

170
00:08:44,460 --> 00:08:46,170
and it's gonna pass it on to the user

171
00:08:46,170 --> 00:08:48,960
or the application from where
this agent is being invoked.

172
00:08:48,960 --> 00:08:51,240
So that's the agent in nutshell.

173
00:08:51,240 --> 00:08:54,420
So when we say agent, what
is the difference between

174
00:08:54,420 --> 00:08:56,670
agentic AI and agentic AI workflow?

175
00:08:56,670 --> 00:08:58,980
Because the solution that
we are going to implement

176
00:08:58,980 --> 00:09:01,203
for this is agentic AI workflow, right?

177
00:09:02,370 --> 00:09:06,750
So the agentic AI, it's
basically autonomous entity

178
00:09:06,750 --> 00:09:11,220
which makes decisions and
act upon those additions

179
00:09:11,220 --> 00:09:16,220
to accomplish a goal with
minimal human intervention.

180
00:09:16,380 --> 00:09:19,080
And when you talk about
agentic AI workflow,

181
00:09:19,080 --> 00:09:21,510
it's the coordinated sequence

182
00:09:21,510 --> 00:09:25,080
where the multiple
agents are orchestrating

183
00:09:25,080 --> 00:09:27,450
to accomplish a complex goal

184
00:09:27,450 --> 00:09:30,450
to solve the biggest
problem that you have.

185
00:09:30,450 --> 00:09:32,790
So this is what we talk about agentic AI

186
00:09:32,790 --> 00:09:34,230
and agentic AI workflow.

187
00:09:34,230 --> 00:09:39,230
And when do we use agentic AI workflow?

188
00:09:39,270 --> 00:09:42,360
Just because everywhere
we talk about agents,

189
00:09:42,360 --> 00:09:45,060
not necessary that we have
to use only agentic AI

190
00:09:45,060 --> 00:09:48,060
to every damn problem that we see.

191
00:09:48,060 --> 00:09:50,070
There are advantages in using traditional

192
00:09:50,070 --> 00:09:51,360
as well as agentic AI.

193
00:09:51,360 --> 00:09:53,730
So that's what I wanted
to talk about in this.

194
00:09:53,730 --> 00:09:56,700
So when you take about agentic AI,

195
00:09:56,700 --> 00:10:00,270
when you wanna deal
with complex workflows,

196
00:10:00,270 --> 00:10:03,270
when you have a diverse data set

197
00:10:03,270 --> 00:10:08,070
or when you wanted to have a
memory that is to be retained

198
00:10:08,070 --> 00:10:12,090
after the conversations that
is happening from start to end,

199
00:10:12,090 --> 00:10:15,930
so in all these cases you will
go for Agentic AI workflow.

200
00:10:15,930 --> 00:10:18,180
When we talk about the
tools that is powering this,

201
00:10:18,180 --> 00:10:20,250
you will understand
and relate this better.

202
00:10:20,250 --> 00:10:22,410
But for now, so for all these scenarios,

203
00:10:22,410 --> 00:10:24,330
we'll go for Agentic AI workflow.

204
00:10:24,330 --> 00:10:26,130
And for the traditional,

205
00:10:26,130 --> 00:10:29,010
when you have the mission
critical applications

206
00:10:29,010 --> 00:10:31,800
where the results has to
be 100% deterministic,

207
00:10:31,800 --> 00:10:34,560
we would go for this traditional workflow.

208
00:10:34,560 --> 00:10:38,790
And when you have a system
which needs ultra low latency,

209
00:10:38,790 --> 00:10:39,990
you need this.

210
00:10:39,990 --> 00:10:43,000
And if it is a fixed rule-based system

211
00:10:43,980 --> 00:10:47,220
which can actually derive
better results with that

212
00:10:47,220 --> 00:10:50,730
than traditional solution is better.

213
00:10:50,730 --> 00:10:53,190
Okay, so now when we
talk about these things,

214
00:10:53,190 --> 00:10:56,430
what are the technology that
is powering these solutions?

215
00:10:56,430 --> 00:10:59,580
So we are gonna talk about AWS Strands SDK

216
00:10:59,580 --> 00:11:04,350
and Amazon Bedrock AgentCore
which has powered these things.

217
00:11:04,350 --> 00:11:08,910
So when you say Strands SDK,
it's the open source framework

218
00:11:08,910 --> 00:11:11,820
from Amazon with which

219
00:11:11,820 --> 00:11:15,840
without worrying too much
about the infrastructure

220
00:11:15,840 --> 00:11:20,280
or writing thousands and
thousands of lines of code

221
00:11:20,280 --> 00:11:22,050
with just few lines,

222
00:11:22,050 --> 00:11:26,670
anybody should be able to create an agent.

223
00:11:26,670 --> 00:11:28,680
If you had watched the keynote today,

224
00:11:28,680 --> 00:11:30,960
so Swami gave an amazing number,

225
00:11:30,960 --> 00:11:33,600
there are already over 5 million downloads

226
00:11:33,600 --> 00:11:35,640
for this Strands SDK.

227
00:11:35,640 --> 00:11:38,490
People are really using
like day in and day out.

228
00:11:38,490 --> 00:11:40,170
Anybody talking about agents

229
00:11:40,170 --> 00:11:41,880
are building agents with Strands SDK.

230
00:11:41,880 --> 00:11:44,520
It's becoming so, so powerful.

231
00:11:44,520 --> 00:11:47,310
So that's what we have used
as well to create our agents.

232
00:11:47,310 --> 00:11:49,830
It can actually natively integrate

233
00:11:49,830 --> 00:11:51,900
with any of the AWS services

234
00:11:51,900 --> 00:11:55,200
and it can connect to native
tools, any MCP servers,

235
00:11:55,200 --> 00:11:57,600
whether you have created or it's external.

236
00:11:57,600 --> 00:12:00,870
iI works seamlessly, it
can work with any model.

237
00:12:00,870 --> 00:12:02,943
That is the power of Strands SDK.

238
00:12:03,909 --> 00:12:08,909
And so when you have one agent,
you create it for one task,

239
00:12:09,390 --> 00:12:10,620
it's all good, right?

240
00:12:10,620 --> 00:12:14,850
Imagine you have a stream
of agent interconnected

241
00:12:14,850 --> 00:12:19,850
to actually think, act
and remember all at once

242
00:12:19,980 --> 00:12:21,363
at a massive scale.

243
00:12:22,590 --> 00:12:27,390
That's when we need service
like Bedrock AgentCore

244
00:12:27,390 --> 00:12:30,450
to take care all of this completely.

245
00:12:30,450 --> 00:12:32,999
So you build agent with Strands SDK

246
00:12:32,999 --> 00:12:36,720
or you can build agents with
any framework for the matter.

247
00:12:36,720 --> 00:12:41,720
It could be from Llama,
LlamaIndex, LangChain, LangGraph

248
00:12:42,458 --> 00:12:45,120
CrewAI or Google.

249
00:12:45,120 --> 00:12:47,340
So you build with anything.

250
00:12:47,340 --> 00:12:50,820
You can use Amazon Bedrock
AgentCore to deploy,

251
00:12:50,820 --> 00:12:52,830
that is so, so powerful.

252
00:12:52,830 --> 00:12:55,860
It is not just a single service.

253
00:12:55,860 --> 00:12:58,470
It's a composite suite of services

254
00:12:58,470 --> 00:13:02,250
which helps you address
whole lot of logistics

255
00:13:02,250 --> 00:13:05,130
that is involved in deploying an agent

256
00:13:05,130 --> 00:13:06,720
at a production scale.

257
00:13:06,720 --> 00:13:09,780
You imagine an agent when
you wanted to deploy,

258
00:13:09,780 --> 00:13:11,730
you don't have to deal
with infrastructure,

259
00:13:11,730 --> 00:13:13,860
that's where runtime comes into picture.

260
00:13:13,860 --> 00:13:15,690
And when you're deploying it,

261
00:13:15,690 --> 00:13:18,120
you have to ensure that the conversation

262
00:13:18,120 --> 00:13:22,440
between the agents are secured, seamless

263
00:13:22,440 --> 00:13:26,790
and nothing gets leaked beyond
the conversation context.

264
00:13:26,790 --> 00:13:30,510
So in this case, the identity
management comes into picture.

265
00:13:30,510 --> 00:13:33,000
So when your agent wanted to interact with

266
00:13:33,000 --> 00:13:34,800
other tools and other stuff,

267
00:13:34,800 --> 00:13:37,440
Bedrock AgentCore gateway is there.

268
00:13:37,440 --> 00:13:41,880
And when you wanted to
audit, debug and report,

269
00:13:41,880 --> 00:13:45,480
that's where AgentCore
observability is there.

270
00:13:45,480 --> 00:13:48,180
And so when you want these information

271
00:13:48,180 --> 00:13:51,510
across the conversations and
chats has to be remembered,

272
00:13:51,510 --> 00:13:53,130
refer for insights,

273
00:13:53,130 --> 00:13:55,710
that's when AgentCore
memory comes into picture.

274
00:13:55,710 --> 00:13:59,880
All of these components
holistically work together

275
00:13:59,880 --> 00:14:04,110
to help you deploy agent
run at a production scale.

276
00:14:04,110 --> 00:14:05,940
But otherwise, if you see,

277
00:14:05,940 --> 00:14:09,060
I have a friend who was actually saying

278
00:14:09,060 --> 00:14:14,060
when you do a lot of POCs,
agentic AI solutions,

279
00:14:15,240 --> 00:14:18,090
most of the POCs end by like death by POC.

280
00:14:18,090 --> 00:14:21,570
That's a term, it was
used by one of my friend.

281
00:14:21,570 --> 00:14:24,660
So everybody starts
with agentic AI, right?

282
00:14:24,660 --> 00:14:28,050
Where it suffers, where it struggles is,

283
00:14:28,050 --> 00:14:30,840
but for taking it to
production has been struggles.

284
00:14:30,840 --> 00:14:34,860
That's where AgentCore is
here to rescue and take care.

285
00:14:34,860 --> 00:14:38,700
Let's drill down and look
into three major components.

286
00:14:38,700 --> 00:14:41,010
We can talk about AgentCore
for hours together,

287
00:14:41,010 --> 00:14:42,090
but I want to drill down

288
00:14:42,090 --> 00:14:44,280
and talk about three
important components here

289
00:14:44,280 --> 00:14:45,630
which we are gonna extensively use

290
00:14:45,630 --> 00:14:47,820
for the workflow that we have designed.

291
00:14:47,820 --> 00:14:50,400
So you take AgentCore runtime,

292
00:14:50,400 --> 00:14:53,640
it is the completely
managed serverless service

293
00:14:53,640 --> 00:14:56,190
but it's not like a
traditional serverless service.

294
00:14:56,190 --> 00:14:58,140
We are just invoking a function,

295
00:14:58,140 --> 00:15:00,300
returning a result and going to use it.

296
00:15:00,300 --> 00:15:05,190
This AgentCore runtime is a micro VM.

297
00:15:05,190 --> 00:15:10,190
Whenever you are hosting an
agent, deploying an agent,

298
00:15:10,800 --> 00:15:15,420
this micro VM is started and
this micro VM is available

299
00:15:15,420 --> 00:15:18,210
and runs for the maximum up to eight hours

300
00:15:18,210 --> 00:15:20,550
to serve the functionality of the agent

301
00:15:20,550 --> 00:15:22,890
to the invoked application.

302
00:15:22,890 --> 00:15:25,890
So that is how the micro VM is available,

303
00:15:25,890 --> 00:15:28,203
which is unlike the traditional system.

304
00:15:29,430 --> 00:15:33,810
And using this you can actually
deploy the agents created

305
00:15:33,810 --> 00:15:36,180
from any framework as I mentioned earlier.

306
00:15:36,180 --> 00:15:38,236
It could be from your
LangChain, LangGraph,

307
00:15:38,236 --> 00:15:40,020
LlamaIndex, or CrewAI.

308
00:15:40,020 --> 00:15:41,910
Irrespective of that
you'll be able to build,

309
00:15:41,910 --> 00:15:43,050
all that you needed is

310
00:15:43,050 --> 00:15:45,060
when you invoke this AgentCore runtime,

311
00:15:45,060 --> 00:15:47,460
it creates the docker composed file

312
00:15:47,460 --> 00:15:51,180
and it deploys it to the ECS repository.

313
00:15:51,180 --> 00:15:53,910
Once it is, the image is made available

314
00:15:53,910 --> 00:15:58,740
in the ECR repository, it can be invoked

315
00:15:58,740 --> 00:16:00,210
and deployed into the runtime.

316
00:16:00,210 --> 00:16:03,690
Once it is deployed, you have
an endpoint made available

317
00:16:03,690 --> 00:16:05,970
which can be used to
integrate with the application

318
00:16:05,970 --> 00:16:08,700
to serve your customer request.

319
00:16:08,700 --> 00:16:12,570
So that's how this AgentCore
runtime works in a nutshell.

320
00:16:12,570 --> 00:16:15,363
And when we talk about
the AgentCore gateway,

321
00:16:16,320 --> 00:16:19,350
so you are creating one agent.

322
00:16:19,350 --> 00:16:21,960
This agent cannot work alone.

323
00:16:21,960 --> 00:16:26,523
It need to interact with
multiple agent, right?

324
00:16:27,390 --> 00:16:29,400
So when you wanted this agent to interact

325
00:16:29,400 --> 00:16:32,070
with multiple agent, for an example,

326
00:16:32,070 --> 00:16:34,290
we spoke about diverse data.

327
00:16:34,290 --> 00:16:37,110
When the diverse data
coming in, we have an agent

328
00:16:37,110 --> 00:16:38,910
which is going to read the data

329
00:16:38,910 --> 00:16:42,810
and see whether some data is
actually false positive or not.

330
00:16:42,810 --> 00:16:44,280
So you need an agent.

331
00:16:44,280 --> 00:16:49,200
So this agent should also
go and check the KYC data

332
00:16:49,200 --> 00:16:54,200
or the last seven days data
to see was there any risk.

333
00:16:55,110 --> 00:16:57,750
So when it has to do all of these things,

334
00:16:57,750 --> 00:16:59,610
it has to interact with different tools.

335
00:16:59,610 --> 00:17:02,040
One agent cannot do everything, right?

336
00:17:02,040 --> 00:17:05,550
It needs to have multiple
agents or multiple tools.

337
00:17:05,550 --> 00:17:08,790
So, you can use AgentCore gateway

338
00:17:08,790 --> 00:17:10,800
to connect to the API gateway

339
00:17:10,800 --> 00:17:14,520
and the API gateway in turn
connect to different tools

340
00:17:14,520 --> 00:17:16,560
within AWS services, it can invoke

341
00:17:16,560 --> 00:17:20,190
and it processes and returns
the information that is needed.

342
00:17:20,190 --> 00:17:23,770
We can also make this AgentCore gateway

343
00:17:24,810 --> 00:17:26,580
connect to your lambda function,

344
00:17:26,580 --> 00:17:28,620
which is gonna again
process a set of tools

345
00:17:28,620 --> 00:17:30,030
and return the results.

346
00:17:30,030 --> 00:17:32,970
It can talk to another set of MCP tools.

347
00:17:32,970 --> 00:17:35,160
So the inbound authentication stops

348
00:17:35,160 --> 00:17:39,000
at this AgentCore gateway
and the AgentCore gateway

349
00:17:39,000 --> 00:17:42,000
takes care of the rest of the
interactions with the tools,

350
00:17:42,000 --> 00:17:47,000
MCP tools or the AWS services
like API endpoint or Lambda

351
00:17:47,070 --> 00:17:48,120
and the return results.

352
00:17:48,120 --> 00:17:51,660
So that's how AgentCore gateway works.

353
00:17:51,660 --> 00:17:53,910
And the next one important thing is,

354
00:17:53,910 --> 00:17:55,890
okay, you have a runtime you have hosted,

355
00:17:55,890 --> 00:17:58,740
you have a gateway which
can help you interact,

356
00:17:58,740 --> 00:18:01,473
all is fine but we need memory.

357
00:18:02,460 --> 00:18:04,950
Whatever conversation that happens,

358
00:18:04,950 --> 00:18:06,870
whatever the processing that happens,

359
00:18:06,870 --> 00:18:09,510
all that has to be recorded, stored,

360
00:18:09,510 --> 00:18:13,230
for using it now, at least
during the process or later.

361
00:18:13,230 --> 00:18:17,400
So for that the AgentCore
memory has an amazing feature.

362
00:18:17,400 --> 00:18:18,870
Let's talk about two things.

363
00:18:18,870 --> 00:18:21,690
Short term memory and
long-term memory, how it works.

364
00:18:21,690 --> 00:18:24,900
So when you take an agent, there
is an agent implementation.

365
00:18:24,900 --> 00:18:26,580
When the agent is implemented,

366
00:18:26,580 --> 00:18:29,040
there will be a sequence
of event happenings.

367
00:18:29,040 --> 00:18:31,110
When the sequence of events are happening,

368
00:18:31,110 --> 00:18:34,290
there are messages which gets exchanged

369
00:18:34,290 --> 00:18:36,540
and the state that needs to be stored.

370
00:18:36,540 --> 00:18:39,180
So these messages and states

371
00:18:39,180 --> 00:18:41,981
will be stored in a memory
called short-term memory.

372
00:18:41,981 --> 00:18:45,070
And this short term memory
can be made available

373
00:18:46,050 --> 00:18:49,980
or stored maximum up to 365 days.

374
00:18:49,980 --> 00:18:53,250
Don't ask why 365 days, it's a number,

375
00:18:53,250 --> 00:18:54,840
it's nice to say one year, right?

376
00:18:54,840 --> 00:18:57,540
So it is configurable,

377
00:18:57,540 --> 00:18:59,760
you can say whether I
need it for like one month

378
00:18:59,760 --> 00:19:02,820
or 365 days, but the maximum is 365 days

379
00:19:02,820 --> 00:19:04,440
for short term memory.

380
00:19:04,440 --> 00:19:06,720
And in case of long term memory,

381
00:19:06,720 --> 00:19:10,170
you have a module called
automatic memory extraction module

382
00:19:10,170 --> 00:19:11,730
which processes these data

383
00:19:11,730 --> 00:19:14,790
which gets stored in short-term
memory asynchronously

384
00:19:14,790 --> 00:19:18,630
and extracts insights, summary information

385
00:19:18,630 --> 00:19:20,670
or the semantic data,

386
00:19:20,670 --> 00:19:23,400
all of that and stores
in the long term memory.

387
00:19:23,400 --> 00:19:26,520
On the other hand, the agentic
implementation that has,

388
00:19:26,520 --> 00:19:29,010
whenever it needs any
of these information,

389
00:19:29,010 --> 00:19:30,600
could be user preferences

390
00:19:30,600 --> 00:19:33,150
or the insights that
you wanted to process,

391
00:19:33,150 --> 00:19:36,960
you can actually go ahead
and invoke this information

392
00:19:36,960 --> 00:19:39,720
and then use it asynchronously.

393
00:19:39,720 --> 00:19:42,090
So that's how short term
and long-term memory

394
00:19:42,090 --> 00:19:43,980
is super beneficial

395
00:19:43,980 --> 00:19:47,370
for the agentic AI
workflow implementation.

396
00:19:47,370 --> 00:19:52,370
So we saw what is the global
impact of anti-money laundering

397
00:19:52,950 --> 00:19:56,220
and we went through the diverse
set of data that we have,

398
00:19:56,220 --> 00:19:58,530
how the false alarms gets raised,

399
00:19:58,530 --> 00:20:01,890
how the compliance have been evolving

400
00:20:01,890 --> 00:20:03,450
and we also spoke about the tech

401
00:20:03,450 --> 00:20:06,360
that is powering this agentic AI solution.

402
00:20:06,360 --> 00:20:09,060
And our agentic AI workflow is implemented

403
00:20:09,060 --> 00:20:13,710
using strands SDK and
Amazon Agent Bedrock Core.

404
00:20:13,710 --> 00:20:18,710
So with this insights I
would call upon my co-speaker

405
00:20:19,440 --> 00:20:22,650
Ayyanar Jeyakrishnan, AJ
to continue from here.

406
00:20:22,650 --> 00:20:23,643
Thank you so much.

407
00:20:33,150 --> 00:20:34,473
- Thanks Bhuvana. Okay.

408
00:20:35,340 --> 00:20:40,340
So we all love Strands
which is really flexible

409
00:20:40,500 --> 00:20:44,010
and we also allow the
AgentCore is very modular

410
00:20:44,010 --> 00:20:47,040
and we can deploy at a scale.

411
00:20:47,040 --> 00:20:49,770
And let's dive into the solution,

412
00:20:49,770 --> 00:20:52,000
how are we solving the
anti-money laundering

413
00:20:53,310 --> 00:20:55,053
leveraging the agentic workflow.

414
00:20:56,610 --> 00:20:59,070
So these are the agents we lined up

415
00:20:59,070 --> 00:21:00,840
act as an individual persona,

416
00:21:00,840 --> 00:21:04,440
each one has a different role
to play in this workflow.

417
00:21:04,440 --> 00:21:07,563
Let's start with the first
agent, Perception Agent.

418
00:21:08,850 --> 00:21:11,430
This naming convention speaks for it.

419
00:21:11,430 --> 00:21:14,910
When the transaction
comes, it'll understand

420
00:21:14,910 --> 00:21:19,860
what is this transaction, add
additional perception to it,

421
00:21:19,860 --> 00:21:22,983
then it'll connect to the
different data source.

422
00:21:24,420 --> 00:21:26,730
Based on your requirement,
based on your enterprise,

423
00:21:26,730 --> 00:21:28,560
it'll connect to the different data source

424
00:21:28,560 --> 00:21:30,100
and add to the context agent

425
00:21:31,001 --> 00:21:33,600
and the data source can be varied

426
00:21:33,600 --> 00:21:36,330
but the context you need
to have a streamline,

427
00:21:36,330 --> 00:21:39,000
the information before sending

428
00:21:39,000 --> 00:21:43,800
to any kind of reasoning agent.

429
00:21:43,800 --> 00:21:45,630
So the context, whatever we are telling,

430
00:21:45,630 --> 00:21:48,660
it's all between the enterprise, okay?

431
00:21:48,660 --> 00:21:52,460
But when come to the enterprise,

432
00:21:53,790 --> 00:21:55,830
the real time data matters a lot.

433
00:21:55,830 --> 00:21:57,990
That's where we are going
to add the news agent

434
00:21:57,990 --> 00:21:59,160
into the mixture

435
00:21:59,160 --> 00:22:01,530
which will connect to
the real time data source

436
00:22:01,530 --> 00:22:03,990
and add to the reasoning agent.

437
00:22:03,990 --> 00:22:06,420
This is where the real powerful comes.

438
00:22:06,420 --> 00:22:11,310
The reasoning agent will leverage
both the unstructured data

439
00:22:11,310 --> 00:22:14,280
as well as it user existing context

440
00:22:14,280 --> 00:22:16,290
retrieved from your enterprise

441
00:22:16,290 --> 00:22:20,337
and make a reasoning and
forward to the risk agent.

442
00:22:20,337 --> 00:22:23,280
The risk agent make a decision,

443
00:22:23,280 --> 00:22:28,280
it can connect to your enterprise
existing risk AML models

444
00:22:28,890 --> 00:22:31,020
as well as based on all the context

445
00:22:31,020 --> 00:22:33,450
we have retrieved from you this workflow,

446
00:22:33,450 --> 00:22:37,140
it also give a context and make a risk.

447
00:22:37,140 --> 00:22:38,460
Then, Action Agent comes.

448
00:22:38,460 --> 00:22:41,730
So all good currently whatever
the actions we are making,

449
00:22:41,730 --> 00:22:44,460
it's all highly manual.

450
00:22:44,460 --> 00:22:48,780
This action agent take out
those major chunk of this action

451
00:22:48,780 --> 00:22:49,950
and automate it,

452
00:22:49,950 --> 00:22:51,900
like it can do the
straight through processing

453
00:22:51,900 --> 00:22:53,013
if it all goes good.

454
00:22:53,850 --> 00:22:57,540
And after that all the workflows are fine.

455
00:22:57,540 --> 00:23:00,570
When come to any financial institution

456
00:23:00,570 --> 00:23:02,670
or any enterprise we are building it,

457
00:23:02,670 --> 00:23:04,140
application we are building it,

458
00:23:04,140 --> 00:23:06,600
the audit play a pivotal role.

459
00:23:06,600 --> 00:23:11,400
And when come to the audit,
all the agent make a decision

460
00:23:11,400 --> 00:23:14,620
and we want to make sure every
information will be triaged

461
00:23:15,480 --> 00:23:16,740
and logged.

462
00:23:16,740 --> 00:23:19,920
So, if anybody want to
go and make a decision

463
00:23:19,920 --> 00:23:21,810
why the risk score was different,

464
00:23:21,810 --> 00:23:23,100
we have all the information

465
00:23:23,100 --> 00:23:26,190
from multiple agent went
through, we have an audit.

466
00:23:26,190 --> 00:23:29,283
Then learning agent, this is
one of the my favorite agent.

467
00:23:30,210 --> 00:23:33,630
We need to keep the system more autonomous

468
00:23:33,630 --> 00:23:35,730
because we want to, whatever we observe,

469
00:23:35,730 --> 00:23:39,570
we want to add to the
system as a feedback loop.

470
00:23:39,570 --> 00:23:42,540
So it'll be evolved
over the period of time,

471
00:23:42,540 --> 00:23:44,550
then we need to create a final report.

472
00:23:44,550 --> 00:23:46,560
So if you find it suspicious,

473
00:23:46,560 --> 00:23:50,400
you need to create the
Suspicious Activity Report.

474
00:23:50,400 --> 00:23:53,340
We will create a report leveraging LLM.

475
00:23:53,340 --> 00:23:56,010
This is a high level, we
orchestrated the workflow,

476
00:23:56,010 --> 00:23:57,570
it's completely modular.

477
00:23:57,570 --> 00:24:01,440
We can fix, we can plug
into our enterprise need

478
00:24:01,440 --> 00:24:02,703
with a different agent.

479
00:24:04,500 --> 00:24:06,570
I want a little bit zoomed
down on the risk agent,

480
00:24:06,570 --> 00:24:08,310
which is very important.

481
00:24:08,310 --> 00:24:09,240
Okay.

482
00:24:09,240 --> 00:24:12,330
Based on the risk agent, the
action agent will be invoked.

483
00:24:12,330 --> 00:24:16,020
Okay, if the score is less
than 30, okay, perfect,

484
00:24:16,020 --> 00:24:17,850
we can do the straight through processing.

485
00:24:17,850 --> 00:24:20,160
The agent can do their
straight through processing.

486
00:24:20,160 --> 00:24:24,720
Then if there is the score
is on 30 or between 50,

487
00:24:24,720 --> 00:24:26,070
this will vary.

488
00:24:26,070 --> 00:24:29,640
We can make sure we
are notifying it, okay,

489
00:24:29,640 --> 00:24:32,400
and if it find it's a repeated pattern,

490
00:24:32,400 --> 00:24:35,760
we need to mandatorily file the report.

491
00:24:35,760 --> 00:24:39,840
The report will be created
using LLM and we also make sure

492
00:24:39,840 --> 00:24:44,220
this transaction is monitored and flagged.

493
00:24:44,220 --> 00:24:47,730
But if we feel the score is high,

494
00:24:47,730 --> 00:24:50,310
currently whatever the
action we are making,

495
00:24:50,310 --> 00:24:52,890
sometimes most of the time
we do the false positive

496
00:24:52,890 --> 00:24:56,280
but with this kind of
approach we will be able to

497
00:24:56,280 --> 00:24:59,223
take a freeze that and make a next action.

498
00:25:01,980 --> 00:25:05,133
This is how the overall
system we have orchestrated.

499
00:25:06,720 --> 00:25:09,360
Let me come into the
technical deep dive off

500
00:25:09,360 --> 00:25:10,800
how we lined up this agent,

501
00:25:10,800 --> 00:25:14,385
how we use the Strands
and made it (indistinct)

502
00:25:14,385 --> 00:25:18,030
We made it as a layered
approach based on the use case.

503
00:25:18,030 --> 00:25:20,907
We all started with a major
chunk of use case in the AML,

504
00:25:20,907 --> 00:25:23,280
the transaction monitoring

505
00:25:23,280 --> 00:25:27,450
and post created this workflow
end-to-end and made it work.

506
00:25:27,450 --> 00:25:30,060
We made plugged into the additional layer

507
00:25:30,060 --> 00:25:32,250
which we added a more context

508
00:25:32,250 --> 00:25:35,970
by adding the real time
information like news, OFAC,

509
00:25:35,970 --> 00:25:37,143
all those information.

510
00:25:38,220 --> 00:25:39,930
Now we have created a context,

511
00:25:39,930 --> 00:25:41,760
we have created a end-to-end workflow.

512
00:25:41,760 --> 00:25:43,830
We want to make it more autonomous.

513
00:25:43,830 --> 00:25:45,960
That's where the third layer comes.

514
00:25:45,960 --> 00:25:49,230
We have made it, added the learning agent

515
00:25:49,230 --> 00:25:54,210
and we added a more audit
into the picture, okay.

516
00:25:54,210 --> 00:25:57,693
So this is how step by step
we have built the agents.

517
00:25:59,774 --> 00:26:02,790
Let me dive into the
transaction monitoring

518
00:26:02,790 --> 00:26:04,203
and spend some time on it.

519
00:26:05,820 --> 00:26:09,510
The real time data we are
processing using a Kinesis.

520
00:26:09,510 --> 00:26:11,910
Once we have our real time data,

521
00:26:11,910 --> 00:26:14,510
based on that transaction information,

522
00:26:14,510 --> 00:26:16,470
we will connect to the
existing data source.

523
00:26:16,470 --> 00:26:20,310
It can be your CRM or think
like we have our everything

524
00:26:20,310 --> 00:26:23,850
in our RDS or our relational database.

525
00:26:23,850 --> 00:26:27,510
It'll go connect to it to get those KYC

526
00:26:27,510 --> 00:26:29,850
and the perception agent based on that

527
00:26:29,850 --> 00:26:33,000
it'll create a triage of how
this transaction looks like.

528
00:26:33,000 --> 00:26:34,360
We are using Bedrock

529
00:26:35,790 --> 00:26:38,853
for different kind of model for
different different purpose.

530
00:26:39,840 --> 00:26:43,140
Now let me come to the next
one, the context agent.

531
00:26:43,140 --> 00:26:45,390
With all the information we collected,

532
00:26:45,390 --> 00:26:47,190
we created the context agent.

533
00:26:47,190 --> 00:26:50,760
But the context agent
had a very critical thing

534
00:26:50,760 --> 00:26:52,710
about the historical data.

535
00:26:52,710 --> 00:26:53,940
The historical data

536
00:26:53,940 --> 00:26:57,360
currently we are keeping all
the information at DynamoDB

537
00:26:57,360 --> 00:27:01,350
for the faster retrieval and
we build a flurry of tools.

538
00:27:01,350 --> 00:27:02,940
Take a last in transaction,

539
00:27:02,940 --> 00:27:07,530
the so and so data and
transaction is recently flagged.

540
00:27:07,530 --> 00:27:11,190
We created multiple tools
using a Lambda function

541
00:27:11,190 --> 00:27:15,240
and we kept AgentCore
gateway as a front end

542
00:27:15,240 --> 00:27:17,560
and we connect from the context agent

543
00:27:18,450 --> 00:27:22,170
to those lambda function to
retrieve the data via gateway.

544
00:27:22,170 --> 00:27:24,270
So we no need to change the architecture.

545
00:27:24,270 --> 00:27:26,490
If you have an additional requirement

546
00:27:26,490 --> 00:27:28,650
to connect to the data, all you need to do

547
00:27:28,650 --> 00:27:32,520
is build an additional tool
and it'll be more flexible.

548
00:27:32,520 --> 00:27:34,623
Based on your requirement, we can add it.

549
00:27:35,820 --> 00:27:38,610
Now we have created a context agent

550
00:27:38,610 --> 00:27:40,950
and connect it to the historical data

551
00:27:40,950 --> 00:27:43,740
with the real time data, good.

552
00:27:43,740 --> 00:27:46,230
Now we are adding to the reasoning agent.

553
00:27:46,230 --> 00:27:48,930
All the contacts will be
sent to the reasoning agent.

554
00:27:48,930 --> 00:27:50,820
It used the reasoning model

555
00:27:50,820 --> 00:27:52,740
to make a complete understanding.

556
00:27:52,740 --> 00:27:54,910
It created a risk score by itself

557
00:27:55,860 --> 00:27:58,710
based on the how we
prompted and orchestrated

558
00:27:58,710 --> 00:28:02,610
with all the context, we
got it from perception agent

559
00:28:02,610 --> 00:28:04,233
as well as the context agent.

560
00:28:08,400 --> 00:28:11,830
Once we have the complete
details from the context agent

561
00:28:13,789 --> 00:28:17,250
and the reasoning agent we are
taking into the action agent.

562
00:28:17,250 --> 00:28:19,380
We created a tools here also.

563
00:28:19,380 --> 00:28:22,800
We can build the multiple tools
based on your requirement.

564
00:28:22,800 --> 00:28:24,780
At least for the transaction monitoring,

565
00:28:24,780 --> 00:28:26,760
the notification is very important.

566
00:28:26,760 --> 00:28:29,010
We created a tool for a notification

567
00:28:29,010 --> 00:28:31,620
and also we want to make
sure if it is high risk,

568
00:28:31,620 --> 00:28:34,260
we want to flag the transaction.

569
00:28:34,260 --> 00:28:37,410
So we have created the tool
based on the information,

570
00:28:37,410 --> 00:28:38,670
we got it from the context,

571
00:28:38,670 --> 00:28:40,713
we got it from the reasoning agent.

572
00:28:41,640 --> 00:28:43,620
We will be able to make action.

573
00:28:43,620 --> 00:28:46,170
And if we find it,

574
00:28:46,170 --> 00:28:49,590
yes, this is a transaction
which we want to create

575
00:28:49,590 --> 00:28:51,870
the Suspicious Action Report.

576
00:28:51,870 --> 00:28:55,380
Currently in industry everything
need to be done manually

577
00:28:55,380 --> 00:28:57,270
and whatever the
transaction they have seen,

578
00:28:57,270 --> 00:28:59,070
they have to create a manual report.

579
00:28:59,070 --> 00:29:01,500
With the proper prompt template structure,

580
00:29:01,500 --> 00:29:03,870
we will be able to pre-fill this one

581
00:29:03,870 --> 00:29:05,373
and store it into the S3.

582
00:29:08,790 --> 00:29:12,240
As I mentioned clearly, auditing
is a very important task

583
00:29:12,240 --> 00:29:14,070
if you want to make a decision.

584
00:29:14,070 --> 00:29:17,190
That's where the audit agent
will come into the picture.

585
00:29:17,190 --> 00:29:19,740
All the context we've
taken from the perception

586
00:29:19,740 --> 00:29:22,980
to all the layers and
whatever the action we take,

587
00:29:22,980 --> 00:29:26,700
we audit everything and
keep it in elastic search.

588
00:29:26,700 --> 00:29:27,600
So think like it.

589
00:29:27,600 --> 00:29:31,170
If they found there is a
suspicious in the transaction,

590
00:29:31,170 --> 00:29:33,690
it automatically created a report.

591
00:29:33,690 --> 00:29:36,060
If the human in the loop,
they can check the report

592
00:29:36,060 --> 00:29:38,580
at the same time how we made a decision,

593
00:29:38,580 --> 00:29:40,530
everything will be in elastic search.

594
00:29:40,530 --> 00:29:43,110
So that is how we orchestrated this flow

595
00:29:43,110 --> 00:29:44,703
for the transaction monitoring.

596
00:29:49,080 --> 00:29:52,830
The next layer what we build
is the adverse media monitoring

597
00:29:52,830 --> 00:29:56,520
where we want to add the
real time information

598
00:29:56,520 --> 00:29:58,350
of the news, okay?

599
00:29:58,350 --> 00:30:01,410
We added a news, we created a new agent

600
00:30:01,410 --> 00:30:03,750
which is a News Herald agent.

601
00:30:03,750 --> 00:30:05,400
So that is how we model...

602
00:30:05,400 --> 00:30:07,890
We make it very flexible

603
00:30:07,890 --> 00:30:11,360
so we can keep adding our
agent based on our use case,

604
00:30:11,360 --> 00:30:13,710
with the power of Strands and AgentCore.

605
00:30:13,710 --> 00:30:16,170
We added the News Herald agent

606
00:30:16,170 --> 00:30:18,330
and whatever the information it is getting

607
00:30:18,330 --> 00:30:19,860
it added to the memory.

608
00:30:19,860 --> 00:30:21,000
Why memory?

609
00:30:21,000 --> 00:30:23,910
Imagine if there is a
new transaction coming

610
00:30:23,910 --> 00:30:25,710
and the same person is doing it.

611
00:30:25,710 --> 00:30:28,440
We want to make a quick action.

612
00:30:28,440 --> 00:30:32,340
So yesterday there is a news
comes and we may be flagged

613
00:30:32,340 --> 00:30:34,020
and if there is a change in news,

614
00:30:34,020 --> 00:30:36,300
it'll have both the context
that is a negative news,

615
00:30:36,300 --> 00:30:38,970
there is a positive news,
this is a recent information,

616
00:30:38,970 --> 00:30:40,860
we can make a decision accordingly.

617
00:30:40,860 --> 00:30:44,040
Currently whatever we are doing
is we are doing it manually

618
00:30:44,040 --> 00:30:46,050
but with the AgentCore memory,

619
00:30:46,050 --> 00:30:48,750
this will add a context in a real time

620
00:30:48,750 --> 00:30:53,160
what we are fetching from the
news agent to make a decision.

621
00:30:53,160 --> 00:30:55,650
All this will be fed
into the context agent.

622
00:30:55,650 --> 00:31:00,570
If you look at before,
this will add your batch,

623
00:31:00,570 --> 00:31:03,450
your previous internal
information to the context

624
00:31:03,450 --> 00:31:04,890
in a transaction monitoring.

625
00:31:04,890 --> 00:31:07,790
Here we are adding a real time
information to the context.

626
00:31:09,780 --> 00:31:11,820
So news is one factor

627
00:31:11,820 --> 00:31:15,870
but when we come to the
anti-money laundering,

628
00:31:15,870 --> 00:31:17,280
it's very vast.

629
00:31:17,280 --> 00:31:19,260
Country to country, it'll be vary.

630
00:31:19,260 --> 00:31:21,690
The data source which the each country

631
00:31:21,690 --> 00:31:24,720
or the whatever the act
they have will keep vary.

632
00:31:24,720 --> 00:31:28,200
Take an example of OFAC, Office
of Foreign Asset Control,

633
00:31:28,200 --> 00:31:31,440
which publish the report very frequently.

634
00:31:31,440 --> 00:31:35,880
It has all the information if
any political exposed person,

635
00:31:35,880 --> 00:31:37,860
something of the sanctions are happening.

636
00:31:37,860 --> 00:31:39,480
Every information will be here.

637
00:31:39,480 --> 00:31:40,740
This, I'm taking an example.

638
00:31:40,740 --> 00:31:42,540
So based on your requirement

639
00:31:42,540 --> 00:31:44,610
we can add to that particular data source.

640
00:31:44,610 --> 00:31:49,610
We use the Lambda which will
periodically retrieve the data

641
00:31:50,010 --> 00:31:52,950
and of course we are using a
Bedrock to do the embedding

642
00:31:52,950 --> 00:31:54,900
and write it to our knowledge base.

643
00:31:54,900 --> 00:31:56,043
Why knowledge base?

644
00:31:57,060 --> 00:32:00,330
The News Herald agent,
whichever we built it,

645
00:32:00,330 --> 00:32:03,540
it have both the context of
the real-time information

646
00:32:03,540 --> 00:32:05,100
which we fetch from the news

647
00:32:05,100 --> 00:32:08,940
as well as according
to your country or act,

648
00:32:08,940 --> 00:32:11,910
it'll have this information
in a Bedrock knowledge base.

649
00:32:11,910 --> 00:32:15,183
Both information will be
fed into the context agent.

650
00:32:20,250 --> 00:32:21,210
Okay.

651
00:32:21,210 --> 00:32:23,670
So post to the second...

652
00:32:23,670 --> 00:32:26,010
This is the final layer we have built.

653
00:32:26,010 --> 00:32:29,880
It's all more about instant
risk interdiction, okay?

654
00:32:29,880 --> 00:32:32,160
The reason why we want
to do this banner is

655
00:32:32,160 --> 00:32:35,670
currently mostly we are
doing in a reactive fashion.

656
00:32:35,670 --> 00:32:37,980
Now as I'm saying it's
not a hundred percentage

657
00:32:37,980 --> 00:32:39,930
we will be able to proactively do it

658
00:32:39,930 --> 00:32:41,760
but we can make a quick correction

659
00:32:41,760 --> 00:32:44,550
and avoid more false
positive in this approach.

660
00:32:44,550 --> 00:32:46,980
Here we added two more agent.

661
00:32:46,980 --> 00:32:51,030
One is on the risk assessor agent.

662
00:32:51,030 --> 00:32:53,310
What this risk assessor
agent will do, right?

663
00:32:53,310 --> 00:32:56,580
So it'll integrate to your class,

664
00:32:56,580 --> 00:32:59,040
internally currently whatever
the way we are doing, right?

665
00:32:59,040 --> 00:33:00,390
We may be using a classic model,

666
00:33:00,390 --> 00:33:03,390
it can be your classification model

667
00:33:03,390 --> 00:33:04,890
or it can be your clustering model

668
00:33:04,890 --> 00:33:07,320
like classic ML model you have.

669
00:33:07,320 --> 00:33:11,040
That is how we are flagging
whether it is a risk or not.

670
00:33:11,040 --> 00:33:13,680
What we are doing is we are adding that

671
00:33:13,680 --> 00:33:16,650
as an additional context
to the action agent.

672
00:33:16,650 --> 00:33:19,230
So whatever the information we got it,

673
00:33:19,230 --> 00:33:23,310
we are adding a new agent which
will connect us to the API

674
00:33:23,310 --> 00:33:25,140
and get what is the risk score

675
00:33:25,140 --> 00:33:27,900
for this kind of transaction

676
00:33:27,900 --> 00:33:30,150
and add this information
to the action agent.

677
00:33:31,500 --> 00:33:36,500
And finally we are adding
the learning agent.

678
00:33:37,800 --> 00:33:40,560
Whatever information the risk was done,

679
00:33:40,560 --> 00:33:42,210
it'll be taken into the account...

680
00:33:42,210 --> 00:33:43,530
Using the learning agent,

681
00:33:43,530 --> 00:33:46,440
it'll take all the context information

682
00:33:46,440 --> 00:33:49,200
and write it back to the DynamoDB,

683
00:33:49,200 --> 00:33:51,120
then it act as a feedback loop

684
00:33:51,120 --> 00:33:53,160
for our transaction monitoring.

685
00:33:53,160 --> 00:33:56,190
This is how we have structured the agent.

686
00:33:56,190 --> 00:33:59,010
So it is highly modular,
every use case will differ

687
00:33:59,010 --> 00:34:02,280
and every requirement may be
differ based on your use case.

688
00:34:02,280 --> 00:34:04,950
You can think this as a known reference

689
00:34:04,950 --> 00:34:06,500
and you can build on top of it.

690
00:34:08,700 --> 00:34:10,380
What we have done on this workflow,

691
00:34:10,380 --> 00:34:12,240
what we learned on this workflow, right?

692
00:34:12,240 --> 00:34:16,050
We identified the classic
ML way we are doing

693
00:34:16,050 --> 00:34:18,870
is really, really working well.

694
00:34:18,870 --> 00:34:20,100
But that is a challenge.

695
00:34:20,100 --> 00:34:22,590
We are not able to do
proactive action, okay?

696
00:34:22,590 --> 00:34:25,260
Because lot of decision we are making,

697
00:34:25,260 --> 00:34:27,240
it's all in unstructured manner.

698
00:34:27,240 --> 00:34:31,860
This agentic workflow, we
added the classic ML feature

699
00:34:31,860 --> 00:34:36,420
into our agent workflow pipeline
and we leveraged the gen AI

700
00:34:36,420 --> 00:34:38,910
to process the unstructured data.

701
00:34:38,910 --> 00:34:43,910
And using a bedrock, we applied
all the guardrails needed

702
00:34:44,340 --> 00:34:46,290
to make sure that it is not hallucinating

703
00:34:46,290 --> 00:34:48,783
or it aligned to the enterprise need.

704
00:34:52,050 --> 00:34:53,610
What we have achieved via

705
00:34:53,610 --> 00:34:55,710
this anti-money laundering agentic system

706
00:34:55,710 --> 00:34:58,863
we built using Strands
and AgentCore, right?

707
00:34:59,880 --> 00:35:03,000
I love the future of observability,
AgentCore observability.

708
00:35:03,000 --> 00:35:06,390
All the information we have
called what tool we have called

709
00:35:06,390 --> 00:35:08,940
and how much time the
tool spend that time,

710
00:35:08,940 --> 00:35:10,590
how we made all the information.

711
00:35:10,590 --> 00:35:12,780
I no need to build anything.

712
00:35:12,780 --> 00:35:15,750
I take care of my audit trial

713
00:35:15,750 --> 00:35:18,630
and what done at the transaction level,

714
00:35:18,630 --> 00:35:21,270
everything was observed
by the observability.

715
00:35:21,270 --> 00:35:24,330
Then real time injection,
we have used a kinesis

716
00:35:24,330 --> 00:35:27,360
or we can use a Kafka
according to our requirement.

717
00:35:27,360 --> 00:35:30,270
And session installation, we are adding,

718
00:35:30,270 --> 00:35:32,610
the context is what the
center of the piece, right?

719
00:35:32,610 --> 00:35:35,100
We are using a Bedrock knowledge base.

720
00:35:35,100 --> 00:35:37,380
We are using a AgentCore memory

721
00:35:37,380 --> 00:35:39,960
to manage that complete session

722
00:35:39,960 --> 00:35:42,390
and semantic reasoning for it.

723
00:35:42,390 --> 00:35:44,370
And security and compliance,

724
00:35:44,370 --> 00:35:46,410
we want to store all the data into the S3

725
00:35:46,410 --> 00:35:50,430
and it is encrypted and
we are using a Bedrock.

726
00:35:50,430 --> 00:35:53,670
Connecting to the bedrock
model as well as AgentCore

727
00:35:53,670 --> 00:35:58,670
using a VPC endpoint, then all
the transaction information,

728
00:35:59,100 --> 00:36:03,150
the lineage, everything, we
are using a elastic search

729
00:36:03,150 --> 00:36:07,320
serverless which is highly
scalable for our requirement.

730
00:36:07,320 --> 00:36:10,920
Then, our favorite, we
are using different model

731
00:36:10,920 --> 00:36:12,240
for different requirement.

732
00:36:12,240 --> 00:36:13,073
We are using a...

733
00:36:13,073 --> 00:36:17,760
For the reasoning, we are
using a bedrock cloud model,

734
00:36:17,760 --> 00:36:19,890
sorry, under the bedrock
we are using a cloud model,

735
00:36:19,890 --> 00:36:22,590
for a different purpose, we
are using a (indistinct) model.

736
00:36:22,590 --> 00:36:25,080
So this is how we structured it.

737
00:36:25,080 --> 00:36:26,880
What is our expectation result?

738
00:36:26,880 --> 00:36:29,040
Yes, we reduce the manual review.

739
00:36:29,040 --> 00:36:33,180
As I mentioned how this report
was generated, it's manual.

740
00:36:33,180 --> 00:36:35,830
We are able to accelerate using our LLM

741
00:36:36,690 --> 00:36:40,470
to create those report and
reducing the false positive

742
00:36:40,470 --> 00:36:43,140
and try to track it in a earlier manner.

743
00:36:43,140 --> 00:36:46,620
And audit trial, whatever
the agentic workflow done,

744
00:36:46,620 --> 00:36:49,110
all the context, all
the lineage information,

745
00:36:49,110 --> 00:36:51,090
we are able to track it down.

746
00:36:51,090 --> 00:36:53,433
That is the expected results from us.

747
00:36:54,510 --> 00:36:57,540
That's all from me. And that's me AJ.

748
00:36:57,540 --> 00:37:00,870
I tried to hand over this
the demo, realtime demo

749
00:37:00,870 --> 00:37:03,873
which will be done by
Vivek, my fellow AI Hero.

750
00:37:06,300 --> 00:37:07,133
- Thank you.

751
00:37:16,820 --> 00:37:18,570
So it's time for the demo.

752
00:37:18,570 --> 00:37:20,280
We have understood how things work

753
00:37:20,280 --> 00:37:22,770
and what we have achieved to do.

754
00:37:22,770 --> 00:37:27,060
So I'm gonna concentrate on one
of the most important agents

755
00:37:27,060 --> 00:37:29,790
in this whole workflow,
which is the reasoning agent.

756
00:37:29,790 --> 00:37:31,440
So the reasoning agent is built

757
00:37:31,440 --> 00:37:33,450
using the Strands Agents SDK.

758
00:37:33,450 --> 00:37:36,690
And as you can see the
agent class is instantiated,

759
00:37:36,690 --> 00:37:38,280
which is from the Strands Agents

760
00:37:38,280 --> 00:37:40,890
and the name of that is reasoning agent.

761
00:37:40,890 --> 00:37:43,770
And the system prompt
actually defines the behavior

762
00:37:43,770 --> 00:37:46,680
of the whole agent, which
includes figuring out

763
00:37:46,680 --> 00:37:49,680
what the transaction does
by creating hypothesis,

764
00:37:49,680 --> 00:37:52,200
indicators, explanation, confidence

765
00:37:52,200 --> 00:37:55,530
and recommending what step
needs to be taken next

766
00:37:55,530 --> 00:37:58,050
for this particular
transaction that comes through.

767
00:37:58,050 --> 00:38:00,750
With that being said,
it also understands that

768
00:38:00,750 --> 00:38:04,350
the reasoning agent depends
on the output and the context

769
00:38:04,350 --> 00:38:08,430
that comes from the previous
agents that is in the workflow.

770
00:38:08,430 --> 00:38:11,400
That is help using our AgentCore memory.

771
00:38:11,400 --> 00:38:13,020
This helps the reasoning agent

772
00:38:13,020 --> 00:38:16,260
to make very informed
decision about how to navigate

773
00:38:16,260 --> 00:38:19,470
to make a informed decision
about a particular transaction

774
00:38:19,470 --> 00:38:23,670
before marking that as a
fraudulent transaction or not.

775
00:38:23,670 --> 00:38:27,030
So this AgentCore memory helps
you to maintain the context

776
00:38:27,030 --> 00:38:29,160
across the whole session of the workflow

777
00:38:29,160 --> 00:38:33,450
by saving the outputs of
each and every single agents

778
00:38:33,450 --> 00:38:35,730
that works in this particular workflow.

779
00:38:35,730 --> 00:38:39,720
And as you can see here, we
are trying to keep the context

780
00:38:39,720 --> 00:38:42,480
from perception context
and all the other agents

781
00:38:42,480 --> 00:38:45,420
and all these outputs
have been put under here.

782
00:38:45,420 --> 00:38:48,720
With that being said, this
helps you to actually understand

783
00:38:48,720 --> 00:38:51,420
how we need to actually
take a transaction,

784
00:38:51,420 --> 00:38:54,090
stream it through Kinesis,
take it from Lambda

785
00:38:54,090 --> 00:38:57,750
and also work through the
entire AgentCore system

786
00:38:57,750 --> 00:39:00,270
and figure out how this
transaction comes through.

787
00:39:00,270 --> 00:39:02,430
So this is a simple UI that we have built

788
00:39:02,430 --> 00:39:06,270
and this is preloaded
with a couple of scenarios

789
00:39:06,270 --> 00:39:08,760
that you can see on the left side.

790
00:39:08,760 --> 00:39:10,980
The scenarios are of
different transactions

791
00:39:10,980 --> 00:39:13,110
of different types of categories,

792
00:39:13,110 --> 00:39:15,390
which includes low risk
transaction, medium risk

793
00:39:15,390 --> 00:39:17,880
and high risk transactions.

794
00:39:17,880 --> 00:39:20,420
And you can notice at the below that...

795
00:39:21,840 --> 00:39:24,870
You can notice how in the
below that how this looks like

796
00:39:24,870 --> 00:39:29,870
and we have both a PEP
donation into microstate NGO.

797
00:39:31,830 --> 00:39:32,880
That is what we are going to pick

798
00:39:32,880 --> 00:39:35,130
as one of the first scenario

799
00:39:35,130 --> 00:39:36,510
that we wanted to run it through.

800
00:39:36,510 --> 00:39:38,340
And there are multiple orchestrations

801
00:39:38,340 --> 00:39:39,510
that we have already seen.

802
00:39:39,510 --> 00:39:40,530
We are gonna pick the first one

803
00:39:40,530 --> 00:39:43,350
which is your behavioral signal triage.

804
00:39:43,350 --> 00:39:47,220
And that has a five agent
system which is your perception,

805
00:39:47,220 --> 00:39:50,850
context, reasoning, action and audit.

806
00:39:50,850 --> 00:39:52,230
We are going to run the system to see

807
00:39:52,230 --> 00:39:54,750
how this transaction is being dealt

808
00:39:54,750 --> 00:39:56,100
with this agentic workflow.

809
00:39:57,660 --> 00:40:00,390
So all these agents are
being executed at the moment

810
00:40:00,390 --> 00:40:03,870
and once the whole execution is done,

811
00:40:03,870 --> 00:40:06,270
we also know how it really
works under the hood

812
00:40:06,270 --> 00:40:08,070
by interacting with the gateway

813
00:40:08,070 --> 00:40:09,990
and interacting with the AgentCore memory

814
00:40:09,990 --> 00:40:11,280
and all the other stuff.

815
00:40:11,280 --> 00:40:14,580
And the verdict that this
agentic workflow gives

816
00:40:14,580 --> 00:40:18,120
for the scenario is that you
need to file an SAR report

817
00:40:18,120 --> 00:40:20,190
and freeze this transaction.

818
00:40:20,190 --> 00:40:22,560
But we are really interested
to understand that

819
00:40:22,560 --> 00:40:25,080
how this decision is
really made by the agent

820
00:40:25,080 --> 00:40:27,870
because we want to uncover this black box.

821
00:40:27,870 --> 00:40:32,010
So the perception agent
tries to understand the users

822
00:40:32,010 --> 00:40:34,050
which is a receiver and the sender

823
00:40:34,050 --> 00:40:35,670
about what amount is being sent,

824
00:40:35,670 --> 00:40:37,560
what is the currency that is being there

825
00:40:37,560 --> 00:40:39,237
and where is it being sent and so on.

826
00:40:39,237 --> 00:40:42,060
And one of the most important
jobs of the perception agent

827
00:40:42,060 --> 00:40:44,670
is to understand the
KYC of both the sender

828
00:40:44,670 --> 00:40:46,500
and the receiver here.

829
00:40:46,500 --> 00:40:48,720
So it picks up the KYC details

830
00:40:48,720 --> 00:40:52,320
of the sender and the
receiver and as you can see

831
00:40:52,320 --> 00:40:55,320
the sender is also marked
as a high risk entity

832
00:40:55,320 --> 00:40:58,530
and the receiver KFC also have been marked

833
00:40:58,530 --> 00:41:02,040
as one of the high risk entity
that we have in the system.

834
00:41:02,040 --> 00:41:04,320
So these are some of
the important features

835
00:41:04,320 --> 00:41:07,740
that the perception agent
picks up and not just that,

836
00:41:07,740 --> 00:41:09,330
the perception agent also calculates

837
00:41:09,330 --> 00:41:11,580
a couple of other features such as

838
00:41:11,580 --> 00:41:13,230
what's the device is being used

839
00:41:13,230 --> 00:41:15,900
and what's the deviation of
our amount that takes place

840
00:41:15,900 --> 00:41:17,850
in the transaction and so on.

841
00:41:17,850 --> 00:41:19,380
And with all this information

842
00:41:19,380 --> 00:41:22,020
that is being stored in AgentCore memory

843
00:41:22,020 --> 00:41:24,180
and that is passed down
to your next agent,

844
00:41:24,180 --> 00:41:25,680
which is your context agent.

845
00:41:25,680 --> 00:41:28,770
The context agent picks up
the details of the sender

846
00:41:28,770 --> 00:41:31,380
and the receiver of the 60 day transaction

847
00:41:31,380 --> 00:41:32,580
that it takes place.

848
00:41:32,580 --> 00:41:34,980
So it calculates a lot
of behavioral features

849
00:41:34,980 --> 00:41:38,070
from out of it, like what's
a rolling average and so on.

850
00:41:38,070 --> 00:41:39,900
And now comes one of the most important

851
00:41:39,900 --> 00:41:42,150
and the core agent of the whole workflow,

852
00:41:42,150 --> 00:41:44,010
which is your reasoning agent.

853
00:41:44,010 --> 00:41:46,320
So the reasoning agent comes
with three different things,

854
00:41:46,320 --> 00:41:50,130
which is, it creates a hypothesis
first like to understand

855
00:41:50,130 --> 00:41:52,290
what to really make out
of this transaction.

856
00:41:52,290 --> 00:41:55,080
So the hypothesis that it
really makes out is that

857
00:41:55,080 --> 00:41:57,000
the transaction may be suspicious

858
00:41:57,000 --> 00:42:00,420
but involvement of a PEP
and an excluder provider

859
00:42:00,420 --> 00:42:03,840
and it creates an indicator
how it really marks that

860
00:42:03,840 --> 00:42:06,270
why it makes this transaction
a little bit risky

861
00:42:06,270 --> 00:42:08,010
and it gives a detailed explanation

862
00:42:08,010 --> 00:42:10,740
what really it understands
from the transaction.

863
00:42:10,740 --> 00:42:14,820
And the decision made is
around 0.85 of confidence

864
00:42:14,820 --> 00:42:17,460
and it recommends the steps as well.

865
00:42:17,460 --> 00:42:19,380
And that is passed down
to your action agent,

866
00:42:19,380 --> 00:42:23,790
which recommends that this
needs to be filed SAR report

867
00:42:23,790 --> 00:42:26,460
and you need to freeze this transaction.

868
00:42:26,460 --> 00:42:28,980
And a lot of other actions have
been executed along the same

869
00:42:28,980 --> 00:42:31,170
which is like you have to
freeze the transaction,

870
00:42:31,170 --> 00:42:32,760
notify the operations team

871
00:42:32,760 --> 00:42:35,160
and you have to also store the SAR report.

872
00:42:35,160 --> 00:42:36,810
But depending on your organization,

873
00:42:36,810 --> 00:42:38,940
you can also execute a lot of other tools

874
00:42:38,940 --> 00:42:41,160
and workflows underneath.

875
00:42:41,160 --> 00:42:44,550
And the audit trail is one
of the important trial agent

876
00:42:44,550 --> 00:42:46,530
in the system which
understands and picks up

877
00:42:46,530 --> 00:42:48,570
all the necessary outputs and details

878
00:42:48,570 --> 00:42:50,010
that has been generated by each

879
00:42:50,010 --> 00:42:52,080
and every single agent in the system,

880
00:42:52,080 --> 00:42:55,197
which basically keeps your
audit clean and ready.

881
00:42:55,197 --> 00:42:57,780
And with that being
said, the output is too,

882
00:42:57,780 --> 00:42:59,250
we have to file an SAR.

883
00:42:59,250 --> 00:43:02,070
And this is SAR report,
it has we generated

884
00:43:02,070 --> 00:43:05,310
and the audit trail actually
gives a detail information

885
00:43:05,310 --> 00:43:08,730
about each and every single
agent that is being executed

886
00:43:08,730 --> 00:43:11,100
and what information has collected

887
00:43:11,100 --> 00:43:13,710
and what information
that's produced and so on

888
00:43:13,710 --> 00:43:16,710
so that a human in this particular loop

889
00:43:16,710 --> 00:43:18,030
can identify and figure out

890
00:43:18,030 --> 00:43:20,610
how it's being really
the decision is made.

891
00:43:20,610 --> 00:43:22,710
Now let's try to run the same scenario

892
00:43:22,710 --> 00:43:26,700
using our next use case, which
is a reputation pulse scan.

893
00:43:26,700 --> 00:43:28,980
And you can notice that
we are going to include

894
00:43:28,980 --> 00:43:32,580
a new agent in this workflow,
which is your news agent.

895
00:43:32,580 --> 00:43:35,640
Let's run this orchestration
and see how that works out.

896
00:43:35,640 --> 00:43:38,730
And it goes through each and every agent

897
00:43:38,730 --> 00:43:41,430
and it tries to understand
how the transaction works.

898
00:43:41,430 --> 00:43:44,340
And with that being said, once
the transaction is completed

899
00:43:44,340 --> 00:43:45,930
you get to see the entire results

900
00:43:45,930 --> 00:43:50,820
of how this agent has taken
this particular verdict.

901
00:43:50,820 --> 00:43:52,980
So we already know how
the other agents works.

902
00:43:52,980 --> 00:43:56,580
Let's jump into how this news
agent is really working out

903
00:43:56,580 --> 00:43:59,040
in this new use case.

904
00:43:59,040 --> 00:44:01,470
So, it tries to understand
what is a sender country,

905
00:44:01,470 --> 00:44:03,510
receiver country and so on.

906
00:44:03,510 --> 00:44:06,270
And one of the notes it has
really maintained is that

907
00:44:06,270 --> 00:44:08,730
the receiver is a sanctioned person.

908
00:44:08,730 --> 00:44:11,250
So let's go into audit
to really figure out

909
00:44:11,250 --> 00:44:13,500
how the news agent really came up

910
00:44:13,500 --> 00:44:15,930
with this particular results.

911
00:44:15,930 --> 00:44:18,240
So you can see here that in the news

912
00:44:18,240 --> 00:44:21,630
it has mentioned that the
receiver is sanctioned

913
00:44:21,630 --> 00:44:24,570
but also this news agent
just not stops there.

914
00:44:24,570 --> 00:44:27,720
It tries to understand who's
the receiver, who's the sender

915
00:44:27,720 --> 00:44:30,390
by going and interacting
with the sanctions list

916
00:44:30,390 --> 00:44:31,290
that is available

917
00:44:31,290 --> 00:44:34,920
to mark if the person is
under the sanctions list.

918
00:44:34,920 --> 00:44:37,290
And it also checks the
geopolitical situation

919
00:44:37,290 --> 00:44:38,910
of the transaction to see

920
00:44:38,910 --> 00:44:42,120
if some transaction needs to be restricted

921
00:44:42,120 --> 00:44:45,990
based on the country of
the sender and receiver.

922
00:44:45,990 --> 00:44:48,030
And the third orchestration
workflow is that

923
00:44:48,030 --> 00:44:50,340
you have all the agents in the workflow,

924
00:44:50,340 --> 00:44:54,450
which is your complex and
the full use case that we see

925
00:44:54,450 --> 00:44:58,080
and it involves both risk
and the learning agent.

926
00:44:58,080 --> 00:45:02,760
So let's try to see how this
orchestration goes through

927
00:45:02,760 --> 00:45:07,230
and now our going to be, our
focus is about to learn about

928
00:45:07,230 --> 00:45:09,870
how this risk agent comes
into the whole picture

929
00:45:09,870 --> 00:45:11,970
and how does it really influence

930
00:45:11,970 --> 00:45:13,890
the whole decision making process

931
00:45:13,890 --> 00:45:16,620
and how this learning agent
is going to keep us involved

932
00:45:16,620 --> 00:45:18,240
in this whole process about

933
00:45:18,240 --> 00:45:20,190
to figure out how this
patterns are not being repeated

934
00:45:20,190 --> 00:45:21,023
in the future.

935
00:45:21,870 --> 00:45:23,910
So once this agent has been executed,

936
00:45:23,910 --> 00:45:26,190
let's jump into what we
are really interested about

937
00:45:26,190 --> 00:45:28,050
which is your risk agent.

938
00:45:28,050 --> 00:45:30,500
So we have marked a rule engine system

939
00:45:30,500 --> 00:45:33,360
in this whole workflow and
this rule engine could be

940
00:45:33,360 --> 00:45:35,280
your organization's rule engine

941
00:45:35,280 --> 00:45:38,220
or maybe the compliance's rule
engine that you might have.

942
00:45:38,220 --> 00:45:42,060
Alright, so the rule engine
that we have created is that

943
00:45:42,060 --> 00:45:43,320
the agent has figured out that

944
00:45:43,320 --> 00:45:46,350
there's a high risk of
entity rating for the sender

945
00:45:46,350 --> 00:45:49,260
and there is a sanctioned
status of the receiver.

946
00:45:49,260 --> 00:45:51,270
Let's go into this audit report and see

947
00:45:51,270 --> 00:45:54,540
how this agent really worked out

948
00:45:54,540 --> 00:45:56,850
and what are the information
it was able to figure out

949
00:45:56,850 --> 00:45:58,020
from this whole thing.

950
00:45:58,020 --> 00:46:01,350
So you can see here that
these are the rules that

951
00:46:01,350 --> 00:46:04,170
this particular agent was
able to pick up and execute

952
00:46:04,170 --> 00:46:05,550
based on how it really work.

953
00:46:05,550 --> 00:46:10,170
So this agent is not particularly
an LLM focused agent,

954
00:46:10,170 --> 00:46:11,040
it's a Python agent

955
00:46:11,040 --> 00:46:12,540
but it's driven by your machine learning,

956
00:46:12,540 --> 00:46:14,970
classical machine learning
model or your rule engine.

957
00:46:14,970 --> 00:46:17,700
Based on all these rule
engines which has been created,

958
00:46:17,700 --> 00:46:20,730
these are the contributing
factors, it has figured out that

959
00:46:20,730 --> 00:46:23,730
it might influence the transaction status

960
00:46:23,730 --> 00:46:26,330
and what needs to be done
with the transaction here.

961
00:46:27,270 --> 00:46:28,620
And with that being said,

962
00:46:28,620 --> 00:46:31,680
the learning agent tries to
picks up all these learnings,

963
00:46:31,680 --> 00:46:35,550
put back into the DynamoDB
that we already have so that

964
00:46:35,550 --> 00:46:37,740
when the next such patterns occurs,

965
00:46:37,740 --> 00:46:40,740
your agents are much more
intelligent enough to go ahead

966
00:46:40,740 --> 00:46:43,590
and make more informed
decisions around it.

967
00:46:43,590 --> 00:46:46,440
So now that we have seen a scenario

968
00:46:46,440 --> 00:46:49,140
with almost all the
three different use case,

969
00:46:49,140 --> 00:46:51,930
let's try to mix and
match different scenarios

970
00:46:51,930 --> 00:46:54,120
and see how that really helps out for us.

971
00:46:54,120 --> 00:46:57,630
So we are going to run the
whole, the L3 three use case

972
00:46:57,630 --> 00:47:00,240
with the second scenario which is your,

973
00:47:00,240 --> 00:47:01,860
you're gonna execute a payroll

974
00:47:01,860 --> 00:47:05,400
which is from a Singapore public official.

975
00:47:05,400 --> 00:47:08,100
The verdict is that yeah
you need to file an SAR

976
00:47:08,100 --> 00:47:11,370
but this transaction is okay to be let out

977
00:47:11,370 --> 00:47:13,080
but you need to keep monitoring to see

978
00:47:13,080 --> 00:47:16,140
if something really flags out
in the past, in the future.

979
00:47:16,140 --> 00:47:18,300
So you can see that who's the sender

980
00:47:18,300 --> 00:47:19,770
and the receiver of the agent.

981
00:47:19,770 --> 00:47:21,570
The reasoning agent picks out that

982
00:47:21,570 --> 00:47:24,630
this is a payroll payment and so on

983
00:47:24,630 --> 00:47:27,600
and this is a verdict
that it comes out with.

984
00:47:27,600 --> 00:47:30,120
Now let's even more go with a very simple,

985
00:47:30,120 --> 00:47:32,160
low risk entity scenario

986
00:47:32,160 --> 00:47:34,590
and let's run with one
of the most simplest

987
00:47:34,590 --> 00:47:36,780
agentic workflow that we have here.

988
00:47:36,780 --> 00:47:41,340
With that being said, we
are going to run a scenario

989
00:47:41,340 --> 00:47:43,290
which is a synthetic community payroll.

990
00:47:44,160 --> 00:47:48,180
Though this is a very low
role, sorry low risk entity,

991
00:47:48,180 --> 00:47:51,120
this still flags out that
you need to file an SAR,

992
00:47:51,120 --> 00:47:53,670
which is your suspicious activity report

993
00:47:53,670 --> 00:47:56,790
and you have to monitor
the transaction over here.

994
00:47:56,790 --> 00:47:59,760
And if you go into the
audit report, it figures out

995
00:47:59,760 --> 00:48:01,620
and shows you the whole detail about

996
00:48:01,620 --> 00:48:04,080
what really made this
decision needs to be made.

997
00:48:04,080 --> 00:48:09,080
So with that all being said,
we have seen scenarios where

998
00:48:10,050 --> 00:48:13,110
how a transaction is being taken

999
00:48:13,110 --> 00:48:14,940
and how it's being sent into Kinesis

1000
00:48:14,940 --> 00:48:18,510
and how this whole agentic
workflows has been deployed

1001
00:48:18,510 --> 00:48:21,180
in AgentCore runtime,
which makes it super easy

1002
00:48:21,180 --> 00:48:24,990
and with the help of gateway
to access the more tools

1003
00:48:24,990 --> 00:48:28,920
outside the agent to give the
agents much more accessibility

1004
00:48:28,920 --> 00:48:30,780
and also the memory to keep a context

1005
00:48:30,780 --> 00:48:33,570
of every single transaction
that comes from,

1006
00:48:33,570 --> 00:48:36,750
from the perception to the end
of the agents to figure out

1007
00:48:36,750 --> 00:48:39,210
to make up more informed
decisions around it.

1008
00:48:39,210 --> 00:48:41,610
So we have used couple of strategies

1009
00:48:41,610 --> 00:48:45,300
to keep the memories much more consistent.

1010
00:48:45,300 --> 00:48:47,310
So we have used short-term memory

1011
00:48:47,310 --> 00:48:48,810
but we have manually written down

1012
00:48:48,810 --> 00:48:51,210
each and every output of
the agents which goes there.

1013
00:48:51,210 --> 00:48:54,360
So this is a complete demo that goes into,

1014
00:48:54,360 --> 00:48:56,970
but let's take a bit of time to understand

1015
00:48:56,970 --> 00:48:59,880
how this couple of other
agents has been written

1016
00:48:59,880 --> 00:49:02,430
because not every single
agent that we have seen

1017
00:49:02,430 --> 00:49:04,593
is not a Strands agent in particular.

1018
00:49:06,030 --> 00:49:10,950
So let me go to one of
the agents that we have,

1019
00:49:10,950 --> 00:49:11,840
which is your...

1020
00:49:16,740 --> 00:49:18,600
So let's start with the perception agent,

1021
00:49:18,600 --> 00:49:20,940
which is your most familiar
agent that we have.

1022
00:49:20,940 --> 00:49:24,663
So, here the perception
agent is not really your,

1023
00:49:26,220 --> 00:49:29,520
an LLM powered agent, but it
is a Python powered agent,

1024
00:49:29,520 --> 00:49:31,320
but it still utilizes the tools

1025
00:49:31,320 --> 00:49:33,690
which is being exposed
to this in a way that

1026
00:49:33,690 --> 00:49:35,670
it was able to access the information

1027
00:49:35,670 --> 00:49:38,910
about your KYC details and much more.

1028
00:49:38,910 --> 00:49:41,730
And we have the context agent

1029
00:49:41,730 --> 00:49:43,590
which tries to retrieve the same

1030
00:49:43,590 --> 00:49:45,990
about the 60 days transaction details

1031
00:49:45,990 --> 00:49:48,480
of both the receiver and the sender.

1032
00:49:48,480 --> 00:49:52,380
And even that is exposed
to you from DynamoDB

1033
00:49:52,380 --> 00:49:56,610
through a gateway tools,
through AgentCore gateway tools.

1034
00:49:56,610 --> 00:49:59,490
And we all know the most important agent

1035
00:49:59,490 --> 00:50:02,040
is a reasoning agent,
which we've already seen

1036
00:50:02,040 --> 00:50:03,570
at the start of the demo.

1037
00:50:03,570 --> 00:50:06,240
And this also ensures that

1038
00:50:06,240 --> 00:50:08,160
it drops down the whole information about

1039
00:50:08,160 --> 00:50:10,080
how the decision is being made

1040
00:50:10,080 --> 00:50:11,850
and how it is being made as well.

1041
00:50:11,850 --> 00:50:15,720
And the reasoning agent has
a couple of entities like

1042
00:50:15,720 --> 00:50:19,320
the indicator, what hypothesis it has made

1043
00:50:19,320 --> 00:50:21,210
and what explanation it has given.

1044
00:50:21,210 --> 00:50:24,090
And also the most important
thing is how confident it is

1045
00:50:24,090 --> 00:50:26,010
with the score that has been generated

1046
00:50:26,010 --> 00:50:29,550
so that this transaction
could be flagged or not.

1047
00:50:29,550 --> 00:50:32,210
And next we have is our...

1048
00:50:34,080 --> 00:50:36,240
Before that we also have a news agent.

1049
00:50:36,240 --> 00:50:40,770
So news agent is something
which we have actually taken

1050
00:50:40,770 --> 00:50:42,480
a special interest to create it.

1051
00:50:42,480 --> 00:50:45,570
Usually this news agent
would be a couple of APIs

1052
00:50:45,570 --> 00:50:48,630
which gives you information
about the SDN reports

1053
00:50:48,630 --> 00:50:52,290
or the securities reports or
the sanctions list and so on.

1054
00:50:52,290 --> 00:50:55,560
But for the simplicity
of this particular demo,

1055
00:50:55,560 --> 00:50:59,610
we have stored the entire
sanctions and the securities list

1056
00:50:59,610 --> 00:51:03,120
in a knowledge base and we have
exposed this knowledge base

1057
00:51:03,120 --> 00:51:05,820
to the agent so that it
can access to figure out

1058
00:51:05,820 --> 00:51:09,160
whether this receiver or sender
is part of this particular

1059
00:51:10,320 --> 00:51:11,670
sanctions list and so on.

1060
00:51:11,670 --> 00:51:14,820
And most importantly, not
everything could be just covered

1061
00:51:14,820 --> 00:51:18,810
by saying that, if it just
from this sanctions list,

1062
00:51:18,810 --> 00:51:20,970
it is meant to be a
fraudulent transaction.

1063
00:51:20,970 --> 00:51:22,710
It's not necessarily need to be.

1064
00:51:22,710 --> 00:51:24,990
So, we also actively monitor

1065
00:51:24,990 --> 00:51:27,270
what is a geopolitical
situation that occurs

1066
00:51:27,270 --> 00:51:28,680
around the transaction.

1067
00:51:28,680 --> 00:51:32,130
Like for example, there
is a war-stricken country

1068
00:51:32,130 --> 00:51:36,120
and it's trying to transact
an amount which is absurdly,

1069
00:51:36,120 --> 00:51:37,290
which is very high.

1070
00:51:37,290 --> 00:51:38,880
Of course the human who is in the system

1071
00:51:38,880 --> 00:51:40,680
would be able to easily
understand that hey,

1072
00:51:40,680 --> 00:51:42,570
there is something
wrong which is going on,

1073
00:51:42,570 --> 00:51:45,510
but your agent might really pass it out

1074
00:51:45,510 --> 00:51:47,970
because that's not
really that a flagged out

1075
00:51:47,970 --> 00:51:50,160
as a suspicious transaction.

1076
00:51:50,160 --> 00:51:53,220
But the news agent which
has access to the internet

1077
00:51:53,220 --> 00:51:55,110
through the tool of using the browser,

1078
00:51:55,110 --> 00:51:56,490
it's able to understand that hey,

1079
00:51:56,490 --> 00:51:58,170
there is a war-stricken country

1080
00:51:58,170 --> 00:52:00,300
and this is trying to make a transaction.

1081
00:52:00,300 --> 00:52:02,760
And with all this
information about this news,

1082
00:52:02,760 --> 00:52:06,300
the the KYC details and the
history of the transaction,

1083
00:52:06,300 --> 00:52:09,240
your reasoning agent
now has more information

1084
00:52:09,240 --> 00:52:12,510
and as much efficiency as you as a human

1085
00:52:12,510 --> 00:52:13,830
to make more informed decision

1086
00:52:13,830 --> 00:52:15,990
that this transaction might be flagged

1087
00:52:15,990 --> 00:52:20,160
as a money laundering
transaction with being over here.

1088
00:52:20,160 --> 00:52:24,060
And the rest of the agents keeps
the actions being executed.

1089
00:52:24,060 --> 00:52:26,490
So the action agent figures out

1090
00:52:26,490 --> 00:52:28,800
which sort of risk band
that it falls through.

1091
00:52:28,800 --> 00:52:33,800
And we have your risk agent,
which actually combines

1092
00:52:34,110 --> 00:52:37,320
your existing machine learning models

1093
00:52:37,320 --> 00:52:38,940
or the classical models
that you might build

1094
00:52:38,940 --> 00:52:41,010
for your company or your organization

1095
00:52:41,010 --> 00:52:43,200
so that you don't leave
out the legacy system

1096
00:52:43,200 --> 00:52:45,570
out of the picture, but you also use them

1097
00:52:45,570 --> 00:52:46,980
as one of your helping hands

1098
00:52:46,980 --> 00:52:48,900
to make much more informed decisions.

1099
00:52:48,900 --> 00:52:51,330
This also helps you to
keep the compliancies

1100
00:52:51,330 --> 00:52:54,030
much more intact with the new solutions

1101
00:52:54,030 --> 00:52:56,880
and keeping the whole legacy
solution into the system.

1102
00:52:56,880 --> 00:52:59,670
And all that being said,
the audit helps you

1103
00:52:59,670 --> 00:53:02,100
to keep the entire trial
of the transactions

1104
00:53:02,100 --> 00:53:03,540
and that helps you to

1105
00:53:03,540 --> 00:53:05,940
keep your compliance team much more happy

1106
00:53:05,940 --> 00:53:07,740
to understand how this agent is making

1107
00:53:07,740 --> 00:53:09,390
much more informed decisions.

1108
00:53:09,390 --> 00:53:12,810
And we have finally the learning agent

1109
00:53:12,810 --> 00:53:15,540
where it gives you the feedback loop of

1110
00:53:15,540 --> 00:53:18,570
how this transaction has been evaluated,

1111
00:53:18,570 --> 00:53:21,810
and what was the risk which was associated

1112
00:53:21,810 --> 00:53:23,880
and what was the reasons it has been made

1113
00:53:23,880 --> 00:53:27,510
and how this entity's
risk band has been updated

1114
00:53:27,510 --> 00:53:29,010
post this evaluation.

1115
00:53:29,010 --> 00:53:32,580
And this learning agent
keeps updating the databases,

1116
00:53:32,580 --> 00:53:34,620
which helps you to make
much more informed decisions

1117
00:53:34,620 --> 00:53:37,893
of such existing patterns
occurring in the future as well.

1118
00:53:38,880 --> 00:53:40,200
So with that being said,

1119
00:53:40,200 --> 00:53:42,660
this completely helps you to understand

1120
00:53:42,660 --> 00:53:45,120
how we have built an entire workflow

1121
00:53:45,120 --> 00:53:47,820
to understand how to flag out transaction,

1122
00:53:47,820 --> 00:53:49,440
which might be a money-laundering

1123
00:53:49,440 --> 00:53:51,120
fraudulent transactions here

1124
00:53:51,120 --> 00:53:53,970
and the multi-agent orchestration systems

1125
00:53:53,970 --> 00:53:57,300
have been really helpful
to increase the accuracy

1126
00:53:57,300 --> 00:54:00,150
and decrease the time in
flagging of the system

1127
00:54:00,150 --> 00:54:01,350
and improving the efficiency

1128
00:54:01,350 --> 00:54:03,450
of the whole organization as well.

1129
00:54:03,450 --> 00:54:08,130
So this is Vivek Raja, I'm
AWS machine learning, sorry,

1130
00:54:08,130 --> 00:54:10,170
I'm AWS Machine Learning Hero

1131
00:54:10,170 --> 00:54:13,413
and along with me is
Bhuvaneswari Subramani,

1132
00:54:14,760 --> 00:54:16,530
who is a AWS Hero.

1133
00:54:16,530 --> 00:54:18,420
And we have Ayyanar Jeyakrishnan,

1134
00:54:18,420 --> 00:54:20,460
who is representing AWS community

1135
00:54:20,460 --> 00:54:22,020
and he's also a Machine Learning Hero.

1136
00:54:22,020 --> 00:54:26,310
We'll be around in this
hallway if you have doubts

1137
00:54:26,310 --> 00:54:27,660
or you wanted to interact more about

1138
00:54:27,660 --> 00:54:29,583
how this solution works.

1139
00:54:31,380 --> 00:54:32,213
Sorry?

1140
00:54:33,705 --> 00:54:34,538
Okay.

1141
00:54:37,650 --> 00:54:40,020
So this is us and we'll be
available in the hallway

1142
00:54:40,020 --> 00:54:42,990
if you wanted to catch up with
us to understand more about

1143
00:54:42,990 --> 00:54:45,570
how the solution works or how
you wanted to integrate these

1144
00:54:45,570 --> 00:54:49,080
with your existing solutions
that you have in your company

1145
00:54:49,080 --> 00:54:50,700
or you wanted to explore the same.

1146
00:54:50,700 --> 00:54:52,983
So thank you everyone for this.

