1
00:00:01,230 --> 00:00:04,350
- Welcome to the last talk of the day,

2
00:00:04,350 --> 00:00:06,750
5:30 on a Tuesday, why not?

3
00:00:06,750 --> 00:00:08,790
Although it's Vegas so you
guys probably have like

4
00:00:08,790 --> 00:00:10,800
two dinners and like six happy hours

5
00:00:10,800 --> 00:00:13,200
between now and whenever you go home.

6
00:00:13,200 --> 00:00:15,349
Anyway, my name is Sean Falconer.

7
00:00:15,349 --> 00:00:16,920
- And my name is Cal Rueb.

8
00:00:16,920 --> 00:00:19,290
- And welcome, this is, well,

9
00:00:19,290 --> 00:00:21,600
essentially we're gonna be talking about

10
00:00:21,600 --> 00:00:26,600
how to go from AI Agent Demos
to essentially production.

11
00:00:26,640 --> 00:00:30,660
I think a challenge that many,
many businesses face today.

12
00:00:30,660 --> 00:00:33,840
So first off, how many people here,

13
00:00:33,840 --> 00:00:36,630
just put your hands up, have
built some sort of AI demo?

14
00:00:36,630 --> 00:00:40,680
You know, maybe it's a single
shot prompt, RAG, Agent.

15
00:00:40,680 --> 00:00:42,180
All right, keep your hands up.

16
00:00:43,530 --> 00:00:47,040
And then how many of you
have made those demos

17
00:00:47,040 --> 00:00:48,903
turn into production use cases?

18
00:00:49,770 --> 00:00:50,603
Anybody?

19
00:00:50,603 --> 00:00:52,290
Yep, a few. Great.

20
00:00:52,290 --> 00:00:54,417
So this is one of the challenges

21
00:00:54,417 --> 00:00:57,030
and of course there could
be many, many reasons why

22
00:00:57,030 --> 00:00:58,980
you haven't been able to move
those demos into production.

23
00:00:58,980 --> 00:01:00,180
Maybe the demo is never designed

24
00:01:00,180 --> 00:01:02,580
to be a production use
case to start off with.

25
00:01:02,580 --> 00:01:05,730
But what we're gonna talk a
little bit about today is,

26
00:01:05,730 --> 00:01:08,910
our experience working
with a number of customers

27
00:01:08,910 --> 00:01:11,370
across Confluent as well
as Anthropic and some of

28
00:01:11,370 --> 00:01:13,710
our experience where we
see customers getting stuck

29
00:01:13,710 --> 00:01:15,240
with moving essentially those types of

30
00:01:15,240 --> 00:01:18,360
demos and POCs into production.

31
00:01:18,360 --> 00:01:21,750
And you know, clearly, AI is powering

32
00:01:21,750 --> 00:01:22,740
a lot of new experiences.

33
00:01:22,740 --> 00:01:24,900
We just crossed through the third year

34
00:01:24,900 --> 00:01:27,090
anniversary of Check EPT.

35
00:01:27,090 --> 00:01:29,100
There's been such an
explosion of technology.

36
00:01:29,100 --> 00:01:31,200
Last time I was at
re:Invent was two years ago.

37
00:01:31,200 --> 00:01:33,270
I walk around the expo floor today

38
00:01:33,270 --> 00:01:36,090
and it's unrecognizable to
where it was two years ago

39
00:01:36,090 --> 00:01:38,310
because a lot of those
companies either didn't exist

40
00:01:38,310 --> 00:01:40,650
or they're very much in their
infancy a couple years ago.

41
00:01:40,650 --> 00:01:43,290
Everything's about AI right
now, and it has transformed,

42
00:01:43,290 --> 00:01:47,130
I think, a lot of how we
think about doing our jobs.

43
00:01:47,130 --> 00:01:50,160
If we're engineers, we're
probably using some sort of AI

44
00:01:50,160 --> 00:01:53,550
assistive coding tool,
Claude Code for example.

45
00:01:53,550 --> 00:01:55,500
Or you know, if we're generating content,

46
00:01:55,500 --> 00:01:57,480
we're probably using some sort of AI-based

47
00:01:57,480 --> 00:01:58,860
tool to help us do that.

48
00:01:58,860 --> 00:02:01,170
We're relying more and
more on these systems.

49
00:02:01,170 --> 00:02:02,040
Yet at the same time,

50
00:02:02,040 --> 00:02:04,117
a lot of companies are
still struggling for

51
00:02:04,117 --> 00:02:07,020
"Where is the ROI for
my particular use case?"

52
00:02:07,020 --> 00:02:08,670
or "I wanna solve this problem,

53
00:02:08,670 --> 00:02:09,900
how do I solve this problem?"

54
00:02:09,900 --> 00:02:11,067
And, "I can't get there.

55
00:02:11,067 --> 00:02:12,390
I'm still struggling to essentially

56
00:02:12,390 --> 00:02:14,640
bring that stuff into production."

57
00:02:14,640 --> 00:02:16,080
And while all this is going on,

58
00:02:16,080 --> 00:02:17,250
a lot of people believe also

59
00:02:17,250 --> 00:02:20,192
that like Agents are
the future of software.

60
00:02:20,192 --> 00:02:21,847
You know, you hear of lots
of proclamations like,

61
00:02:21,847 --> 00:02:24,240
"SaaS is dead, it's all about Agents."

62
00:02:24,240 --> 00:02:26,610
And regardless of the
metrics that you look at,

63
00:02:26,610 --> 00:02:27,690
whether it's, you know, this chart

64
00:02:27,690 --> 00:02:29,580
that's predicting the Agent market being

65
00:02:29,580 --> 00:02:31,650
50 billion by the year 2030,

66
00:02:31,650 --> 00:02:35,090
or Gartner reporting that
they think that by 2028,

67
00:02:35,090 --> 00:02:37,320
33% of all software will have

68
00:02:37,320 --> 00:02:39,300
some sort of Agent baked into it.

69
00:02:39,300 --> 00:02:40,980
You know, it's always hard

70
00:02:40,980 --> 00:02:42,480
to make predictions in technology.

71
00:02:42,480 --> 00:02:45,000
We tend to overestimate in the short term

72
00:02:45,000 --> 00:02:47,970
and underestimate in the long term,

73
00:02:47,970 --> 00:02:50,010
but, even if you only
believe some of this stuff,

74
00:02:50,010 --> 00:02:50,843
it's directionally correct,

75
00:02:50,843 --> 00:02:52,110
it's of course something that we all need

76
00:02:52,110 --> 00:02:54,720
to be paying attention to
when we work in technology

77
00:02:54,720 --> 00:02:57,270
and we're trying to all
figure this out right now.

78
00:02:57,270 --> 00:03:02,160
And I think the dream or the
promise of Agents is amazing.

79
00:03:02,160 --> 00:03:04,290
Like the fact that we
could have some sort of

80
00:03:04,290 --> 00:03:07,470
dynamic autonomous system
that's doing work on our behalf.

81
00:03:07,470 --> 00:03:10,530
Everybody gets like, you know,
an intern in their pocket,

82
00:03:10,530 --> 00:03:13,200
really like the smartest
intern that's possible

83
00:03:13,200 --> 00:03:14,280
with almost perfect recall.

84
00:03:14,280 --> 00:03:15,240
That's amazing.

85
00:03:15,240 --> 00:03:18,240
So if we can turn that
dream on for our businesses

86
00:03:18,240 --> 00:03:19,620
to solve all kinds of different use cases,

87
00:03:19,620 --> 00:03:22,530
of course we wanna be able to do that.

88
00:03:22,530 --> 00:03:25,350
Now, fundamentally what is
different about, you know,

89
00:03:25,350 --> 00:03:28,290
these types of models,
and broadly speaking,

90
00:03:28,290 --> 00:03:29,910
when we look at AI,

91
00:03:29,910 --> 00:03:32,100
there's been sort of two
different eras or waves.

92
00:03:32,100 --> 00:03:34,110
We've had purpose-built models,

93
00:03:34,110 --> 00:03:36,450
and then now we have foundation models

94
00:03:36,450 --> 00:03:39,060
or Generative AI, Large Language Models,

95
00:03:39,060 --> 00:03:40,470
however you wanna kinda term it.

96
00:03:40,470 --> 00:03:43,500
And one isn't necessarily a
replacement for the other,

97
00:03:43,500 --> 00:03:45,630
but there are key
characteristic differences

98
00:03:45,630 --> 00:03:47,250
between these kind of two different eras

99
00:03:47,250 --> 00:03:48,660
that's important to understand.

100
00:03:48,660 --> 00:03:51,240
So with purpose-built
models, or predictive AI,

101
00:03:51,240 --> 00:03:52,170
some people might call this,

102
00:03:52,170 --> 00:03:54,570
this is kind of like
the AI that I grew up on

103
00:03:54,570 --> 00:03:57,120
and was trained in and was a researcher in

104
00:03:57,120 --> 00:03:58,500
for a number of years.

105
00:03:58,500 --> 00:04:02,070
The way that you build
these models typically

106
00:04:02,070 --> 00:04:03,720
is you start with your data.

107
00:04:03,720 --> 00:04:05,610
So you start with your business data

108
00:04:05,610 --> 00:04:08,280
and you go through this
batch offline process

109
00:04:08,280 --> 00:04:11,010
of feature extraction,
feature engineering,

110
00:04:11,010 --> 00:04:13,080
you train your model, you test that model.

111
00:04:13,080 --> 00:04:14,427
Once you're happy with
it, you can deploy it

112
00:04:14,427 --> 00:04:17,430
and you start using it
within your application.

113
00:04:17,430 --> 00:04:19,800
And these have served us well for decades

114
00:04:19,800 --> 00:04:22,470
and will continue to serve us
well for decades from here.

115
00:04:22,470 --> 00:04:25,800
But the sort of limitation of these models

116
00:04:25,800 --> 00:04:27,510
is that they're purpose built.

117
00:04:27,510 --> 00:04:28,710
So they're kind of singular purpose.

118
00:04:28,710 --> 00:04:29,820
Like once I've gone ahead

119
00:04:29,820 --> 00:04:31,800
and I've trained my fraud detection model,

120
00:04:31,800 --> 00:04:33,990
I can't just start doing
image classification with it.

121
00:04:33,990 --> 00:04:35,880
I need to go through essentially

122
00:04:35,880 --> 00:04:37,050
a different training process,

123
00:04:37,050 --> 00:04:38,400
maybe even use a different type of model,

124
00:04:38,400 --> 00:04:39,480
probably different features

125
00:04:39,480 --> 00:04:42,330
to go and train that image
classification model.

126
00:04:42,330 --> 00:04:44,610
So they're limited in
terms of their reusability,

127
00:04:44,610 --> 00:04:48,180
but the advantage of the models
is they know a lot about you

128
00:04:48,180 --> 00:04:49,500
because they were trained on your data,

129
00:04:49,500 --> 00:04:52,470
and they were trained to
solve a specific task.

130
00:04:52,470 --> 00:04:55,920
So they have a representation
of essentially your business

131
00:04:55,920 --> 00:04:58,260
baked into the weights of that model.

132
00:04:58,260 --> 00:05:00,240
And foundation models
can have an opposite set

133
00:05:00,240 --> 00:05:03,120
of characteristics where
they are these massive models

134
00:05:03,120 --> 00:05:05,550
that are trained essentially on, you know,

135
00:05:05,550 --> 00:05:06,810
everything publicly available

136
00:05:06,810 --> 00:05:08,460
and only a handful of
companies in the world

137
00:05:08,460 --> 00:05:09,990
have the resources and knowledge

138
00:05:09,990 --> 00:05:11,760
how to actually construct these models.

139
00:05:11,760 --> 00:05:13,740
And they packaged them up in a nice API

140
00:05:13,740 --> 00:05:15,960
that anybody who knows how to call an API

141
00:05:15,960 --> 00:05:18,090
can essentially leverage the model.

142
00:05:18,090 --> 00:05:19,440
They don't need to know anything about

143
00:05:19,440 --> 00:05:20,970
sort of how the model was constructed

144
00:05:20,970 --> 00:05:23,280
or the guts of the model to use it.

145
00:05:23,280 --> 00:05:25,620
And this has democratized access to AI

146
00:05:25,620 --> 00:05:28,830
and I think led in many ways
this explosion of interest

147
00:05:28,830 --> 00:05:33,349
and people building software
that leverages AI today.

148
00:05:33,349 --> 00:05:34,560
And the other amazing thing is

149
00:05:34,560 --> 00:05:36,450
that they can be used for
infinitely many things.

150
00:05:36,450 --> 00:05:39,360
I can use the same model for
many, many different use cases.

151
00:05:39,360 --> 00:05:41,400
But the limitation of the models is that

152
00:05:41,400 --> 00:05:43,890
as smart as they are
about public information,

153
00:05:43,890 --> 00:05:45,300
and general information,

154
00:05:45,300 --> 00:05:46,890
they're kind of dumb when it comes

155
00:05:46,890 --> 00:05:48,180
to essentially your business information

156
00:05:48,180 --> 00:05:49,770
'cause they lack that context.

157
00:05:49,770 --> 00:05:52,620
They weren't actually
trained on your customer data

158
00:05:52,620 --> 00:05:54,990
or on the data within your business.

159
00:05:54,990 --> 00:05:57,030
So you have to give them that information.

160
00:05:57,030 --> 00:05:57,863
So how do you do that?

161
00:05:57,863 --> 00:06:00,360
Well typically that
happens during this process

162
00:06:00,360 --> 00:06:01,260
of prompt time assembly.

163
00:06:01,260 --> 00:06:04,170
So, when I'm about to
call the API to the model,

164
00:06:04,170 --> 00:06:07,530
I need to go and gather essentially
whatever additional data

165
00:06:07,530 --> 00:06:10,200
that I need to sort of
to give to the model

166
00:06:10,200 --> 00:06:11,760
so that it understands what the task is

167
00:06:11,760 --> 00:06:14,100
and they can accomplish this goal.

168
00:06:14,100 --> 00:06:15,900
And in an enterprise scenario,

169
00:06:15,900 --> 00:06:18,180
this is kind of easier
said than done because

170
00:06:18,180 --> 00:06:20,040
enterprises have data all over the place.

171
00:06:20,040 --> 00:06:22,080
You might have thousands
of different databases.

172
00:06:22,080 --> 00:06:23,820
You have SaaS locations,

173
00:06:23,820 --> 00:06:26,190
SaaS applications where
your data might be located,

174
00:06:26,190 --> 00:06:28,380
you have APIs, all these things.

175
00:06:28,380 --> 00:06:32,670
And this has been these data
silos and data fragmentation,

176
00:06:32,670 --> 00:06:35,460
and just understanding where your data is,

177
00:06:35,460 --> 00:06:37,947
has been a problem in
businesses for decades now.

178
00:06:37,947 --> 00:06:40,890
And AI is really just the
next sort of forcing function

179
00:06:40,890 --> 00:06:42,750
for people to think about deeply

180
00:06:42,750 --> 00:06:45,300
what their AI or their data strategy is,

181
00:06:45,300 --> 00:06:46,290
'cause fundamentally it's hard to have

182
00:06:46,290 --> 00:06:48,300
an AI strategy without a data strategy.

183
00:06:48,300 --> 00:06:49,133
'Cause if your data's a mess, you know,

184
00:06:49,133 --> 00:06:50,640
slapping a model on top of it

185
00:06:50,640 --> 00:06:52,440
doesn't really solve that mess.

186
00:06:52,440 --> 00:06:54,147
So how do you essentially do that?

187
00:06:54,147 --> 00:06:55,680
And a lot of this essentially

188
00:06:55,680 --> 00:06:58,710
is grounded in this concept
of context engineering.

189
00:06:58,710 --> 00:07:01,440
I'm gonna hand this off to
Cal to talk a little bit about

190
00:07:01,440 --> 00:07:04,500
how we've evolved essentially
beyond the prompt.

191
00:07:04,500 --> 00:07:05,650
- All right, thank you.

192
00:07:07,320 --> 00:07:09,870
So I joined Anthropic about two years ago

193
00:07:09,870 --> 00:07:12,960
to help start a team
that we call Applied AI

194
00:07:12,960 --> 00:07:15,510
and it's Applied AI's mission and goal

195
00:07:15,510 --> 00:07:17,820
to help our customers build great products

196
00:07:17,820 --> 00:07:19,710
and features on top of Claude.

197
00:07:19,710 --> 00:07:21,750
So when I first showed up at Anthropic,

198
00:07:21,750 --> 00:07:24,960
I was meeting with companies
from AI native startups

199
00:07:24,960 --> 00:07:27,930
to large banks, meeting
with their products teams,

200
00:07:27,930 --> 00:07:28,860
their engineering teams,

201
00:07:28,860 --> 00:07:30,090
figuring out what they're trying to build

202
00:07:30,090 --> 00:07:31,380
and seeing if we can do it with Claude,

203
00:07:31,380 --> 00:07:33,630
if Claude can solve their problems.

204
00:07:33,630 --> 00:07:35,970
On top of that, everyone
on the Applied AI team

205
00:07:35,970 --> 00:07:39,540
to make sure we're not just
people that talk to customers

206
00:07:39,540 --> 00:07:41,640
but don't actually do the work,

207
00:07:41,640 --> 00:07:42,780
everyone on the Applied AI team

208
00:07:42,780 --> 00:07:45,480
also contributes to Anthropics products.

209
00:07:45,480 --> 00:07:48,060
And so when Claude Code
was still an internal tool,

210
00:07:48,060 --> 00:07:50,160
I discovered it and really
fell in love with it

211
00:07:50,160 --> 00:07:52,560
and got to know Kat
and Boris and the team,

212
00:07:52,560 --> 00:07:55,650
and kind of joined that team
as like a second job almost.

213
00:07:55,650 --> 00:07:59,100
And so, most of the
system prompt, the tools,

214
00:07:59,100 --> 00:08:02,310
all the kind of AI engineering
that powers Claude Code

215
00:08:02,310 --> 00:08:04,860
I wrote or worked on in some way.

216
00:08:04,860 --> 00:08:07,680
And so between those things
I've had a very nice,

217
00:08:07,680 --> 00:08:10,560
I've had kind of the privilege
to have a front row seat

218
00:08:10,560 --> 00:08:14,670
into how we build on top of these models

219
00:08:14,670 --> 00:08:17,883
and get things into production,
and how this has evolved.

220
00:08:18,810 --> 00:08:21,720
So when I joined Anthropic
in January of 2024,

221
00:08:21,720 --> 00:08:24,450
we had a model called Claude 2.1.

222
00:08:24,450 --> 00:08:27,170
Has anyone here ever use Claude 2.1?

223
00:08:29,100 --> 00:08:32,220
Okay, no one. That doesn't
surprise me too much.

224
00:08:32,220 --> 00:08:35,730
Claude 2.1 was not the
best model in the world.

225
00:08:35,730 --> 00:08:36,900
There were some cool things about it.

226
00:08:36,900 --> 00:08:39,450
It was on AWS Bedrock,
something that our customers

227
00:08:39,450 --> 00:08:42,000
still really appreciate
about Claude today,

228
00:08:42,000 --> 00:08:43,530
and additionally it had a very large

229
00:08:43,530 --> 00:08:45,960
context window of 200,000 tokens,

230
00:08:45,960 --> 00:08:48,570
which many of the other
players in the space

231
00:08:48,570 --> 00:08:52,170
kind of topped out at
about 32,000 or 64,000.

232
00:08:52,170 --> 00:08:55,440
So we had a few customers
but things weren't crazy.

233
00:08:55,440 --> 00:08:57,570
Then we released Opus 3.

234
00:08:57,570 --> 00:08:59,043
Has anyone here used Opus 3?

235
00:09:00,990 --> 00:09:03,060
Maybe? One, all right.

236
00:09:03,060 --> 00:09:05,700
Opus 3 when we released
it was by many measures

237
00:09:05,700 --> 00:09:08,790
the best model in the world
and it really put us on the map

238
00:09:08,790 --> 00:09:12,660
and kind of set us off on
this awesome trajectory.

239
00:09:12,660 --> 00:09:14,400
One thing we believe at Anthropic

240
00:09:14,400 --> 00:09:17,940
is we believe we are on this path to build

241
00:09:17,940 --> 00:09:18,975
better and better models

242
00:09:18,975 --> 00:09:21,960
and we think this is
gonna happen very rapidly.

243
00:09:21,960 --> 00:09:25,650
And we also believe that
this rapid improvement in AI

244
00:09:25,650 --> 00:09:27,840
will have transformational effects

245
00:09:27,840 --> 00:09:30,330
on society and the world and how we work.

246
00:09:30,330 --> 00:09:32,700
And we do a lot of work to study this

247
00:09:32,700 --> 00:09:34,533
and research it and get ahead of it.

248
00:09:35,850 --> 00:09:38,700
But more practically, as the
models have gotten better,

249
00:09:38,700 --> 00:09:40,530
and as continue to get better,

250
00:09:40,530 --> 00:09:44,250
the way we build on top of
these models has evolved.

251
00:09:44,250 --> 00:09:47,520
So when I joined Anthropic and
I was meeting with customers

252
00:09:47,520 --> 00:09:50,880
in the Claude 2.1 days
and the Claude 3 days,

253
00:09:50,880 --> 00:09:52,590
most of the things people were building,

254
00:09:52,590 --> 00:09:54,210
not super ambitious,

255
00:09:54,210 --> 00:09:56,790
were what we might call
kind of single turn prompts.

256
00:09:56,790 --> 00:09:59,280
Things like, "Hey I need to classify

257
00:09:59,280 --> 00:10:01,560
a whole bunch of product reviews,"

258
00:10:01,560 --> 00:10:04,740
or "I need to write a
first draft of an email."

259
00:10:04,740 --> 00:10:08,820
Or, we did a lot of this, "Here's
three help center articles

260
00:10:08,820 --> 00:10:12,780
and a customer question,
can you draft a response?"

261
00:10:12,780 --> 00:10:15,273
A lot of like Q&A chatbot sort of stuff.

262
00:10:16,590 --> 00:10:17,940
The models started to get a little better

263
00:10:17,940 --> 00:10:19,890
and people started to get more ambitious

264
00:10:19,890 --> 00:10:23,250
about what can we build
on top of these LMs,

265
00:10:23,250 --> 00:10:27,120
and we transitioned into
what we call Workflows.

266
00:10:27,120 --> 00:10:28,770
So one thing you could think about doing

267
00:10:28,770 --> 00:10:31,440
is you have your single prompts
and a bunch of instructions.

268
00:10:31,440 --> 00:10:34,110
You could just say,
"Okay, I'll just put more

269
00:10:34,110 --> 00:10:35,700
in my single prompt and have it do more

270
00:10:35,700 --> 00:10:37,590
interesting complex things."

271
00:10:37,590 --> 00:10:39,990
Well in practice that
doesn't work very well.

272
00:10:39,990 --> 00:10:42,390
The model can, you know,
maybe only reliably follow

273
00:10:42,390 --> 00:10:44,340
so many instructions at once.

274
00:10:44,340 --> 00:10:47,580
And so how do we build something
that's more interesting

275
00:10:47,580 --> 00:10:49,980
and rich that we can't get
done in a single prompt?

276
00:10:49,980 --> 00:10:53,310
Well we try to decompose
this task and split it up

277
00:10:53,310 --> 00:10:55,020
and chain multiple prompts together

278
00:10:55,020 --> 00:10:57,690
and maybe mix in some deterministic logic

279
00:10:57,690 --> 00:11:00,030
to get something more interesting and rich

280
00:11:00,030 --> 00:11:03,420
than we could have in our kind
of single turn architecture.

281
00:11:03,420 --> 00:11:08,160
And so if you have used
AI features and products,

282
00:11:08,160 --> 00:11:12,120
even today, if you were
to peer under the hood,

283
00:11:12,120 --> 00:11:15,330
probably a lot of that stuff
is powered by Workflows.

284
00:11:15,330 --> 00:11:19,110
Now Workflows in practice
have two problems.

285
00:11:19,110 --> 00:11:22,200
One of them is that Workflows
are really only as good

286
00:11:22,200 --> 00:11:24,060
as kind of all the edge cases

287
00:11:24,060 --> 00:11:25,920
that you've kind of planned for, right?

288
00:11:25,920 --> 00:11:30,210
Like we have kind of this
predetermined set of things

289
00:11:30,210 --> 00:11:32,100
that this Workflow can do,

290
00:11:32,100 --> 00:11:35,640
and that doesn't work very
well for open-ended tasks.

291
00:11:35,640 --> 00:11:37,650
So if you're trying to build an AI system

292
00:11:37,650 --> 00:11:40,830
that can just do day-to-day
software engineering for you,

293
00:11:40,830 --> 00:11:43,140
very hard to build that in a Workflow.

294
00:11:43,140 --> 00:11:45,510
I've met with customers and seen customers

295
00:11:45,510 --> 00:11:48,540
that have Workflows that are
made up of 50 different prompts

296
00:11:48,540 --> 00:11:50,790
and it can be very challenging
to kind of manage this

297
00:11:50,790 --> 00:11:53,130
and keep this under control.

298
00:11:53,130 --> 00:11:56,100
The other thing that is tricky
about building as a Workflow

299
00:11:56,100 --> 00:11:58,020
is that if something goes wrong

300
00:11:58,020 --> 00:12:00,540
in the middle of this Workflow,
you're on LLM call two,

301
00:12:00,540 --> 00:12:02,700
and something, I don't
know, unexpected happens,

302
00:12:02,700 --> 00:12:05,970
the LM makes a mistake
or something like that,

303
00:12:05,970 --> 00:12:08,700
it is very hard to build
any sort of error correction

304
00:12:08,700 --> 00:12:11,100
or the Workflow notices
something went wrong

305
00:12:11,100 --> 00:12:12,650
and can't kind of self correct.

306
00:12:13,710 --> 00:12:17,040
And so, starting late last
year, and certainly this year,

307
00:12:17,040 --> 00:12:19,710
we have moved into, for many problems,

308
00:12:19,710 --> 00:12:22,410
building on top of a
different architecture.

309
00:12:22,410 --> 00:12:26,130
At Anthropic, this is what we call Agents.

310
00:12:26,130 --> 00:12:29,310
And with an Agents, in many
ways it is much more simple,

311
00:12:29,310 --> 00:12:31,307
but we take our LLM, we give
it a set of instructions,

312
00:12:31,307 --> 00:12:33,630
and we give it a set of tools

313
00:12:33,630 --> 00:12:36,030
and some sort of open-ended task

314
00:12:36,030 --> 00:12:39,060
and we basically say to
the LM, "Work on this task,

315
00:12:39,060 --> 00:12:41,130
call these tools as much as you want.

316
00:12:41,130 --> 00:12:42,900
Let me know when you're done."

317
00:12:42,900 --> 00:12:45,197
And this helps with our open-ended problem

318
00:12:45,197 --> 00:12:48,420
'cause we don't have to
code for everything ourself.

319
00:12:48,420 --> 00:12:51,450
We let the Agent kind of figure
the problem out on its own,

320
00:12:51,450 --> 00:12:54,240
we trust it to do it,
we're giving it agency.

321
00:12:54,240 --> 00:12:57,600
And on top of that, if things
go wrong, I don't know,

322
00:12:57,600 --> 00:13:00,120
the model calls a tool and
it gets back a response

323
00:13:00,120 --> 00:13:02,670
that it didn't expect or
it gets back an error,

324
00:13:02,670 --> 00:13:05,130
the model can see that and react to it

325
00:13:05,130 --> 00:13:07,827
and adjust its course and try again.

326
00:13:07,827 --> 00:13:10,810
And so it gives you a lot
more of this reliability

327
00:13:12,600 --> 00:13:15,870
and you can build more
rich, robust kind of

328
00:13:15,870 --> 00:13:18,813
products and applications
on top of this architecture.

329
00:13:21,180 --> 00:13:24,870
And so at Anthropic we see
both of these kind of setups

330
00:13:24,870 --> 00:13:27,390
in production today, they're
good at different times.

331
00:13:27,390 --> 00:13:31,740
We have Workflows when we have
more narrow, very repeatable,

332
00:13:31,740 --> 00:13:35,910
maybe we wanna mix in a little
deterministic logic tasks,

333
00:13:35,910 --> 00:13:38,160
and then we use our
Agents when we're building

334
00:13:38,160 --> 00:13:43,160
more kind of open-ended,
broad, sort of, I dunno,

335
00:13:43,200 --> 00:13:44,880
working on those sort of problems

336
00:13:44,880 --> 00:13:48,090
and maybe we have a set of
tools and things can go wrong,

337
00:13:48,090 --> 00:13:51,543
and we're trusting the model
to deal with more ambiguity.

338
00:13:55,620 --> 00:13:56,940
- Great, thank you.

339
00:13:56,940 --> 00:14:00,390
So as we've evolved from
sort of this, you know,

340
00:14:00,390 --> 00:14:05,280
single call shot prompting
into Agents and Workflows,

341
00:14:05,280 --> 00:14:07,980
this has also I think,
represented an important shift

342
00:14:07,980 --> 00:14:10,287
in how we think about engineering,

343
00:14:10,287 --> 00:14:13,710
and a shift in sort of
architecting software.

344
00:14:13,710 --> 00:14:15,430
So with traditional software

345
00:14:16,320 --> 00:14:19,230
we essentially code the
business logic of the software

346
00:14:19,230 --> 00:14:21,540
using precise logic and rules.

347
00:14:21,540 --> 00:14:23,790
You know, we're writing
essentially that code.

348
00:14:23,790 --> 00:14:26,400
I click on a button, something
happens that has been

349
00:14:26,400 --> 00:14:29,370
predetermined and essentially
baked into the software.

350
00:14:29,370 --> 00:14:31,410
But with AI systems, what we're doing is,

351
00:14:31,410 --> 00:14:34,110
since we're relying on
these probabilistic models

352
00:14:34,110 --> 00:14:36,810
to make certain dynamic decisions,

353
00:14:36,810 --> 00:14:39,207
we're essentially steering
the model with the data

354
00:14:39,207 --> 00:14:41,610
and the context that
we feed into the model.

355
00:14:41,610 --> 00:14:42,540
So in a lot of ways,

356
00:14:42,540 --> 00:14:47,540
the business logic essentially
becomes a output of the data

357
00:14:47,547 --> 00:14:50,110
and the context that we're
feeding into the model.

358
00:14:50,110 --> 00:14:52,650
And it's a shift, represents a shift,

359
00:14:52,650 --> 00:14:55,290
where instead of software
necessarily being

360
00:14:55,290 --> 00:14:56,640
precise logic and rules,

361
00:14:56,640 --> 00:14:58,290
your data pipeline in a lot of ways,

362
00:14:58,290 --> 00:15:00,750
becomes kind of your software application.

363
00:15:00,750 --> 00:15:03,600
And the same change is kind of happening

364
00:15:03,600 --> 00:15:06,930
in the world of testing where,
with traditional software,

365
00:15:06,930 --> 00:15:08,880
we use unit tests, we use system tests,

366
00:15:08,880 --> 00:15:10,980
where we can deterministically
test the software,

367
00:15:10,980 --> 00:15:12,990
but now we're moving
in this world of evals

368
00:15:12,990 --> 00:15:14,880
where we're using probabilistic tests

369
00:15:14,880 --> 00:15:16,410
against the AI systems.

370
00:15:16,410 --> 00:15:19,380
And with unit tests we
don't necessarily need

371
00:15:19,380 --> 00:15:24,380
to test our software using a
real data because essentially

372
00:15:24,540 --> 00:15:26,370
the same input's gonna
generate same output,

373
00:15:26,370 --> 00:15:27,810
it can be deterministically run.

374
00:15:27,810 --> 00:15:30,060
If the unit has passed, we
have some level of confidence

375
00:15:30,060 --> 00:15:33,600
that the software is
going to run as expected

376
00:15:33,600 --> 00:15:35,220
once we put it into production.

377
00:15:35,220 --> 00:15:37,440
With AI systems, it's
hard to do that without

378
00:15:37,440 --> 00:15:39,150
some representation of the real data

379
00:15:39,150 --> 00:15:41,820
because the data is
such an important input

380
00:15:41,820 --> 00:15:43,860
to orchestrate or sort
of steering the model

381
00:15:43,860 --> 00:15:45,030
in a particular direction.

382
00:15:45,030 --> 00:15:48,000
So we need to be able
to essentially evaluate

383
00:15:48,000 --> 00:15:51,030
in batch offline using some
representation of the real data,

384
00:15:51,030 --> 00:15:53,580
but we also need to be observing
these sort of in real time

385
00:15:53,580 --> 00:15:56,100
and also continually
evaluating the AI system

386
00:15:56,100 --> 00:15:57,630
against a real reflection of the data

387
00:15:57,630 --> 00:16:02,190
to have some sense that, or of
reliability of the AI system.

388
00:16:02,190 --> 00:16:03,750
So with traditional software,

389
00:16:03,750 --> 00:16:06,090
we lived in a world of iterating on code,

390
00:16:06,090 --> 00:16:08,670
and with AI systems we're
essentially moving in the world

391
00:16:08,670 --> 00:16:10,410
where we're iterating
on data all the time.

392
00:16:10,410 --> 00:16:14,217
We need to iterate, sort of
process, reprocess the data,

393
00:16:14,217 --> 00:16:17,190
and test and eval and get to a place

394
00:16:17,190 --> 00:16:18,630
where we have some level of confidence

395
00:16:18,630 --> 00:16:21,453
this AI system's gonna do
what we expect it to do.

396
00:16:22,620 --> 00:16:25,980
And, talk more about sort of
all the components of this,

397
00:16:25,980 --> 00:16:27,780
like why context matters,

398
00:16:27,780 --> 00:16:29,430
what are all the elements
of context engineering,

399
00:16:29,430 --> 00:16:31,203
I'll pass this back to Cal.

400
00:16:34,200 --> 00:16:37,950
- Okay, so remember when
we were doing single turn?

401
00:16:37,950 --> 00:16:39,397
Back then, we weren't really,

402
00:16:39,397 --> 00:16:42,090
you know, the models weren't very smart

403
00:16:42,090 --> 00:16:44,250
and we weren't quite,

404
00:16:44,250 --> 00:16:45,480
we hadn't quite figured things out.

405
00:16:45,480 --> 00:16:48,330
And so I would call this the
era of prompt engineering.

406
00:16:48,330 --> 00:16:50,100
Last year when I was here at re:Invent,

407
00:16:50,100 --> 00:16:52,170
I had a whole kind of talk
where I was talking about

408
00:16:52,170 --> 00:16:54,480
prompt engineering best practices.

409
00:16:54,480 --> 00:16:57,487
And, I don't know, prompt
engineering was all about

410
00:16:57,487 --> 00:17:00,030
"Okay, you know, the
model's not very smart

411
00:17:00,030 --> 00:17:02,460
so I gotta think about
how exactly do I craft

412
00:17:02,460 --> 00:17:03,930
my instructions in a way where I get

413
00:17:03,930 --> 00:17:06,420
something useful outta the
model on the other side?"

414
00:17:06,420 --> 00:17:08,167
There are all these tips and tricks like,

415
00:17:08,167 --> 00:17:10,350
"Oh how many examples should I use?"

416
00:17:10,350 --> 00:17:12,510
And "Oh, if I'm using anthropic models

417
00:17:12,510 --> 00:17:14,340
I better wrap everything in XML tags.

418
00:17:14,340 --> 00:17:16,990
I think that'll make the
model work a little better."

419
00:17:18,900 --> 00:17:20,940
And so, when you were kind of building

420
00:17:20,940 --> 00:17:22,560
on top of single turn prompts,

421
00:17:22,560 --> 00:17:23,407
what you're thinking about was,

422
00:17:23,407 --> 00:17:27,180
"Okay, how do I kind of, what
do I put in my system prompt?

423
00:17:27,180 --> 00:17:29,130
What do I put in my user message?"

424
00:17:29,130 --> 00:17:30,900
There was a time at Anthropic where like

425
00:17:30,900 --> 00:17:33,397
one of the pro-prompt engineering tips was

426
00:17:33,397 --> 00:17:35,820
"Never use the system
prompt for anything,"

427
00:17:35,820 --> 00:17:38,880
because Claude was
anecdotally a little better

428
00:17:38,880 --> 00:17:41,520
at instruction following if
it was in the user message.

429
00:17:41,520 --> 00:17:43,830
And so there's this, all
these kind of little tricks

430
00:17:43,830 --> 00:17:45,120
that people would, you know,

431
00:17:45,120 --> 00:17:47,870
kind of think about and and
try to iterate on and test.

432
00:17:49,170 --> 00:17:54,170
Now, we are in kind of the Agentic world

433
00:17:54,180 --> 00:17:57,510
and so we have moved on
from prompt engineering

434
00:17:57,510 --> 00:18:00,090
to what we call context engineering,

435
00:18:00,090 --> 00:18:01,740
and we kind of think of this as a more

436
00:18:01,740 --> 00:18:03,240
broad and interesting problem.

437
00:18:03,240 --> 00:18:04,440
Why?

438
00:18:04,440 --> 00:18:06,210
Well we have our system prompt

439
00:18:06,210 --> 00:18:08,520
and user message just like before,

440
00:18:08,520 --> 00:18:10,500
but we have other things
that we wanna think about.

441
00:18:10,500 --> 00:18:13,260
Now we have our tools and if
we wanna maybe give our Agent

442
00:18:13,260 --> 00:18:16,950
access to documents and
other pieces of text,

443
00:18:16,950 --> 00:18:18,150
how do we do that?

444
00:18:18,150 --> 00:18:21,870
And then remember, the Agent
is the LM running in a loop.

445
00:18:21,870 --> 00:18:25,380
So it's not just one single
API called to the LM,

446
00:18:25,380 --> 00:18:28,560
it's going to be calling
the LM, it does something,

447
00:18:28,560 --> 00:18:30,357
you go do something else, then
you give it back to the LM,

448
00:18:30,357 --> 00:18:33,000
and it's running a loop
and going and going, going.

449
00:18:33,000 --> 00:18:35,520
So we have the assistant
message, what does the Agent say?

450
00:18:35,520 --> 00:18:38,070
And we're gonna have all of
our tool calls and results

451
00:18:38,070 --> 00:18:41,463
and this is gonna build up over time.

452
00:18:43,440 --> 00:18:45,390
And then, maybe to mix things up,

453
00:18:45,390 --> 00:18:47,310
we wanna add some new
tools, some new documents.

454
00:18:47,310 --> 00:18:48,690
And so the problem space,

455
00:18:48,690 --> 00:18:50,190
what we need to think about and work on

456
00:18:50,190 --> 00:18:53,553
when we're building Agents,
putting them into production,

457
00:18:54,420 --> 00:18:56,130
a little more interesting,
a little more fun

458
00:18:56,130 --> 00:18:58,440
than prompt engineering in my opinion.

459
00:18:58,440 --> 00:19:00,383
So that's what I'm gonna be talking about.

460
00:19:01,770 --> 00:19:04,200
So prompt engineering, back in the day,

461
00:19:04,200 --> 00:19:05,340
models weren't super smart.

462
00:19:05,340 --> 00:19:07,830
They were very, very sensitive to exactly

463
00:19:07,830 --> 00:19:10,830
how you phrase things and worded things.

464
00:19:10,830 --> 00:19:14,400
What words will get me
the absolute best output?

465
00:19:14,400 --> 00:19:17,190
Context engineering much
more about just managing

466
00:19:17,190 --> 00:19:19,110
this whole information environment.

467
00:19:19,110 --> 00:19:22,560
What tokens, what am I gonna
present to my Agent and when?

468
00:19:22,560 --> 00:19:23,760
How am I going to do it?

469
00:19:24,990 --> 00:19:28,320
What is the optimal
configuration of context

470
00:19:28,320 --> 00:19:32,163
to get my desired behavior
out of this system?

471
00:19:34,470 --> 00:19:35,940
I've said context a few times,

472
00:19:35,940 --> 00:19:37,740
it's worth mentioning
that when I say context,

473
00:19:37,740 --> 00:19:39,240
I mean the context window.

474
00:19:39,240 --> 00:19:41,130
So all LMs, whether you're using

475
00:19:41,130 --> 00:19:44,970
Claude or ChatGPT or Gemini,

476
00:19:44,970 --> 00:19:46,980
they have this context window limit

477
00:19:46,980 --> 00:19:49,680
and this is actually
enforced at the API level,

478
00:19:49,680 --> 00:19:51,930
but there's only so much
text or so many words

479
00:19:51,930 --> 00:19:55,890
you can pour into the LM
and get a response back.

480
00:19:55,890 --> 00:19:58,230
And it's not that we don't
know how to do the math

481
00:19:58,230 --> 00:20:01,950
where if you gave us, you
know, 10 million tokens,

482
00:20:01,950 --> 00:20:03,180
we wouldn't know how to process it.

483
00:20:03,180 --> 00:20:05,190
It's more about that
the LM, at some point,

484
00:20:05,190 --> 00:20:07,650
we start to see like diminishing returns

485
00:20:07,650 --> 00:20:10,350
or if you pour too much text into the LM,

486
00:20:10,350 --> 00:20:12,270
it starts to get confused
and do a bad job.

487
00:20:12,270 --> 00:20:14,670
So we have to like cut,
set some thresholds,

488
00:20:14,670 --> 00:20:16,987
where we think it's an
appropriate time to just say,

489
00:20:16,987 --> 00:20:18,150
"Hey you shouldn't be passing

490
00:20:18,150 --> 00:20:19,700
any more tokens to this model."

491
00:20:23,070 --> 00:20:26,040
There's this idea of
context rot, which is,

492
00:20:26,040 --> 00:20:27,810
okay we have all these tokens,

493
00:20:27,810 --> 00:20:30,240
all this text that we
could put into the model.

494
00:20:30,240 --> 00:20:32,160
I kind of hinted at this earlier,

495
00:20:32,160 --> 00:20:34,320
which is we could take
all these instructions

496
00:20:34,320 --> 00:20:36,630
and put them into the,
(stumbles over words)

497
00:20:36,630 --> 00:20:38,040
give it to the model.

498
00:20:38,040 --> 00:20:40,020
We could take a whole bunch of documents

499
00:20:40,020 --> 00:20:41,130
and give it to the model.

500
00:20:41,130 --> 00:20:43,830
What we find is in most use cases,

501
00:20:43,830 --> 00:20:46,620
if you just start dumping text in there,

502
00:20:46,620 --> 00:20:48,570
the model tends to do a little worse

503
00:20:48,570 --> 00:20:50,790
at whatever you're gonna ask it to do.

504
00:20:50,790 --> 00:20:54,180
And so, even before you hit
this context window limit,

505
00:20:54,180 --> 00:20:57,780
you wanna be mindful of, okay,
when my Agent is working,

506
00:20:57,780 --> 00:21:00,420
when it's calling Tools
and getting responses back,

507
00:21:00,420 --> 00:21:01,680
the initial instructions,

508
00:21:01,680 --> 00:21:03,690
I don't wanna lot of extra junk in there

509
00:21:03,690 --> 00:21:06,693
because it's probably gonna
be impacting performance.

510
00:21:07,980 --> 00:21:08,910
There's a company called Chroma,

511
00:21:08,910 --> 00:21:11,940
they did a very nice technical
report, it's a blog post,

512
00:21:11,940 --> 00:21:13,890
look it up, they write all about this,

513
00:21:13,890 --> 00:21:15,330
and they actually kind of break it down

514
00:21:15,330 --> 00:21:18,093
and talk about different
ways that this can fail.

515
00:21:18,960 --> 00:21:21,870
The other reason you're gonna
want to think about context,

516
00:21:21,870 --> 00:21:23,610
especially when you're building Agents,

517
00:21:23,610 --> 00:21:27,420
remember I said that an Agent
is the LM running in a loop,

518
00:21:27,420 --> 00:21:30,090
multiple calls over and over again,

519
00:21:30,090 --> 00:21:33,150
is if you build your
Agent in the right way

520
00:21:33,150 --> 00:21:34,590
and you're thinking about context,

521
00:21:34,590 --> 00:21:37,560
you can take advantage of
things like prompt caching.

522
00:21:37,560 --> 00:21:39,600
The idea with prompt caching is

523
00:21:39,600 --> 00:21:42,990
if you make an API call to an LLM,

524
00:21:42,990 --> 00:21:44,880
and then you make another
call and there's some sort of

525
00:21:44,880 --> 00:21:48,120
fixed prefix like the text didn't change

526
00:21:48,120 --> 00:21:50,400
from one API call to the next,

527
00:21:50,400 --> 00:21:52,710
Anthropic can cache it behind the scenes

528
00:21:52,710 --> 00:21:54,670
and then we can pass on a very nice

529
00:21:55,620 --> 00:21:56,940
little cost discount to you

530
00:21:56,940 --> 00:21:58,890
as well as you benefit from some latency

531
00:21:58,890 --> 00:22:01,347
because we don't have to process
these input tokens again.

532
00:22:01,347 --> 00:22:05,130
And so if you are building with
context engineering in mind,

533
00:22:05,130 --> 00:22:07,830
you can take advantage of these things.

534
00:22:07,830 --> 00:22:10,110
And so when we talk about
context engineering,

535
00:22:10,110 --> 00:22:12,960
we're really trying to kind of
move three different levers.

536
00:22:12,960 --> 00:22:14,910
One of 'em is very practical and boring.

537
00:22:14,910 --> 00:22:17,280
It's the fact that our
API will only let you pass

538
00:22:17,280 --> 00:22:19,740
so much text into it at once.

539
00:22:19,740 --> 00:22:20,610
So we need to think about,

540
00:22:20,610 --> 00:22:23,190
okay, how are we gonna deal
with this context window limit

541
00:22:23,190 --> 00:22:25,770
and get around that and
still get our system

542
00:22:25,770 --> 00:22:27,480
to do cool things?

543
00:22:27,480 --> 00:22:29,940
We can reduce context rot,

544
00:22:29,940 --> 00:22:33,540
which is this idea of
even after we've kind of,

545
00:22:33,540 --> 00:22:35,490
when we are giving stuff to the model,

546
00:22:35,490 --> 00:22:37,620
can we make sure the tokens
that we're showing it

547
00:22:37,620 --> 00:22:41,130
are useful and we're not hurting
our accuracy in some way?

548
00:22:41,130 --> 00:22:42,810
And then finally,

549
00:22:42,810 --> 00:22:45,870
if we do this right and we
are mindful of prompt caching,

550
00:22:45,870 --> 00:22:48,540
we get some nice cost and latency benefits

551
00:22:48,540 --> 00:22:50,550
and so we do all these
things in our own products

552
00:22:50,550 --> 00:22:52,650
when we're building Claude Code

553
00:22:52,650 --> 00:22:55,413
and we advise our customers
to do this as well.

554
00:22:57,900 --> 00:22:59,580
What are some other
things we can think about

555
00:22:59,580 --> 00:23:01,380
when we're doing context engineering?

556
00:23:01,380 --> 00:23:03,330
Well, we have our system prompts,

557
00:23:03,330 --> 00:23:06,630
the instructions that we're
gonna give the Agent, the model.

558
00:23:06,630 --> 00:23:08,130
We have our tools, okay?

559
00:23:08,130 --> 00:23:09,450
What is our Agent gonna be able to do?

560
00:23:09,450 --> 00:23:11,220
How can it interact with the world

561
00:23:11,220 --> 00:23:15,060
and pull more information
in and change things?

562
00:23:15,060 --> 00:23:17,550
We have data retrieval, which
we're gonna talk about a lot,

563
00:23:17,550 --> 00:23:21,420
which is, okay, this Agent
is only gonna be as useful

564
00:23:21,420 --> 00:23:24,870
as kind of the information that
wasn't pre-trained into it.

565
00:23:24,870 --> 00:23:27,300
How do we pull things
in about the business,

566
00:23:27,300 --> 00:23:29,190
about the problem, about the customer,

567
00:23:29,190 --> 00:23:31,560
so that it can make smart decisions?

568
00:23:31,560 --> 00:23:33,330
And then I'll talk a little bit about

569
00:23:33,330 --> 00:23:35,520
long horizon optimizations.

570
00:23:35,520 --> 00:23:37,230
If we're building an Agent that might work

571
00:23:37,230 --> 00:23:39,840
for minutes or hours or days,

572
00:23:39,840 --> 00:23:41,790
we're gonna have to do some fancy stuff

573
00:23:41,790 --> 00:23:45,030
to get around some more
practical limitations

574
00:23:45,030 --> 00:23:47,943
like the context window
which is going to fill up.

575
00:23:49,020 --> 00:23:51,540
So let's start with the system prompts.

576
00:23:51,540 --> 00:23:54,030
And when we talk about prompting today,

577
00:23:54,030 --> 00:23:56,370
when I'm meeting with customers
and talking about prompting,

578
00:23:56,370 --> 00:24:00,090
it's less about, okay,
should I format my prompt

579
00:24:00,090 --> 00:24:04,590
as JSON or markdown, or, "Cal,
should I be using XML tags

580
00:24:04,590 --> 00:24:06,480
and where should I be doing it?"

581
00:24:06,480 --> 00:24:09,210
We're at a point where
we've done so much work

582
00:24:09,210 --> 00:24:14,210
to make the model steerable
that the little tips and tricks

583
00:24:14,226 --> 00:24:17,490
around XML tags don't matter so much.

584
00:24:17,490 --> 00:24:18,427
So when people ask me,

585
00:24:18,427 --> 00:24:21,030
"Hey Cal, what's like
your best prompting tip?"

586
00:24:21,030 --> 00:24:23,580
I always tell them that
the best tip I have

587
00:24:23,580 --> 00:24:25,480
when you're writing a prompt for an LM

588
00:24:26,318 --> 00:24:27,780
is you should take that prompt

589
00:24:27,780 --> 00:24:30,360
and imagine you are
giving it to your friend

590
00:24:30,360 --> 00:24:33,750
or your coworker that doesn't
know what you're working on

591
00:24:33,750 --> 00:24:35,430
and you say to them,
"Hey, with this prompt,

592
00:24:35,430 --> 00:24:39,000
with these instructions, would
you be able to do this task?"

593
00:24:39,000 --> 00:24:41,820
And if they say yes, then
probably the LM can do it too.

594
00:24:41,820 --> 00:24:43,380
And if they say, "No,
I'm a little confused,

595
00:24:43,380 --> 00:24:45,480
I don't really know what
you're asking me for,"

596
00:24:45,480 --> 00:24:48,360
probably the LM is confused as well.

597
00:24:48,360 --> 00:24:51,600
My team, what we do is
we go meet with customers

598
00:24:51,600 --> 00:24:53,917
and very often a customer
will say something like,

599
00:24:53,917 --> 00:24:56,150
"Eh, we tried Claude,
but like I don't know,

600
00:24:56,150 --> 00:24:57,300
it didn't really work that well.

601
00:24:57,300 --> 00:25:00,120
I don't think we wanna
use it in production."

602
00:25:00,120 --> 00:25:01,807
And always what we'll say back is like,

603
00:25:01,807 --> 00:25:03,090
"Oh okay, that's fine.

604
00:25:03,090 --> 00:25:05,070
But can we take a look at the prompts?

605
00:25:05,070 --> 00:25:06,270
We might be able to help."

606
00:25:06,270 --> 00:25:10,020
And nine times outta 10 when
we go and look at the prompts,

607
00:25:10,020 --> 00:25:12,210
there's something confusing
in the instructions

608
00:25:12,210 --> 00:25:13,740
and we can go in and point it out

609
00:25:13,740 --> 00:25:16,410
and clean it up and fix it,
put that into production,

610
00:25:16,410 --> 00:25:18,310
and all of a sudden Claude works well.

611
00:25:19,410 --> 00:25:22,110
And so there's kind of two failure modes,

612
00:25:22,110 --> 00:25:23,490
even if you write good instructions,

613
00:25:23,490 --> 00:25:25,470
where things can go wrong.

614
00:25:25,470 --> 00:25:29,070
So, one example of this is I
was working with a customer

615
00:25:29,070 --> 00:25:31,800
and was building a Customer Support Agent,

616
00:25:31,800 --> 00:25:34,310
and what they did at the very
start in their kind of POC

617
00:25:34,310 --> 00:25:37,710
is they took the standard
operating procedure, the SOP,

618
00:25:37,710 --> 00:25:40,170
that they give their human Support Agents

619
00:25:40,170 --> 00:25:42,630
when they onboard, when
they start on the first day.

620
00:25:42,630 --> 00:25:44,643
It's about a 32-page PDF,

621
00:25:45,660 --> 00:25:48,270
they copy pasted it into the prompts

622
00:25:48,270 --> 00:25:49,447
and then they came to me and said,

623
00:25:49,447 --> 00:25:50,959
"Hey, this isn't working very well."

624
00:25:50,959 --> 00:25:53,340
(audience chuckles)

625
00:25:53,340 --> 00:25:55,617
And I was like, "Oh my god."

626
00:25:57,300 --> 00:26:00,600
And so, this is where
you can get too specific.

627
00:26:00,600 --> 00:26:03,240
If your prompt starts to look
like something on the left

628
00:26:03,240 --> 00:26:05,670
where you have like this
complicated Workflow,

629
00:26:05,670 --> 00:26:09,210
and especially if you have all
of these if/else statements,

630
00:26:09,210 --> 00:26:12,450
you have this very complicated
chain of instructions

631
00:26:12,450 --> 00:26:13,650
that goes on and on and on,

632
00:26:13,650 --> 00:26:16,200
especially for thousands
and thousands of tokens,

633
00:26:16,200 --> 00:26:17,910
you're gonna overwhelm the model.

634
00:26:17,910 --> 00:26:19,470
It's not gonna be able
to do this very well.

635
00:26:19,470 --> 00:26:21,990
And there's techniques and
ways to get around this,

636
00:26:21,990 --> 00:26:24,810
but this is probably not what
your prompt should look like.

637
00:26:24,810 --> 00:26:28,200
On the other side, you can
fail by being too vague,

638
00:26:28,200 --> 00:26:30,120
and this is what I talked about earlier.

639
00:26:30,120 --> 00:26:31,987
You give the prompt to your
friend and they're like,

640
00:26:31,987 --> 00:26:33,060
"I don't know what you're talking about.

641
00:26:33,060 --> 00:26:35,430
I don't know how I would
do this task myself

642
00:26:35,430 --> 00:26:36,930
with these instructions."

643
00:26:36,930 --> 00:26:38,940
And so when we think about prompting,

644
00:26:38,940 --> 00:26:41,220
we're kind of trying to
get into what we call

645
00:26:41,220 --> 00:26:43,290
this Goldilocks zone where have

646
00:26:43,290 --> 00:26:44,880
just the right amount of details

647
00:26:44,880 --> 00:26:46,530
but we're leaving things open-ended

648
00:26:46,530 --> 00:26:48,990
and letting the model
do what it does best,

649
00:26:48,990 --> 00:26:50,370
which is deal with nuance.

650
00:26:50,370 --> 00:26:52,890
We're not trying to
hard code in a Workflow,

651
00:26:52,890 --> 00:26:54,900
we're trying to give agency to the model

652
00:26:54,900 --> 00:26:56,730
so it can kind of work.

653
00:26:56,730 --> 00:26:59,970
And we want to just be
telling the model, you know,

654
00:26:59,970 --> 00:27:02,460
the general way of how it's
gonna solve this problem

655
00:27:02,460 --> 00:27:04,440
and then the non-negotiable things

656
00:27:04,440 --> 00:27:06,840
that it absolutely must do
or absolutely shouldn't do.

657
00:27:06,840 --> 00:27:07,890
And then everything else,

658
00:27:07,890 --> 00:27:10,293
we should try to let it
figure out on its own.

659
00:27:12,270 --> 00:27:14,310
So it can be too prescriptive.

660
00:27:14,310 --> 00:27:17,933
Signs of that is if we have a
whole bunch of if/else logic,

661
00:27:17,933 --> 00:27:21,450
we have these very complex
and brutal instructions,

662
00:27:21,450 --> 00:27:23,580
and we're trying to encode

663
00:27:23,580 --> 00:27:26,670
every single possible scenario
into the instructions.

664
00:27:26,670 --> 00:27:27,630
And then of course,

665
00:27:27,630 --> 00:27:29,793
we can fail on the other side like I said.

666
00:27:31,800 --> 00:27:33,780
That's the system prompt.

667
00:27:33,780 --> 00:27:35,190
Okay, what about tool design?

668
00:27:35,190 --> 00:27:37,590
So we have our instructions
in the system prompts,

669
00:27:37,590 --> 00:27:39,540
but we're also going to give our Agent

670
00:27:39,540 --> 00:27:43,710
1, 2, 10, 50 different tools?

671
00:27:43,710 --> 00:27:46,050
How do we do that well?

672
00:27:46,050 --> 00:27:47,610
Well, we wanna remember that the tools,

673
00:27:47,610 --> 00:27:49,800
when we give a tool to the model,

674
00:27:49,800 --> 00:27:51,990
we should just think of that
as additional prompting.

675
00:27:51,990 --> 00:27:54,300
What happens behind the
scenes when you make

676
00:27:54,300 --> 00:27:57,450
an API call to Anthropic and
you pass the tools array,

677
00:27:57,450 --> 00:27:58,890
we take that tools array,

678
00:27:58,890 --> 00:28:01,290
we actually just plop it at
the top of the system prompt

679
00:28:01,290 --> 00:28:02,587
and it says something like,

680
00:28:02,587 --> 00:28:04,677
"Hey Claude, here's
the tools you can use."

681
00:28:04,677 --> 00:28:05,610
And Claude's been trained

682
00:28:05,610 --> 00:28:07,650
to kind of know what to do from there.

683
00:28:07,650 --> 00:28:09,570
But when you're defining these tools

684
00:28:09,570 --> 00:28:11,490
and passing 'em in the API,

685
00:28:11,490 --> 00:28:13,380
you gotta remember that those definitions

686
00:28:13,380 --> 00:28:14,520
are going straight to the model.

687
00:28:14,520 --> 00:28:17,310
It is seeing what you are typing in there.

688
00:28:17,310 --> 00:28:19,530
And so there's some things we can do here

689
00:28:19,530 --> 00:28:21,480
to make sure that we do well.

690
00:28:21,480 --> 00:28:25,200
So one, is we want just
simple accurate names,

691
00:28:25,200 --> 00:28:26,250
search customers.

692
00:28:26,250 --> 00:28:29,460
We don't want something that's
just like, I don't know,

693
00:28:29,460 --> 00:28:31,920
X, Y, Z, 1, 2, 3.

694
00:28:31,920 --> 00:28:35,310
We want detailed and
well-formed descriptions

695
00:28:35,310 --> 00:28:37,440
and we can do things in our descriptions.

696
00:28:37,440 --> 00:28:39,240
Think of it like more prompting.

697
00:28:39,240 --> 00:28:42,480
We can do things in our
descriptions like provide examples,

698
00:28:42,480 --> 00:28:44,460
like here are good times to use this tool

699
00:28:44,460 --> 00:28:46,680
and here are bad times to use this tool.

700
00:28:46,680 --> 00:28:48,960
When I was working on Claude Code,

701
00:28:48,960 --> 00:28:52,590
I was very often not messing
with our system prompts

702
00:28:52,590 --> 00:28:55,320
but I was spending most of
my time in tool descriptions

703
00:28:55,320 --> 00:28:58,953
tweaking kind of the prompting
and instructions there.

704
00:29:00,300 --> 00:29:02,400
One failure mode that
can definitely happen

705
00:29:02,400 --> 00:29:04,770
when you're building an Agent
that's more general purpose

706
00:29:04,770 --> 00:29:08,460
and can do a lot of
things is in claude.ai,

707
00:29:08,460 --> 00:29:11,250
which is our kind of chatbot tool

708
00:29:11,250 --> 00:29:13,410
that we sell to enterprises.

709
00:29:13,410 --> 00:29:15,510
We had one team that was off building

710
00:29:15,510 --> 00:29:17,490
a web search feature at some point.

711
00:29:17,490 --> 00:29:20,550
They had built this tool that
was something like Search Web,

712
00:29:20,550 --> 00:29:22,770
and meanwhile another
team was building out

713
00:29:22,770 --> 00:29:24,300
our Google Drive integration,

714
00:29:24,300 --> 00:29:27,720
so they had built this search drive tool.

715
00:29:27,720 --> 00:29:30,960
And both of these things
were working very well

716
00:29:30,960 --> 00:29:33,180
and we shipped these
at around the same time

717
00:29:33,180 --> 00:29:35,100
and we kind of put 'em in, you know,

718
00:29:35,100 --> 00:29:37,020
the model now has the search web tool

719
00:29:37,020 --> 00:29:40,050
and the search drive
tool, and all of a sudden,

720
00:29:40,050 --> 00:29:42,750
the model kind of, there wasn't
very good prompting here,

721
00:29:42,750 --> 00:29:44,850
and so the model was confused about

722
00:29:44,850 --> 00:29:46,830
when to use which tool and when.

723
00:29:46,830 --> 00:29:49,440
What information would be
hiding behind a Google Drive

724
00:29:49,440 --> 00:29:51,000
and what would be behind the web.

725
00:29:51,000 --> 00:29:53,460
And so the model would
be searching for things

726
00:29:53,460 --> 00:29:54,870
in Google Drive where clearly

727
00:29:54,870 --> 00:29:57,420
it should be using the web and vice versa.

728
00:29:57,420 --> 00:30:00,270
And so if our tools, the
names and descriptions,

729
00:30:00,270 --> 00:30:03,360
especially on searches where
we've ran into this the most,

730
00:30:03,360 --> 00:30:05,280
are too similar,

731
00:30:05,280 --> 00:30:07,630
you can get into trouble
and confuse the model.

732
00:30:12,270 --> 00:30:16,830
Okay, data retrieval paradigm shifts.

733
00:30:16,830 --> 00:30:19,920
So, back in the day back
when we were building

734
00:30:19,920 --> 00:30:22,800
single term prompts and and Workflows,

735
00:30:22,800 --> 00:30:25,890
the way you would give the
model information about things

736
00:30:25,890 --> 00:30:27,870
it wouldn't know about because
it wasn't trained on it,

737
00:30:27,870 --> 00:30:29,850
it wasn't in the pre-training set,

738
00:30:29,850 --> 00:30:31,410
was you do this thing called RAG:

739
00:30:31,410 --> 00:30:33,240
Retrieve Augmented Generation.

740
00:30:33,240 --> 00:30:34,710
The basic idea is here,

741
00:30:34,710 --> 00:30:38,520
is you have a step before you call the LM

742
00:30:38,520 --> 00:30:40,260
where you go try to grab all

743
00:30:40,260 --> 00:30:42,600
the potentially useful information

744
00:30:42,600 --> 00:30:44,347
and then you give it
to the LM and you say,

745
00:30:44,347 --> 00:30:45,720
"Here's the information.

746
00:30:45,720 --> 00:30:48,720
Try to do, I dunno, try to
answer this question. Good luck."

747
00:30:49,650 --> 00:30:52,470
RAG has a problem, which is,
if you fail the retrieval,

748
00:30:52,470 --> 00:30:54,600
if you do a bad job at retrieval,

749
00:30:54,600 --> 00:30:56,460
there's nothing the LM
can really do about it.

750
00:30:56,460 --> 00:30:57,720
If you give it kind of junk data,

751
00:30:57,720 --> 00:30:59,970
it can't really recover out of it.

752
00:30:59,970 --> 00:31:02,250
Agents solve this problem

753
00:31:02,250 --> 00:31:04,980
because we can give
the Agent a search tool

754
00:31:04,980 --> 00:31:08,430
and the Agent can write
a query to run a search,

755
00:31:08,430 --> 00:31:09,937
get some results back and think,

756
00:31:09,937 --> 00:31:12,930
"Oh weird, I didn't get what
I wanted, let me try again."

757
00:31:12,930 --> 00:31:15,510
So that sort of like I
talked about earlier,

758
00:31:15,510 --> 00:31:18,903
the ability to kind of recover
out of errors in bad states.

759
00:31:20,250 --> 00:31:23,880
And so in an Agentic setup
when we're context engineering,

760
00:31:23,880 --> 00:31:25,207
we're always thinking about,

761
00:31:25,207 --> 00:31:27,750
"Okay, what do I wanna
preload into my Agent?

762
00:31:27,750 --> 00:31:29,970
What do I want to always be there?"

763
00:31:29,970 --> 00:31:32,220
Probably the instructions and the tools

764
00:31:32,220 --> 00:31:35,280
and what information
can I kind of hide away

765
00:31:35,280 --> 00:31:37,020
and tuck away behind my tools

766
00:31:37,020 --> 00:31:40,680
and the Agent can go grab it
only if it really needs it?

767
00:31:40,680 --> 00:31:44,370
So in Claude Code for
instance, if you use this tool,

768
00:31:44,370 --> 00:31:46,980
we have something called Claude.md.

769
00:31:46,980 --> 00:31:50,220
This is like a special
markdown file that is optional,

770
00:31:50,220 --> 00:31:52,410
but we let our developers basically

771
00:31:52,410 --> 00:31:55,920
put in additional like
information and instructions

772
00:31:55,920 --> 00:31:57,870
and preferences that are unique to them

773
00:31:57,870 --> 00:32:00,480
about how they want Claude Code to behave

774
00:32:00,480 --> 00:32:02,850
and you know, what they
want it to know about

775
00:32:02,850 --> 00:32:04,590
themselves or the code base.

776
00:32:04,590 --> 00:32:07,590
And so something like that,
we preload no matter what.

777
00:32:07,590 --> 00:32:09,141
When the Agent starts,

778
00:32:09,141 --> 00:32:11,760
we just look in the
current working directory

779
00:32:11,760 --> 00:32:13,140
for a Claude.md file.

780
00:32:13,140 --> 00:32:15,780
If it's there we put
it in the system prompt

781
00:32:15,780 --> 00:32:17,407
and we literally say something like,

782
00:32:17,407 --> 00:32:18,990
"Hey, here's some additional instructions

783
00:32:18,990 --> 00:32:20,820
this developer wanted you to know."

784
00:32:20,820 --> 00:32:22,620
So that's something we preload.

785
00:32:22,620 --> 00:32:25,680
But what we don't do in Claude
Code is when we start it up,

786
00:32:25,680 --> 00:32:28,440
we don't take all the
files in the code base

787
00:32:28,440 --> 00:32:30,157
and just like dump 'em
in the prompt and say

788
00:32:30,157 --> 00:32:33,300
"Hey, here's all the files in
this code base, good luck."

789
00:32:33,300 --> 00:32:37,410
Instead, we give Claude two
tools to basically just kind of

790
00:32:37,410 --> 00:32:41,310
grab and find and search a
code base like you or I would.

791
00:32:41,310 --> 00:32:42,750
And so we're thinking about ways

792
00:32:42,750 --> 00:32:45,000
we can do progressive disclosure.

793
00:32:45,000 --> 00:32:49,080
How do we kind of give
the model hints about,

794
00:32:49,080 --> 00:32:51,660
okay, what information
might be available to it

795
00:32:51,660 --> 00:32:54,660
and if it thinks it's
interested then it can go

796
00:32:54,660 --> 00:32:57,870
and look things up and
figure out more about it.

797
00:32:57,870 --> 00:33:02,250
Has anyone here about
heard about Skills? Yes.

798
00:33:02,250 --> 00:33:04,860
So Skills is kind of
building on this pattern.

799
00:33:04,860 --> 00:33:08,430
We saw this in Claude Code
where we could take files

800
00:33:08,430 --> 00:33:10,470
that might be interesting at some point

801
00:33:10,470 --> 00:33:13,020
and let the model kind of figure
out and use them over time

802
00:33:13,020 --> 00:33:15,810
without having to load all
the information up front.

803
00:33:15,810 --> 00:33:18,000
And so this is really what
Skills is under the hood.

804
00:33:18,000 --> 00:33:21,660
So Skills is like this idea
where you as the end user

805
00:33:21,660 --> 00:33:24,720
basically define, I don't
know, markdown files,

806
00:33:24,720 --> 00:33:26,670
python files, things like that,

807
00:33:26,670 --> 00:33:29,220
that might be useful for
the Agent at certain times.

808
00:33:29,220 --> 00:33:34,220
So in claude.ai, a good
example of this is,

809
00:33:34,290 --> 00:33:36,360
we want claude.ai to be
able to, I don't know,

810
00:33:36,360 --> 00:33:38,673
make a PowerPoint or build a spreadsheet,

811
00:33:40,170 --> 00:33:42,420
but we don't have to
take all the instructions

812
00:33:42,420 --> 00:33:44,970
for making PowerPoints and
making good spreadsheets

813
00:33:44,970 --> 00:33:47,340
and put it in the system
prompt all the time.

814
00:33:47,340 --> 00:33:49,177
Instead in the system prompt,
we say something like,

815
00:33:49,177 --> 00:33:52,440
"Hey, if the user asks
you to make a PowerPoint

816
00:33:52,440 --> 00:33:54,480
or build a spreadsheet,

817
00:33:54,480 --> 00:33:56,790
you go look in the Skills
folder and there's gonna be

818
00:33:56,790 --> 00:33:59,190
a whole bunch of useful
stuff in there for you."

819
00:33:59,190 --> 00:34:01,320
And so, in the 10% of
the time or whatever,

820
00:34:01,320 --> 00:34:04,830
where the model where the end
user's gonna ask for this,

821
00:34:04,830 --> 00:34:08,853
the model knows how to go
explore and get that information.

822
00:34:11,040 --> 00:34:12,690
And then the last thing I wanna talk about

823
00:34:12,690 --> 00:34:13,950
is long horizon tasks.

824
00:34:13,950 --> 00:34:17,250
So remember we have this context
window that's gonna fill up

825
00:34:17,250 --> 00:34:19,382
and remember that the
model is running in a loop.

826
00:34:19,382 --> 00:34:21,360
API call, API call, API call,

827
00:34:21,360 --> 00:34:23,640
and we don't wanna bust the prompt cache.

828
00:34:23,640 --> 00:34:25,440
So that means we're not ever gonna

829
00:34:25,440 --> 00:34:28,410
remove text from this conversation chain.

830
00:34:28,410 --> 00:34:29,787
We're gonna be append only.

831
00:34:29,787 --> 00:34:32,970
And so at some point our
conversation's gonna get too long

832
00:34:32,970 --> 00:34:35,970
and we're gonna get to 200,000
tokens and what do we do?

833
00:34:35,970 --> 00:34:37,020
Well, in Claude Code,

834
00:34:37,020 --> 00:34:40,740
the way we solve for this is
something we call a compaction.

835
00:34:40,740 --> 00:34:43,110
When Claude is getting
close to the context window,

836
00:34:43,110 --> 00:34:44,910
we can detect this and what we do

837
00:34:44,910 --> 00:34:48,570
is we basically inject a user message in

838
00:34:48,570 --> 00:34:51,217
and the user message says
something along the lines of,

839
00:34:51,217 --> 00:34:55,350
"Hey, I need to pass this
task off to another developer,

840
00:34:55,350 --> 00:34:58,050
summarize everything
we were just working on

841
00:34:58,050 --> 00:34:59,877
and all the important details."

842
00:35:01,350 --> 00:35:02,730
And then we take that summary,

843
00:35:02,730 --> 00:35:05,730
we clear out the whole conversation
so we start over fresh,

844
00:35:05,730 --> 00:35:07,627
we put that summary at the
very start and then we say,

845
00:35:07,627 --> 00:35:09,237
"Okay, keep working from here."

846
00:35:10,740 --> 00:35:12,180
But there are other ways to solve this.

847
00:35:12,180 --> 00:35:14,100
More experimental memory.

848
00:35:14,100 --> 00:35:16,950
Can the model just write notes for itself?

849
00:35:16,950 --> 00:35:19,593
And then also sub-Agent architectures.

850
00:35:21,180 --> 00:35:22,800
So system prompts,

851
00:35:22,800 --> 00:35:25,260
how do we get the instructions
in the right shape?

852
00:35:25,260 --> 00:35:27,000
Tools, probably the most interesting

853
00:35:27,000 --> 00:35:29,370
and useful things that the Agent can do.

854
00:35:29,370 --> 00:35:31,830
Think about iterating on the tools.

855
00:35:31,830 --> 00:35:34,020
Data retrieval, which we'll talk about.

856
00:35:34,020 --> 00:35:36,030
How do we get the right information

857
00:35:36,030 --> 00:35:38,370
to the Agent to do useful things?

858
00:35:38,370 --> 00:35:41,880
And then being mindful of
long horizon optimizations,

859
00:35:41,880 --> 00:35:43,530
if we're building an
Agent that's gonna work

860
00:35:43,530 --> 00:35:45,213
for many minutes or hours.

861
00:35:47,310 --> 00:35:48,420
- Awesome.

862
00:35:48,420 --> 00:35:50,490
So I'm gonna dig into this kind of

863
00:35:50,490 --> 00:35:54,930
data to retrieval challenge
and how do you curate context?

864
00:35:54,930 --> 00:35:56,310
So if we kind of pause for a moment

865
00:35:56,310 --> 00:35:58,680
and we think about human reasoning.

866
00:35:58,680 --> 00:36:02,220
So, if you were to cross
a street, you know,

867
00:36:02,220 --> 00:36:04,410
how many people would feel
comfortable crossing a street

868
00:36:04,410 --> 00:36:06,180
based on essentially a snapshot

869
00:36:06,180 --> 00:36:08,310
of where the cars were
on the street yesterday?

870
00:36:08,310 --> 00:36:10,620
Like, most of us probably
wouldn't feel confident

871
00:36:10,620 --> 00:36:11,670
about crossing that street.

872
00:36:11,670 --> 00:36:15,210
And when it comes to human
reasoning and decision making,

873
00:36:15,210 --> 00:36:17,580
you know, something as simple
as crossing the street,

874
00:36:17,580 --> 00:36:20,310
obviously, we have a lot
of history of doing that.

875
00:36:20,310 --> 00:36:22,080
Like I've probably crossed
the street successfully

876
00:36:22,080 --> 00:36:24,120
tens of thousands of times in my life,

877
00:36:24,120 --> 00:36:27,630
but I don't just rely on
my historical reference.

878
00:36:27,630 --> 00:36:29,610
I also need, essentially,
a fresh representation

879
00:36:29,610 --> 00:36:30,900
of what's happening in the moment.

880
00:36:30,900 --> 00:36:33,490
So I need to pair essentially both

881
00:36:34,470 --> 00:36:36,080
sort of real time signal information

882
00:36:36,080 --> 00:36:38,910
of what's happening in the
moment, or fresh context,

883
00:36:38,910 --> 00:36:41,490
with historical pattern
matching and so forth.

884
00:36:41,490 --> 00:36:44,550
And this is true of most sort
of human reasoning situations,

885
00:36:44,550 --> 00:36:47,670
but it's also true of
most operational use cases

886
00:36:47,670 --> 00:36:48,900
when it comes to software,

887
00:36:48,900 --> 00:36:51,150
you know, dealing with
customers and so forth.

888
00:36:51,150 --> 00:36:53,400
So these are important
things to think about.

889
00:36:53,400 --> 00:36:55,410
And this is, in many ways,

890
00:36:55,410 --> 00:36:58,170
what the context problem is
when it comes to data retrieval,

891
00:36:58,170 --> 00:37:00,540
because during this kind of online process

892
00:37:00,540 --> 00:37:01,800
of prompt time assembly,

893
00:37:01,800 --> 00:37:04,980
I need to go and gather
this contextual information.

894
00:37:04,980 --> 00:37:08,730
And if my AI system is
doing something like

895
00:37:08,730 --> 00:37:11,850
helping doctors or
nurses monitor patients,

896
00:37:11,850 --> 00:37:15,360
I don't want that AI system
to be making decisions

897
00:37:15,360 --> 00:37:17,970
based on vitals of the
patient from six hours ago.

898
00:37:17,970 --> 00:37:19,530
I want it to be making decisions

899
00:37:19,530 --> 00:37:22,080
based on what's happening
right now in this moment.

900
00:37:23,220 --> 00:37:26,040
But that's a hard problem
in many businesses.

901
00:37:26,040 --> 00:37:27,570
But there's a couple different ways

902
00:37:27,570 --> 00:37:28,620
or two or three approaches

903
00:37:28,620 --> 00:37:31,560
that I see businesses trying
to tackle this problem.

904
00:37:31,560 --> 00:37:33,570
So the first thing is

905
00:37:33,570 --> 00:37:36,900
essentially taking all of
their operational data stores,

906
00:37:36,900 --> 00:37:38,730
whether it's the database, an API,

907
00:37:38,730 --> 00:37:41,020
some sort SaaS application and
throwing MCP in front of it,

908
00:37:41,020 --> 00:37:43,860
and I actually had a call
very early this morning

909
00:37:43,860 --> 00:37:46,950
with a company that is
attempting this approach,

910
00:37:46,950 --> 00:37:48,900
and it makes a lot of sense.

911
00:37:48,900 --> 00:37:51,690
It's like let's take all of our
operational sources of truth

912
00:37:51,690 --> 00:37:53,130
and we'll throw MCP on front of it

913
00:37:53,130 --> 00:37:54,827
and we'll use tool calls into it,

914
00:37:54,827 --> 00:37:56,460
and we'll get sort of
the latest information

915
00:37:56,460 --> 00:37:58,380
about our business estate.

916
00:37:58,380 --> 00:38:01,080
But in practice, there's a
number of challenges with this,

917
00:38:01,080 --> 00:38:03,720
and it has nothing to do
with MCP, MCP's great,

918
00:38:03,720 --> 00:38:06,390
but what you're doing
when you sort of open up

919
00:38:06,390 --> 00:38:10,800
all your different locations
to a new workload like this

920
00:38:10,800 --> 00:38:13,650
is you're adding a pretty
large security footprint

921
00:38:13,650 --> 00:38:15,330
on these existing systems

922
00:38:15,330 --> 00:38:17,670
that are probably all have their own ways

923
00:38:17,670 --> 00:38:19,500
of governing access and access control.

924
00:38:19,500 --> 00:38:21,360
So that's one problem you need to solve.

925
00:38:21,360 --> 00:38:22,500
They're also probably serving

926
00:38:22,500 --> 00:38:24,330
other workloads within your business.

927
00:38:24,330 --> 00:38:26,970
So you're adding a bunch of
different new operational load

928
00:38:26,970 --> 00:38:29,280
to these databases and other systems.

929
00:38:29,280 --> 00:38:31,110
And probably one of the biggest challenges

930
00:38:31,110 --> 00:38:34,440
is that none of these
systems were ever designed

931
00:38:34,440 --> 00:38:37,320
with the idea that an AI
system was gonna use them.

932
00:38:37,320 --> 00:38:38,773
They were designed for humans to use them.

933
00:38:38,773 --> 00:38:41,130
So if I'm, you know, designing an API

934
00:38:41,130 --> 00:38:43,080
and I'm an engineer that's
gonna do some integration

935
00:38:43,080 --> 00:38:46,110
with that API, well I can
read the documentation,

936
00:38:46,110 --> 00:38:47,760
I can read the API spec,

937
00:38:47,760 --> 00:38:50,310
and I interpret it and
I write business logic

938
00:38:50,310 --> 00:38:51,720
that allows me to use that API.

939
00:38:51,720 --> 00:38:53,880
Maybe I'm only using a subset of the data

940
00:38:53,880 --> 00:38:55,710
or I need to write code

941
00:38:55,710 --> 00:38:58,200
to translate that data
into a different format.

942
00:38:58,200 --> 00:38:59,580
Whatever it is, I can essentially,

943
00:38:59,580 --> 00:39:03,330
I have the context to
understand that raw data,

944
00:39:03,330 --> 00:39:05,400
but the model doesn't.

945
00:39:05,400 --> 00:39:08,520
So what you need is not the raw data,

946
00:39:08,520 --> 00:39:10,380
because the raw data
ends up with this problem

947
00:39:10,380 --> 00:39:11,910
of exploding token costs
where we're feeding

948
00:39:11,910 --> 00:39:15,180
a lot of information essentially
on the ingress in the model

949
00:39:15,180 --> 00:39:16,380
and then leads to mistakes.

950
00:39:16,380 --> 00:39:19,770
What you need is refined
data, or a dry data set.

951
00:39:19,770 --> 00:39:23,010
It's like, we don't put
crude oil into a car.

952
00:39:23,010 --> 00:39:24,750
The oil goes through a refinement process

953
00:39:24,750 --> 00:39:27,540
before we feed a car and end up with fuel.

954
00:39:27,540 --> 00:39:30,900
Or you know, we don't take
a bunch of raw ingredients

955
00:39:30,900 --> 00:39:34,200
like you know, salt and pepper and spices

956
00:39:34,200 --> 00:39:37,050
and a bunch of raw vegetables and so forth

957
00:39:37,050 --> 00:39:38,070
and jam them in our mouths.

958
00:39:38,070 --> 00:39:40,110
Maybe you do, I don't know, but,

959
00:39:40,110 --> 00:39:42,120
usually you go through
some refinement process.

960
00:39:42,120 --> 00:39:44,670
You cook it together in certain quantities

961
00:39:44,670 --> 00:39:47,820
to derive a data set or
derive essentially a meal.

962
00:39:47,820 --> 00:39:48,900
You goes through a refinement process.

963
00:39:48,900 --> 00:39:50,640
The same thing needs to be applied

964
00:39:50,640 --> 00:39:51,780
when you're building AI systems.

965
00:39:51,780 --> 00:39:53,610
You need to essentially refine the data,

966
00:39:53,610 --> 00:39:55,110
come up with curated data.

967
00:39:55,110 --> 00:39:57,600
So once you realize that this problem,

968
00:39:57,600 --> 00:40:00,150
where do you go to get derived data?

969
00:40:00,150 --> 00:40:02,370
Well, there's a place
where many businesses

970
00:40:02,370 --> 00:40:03,720
already create derived data sets

971
00:40:03,720 --> 00:40:05,280
and that's typically in the lake house

972
00:40:05,280 --> 00:40:08,010
or the data warehouse where
they're already taking

973
00:40:08,010 --> 00:40:09,840
a bunch of their operational data,

974
00:40:09,840 --> 00:40:13,290
they're sort of throwing it
left or right through ETL

975
00:40:13,290 --> 00:40:15,180
into the lake house or the warehouse.

976
00:40:15,180 --> 00:40:16,530
And then they might be going through like

977
00:40:16,530 --> 00:40:19,920
a medallion architecture
of bronze, silver, gold,

978
00:40:19,920 --> 00:40:21,960
and getting, defining a data product,

979
00:40:21,960 --> 00:40:23,190
and that data product's used

980
00:40:23,190 --> 00:40:24,870
to feed dashboards and so forth.

981
00:40:24,870 --> 00:40:27,630
They can reverse ETL that out
to some operational database,

982
00:40:27,630 --> 00:40:29,340
maybe throw MCP in front of that,

983
00:40:29,340 --> 00:40:31,650
and then have their Agent talk to it.

984
00:40:31,650 --> 00:40:34,980
So this solves the problem
of getting derived data,

985
00:40:34,980 --> 00:40:37,380
but it introduces a new problem.

986
00:40:37,380 --> 00:40:38,880
And the new problem is that

987
00:40:38,880 --> 00:40:41,790
this is just too slow for
most operational use cases.

988
00:40:41,790 --> 00:40:43,710
So it carries all of the same challenges

989
00:40:43,710 --> 00:40:45,390
that ETL carries with it,

990
00:40:45,390 --> 00:40:48,270
where you have different batch pipelines

991
00:40:48,270 --> 00:40:50,370
delivering data at different stages,

992
00:40:50,370 --> 00:40:52,830
you know, maybe it's 60
minutes, maybe it's once a day,

993
00:40:52,830 --> 00:40:55,080
and you're combining
that data in some fashion

994
00:40:55,080 --> 00:40:56,880
where it represents, essentially,

995
00:40:56,880 --> 00:40:59,970
your data's only gonna be as
good as the slowest pipeline.

996
00:40:59,970 --> 00:41:01,980
A lot of times that data is thrown raw,

997
00:41:01,980 --> 00:41:03,870
so into the lake house,

998
00:41:03,870 --> 00:41:05,670
and the data engineer
team has to figure out

999
00:41:05,670 --> 00:41:07,860
how to reverse engineer and
understand what the scheme is,

1000
00:41:07,860 --> 00:41:09,240
the lineage and so forth.

1001
00:41:09,240 --> 00:41:12,150
Ends up with a lot of
reprocessing, remodeling,

1002
00:41:12,150 --> 00:41:15,390
and a bunch of cascading downsides.

1003
00:41:15,390 --> 00:41:17,640
But, we've been using this to essentially

1004
00:41:17,640 --> 00:41:19,740
feed dashboards and reports.

1005
00:41:19,740 --> 00:41:21,180
But it's a challenge when it comes

1006
00:41:21,180 --> 00:41:23,730
to trying to feed AI systems,

1007
00:41:23,730 --> 00:41:25,410
especially in the operational use case.

1008
00:41:25,410 --> 00:41:27,390
I mentioned patient monitoring.

1009
00:41:27,390 --> 00:41:30,990
There's very unlikely that
you'd be able to build a system

1010
00:41:30,990 --> 00:41:32,340
that goes through this process

1011
00:41:32,340 --> 00:41:35,000
that can monitor patients
at sort of the level

1012
00:41:35,000 --> 00:41:36,845
or the latency that you'd really want

1013
00:41:36,845 --> 00:41:38,730
to be able to make accurate decisions.

1014
00:41:38,730 --> 00:41:41,580
Similarly, if we take like
an example from airlines.

1015
00:41:41,580 --> 00:41:44,250
If I'm interfacing with
a customer service bot

1016
00:41:44,250 --> 00:41:45,570
that's powered by an AI Agent,

1017
00:41:45,570 --> 00:41:47,340
and I wanna rebook my flight,

1018
00:41:47,340 --> 00:41:49,170
well that Agent needs to know

1019
00:41:49,170 --> 00:41:51,030
what flights are available right now.

1020
00:41:51,030 --> 00:41:53,790
And in the, essentially
the foreseeable future,

1021
00:41:53,790 --> 00:41:56,010
can't make decisions based on a report

1022
00:41:56,010 --> 00:41:57,450
that was generated a day ago.

1023
00:41:57,450 --> 00:42:00,120
It also needs to know my
itinerary, my customer preference,

1024
00:42:00,120 --> 00:42:02,070
my preferences, maybe my status.

1025
00:42:02,070 --> 00:42:04,650
All this stuff needs to
be as fresh as possible.

1026
00:42:04,650 --> 00:42:06,690
So how do we sort of marry these worlds

1027
00:42:06,690 --> 00:42:10,080
of having both fresh
data and derived data?

1028
00:42:10,080 --> 00:42:11,280
That's really the key problem.

1029
00:42:11,280 --> 00:42:13,140
So we need a derived data set

1030
00:42:13,140 --> 00:42:15,450
that represents the current
state of the business,

1031
00:42:15,450 --> 00:42:18,480
and we can do that using a
combination of technologies.

1032
00:42:18,480 --> 00:42:20,820
So streaming data capture is really good

1033
00:42:20,820 --> 00:42:24,300
at essentially capturing
data as it's generated,

1034
00:42:24,300 --> 00:42:27,840
realtime data using technology
and tools like Kafka.

1035
00:42:27,840 --> 00:42:31,260
We can use stream processing,
in particular Apache Flink,

1036
00:42:31,260 --> 00:42:35,793
which helps you essentially
bring both sort of,

1037
00:42:37,260 --> 00:42:40,467
data at rest or batch data
together with realtime data

1038
00:42:40,467 --> 00:42:43,170
and just essentially batch data is just

1039
00:42:43,170 --> 00:42:45,480
bounded streams versus unbounded streams.

1040
00:42:45,480 --> 00:42:47,760
So we can combine that data in the stream

1041
00:42:47,760 --> 00:42:49,140
to create these dry data sets

1042
00:42:49,140 --> 00:42:51,120
using stream processing technology,

1043
00:42:51,120 --> 00:42:53,040
and then we need some
way of serving that data.

1044
00:42:53,040 --> 00:42:54,900
And ideally we have
one layer of governance

1045
00:42:54,900 --> 00:42:56,430
across all of this.

1046
00:42:56,430 --> 00:42:58,650
So at Confluent we've been
working on this problem

1047
00:42:58,650 --> 00:43:00,930
for a number of years
and a couple years ago

1048
00:43:00,930 --> 00:43:02,880
we launched a product called Tableflow,

1049
00:43:02,880 --> 00:43:05,520
which doesn't quite address this problem

1050
00:43:05,520 --> 00:43:07,500
but kind of starts to address
some of the challenges.

1051
00:43:07,500 --> 00:43:09,870
So Tableflow was designed
to try to bridge the gap

1052
00:43:09,870 --> 00:43:13,290
between the operational estate
and the analytics estate,

1053
00:43:13,290 --> 00:43:16,050
where we can do streaming data capture,

1054
00:43:16,050 --> 00:43:18,630
we can use stream processing
to clean the data,

1055
00:43:18,630 --> 00:43:21,000
sort of as close to
the source as possible,

1056
00:43:21,000 --> 00:43:22,950
create these derived data products

1057
00:43:22,950 --> 00:43:27,210
and then materialize that
data as iceberg tables

1058
00:43:27,210 --> 00:43:32,160
or delta lake tables directly
into your analytics platform

1059
00:43:32,160 --> 00:43:35,250
and kind of taking out the ETL process.

1060
00:43:35,250 --> 00:43:37,500
And this is great for
sort of bridging the gap

1061
00:43:37,500 --> 00:43:39,480
and it can also work both ways, where,

1062
00:43:39,480 --> 00:43:41,540
as you create data in
the analytics estate,

1063
00:43:41,540 --> 00:43:43,380
it also writes back out to Kafka

1064
00:43:43,380 --> 00:43:46,110
so you can serve your
operational use case as well,

1065
00:43:46,110 --> 00:43:48,330
but still a column restore is probably not

1066
00:43:48,330 --> 00:43:51,300
the right sort of data
layer for context serving.

1067
00:43:51,300 --> 00:43:53,940
So, what we launched a couple months ago

1068
00:43:53,940 --> 00:43:56,130
is what we called a
Real-Time Context Engine.

1069
00:43:56,130 --> 00:43:58,920
Where, as Tableflow,
you're taking a Kafka topic

1070
00:43:58,920 --> 00:44:02,220
and materializing as an iceberg
table or delta lake table.

1071
00:44:02,220 --> 00:44:03,630
With the Real-Time Context Engine,

1072
00:44:03,630 --> 00:44:05,970
what you're doing is you're
taking your Kafka topic

1073
00:44:05,970 --> 00:44:07,590
or your derived data set

1074
00:44:07,590 --> 00:44:10,750
and you're materializing
it as a fully managed

1075
00:44:11,640 --> 00:44:14,820
materialized table that's
managed by Confluent Cloud

1076
00:44:14,820 --> 00:44:17,760
and then is served as a tool over MCP.

1077
00:44:17,760 --> 00:44:20,820
So that way from data creation to serving

1078
00:44:20,820 --> 00:44:22,680
is very, very low latency,

1079
00:44:22,680 --> 00:44:25,770
and it's designed essentially
for feeding these AI systems.

1080
00:44:25,770 --> 00:44:28,110
And the AI system doesn't need
to be running on Confluent,

1081
00:44:28,110 --> 00:44:30,510
it could be running wherever
you want externally,

1082
00:44:30,510 --> 00:44:31,650
and it doesn't need to know anything

1083
00:44:31,650 --> 00:44:34,620
about the streaming architecture,
it's just talking MCP.

1084
00:44:34,620 --> 00:44:36,270
And this is one of the core components

1085
00:44:36,270 --> 00:44:37,800
of something that we call
Confluent Intelligence,

1086
00:44:37,800 --> 00:44:39,570
which we launched recently as well.

1087
00:44:39,570 --> 00:44:41,160
And the other two core components of that

1088
00:44:41,160 --> 00:44:42,060
is streaming Agents,

1089
00:44:42,060 --> 00:44:45,750
which allows you to build
event-driven Agents that are,

1090
00:44:45,750 --> 00:44:46,860
these aren't chat-based Agents,

1091
00:44:46,860 --> 00:44:48,450
these are essentially
system-triggered Agents

1092
00:44:48,450 --> 00:44:50,670
that react to data as it's being

1093
00:44:50,670 --> 00:44:52,140
generated within the stream.

1094
00:44:52,140 --> 00:44:55,950
And then also built in ML
functions or statistical models

1095
00:44:55,950 --> 00:44:57,720
for doing things like anomaly detection,

1096
00:44:57,720 --> 00:45:00,033
forecasting and fraud detection.

1097
00:45:02,610 --> 00:45:05,250
And all of this runs on Confluence
data streaming platforms.

1098
00:45:05,250 --> 00:45:07,440
So you can do your streaming data capture,

1099
00:45:07,440 --> 00:45:09,030
you can define these data products,

1100
00:45:09,030 --> 00:45:13,410
then you can materialize those
into your analytics systems

1101
00:45:13,410 --> 00:45:16,170
as well as power these
different AI systems

1102
00:45:16,170 --> 00:45:18,520
or streaming Agents
running on Confluent Cloud.

1103
00:45:19,650 --> 00:45:22,920
All right, so let's get
into a couple demos.

1104
00:45:22,920 --> 00:45:25,500
So I'm gonna walk through
two different demos.

1105
00:45:25,500 --> 00:45:26,580
The first one's pretty simple.

1106
00:45:26,580 --> 00:45:28,133
What we're gonna do is just show off

1107
00:45:28,133 --> 00:45:30,720
sort of how som some of these,

1108
00:45:30,720 --> 00:45:32,970
this concept of the Real-Time
Context Engine works.

1109
00:45:32,970 --> 00:45:35,280
So I'm gonna take a couple
different Kafka topics,

1110
00:45:35,280 --> 00:45:37,020
I'm gonna materialize them as tables

1111
00:45:37,020 --> 00:45:38,490
and then we're gonna use Claude Code

1112
00:45:38,490 --> 00:45:39,810
to talk to the MTP server

1113
00:45:39,810 --> 00:45:41,130
and I'll kind of walk through that.

1114
00:45:41,130 --> 00:45:44,250
So what we have here is
we have a Kafka topic

1115
00:45:44,250 --> 00:45:45,573
that represents customers.

1116
00:45:46,440 --> 00:45:49,080
We have orders that are being
made by those customers,

1117
00:45:49,080 --> 00:45:50,790
and then we're creating,
we're using Flink,

1118
00:45:50,790 --> 00:45:54,060
to combine those into an
enriched orders Kafka topic

1119
00:45:54,060 --> 00:45:57,060
and then we're serving
those as Tools over MTP.

1120
00:45:57,060 --> 00:45:59,400
And then we're gonna
essentially use Claude Code

1121
00:45:59,400 --> 00:46:01,113
as our MTP client to talk to it.

1122
00:46:02,700 --> 00:46:06,090
All right, so here on the
left we have Claude Code

1123
00:46:06,090 --> 00:46:09,840
and then there on the right
we have Confluent Cloud,

1124
00:46:09,840 --> 00:46:10,800
and you can see on Confluent Cloud

1125
00:46:10,800 --> 00:46:12,705
we're just looking at the
customer's Kafka topic

1126
00:46:12,705 --> 00:46:15,270
in a particular event that was created.

1127
00:46:15,270 --> 00:46:17,220
So the first thing I'm
gonna do, I'm gonna say,

1128
00:46:17,220 --> 00:46:19,730
ask to show me the topics
that I have access to.

1129
00:46:19,730 --> 00:46:24,270
So Claude's going to essentially reach out

1130
00:46:24,270 --> 00:46:26,040
and there's three
different tools available

1131
00:46:26,040 --> 00:46:28,020
within our MTP server.

1132
00:46:28,020 --> 00:46:30,530
One allows you to pull back the tables,

1133
00:46:30,530 --> 00:46:32,640
or essentially the topics
that are being materialized.

1134
00:46:32,640 --> 00:46:34,980
Here we have customers, we have
orders and enriched orders.

1135
00:46:34,980 --> 00:46:37,950
All of these have descriptions
so that MCP clients

1136
00:46:37,950 --> 00:46:41,460
and Claude can understand
what these actually mean.

1137
00:46:41,460 --> 00:46:43,740
And then we can ask for
details, in this case,

1138
00:46:43,740 --> 00:46:44,700
about the customer.

1139
00:46:44,700 --> 00:46:47,790
So we have table lookup,

1140
00:46:47,790 --> 00:46:49,950
essentially metadata or schema lookup

1141
00:46:49,950 --> 00:46:51,210
for these various tables.

1142
00:46:51,210 --> 00:46:54,330
And then we also have
essentially point in time lookup

1143
00:46:54,330 --> 00:46:56,040
so we can look up this
customer information

1144
00:46:56,040 --> 00:46:58,080
of Joe in this case.

1145
00:46:58,080 --> 00:46:59,520
So, pretty simple,

1146
00:46:59,520 --> 00:47:02,550
and you can see that matches
the information on the right.

1147
00:47:02,550 --> 00:47:03,930
Not, you know, groundbreaking.

1148
00:47:03,930 --> 00:47:05,820
You could probably do the
same thing with the database.

1149
00:47:05,820 --> 00:47:08,790
But the key here is that,
as we generate new data,

1150
00:47:08,790 --> 00:47:10,320
essentially it's
immediately reflected here.

1151
00:47:10,320 --> 00:47:13,620
So we will fully manage this
as new data gets generated,

1152
00:47:13,620 --> 00:47:16,260
it will automatically get
upserted and reindexed.

1153
00:47:16,260 --> 00:47:18,840
Or if you need to change
essentially the data model,

1154
00:47:18,840 --> 00:47:22,443
you can handle those kind of
reprocessing steps of batch up,

1155
00:47:23,310 --> 00:47:25,650
essentially completely remodeling the data

1156
00:47:25,650 --> 00:47:27,900
into a way that's actually
gonna serve your use case.

1157
00:47:27,900 --> 00:47:29,430
So we cleared the context here.

1158
00:47:29,430 --> 00:47:32,880
So now we're gonna say, show
me the last order placed.

1159
00:47:32,880 --> 00:47:35,670
In this case, it's gonna make
two different Tool calls.

1160
00:47:35,670 --> 00:47:38,430
It's gonna ask first for
what tables are available

1161
00:47:38,430 --> 00:47:39,840
'cause it needs to know
what tables are there,

1162
00:47:39,840 --> 00:47:41,400
and then it's gonna do
the point in time lookup

1163
00:47:41,400 --> 00:47:44,673
to pull in the orders
placed by this customer.

1164
00:47:48,150 --> 00:47:50,640
All right, so the next
thing we're gonna do

1165
00:47:50,640 --> 00:47:52,860
is we're gonna go over to Confluent Cloud

1166
00:47:52,860 --> 00:47:57,210
and we're gonna generate
a new event to update

1167
00:47:57,210 --> 00:48:00,720
this customer's email to show
how sort of updates work.

1168
00:48:00,720 --> 00:48:01,920
So we're gonna produce a new message,

1169
00:48:01,920 --> 00:48:03,240
but what you can imagine here is,

1170
00:48:03,240 --> 00:48:06,450
if you had some customer
profile page on a website,

1171
00:48:06,450 --> 00:48:10,410
I could go into that page,
update my email, click save,

1172
00:48:10,410 --> 00:48:13,260
that's gonna write as some
event into a Kafka topic

1173
00:48:13,260 --> 00:48:15,071
that I probably then do a database update

1174
00:48:15,071 --> 00:48:16,560
at some point as well.

1175
00:48:16,560 --> 00:48:20,250
But as I essentially
send in that new message,

1176
00:48:20,250 --> 00:48:23,430
behind the scenes, we're taking that data,

1177
00:48:23,430 --> 00:48:26,040
we're gonna upsert it into
the materialized table,

1178
00:48:26,040 --> 00:48:27,960
reindex the table, update the index,

1179
00:48:27,960 --> 00:48:31,200
and then that's immediately
available through MTP

1180
00:48:31,200 --> 00:48:33,120
for the AI Agent to consume.

1181
00:48:33,120 --> 00:48:35,910
So we're producing that message now.

1182
00:48:35,910 --> 00:48:38,520
You can see that it's a new message there.

1183
00:48:38,520 --> 00:48:39,900
And then once we go back over here,

1184
00:48:39,900 --> 00:48:42,030
we're just gonna clear the context

1185
00:48:42,030 --> 00:48:45,090
and ask to show the customer record again,

1186
00:48:45,090 --> 00:48:46,490
the details of the customer.

1187
00:48:50,580 --> 00:48:53,250
So there's really from it,

1188
00:48:53,250 --> 00:48:56,340
because this is all built on
the data streaming platform too

1189
00:48:56,340 --> 00:48:59,520
and sort of Kafka as the
basis for that, and Flink,

1190
00:48:59,520 --> 00:49:00,510
these are really designed

1191
00:49:00,510 --> 00:49:05,010
for really extreme high load
and low latency use cases.

1192
00:49:05,010 --> 00:49:07,350
So it doesn't matter how
complicated your data is

1193
00:49:07,350 --> 00:49:08,940
or how fast things are updating,

1194
00:49:08,940 --> 00:49:11,730
essentially you could combine
that in whatever way you want,

1195
00:49:11,730 --> 00:49:13,707
mix it however you want to
create these dry data sets,

1196
00:49:13,707 --> 00:49:17,220
and it's gonna be instantly
available to your AI systems.

1197
00:49:17,220 --> 00:49:18,840
So there we see the new email

1198
00:49:18,840 --> 00:49:21,060
and then we can continue to
do this to show, you know,

1199
00:49:21,060 --> 00:49:24,153
the latest enriched sort of
view of this data and so forth.

1200
00:49:25,410 --> 00:49:27,060
All right, so let's go
to the next use case.

1201
00:49:27,060 --> 00:49:30,120
So the next one is an application

1202
00:49:30,120 --> 00:49:31,860
for Robotaxi Customer Service.

1203
00:49:31,860 --> 00:49:34,320
Actually, before we came up here to talk,

1204
00:49:34,320 --> 00:49:36,247
we were talking about Waymos and Zoox

1205
00:49:37,230 --> 00:49:38,610
and all the autonomous drivers.

1206
00:49:38,610 --> 00:49:40,110
Well this is the next iteration of this,

1207
00:49:40,110 --> 00:49:41,430
this is River Robotaxis.

1208
00:49:41,430 --> 00:49:43,950
So these are like Waymos,
but for riverboats.

1209
00:49:43,950 --> 00:49:46,530
So imagine you're on the
Mississippi in New Orleans,

1210
00:49:46,530 --> 00:49:49,080
you pull up your River Robotaxi app

1211
00:49:49,080 --> 00:49:50,850
and you book essentially a riverboat.

1212
00:49:50,850 --> 00:49:52,800
That riverboat comes and picks you up.

1213
00:49:52,800 --> 00:49:55,020
So we're not gonna talk
about the fleet management.

1214
00:49:55,020 --> 00:49:56,280
What we're gonna talk about

1215
00:49:56,280 --> 00:49:58,200
is the customer service part of this.

1216
00:49:58,200 --> 00:50:00,420
So with the River Robotaxi,

1217
00:50:00,420 --> 00:50:01,980
there's gonna be different
spikes that happen

1218
00:50:01,980 --> 00:50:03,060
in terms of ride requests

1219
00:50:03,060 --> 00:50:04,350
and they need to take certain actions.

1220
00:50:04,350 --> 00:50:05,370
Maybe they need to dispatch

1221
00:50:05,370 --> 00:50:07,110
new boats to the area and so forth.

1222
00:50:07,110 --> 00:50:11,340
So what the scenario here is,
is that I've ordered a boat,

1223
00:50:11,340 --> 00:50:15,150
but it's taking longer
than expected to arrive.

1224
00:50:15,150 --> 00:50:18,750
I'm sure anybody's ever ridden
in an Uber, an Uber minute.

1225
00:50:18,750 --> 00:50:21,420
You know, one Uber minute
is really like five minutes.

1226
00:50:21,420 --> 00:50:22,350
It's very frustrating.

1227
00:50:22,350 --> 00:50:26,040
But so with this, what I
can do is I can go into

1228
00:50:26,040 --> 00:50:28,290
the River Robotaxi mobile app,

1229
00:50:28,290 --> 00:50:29,700
start a chat with customer service,

1230
00:50:29,700 --> 00:50:31,830
which is powered by an AI Agent,

1231
00:50:31,830 --> 00:50:33,540
and I want to know where is my boat?

1232
00:50:33,540 --> 00:50:34,680
What is taking so long?

1233
00:50:34,680 --> 00:50:38,070
So for in order for it
to be able to understand

1234
00:50:38,070 --> 00:50:39,840
and correctly contextualize response,

1235
00:50:39,840 --> 00:50:42,210
it needs to understand the ride requests,

1236
00:50:42,210 --> 00:50:45,090
the volume requests, what
decisions have been made.

1237
00:50:45,090 --> 00:50:47,610
Vehicle location telemetry
that's kind of streaming off

1238
00:50:47,610 --> 00:50:52,050
of these different
riverboats, customer profiles,

1239
00:50:52,050 --> 00:50:54,240
all need to be taken into account.

1240
00:50:54,240 --> 00:50:55,710
And what we're gonna do is essentially

1241
00:50:55,710 --> 00:51:00,697
use the context engine to serve
this data to the AI Agent,

1242
00:51:01,830 --> 00:51:04,440
which in this case was
built using LangGraph,

1243
00:51:04,440 --> 00:51:07,203
running on NAWS and
using Claude as a model.

1244
00:51:08,370 --> 00:51:10,443
All right, so let's cue that demo.

1245
00:51:14,820 --> 00:51:16,620
Little magic happening
behind the scenes here.

1246
00:51:16,620 --> 00:51:17,453
All right, there.

1247
00:51:17,453 --> 00:51:19,710
So this is our various Kafka topics here.

1248
00:51:19,710 --> 00:51:22,620
We have different topics
that we want to essentially

1249
00:51:22,620 --> 00:51:24,330
materialize through the context engine.

1250
00:51:24,330 --> 00:51:27,000
So we have completed actions
which represent decisions made

1251
00:51:27,000 --> 00:51:29,670
by Robotaxi for dealing with spikes

1252
00:51:29,670 --> 00:51:31,440
in ride requests and so forth.

1253
00:51:31,440 --> 00:51:34,140
And we're just gonna enable
the context engine for these.

1254
00:51:34,140 --> 00:51:36,360
And we can do the same
thing for ride requests.

1255
00:51:36,360 --> 00:51:37,260
Once we've done this,

1256
00:51:37,260 --> 00:51:40,260
these are immediately available
as these materialized tables

1257
00:51:40,260 --> 00:51:42,030
that can be consumed by our MCP.

1258
00:51:42,030 --> 00:51:45,360
I go over the River Support
and I ask about my ride.

1259
00:51:45,360 --> 00:51:47,730
On the left you can see the sort of

1260
00:51:47,730 --> 00:51:49,830
chain of thought reasoning
that Claude's going through

1261
00:51:49,830 --> 00:51:52,260
to get essentially the customer profile,

1262
00:51:52,260 --> 00:51:54,690
and then also get the
decision that was made

1263
00:51:54,690 --> 00:51:58,650
about why that there's a
delay going on right now.

1264
00:51:58,650 --> 00:52:02,850
It uses that to contextualize
a response back to the user,

1265
00:52:02,850 --> 00:52:05,370
letting them know that
they're aware of a delay,

1266
00:52:05,370 --> 00:52:07,890
they dispatched new boats
to the area to deal with it

1267
00:52:07,890 --> 00:52:09,390
and to please be patient.

1268
00:52:09,390 --> 00:52:12,200
But the only way it's able
to make a decision like that

1269
00:52:12,200 --> 00:52:14,580
or essentially be able to
create a response like that,

1270
00:52:14,580 --> 00:52:17,340
is it needs access to
that fresh contextual data

1271
00:52:17,340 --> 00:52:19,110
to be able to do it.

1272
00:52:19,110 --> 00:52:19,950
And this is again,

1273
00:52:19,950 --> 00:52:23,310
true for most of these kind
of operational use cases.

1274
00:52:23,310 --> 00:52:25,650
Oops, all right, what I
just said. Next steps.

1275
00:52:25,650 --> 00:52:27,000
All right, let's talk next steps here

1276
00:52:27,000 --> 00:52:28,140
before we get into questions.

1277
00:52:28,140 --> 00:52:30,237
So if this is of interest to you

1278
00:52:30,237 --> 00:52:31,740
and you wanna play around
with some of this stuff

1279
00:52:31,740 --> 00:52:34,500
you could check out our
Streaming Agents product.

1280
00:52:34,500 --> 00:52:35,760
You can also do,

1281
00:52:35,760 --> 00:52:37,860
there's a workshop that's
going on with this.

1282
00:52:37,860 --> 00:52:41,160
There's a quick start you can also use

1283
00:52:41,160 --> 00:52:43,380
if you wanna sort of
do the self-guided tour

1284
00:52:43,380 --> 00:52:45,060
and you can try this all out for free.

1285
00:52:45,060 --> 00:52:47,610
Using Confluent Cloud you get
$400 worth of free credits

1286
00:52:47,610 --> 00:52:49,320
for the first 30 days.

1287
00:52:49,320 --> 00:52:51,933
I'll pause for a minute
as people take pictures.

1288
00:52:54,660 --> 00:52:57,660
And the last thing here is just this week

1289
00:52:57,660 --> 00:52:59,340
we launched Confluent Marketplace,

1290
00:52:59,340 --> 00:53:02,310
which is a marketplace
for seeing all of these

1291
00:53:02,310 --> 00:53:03,720
various community connectors

1292
00:53:03,720 --> 00:53:06,930
and a whole bunch of other
community driven projects

1293
00:53:06,930 --> 00:53:09,420
that you can use within Confluence
Data Streaming Platform.

1294
00:53:09,420 --> 00:53:12,300
This allows you to ingest data
from pretty much anywhere,

1295
00:53:12,300 --> 00:53:15,693
any kind of source system
within the enterprise.

1296
00:53:17,610 --> 00:53:18,633
Really cool project.

1297
00:53:20,910 --> 00:53:23,210
And you can try that all
out for free as well.

