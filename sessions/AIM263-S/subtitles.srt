1
00:00:00,570 --> 00:00:04,470
- All right, why are we talking today

2
00:00:04,470 --> 00:00:06,510
about voice?

3
00:00:06,510 --> 00:00:09,060
Voice is actually not yet out of fashion.

4
00:00:09,060 --> 00:00:10,110
Voice still exists

5
00:00:10,110 --> 00:00:13,200
and is very persistent
actually across different

6
00:00:13,200 --> 00:00:17,040
technologies from fixed to
mobile to voice assistance

7
00:00:17,040 --> 00:00:20,940
and actually now in AI-powered
voice communication.

8
00:00:20,940 --> 00:00:24,540
And what we are gonna do now
today is really talk about

9
00:00:24,540 --> 00:00:27,570
how AI-powered voice
communication has benefits

10
00:00:27,570 --> 00:00:32,040
to improve customer
experience, to reduce cost,

11
00:00:32,040 --> 00:00:35,340
and actually increase security
in financial services.

12
00:00:35,340 --> 00:00:38,790
I am here today actually with Chao

13
00:00:38,790 --> 00:00:41,100
and I let you present yourself Chao.

14
00:00:41,100 --> 00:00:43,200
- Sure. So my name is Chao.

15
00:00:43,200 --> 00:00:47,760
I'm a director of applied
science with Amazon.

16
00:00:47,760 --> 00:00:51,460
I've been with Amazon for
about 10 years, initially

17
00:00:52,470 --> 00:00:56,880
working in Alexa on the speech

18
00:00:56,880 --> 00:00:59,010
interactive experiences.

19
00:00:59,010 --> 00:01:03,810
And now I lead a team in
AGI foundations focusing on

20
00:01:03,810 --> 00:01:06,630
building the speech-to-speech
foundation model.

21
00:01:06,630 --> 00:01:10,800
So I hope you've all heard
about the announcement

22
00:01:10,800 --> 00:01:13,110
of Nova Sonic launch this morning

23
00:01:13,110 --> 00:01:17,640
and I'm really excited to
have this opportunity to talk

24
00:01:17,640 --> 00:01:19,140
to you about Sonic a little bit

25
00:01:19,140 --> 00:01:22,080
and also about the
collaboration with Vonage

26
00:01:22,080 --> 00:01:25,210
to use speech foundation models to build

27
00:01:26,250 --> 00:01:30,060
AI agents that can interact
with users as naturally

28
00:01:30,060 --> 00:01:33,270
and intelligently as human agents.

29
00:01:33,270 --> 00:01:35,100
- Thank you. And my name is Christophe.

30
00:01:35,100 --> 00:01:39,570
I'm a president of the
business unit API at Vonage.

31
00:01:39,570 --> 00:01:43,440
And we are a company responsible
for cloud communication,

32
00:01:43,440 --> 00:01:46,290
doing a communication
platform as a service

33
00:01:46,290 --> 00:01:49,860
and also network API, allowing
applications to communicate

34
00:01:49,860 --> 00:01:51,780
with users.

35
00:01:51,780 --> 00:01:55,710
Now, as I said, voice is very persistent

36
00:01:55,710 --> 00:02:00,540
and it has been so over time,
across multiple technologies.

37
00:02:00,540 --> 00:02:02,700
It started all with fixed voice.

38
00:02:02,700 --> 00:02:06,510
You could dial a human connecting
offices, connecting homes,

39
00:02:06,510 --> 00:02:10,290
then it was on the mobile
side, you could actually talk

40
00:02:10,290 --> 00:02:12,660
and communicate on the move.

41
00:02:12,660 --> 00:02:16,290
Then to voice assistance,
actually using your voice

42
00:02:16,290 --> 00:02:19,410
to do a command or ask for the weather

43
00:02:19,410 --> 00:02:21,660
or a certain command and a response.

44
00:02:21,660 --> 00:02:24,420
And then now AI-powered voice,

45
00:02:24,420 --> 00:02:28,050
where actually you can
have a real interaction

46
00:02:28,050 --> 00:02:31,140
with an agent, which is multi-turn

47
00:02:31,140 --> 00:02:36,030
and which also remembers basic
your previous interactions.

48
00:02:36,030 --> 00:02:38,610
And why is voice persistent?

49
00:02:38,610 --> 00:02:42,090
It's because it's fast,
it's faster than dialing;

50
00:02:42,090 --> 00:02:45,090
it's situational, wherever you are;

51
00:02:45,090 --> 00:02:49,230
and it also supports
actually context and nuance

52
00:02:49,230 --> 00:02:50,523
and personalization.

53
00:02:51,870 --> 00:02:53,790
What are the benefits that we are seeing

54
00:02:53,790 --> 00:02:55,830
of AI-powered voice?

55
00:02:55,830 --> 00:02:58,290
When we look at the finance sector,

56
00:02:58,290 --> 00:03:02,010
on one hand there is an
enhanced customer experience.

57
00:03:02,010 --> 00:03:06,510
So personalization actually
of that is possible.

58
00:03:06,510 --> 00:03:10,650
It remembers your past
interactions that you had.

59
00:03:10,650 --> 00:03:12,900
It's 24/7 available.

60
00:03:12,900 --> 00:03:16,920
You can always call an
an AI-powered agent.

61
00:03:16,920 --> 00:03:19,410
Voice agent is always there

62
00:03:19,410 --> 00:03:21,720
and it's emotionally intelligent now.

63
00:03:21,720 --> 00:03:25,620
So basically it can grasp
actually frustration

64
00:03:25,620 --> 00:03:30,000
and can show more empathy
or adapt a bit the pace

65
00:03:30,000 --> 00:03:31,950
and the reaction.

66
00:03:31,950 --> 00:03:36,060
Secondly, it results into efficiency.

67
00:03:36,060 --> 00:03:37,440
Which type of efficiencies?

68
00:03:37,440 --> 00:03:42,280
Well of course you can
automate repetitive tasks

69
00:03:43,140 --> 00:03:45,363
like your balance inquiry.

70
00:03:46,980 --> 00:03:50,130
It's scalable in a sense
that when you have peaks,

71
00:03:50,130 --> 00:03:52,320
for example on the tax returns,

72
00:03:52,320 --> 00:03:56,640
it can absorb that by your agents

73
00:03:56,640 --> 00:03:59,940
and of course cost saving from less agents

74
00:03:59,940 --> 00:04:01,380
in your call center.

75
00:04:01,380 --> 00:04:04,410
But also important for security reasons.

76
00:04:04,410 --> 00:04:05,640
Why for security?

77
00:04:05,640 --> 00:04:10,350
Well, with your voice
footprint is an ability

78
00:04:10,350 --> 00:04:14,820
to be authenticated or of
course when there is fraud,

79
00:04:14,820 --> 00:04:18,180
you can be called by a voice agent

80
00:04:18,180 --> 00:04:20,760
when there is a fraudulent
activity on your account.

81
00:04:20,760 --> 00:04:22,620
And this 24/7.

82
00:04:22,620 --> 00:04:24,840
So there is also a lot of security

83
00:04:24,840 --> 00:04:28,960
and compliance applications
that are applicable

84
00:04:29,910 --> 00:04:31,980
for AI-powered voice.

85
00:04:31,980 --> 00:04:34,020
And also towards the future,

86
00:04:34,020 --> 00:04:37,200
but Chao will get more
into detail on that.

87
00:04:37,200 --> 00:04:39,360
We will see there is an opportunity

88
00:04:39,360 --> 00:04:41,760
for much more proactivity

89
00:04:41,760 --> 00:04:46,260
and also integration with other
type of channels like text

90
00:04:46,260 --> 00:04:48,540
so that you have a unified
customer experience,

91
00:04:48,540 --> 00:04:50,793
not only purely voice.

92
00:04:52,050 --> 00:04:56,520
Now what are actually some of
the use cases that it enables?

93
00:04:56,520 --> 00:04:59,370
When you look at financial services,

94
00:04:59,370 --> 00:05:00,690
actually there is a multitude

95
00:05:00,690 --> 00:05:02,493
of use cases that are possible.

96
00:05:03,480 --> 00:05:05,070
When we look at the banking

97
00:05:05,070 --> 00:05:08,250
and financial services, there is actually

98
00:05:08,250 --> 00:05:10,050
really customer support.

99
00:05:10,050 --> 00:05:13,650
As I said, very basic routine

100
00:05:13,650 --> 00:05:16,800
balance inquiries can be done by agents,

101
00:05:16,800 --> 00:05:21,800
it actually can give
personalized recommendation.

102
00:05:23,160 --> 00:05:27,360
An agent can give you a
recommendation for investments

103
00:05:27,360 --> 00:05:29,370
but also fraud protection as I said,

104
00:05:29,370 --> 00:05:34,370
using actually your voice
footprint for authentication.

105
00:05:34,410 --> 00:05:38,703
It can call you when there
is fraudulent activity

106
00:05:38,703 --> 00:05:40,803
on your account that has been spotted.

107
00:05:41,730 --> 00:05:45,090
And it can also of course
for compliance reasons,

108
00:05:45,090 --> 00:05:48,510
record certain transactions
that you are having

109
00:05:48,510 --> 00:05:51,153
and know actually when to do that.

110
00:05:52,050 --> 00:05:55,860
For wealth and management and investment.

111
00:05:55,860 --> 00:05:59,070
Other use cases are, for
example, proactive recommendation

112
00:05:59,070 --> 00:06:04,070
for fund investments and
many other engagements.

113
00:06:05,460 --> 00:06:06,870
On the insurance side,

114
00:06:06,870 --> 00:06:10,290
we could imagine actually basic claims

115
00:06:10,290 --> 00:06:13,110
entering basic information
around the claim

116
00:06:13,110 --> 00:06:16,140
can be done through AI agents

117
00:06:16,140 --> 00:06:19,020
but also lead qualification.

118
00:06:19,020 --> 00:06:22,080
You can by asking simple
question it could do

119
00:06:22,080 --> 00:06:24,480
a prioritization of leads

120
00:06:24,480 --> 00:06:26,280
or an assessment, a risk assessment

121
00:06:26,280 --> 00:06:28,953
of a potential lead in insurance.

122
00:06:30,300 --> 00:06:32,460
So a lot of use cases that are possible.

123
00:06:32,460 --> 00:06:34,620
But then comes the question

124
00:06:34,620 --> 00:06:37,110
how do we do this technology wise?

125
00:06:37,110 --> 00:06:41,880
And that's why we are gonna
now give both a presentation

126
00:06:41,880 --> 00:06:45,840
on what is Amazon Nova Sonic.

127
00:06:45,840 --> 00:06:49,500
Enabling actually from a speech-to-speech

128
00:06:49,500 --> 00:06:51,120
modeling perspective

129
00:06:51,120 --> 00:06:54,090
and how the combination with
the voice infrastructure

130
00:06:54,090 --> 00:06:57,640
of Vonage can make it easy for developers

131
00:06:58,770 --> 00:07:02,100
and enterprises to build
agents in an easy way.

132
00:07:02,100 --> 00:07:03,390
So Chao, I'll let you...

133
00:07:03,390 --> 00:07:04,503
- Yeah, thank you.

134
00:07:06,090 --> 00:07:09,340
So okay, so

135
00:07:11,160 --> 00:07:14,403
I want to tell you a little
bit more about Nova Sonic.

136
00:07:15,270 --> 00:07:18,120
Nova Sonic is a speech-to-speech
foundation model

137
00:07:18,120 --> 00:07:22,110
for real time human-like
conversational AI.

138
00:07:22,110 --> 00:07:26,880
And maybe I can walk you
through this diagram first

139
00:07:26,880 --> 00:07:30,000
because that will give you an idea of why

140
00:07:30,000 --> 00:07:35,000
a speech-to-speech foundation
model is like the future.

141
00:07:35,070 --> 00:07:39,210
It revolutionizes how we
build these kind of agents.

142
00:07:39,210 --> 00:07:42,600
So the first thing when
you look at this picture is

143
00:07:42,600 --> 00:07:43,950
how simple it is

144
00:07:43,950 --> 00:07:46,800
because if you've worked with voice agents

145
00:07:46,800 --> 00:07:50,490
for a long time then you'll
probably be very familiar

146
00:07:50,490 --> 00:07:54,090
with the traditional cascade
kind of system architecture

147
00:07:54,090 --> 00:07:57,030
where you start with an ASR system

148
00:07:57,030 --> 00:07:59,280
that converts speech into text.

149
00:07:59,280 --> 00:08:01,680
Then you might have like an NRU system

150
00:08:01,680 --> 00:08:04,020
that derives meaning out of that text

151
00:08:04,020 --> 00:08:06,720
and you have some kind of
dialogue control that figures out

152
00:08:06,720 --> 00:08:09,420
how to sort of respond to the customer.

153
00:08:09,420 --> 00:08:11,250
And then you have a TTS system

154
00:08:11,250 --> 00:08:14,850
that turns the response text into speech

155
00:08:14,850 --> 00:08:19,380
with foundation model,
literally you just integrate

156
00:08:19,380 --> 00:08:22,920
with a bi-directional streaming interface

157
00:08:22,920 --> 00:08:26,130
and this interface handles everything.

158
00:08:26,130 --> 00:08:29,580
So you have speech coming in

159
00:08:29,580 --> 00:08:32,610
and then inside this model it's going

160
00:08:32,610 --> 00:08:35,490
to do streaming based processing.

161
00:08:35,490 --> 00:08:39,540
As soon as the speech
is received by the model

162
00:08:39,540 --> 00:08:40,980
and the inference engine,

163
00:08:40,980 --> 00:08:44,670
it's going to actually
generate live transcript

164
00:08:44,670 --> 00:08:49,670
out of the speech and it can also generate

165
00:08:50,130 --> 00:08:55,130
API tool calling kind
of commands if the input

166
00:08:55,230 --> 00:08:58,623
of requires that kind of handling.

167
00:09:00,750 --> 00:09:04,170
And then when the tool call
information comes back,

168
00:09:04,170 --> 00:09:06,690
the model can generate the response,

169
00:09:06,690 --> 00:09:09,720
incorporating the information
coming back from the tool,

170
00:09:09,720 --> 00:09:13,380
coming back from, you know,
the developer's design of

171
00:09:13,380 --> 00:09:15,480
what this agent is supposed to do.

172
00:09:15,480 --> 00:09:17,910
And then at that point of time it's going

173
00:09:17,910 --> 00:09:20,220
to generate agent speech.

174
00:09:20,220 --> 00:09:24,150
And the beauty of this
whole pipeline is that

175
00:09:24,150 --> 00:09:26,520
we actually have the transcript,

176
00:09:26,520 --> 00:09:29,940
which is the text representation
of what the user said

177
00:09:29,940 --> 00:09:33,877
as an intermediate output which
help grounding sort of like

178
00:09:36,360 --> 00:09:39,000
what the agent think the user is saying.

179
00:09:39,000 --> 00:09:42,210
So it brings transparency
about sort of like

180
00:09:42,210 --> 00:09:46,170
the agent's behavior in
terms of how to handle this.

181
00:09:46,170 --> 00:09:47,610
It also is able

182
00:09:47,610 --> 00:09:50,820
to generate the speech taking into account

183
00:09:50,820 --> 00:09:54,570
all the information that's
available to this large model

184
00:09:54,570 --> 00:09:56,940
that includes all the dialogue history

185
00:09:56,940 --> 00:10:00,000
as well as the input user speech

186
00:10:00,000 --> 00:10:03,360
so that the agent's speech
can be not only natural

187
00:10:03,360 --> 00:10:06,540
and expressive but also
it's paying attention to

188
00:10:06,540 --> 00:10:09,930
how the user is expressing
themselves in addition

189
00:10:09,930 --> 00:10:12,480
to the content of what they say.

190
00:10:12,480 --> 00:10:15,630
That way the agent's
behavior will be a lot more

191
00:10:15,630 --> 00:10:18,180
empathetic and human-like.

192
00:10:18,180 --> 00:10:22,563
So I just want to walk
through a little bit of this.

193
00:10:23,400 --> 00:10:27,610
So essentially with this
architecture you can do very

194
00:10:29,130 --> 00:10:33,030
fluid dialogue handling
and natural turn taking.

195
00:10:33,030 --> 00:10:35,970
By that what I mean is as soon as the user

196
00:10:35,970 --> 00:10:37,650
finishes speaking,

197
00:10:37,650 --> 00:10:40,867
the system is going to make
a determination to say,

198
00:10:40,867 --> 00:10:43,140
"Oh the customer finished speaking,"

199
00:10:43,140 --> 00:10:45,270
and it's going to start responding.

200
00:10:45,270 --> 00:10:49,380
But if the customer interrupts
the agent responses,

201
00:10:49,380 --> 00:10:51,930
it's going to stop almost immediately

202
00:10:51,930 --> 00:10:53,730
and to listen to the customer

203
00:10:53,730 --> 00:10:57,240
and then respond to what they said next.

204
00:10:57,240 --> 00:11:00,120
We also are very proud

205
00:11:00,120 --> 00:11:02,190
of our speech recognition performance.

206
00:11:02,190 --> 00:11:06,740
And you probably see in this
morning's keynote presentation

207
00:11:08,850 --> 00:11:11,730
that we achieve state
of the art accuracies

208
00:11:11,730 --> 00:11:13,650
speech recognition.

209
00:11:13,650 --> 00:11:18,480
And I mentioned that we support
adaptive speech responses,

210
00:11:18,480 --> 00:11:22,200
adaptive meaning it's adapting
to how user is speaking,

211
00:11:22,200 --> 00:11:24,183
not only just what they're speaking.

212
00:11:25,620 --> 00:11:29,190
And I mentioned that if we
have very expressive voices,

213
00:11:29,190 --> 00:11:33,540
I hope you'll show a demo
that demonstrates that

214
00:11:33,540 --> 00:11:36,510
and it's available in multiple languages.

215
00:11:36,510 --> 00:11:38,850
And because of this
very simple architecture

216
00:11:38,850 --> 00:11:41,280
of speech-to-speech, it naturally achieves

217
00:11:41,280 --> 00:11:43,143
very low latency in responding.

218
00:11:44,370 --> 00:11:45,203
All right.

219
00:11:46,320 --> 00:11:48,450
- And actually what we
are doing is combining

220
00:11:48,450 --> 00:11:53,450
the Amazon Nova Sonic technology
with the Vonage Voice API.

221
00:11:54,660 --> 00:11:59,660
So basically combining the
Amazon Nova Sonic AI capabilities

222
00:12:01,530 --> 00:12:04,770
and speech-to-speech models

223
00:12:04,770 --> 00:12:08,520
with the voice infrastructure of Vonage.

224
00:12:08,520 --> 00:12:12,960
So actually that it is very
easy to do inbound calls,

225
00:12:12,960 --> 00:12:16,500
outbound calling, it can be
done on multiple technologies.

226
00:12:16,500 --> 00:12:19,200
So it can be done on mobile apps, web apps

227
00:12:19,200 --> 00:12:23,280
or the very traditional PSTN calls.

228
00:12:23,280 --> 00:12:26,280
So it's really the combination of the two,

229
00:12:26,280 --> 00:12:29,940
the voice infrastructure
together with Nova Sonic.

230
00:12:29,940 --> 00:12:34,080
That makes it actually
easy for enterprises,

231
00:12:34,080 --> 00:12:37,110
for developers to build agents

232
00:12:37,110 --> 00:12:39,570
and that's what we really try
to do by that partnership.

233
00:12:39,570 --> 00:12:42,840
But that combination is to
make it easy for developers

234
00:12:42,840 --> 00:12:46,080
to build agents for the future.

235
00:12:46,080 --> 00:12:49,020
But of course we want to demo this.

236
00:12:49,020 --> 00:12:52,320
This is always better
than explaining slides

237
00:12:52,320 --> 00:12:54,030
and how it could work.

238
00:12:54,030 --> 00:12:58,651
So let's have a little sneak
peek on how that can work.

239
00:12:58,651 --> 00:13:01,140
(animation chiming)

240
00:13:01,140 --> 00:13:04,350
- [Agent] Hello, this is your
financial services assistant.

241
00:13:04,350 --> 00:13:06,487
For your security, please say the phrase,

242
00:13:06,487 --> 00:13:08,760
"My voice confirms my identity."

243
00:13:08,760 --> 00:13:10,623
- My voice confirms my identity.

244
00:13:12,450 --> 00:13:15,030
- [Agent] Authentication
is complete and secure.

245
00:13:15,030 --> 00:13:16,923
Hello, how can I assist you today?

246
00:13:18,240 --> 00:13:20,490
- What is my current
savings account balance?

247
00:13:22,230 --> 00:13:23,970
- [Agent] Let me retrieve
your current savings

248
00:13:23,970 --> 00:13:25,260
account balance for you.

249
00:13:25,260 --> 00:13:30,260
Your savings balance is $23,540.15.

250
00:13:31,110 --> 00:13:32,970
Let's switch to your investments.

251
00:13:32,970 --> 00:13:35,220
Your portfolio is doing
quite well this year

252
00:13:35,220 --> 00:13:39,707
with a total value of $512,040.75,

253
00:13:40,740 --> 00:13:44,073
which is up by 6.2% year to date.

254
00:13:44,975 --> 00:13:49,975
- Okay, let's schedule a call
with my financial advisor.

255
00:13:50,040 --> 00:13:51,340
Can you help me with that?

256
00:13:52,770 --> 00:13:54,570
- [Agent] Certainly I can
help you schedule a call

257
00:13:54,570 --> 00:13:56,130
with your financial advisor.

258
00:13:56,130 --> 00:13:58,530
Let me check the
availability for next week.

259
00:13:58,530 --> 00:14:01,410
It looks like your advisor
is available on Tuesday

260
00:14:01,410 --> 00:14:02,700
at 10:00 AM.

261
00:14:02,700 --> 00:14:03,900
Would that work for you?

262
00:14:05,280 --> 00:14:07,503
- Do you have any openings for Wednesday?

263
00:14:09,360 --> 00:14:11,730
- [Agent] Let me check the
availability for Wednesday.

264
00:14:11,730 --> 00:14:14,640
It appears that your advisor
is available on Wednesday

265
00:14:14,640 --> 00:14:15,990
at 2:00 PM.

266
00:14:15,990 --> 00:14:17,520
Would that time work for you?

267
00:14:17,520 --> 00:14:18,353
- That works.

268
00:14:21,240 --> 00:14:22,830
- [Agent] Great, I've scheduled a meeting

269
00:14:22,830 --> 00:14:26,490
with your financial advisor
for Wednesday at 2:00 PM.

270
00:14:26,490 --> 00:14:28,893
You will receive a
confirmation email shortly.

271
00:14:31,050 --> 00:14:33,210
- Alright, so that's how it works.

272
00:14:33,210 --> 00:14:34,080
Cool, huh?

273
00:14:34,080 --> 00:14:38,430
So now of course we explained a bit

274
00:14:38,430 --> 00:14:40,980
what we have now, but maybe you can,

275
00:14:40,980 --> 00:14:44,490
without divulging any secrets,

276
00:14:44,490 --> 00:14:46,170
tell us a bit what is next?

277
00:14:46,170 --> 00:14:47,003
What is our...

278
00:14:47,003 --> 00:14:48,120
- Yeah, yeah.

279
00:14:48,120 --> 00:14:49,500
Well actually it's easy for me

280
00:14:49,500 --> 00:14:53,520
because we just announced
Sonic, Nova 2 Sonic,

281
00:14:53,520 --> 00:14:55,590
which is the next generation of Sonic.

282
00:14:55,590 --> 00:14:57,300
And let me just give you a sneak peek

283
00:14:57,300 --> 00:15:00,510
of the new features that we launched.

284
00:15:00,510 --> 00:15:05,070
So Sonic, in version one
supports English, French,

285
00:15:05,070 --> 00:15:07,050
Italian, German, and Spanish.

286
00:15:07,050 --> 00:15:10,830
And with Sonic 2 we added new languages,

287
00:15:10,830 --> 00:15:12,840
Hindi and Portuguese.

288
00:15:12,840 --> 00:15:16,500
And we have an exciting
language roadmap in the pipeline

289
00:15:16,500 --> 00:15:19,803
that hopefully we will
share in coming quarters.

290
00:15:25,347 --> 00:15:26,380
We also added what we
call polyglot voices,

291
00:15:29,490 --> 00:15:32,970
which means the voice can
speak multiple languages

292
00:15:32,970 --> 00:15:36,810
even though the original voice
talent were only monolingual.

293
00:15:36,810 --> 00:15:40,050
And this way we can handle sessions

294
00:15:40,050 --> 00:15:43,350
with language switching very seamlessly.

295
00:15:43,350 --> 00:15:46,380
A user can literally
switch between, you know,

296
00:15:46,380 --> 00:15:48,360
let's say English and Spanish,

297
00:15:48,360 --> 00:15:51,210
depending on how they feel
comfortable almost naturally

298
00:15:51,210 --> 00:15:52,350
expressing themselves.

299
00:15:52,350 --> 00:15:55,290
And the same agent voice can respond

300
00:15:55,290 --> 00:15:58,263
in English or Spanish given that context.

301
00:16:00,300 --> 00:16:04,290
We also added a feature called
asynchronous tool calling.

302
00:16:04,290 --> 00:16:06,060
'Cause you know these models,

303
00:16:06,060 --> 00:16:08,460
they're very fast if you're
just doing chitchatting,

304
00:16:08,460 --> 00:16:11,670
but if sometimes you go
off to do a tool call,

305
00:16:11,670 --> 00:16:13,170
that can take a long time.

306
00:16:13,170 --> 00:16:15,540
And if you're just waiting
for the tool call to come back

307
00:16:15,540 --> 00:16:17,790
to continue the conversation,

308
00:16:17,790 --> 00:16:21,930
then you sometimes get stuck
in this very awkward silence

309
00:16:21,930 --> 00:16:24,240
with the user and
sometimes the user would be

310
00:16:24,240 --> 00:16:25,590
wondering like, what's going on

311
00:16:25,590 --> 00:16:27,240
'cause the system almost feels like

312
00:16:27,240 --> 00:16:29,700
it's kind of dead or broken.

313
00:16:29,700 --> 00:16:34,290
So we enabled this asynchronous
tool calling capability

314
00:16:34,290 --> 00:16:38,100
where the agent can basically
continue the conversation

315
00:16:38,100 --> 00:16:41,160
with the customer when
the tool call is being

316
00:16:41,160 --> 00:16:43,050
executed in the background.

317
00:16:43,050 --> 00:16:46,380
And when the tool call in, you
know, the results comes back,

318
00:16:46,380 --> 00:16:48,060
the agent is going to incorporate

319
00:16:48,060 --> 00:16:51,780
that information into the
dialogue to continue sort of

320
00:16:51,780 --> 00:16:55,563
the conversation with the
customer in a very natural way.

321
00:16:56,970 --> 00:16:58,830
Another feature we added is actually

322
00:16:58,830 --> 00:17:02,460
to add text into the speech input as well.

323
00:17:02,460 --> 00:17:06,210
So it's not just speech-to-speech,
it's actually speech

324
00:17:06,210 --> 00:17:09,330
and text to speech and text.

325
00:17:09,330 --> 00:17:12,510
That way, even though we say

326
00:17:12,510 --> 00:17:15,840
that these are voice
first kind of experiences,

327
00:17:15,840 --> 00:17:19,950
having text capabilities is
helpful for a lot of use cases.

328
00:17:19,950 --> 00:17:22,530
For example, if you want
the agent to say something

329
00:17:22,530 --> 00:17:24,930
before the customer say anything,

330
00:17:24,930 --> 00:17:28,140
then you can use the text
input from the developer side

331
00:17:28,140 --> 00:17:32,340
to prompt the model so that the model

332
00:17:32,340 --> 00:17:34,920
will start speaking without waiting

333
00:17:34,920 --> 00:17:37,320
for the user to have speech input.

334
00:17:37,320 --> 00:17:39,390
You can also use that capability

335
00:17:39,390 --> 00:17:42,330
to handle like touch pad kind of inputs

336
00:17:42,330 --> 00:17:45,510
so that these touch pads key presses

337
00:17:45,510 --> 00:17:49,410
can be converted into text
as input into the model.

338
00:17:49,410 --> 00:17:51,060
The benefit of this is all

339
00:17:51,060 --> 00:17:55,680
of these are seamlessly
incorporated into the model

340
00:17:55,680 --> 00:17:57,480
as if it's like just a same...

341
00:17:57,480 --> 00:18:00,930
Like there's never loss of
context or switch of context

342
00:18:00,930 --> 00:18:03,180
when you have different modality of input.

343
00:18:03,180 --> 00:18:06,570
It's all the same context information

344
00:18:06,570 --> 00:18:08,430
available to the model.

345
00:18:08,430 --> 00:18:13,280
One last feature that I want
to talk to you about is the...

346
00:18:14,460 --> 00:18:18,720
Oh, configurable turn taking behavior.

347
00:18:18,720 --> 00:18:21,840
So we all like these
agents to be like snappy,

348
00:18:21,840 --> 00:18:24,150
you talk and then the agents comes back.

349
00:18:24,150 --> 00:18:25,860
But there are actually scenarios

350
00:18:25,860 --> 00:18:28,050
where users prefer the agents

351
00:18:28,050 --> 00:18:29,820
to be a little bit more relaxed

352
00:18:29,820 --> 00:18:33,210
so they don't feel like they
have to talk in case they stop,

353
00:18:33,210 --> 00:18:35,100
then the agent will cut them off.

354
00:18:35,100 --> 00:18:39,930
So there is ability to configure
these kind of thresholds

355
00:18:39,930 --> 00:18:42,390
to be sensitivity low, medium, high,

356
00:18:42,390 --> 00:18:45,360
so that you can basically
trade off sort of

357
00:18:45,360 --> 00:18:48,510
some of these latencies for just a more

358
00:18:48,510 --> 00:18:51,360
relaxed kind of interaction vibe.

359
00:18:51,360 --> 00:18:54,480
So I think that's what I can share now.

360
00:18:54,480 --> 00:18:59,480
Hopefully, you know, if you
watch for our Nova pages

361
00:18:59,760 --> 00:19:04,760
then you'll see we always
update and launch new features

362
00:19:05,880 --> 00:19:08,700
over the course of the year.

363
00:19:08,700 --> 00:19:09,990
- Yeah, and if you wanna learn more...

364
00:19:09,990 --> 00:19:10,890
- Oh that's right.

365
00:19:10,890 --> 00:19:12,660
So I should mention this.

366
00:19:12,660 --> 00:19:15,360
So there are quite a few
sessions to talk about Sonic,

367
00:19:15,360 --> 00:19:18,120
if you want to learn
how to build with Sonic.

368
00:19:18,120 --> 00:19:20,580
There's a workshop, which is amazing.

369
00:19:20,580 --> 00:19:21,900
It's two hours long

370
00:19:21,900 --> 00:19:24,360
and it tells you everything about how

371
00:19:24,360 --> 00:19:26,493
to build these kind of agents.

372
00:19:27,450 --> 00:19:30,495
Unfortunately it's happening
right now, so you are not going

373
00:19:30,495 --> 00:19:32,070
to be able to catch it.

374
00:19:32,070 --> 00:19:34,440
But these sessions are
recorded so you should be able

375
00:19:34,440 --> 00:19:37,080
to look it up, searching for keywords

376
00:19:37,080 --> 00:19:42,080
or the session to watch
it at a later time.

377
00:19:42,570 --> 00:19:44,790
There's these chalk talks

378
00:19:44,790 --> 00:19:47,160
that are happening in
the next couple of days

379
00:19:47,160 --> 00:19:50,010
and also there's a breakout
session which goes into

380
00:19:50,010 --> 00:19:52,620
one hour long presentation about Sonic.

381
00:19:52,620 --> 00:19:55,440
I hope you'll be able to
catch that one tomorrow.

382
00:19:55,440 --> 00:19:59,070
- Yep, and you're always welcome
at the Vonage meeting room

383
00:19:59,070 --> 00:20:00,720
and we have also drinks

384
00:20:00,720 --> 00:20:03,570
and presentation later tonight at Paris.

385
00:20:03,570 --> 00:20:06,990
I think some leaflets will be
handed out right over there

386
00:20:06,990 --> 00:20:09,570
if you're interested
to come and learn more.

387
00:20:09,570 --> 00:20:11,040
So thank you all for your attention.

388
00:20:11,040 --> 00:20:11,873
- Thank you so much for attending.

389
00:20:11,873 --> 00:20:12,706
- Bye-bye.

