1
00:00:00,180 --> 00:00:01,320
- Good morning.
(audience applauding)

2
00:00:01,320 --> 00:00:02,940
Wow. Clapping, I love it.

3
00:00:02,940 --> 00:00:04,290
Can you guys all hear me out there?

4
00:00:04,290 --> 00:00:05,820
It sounds like it.

5
00:00:05,820 --> 00:00:07,380
I almost forgot I had a clicker

6
00:00:07,380 --> 00:00:09,180
put in my pocket on accident.

7
00:00:09,180 --> 00:00:12,783
So yeah, excited to be here
today and talk about GenAI.

8
00:00:13,650 --> 00:00:15,510
Just a little bit about me.

9
00:00:15,510 --> 00:00:18,330
I've been in this industry
for over 20 years.

10
00:00:18,330 --> 00:00:19,740
I guess I aged myself a little bit,

11
00:00:19,740 --> 00:00:22,200
back when we used to
have other words, right?

12
00:00:22,200 --> 00:00:25,050
We used to talk about NLP
more and now it's all GenAI,

13
00:00:25,050 --> 00:00:26,610
and everyone might remember

14
00:00:26,610 --> 00:00:28,950
image registration versus computer vision

15
00:00:28,950 --> 00:00:29,850
and all those good things.

16
00:00:29,850 --> 00:00:32,040
So I've been working on this a long time

17
00:00:32,040 --> 00:00:33,897
and helping companies develop that.

18
00:00:33,897 --> 00:00:37,350
And working with AWS,
we've won a lot of awards

19
00:00:37,350 --> 00:00:39,570
and been runners up in GenAI consulting

20
00:00:39,570 --> 00:00:42,480
for the last two years
in AI and other years.

21
00:00:42,480 --> 00:00:44,910
So Mission is really
here to help you guys.

22
00:00:44,910 --> 00:00:48,480
We built out over 175 projects
over the last two years.

23
00:00:48,480 --> 00:00:53,100
We're the first SI partner
to get access to Bedrock.

24
00:00:53,100 --> 00:00:55,650
So we've been building on
Bedrock for 2 1/2 years.

25
00:00:55,650 --> 00:00:57,690
So if you guys have questions,

26
00:00:57,690 --> 00:00:58,800
feel free to come and find us,

27
00:00:58,800 --> 00:01:01,530
our booth is right behind
this in the dev center,

28
00:01:01,530 --> 00:01:02,970
right behind it.

29
00:01:02,970 --> 00:01:04,350
So excited to talk to you guys

30
00:01:04,350 --> 00:01:06,390
and see, you know, whether we can continue

31
00:01:06,390 --> 00:01:07,940
the conversation we have today.

32
00:01:08,820 --> 00:01:10,953
How many of you guys saw this article?

33
00:01:11,940 --> 00:01:15,123
How many of you guys actually
read any of these articles?

34
00:01:16,050 --> 00:01:18,900
Oh, actually way better than usual.

35
00:01:18,900 --> 00:01:21,090
It's, you know, I love headlines nowadays.

36
00:01:21,090 --> 00:01:22,500
It's all a lot of click bait, right?

37
00:01:22,500 --> 00:01:24,870
Trying to get people
to come in and read it.

38
00:01:24,870 --> 00:01:26,730
But what did the article actually say?

39
00:01:26,730 --> 00:01:30,840
It did say yes, 95% did
not see measurable ROI.

40
00:01:30,840 --> 00:01:33,120
But what does measurable ROI mean, right?

41
00:01:33,120 --> 00:01:35,344
It doesn't mean they didn't see ROI,

42
00:01:35,344 --> 00:01:36,420
they just didn't see something

43
00:01:36,420 --> 00:01:38,940
that they felt really
had a big return, right?

44
00:01:38,940 --> 00:01:40,460
2x, 3x, or things like that.

45
00:01:40,460 --> 00:01:43,440
It might've only had like a 1.1x return,

46
00:01:43,440 --> 00:01:47,820
but they still, 40% of them
did put this into deployment,

47
00:01:47,820 --> 00:01:51,960
and so it still, even though
that article said only 5%,

48
00:01:51,960 --> 00:01:54,600
you still saw 40% put into deployment.

49
00:01:54,600 --> 00:01:58,200
And the number I really
like is that 67% of those

50
00:01:58,200 --> 00:01:59,970
were done by companies like Mission

51
00:01:59,970 --> 00:02:02,460
that were able to come in
and help companies build

52
00:02:02,460 --> 00:02:04,437
because we have that
expertise to help you.

53
00:02:04,437 --> 00:02:06,093
And the other thing it said,

54
00:02:06,960 --> 00:02:09,300
one of the issues people always had

55
00:02:09,300 --> 00:02:12,060
was they chose bad use cases, right?

56
00:02:12,060 --> 00:02:14,850
That is the one thing you
should always be looking at

57
00:02:14,850 --> 00:02:17,220
is what use case am I doing, right?

58
00:02:17,220 --> 00:02:19,740
AI isn't the problem most of the time,

59
00:02:19,740 --> 00:02:21,480
AI does what you tell it,

60
00:02:21,480 --> 00:02:24,840
but you are choosing a
bad problem to solve.

61
00:02:24,840 --> 00:02:27,780
You are looking at maybe
something that was,

62
00:02:27,780 --> 00:02:29,730
I'm gonna build images
in my marketing team

63
00:02:29,730 --> 00:02:30,563
or something like that,

64
00:02:30,563 --> 00:02:32,640
and then you're having a
hard time quantifying it,

65
00:02:32,640 --> 00:02:34,140
'cause hey, I'm only saving

66
00:02:34,140 --> 00:02:35,730
a little bit of money by doing that.

67
00:02:35,730 --> 00:02:38,100
And so you're not seeing that massive ROI.

68
00:02:38,100 --> 00:02:41,640
Now, people that were
looking at better use cases

69
00:02:41,640 --> 00:02:44,130
that were automating, you
know, run of the mill tasks

70
00:02:44,130 --> 00:02:45,600
that weren't that interesting,

71
00:02:45,600 --> 00:02:48,090
were able to see a lot more ROI.

72
00:02:48,090 --> 00:02:51,030
Also, you know, a lot
of internal experts are,

73
00:02:51,030 --> 00:02:52,350
you know, important to have.

74
00:02:52,350 --> 00:02:54,690
You need it, but it's
not insufficient, right?

75
00:02:54,690 --> 00:02:56,490
You need to also be working with people

76
00:02:56,490 --> 00:02:58,110
that understand the tech.

77
00:02:58,110 --> 00:03:01,200
and then I'm sure you guys
have seen it over and over,

78
00:03:01,200 --> 00:03:03,690
especially as you look at coding tools,

79
00:03:03,690 --> 00:03:05,880
that this is not just a technology change,

80
00:03:05,880 --> 00:03:07,380
it's a cultural change, right?

81
00:03:07,380 --> 00:03:09,960
How many of you guys have
started to look at like Kiro

82
00:03:09,960 --> 00:03:12,240
as a developing platform?

83
00:03:12,240 --> 00:03:13,110
A couple of people.

84
00:03:13,110 --> 00:03:17,010
And so Kiro is really pushing
on spec-driven coding, right?

85
00:03:17,010 --> 00:03:18,750
Most of the time when
you're looking at coding,

86
00:03:18,750 --> 00:03:20,550
people just kind of start

87
00:03:20,550 --> 00:03:22,380
and they start making their application,

88
00:03:22,380 --> 00:03:24,810
and they don't really think
out all the little steps.

89
00:03:24,810 --> 00:03:27,510
But now as you start
using these coding agents,

90
00:03:27,510 --> 00:03:29,910
you have to start thinking about
what are each of the steps?

91
00:03:29,910 --> 00:03:32,070
I need to start looking
at it really early.

92
00:03:32,070 --> 00:03:34,830
And so now your developers
need to start thinking

93
00:03:34,830 --> 00:03:36,270
more like product managers, right?

94
00:03:36,270 --> 00:03:38,580
So you're gonna see this
real cultural change

95
00:03:38,580 --> 00:03:40,860
that has to happen inside these systems.

96
00:03:40,860 --> 00:03:43,893
So it's really important
that people understand that.

97
00:03:45,570 --> 00:03:48,480
So little bit of a summary,

98
00:03:48,480 --> 00:03:50,100
we're gonna talk about who we are.

99
00:03:50,100 --> 00:03:51,750
Kind of mentioned it already.

100
00:03:51,750 --> 00:03:54,120
We do a lot of AWS stuff,

101
00:03:54,120 --> 00:03:57,030
tons of competencies in
all the different spaces.

102
00:03:57,030 --> 00:03:59,730
And so we are a one stop shop

103
00:03:59,730 --> 00:04:02,880
where we do cost ops and
resell, 24/7 support,

104
00:04:02,880 --> 00:04:04,470
and then professional services.

105
00:04:04,470 --> 00:04:06,240
So if you're looking for any of those,

106
00:04:06,240 --> 00:04:08,820
feel free to come and talk to us.

107
00:04:08,820 --> 00:04:12,060
And now I like to just talk
a little bit about GenAI.

108
00:04:12,060 --> 00:04:13,440
Who thinks GenAI's new?

109
00:04:13,440 --> 00:04:15,060
And obviously you can see my slide

110
00:04:15,060 --> 00:04:17,760
and know that I don't
think it's new, right?

111
00:04:17,760 --> 00:04:20,220
It really dates back to 1906.

112
00:04:20,220 --> 00:04:22,290
Who thought it went back
over a hundred years?

113
00:04:22,290 --> 00:04:23,123
Anybody?

114
00:04:24,360 --> 00:04:26,340
Nobody thought it went back.

115
00:04:26,340 --> 00:04:30,030
So that was probabilistic
text generation in 1906.

116
00:04:30,030 --> 00:04:30,990
Think about that.

117
00:04:30,990 --> 00:04:33,690
These are like handwritten algorithms

118
00:04:33,690 --> 00:04:36,750
to figure out what text should
come next in a sentence.

119
00:04:36,750 --> 00:04:39,840
Then you kinda had a lot of
early concepts in the 50s.

120
00:04:39,840 --> 00:04:41,340
There were a lot of rule-based systems.

121
00:04:41,340 --> 00:04:43,170
You started to see early neural nets.

122
00:04:43,170 --> 00:04:44,760
But then we had the AI winner, right?

123
00:04:44,760 --> 00:04:46,260
And then the 80s came,

124
00:04:46,260 --> 00:04:48,660
and now everyone had personal computers

125
00:04:48,660 --> 00:04:50,940
and you started to see
clusters in universities.

126
00:04:50,940 --> 00:04:54,060
So neural nets were pushed
further and further again, right?

127
00:04:54,060 --> 00:04:55,470
And then the early 2010s,

128
00:04:55,470 --> 00:04:57,840
this is when the research on GaN started.

129
00:04:57,840 --> 00:04:59,760
And a lot of it was really enabled

130
00:04:59,760 --> 00:05:01,590
because now I have the cloud, right?

131
00:05:01,590 --> 00:05:03,690
That's kind of when the cloud started,

132
00:05:03,690 --> 00:05:06,720
now I have infinite compute
and storage essentially, right?

133
00:05:06,720 --> 00:05:08,040
And so that's really where you started

134
00:05:08,040 --> 00:05:09,480
to see all of these things.

135
00:05:09,480 --> 00:05:11,820
And then, you know, in the 2020s,

136
00:05:11,820 --> 00:05:15,450
did anyone use GPT-1 or GPT-2 past myself?

137
00:05:15,450 --> 00:05:16,620
A couple of guys maybe. Yeah.

138
00:05:16,620 --> 00:05:20,160
So like in the early 2020s
we were doing GPT-1 stuff

139
00:05:20,160 --> 00:05:23,310
and then '22, GPT-2,
there were things done,

140
00:05:23,310 --> 00:05:26,073
and now everything is agents.

141
00:05:27,780 --> 00:05:30,060
Who looked at my pretty chart, right?

142
00:05:30,060 --> 00:05:33,420
I love using image generation. It's great.

143
00:05:33,420 --> 00:05:35,520
Does the timeline really work?

144
00:05:35,520 --> 00:05:38,370
Did anyone notice that great timeline?

145
00:05:38,370 --> 00:05:39,840
So I then prompt it better.

146
00:05:39,840 --> 00:05:41,910
I'm like, "I can prompt better."

147
00:05:41,910 --> 00:05:43,350
And I made it worse.

148
00:05:43,350 --> 00:05:45,090
How many of us love prompting?

149
00:05:45,090 --> 00:05:47,370
Anybody love prompting?

150
00:05:47,370 --> 00:05:49,470
But I really like a good timeline

151
00:05:49,470 --> 00:05:52,020
that has the 1500s
mixed in with the 1900s.

152
00:05:52,020 --> 00:05:55,383
It's a really powerful tool here.

153
00:05:56,880 --> 00:05:59,130
So I like to ask this question.

154
00:05:59,130 --> 00:06:02,310
What innovation happened in 2023

155
00:06:02,310 --> 00:06:04,230
that made everyone excited about GenAI?

156
00:06:04,230 --> 00:06:05,403
Anyone, shout it out.

157
00:06:06,450 --> 00:06:08,823
ChatGPT. What was ChatGPT?

158
00:06:09,840 --> 00:06:10,673
Anybody?

159
00:06:11,623 --> 00:06:14,820
Okay, ChatGPT was someone made a website.

160
00:06:14,820 --> 00:06:15,840
That's it, right?

161
00:06:15,840 --> 00:06:17,430
These models existed,

162
00:06:17,430 --> 00:06:19,830
they just were more accessed
by people like myself

163
00:06:19,830 --> 00:06:23,370
that's a data scientist that
would spin it up in SageMaker,

164
00:06:23,370 --> 00:06:25,680
you know, maybe you're using
Hugging Face at the time,

165
00:06:25,680 --> 00:06:28,800
but now you have a website
that fronts a model

166
00:06:28,800 --> 00:06:30,180
that you can now talk to.

167
00:06:30,180 --> 00:06:32,790
They made it intuitive,
right? It's cool, it works.

168
00:06:32,790 --> 00:06:34,230
And so, but that's the innovation

169
00:06:34,230 --> 00:06:35,580
when you really think about it

170
00:06:35,580 --> 00:06:38,520
is someone just made it
easier to access a model.

171
00:06:38,520 --> 00:06:40,980
That's it, that's the whole
craze that started is,

172
00:06:40,980 --> 00:06:43,710
it's now easy for anyone
to think about it,

173
00:06:43,710 --> 00:06:46,140
look at the ideas and understand

174
00:06:46,140 --> 00:06:47,540
where you can go from there.

175
00:06:48,540 --> 00:06:51,990
So for us, we have our own chat bot.

176
00:06:51,990 --> 00:06:53,487
Everyone probably has
a chat bot now, right?

177
00:06:53,487 --> 00:06:54,990
You can make them super easy.

178
00:06:54,990 --> 00:06:58,050
Bedrock even has OpenSearch
and you can create a chat bot,

179
00:06:58,050 --> 00:07:00,210
and you're gonna ask all
kinds of of fun questions

180
00:07:00,210 --> 00:07:01,710
to your chat bot.

181
00:07:01,710 --> 00:07:05,220
Like, I got a a little joke
going on with my own chat bot.

182
00:07:05,220 --> 00:07:07,260
But why is it a chat bot?

183
00:07:07,260 --> 00:07:08,880
It's really because that's the easiest way

184
00:07:08,880 --> 00:07:11,250
to do back and forth conversations, right?

185
00:07:11,250 --> 00:07:12,420
And you're really looking at

186
00:07:12,420 --> 00:07:14,610
how do I simplify the interactions?

187
00:07:14,610 --> 00:07:15,870
'Cause everyone is looking at

188
00:07:15,870 --> 00:07:18,960
I just wanna be able to talk
to it and get information out.

189
00:07:18,960 --> 00:07:21,720
Now, what we've noticed is that people now

190
00:07:21,720 --> 00:07:24,270
just confuse everything
with a chat bot, right?

191
00:07:24,270 --> 00:07:25,650
Because they wanna talk to things.

192
00:07:25,650 --> 00:07:28,740
They may want to have
traditional ML models.

193
00:07:28,740 --> 00:07:30,600
You still may wanna do clustering,

194
00:07:30,600 --> 00:07:33,930
or you wanna do some kind
of prescriptive analytics

195
00:07:33,930 --> 00:07:35,280
or things like that.

196
00:07:35,280 --> 00:07:37,417
But all that people wanna say is like,

197
00:07:37,417 --> 00:07:39,630
"I just wanna talk to my
data, or I wanna do this."

198
00:07:39,630 --> 00:07:42,270
And so everything gets
buried behind a chat bot.

199
00:07:42,270 --> 00:07:44,550
So even though someone's coming to you

200
00:07:44,550 --> 00:07:47,520
and they may be asking about GenAI,

201
00:07:47,520 --> 00:07:49,710
often it's just an interface, right?

202
00:07:49,710 --> 00:07:51,150
So to think about that,

203
00:07:51,150 --> 00:07:54,540
your chatbots, often just your
interface and now chatbots,

204
00:07:54,540 --> 00:07:57,210
you're gonna have kickstart,
you know, agentic workflows.

205
00:07:57,210 --> 00:08:00,600
And then the other thing we
see a lot of is just gen BI.

206
00:08:00,600 --> 00:08:02,790
How many of you guys have
used like QuickSight Q

207
00:08:02,790 --> 00:08:04,983
or Quick Suite, or any of those tools?

208
00:08:07,170 --> 00:08:08,610
Couple of people.

209
00:08:08,610 --> 00:08:10,110
So, you know, they're really nice,

210
00:08:10,110 --> 00:08:12,660
but like you said, they
do have limitations.

211
00:08:12,660 --> 00:08:15,480
And so people are using generative systems

212
00:08:15,480 --> 00:08:17,190
with cool React libraries

213
00:08:17,190 --> 00:08:19,410
to come and populate all of your graphs,

214
00:08:19,410 --> 00:08:23,010
and then you really get into
pushing an LLM to write code.

215
00:08:23,010 --> 00:08:24,540
So there's a lot of
really fun things there,

216
00:08:24,540 --> 00:08:27,180
but at the end of the day,
everyone is looking at

217
00:08:27,180 --> 00:08:28,770
how can I just talk to the system?

218
00:08:28,770 --> 00:08:31,653
So that's why chatbots have
become our main interface.

219
00:08:33,120 --> 00:08:34,923
So (indistinct) for a minute.

220
00:08:37,750 --> 00:08:39,870
I like images, as you guys can see, right?

221
00:08:39,870 --> 00:08:40,830
The good.

222
00:08:40,830 --> 00:08:45,150
I asked for an monkey astronaut
riding the bike on the moon.

223
00:08:45,150 --> 00:08:48,450
How did we do? We do good?

224
00:08:48,450 --> 00:08:50,010
Well, it did mostly good.

225
00:08:50,010 --> 00:08:51,720
There is a moon in the background

226
00:08:51,720 --> 00:08:53,730
if anyone didn't catch that bit.

227
00:08:53,730 --> 00:08:56,430
And early on, it was really
bad at letters, right?

228
00:08:56,430 --> 00:08:59,493
So it actually works pretty
well with letters and all that.

229
00:09:00,450 --> 00:09:02,250
And then we get into the bad.

230
00:09:02,250 --> 00:09:05,760
Anybody have a guess on what
I wanted the system to do?

231
00:09:05,760 --> 00:09:06,903
Any guesses?

232
00:09:08,018 --> 00:09:09,360
- [Audience Member] Tower Bridge?

233
00:09:09,360 --> 00:09:11,160
- Tower Bridge. Good guess, good guess.

234
00:09:11,160 --> 00:09:15,450
But I asked for an AWS
architecture diagram

235
00:09:15,450 --> 00:09:18,900
of Glue connected to Redshift
connected to QuickSight.

236
00:09:18,900 --> 00:09:20,880
How did we do? Anybody?

237
00:09:20,880 --> 00:09:23,520
Did we do good? Did we do bad?

238
00:09:23,520 --> 00:09:27,480
This woman is very smart, she
says we did good, and we did.

239
00:09:27,480 --> 00:09:31,080
I asked for things for
an architecture diagram,

240
00:09:31,080 --> 00:09:33,630
it's buildings, we made architecture,

241
00:09:33,630 --> 00:09:36,180
I said Glue, glued them together.

242
00:09:36,180 --> 00:09:38,820
How many people know what Redshift is?

243
00:09:38,820 --> 00:09:40,800
Sunset, right? Sunset.

244
00:09:40,800 --> 00:09:42,360
So it made a sunset.

245
00:09:42,360 --> 00:09:44,820
It did exactly what I asked it to do.

246
00:09:44,820 --> 00:09:47,880
It just didn't really
understand that I needed

247
00:09:47,880 --> 00:09:51,030
to have a diagram that
had boxes of SageMaker

248
00:09:51,030 --> 00:09:52,740
and things like that attached to it,

249
00:09:52,740 --> 00:09:54,480
but it did exactly what I wanted.

250
00:09:54,480 --> 00:09:56,683
And so that's one of the
bad parts about GenAI

251
00:09:56,683 --> 00:09:59,280
is it will always give you an answer.

252
00:09:59,280 --> 00:10:02,760
It's not necessarily the
answer you want or you need,

253
00:10:02,760 --> 00:10:04,110
but it will give you an answer.

254
00:10:04,110 --> 00:10:06,270
And so you as the individual

255
00:10:06,270 --> 00:10:08,040
have to be looking at the answers,

256
00:10:08,040 --> 00:10:11,163
and you have to come and
understand what am I trying to do?

257
00:10:12,240 --> 00:10:13,170
Now the ugly.

258
00:10:13,170 --> 00:10:15,060
We were doing an event in July,

259
00:10:15,060 --> 00:10:17,580
and we wanted Rudolph
the Red-Nosed Reindeer.

260
00:10:17,580 --> 00:10:20,220
Now, these are some older GenAI images,

261
00:10:20,220 --> 00:10:21,900
but I use them for an example

262
00:10:21,900 --> 00:10:22,980
because the new ones will create

263
00:10:22,980 --> 00:10:24,600
Rudolph the Red-Nosed Reindeer,

264
00:10:24,600 --> 00:10:26,700
but before, they wouldn't.

265
00:10:26,700 --> 00:10:28,530
And we went through a lot
of prompted iterations,

266
00:10:28,530 --> 00:10:30,090
there were like 30 pictures in the series,

267
00:10:30,090 --> 00:10:31,710
so I'll only show a few.

268
00:10:31,710 --> 00:10:34,110
And, you know, I was
like, give me a reindeer

269
00:10:34,110 --> 00:10:36,780
with a red nose, and nothing.

270
00:10:36,780 --> 00:10:39,180
Then I was like trying to go closer,

271
00:10:39,180 --> 00:10:43,200
and it was like, give me a
reindeer with a clown nose,

272
00:10:43,200 --> 00:10:45,570
and it gave me a balloon
with a clown balloon.

273
00:10:45,570 --> 00:10:48,150
So it just, it didn't really get it right.

274
00:10:48,150 --> 00:10:51,697
Now, I was giving this talk a
while back and someone goes,

275
00:10:51,697 --> 00:10:54,810
"Do you know what the biggest
problem is with your images?"

276
00:10:54,810 --> 00:10:56,520
And I said, "No."

277
00:10:56,520 --> 00:10:59,280
I'm sitting there thinking,
"Hey, I'm gonna win

278
00:10:59,280 --> 00:11:02,130
because it's not Rudolph the
Red-Nosed Reindeer," right?

279
00:11:02,130 --> 00:11:04,980
And so this guy's like, "Do
you know the real issue?"

280
00:11:04,980 --> 00:11:06,630
And I don't know how
many of you guys know,

281
00:11:06,630 --> 00:11:08,670
but this is a whitetail buck deer.

282
00:11:08,670 --> 00:11:10,170
It's not even a reindeer.

283
00:11:10,170 --> 00:11:13,800
So if you're asking questions to GenAI

284
00:11:13,800 --> 00:11:15,570
and you don't really know the answer

285
00:11:15,570 --> 00:11:18,720
or what you're expecting,
you can't even validate

286
00:11:18,720 --> 00:11:20,070
that it's giving you the right answer,

287
00:11:20,070 --> 00:11:21,697
because to me I was like,

288
00:11:21,697 --> 00:11:23,250
"Oh yeah, that looks like a reindeer.

289
00:11:23,250 --> 00:11:24,750
It just doesn't look like Rudolph."

290
00:11:24,750 --> 00:11:28,350
So it's really important as
you're building these systems

291
00:11:28,350 --> 00:11:30,960
that you can understand,
how do I validate it?

292
00:11:30,960 --> 00:11:34,320
How do I prove out that it is
giving me the answers I want?

293
00:11:34,320 --> 00:11:36,210
How am I going to write unit tests?

294
00:11:36,210 --> 00:11:39,030
How am I gonna make
cases that just validate

295
00:11:39,030 --> 00:11:40,710
that yes, the answer's coming out?

296
00:11:40,710 --> 00:11:43,620
Especially when you're gonna
deliver a system to people

297
00:11:43,620 --> 00:11:45,570
that may not know what
the answer should be,

298
00:11:45,570 --> 00:11:47,103
because it will hallucinate.

299
00:11:48,510 --> 00:11:52,050
How many of you guys get inundated
with all the news, right?

300
00:11:52,050 --> 00:11:52,963
Even last week was crazy, right,

301
00:11:52,963 --> 00:11:55,830
there were like 10 new announcements,

302
00:11:55,830 --> 00:11:58,260
everything's giving you whiplash.

303
00:11:58,260 --> 00:12:01,890
The advice we often give
to people is choose a model

304
00:12:01,890 --> 00:12:03,750
that works for your particular use case,

305
00:12:03,750 --> 00:12:06,090
and each use case may have
a slightly different model

306
00:12:06,090 --> 00:12:09,090
that you're using, but choose one family,

307
00:12:09,090 --> 00:12:10,620
and then you just keep using that family

308
00:12:10,620 --> 00:12:12,360
because you're gonna gain expertise.

309
00:12:12,360 --> 00:12:14,160
They're all like coding languages, right?

310
00:12:14,160 --> 00:12:15,870
You don't want your coders to be switching

311
00:12:15,870 --> 00:12:18,180
from Python to .NET to everything

312
00:12:18,180 --> 00:12:20,730
because they're just not gonna be as adept

313
00:12:20,730 --> 00:12:21,780
at getting the answers

314
00:12:21,780 --> 00:12:24,300
as if they just always are
working in the same family.

315
00:12:24,300 --> 00:12:26,880
And every model's always like
leapfrogging the next, right?

316
00:12:26,880 --> 00:12:29,490
So wait two weeks and whatever
your favorite model is

317
00:12:29,490 --> 00:12:31,800
is gonna be the top model
on the leaderboards.

318
00:12:31,800 --> 00:12:34,590
So you don't have to always
do that model hopping.

319
00:12:34,590 --> 00:12:38,010
The other thing that's always
kind of interesting to me

320
00:12:38,010 --> 00:12:40,470
is did you guys read any of the reports

321
00:12:40,470 --> 00:12:43,050
when OpenAI launched GPT-5?

322
00:12:43,050 --> 00:12:44,940
Anybody read the reports?

323
00:12:44,940 --> 00:12:49,890
So OpenAI said that GPT-5 hallucinates

324
00:12:49,890 --> 00:12:51,960
40% to 45% of the time.

325
00:12:51,960 --> 00:12:54,150
Anybody know that? Huge, right?

326
00:12:54,150 --> 00:12:56,760
Hallucinations are
astronomical in these systems.

327
00:12:56,760 --> 00:12:59,550
Now, if you connect GPT-5 to the internet,

328
00:12:59,550 --> 00:13:02,520
which is why OpenAI has GPT-5
connected to the internet,

329
00:13:02,520 --> 00:13:04,860
the hallucination rate drops to 6%.

330
00:13:04,860 --> 00:13:07,950
And so that's why if you're
building a model inside of AWS,

331
00:13:07,950 --> 00:13:10,740
you need to be either
attaching it to the internet

332
00:13:10,740 --> 00:13:13,080
or putting it with a RAG database

333
00:13:13,080 --> 00:13:15,720
so that you can push your
hallucinations down, right?

334
00:13:15,720 --> 00:13:17,250
If you're not doing that,

335
00:13:17,250 --> 00:13:20,700
you will be looking at the probability

336
00:13:20,700 --> 00:13:22,170
of a high hallucination rate

337
00:13:22,170 --> 00:13:23,880
depending on the questions you're asking.

338
00:13:23,880 --> 00:13:26,250
So it's really important
to think about that

339
00:13:26,250 --> 00:13:28,200
when you're building out these systems.

340
00:13:29,550 --> 00:13:30,383
GenAI agents.

341
00:13:30,383 --> 00:13:33,810
Is everyone tired of GenAI agents? No?

342
00:13:33,810 --> 00:13:36,183
Wow, I'm tired of GenAI agents.

343
00:13:37,110 --> 00:13:39,690
So agents are fun, right?

344
00:13:39,690 --> 00:13:41,460
It's gonna go do everything.

345
00:13:41,460 --> 00:13:45,210
I've got an agent there,
he's my group leader,

346
00:13:45,210 --> 00:13:48,270
he's got all my other sub-agents,
I'm gonna send them out,

347
00:13:48,270 --> 00:13:50,070
I'm gonna do all kinds of cool things.

348
00:13:50,070 --> 00:13:52,980
We're gonna have some
autonomous goal achievement

349
00:13:52,980 --> 00:13:54,180
and we're gonna decide

350
00:13:54,180 --> 00:13:57,390
how to answer all of our questions, right?

351
00:13:57,390 --> 00:14:00,030
Now, when you look at
agents, it's really important

352
00:14:00,030 --> 00:14:01,320
to understand your use case,

353
00:14:01,320 --> 00:14:04,290
because I feel especially, you know,

354
00:14:04,290 --> 00:14:06,720
most engineers I talk to
have just gotten lazy.

355
00:14:06,720 --> 00:14:08,327
They're like drawing a diagram

356
00:14:08,327 --> 00:14:10,770
that's just like agent to do this,

357
00:14:10,770 --> 00:14:13,230
an agent to do that, an
agent to do this, right?

358
00:14:13,230 --> 00:14:15,090
They're not even really
putting in the thought,

359
00:14:15,090 --> 00:14:17,520
like what does each of those agents do?

360
00:14:17,520 --> 00:14:20,640
Is it actually an agent or is it a prompt?

361
00:14:20,640 --> 00:14:22,170
On my team, there's a lot of people

362
00:14:22,170 --> 00:14:24,240
and we have conversations all the time,

363
00:14:24,240 --> 00:14:25,830
is that a prompt or is it an agent?

364
00:14:25,830 --> 00:14:27,270
And there's a lot of things

365
00:14:27,270 --> 00:14:28,290
between the two of those, right?

366
00:14:28,290 --> 00:14:31,320
Like if I go to an agent, I
have to build the framework,

367
00:14:31,320 --> 00:14:33,120
although there's AgentCore, right, now

368
00:14:33,120 --> 00:14:35,100
to do the framework to make it easier.

369
00:14:35,100 --> 00:14:38,220
But you still have, when
you're doing agents,

370
00:14:38,220 --> 00:14:39,600
delays in your time.

371
00:14:39,600 --> 00:14:42,480
So if you have time-critical matters,

372
00:14:42,480 --> 00:14:44,130
often you're going to wanna just run

373
00:14:44,130 --> 00:14:45,840
with prompts versus agents

374
00:14:45,840 --> 00:14:48,060
because you're gonna get
the answer back faster

375
00:14:48,060 --> 00:14:49,110
through just a prompt.

376
00:14:49,110 --> 00:14:51,540
And most of the time you can prompt

377
00:14:51,540 --> 00:14:54,180
most of the things you're trying
to do that an agent can do.

378
00:14:54,180 --> 00:14:56,970
And so that's things to look
at, is what's my use case?

379
00:14:56,970 --> 00:14:58,320
Do I really need an agent?

380
00:14:58,320 --> 00:15:01,140
Agents are also potentially
gonna be more expensive,

381
00:15:01,140 --> 00:15:02,100
and they take longer.

382
00:15:02,100 --> 00:15:04,590
So you really have to think
about what's my system?

383
00:15:04,590 --> 00:15:07,653
Am I really doing something
that's an agent or not an agent?

384
00:15:09,390 --> 00:15:12,390
So we've done a lot of
use cases, as I mentioned,

385
00:15:12,390 --> 00:15:14,280
tons and tons of cool stuff.

386
00:15:14,280 --> 00:15:16,710
I won't get to talk
about too many of these,

387
00:15:16,710 --> 00:15:18,630
but we've done everything.

388
00:15:18,630 --> 00:15:20,820
I haven't seen anything
new in at least six months,

389
00:15:20,820 --> 00:15:23,490
so if you guys have use
cases, wanna ask about,

390
00:15:23,490 --> 00:15:25,050
hey, would this be possible?

391
00:15:25,050 --> 00:15:26,700
Can we do that or not?

392
00:15:26,700 --> 00:15:29,610
We're here, like I said,
back over that way,

393
00:15:29,610 --> 00:15:32,340
right on this side of
the CrowdStrike booth.

394
00:15:32,340 --> 00:15:34,950
The biggest use cases we
see in the market right now

395
00:15:34,950 --> 00:15:36,330
are IDP, right?

396
00:15:36,330 --> 00:15:39,060
About 60% of the market's doing IDP stuff.

397
00:15:39,060 --> 00:15:40,500
Really cool space.

398
00:15:40,500 --> 00:15:42,900
Then you've got chatbots, as
I mentioned, doing chatbots,

399
00:15:42,900 --> 00:15:44,430
but then there's everything else, right?

400
00:15:44,430 --> 00:15:47,610
Code generation,
recruiting, drug discovery,

401
00:15:47,610 --> 00:15:49,800
there's cool things you
can do with chatbots

402
00:15:49,800 --> 00:15:52,110
where you can do training,
educational training,

403
00:15:52,110 --> 00:15:54,060
or other training of your employees.

404
00:15:54,060 --> 00:15:55,950
And if they're going the wrong route,

405
00:15:55,950 --> 00:15:59,790
you can iteratively change
how the chatbot responds.

406
00:15:59,790 --> 00:16:02,310
So we had that built in where
we were working with a company

407
00:16:02,310 --> 00:16:04,770
that does medical
training for new doctors,

408
00:16:04,770 --> 00:16:07,380
and if the doctor was
going down a wrong path

409
00:16:07,380 --> 00:16:11,160
of questioning, the agent
would then get agitated.

410
00:16:11,160 --> 00:16:13,170
Well, the patient would then get agitated

411
00:16:13,170 --> 00:16:15,540
and start being like, "Hey,
you've asked me that already."

412
00:16:15,540 --> 00:16:16,470
And stuff like that, right?

413
00:16:16,470 --> 00:16:18,540
So there's really cool things you can do.

414
00:16:18,540 --> 00:16:21,633
Dubbing and translation's been
big, all kinds of cool stuff.

415
00:16:22,830 --> 00:16:25,890
And then like I mentioned,
chatbots is that interface.

416
00:16:25,890 --> 00:16:28,590
If you really want to learn about chatbots

417
00:16:28,590 --> 00:16:30,420
or have us build you a chatbot,

418
00:16:30,420 --> 00:16:34,260
we have a lot of really cool
fast track packages out there

419
00:16:34,260 --> 00:16:36,060
that we can help you guys build these.

420
00:16:36,060 --> 00:16:38,580
These are things we've
done day in and day out.

421
00:16:38,580 --> 00:16:39,723
They're really cool.

422
00:16:40,740 --> 00:16:42,360
Quick Suite, QuickSight, you know,

423
00:16:42,360 --> 00:16:44,670
that's something you guys
will see a lot of this week.

424
00:16:44,670 --> 00:16:47,400
Something to look at and talk about.

425
00:16:47,400 --> 00:16:50,700
So I'll just skip
through IDP for a second.

426
00:16:50,700 --> 00:16:53,670
So this was a really fun use case for IDP.

427
00:16:53,670 --> 00:16:55,980
We were working with an insurance company,

428
00:16:55,980 --> 00:16:57,570
and they're underwriters,

429
00:16:57,570 --> 00:16:59,850
so they get applications all the time.

430
00:16:59,850 --> 00:17:03,750
And the underwriters
spending four to five hours

431
00:17:03,750 --> 00:17:04,680
on the system.

432
00:17:04,680 --> 00:17:08,580
And so this company, it gets
10 to 15,000 applications,

433
00:17:08,580 --> 00:17:09,413
and they were growing,

434
00:17:09,413 --> 00:17:11,550
they just got bought by a
bigger insurance company,

435
00:17:11,550 --> 00:17:13,650
and so they can't hire fast enough, right?

436
00:17:13,650 --> 00:17:16,290
So that's one of those use
cases where you look at

437
00:17:16,290 --> 00:17:18,930
how much just manual work is there,

438
00:17:18,930 --> 00:17:21,270
how are you going to solve that problem?

439
00:17:21,270 --> 00:17:23,880
And if it's most of the time
I hire and train somebody,

440
00:17:23,880 --> 00:17:25,440
then you can probably automate it, right?

441
00:17:25,440 --> 00:17:28,170
So that's the system to look
at, I'm gonna automate this.

442
00:17:28,170 --> 00:17:31,230
And then you can build
out IDP really cool.

443
00:17:31,230 --> 00:17:33,840
And then you can put
everything into a database,

444
00:17:33,840 --> 00:17:35,640
and you can ask questions to it, right?

445
00:17:35,640 --> 00:17:37,890
So now the underwriter will get results,

446
00:17:37,890 --> 00:17:38,970
and then if he asks questions

447
00:17:38,970 --> 00:17:40,250
where he wants a further answer,

448
00:17:40,250 --> 00:17:43,320
he can then ask about the
application to do his work.

449
00:17:43,320 --> 00:17:46,740
And so it was really neat, we
were able to take their time

450
00:17:46,740 --> 00:17:49,260
from, you know, four to five
hours down to two hours,

451
00:17:49,260 --> 00:17:50,760
saving them 50%.

452
00:17:50,760 --> 00:17:52,560
And so there's massive things.

453
00:17:52,560 --> 00:17:54,330
This was just the first phase, right?

454
00:17:54,330 --> 00:17:57,180
We're looking at how can we
help continue to improve this

455
00:17:57,180 --> 00:17:58,230
to get it down even further?

456
00:17:58,230 --> 00:18:00,540
So there are tons of savings out there

457
00:18:00,540 --> 00:18:02,523
when you look at these chat bots.

458
00:18:03,570 --> 00:18:06,750
So another, retrieval
augmented generation,

459
00:18:06,750 --> 00:18:10,260
I'm sure everyone knows
retrieval augmented generation.

460
00:18:10,260 --> 00:18:12,390
Here's a pretty standard
architecture, right?

461
00:18:12,390 --> 00:18:16,230
Some kind of interface connected
to an LLM connected to,

462
00:18:16,230 --> 00:18:18,833
you know, your agents at the
end of the day and all that.

463
00:18:19,860 --> 00:18:21,780
And so we were working with a company,

464
00:18:21,780 --> 00:18:23,940
and this is where we get into all of that,

465
00:18:23,940 --> 00:18:25,110
like timing bits, right?

466
00:18:25,110 --> 00:18:27,000
So this is the IVR system.

467
00:18:27,000 --> 00:18:30,660
So now you have to think
about somebody's on the phone,

468
00:18:30,660 --> 00:18:32,730
they're calling and they're talking

469
00:18:32,730 --> 00:18:34,440
to a, you know, your bot.

470
00:18:34,440 --> 00:18:36,270
And so it has to be fast.

471
00:18:36,270 --> 00:18:38,670
So I don't know if you
guys have used Nova,

472
00:18:38,670 --> 00:18:40,800
but Nova Micro is actually pretty awesome

473
00:18:40,800 --> 00:18:42,930
where you can sort through really quickly

474
00:18:42,930 --> 00:18:46,350
with Nova Micro on the inference
side, get to an answer,

475
00:18:46,350 --> 00:18:48,630
and see what's going on there.

476
00:18:48,630 --> 00:18:50,340
And this was kind of the architecture

477
00:18:50,340 --> 00:18:52,350
for kind of an IVR system.

478
00:18:52,350 --> 00:18:55,050
Has Connect, which we all love Connect,

479
00:18:55,050 --> 00:18:58,050
Lex, Polly, to do the text to voice.

480
00:18:58,050 --> 00:19:00,600
So a lot of really cool things going on.

481
00:19:00,600 --> 00:19:02,880
Now, I have way too many slides,

482
00:19:02,880 --> 00:19:04,920
but we do lots of cool stuff.

483
00:19:04,920 --> 00:19:06,780
We could have talked about
agents and cool things.

484
00:19:06,780 --> 00:19:08,820
So on agents, I'm giving a talk

485
00:19:08,820 --> 00:19:12,630
with AWS in like two weeks about agents.

486
00:19:12,630 --> 00:19:14,610
So, you know, anyone that was here,

487
00:19:14,610 --> 00:19:16,500
just look for a talk about agents.

488
00:19:16,500 --> 00:19:18,270
It's a pretty cool use case.

489
00:19:18,270 --> 00:19:21,213
Lots of fun architecture at the end.

490
00:19:22,256 --> 00:19:26,190
AgentCore, and I have way
too many slides, sorry.

491
00:19:26,190 --> 00:19:27,810
But if you wanna work together,

492
00:19:27,810 --> 00:19:30,210
you can find us in the booth in the back.

493
00:19:30,210 --> 00:19:32,700
I put out a newsletter every week.

494
00:19:32,700 --> 00:19:34,890
I think we talk about fun, cool stuff.

495
00:19:34,890 --> 00:19:38,130
So if anyone wants to
hear my random thoughts,

496
00:19:38,130 --> 00:19:39,843
this is how you can hear it.

497
00:19:40,860 --> 00:19:43,080
Appreciate you guys all attending today.

498
00:19:43,080 --> 00:19:46,020
And they're gonna give me
the hook in 19 seconds.

499
00:19:46,020 --> 00:19:49,470
So if anyone has a question,
you know, like I said,

500
00:19:49,470 --> 00:19:52,920
I'll be over at our booth
for the next 30 ish minutes

501
00:19:52,920 --> 00:19:55,620
and happy to talk through
anything you guys want.

502
00:19:55,620 --> 00:19:56,823
But thank you, everyone.

503
00:19:58,100 --> 00:19:59,684
(audience applauding)

