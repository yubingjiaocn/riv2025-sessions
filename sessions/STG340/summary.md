# AWS re:Invent 2025 - 使用 AWS DataSync 进行大规模数据迁移

## 会议概述

本次会议深入探讨了 AWS DataSync 服务在大规模数据迁移场景中的应用。演讲者包括 AWS 市场专家 Tulagal、DataSync 首席产品经理 Jeff Bartley，以及 Path AI 工程副总裁 Aditya Dud。

会议重点介绍了企业在云迁移过程中面临的数据传输挑战，特别是当需要处理 PB 级数据和数十亿文件时。传统的 DIY 工具和开源解决方案在处理大规模数据时往往会遇到数据验证、错误恢复、安全性和性能等方面的问题。AWS DataSync 作为一个完全托管的在线数据传输服务，提供了快速、安全、可靠的解决方案，支持从本地、其他云平台到 AWS 的文件和对象数据迁移。

Path AI 的实际案例展示了如何利用 DataSync 将病理学实验室的数字化玻片图像（每张超过 1GB）从本地环境无缝传输到云端，实现了从传统手工流程到现代化 AI 辅助诊断的转型。通过部署 DataSync 代理，Path AI 成功地在美国、欧洲和南美的多个实验室建立了标准化的数据管道，每天处理 PB 级的医学影像数据。

## 详细时间线

### 开场与背景介绍
[00:00 - 02:30] - 会议开场，介绍演讲嘉宾和议程安排

[02:30 - 05:00] - 阐述企业数据挑战：企业每天创建 EB 级数据，平均使用超过 500 个应用系统，数据分布在多云环境中

[05:00 - 07:00] - 讨论数据治理、安全性和可靠性的重要性，强调零数据丢失的必要性

[07:00 - 09:00] - 说明企业数据分布的复杂性：跨区域、边缘位置、多个本地数据中心和多云环境

### AWS DataSync 服务介绍
[09:00 - 11:30] - 介绍传统数据迁移方法的局限性，包括 DIY 工具和开源解决方案的挑战

[11:30 - 14:00] - 正式介绍 AWS DataSync：在线数据传输服务，支持从本地、其他云和 AWS 之间移动文件和对象数据

[14:00 - 16:00] - DataSync 核心特性：快速易用、内置高级过滤、灵活调度、精确带宽控制、加密传输、自定义网络协议

[16:00 - 18:00] - DataSync 的深度 AWS 生态系统集成优势

### DataSync 使用场景
[18:00 - 20:00] - 四大主要使用场景：迁移、复制、归档和业务工作流加速

[20:00 - 22:00] - 迁移场景：快速将文件和对象数据迁移到 AWS

[22:00 - 23:30] - 复制场景：为灾难恢复创建数据副本

[23:30 - 25:00] - 归档场景：将冷数据移至 S3 Glacier，释放本地存储空间

[25:00 - 27:00] - 工作流加速：生命科学行业使用基因测序仪等设备产生的数据传输到云端进行处理

### 数据移动场景
[27:00 - 30:00] - 三种数据移动场景：本地到 AWS、跨云到 AWS、AWS 内部存储服务之间

[30:00 - 32:00] - 本地到 AWS：支持 NFS、SMB、对象存储和 Hadoop，目标为 S3、FSx 或 EFS

[32:00 - 34:00] - 跨云传输：支持 Google Cloud Storage、Azure Blob 等，使用安全协议

[34:00 - 36:00] - AWS 内部传输：跨账户、跨区域，通过 AWS 骨干网络传输

### GenAI 应用场景
[36:00 - 39:00] - DataSync 在 GenAI 中的新兴应用：将 PB 级数据传输到 FSx for Lustre 或 S3，用于构建训练模型和数据湖

[39:00 - 41:00] - 客户使用案例：在 S3 存储桶之间移动训练数据以优化 GPU 性能

### 最新功能发布
[41:00 - 44:00] - DataSync 增强模式：支持无限数量文件传输，增强的指标和报告功能

[44:00 - 46:00] - 大文件传输优化：将大文件分块并行传输，显著提高传输速度

[46:00 - 48:00] - 简化跨云传输：无需基础设施管理，无需在其他云部署代理

### Path AI 客户案例
[48:00 - 50:00] - Path AI 公司介绍：使用 AI 驱动的病理学改善患者治疗结果

[50:00 - 52:30] - 病理学工作流程：从活检到玻片制作，传统流程 100 多年未变

[52:30 - 55:00] - 数字化挑战：病理学是最后数字化的影像模式，实验室仍使用手工流程

[55:00 - 57:30] - 数字化优势：远程审查、AI 辅助诊断、数据驱动的工作流程

[57:30 - 60:00] - 数据规模：每张数字化玻片超过 1GB，需要管理 PB 级数据

[60:00 - 62:30] - AISight 平台：基于 AWS 构建，使用 DataSync 自动化工具将图像推送到云端

[62:30 - 65:00] - 实验室瓶颈：TB/PB 级影像数据、严格防火墙、IT 团队负担重、网络配置各异

[65:00 - 67:30] - 多实验室挑战：跨州、跨国的多个实验室需要标准化解决方案

[67:30 - 70:00] - DataSync 架构：代理运行在本地虚拟机管理程序上，将数据推送到实验室的 S3 存储桶

[70:00 - 73:00] - 详细架构说明：本地扫描仪 → 本地存储 → DataSync 代理 → 实验室 AWS S3 → Path AI AWS 环境

[73:00 - 75:00] - 元数据集成：通过 AISight Link 中间件使用 HL7 消息获取患者元数据

[75:00 - 77:00] - 运营影响：在美国、欧洲和南美上线实验室，定期移动 PB 级数据，简化 IT 运营

### DataSync 技术深度解析
[77:00 - 80:00] - Jeff Bartley 开始技术深度讲解，使用迁移场景作为示例

[80:00 - 82:00] - 示例配置：从本地 NFS 服务器迁移到 US West 2 的 S3 存储桶，使用 Direct Connect（2 x 10 Gbps）

[82:00 - 84:00] - 三个主要讨论领域：DataSync 代理、运行测试、性能优化

### DataSync 代理详解
[84:00 - 87:00] - 代理定义：部署在 AWS 外部的虚拟机，用于访问外部存储

[87:00 - 89:00] - 支持的虚拟机管理程序：VMware、KVM、Hyper-V、Nutanix，也可作为 EC2 实例部署

[89:00 - 91:00] - 代理优势：压缩传输中的数据，优化网络利用率

[91:00 - 94:00] - EC2 vs 本地部署决策：EC2 部署简单但需考虑延迟，NFS/SMB 协议对延迟敏感

[94:00 - 97:00] - 本地部署优势：使用自定义协议、压缩、加密、并行流、网络容错

[97:00 - 100:00] - 端点类型：公共端点（通过互联网）和私有端点（通过 Direct Connect 或 VPN）

[100:00 - 103:00] - 私有端点通信路径：控制流量通过 VPC 端点，数据路径通过 ENI 直接连接

[103:00 - 105:00] - 网络注意事项：确保子网有足够的 IP 地址空间，每个任务创建多个 ENI

### 运行测试
[105:00 - 108:00] - 测试重要性：验证性能、存储连接、网络连接和防火墙设置

[108:00 - 110:00] - 数据集特征：跨多年分布、旧数据只读、大小文件混合

[110:00 - 113:00] - 过滤功能：包含过滤器、排除过滤器、清单文件

[113:00 - 115:00] - 测试设置：使用包含过滤器仅复制 2025 年 1 月文件夹

[115:00 - 117:00] - 任务创建：源位置（NFS）、目标位置（S3）、任务选项配置

[117:00 - 120:00] - 测试结果：传输 550GB 数据用时 17 分钟，吞吐量约 550 MB/s

[120:00 - 122:00] - 性能差距：目标 20 Gbps（2400 MB/s），实际仅达到 550 MB/s

[122:00 - 124:00] - 瓶颈识别：代理与路由器之间网络限制，单代理最多 5 Gbps

### 性能优化
[124:00 - 127:00] - 迁移模式：初始传输 → 增量传输 → 切换

[127:00 - 130:00] - DataSync 迁移能力：复制文件数据和元数据、过滤器、带宽最大化

[130:00 - 132:00] - 增量传输功能：内置调度、详细日志和审计报告

[132:00 - 135:00] - 扩展策略：按文件夹分区数据集，并行运行多个任务和代理

[135:00 - 137:00] - 参考资源：解决方案架构师博客文章（提供 QR 码）

[137:00 - 140:00] - 扩展实施：按年份分区（2022-2025），部署 4 个代理

[140:00 - 142:00] - 创建 4 个任务：每个任务使用包含过滤器指向各年份的 2 月文件夹

[142:00 - 145:00] - 并行测试结果：4 个任务同时运行，每个达到约 520 MB/s

[145:00 - 147:00] - 聚合性能：总吞吐量超过 2000 MB/s，成功利用网络带宽

[147:00 - 结束] - 总结和资源分享