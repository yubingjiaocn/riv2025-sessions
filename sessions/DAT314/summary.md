# AWS re:Invent 2025 DAT314 会议总结

## 会议概述

本次会议（DAT314）由AWS首席数据库专家Shyon Sal主讲，深入探讨了如何使用Amazon ElastiCache和Aurora PostgreSQL构建无服务器聊天机器人系统。会议以虚构的旅游平台Flightly为案例，展示了从基础聊天机器人到智能代理AI系统的完整演进过程。

Flightly最初面临严重的性能瓶颈问题——平均响应时间达30秒，导致约50%的用户流失。通过行业数据分析，每秒延迟会造成7%的转化率损失，这使得Flightly每天损失约15万美元，年损失高达5000万美元。问题的根源不在于数据库本身，而在于访问模式。Aurora PostgreSQL作为真实数据源表现稳定，但在处理每天百万级请求时，每次查询都触发数据库访问、向量距离计算和LLM调用，导致延迟累积。

解决方案的核心是引入ElastiCache作为速度层，配合Aurora PostgreSQL的智能层（通过pgvector扩展实现语义搜索）。这种架构不仅将响应时间降至亚毫秒级别，还通过语义缓存实现了90%以上的缓存命中率。会议还展示了如何使用Strand Agents框架和Model Context Protocol (MCP)构建生产级的多代理AI系统，实现从简单问答到自主执行任务的跨越。

## 详细时间线

### 开场与问题陈述 (0:00 - 5:30)
- **0:00** - 会议开始，Shyon Sal介绍自己是AWS首席数据库专家，会议主题为DAT314：使用ElastiCache和Aurora PostgreSQL构建无服务器聊天机器人
- **1:15** - 现场调查：大多数观众在生产环境使用Aurora，但无人使用Aurora PostgreSQL构建聊天机器人
- **1:45** - 介绍案例研究对象：Flightly，一个虚构的旅游平台，提供航班搜索、酒店预订和假期规划服务
- **2:30** - 演示问题场景：用户查询夏威夷旅行，系统持续"思考中"，用户转而查看邮件，发现竞争对手Island Air的促销活动并完成预订，Flightly失去客户

### 业务影响分析 (5:30 - 8:00)
- **5:45** - 量化性能问题的业务成本：平均响应时间30秒，50%用户遇到性能瓶颈，平均订单价值300美元，每天处理100万请求
- **6:20** - 行业数据显示每秒延迟导致7%转化率损失，计算结果：每天损失15万美元，年损失5000万美元
- **7:00** - 分析问题根源：Flightly构建MVP时未预见规模问题，用户从数千增长到数百万后出现新的瓶颈

### 当前架构分析 (8:00 - 12:30)
- **8:30** - 介绍Flightly的数据资产：客户数据（历史预订、搜索历史、偏好）和公司数据（航班库存、酒店库存、促销信息），全部存储在Aurora PostgreSQL中
- **9:15** - 解释当前架构流程：用户查询→Aurora知识库查询→提取相关上下文→组装系统提示词→发送至LLM→生成响应
- **10:00** - 展示扩展问题：多用户并发时，每个查询触发相同的昂贵流程（数据库查询、距离计算、上下文获取、系统提示词组装、LLM调用），每个操作增加约100毫秒延迟
- **11:00** - 强调问题本质：不是数据库故障，而是访问模式问题

### 缓存的必要性 (12:30 - 16:00)
- **12:45** - 解释为什么缓存对会话AI至关重要：常见问题（如行李政策）可在1毫秒内从缓存返回，而数据库查询需要50毫秒（即使使用SSD）
- **13:30** - 分析协议开销：每个数据库连接需要TCP握手、TLS协商、跨可用区往返，每次迭代增加约5毫秒
- **14:15** - API经济学：重复查询（如"显示飞往夏威夷的航班"）每天被问数千次，每个未缓存请求消耗推理成本（嵌入生成、LLM调用）
- **15:00** - 语义搜索成本：余弦距离计算跨越1024、1536或3072维向量，涉及数百万向量，缓存top-K结果可完全跳过这些浮点运算

### ElastiCache服务介绍 (16:00 - 19:00)
- **16:15** - 介绍Amazon ElastiCache：完全托管的缓存服务，兼容Redis OSS、Memcached和Valkey
- **17:00** - 架构说明：应用通过单一DNS端点连接，后端是托管代理集群，处理连接复用、一致性哈希、异步复制和亚毫秒级故障转移
- **17:45** - 宣布新功能：re:Invent前一周推出ElastiCache向量搜索和持久语义缓存，实现90%以上缓存命中率
- **18:30** - 强调弹性和可扩展性：每个分片跨可用区维护读副本，自动故障转移，根据流量自动扩展（如春假期间流量可能是2月基线的15倍）

### 语义搜索原理 (19:00 - 24:00)
- **19:30** - 解释用户查询特点：用户不会问"SELECT  FROM destinations WHERE activities LIKE beach"，而是问"哪里可以冲浪和派对？"
- *20:00** - 语义搜索工作流程：领域知识（旅游指南、酒店描述、签证政策）→分块→通过嵌入模型转换为多维向量
- **21:00** - 向量示例：迈阿密的嵌入表示"原始海滩+世界级俱乐部"，巴厘岛表示"热带冲浪海滩+健康水疗"，两者都包含海滩元素但主题不同
- **22:00** - 介绍pgvector：PostgreSQL扩展，用于存储和查询向量嵌入，现场调查显示多数观众了解pgvector
- **23:00** - 查询过程：用户查询"哪里可以冲浪和派对"→转换为1024维向量→对Aurora执行语义搜索→返回top匹配（迈阿密和巴厘岛）按相似度评分排序
- **23:45** - 补充说明：虽然重点是语义搜索，但传统关键词全文搜索也很重要，实践中常结合两者（混合搜索），推荐参加明天的DAT409会议

### Aurora PostgreSQL服务介绍 (24:00 - 27:00)
- **24:15** - AWS提供多个支持原生向量搜索的托管数据库：RDS for PostgreSQL、Aurora PostgreSQL、DocumentDB、OpenSearch等
- **25:00** - Flightly选择Aurora PostgreSQL的原因：数据已存储在那里，是简单的选择
- **25:30** - Aurora Serverless架构：解耦计算和存储层，通过Aurora容量单位(ACU)控制扩展，Aurora IO优化配置处理IO密集型向量搜索和常规事务（预订、支付）而无性能下降
- **26:15** - 数据局部性优势：向量嵌入与事务数据（预订、客户档案）存储在同一PostgreSQL表中，无需外部数据库、ETL管道或迁移风险
- **26:45** - 全球覆盖：全球数据库跨区域复制，复制延迟低于1秒，东京用户从亚太副本获取服务，伦敦用户从欧盟副本获取服务

### 集成架构演进 (27:00 - 38:00)
- **27:30** - 完整架构概述：ElastiCache提供亚毫秒级缓存性能，Aurora通过pgvector提供持久语义智能层
- **28:00** - 步骤1：简单问答 - 用户查询"能预订从拉斯维加斯到夏威夷的航班吗？"直接路由到Bedrock，无预处理，LLM仅使用预训练知识返回通用响应
- **29:30** - 步骤2：添加对话历史 - LLM本质上是无状态的，不维护会话状态，使用ElastiCache存储对话历史，后续查询（如"那里的酒店怎么样？"）可获取先前上下文
- **31:00** - 步骤3：添加个性化 - ElastiCache扩展角色，缓存用户档案数据（家庭组成：两个孩子4岁和8岁、活动偏好：户外冒险、预算限制：最高300美元），使用HGETALL检索完整偏好哈希并注入提示词
- **33:00** - 步骤4：上下文智能（RAG） - 用户查询"下个月最便宜的航班选项"，应用生成嵌入→对Aurora执行语义搜索→检索匹配的最便宜选项→按日期范围过滤→结合实时定价
- **35:00** - 总结四步构建：记忆（对话历史）、个性化（用户偏好）、上下文智能（领域知识），但仍处于聊天机器人阶段

### 代理AI转型 (38:00 - 48:00)
- **38:30** - 提出问题：如何超越简单问答？从提供信息到采取行动（预订航班和酒店）
- **39:00** - AI演进历程：两年前的GenAI聊天机器人（单轮、基于规则、持续人工监督）→GenAI代理（目标驱动、规划推理、使用工具但单一领域）→代理AI（多代理系统，专业代理协调，最少监督）
- **40:30** - 代理架构流程：用户查询→代理并行从Valkey检索缓存上下文（HGETALL获取用户档案、LRANGE获取对话历史、GET获取会话状态）→同时对Aurora执行语义搜索→组装完整用户上下文
- **42:00** - 引入Model Context Protocol (MCP)：为LLM与各种服务（API、数据库）通信提供标准化接口，代理可调用外部API（天气预报、旅行建议、FAA法规）
- **43:30** - 介绍Strand Agents：开源SDK，用于构建AI代理，轻量级、模型无关、原生支持Bedrock，也集成OpenAI、Anthropic、Ollama等，处理多代理编排，提供原生MCP工具支持（超过85个工具）

### 代码实现 (48:00 - 58:00)
- **48:15** - 构建代理的基本步骤：导入核心原语→配置LLM（使用Bedrock上的Claude Sonnet 4）→创建代理（一行代码）
- **49:30** - 定义系统提示词：设置代理个性（Flightly旅行助手，专注航班预订和旅行行程，提供清晰、简洁、专业的响应）
- **50:45** - 添加工具能力：最快方式是通过Aurora PostgreSQL MCP服务器，使用标准连接参数（主机名、数据库凭证），无需自定义工具实现或手写SQL包装器
- **52:00** - MCP工具发现：Strand提供list_tools_sync API自动发现工具，Aurora PostgreSQL MCP服务器公开两个工具：get_table_schema（模式发现）和run_query（运行SQL查询）
- **53:00** - 性能优势：数据库调用约两位数毫秒，持久MCP连接消除重连开销（TCP握手、TLS协商）
- **54:00** - 添加外部API：使用MCP工具装饰器定义天气API函数，将外部API作为MCP工具公开给代理
- **55:30** - 生产挑战：每天百万查询，许多语义相似（"夏威夷天气"、"夏威夷天气预报"、"檀香山温度"），每次触发API调用（昂贵、缓慢、不必要）
- **56:30** - 自定义工具解决方案：工具装饰器提供完整执行逻辑控制，search_flights函数首先检查Valkey缓存→如果存在则亚毫秒返回→如果不存在则查询Aurora（首次惩罚）→缓存后续结果到Valkey

### 可复用架构模式 (58:00 - 70:00)
- **58:30** - 模式1：上下文缓存 - 用户查询"那里的酒店怎么样？"→Valkey检索完整上下文（对话历史、会话状态、用户偏好）→同时Aurora执行语义搜索→生成上下文感知响应，适用于客户服务、虚拟助手、医疗聊天机器人等需要对话连续性的系统
- **60:00** - 模式2：嵌入缓存 - 通过缓存向量嵌入加速语义搜索，用户搜索"京都标志性寺庙"、"东京最佳美食"等重复问题，首次遭遇走数据库（嵌入管道约200毫秒），后续检索通过缓存层
- **62:00** - 模式3：持久语义缓存 - 用户以不同方式表达相同意图（"夏威夷最佳海滩目的地"、"推荐夏威夷海滩度假村"），定义相似度阈值，超过阈值的相似问题分组，缓存相似度和LLM响应，跳过整个生成流程，零LLM成本、零延迟、亚毫秒性能
- **64:00** - 推荐周一的DAT451深度会议，详细讲解语义缓存
- **65:00** - 对比展示：启用语义缓存（绿色）从Valky获得即时响应，保持用户参与，按时完成预订；未启用（红色）每次触发完整LLM推理，用户注意到延迟并中途放弃
- **66:00** - 模式4：分层内存管理 - 用户说"预订家庭航班。避开那家航空公司"，代理将消息传递给Valkey作为短期内存（聊天消息、会话状态、工作流检查点），Lambda异步提取短期内存片段推送到Aurora作为长期存储
- **67:30** - 长期存储优势：使用pgvector进行情节回忆，每次过去历史以session_id和memory_id存储，可重建整个对话，持久化用户偏好（如"此用户偏好过道座位"、"预算上限300美元"），跨设备、跨渠道访问
- **68:30** - MCP功能：提取内存模块、按顺序列出内存事件、检索内存记录、重建对话等
- **69:00** - 模式5：多代理共享内存 - 用户请求"预订航班前添加旅行保险，使用我们支持对话中的电子邮件"，编排器协调三个专业代理（支持代理、预订代理、支付代理），所有代理共享ElastiCache和Aurora PostgreSQL中的内存

### 生产部署 (70:00 - 结束)
- **70:30** - 提出生产问题：如何扩展到每天百万查询？如何确保高可用性、成本优化和安全性？
- **71:00** - 当前限制：代理在本地笔记本运行，Aurora PostgreSQL MCP服务器作为本地Python子进程运行，笔记本崩溃会导致事务丢失
- **72:00** - 介绍Bedrock Agent Core：现场调查显示几乎所有人都听说过，一人未听说过
- **72:30** - Agent Core定义：代理平台，用于安全地大规模构建、运行和部署代理，类似于自管理PostgreSQL服务器与Aurora PostgreSQL完全托管服务的关系
- **73:00** - Agent Core组件：运行时提供在云上大规模运行代理的环境，不再本地运行，框架不限于Bedrock模型，可使用其他模型
- **73:30** - 会议结束提示：有许多关于Agent Core的其他会议可供参考