# AWS re:Invent 2025 会议总结：使用图RAG技术改进生成式AI问答

## 会议概述

本次会议由Amazon Neptune服务团队的图架构师Ian Robinson和Deloitte网络运营副总裁Evan Owie共同主讲。会议重点介绍了Neptune团队开发的开源Python库——图RAG工具包(Graph RAG Toolkit)，以及Deloitte如何利用该工具构建其网络安全智能中心(Cyber Security Intelligence Center)。

会议的核心主题是如何通过图RAG(检索增强生成)技术来改进生成式AI的问答质量。传统的向量相似性搜索只能找到与问题语义相似的内容，但往往会遗漏结构上相关但语义不同的重要信息。图RAG工具包通过结合向量搜索和图搜索的混合方法，能够检索到更全面、更准确的上下文信息，从而生成更可靠和细致的答案。

Deloitte将这一技术应用于网络安全领域，构建了"AI辅助分类"(AI for Triage)系统，帮助安全运营工程师在面对大量安全告警时，能够基于组织特定的安全策略和生产系统状态做出明智的优先级判断和修复决策。该系统通过维护不断演进的组织知识库，将短期记忆(工具告警)转化为长期记忆(分类记录)，实现了分析师与业务部门之间的有效协作。

## 详细时间线

### 开场介绍 (00:00 - 02:30)
- **00:00** - Ian Robinson介绍自己是Amazon Neptune服务团队的图架构师
- **00:15** - 介绍Evan Owie，Deloitte网络运营副总裁
- **00:30** - 说明会议主题：Neptune团队改进生成式AI问答的工作，以及Deloitte如何使用图RAG工具包
- **01:00** - 假设听众已熟悉图数据库、向量相似性搜索和RAG技术
- **01:30** - 将重点放在Deloitte网络安全智能中心的实际应用上

### 问题背景：云安全平台的挑战 (02:30 - 05:00)
- **02:30** - 询问听众是否使用过Wiz或CrowdStrike等云安全平台
- **03:00** - 描述首次启用安全平台时的场景："整个圣诞树都亮起来了"——出现数百甚至数千个告警
- **03:30** - 提出核心问题：安全运营工程师如何安全及时地修复这些问题
- **04:00** - 强调不能简单自动化修复，需要进行分类和优先级排序
- **04:30** - 指出需要两个关键因素：理解组织网络安全策略背景，以及了解修复对生产系统的影响

### 上下文问题的重要性 (05:00 - 07:00)
- **05:00** - 强调这是一个信息过载和上下文问题
- **05:30** - 列举所需的组织特定知识：安全策略、运行手册、最佳实践、架构指导、生产系统当前状态
- **06:00** - 提出解决方案方向：生成式AI和RAG技术
- **06:30** - 预告Evan将讨论"AI辅助分类"系统

### 图RAG工具包介绍 (07:00 - 09:00)
- **07:00** - 介绍图RAG工具包是Neptune团队开发的开源Python库
- **07:30** - 说明AI辅助分类使用该工具包维护不断演进的组织知识库
- **08:00** - 知识库包含：政策文档、运行手册、架构指导和分类记录
- **08:30** - 过渡到详细讲解Neptune团队改进图RAG技术的工作

### RAG中的上下文检索问题 (09:00 - 12:00)
- **09:00** - 强调RAG的核心是上下文
- **09:30** - 提出关键观点：检索的上下文类型和检索方式会显著影响响应质量
- **10:00** - 开始示例：假设管理包含数千份文档的语料库
- **10:30** - 列举五个关键文档：Example Corp的新产品、英国小部件需求、物流合作、Turquoise运河、网络安全事件
- **11:30** - 提出分析师问题："Example Corp在英国的销售前景如何？"

### 向量搜索的局限性 (12:00 - 14:30)
- **12:00** - 解释向量相似性搜索会找到语义相似的内容
- **12:30** - 展示搜索结果：前三篇文章提到Example Corp和英国
- **13:00** - 基于这些证据，系统回答"销售前景很好"
- **13:30** - 指出问题：这不是完整的故事，缺少更细致的答案
- **14:00** - 强调需要检索结构相关但可能不相似的内容

### 混合RAG方法 (14:30 - 17:00)
- **14:30** - 提出需要检索结构相关但潜在不相似的内容
- **15:00** - 展示完整的文档连接：Example Corp → 物流公司 → Turquoise运河 → 网络安全事件
- **15:30** - 使用混合方法后的改进答案：销售前景好，但可能受网络安全事件负面影响
- **16:00** - 定义召回率(Recall)：系统检索到的相关内容百分比
- **16:30** - 介绍混合RAG：使用向量搜索找相似内容，图搜索找结构相关内容

### 图RAG工具包的设计目标 (17:00 - 19:00)
- **17:00** - 指出混合RAG的问题：图搜索质量依赖于底层图的质量
- **17:30** - 提出两个高层设计目标
- **18:00** - 目标一：轻松从非结构化/半结构化数据构建图，减少信息架构开销
- **18:30** - 目标二：轻松找到所有相关但不明显或潜在不相似的内容，无需编写复杂图查询

### 分层词汇图模型 (19:00 - 23:00)
- **19:00** - 介绍工具包自动构建"分层词汇图"(Hierarchical Lexical Graph)
- **19:30** - 核心概念：语句(Statement)是从源数据提取的简短、完整的独立命题
- **20:00** - 语句是传递给语言模型的主要上下文单元
- **20:30** - 检索目标：找到高度相关的语句，按主题分组，归属到源文档
- **21:00** - 介绍图模型的三层结构
- **21:30** - 血统层(蓝色)：源节点(包含元数据)和块节点(向量搜索入口点)
- **22:00** - 总结层(中间)：语句、主题和事实
- **22:30** - 实体关系层(底部)：实体和关系，帮助找到结构相关但不相似的信息

### 主题和事实的作用 (23:00 - 25:00)
- **23:00** - 主题(Topics)：按主题对同一源文档的语句进行分组
- **23:30** - 主题提供"局部连接性"，支持对单个文档的深度调查
- **24:00** - 事实(Facts)：可以连接来自不同源文档的多个语句
- **24:30** - 事实提供"全局连接性"，支持跨语料库的广泛调查

### 上下文窗口示例 (25:00 - 27:00)
- **25:00** - 展示实际传递给LLM的上下文窗口格式
- **25:30** - 格式：按主题分组的语句集，归属到各个源文档
- **26:00** - 关键要点：基于职责的图建模方法
- **26:30** - 传统方法关注"节点代表什么"，新方法关注"节点能为我做什么"

### 实体网络上下文生成 (27:00 - 32:00)
- **27:00** - 重新表述检索目标：找到与问题相似的内容，以及与"其他内容"相似的内容
- **27:30** - 将图搜索转换为两个相似性搜索
- **28:00** - 引入"实体网络上下文"概念
- **28:30** - 实体网络上下文：围绕关键实体和关键词的1-2跳网络
- **29:00** - 开始详细说明生成过程
- **29:30** - 步骤1：从问题中查找实体关系层中的重要实体和关键词
- **30:00** - 步骤2：对候选实体节点进行重新排序
- **30:30** - 步骤3：识别最重要的实体，记录其度中心性
- **31:00** - 步骤4：对每个候选节点进行1-2跳路径扩展
- **31:30** - 步骤5：基于度中心性阈值过滤路径，消除"鲸鱼和小鱼"

### 路径评分和选择 (32:00 - 34:00)
- **32:00** - 步骤6：对每条路径上的所有节点重新评分
- **32:30** - 步骤7：计算每条路径的平均分数
- **33:00** - 步骤8：根据平均分数重新排序路径
- **33:30** - 步骤9：限制路径列表(例如前3-5条)，创建文本转录

### 实体网络上下文的三种用途 (34:00 - 38:00)
- **34:00** - 展示三条路径示例，越往下不相似度越高
- **34:30** - 用途一：作为不相似性搜索的种子
- **35:00** - 对每个实体网络路径进行向量相似性搜索
- **35:30** - 使用结果找到词汇图中对应的块节点
- **36:00** - 从块节点开始遍历图，利用局部和全局连接性
- **36:30** - 用途二：使用加权词频分析重新排序结果
- **37:00** - 创建匹配项集合：原始问题+所有实体网络上下文(降序)
- **37:30** - 对匹配项加权，原始问题和第一条路径权重最高

### 重新排序和提示增强 (38:00 - 40:30)
- **38:00** - 对每个语句与每个匹配项评分，计算平均分
- **38:30** - 展示结果：提到物流公司和Turquoise运河的语句被提升到顶部
- **39:00** - 这些语句对原始问题得分很低，但对后两个实体网络上下文得分高
- **39:30** - 用途三：丰富生成响应的提示
- **40:00** - 除了用户问题和搜索结果，还添加实体网络上下文作为额外上下文
- **40:30** - 指导LLM关注可能被忽略的语句

### 效果对比 (40:30 - 42:30)
- **40:30** - 提问："这有效吗？"回答："是的"
- **41:00** - 传统向量搜索结果：大量细节，但过于乐观——"销售前景异常强劲"
- **41:30** - 图RAG工具包结果：同样的细节，但结论更细致
- **42:00** - 改进的答案提到：潜在供应链挑战、全球分销可能中断、大规模网络攻击、产品短缺和交付时间影响
- **42:30** - 关键要点：图搜索和向量搜索相互受益

### 工具包资源和支持 (42:30 - 44:30)
- **42:30** - 图搜索擅长找结构相关内容，向量搜索擅长缓解质量问题
- **43:00** - 两者在检索过程中协同工作，平滑质量问题
- **43:30** - 展示GitHub仓库的QR码和链接
- **44:00** - 提供详细描述分层词汇图的论文链接
- **44:30** - 说明工具包采用混合RAG方法，支持多个后端

### 支持的后端系统 (44:30 - 46:00)
- **44:30** - 图数据库：Amazon Neptune、Neptune Analytics、Neo4j
- **45:00** - 向量存储：Neptune Analytics、OpenSearch Serverless、带PG Vector扩展的PostgreSQL
- **45:30** - 强调这是一个库，不是完整应用
- **46:00** - 设计用于与其他工具和库结合，构建功能完整的应用

### Evan Owie开始讲解Deloitte应用 (46:00 - 49:00)
- **46:00** - Evan接手演讲，表示不会过多谈论Deloitte公司本身
- **46:30** - 引入人类记忆类比：长期记忆、工作记忆、短期记忆
- **47:00** - 图RAG工具包类比为长期记忆
- **47:30** - 指出常见问题：许多工具只基于短期记忆做出反应
- **48:00** - 这会导致无法建立组织范围内问题的真实本质
- **48:30** - 介绍"零断开困境"(Zero Disconnect Dilemma)

### 零断开困境 (49:00 - 51:30)
- **49:00** - 组织希望保持连接(网络或威胁情报)
- **49:30** - 同时，攻击者也在做同样的事但目的相反
- **50:00** - 类比：会议室中有恶意代理试图破坏，但无法识别
- **50:30** - 这就是网络安全的世界：没有明确的敌友
- **51:00** - Deloitte与AWS团队合作，认识到图可以帮助实现零断开
- **51:30** - 许多组织存在断开连接的问题

### 组织防御机制的问题 (51:30 - 54:00)
- **51:30** - 组织有各种防御理由：复选框合规、光学驱动(看起来不错)
- **52:00** - 购买了最好的工具，但最终归结为"合理否认"
- **52:30** - 如果做得足够多,就没人能说做得不够好
- **53:00** - Evan自称是开发者，知道向老板说A但实际是B的情况
- **53:30** - 问题：SOC分析师尽力分类，然后"扔过围栏"给业务部门
- **54:00** - 业务部门只是观察者,做自己的笔记,两边的笔记不一致

### Deloitte的愿景 (54:00 - 56:30)
- **54:00** - 目标：建立长期记忆
- **54:30** - 将分类记录中的经验教训(而非工具告诉的内容)反馈到工厂
- **55:00** - 成为组织或客户组织网络安全的中央存储库
- **55:30** - 认识到图RAG工具包可以做到这一点
- **56:00** - 必须保持AI生成的分类记录与人工生成的分离,不可变
- **56:30** - 人工仲裁非常重要,必须能够说明什么是AI生成的,什么是人工生成的

### 协作和零断开愿景 (56:30 - 58:30)
- **56:30** - 如果打破这个规则,决策将无法辩护
- **57:00** - 有人想使用分类记录进行推理和反思
- **57:30** - 如果正确使用工具包,可以更接近零断开愿景
- **58:00** - 在分析师和业务部门之间创建协作
- **58:30** - 提问："我们能做到吗？"

### 短期记忆的缺失 (58:30 - 60:30)
- **58:30** - 发现缺少短期记忆
- **59:00** - 从工具获得的信号和反馈不是长期记忆
- **59:30** - 需要转换为分类记录才能成为长期记忆
- **60:00** - 当前这些只是噪音和信号,需要文档图
- **60:30** - 构建了文档图并添加到图RAG工具包

### 文档图的设计 (60:30 - 62:30)
- **60:30** - 以可以将文档图构建到逻辑域的方式构建
- **61:00** - 允许从工具中分组以文档为中心的信息
- **61:30** - 例如Wiz有自己的派生词汇表
- **62:00** - 在该域内可以有短期派生词汇表
- **62:30** - 可以进行适度的实体解析,因为在Wiz或Prisma空间内存在固有关系

### 分类记录的重要性 (62:30 - 65:00)
- **62:30** - 重申目标：构建分类记录,将短期记忆转换为长期记忆
- **63:00** - 常见错误：认为AI就是对所有短期记忆做出反应
- **63:30** - 强调：这会错过共同经验的增强
- **64:00** - 总结：图RAG是知识语料库,是经验
- **64:30** - 就像人随着年龄增长有更多经验,组织也想捕获经验
- **65:00** - 想要检索良好的经验,同时策划短期记忆

### 系统架构 (65:00 - 67:30)
- **65:00** - 构建了文档图作为硬数据
- **65:30** - 以AI生成的分类记录形式将硬数据带给分析师
- **66:00** - 将其反馈到文档图中,用于总体上下文分析
- **66:30** - 这样可以获得组织的全貌,而不是大量工具的图景
- **67:00** - 通过"中间人"、"人在回路中"来实现,确保问责
- **67:30** - 做出的决策是"人类增强决策",相当于给人员穿上钢铁侠套装

### 技术改进 (67:30 - 70:00)
- **67:30** - 不是构建机器人取代人员,那样行不通
- **68:00** - 学到的经验：需要做几件事
- **68:30** - 与AWS密切合作,确保图RAG工具包可以从更多来源读取
- **69:00** - 添加了更多来源,JSON很好但需要其他来源
- **69:30** - 短期和长期记忆都需要视频、音频,需要多模态嵌入
- **70:00** - 最大的挑战：如何快速将大量数据从各种工具导入图中

### 数据管道 (70:00 - 72:00)
- **70:00** - 团队成员不想成为图专家
- **70:30** - 编写了非常复杂的管道,管道中嵌入了AI和Bedrock
- **71:00** - 构建了将任何信号、日志、突触等数据转换为JSON的机制
- **71:30** - 然后快速将其转换为短期记忆
- **72:00** - 举例：对访问地点的短期体验感兴趣

### IP地址示例 (72:00 - 结束)
- **72:00** - 实际应用：获取有关IP地址的信息
- **72:30** - IP地址不是直接访问的地方,而是间接的
- **73:00** - 管道将获取IP地址...(字幕在此处截断)

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


注： 字幕在讲解IP地址示例时突然截断,可能还有后续内容未包含在提供的字幕中。