1
00:00:00,000 --> 00:00:03,585
- All right, well, thank you
all for attending this session.

2
00:00:03,585 --> 00:00:05,000
I'm gonna have to get used to the fact

3
00:00:05,000 --> 00:00:06,749
that you're all wearing
headphones, and I'm not,

4
00:00:06,749 --> 00:00:11,094
so I'll just trust that you
can hear and are interested.

5
00:00:11,094 --> 00:00:14,352
So we are here to talk
about something, I think,

6
00:00:14,352 --> 00:00:18,499
that has really evolved
tremendously over the last year

7
00:00:18,499 --> 00:00:23,290
is the security implications
specific to how AI

8
00:00:24,338 --> 00:00:28,239
is, you know, fundamentally
shifting what we do in security.

9
00:00:28,239 --> 00:00:31,581
And so this is gonna be
a conversational piece

10
00:00:31,581 --> 00:00:33,675
where my friend Ammar here

11
00:00:33,675 --> 00:00:37,100
and I are going to talk about
things that we're seeing,

12
00:00:37,100 --> 00:00:39,413
some of the best practices that

13
00:00:39,413 --> 00:00:41,384
we have been looking to implement,

14
00:00:41,384 --> 00:00:44,600
or, you know, maybe Adobe has implemented.

15
00:00:44,600 --> 00:00:48,352
But just for a quick introduction,

16
00:00:48,352 --> 00:00:52,200
this is a session where both Fortinet and

17
00:00:52,200 --> 00:00:55,490
Adobe have, you know,
kind of collaborated.

18
00:00:55,490 --> 00:00:58,154
Ammar and I have done this a few times,

19
00:00:58,154 --> 00:01:00,743
you know, not in this
topic, but various topics.

20
00:01:00,743 --> 00:01:03,828
And so I love how he frames things.

21
00:01:03,828 --> 00:01:06,496
But, you know, Ammar, thank
you for being with me.

22
00:01:06,496 --> 00:01:07,861
I always appreciate, you know,

23
00:01:07,861 --> 00:01:10,003
the opportunity to do
these things with you.

24
00:01:10,003 --> 00:01:12,251
Maybe quickly introduce yourself.

25
00:01:12,251 --> 00:01:13,752
- Yeah, absolutely.

26
00:01:13,752 --> 00:01:16,453
Really happy to be here.

27
00:01:16,453 --> 00:01:19,300
re:Invent is one of my favorite

28
00:01:20,608 --> 00:01:23,873
conferences as an AWS Community Builder.

29
00:01:23,873 --> 00:01:27,918
And before we start, I just
wanna understand the room

30
00:01:27,918 --> 00:01:31,997
and see who are, get to
know the audience more.

31
00:01:31,997 --> 00:01:35,097
Just raise your hand who here is

32
00:01:35,097 --> 00:01:37,999
responsible for securing

33
00:01:37,999 --> 00:01:40,241
AI workloads?

34
00:01:40,241 --> 00:01:42,740
- Oh, that's a pretty big number.

35
00:01:42,740 --> 00:01:46,642
- Who here is being asked to

36
00:01:46,642 --> 00:01:51,642
use AI to do something, whether
it's security, operations?

37
00:01:52,293 --> 00:01:55,106
- Okay. All right, so we've
got the right audience.

38
00:01:55,106 --> 00:01:56,997
- One last question,

39
00:01:56,997 --> 00:02:00,744
who here has not used AI

40
00:02:00,744 --> 00:02:01,883
yet,

41
00:02:01,883 --> 00:02:03,418
planning on?

42
00:02:03,418 --> 00:02:06,493
Okay, we have a couple.

43
00:02:06,493 --> 00:02:10,424
I expected maybe five, so two is not

44
00:02:10,424 --> 00:02:11,418
- [Aidan] Yeah.

45
00:02:11,418 --> 00:02:14,228
- too off, so yeah, I'm excited to be here

46
00:02:14,228 --> 00:02:15,581
to talk about the implications.

47
00:02:15,581 --> 00:02:18,630
I think from 2019,

48
00:02:18,630 --> 00:02:20,666
maybe to 2030,

49
00:02:20,666 --> 00:02:24,070
is going to go down in history as a very

50
00:02:25,592 --> 00:02:27,660
big moment in human history, right?

51
00:02:27,660 --> 00:02:31,867
It's similar to discovering electricity or

52
00:02:31,867 --> 00:02:33,398
hospitals,

53
00:02:33,398 --> 00:02:35,381
fire, like so many-
- The internet.

54
00:02:35,381 --> 00:02:37,893
- The internet, absolutely.
- Yeah.

55
00:02:38,988 --> 00:02:42,115
- Those changes are
coming at us very fast.

56
00:02:42,115 --> 00:02:46,973
Like, sometimes my team
deploys something that is AI,

57
00:02:46,973 --> 00:02:49,592
and as a security person, I'm not aware.

58
00:02:49,592 --> 00:02:51,660
Why? Because they wanna
keep up with the market.

59
00:02:51,660 --> 00:02:54,834
They wanna move fast. They
don't have time for checks.

60
00:02:54,834 --> 00:02:58,243
So we all here to kind of
figure it out together,

61
00:02:58,243 --> 00:03:01,883
and without further ado, I'm
just gonna introduce myself.

62
00:03:01,883 --> 00:03:03,001
I'm Ammar.

63
00:03:03,001 --> 00:03:07,150
I am an AWS Community Builder, and I also

64
00:03:07,991 --> 00:03:10,881
like look after DevOps,
the DevOps team at Adobe,

65
00:03:10,881 --> 00:03:14,623
so a little bit of
cloud, web applications,

66
00:03:14,623 --> 00:03:16,350
and AI security.

67
00:03:16,350 --> 00:03:19,245
Without me signing up for
any of the AI security,

68
00:03:19,245 --> 00:03:22,488
I found myself, like many of you guys,

69
00:03:22,488 --> 00:03:25,346
my applications has AI in them,

70
00:03:25,346 --> 00:03:28,236
and now I'm responsible for AI security.

71
00:03:28,236 --> 00:03:31,748
- Yeah, I think that the
scale that Adobe has in AI

72
00:03:31,748 --> 00:03:34,110
is why I like getting your input.

73
00:03:34,110 --> 00:03:36,885
It's like you have literally
hundreds of applications

74
00:03:36,885 --> 00:03:38,390
that are quite mature.

75
00:03:38,390 --> 00:03:39,836
I use these applications.

76
00:03:39,836 --> 00:03:43,812
I'm sure many of this audience uses them.

77
00:03:43,812 --> 00:03:45,655
And so, you know, for my part,

78
00:03:45,655 --> 00:03:46,993
you know, we have different perspectives.

79
00:03:46,993 --> 00:03:48,420
Ammar

80
00:03:48,420 --> 00:03:49,253
is

81
00:03:49,253 --> 00:03:50,948
a consumer of security tools.

82
00:03:50,948 --> 00:03:52,996
He builds his own security tools.

83
00:03:52,996 --> 00:03:55,597
They build AI applications.

84
00:03:55,597 --> 00:03:59,864
For my part, I'm responsible
at Fortinet for cloud,

85
00:03:59,864 --> 00:04:01,754
SaaS, and AI engineering.

86
00:04:01,754 --> 00:04:05,732
And so primarily what I'm doing
is not just looking at tools

87
00:04:05,732 --> 00:04:08,477
that we consume internally
and ensuring our practices,

88
00:04:08,477 --> 00:04:12,650
but how customers want to adopt
third-party security tooling

89
00:04:12,650 --> 00:04:16,138
and integrate those in their
pipelines and workflows.

90
00:04:16,138 --> 00:04:17,410
And so we have these, you know,

91
00:04:17,410 --> 00:04:20,101
I think complementary views on the world.

92
00:04:20,101 --> 00:04:23,140
So, you know, one of the
things that I think is

93
00:04:24,598 --> 00:04:28,260
very, you know, interesting
about this era is

94
00:04:28,260 --> 00:04:30,740
how we build applications,

95
00:04:30,740 --> 00:04:32,325
how those applications are attacked,

96
00:04:32,325 --> 00:04:34,046
and how we defend from those attacks

97
00:04:34,046 --> 00:04:35,752
has changed so much, right?

98
00:04:35,752 --> 00:04:39,996
Before we had this environment
where it was largely static.

99
00:04:39,996 --> 00:04:42,960
You were concerned about
the infrastructure.

100
00:04:42,960 --> 00:04:45,860
You built an application, you
were protecting source code,

101
00:04:46,739 --> 00:04:49,499
and it was very deterministic.

102
00:04:49,499 --> 00:04:52,139
But now we've added on
this additional layer,

103
00:04:52,139 --> 00:04:53,007
it's additive, right?

104
00:04:53,007 --> 00:04:54,649
So you still have to take
care of the old stuff,

105
00:04:54,649 --> 00:04:58,640
but now we have a system
that reasons, right?

106
00:04:58,640 --> 00:05:02,463
So you don't necessarily always
know what the outputs are.

107
00:05:03,390 --> 00:05:05,790
You know, I imagine your environments

108
00:05:05,790 --> 00:05:07,679
are very much like this.

109
00:05:07,679 --> 00:05:08,512
- Absolutely.

110
00:05:08,512 --> 00:05:11,679
So if you, this is not a
Adobe pitch or anything,

111
00:05:11,679 --> 00:05:14,793
but if you think about the applications

112
00:05:14,793 --> 00:05:18,004
that you guys use prior, you know, BDF,

113
00:05:18,004 --> 00:05:19,914
anyone here probably have used one,

114
00:05:19,914 --> 00:05:21,490
Photoshop, maybe you haven't used it,

115
00:05:21,490 --> 00:05:25,838
but now all of these established
legacy, in my opinion,

116
00:05:25,838 --> 00:05:29,245
they've been there for a long
time, not legacy in a bad way,

117
00:05:29,245 --> 00:05:32,408
they've been there for a long
time, they have AI in them.

118
00:05:32,408 --> 00:05:37,075
So you can edit using prompts
like prompt-driven editing.

119
00:05:37,075 --> 00:05:39,251
You can say remove the background.

120
00:05:39,251 --> 00:05:41,179
The AI component wasn't there.

121
00:05:41,179 --> 00:05:45,254
Everything else has been there,
hasn't changed, is the same.

122
00:05:45,254 --> 00:05:47,290
So, before people

123
00:05:48,245 --> 00:05:50,669
really get concerned about AI,

124
00:05:50,669 --> 00:05:52,744
which you should be concerned about,

125
00:05:52,744 --> 00:05:54,827
the fundamentals have not changed.

126
00:05:54,827 --> 00:05:57,126
Defense in depth has not changed.

127
00:05:57,126 --> 00:05:59,996
The way you set up your AWS
accounts has not changed.

128
00:05:59,996 --> 00:06:02,147
Your VBCs, your IAM policies,

129
00:06:02,147 --> 00:06:05,580
all of these things still
exist, did not go away.

130
00:06:05,580 --> 00:06:08,738
In addition to that, you
now have to think about,

131
00:06:08,738 --> 00:06:12,590
"Hey, do I have a model that
is part of Photoshop or BDF

132
00:06:12,590 --> 00:06:14,820
or whatever your product is?"

133
00:06:14,820 --> 00:06:16,744
Is it built in-house?

134
00:06:16,744 --> 00:06:19,430
Is it off-the-shelf model?

135
00:06:19,430 --> 00:06:21,834
Who is able to access that model?

136
00:06:21,834 --> 00:06:24,483
Am I calling that model privately?

137
00:06:25,391 --> 00:06:29,238
If it's a model that we've
built, where the data is stored,

138
00:06:29,238 --> 00:06:32,232
how is the data curated, cleaned up,

139
00:06:32,232 --> 00:06:35,579
encrypted in rest, at rest,
in transit, and all of those?

140
00:06:35,579 --> 00:06:37,345
So yeah,

141
00:06:37,345 --> 00:06:39,386
this is a typical

142
00:06:39,386 --> 00:06:42,494
AI stack now, where you
have a data pipeline,

143
00:06:42,494 --> 00:06:45,935
you have agents, probably, which is

144
00:06:45,935 --> 00:06:47,335
simply

145
00:06:47,335 --> 00:06:52,335
a tool that can make some
decisions and call other tools

146
00:06:52,488 --> 00:06:54,995
backed by an LLM intelligence.

147
00:06:54,995 --> 00:06:57,744
So it could invoke

148
00:06:57,744 --> 00:07:00,400
an API, it could get data from,

149
00:07:00,400 --> 00:07:03,737
you know, a data store,
it could read Jira,

150
00:07:03,737 --> 00:07:05,302
whatever you give it access to.

151
00:07:05,302 --> 00:07:07,840
So, we'll talk more about access control

152
00:07:07,840 --> 00:07:10,295
and the nitty-gritty, but

153
00:07:10,295 --> 00:07:11,827
- Yeah, it-
- simple that this is, yes,

154
00:07:11,827 --> 00:07:13,254
this is the infrastructure.

155
00:07:13,254 --> 00:07:14,253
- For us, we just say we,

156
00:07:14,253 --> 00:07:18,001
you know, think this is just
a much larger attack surface

157
00:07:18,001 --> 00:07:22,133
that is really perimeterless, truly.

158
00:07:22,133 --> 00:07:23,220
- Absolutely.

159
00:07:23,220 --> 00:07:24,840
- And we have to think about the old ways

160
00:07:24,840 --> 00:07:26,671
that these applications were attacked

161
00:07:26,671 --> 00:07:28,851
because they can be chained to,

162
00:07:28,851 --> 00:07:31,508
and we'll show an example of that,

163
00:07:31,508 --> 00:07:33,760
two new styles of attacks

164
00:07:35,100 --> 00:07:36,830
that are specific to the AI.

165
00:07:36,830 --> 00:07:38,740
Now the risks and concerns.

166
00:07:38,740 --> 00:07:40,675
Now I mentioned earlier

167
00:07:40,675 --> 00:07:43,920
that these things were
largely anecdotal, you know?

168
00:07:43,920 --> 00:07:47,001
If you go back maybe
a year, 18 months ago,

169
00:07:47,001 --> 00:07:48,246
we saw these things happening,

170
00:07:48,246 --> 00:07:52,443
but now we literally see these
happening on a daily basis.

171
00:07:53,353 --> 00:07:56,242
You know, model poisoning,
this can happen very quickly,

172
00:07:56,242 --> 00:07:58,067
or it can happen slowly over time.

173
00:07:58,067 --> 00:08:00,737
Like, you know, as if you're
boiling the frog, right?

174
00:08:00,737 --> 00:08:02,440
So I can start to

175
00:08:03,345 --> 00:08:06,591
create bias or poison that model slowly,

176
00:08:06,591 --> 00:08:08,483
so I don't trigger anything.

177
00:08:08,483 --> 00:08:10,861
And those things are harder to catch.

178
00:08:10,861 --> 00:08:11,917
Unauthorized access.

179
00:08:11,917 --> 00:08:14,119
You know, this could be
privileged escalations.

180
00:08:14,119 --> 00:08:18,910
We see all the time where
people are creating tools

181
00:08:20,190 --> 00:08:24,489
that are not well secured, and
maybe the user's using them

182
00:08:24,489 --> 00:08:26,150
for privilege escalation, right?

183
00:08:26,150 --> 00:08:28,496
So that's a common attack path.

184
00:08:28,496 --> 00:08:30,339
Malicious prompts, you know, this is,

185
00:08:30,339 --> 00:08:31,853
like, you guys are focused

186
00:08:31,853 --> 00:08:34,491
on protecting prompts all day long.

187
00:08:34,491 --> 00:08:35,605
And data leak, right?

188
00:08:35,605 --> 00:08:40,105
So, asking for information from

189
00:08:40,105 --> 00:08:41,910
an AI tool, an agent,

190
00:08:41,910 --> 00:08:45,741
and then getting back data
that it should not have gotten.

191
00:08:45,741 --> 00:08:48,493
This happens every day.

192
00:08:48,493 --> 00:08:49,830
In addition, like what do you see?

193
00:08:49,830 --> 00:08:52,377
These are the ones that I
see, like what do you see?

194
00:08:52,377 --> 00:08:54,997
Are this consistent?
Anything you would add?

195
00:08:54,997 --> 00:08:58,743
- There's this, and there's another one,

196
00:08:58,743 --> 00:09:01,050
which is the AI layer,

197
00:09:01,050 --> 00:09:04,157
meaning I would consider this
more of a machine learning.

198
00:09:04,157 --> 00:09:06,403
You're building models in-house.

199
00:09:06,403 --> 00:09:08,885
These are concerns for you.

200
00:09:08,885 --> 00:09:11,840
But as a consumer of AI tooling,

201
00:09:11,840 --> 00:09:16,596
there's another segment that
we should talk about, probably.

202
00:09:16,596 --> 00:09:18,480
And just a quick,

203
00:09:18,480 --> 00:09:21,494
I wanna understand who here
are building models in-house

204
00:09:21,494 --> 00:09:24,358
and who here are just using
AI tooling that you buy?

205
00:09:24,358 --> 00:09:26,397
So who in the audience

206
00:09:26,397 --> 00:09:29,631
is building their own models in-house?

207
00:09:29,631 --> 00:09:31,162
- Nice.

208
00:09:31,162 --> 00:09:35,100
- Who is using off-the-shelf
models and other AI tools?

209
00:09:35,100 --> 00:09:36,657
Pretty much everyone.

210
00:09:36,657 --> 00:09:37,907
So

211
00:09:37,907 --> 00:09:39,315
you are

212
00:09:39,315 --> 00:09:42,740
likely trying to get the most out of

213
00:09:42,740 --> 00:09:43,920
an LLM

214
00:09:43,920 --> 00:09:48,920
if you buy it, for example,
if you're using the APIs,

215
00:09:48,997 --> 00:09:51,240
the LLM is not to be trusted

216
00:09:51,240 --> 00:09:53,409
because maybe it has limitations, right?

217
00:09:53,409 --> 00:09:57,242
Like it was trained three
months ago, maybe two years ago,

218
00:09:57,242 --> 00:10:02,144
and you want to feed it
your own enterprise data.

219
00:10:02,144 --> 00:10:06,848
Maybe your documentation,
maybe your workday information,

220
00:10:06,848 --> 00:10:09,738
whatever the use case is.

221
00:10:09,738 --> 00:10:12,621
So your attack surface is,

222
00:10:12,621 --> 00:10:16,419
can your company data get leaked,

223
00:10:16,419 --> 00:10:20,153
and who has access to that data, right?

224
00:10:20,153 --> 00:10:21,999
You're gonna put that
in a vector database.

225
00:10:21,999 --> 00:10:24,323
How do you do that correctly?

226
00:10:24,323 --> 00:10:26,494
How do you worry about context engineering

227
00:10:26,494 --> 00:10:29,745
so your agents are reliable?

228
00:10:29,745 --> 00:10:31,579
You're using MCP servers.

229
00:10:31,579 --> 00:10:35,001
Probably you have, you
know, remote MCP servers,

230
00:10:35,001 --> 00:10:37,328
which I do not recommend.

231
00:10:37,328 --> 00:10:39,995
Building an MCP server is
really easy these days,

232
00:10:39,995 --> 00:10:41,373
where just build your own,

233
00:10:41,373 --> 00:10:43,998
like your own GitHub MCP, for example.

234
00:10:43,998 --> 00:10:47,896
And I get, like, MCP
servers make life super easy

235
00:10:47,896 --> 00:10:52,359
because your prompt now has
a lot of tooling behind it

236
00:10:52,359 --> 00:10:55,888
that can be invoked to
get a lot of work done.

237
00:10:55,888 --> 00:10:57,238
- So can I ask you a question on that?

238
00:10:57,238 --> 00:10:59,866
- Yeah, absolutely.
- So, as a security provider,

239
00:10:59,866 --> 00:11:02,440
we get asked by our customers to provide

240
00:11:06,177 --> 00:11:08,103
MCP agents for our security
tools to integrate them.

241
00:11:11,342 --> 00:11:13,824
You know, do you look at
vendor implementations

242
00:11:13,824 --> 00:11:15,921
as separate from maybe
these other examples

243
00:11:15,921 --> 00:11:17,377
that you're talking about?

244
00:11:17,377 --> 00:11:20,250
You know, public projects?
- Yeah, if there is a trusted

245
00:11:20,250 --> 00:11:21,883
vendor, yeah, like there's a difference

246
00:11:21,883 --> 00:11:26,693
between a remote open-source
MCP and a trusted vendor MCP.

247
00:11:26,693 --> 00:11:28,993
So, for a company like you

248
00:11:28,993 --> 00:11:33,993
with a complicated set of APIs
that I cannot, I don't know

249
00:11:34,245 --> 00:11:39,104
fully, providing me with
an MCP that can help me

250
00:11:39,104 --> 00:11:42,495
use natural language to
interact with the API

251
00:11:42,495 --> 00:11:45,734
would be lovely if it's
secure, maintained, well done.

252
00:11:45,734 --> 00:11:50,240
I can also try to have just
enough MCP that I built.

253
00:11:50,240 --> 00:11:52,992
Like, it doesn't have to be
very comprehensive, right?

254
00:11:52,992 --> 00:11:55,990
But I would be very hesitant to

255
00:11:56,850 --> 00:11:59,840
just pulling a remote MCP

256
00:11:59,840 --> 00:12:02,598
without looking at the code.

257
00:12:02,598 --> 00:12:05,937
You know, you integrate that
MCP server with your IDE,

258
00:12:05,937 --> 00:12:07,590
and all of the sudden,

259
00:12:07,590 --> 00:12:10,249
your IDE can actually invoke that MCP,

260
00:12:10,249 --> 00:12:11,734
and all of the sudden,

261
00:12:11,734 --> 00:12:15,481
you have an OS injection
attack on your laptop

262
00:12:15,481 --> 00:12:17,911
that could harness credentials,
that could do whatever.

263
00:12:17,911 --> 00:12:20,606
So I would be very careful

264
00:12:20,606 --> 00:12:23,835
with open-source remote
MCPs because attackers

265
00:12:23,835 --> 00:12:28,150
are actually like
sprinkling those out there,

266
00:12:28,150 --> 00:12:30,392
you know, to lure you to use them,

267
00:12:30,392 --> 00:12:32,181
which that's what they were looking for.

268
00:12:32,181 --> 00:12:34,389
So it's like

269
00:12:34,389 --> 00:12:37,741
importing untrusted library
that you don't trust.

270
00:12:37,741 --> 00:12:39,006
- Absolutely. Yeah.

271
00:12:39,006 --> 00:12:42,434
And in fact, you know, this
has gone from anecdotal

272
00:12:42,434 --> 00:12:43,938
to being so well established.

273
00:12:43,938 --> 00:12:46,500
I mean, you know, if you're in security,

274
00:12:46,500 --> 00:12:51,104
you probably understand that
OWASP is a top 10 for LLMs

275
00:12:51,104 --> 00:12:55,122
and generative AI in addition
to their traditional top 10.

276
00:12:55,122 --> 00:12:56,336
But these are the ones that we see,

277
00:12:56,336 --> 00:12:58,844
and that was a good one, I think, Ammar.

278
00:12:58,844 --> 00:13:01,002
So, you know,

279
00:13:01,002 --> 00:13:03,838
let's talk about kind of
the camps that we see.

280
00:13:03,838 --> 00:13:07,415
And this is our experience
internally at Fortinet.

281
00:13:07,415 --> 00:13:11,611
We have people in our finance team,

282
00:13:11,611 --> 00:13:13,999
you were talking to our
CISO the other day about,

283
00:13:13,999 --> 00:13:15,161
that are literally thinking,

284
00:13:15,161 --> 00:13:16,606
"Okay, I can vibe something out,

285
00:13:16,606 --> 00:13:18,549
and I've created this application.

286
00:13:18,549 --> 00:13:20,003
It's got maybe like it's some kind

287
00:13:20,003 --> 00:13:21,837
of agent component in it."

288
00:13:23,145 --> 00:13:25,491
That is not a mature product.

289
00:13:25,491 --> 00:13:29,129
We have tons of those
proliferating both, you know,

290
00:13:29,129 --> 00:13:32,495
like our, you know, skunkworks
and shadow IT efforts,

291
00:13:32,495 --> 00:13:34,148
and then, you know, we have our customers

292
00:13:34,148 --> 00:13:35,865
who have tremendous numbers of these,

293
00:13:35,865 --> 00:13:37,908
but these are, I would call POCs, right?

294
00:13:37,908 --> 00:13:39,236
- Yeah.
- They're very fragile.

295
00:13:39,236 --> 00:13:41,898
They're not meant to be in production.

296
00:13:41,898 --> 00:13:44,374
You know, when you start
getting maybe even sophisticated

297
00:13:44,374 --> 00:13:46,350
in your POCs, you have, you know,

298
00:13:46,350 --> 00:13:48,270
agent-to-agent communication,

299
00:13:48,270 --> 00:13:50,996
and then you have these
unvalidated reasoning loops that,

300
00:13:50,996 --> 00:13:54,383
you know, if you have a compromise
in one or a bias in one,

301
00:13:54,383 --> 00:13:55,492
then it propagates

302
00:13:55,492 --> 00:13:59,013
and escalates through
that reasoning chain.

303
00:14:00,233 --> 00:14:02,130
Telemetry and observability.

304
00:14:02,130 --> 00:14:04,740
You know, we get these AI tools,

305
00:14:04,740 --> 00:14:07,953
and these agents, and
nobody has thought about,

306
00:14:09,090 --> 00:14:11,835
one, how do I observe the infrastructure

307
00:14:11,835 --> 00:14:13,368
on which these services run

308
00:14:13,368 --> 00:14:16,110
to make sure it's on
trusted infrastructure?

309
00:14:16,110 --> 00:14:18,418
And then two,

310
00:14:18,418 --> 00:14:20,907
you know, am I auditing,

311
00:14:20,907 --> 00:14:23,248
which is very important and very different

312
00:14:23,248 --> 00:14:25,450
from what it used to be, but auditing

313
00:14:27,247 --> 00:14:29,172
the response and how the agent

314
00:14:29,172 --> 00:14:32,832
or the application comes to reason.

315
00:14:32,832 --> 00:14:35,910
None of that is happening in a
lot of these implementations.

316
00:14:35,910 --> 00:14:39,382
And so, you know, all
of these things like,

317
00:14:39,382 --> 00:14:41,991
you know, no recovery
and backup processes,

318
00:14:41,991 --> 00:14:43,989
no data maturity,

319
00:14:43,989 --> 00:14:47,241
you know, we see that
every day proliferate.

320
00:14:47,241 --> 00:14:49,243
And I think there's a second camp here,

321
00:14:49,243 --> 00:14:51,360
and maybe I'll let you
look at some of these

322
00:14:51,360 --> 00:14:53,233
and talk about the lessons

323
00:14:53,233 --> 00:14:56,348
that you guys have learned at
Adobe, 'cause in my opinion,

324
00:14:56,348 --> 00:14:59,237
I think you guys have done
a lot of things really well.

325
00:14:59,237 --> 00:15:01,263
You know, you and I have talked about,

326
00:15:02,738 --> 00:15:05,894
you know, sequestering agents
not being overly permissive.

327
00:15:05,894 --> 00:15:09,488
I think that's, you know,
controlling reasoning chains,

328
00:15:09,488 --> 00:15:12,338
continuously logging, which
I wanna expand on that,

329
00:15:12,338 --> 00:15:15,496
but maybe you'll touch
on these points for us.

330
00:15:15,496 --> 00:15:16,560
- Yeah, absolutely.

331
00:15:16,560 --> 00:15:18,626
So when we think about building agents,

332
00:15:18,626 --> 00:15:23,386
we think about the agent as
a user, like a human user,

333
00:15:23,386 --> 00:15:27,503
just to make it simple to
understand what this agent is.

334
00:15:27,503 --> 00:15:31,320
Typically, an agent is receiving
information from somewhere,

335
00:15:31,320 --> 00:15:32,430
which is a prompt.

336
00:15:32,430 --> 00:15:35,413
It could be from external users,

337
00:15:35,413 --> 00:15:37,749
internal users, or a system.

338
00:15:37,749 --> 00:15:40,745
For example, the agent could
be reading Jira tickets

339
00:15:40,745 --> 00:15:43,492
and, based on that, is
making some decisions.

340
00:15:43,492 --> 00:15:45,003
So, where the data,

341
00:15:45,003 --> 00:15:48,150
where the instructions to
the agent are coming from.

342
00:15:48,150 --> 00:15:52,841
Second, what that agent
is allowed to access.

343
00:15:52,841 --> 00:15:56,605
So, how many systems that
agent is allowed to access?

344
00:15:56,605 --> 00:15:58,736
Does it have just enough access,

345
00:15:58,736 --> 00:16:01,599
or does it have access
to all your S3 buckets,

346
00:16:01,599 --> 00:16:03,742
even though they, you
know, it's just easy,

347
00:16:03,742 --> 00:16:06,603
you know, to just give it access

348
00:16:06,603 --> 00:16:08,993
and let it vector information
from the right places.

349
00:16:08,993 --> 00:16:10,661
Let it figure that out.

350
00:16:10,661 --> 00:16:14,087
And third, where the
agent put the information.

351
00:16:14,087 --> 00:16:17,239
Why do I think about
it like agent security

352
00:16:17,239 --> 00:16:18,593
from that perspective?

353
00:16:18,593 --> 00:16:21,343
First, the prompt could be malicious.

354
00:16:21,343 --> 00:16:24,241
For example, let's assume
you have a Zendesk,

355
00:16:24,241 --> 00:16:28,585
which is where you customers
kind of file tickets,

356
00:16:28,585 --> 00:16:31,504
and that Zendesk replicate
the ticket internally

357
00:16:31,504 --> 00:16:33,642
to your internal Jira system.

358
00:16:33,642 --> 00:16:36,988
Meaning if I embed some
malicious instructions

359
00:16:36,988 --> 00:16:38,492
in that Zendesk ticket,

360
00:16:38,492 --> 00:16:42,643
it gets replicated to a
private, trusted Jira system

361
00:16:42,643 --> 00:16:44,908
and gets picked up by your agent.

362
00:16:44,908 --> 00:16:48,020
So all of the sudden,
without you kind of analyzing

363
00:16:48,020 --> 00:16:51,630
and doing threat modeling, you have

364
00:16:51,630 --> 00:16:55,610
gotten bad instructions
to the agent without,

365
00:16:55,610 --> 00:16:57,873
you know, thinking about it carefully.

366
00:16:58,890 --> 00:17:02,398
That instruction could allow the agent

367
00:17:02,398 --> 00:17:04,852
to fetch some secrets or whatever.

368
00:17:04,852 --> 00:17:07,584
Then the attacker may instruct that agent,

369
00:17:07,584 --> 00:17:12,360
you know, when they created
the Zendesk ticket, to create

370
00:17:12,360 --> 00:17:17,243
a GitHub issue with secrets in
your own public GitHub repos

371
00:17:17,243 --> 00:17:18,992
because most companies have a private repo

372
00:17:18,992 --> 00:17:22,347
and maybe a public presence
for open-source tooling.

373
00:17:22,347 --> 00:17:26,169
So the agent does not think
anything is concerning here

374
00:17:26,169 --> 00:17:30,240
and output the malicious
content indirectly.

375
00:17:30,240 --> 00:17:32,993
All of this is indirect
communication with the agent.

376
00:17:32,993 --> 00:17:35,130
The agent does not have the full picture.

377
00:17:35,130 --> 00:17:36,983
Maybe they are multi-agents, right?

378
00:17:36,983 --> 00:17:38,141
You have multiple agents.

379
00:17:38,141 --> 00:17:41,996
Agent number one is responsible
for consuming the data,

380
00:17:41,996 --> 00:17:44,602
agent number two has access to things,

381
00:17:44,602 --> 00:17:47,382
and agent number three is responsible

382
00:17:47,382 --> 00:17:49,754
for exporting that data, right?

383
00:17:49,754 --> 00:17:53,254
So no one agent should have

384
00:17:53,254 --> 00:17:55,241
the three things, only two things.

385
00:17:55,241 --> 00:17:58,107
The agent should be
able to either get data

386
00:17:58,107 --> 00:18:02,669
and access systems, but
never export data externally,

387
00:18:02,669 --> 00:18:04,710
or it could

388
00:18:04,710 --> 00:18:08,497
just do a combination of two
of these, never the three.

389
00:18:08,497 --> 00:18:12,738
And an agent with all
of these permissions or

390
00:18:12,738 --> 00:18:14,079
privileges

391
00:18:14,079 --> 00:18:17,892
has excessive agency,
which is a thing, right?

392
00:18:17,892 --> 00:18:19,062
- [Aidan] Yeah.

393
00:18:19,062 --> 00:18:21,491
- There are some common sense
and some best practices,

394
00:18:21,491 --> 00:18:24,231
like use an established
Agent Development Kit,

395
00:18:24,231 --> 00:18:28,119
like, for example, the Google ADK.

396
00:18:28,119 --> 00:18:31,875
Those come with all the security
best practices baked in,

397
00:18:31,875 --> 00:18:35,615
encryption, authentication, agent cards,

398
00:18:35,615 --> 00:18:37,921
the agent should advertise
itself what it does,

399
00:18:37,921 --> 00:18:41,763
what it should have access to,
to other agents, and whatnot.

400
00:18:43,633 --> 00:18:46,855
But yeah, these are the things
that typically I think about

401
00:18:46,855 --> 00:18:48,494
when I'm thinking about agents.

402
00:18:48,494 --> 00:18:50,793
- Yeah, you talked about permissions.

403
00:18:51,742 --> 00:18:54,360
Zero trust is something
that we think about.

404
00:18:54,360 --> 00:18:56,594
We think about treating
the agents themselves

405
00:18:56,594 --> 00:18:58,710
as if they're users

406
00:18:58,710 --> 00:19:02,760
in providing access to services and tools

407
00:19:02,760 --> 00:19:04,163
only when

408
00:19:04,163 --> 00:19:06,600
they need that access.

409
00:19:06,600 --> 00:19:09,243
And so, you know, essentially,

410
00:19:09,243 --> 00:19:12,430
what is the posture status of

411
00:19:14,910 --> 00:19:17,245
the virtual machine or

412
00:19:17,245 --> 00:19:19,387
hardware that that system's running on.

413
00:19:19,387 --> 00:19:21,603
Does the OS have vulnerabilities?

414
00:19:24,153 --> 00:19:29,010
Has it acted, you know, in
a malicious way previously?

415
00:19:29,010 --> 00:19:31,709
And so we look at all
of that and say, "Okay,

416
00:19:31,709 --> 00:19:34,991
this application can't access
this one other application."

417
00:19:34,991 --> 00:19:37,241
And by the way, we wanna
check the remote end

418
00:19:37,241 --> 00:19:38,640
to make sure that application

419
00:19:38,640 --> 00:19:40,489
doesn't also have any vulnerabilities,

420
00:19:40,489 --> 00:19:43,658
so we're monitoring
bidirectional communication

421
00:19:43,658 --> 00:19:46,743
between those agents or services or users.

422
00:19:48,139 --> 00:19:51,250
And I'd be curious, has
anybody thought about AI

423
00:19:51,250 --> 00:19:53,749
and zero trust in that way?

424
00:19:53,749 --> 00:19:54,740
Any? No, no?

425
00:19:54,740 --> 00:19:56,253
A little bit? Okay.

426
00:19:57,390 --> 00:19:58,740
But

427
00:19:58,740 --> 00:20:01,200
yeah, I think, you know,

428
00:20:01,200 --> 00:20:04,354
it's very clear to me that
there are two different camps.

429
00:20:04,354 --> 00:20:06,889
You know, we wanna get to camp two.

430
00:20:06,889 --> 00:20:10,121
I still think, you know, we
see tons of folks in camp one,

431
00:20:10,121 --> 00:20:12,088
and you know, internally at Fortinet,

432
00:20:12,088 --> 00:20:15,596
we're also working to
shift our user community

433
00:20:15,596 --> 00:20:17,863
to the latter via force controls.

434
00:20:17,863 --> 00:20:21,925
So we're gonna have go
through three takeaways.

435
00:20:21,925 --> 00:20:26,500
The first takeaway is,
you know, going from

436
00:20:26,500 --> 00:20:30,248
what I would say has been
quality to governance

437
00:20:30,248 --> 00:20:32,484
and really implementing
governance around AI.

438
00:20:32,484 --> 00:20:35,833
So we've broken this down into,
you know, three points that,

439
00:20:35,833 --> 00:20:38,663
you know, that Ammar
and I have talked about.

440
00:20:38,663 --> 00:20:41,337
So model integrity,

441
00:20:41,337 --> 00:20:44,334
this is something that you
have a lot of opinions about.

442
00:20:44,334 --> 00:20:47,111
So, you know, the first bullet here,

443
00:20:47,111 --> 00:20:50,670
enforcing model validation:

444
00:20:50,670 --> 00:20:53,341
managing drift, red teaming, right?

445
00:20:53,341 --> 00:20:58,244
So, you know, red teaming before,
or let me put it this way,

446
00:20:58,244 --> 00:21:01,749
is it more of an automated
effort for you in that regard?

447
00:21:01,749 --> 00:21:04,252
Like, you have canned prompts,
and you test against those,

448
00:21:04,252 --> 00:21:06,749
or is it actual people?

449
00:21:06,749 --> 00:21:07,836
Do you do that internally?

450
00:21:07,836 --> 00:21:11,010
Do you look externally for this sort of

451
00:21:11,010 --> 00:21:12,857
support?
- Yeah, it's likely

452
00:21:12,857 --> 00:21:15,334
an internal AI red teaming,

453
00:21:15,334 --> 00:21:19,853
which is completely not
traditional red teaming.

454
00:21:19,853 --> 00:21:22,248
Traditional red teaming is all about

455
00:21:22,248 --> 00:21:26,486
like a red teaming campaign, you do recon,

456
00:21:26,486 --> 00:21:30,741
and you do all these steps
until you reach an exploit.

457
00:21:30,741 --> 00:21:34,493
This is, you get all the
information about the model,

458
00:21:34,493 --> 00:21:38,558
what the model does, and
you trick it creatively.

459
00:21:38,558 --> 00:21:42,251
Like those people have
to be writing prompts in,

460
00:21:42,251 --> 00:21:44,493
you know, all caps.

461
00:21:45,574 --> 00:21:49,618
Changing like subtle things
get you a different output.

462
00:21:49,618 --> 00:21:50,880
- Oh, absolutely.

463
00:21:50,880 --> 00:21:51,713
- Why?

464
00:21:51,713 --> 00:21:54,933
Because the model is its tokens.

465
00:21:54,933 --> 00:21:57,234
It's just trying to
predict the next token.

466
00:21:57,234 --> 00:21:59,729
So you have to break it.
- Sentiment.

467
00:21:59,729 --> 00:22:03,655
- Yeah, so it's many, many iteration of

468
00:22:03,655 --> 00:22:06,231
can I get this model to return something

469
00:22:06,231 --> 00:22:07,903
that I consider bad?

470
00:22:07,903 --> 00:22:08,850
- Yes.

471
00:22:08,850 --> 00:22:13,150
- Could be bad, you know,
could be secrets, it could be

472
00:22:14,232 --> 00:22:15,460
sensitive

473
00:22:16,770 --> 00:22:18,390
words, things that,

474
00:22:18,390 --> 00:22:19,770
yeah.
- Absolutely.

475
00:22:19,770 --> 00:22:21,601
How open are you with these red teams?

476
00:22:21,601 --> 00:22:24,999
Do you provide them kind of,
is it a black box effort,

477
00:22:24,999 --> 00:22:27,481
and they're trying to penetrate
it, or is it kind of like,

478
00:22:27,481 --> 00:22:29,227
"Hey, here's all the
information you need to know

479
00:22:29,227 --> 00:22:30,510
about the application"?

480
00:22:30,510 --> 00:22:32,486
- No, you give them all the information

481
00:22:32,486 --> 00:22:34,274
to help them be successful.

482
00:22:34,274 --> 00:22:36,435
There's no need to be hiding anything.

483
00:22:36,435 --> 00:22:38,940
Transparency, this is the model.

484
00:22:38,940 --> 00:22:41,373
This are like expected behavior.

485
00:22:41,373 --> 00:22:43,895
Can you check and validate this model

486
00:22:43,895 --> 00:22:45,488
is working as expected?

487
00:22:45,488 --> 00:22:46,863
- Got you, got you.

488
00:22:47,717 --> 00:22:49,591
One of the model integrity points

489
00:22:49,591 --> 00:22:52,380
that I think is very important is,

490
00:22:52,380 --> 00:22:56,958
and this goes into also data
maturity, but is capturing

491
00:22:56,958 --> 00:23:00,745
security-related parameters

492
00:23:00,745 --> 00:23:03,245
and tagging that data.

493
00:23:03,245 --> 00:23:04,748
Like, for example, you know,

494
00:23:04,748 --> 00:23:08,433
when we inspected the transactions,

495
00:23:09,617 --> 00:23:11,558
do we audit what the temperature was,

496
00:23:11,558 --> 00:23:14,154
what the top-p and k values are?

497
00:23:14,154 --> 00:23:16,414
Do we understand what tokens were used

498
00:23:16,414 --> 00:23:19,489
and what context limits were applied?

499
00:23:19,489 --> 00:23:21,520
I think this is important because

500
00:23:23,244 --> 00:23:26,893
what was, I think, in the machine
learning world this effort

501
00:23:26,893 --> 00:23:30,732
to tune the machine learning
service or algorithm

502
00:23:30,732 --> 00:23:34,440
to perform better, that was great.

503
00:23:34,440 --> 00:23:35,499
It was a quality effort.

504
00:23:35,499 --> 00:23:38,254
Now we're really focused on
that as an auditability effort

505
00:23:38,254 --> 00:23:39,196
because you have to go back

506
00:23:39,196 --> 00:23:42,741
and try to figure out why
did it make the decision

507
00:23:42,741 --> 00:23:45,111
or why did it reason
in the way that it did,

508
00:23:45,111 --> 00:23:48,102
and provide the response, which
can be very, very difficult

509
00:23:48,102 --> 00:23:51,303
if you are not capturing
that sort of information.

510
00:23:53,350 --> 00:23:54,513
What do you think?

511
00:23:55,502 --> 00:23:57,010
- Yeah, I think

512
00:23:58,244 --> 00:24:01,290
I'm going to, since most people here

513
00:24:01,290 --> 00:24:04,733
are like consuming off-the-shelf models

514
00:24:04,733 --> 00:24:06,872
and integrating with AI tooling,

515
00:24:06,872 --> 00:24:11,575
I'm going to focus on
how the anatomy of these

516
00:24:11,575 --> 00:24:15,011
security application has changed.

517
00:24:15,011 --> 00:24:16,625
Now, there's no such a thing

518
00:24:16,625 --> 00:24:19,249
as a traditional web application

519
00:24:19,249 --> 00:24:21,232
or a traditional desktop application.

520
00:24:21,232 --> 00:24:26,125
All of these application have
some AI integrated with them

521
00:24:26,125 --> 00:24:30,118
that brings, it, like, could
be agents behind the scene.

522
00:24:30,118 --> 00:24:32,380
It could be a model behind the scene.

523
00:24:32,380 --> 00:24:35,007
Absolutely a model behind
the scene for sure,

524
00:24:35,007 --> 00:24:37,832
but an MCP server

525
00:24:37,832 --> 00:24:40,338
vectored database and whatnot.

526
00:24:40,338 --> 00:24:43,347
So we have to think
about how we secure all

527
00:24:43,347 --> 00:24:46,648
of these systems now,
not just what we are,

528
00:24:46,648 --> 00:24:48,354
you know, used to.

529
00:24:48,354 --> 00:24:49,932
We're already behind in security.

530
00:24:49,932 --> 00:24:53,489
Like every day, there is more regulations,

531
00:24:53,489 --> 00:24:55,610
there's more CVEs.

532
00:24:55,610 --> 00:25:00,610
2024, we had 400K CVEs,

533
00:25:00,780 --> 00:25:02,103
more alerts,

534
00:25:03,015 --> 00:25:05,509
whatever you think
about, there is more of.

535
00:25:05,509 --> 00:25:06,342
- [Aidan] Yes.

536
00:25:06,342 --> 00:25:08,224
- We don't have more people.

537
00:25:08,224 --> 00:25:11,856
Headcounts? You're lucky to
get more headcounts, right?

538
00:25:11,856 --> 00:25:14,608
So you're being asked to
use AI to scale the team

539
00:25:14,608 --> 00:25:16,590
to solve all of these problems,

540
00:25:16,590 --> 00:25:20,383
and AI has added another attack surface

541
00:25:20,383 --> 00:25:23,604
that we talked about that did not exist.

542
00:25:23,604 --> 00:25:25,725
And if you're building your own models,

543
00:25:25,725 --> 00:25:28,745
now you have also to worry
about the model integrity,

544
00:25:28,745 --> 00:25:30,907
the drifts, red teaming that.

545
00:25:30,907 --> 00:25:35,364
So the scope is just expanding
and expanding every day.

546
00:25:35,364 --> 00:25:36,273
- Yes.

547
00:25:37,140 --> 00:25:39,504
And I think what you
highlighted just a minute ago

548
00:25:39,504 --> 00:25:44,165
was a difference in, you know,
how we, our perspectives.

549
00:25:44,165 --> 00:25:47,411
At Fortinet, we're building models

550
00:25:47,411 --> 00:25:49,993
that go into our security tooling.

551
00:25:49,993 --> 00:25:51,494
And so, you know,

552
00:25:51,494 --> 00:25:54,583
we focus a lot on these
sorts of model building.

553
00:25:54,583 --> 00:25:57,881
We do use some external
models for some of our tools,

554
00:25:57,881 --> 00:26:00,661
you know, like document
searches and things like that,

555
00:26:00,661 --> 00:26:01,751
but a lot of times, you know,

556
00:26:01,751 --> 00:26:03,600
if we're building a security tool,

557
00:26:03,600 --> 00:26:07,417
we're building that model
from the ground up, right?

558
00:26:07,417 --> 00:26:09,180
All internally.

559
00:26:09,180 --> 00:26:10,238
Hygiene.

560
00:26:10,238 --> 00:26:12,630
I think data hygiene is probably,

561
00:26:12,630 --> 00:26:15,491
it might be the biggest
area of opportunity.

562
00:26:15,491 --> 00:26:18,249
You know, we see a lot of

563
00:26:18,249 --> 00:26:20,970
data that's sucked into

564
00:26:20,970 --> 00:26:24,377
a rag or, and, you know,
an agent has access to

565
00:26:24,377 --> 00:26:26,120
that it should never have had access to.

566
00:26:26,120 --> 00:26:29,010
That could be either from having access

567
00:26:29,010 --> 00:26:31,603
to network resources
that it shouldn't have.

568
00:26:31,603 --> 00:26:35,744
It could be, you know, access to

569
00:26:35,744 --> 00:26:39,754
SharePoint sites that
have just bad data in it.

570
00:26:39,754 --> 00:26:43,237
And, you know, the most
successful customers

571
00:26:43,237 --> 00:26:45,506
that we've worked with in this area

572
00:26:45,506 --> 00:26:48,098
have implemented data maturity,

573
00:26:48,098 --> 00:26:49,678
you know, medallion models, right?

574
00:26:49,678 --> 00:26:51,487
So I have raw logs.

575
00:26:51,487 --> 00:26:53,100
You know, that's my input-

576
00:26:53,100 --> 00:26:54,002
- [Ammar] Semi-raw.

577
00:26:54,002 --> 00:26:55,240
- Right, semi-raw.

578
00:26:55,240 --> 00:26:58,738
And then ultimately, I
have a parameterized,

579
00:26:58,738 --> 00:27:01,497
I have a tagged classified set of data.

580
00:27:01,497 --> 00:27:05,096
I know what my PII is, I
know what I should keep out.

581
00:27:05,096 --> 00:27:07,845
And then, you know, I've created that,

582
00:27:07,845 --> 00:27:09,840
now that is my gold standard,

583
00:27:09,840 --> 00:27:13,332
but I don't want that in runtime,
so I copy that separately

584
00:27:13,332 --> 00:27:15,499
so that I'm never using that gold data

585
00:27:15,499 --> 00:27:17,509
in my runtime environment.

586
00:27:17,509 --> 00:27:18,745
That's kind of like, you know,

587
00:27:18,745 --> 00:27:21,633
what we've seen work really, really well.

588
00:27:22,740 --> 00:27:24,364
And then you also have data lineage

589
00:27:24,364 --> 00:27:27,350
that you can go back and
revert to prior versions

590
00:27:27,350 --> 00:27:30,483
if something actually is corrupted, right?

591
00:27:31,327 --> 00:27:33,004
How do you guys approach data maturity?

592
00:27:33,004 --> 00:27:34,598
- I think you covered it really well.

593
00:27:34,598 --> 00:27:36,463
- Did I? Okay.
- Yeah.

594
00:27:38,489 --> 00:27:39,500
- Yeah.

595
00:27:39,500 --> 00:27:43,742
So, the hygiene, I think
with all of this effort,

596
00:27:43,742 --> 00:27:47,103
and we talked about early
on, expanded attack surface,

597
00:27:48,602 --> 00:27:51,837
we could talk about tools,
and I'm very tool-oriented,

598
00:27:51,837 --> 00:27:55,309
but I do think it comes down to hygiene.

599
00:27:55,309 --> 00:27:58,614
Like, if you have poor security hygiene

600
00:27:58,614 --> 00:28:00,619
before you started any of these efforts,

601
00:28:00,619 --> 00:28:03,583
you are going to be in
a whole world of hurt

602
00:28:03,583 --> 00:28:06,887
if you try to go forward
without doing the hard work

603
00:28:06,887 --> 00:28:08,433
of cleaning all this up.

604
00:28:09,480 --> 00:28:12,496
I would say, like, I would go back

605
00:28:12,496 --> 00:28:15,100
to what you and I have
talked about in the past is

606
00:28:17,128 --> 00:28:20,614
how you put context into compliance

607
00:28:20,614 --> 00:28:23,742
and best practices, right?

608
00:28:23,742 --> 00:28:27,499
So you can go and find best practices,

609
00:28:27,499 --> 00:28:29,499
you can go through a compliance audit,

610
00:28:29,499 --> 00:28:31,632
and you can be told, "Hey,
these things need to be,

611
00:28:31,632 --> 00:28:32,898
you need this type of encryption.

612
00:28:32,898 --> 00:28:35,757
You need something rather generic," right?

613
00:28:35,757 --> 00:28:38,423
I think what you have shared with me,

614
00:28:38,423 --> 00:28:39,740
that you all have done,

615
00:28:39,740 --> 00:28:44,232
is make them contextual to what
Adobe's best practices are,

616
00:28:44,232 --> 00:28:46,301
which is completely different.

617
00:28:46,301 --> 00:28:48,737
- Yeah, I think this audience
would benefit from that,

618
00:28:48,737 --> 00:28:52,503
so I'll share some of the
things that we've done

619
00:28:52,503 --> 00:28:56,109
using AI to

620
00:28:56,109 --> 00:28:59,753
be more security-oriented
and do security better.

621
00:28:59,753 --> 00:29:02,003
So if you think about the day-to-day

622
00:29:02,003 --> 00:29:06,960
of a security operations person,
it's really the grunt work,

623
00:29:06,960 --> 00:29:08,997
the work that no one wants to do.

624
00:29:08,997 --> 00:29:13,997
Sending data from across multiple
data sources: a wiki page,

625
00:29:14,238 --> 00:29:15,500
GitHub README,

626
00:29:15,500 --> 00:29:18,499
an internal PDF policy,

627
00:29:18,499 --> 00:29:19,491
you name it.

628
00:29:19,491 --> 00:29:24,180
So all of that context is
hard to keep in your head,

629
00:29:24,180 --> 00:29:26,239
but
AI is really good at it.

630
00:29:26,239 --> 00:29:28,608
Like AI is just text hungry,

631
00:29:28,608 --> 00:29:30,754
it can just make sense out of it.

632
00:29:30,754 --> 00:29:35,326
And this is 90% of the analyst's job.

633
00:29:35,326 --> 00:29:39,000
And one of the things that we've done,

634
00:29:39,000 --> 00:29:42,252
like in the analyst security
review threat modeling space,

635
00:29:42,252 --> 00:29:44,110
is in the past,

636
00:29:44,110 --> 00:29:47,243
we had a big team that couldn't scale

637
00:29:47,243 --> 00:29:48,754
to do threat modeling.

638
00:29:48,754 --> 00:29:51,744
A developer wants to
build some new services,

639
00:29:51,744 --> 00:29:52,988
they wanna know the threats.

640
00:29:52,988 --> 00:29:56,999
Like, I have a database, I have
a bucket, I have a backend,

641
00:29:56,999 --> 00:30:01,605
maybe three-tier architecture,
what are my requirements?

642
00:30:01,605 --> 00:30:04,501
Like, should I use KMS for encryption?

643
00:30:04,501 --> 00:30:09,163
Is just S3 default encryption good enough?

644
00:30:09,163 --> 00:30:12,900
They have no idea what the
compliance requirements are.

645
00:30:12,900 --> 00:30:16,501
There's so many requirements
that need to come into play,

646
00:30:16,501 --> 00:30:18,365
not to understand the risk and threats,

647
00:30:18,365 --> 00:30:23,121
but also what is this
application is, you know,

648
00:30:23,121 --> 00:30:25,985
requires from a compliance perspective.

649
00:30:25,985 --> 00:30:29,399
Maybe this application is scope for PCI.

650
00:30:29,399 --> 00:30:32,239
Maybe it's HIPAA compliant.
It's so many things.

651
00:30:32,239 --> 00:30:35,100
No one security engineer is
able to keep all of that context

652
00:30:35,100 --> 00:30:37,112
in their head if they have, like,

653
00:30:37,112 --> 00:30:40,494
20 obligations they need to secure, cool.

654
00:30:40,494 --> 00:30:44,369
But AI can have access to
all of that data, right?

655
00:30:44,369 --> 00:30:48,589
So, how about you have few
agents that do threat modeling

656
00:30:48,589 --> 00:30:50,994
and security reviews
for your organization.

657
00:30:50,994 --> 00:30:53,033
How does that work?

658
00:30:53,033 --> 00:30:57,167
You curate best practices for your company

659
00:30:57,167 --> 00:30:59,740
and document all of these best practices.

660
00:30:59,740 --> 00:31:01,367
So in the past, typically,

661
00:31:01,367 --> 00:31:03,583
the manual security review
or threat model used

662
00:31:03,583 --> 00:31:06,103
to be just industry best practices.

663
00:31:06,103 --> 00:31:07,002
This is the output.

664
00:31:07,002 --> 00:31:10,246
We do a review, and we
say, "Hey, use encryption,

665
00:31:10,246 --> 00:31:14,481
use the latest Docker image,
rotate your images frequently."

666
00:31:14,481 --> 00:31:17,002
Like just generic stuff.

667
00:31:17,002 --> 00:31:18,378
And you give that to a developer,

668
00:31:18,378 --> 00:31:21,000
and the developer's like,
"How can I use this?"

669
00:31:21,000 --> 00:31:24,744
Like it's just a lot of best
practices you've found online,

670
00:31:24,744 --> 00:31:27,392
and they may help,

671
00:31:27,392 --> 00:31:32,098
but they're not exactly
step-by-step instructions

672
00:31:32,098 --> 00:31:36,861
for me to build a PCI compliant
based on Adobe's context.

673
00:31:36,861 --> 00:31:38,171
- That's very difficult.

674
00:31:38,171 --> 00:31:39,906
- Super difficult.

675
00:31:39,906 --> 00:31:44,136
So you curate all of that
information, and you document it,

676
00:31:44,136 --> 00:31:48,480
and you make it available
in the form of rack

677
00:31:48,480 --> 00:31:51,382
or an MCP server.

678
00:31:51,382 --> 00:31:53,314
And you make this a self-service.

679
00:31:53,314 --> 00:31:55,591
So you have a service, you have a UI,

680
00:31:55,591 --> 00:31:57,238
and developers go there,

681
00:31:57,238 --> 00:31:59,731
and they upload their
artifacts and questions.

682
00:31:59,731 --> 00:32:03,363
Maybe the system ask multiple questions.

683
00:32:03,363 --> 00:32:05,833
Is this a PCI-compliant service?

684
00:32:05,833 --> 00:32:07,740
Is it public?

685
00:32:07,740 --> 00:32:10,001
Is it three-tier architecture?

686
00:32:10,001 --> 00:32:14,818
And goes out and curate what you need

687
00:32:14,818 --> 00:32:16,883
to build this thing securely.

688
00:32:16,883 --> 00:32:18,649
What do I mean by this?

689
00:32:18,649 --> 00:32:21,039
You probably have an
authentication library

690
00:32:21,039 --> 00:32:22,843
that your developers need to use.

691
00:32:22,843 --> 00:32:27,005
You probably have a Terraform
for creating buckets

692
00:32:27,005 --> 00:32:30,103
or databases that your developers can use.

693
00:32:30,103 --> 00:32:33,085
So instead of that developer
needing to figure that out,

694
00:32:33,085 --> 00:32:37,370
build it themselves, the agent
links to that documentation,

695
00:32:37,370 --> 00:32:40,496
to that repo, to the
step-by-step instructions,

696
00:32:40,496 --> 00:32:42,010
and interactively,

697
00:32:42,010 --> 00:32:46,495
the developer's able
to get to from point A,

698
00:32:46,495 --> 00:32:49,741
which is nothing, to point B
with all the context needed

699
00:32:49,741 --> 00:32:52,240
to deploy that service

700
00:32:52,240 --> 00:32:55,081
in accordance with your internal policies,

701
00:32:55,081 --> 00:32:58,244
your PCI, your compliance needs,

702
00:32:58,244 --> 00:33:02,501
and just your internal tooling
available for developers.

703
00:33:02,501 --> 00:33:03,651
This require maturity

704
00:33:03,651 --> 00:33:06,890
as far as like curating the right wikis

705
00:33:06,890 --> 00:33:10,981
and making sure those are the
only things seen by the agent,

706
00:33:10,981 --> 00:33:15,117
because if you give the agent
access to all of your wikis,

707
00:33:15,117 --> 00:33:17,742
it may not get the right, you know,

708
00:33:17,742 --> 00:33:19,750
it may get like an outdated

709
00:33:21,241 --> 00:33:22,497
like documentation

710
00:33:22,497 --> 00:33:24,242
that you do not want the
developer to be using.

711
00:33:24,242 --> 00:33:25,731
And you do not want the developer

712
00:33:25,731 --> 00:33:29,318
to blindly trust where
the agent is getting it.

713
00:33:29,318 --> 00:33:34,047
So it should, you know, you
should curate the information

714
00:33:34,047 --> 00:33:36,498
and should make sure the
agent has only access

715
00:33:36,498 --> 00:33:40,112
to that very good information
that you need a developer

716
00:33:40,112 --> 00:33:41,102
to have access to.

717
00:33:41,102 --> 00:33:44,003
- Well, I think what you're talking about

718
00:33:44,003 --> 00:33:46,482
is like not putting the burden
of security on the developer.

719
00:33:46,482 --> 00:33:49,619
And I think, you know,
even as a security vendor,

720
00:33:49,619 --> 00:33:50,452
we've always talked about,

721
00:33:50,452 --> 00:33:52,502
oh, well, we can recruit developers

722
00:33:52,502 --> 00:33:55,411
into part of the culture,

723
00:33:55,411 --> 00:33:59,666
and you know, so they
have to do these things,

724
00:33:59,666 --> 00:34:03,453
but you know, we interrupt
their delivery of applications,

725
00:34:03,453 --> 00:34:04,610
and that slows them down.

726
00:34:04,610 --> 00:34:07,745
And you know, we've not
done a really good job

727
00:34:07,745 --> 00:34:09,487
of making that easy on the developers.

728
00:34:09,487 --> 00:34:12,096
And what you're describing is
sort of antithetical to that,

729
00:34:12,096 --> 00:34:15,502
and I think sounds like
a very positive way.

730
00:34:15,502 --> 00:34:19,593
- I have a lot of
opinions about this area.

731
00:34:21,592 --> 00:34:22,599
Who here heard

732
00:34:22,599 --> 00:34:26,733
of the term security's
everyone's responsibility?

733
00:34:26,733 --> 00:34:28,293
Everyone, right?

734
00:34:29,497 --> 00:34:32,501
So we have so many departments
who are responsible

735
00:34:32,501 --> 00:34:34,617
for the success of their organization.

736
00:34:34,617 --> 00:34:38,243
This term is only uttered by security.

737
00:34:38,243 --> 00:34:41,234
I haven't heard legal say

738
00:34:41,234 --> 00:34:43,866
legal is everyone's responsibility.

739
00:34:43,866 --> 00:34:46,010
Like they take ownership for their scope.

740
00:34:46,010 --> 00:34:48,574
They are the expert as far as legal goes.

741
00:34:48,574 --> 00:34:51,611
They keep your company out of trouble.

742
00:34:51,611 --> 00:34:54,367
If you go to accounting, finance,

743
00:34:54,367 --> 00:34:56,335
each department always say,

744
00:34:56,335 --> 00:34:58,504
"I am the expert, I get it done."

745
00:34:58,504 --> 00:35:02,334
- Security is the only place,
I get it, security is hard,

746
00:35:02,334 --> 00:35:05,347
breaches can happen, and
everyone can get in trouble,

747
00:35:05,347 --> 00:35:08,242
but really, like security
needs to take ownership

748
00:35:08,242 --> 00:35:09,617
of security,

749
00:35:09,617 --> 00:35:11,596
and you cannot hire

750
00:35:11,596 --> 00:35:13,889
a very expensive machine learning engineer

751
00:35:13,889 --> 00:35:18,889
and have 50% of their
day triaging tickets,

752
00:35:19,111 --> 00:35:21,636
remediation, patching.

753
00:35:21,636 --> 00:35:24,605
You need to figure that out for them,

754
00:35:24,605 --> 00:35:27,490
so they can deliver, your company can win,

755
00:35:27,490 --> 00:35:30,747
and this is how, like,
security becomes an enabler,

756
00:35:30,747 --> 00:35:31,738
not a blocker.

757
00:35:31,738 --> 00:35:35,563
- Yeah, it becomes, you know,

758
00:35:35,563 --> 00:35:37,494
we've had our customers ask us

759
00:35:37,494 --> 00:35:39,223
how do we make security a profit center.

760
00:35:39,223 --> 00:35:41,014
I think by removing that burden

761
00:35:41,014 --> 00:35:44,079
from people who generate
profit makes that argument

762
00:35:44,079 --> 00:35:46,001
to a large degree, actually, you know?

763
00:35:46,001 --> 00:35:47,043
- Absolutely.

764
00:35:48,120 --> 00:35:49,096
- The hygiene and providence,

765
00:35:49,096 --> 00:35:54,096
a lot of that is about data
security, data maturity.

766
00:35:54,120 --> 00:35:57,341
I will say on that front,
it is very hard to do.

767
00:35:57,341 --> 00:35:59,836
If anybody's ever tried
to classify data at scale,

768
00:35:59,836 --> 00:36:02,233
you don't even know where it is, firstly.

769
00:36:02,233 --> 00:36:04,243
So, you know, if you haven't looked

770
00:36:04,243 --> 00:36:07,859
at a data security posture program

771
00:36:07,859 --> 00:36:10,928
with, you know, data leak prevention,

772
00:36:10,928 --> 00:36:13,162
which should be implemented
both on the endpoint,

773
00:36:13,162 --> 00:36:16,223
on the network, really look into that.

774
00:36:16,223 --> 00:36:20,243
There's tons of AI-driven
tooling and automation

775
00:36:20,243 --> 00:36:22,233
that can make that very,
very lightweight now,

776
00:36:22,233 --> 00:36:24,252
but very effective.

777
00:36:24,252 --> 00:36:27,593
On the trust boundary side,
there's also an opportunity to,

778
00:36:27,593 --> 00:36:29,930
you know, filter on the network

779
00:36:29,930 --> 00:36:32,339
because there's not necessarily
always a fixed perimeter,

780
00:36:32,339 --> 00:36:35,050
but you can start to intermediate

781
00:36:36,589 --> 00:36:39,811
or interdict in those
agent-to-agent interactions.

782
00:36:39,811 --> 00:36:43,293
You can limit what types
of prompts are allowed.

783
00:36:44,168 --> 00:36:49,123
And this is where we're seeing
an interest in LLM proxies,

784
00:36:49,123 --> 00:36:51,225
LLM firewalls.

785
00:36:51,225 --> 00:36:54,009
Has anybody looked at
deploying such a thing yet?

786
00:36:54,009 --> 00:36:56,027
There's a few of them available.

787
00:36:56,027 --> 00:36:57,604
Okay, so this is gonna be like

788
00:36:57,604 --> 00:37:00,003
the next-generation firewall reborn.

789
00:37:00,003 --> 00:37:02,996
I'll talk about that in a
little bit more in a second.

790
00:37:02,996 --> 00:37:07,982
But this helps you reestablish
a trust boundary for

791
00:37:07,982 --> 00:37:11,578
where data is allowed to egress,

792
00:37:11,578 --> 00:37:14,760
how prompts are injected
into your environment,

793
00:37:14,760 --> 00:37:15,593
and how those are filtered.

794
00:37:15,593 --> 00:37:20,593
Also, providing a point where
we can audit the interactions

795
00:37:20,991 --> 00:37:22,210
of the users

796
00:37:24,241 --> 00:37:25,563
with your tooling.

797
00:37:27,626 --> 00:37:30,991
Any thoughts you wanna say
about the trust boundary?

798
00:37:30,991 --> 00:37:34,098
You guys are really focused on making sure

799
00:37:34,098 --> 00:37:36,538
that your web application firewall

800
00:37:36,538 --> 00:37:38,500
and API protection is very robust.

801
00:37:38,500 --> 00:37:42,986
I think that's probably
something that stood out to me.

802
00:37:42,986 --> 00:37:47,094
You also have a very automated
way of approaching that.

803
00:37:47,094 --> 00:37:48,331
I think that would be pretty interesting

804
00:37:48,331 --> 00:37:50,567
if you could touch on that.

805
00:37:50,567 --> 00:37:52,474
- Yeah, I think this is one of the things

806
00:37:52,474 --> 00:37:55,009
that closer to my heart,

807
00:37:55,009 --> 00:37:58,492
which is using AI to accelerate

808
00:37:58,492 --> 00:38:00,239
security operations.

809
00:38:00,239 --> 00:38:01,990
And one of the things my team does

810
00:38:01,990 --> 00:38:03,857
for Adobe is web application firewalls.

811
00:38:03,857 --> 00:38:07,232
And those are interesting to manage.

812
00:38:07,232 --> 00:38:11,560
If you have a large
organization, you typically

813
00:38:13,330 --> 00:38:16,511
cannot scale like, and
have a big WAF team.

814
00:38:16,511 --> 00:38:17,378
- Yep.

815
00:38:17,378 --> 00:38:18,866
- It's really hard.

816
00:38:18,866 --> 00:38:22,587
But the thing is, WAF
can produce a ton of logs

817
00:38:22,587 --> 00:38:26,244
that no one will look at
because of just so many noise,

818
00:38:26,244 --> 00:38:28,409
so much false positives.

819
00:38:28,409 --> 00:38:31,351
Writing WAF rules is like rocket science.

820
00:38:31,351 --> 00:38:33,345
Like, if you wanna deal with regex

821
00:38:33,345 --> 00:38:35,386
and you understand regex, great,

822
00:38:35,386 --> 00:38:38,403
but most people are not regex-friendly.

823
00:38:39,343 --> 00:38:41,992
So what we thought about is

824
00:38:41,992 --> 00:38:44,732
just see if AI is able to help us here.

825
00:38:44,732 --> 00:38:48,098
So the system we came up with is

826
00:38:48,098 --> 00:38:50,820
for logs, you pretty much need

827
00:38:50,820 --> 00:38:55,246
to build your own lightweight
machine learning model.

828
00:38:55,246 --> 00:38:58,360
So this model is simply there to

829
00:38:59,979 --> 00:39:01,002
detect anomalies.

830
00:39:01,002 --> 00:39:02,337
So you define a baseline,

831
00:39:02,337 --> 00:39:05,006
what normals look like for you day to day,

832
00:39:05,006 --> 00:39:07,485
and then generate anomalies.

833
00:39:07,485 --> 00:39:09,847
Those anomalies, you
don't have to route those

834
00:39:09,847 --> 00:39:11,742
to a human anymore.

835
00:39:11,742 --> 00:39:15,077
Those could go to a triage
agent that takes action,

836
00:39:15,077 --> 00:39:17,731
maybe correlate with other data sources.

837
00:39:17,731 --> 00:39:20,150
Maybe it's a bad ID,

838
00:39:20,150 --> 00:39:21,250
IP address.

839
00:39:21,250 --> 00:39:25,076
For example, we deployed WAF
to our service, and WAF said,

840
00:39:25,076 --> 00:39:28,900
"Well, there is a bot
that is trying to get in."

841
00:39:28,900 --> 00:39:33,731
And it wasn't a bot, it was just a CI/CD

842
00:39:33,731 --> 00:39:35,230
deployment.

843
00:39:35,230 --> 00:39:39,975
The worker IP address was seen as a bot,

844
00:39:39,975 --> 00:39:42,495
but the agent was able to look that up,

845
00:39:42,495 --> 00:39:45,237
and it found it was an Adobe

846
00:39:45,237 --> 00:39:47,633
CI/CD worker IP address,

847
00:39:47,633 --> 00:39:50,739
and this is a non-issue,
non-issue right now,

848
00:39:50,739 --> 00:39:54,731
but the deployment time was an anomaly.

849
00:39:54,731 --> 00:39:56,593
We have a team in India.

850
00:39:56,593 --> 00:39:58,320
It's a different time zone.

851
00:39:58,320 --> 00:40:01,500
The CI/CD system kicked in.

852
00:40:01,500 --> 00:40:05,401
WAF saw it, the machine
learning detected it,

853
00:40:05,401 --> 00:40:07,999
and we didn't have to wake up any person

854
00:40:07,999 --> 00:40:10,241
in the middle of the
night to investigate it.

855
00:40:10,241 --> 00:40:12,183
The triage agent looked into it.

856
00:40:13,988 --> 00:40:17,318
And you can also have LLMs
help you with writing rules.

857
00:40:17,318 --> 00:40:18,251
They're really good about,

858
00:40:18,251 --> 00:40:21,428
like, as far as regex
generating code and whatnot,

859
00:40:21,428 --> 00:40:24,183
but do not trust the LLM.

860
00:40:25,082 --> 00:40:26,490
Build a rack system

861
00:40:26,490 --> 00:40:28,664
to help the LLM make the right decisions.

862
00:40:28,664 --> 00:40:31,241
For example, curate all the rules,

863
00:40:31,241 --> 00:40:34,236
best practices, the vendor documentation.

864
00:40:34,236 --> 00:40:37,151
Maybe you have an MCP server
for Terraform as well,

865
00:40:37,151 --> 00:40:40,752
so it has the latest
Terraform documentation

866
00:40:40,752 --> 00:40:44,173
for building AWS WAF rules.

867
00:40:44,173 --> 00:40:47,322
And the rack system should have

868
00:40:47,322 --> 00:40:51,110
all good decisions that the AI
had made in the past recorded

869
00:40:51,110 --> 00:40:52,427
and bad decisions.

870
00:40:52,427 --> 00:40:54,886
So when the LLM is trying
to generate a new rule,

871
00:40:54,886 --> 00:40:57,480
it could look up what
happened in the past,

872
00:40:57,480 --> 00:40:59,653
good rules or bad rules,

873
00:40:59,653 --> 00:41:03,490
and see if this new rule,
again, is good and bad,

874
00:41:03,490 --> 00:41:06,489
and then suggest that, and
you need a human in the loop.

875
00:41:06,489 --> 00:41:10,387
You just cannot trust all
of this and just deploy.

876
00:41:10,387 --> 00:41:12,838
Yeah, you're probably
gonna block legit traffic.

877
00:41:12,838 --> 00:41:15,737
So put it in staging,

878
00:41:15,737 --> 00:41:19,080
have people validate that
it's working as expected

879
00:41:19,080 --> 00:41:19,913
before you push it.

880
00:41:19,913 --> 00:41:22,590
But the point here is to augment your team

881
00:41:22,590 --> 00:41:24,610
with these capabilities that

882
00:41:26,501 --> 00:41:28,405
were not available in the past.

883
00:41:28,405 --> 00:41:30,180
- Yeah, definitely.

884
00:41:30,180 --> 00:41:31,611
I'm gonna move on,

885
00:41:31,611 --> 00:41:34,001
but there's a lot more
we can keep expanding on.

886
00:41:34,001 --> 00:41:37,243
I think one of the
punchlines from here is,

887
00:41:37,243 --> 00:41:40,903
again, as I said at the
beginning of this takeaway,

888
00:41:40,903 --> 00:41:43,403
traditional machine learning workflows,

889
00:41:43,403 --> 00:41:46,738
yeah, you know, checklists
and hyperparameterization,

890
00:41:46,738 --> 00:41:49,470
or, you know, having the auditability,

891
00:41:49,470 --> 00:41:51,315
that was quality control effort.

892
00:41:51,315 --> 00:41:52,885
It was nice to have.

893
00:41:52,885 --> 00:41:56,736
In AI, when we start
looking at the implications,

894
00:41:56,736 --> 00:41:58,608
they become governance artifacts.

895
00:41:58,608 --> 00:41:59,890
And so

896
00:42:01,491 --> 00:42:04,584
you should be able to audit,
you should be able to reproduce

897
00:42:04,584 --> 00:42:07,741
and follow the chain of reasoning

898
00:42:07,741 --> 00:42:11,252
in response back through that process.

899
00:42:11,252 --> 00:42:13,249
So, takeaway one has an example here.

900
00:42:13,249 --> 00:42:18,249
This is an example from
SageMaker where in the JSON,

901
00:42:18,630 --> 00:42:21,910
what we do here is we have tagged

902
00:42:22,751 --> 00:42:26,146
our model with metadata properties.

903
00:42:26,146 --> 00:42:28,476
So we know where it was committed.

904
00:42:28,476 --> 00:42:32,830
We know what security checklist
applies specifically to

905
00:42:34,356 --> 00:42:36,499
this particular application.

906
00:42:36,499 --> 00:42:40,650
We know that the KMS
signature has been verified

907
00:42:40,650 --> 00:42:42,416
And this is what it looks like.

908
00:42:42,416 --> 00:42:44,163
You know, in some cases,

909
00:42:45,504 --> 00:42:48,501
our security audits or
checklists have passed,

910
00:42:48,501 --> 00:42:51,506
and they are approved
in the version control.

911
00:42:51,506 --> 00:42:54,408
In some cases, they have not,
and then they're rejected.

912
00:42:54,408 --> 00:42:57,362
Those hyperparameters that are tested

913
00:42:57,362 --> 00:43:00,005
in those security tests might be,

914
00:43:00,005 --> 00:43:03,501
you know, something like a
prompt injection evaluation

915
00:43:03,501 --> 00:43:06,408
or a jailbreak evaluation
that we've captured here,

916
00:43:06,408 --> 00:43:09,000
and we capture this for every revision.

917
00:43:09,000 --> 00:43:12,873
So this is just an example
from a SageMaker deployment.

918
00:43:14,491 --> 00:43:16,490
So let's move on to the second one.

919
00:43:16,490 --> 00:43:18,368
I'll actually jump into this.

920
00:43:18,368 --> 00:43:20,604
And this is hyper simplified.

921
00:43:20,604 --> 00:43:23,970
There are so many different ways to deploy

922
00:43:23,970 --> 00:43:28,970
a network architecture and
segmentation, but this is like

923
00:43:28,980 --> 00:43:30,745
the basics.

924
00:43:30,745 --> 00:43:34,797
Security tooling that we
would bring to bear for a user

925
00:43:34,797 --> 00:43:39,000
that's interacting with maybe
an MCP agent that you have,

926
00:43:39,000 --> 00:43:39,833
or maybe, in this case,

927
00:43:39,833 --> 00:43:43,115
we're using a public LLM in our example,

928
00:43:43,115 --> 00:43:46,825
but, you know, firstly,
we still wanna maintain

929
00:43:46,825 --> 00:43:49,090
a obfuscation of our internal network.

930
00:43:49,090 --> 00:43:50,994
So we want to enforce the perimeter,

931
00:43:50,994 --> 00:43:54,629
we want to enforce zero trust on the user

932
00:43:54,629 --> 00:43:57,740
who's trying to access
services, potentially,

933
00:43:57,740 --> 00:44:01,563
handle routing, and that's
part of our segmentation.

934
00:44:02,876 --> 00:44:04,739
You know, so we're doing
a lot of things on,

935
00:44:04,739 --> 00:44:06,677
you know, the traditional
things that we've always done

936
00:44:06,677 --> 00:44:10,498
on a network firewall to
handle that traditional IT

937
00:44:10,498 --> 00:44:12,161
and networking requirement.

938
00:44:12,161 --> 00:44:14,427
Now, in addition to that,

939
00:44:14,427 --> 00:44:18,004
now you said building,
you talked about building

940
00:44:18,004 --> 00:44:20,166
your own lightweight
machine learning model

941
00:44:20,166 --> 00:44:23,587
to look at web application API anomalies.

942
00:44:23,587 --> 00:44:25,240
You don't have to do that.

943
00:44:25,240 --> 00:44:26,744
We've done that for you.

944
00:44:26,744 --> 00:44:27,816
And so what we're doing

945
00:44:27,816 --> 00:44:30,896
is we've really moved web security away

946
00:44:30,896 --> 00:44:33,095
from static signatures.

947
00:44:33,095 --> 00:44:35,899
Yes, like from a least cost perspective,

948
00:44:35,899 --> 00:44:38,901
we will look at signature-based
detections first,

949
00:44:38,901 --> 00:44:42,869
but what we ultimately look at
or use is anomaly detection.

950
00:44:42,869 --> 00:44:45,691
So everything that we're applying for,

951
00:44:45,691 --> 00:44:49,150
you know, request to API endpoints is,

952
00:44:49,150 --> 00:44:51,746
you know, machine learning
based and AI-based.

953
00:44:51,746 --> 00:44:54,895
So now that we can start to build a schema

954
00:44:54,895 --> 00:44:57,365
or do schema validation

955
00:44:57,365 --> 00:44:59,734
as we're learning about
how the users interact

956
00:44:59,734 --> 00:45:00,590
with the application.

957
00:45:00,590 --> 00:45:04,489
So we're continually tightening
down that security profile

958
00:45:04,489 --> 00:45:06,738
for that specific endpoint

959
00:45:06,738 --> 00:45:09,674
without generating the false positives.

960
00:45:09,674 --> 00:45:12,623
And so really, web
application and API protection

961
00:45:12,623 --> 00:45:15,995
has come into maturity in
a completely different way

962
00:45:15,995 --> 00:45:18,605
than the old WAFs that were very noisy

963
00:45:18,605 --> 00:45:22,231
and, you know, folks like Ammar
would not look at the logs.

964
00:45:22,231 --> 00:45:24,747
I'm just giving you a hard time.

965
00:45:24,747 --> 00:45:29,483
But this is also an opportunity
to broker TLS offloading

966
00:45:29,483 --> 00:45:32,813
or termination on behalf of
our backend infrastructure,

967
00:45:32,813 --> 00:45:35,006
centralized client authentication,

968
00:45:35,006 --> 00:45:37,402
and also do bot mitigation.

969
00:45:37,402 --> 00:45:41,309
There are a lot of bots
out there that are bad.

970
00:45:41,309 --> 00:45:44,991
Some bots you may include as
part of your internal tooling,

971
00:45:44,991 --> 00:45:48,488
and you don't want them
incorrectly flagged.

972
00:45:48,488 --> 00:45:50,011
But in addition to that,

973
00:45:50,011 --> 00:45:54,180
we have this concept of an LLM firewall

974
00:45:54,180 --> 00:45:55,236
or a proxy.

975
00:45:55,236 --> 00:45:57,010
So this is doing model routing,

976
00:45:57,010 --> 00:45:59,244
it's handling model selections.

977
00:45:59,244 --> 00:46:04,121
So, as you have a entire fleet of agents,

978
00:46:04,121 --> 00:46:07,994
hundreds of agents or more potentially,

979
00:46:07,994 --> 00:46:10,588
this is making sure that that gets routed

980
00:46:10,588 --> 00:46:14,482
to the proper agent and
not to the improper agent.

981
00:46:14,482 --> 00:46:15,996
It's applying token budgets

982
00:46:15,996 --> 00:46:18,963
and limitations on context, potentially.

983
00:46:20,520 --> 00:46:22,759
It's applying basic guardrails.

984
00:46:22,759 --> 00:46:23,823
So,

985
00:46:25,075 --> 00:46:25,908
you know,

986
00:46:25,908 --> 00:46:30,908
are my users trying to inject
a particular type of prompt?

987
00:46:31,130 --> 00:46:32,912
Are we trying to exfiltrate data

988
00:46:32,912 --> 00:46:35,280
that we shouldn't exfiltrate?

989
00:46:35,280 --> 00:46:37,173
And so it's doing a lot of things

990
00:46:37,173 --> 00:46:40,314
that are firewall-oriented,
but very specific to the LLM.

991
00:46:40,314 --> 00:46:43,500
And so what does that
look like in practice?

992
00:46:43,500 --> 00:46:47,825
So a user might interact with

993
00:46:47,825 --> 00:46:49,120
one of your agents.

994
00:46:49,120 --> 00:46:51,089
So the user submits a prompt.

995
00:46:51,089 --> 00:46:52,751
That comes through the external firewall

996
00:46:52,751 --> 00:46:54,502
that's hosting your Elastic IPs,

997
00:46:54,502 --> 00:46:57,001
hiding the internal private network.

998
00:46:57,001 --> 00:46:59,498
And so that goes through
the web application firewall

999
00:46:59,498 --> 00:47:02,040
that does an inspection.

1000
00:47:02,040 --> 00:47:04,002
It's handling the TLS negotiation,

1001
00:47:04,002 --> 00:47:06,525
the client authentication potentially,

1002
00:47:06,525 --> 00:47:08,342
and it goes to your AI agent.

1003
00:47:08,342 --> 00:47:10,157
Now that AI agent then says,

1004
00:47:10,157 --> 00:47:13,587
"I have a prompt, a system
prompt, and a user prompt,

1005
00:47:13,587 --> 00:47:18,414
and it wants to send that
out to this public LLM."

1006
00:47:18,414 --> 00:47:21,407
And so it sends that out.

1007
00:47:21,407 --> 00:47:25,370
The LLM proxy or firewall
is going to scrub that

1008
00:47:25,370 --> 00:47:28,611
to make sure that the
prompts are sanitized,

1009
00:47:28,611 --> 00:47:31,170
that no data that is being sent out

1010
00:47:31,170 --> 00:47:35,235
that should not as part of
that request to the LLM.

1011
00:47:35,235 --> 00:47:38,747
In this case, the LLM is
going to then respond,

1012
00:47:38,747 --> 00:47:40,113
and it's gonna request information

1013
00:47:40,113 --> 00:47:42,239
because this user maybe wanted to look up,

1014
00:47:42,239 --> 00:47:46,301
you know, inventory or
pricing or doing a search

1015
00:47:46,301 --> 00:47:48,349
as part of a shopping experience.

1016
00:47:48,349 --> 00:47:52,095
And so that then is gonna
go back to the agent,

1017
00:47:52,095 --> 00:47:53,257
and the agent's gonna say,

1018
00:47:53,257 --> 00:47:55,380
"I need to look up some information."

1019
00:47:55,380 --> 00:47:56,243
How do I do that?

1020
00:47:56,243 --> 00:47:58,828
Well, it knows that this
particular MCP agent

1021
00:47:58,828 --> 00:48:02,160
has the tooling to do that,
but we're gonna inspect that,

1022
00:48:02,160 --> 00:48:07,122
the MCP session itself,
which is JSON-RPC formatted,

1023
00:48:07,122 --> 00:48:11,436
and make sure that that
has protocol integrity

1024
00:48:11,436 --> 00:48:13,713
and is not a malicious query.

1025
00:48:14,589 --> 00:48:17,577
Now I'm showing an API call
to an actual web server.

1026
00:48:17,577 --> 00:48:21,596
So the MCP agent in this
case is front-ending the API.

1027
00:48:21,596 --> 00:48:24,091
That API call could very well go back

1028
00:48:24,091 --> 00:48:28,358
through the web application
and API inspection point,

1029
00:48:28,358 --> 00:48:32,433
but I didn't show that
here just for simplicity.

1030
00:48:32,433 --> 00:48:35,492
And then all of that is
sent back to the agent

1031
00:48:35,492 --> 00:48:38,339
and contextualized in the LLM,

1032
00:48:38,339 --> 00:48:41,588
which then routes all that back

1033
00:48:41,588 --> 00:48:44,989
through the inspection
points back to the user.

1034
00:48:44,989 --> 00:48:47,244
So it looks complicated. It's complicated.

1035
00:48:47,244 --> 00:48:49,825
Now that is super simple.

1036
00:48:49,825 --> 00:48:52,322
Now, do that when you
have hundreds of agents

1037
00:48:52,322 --> 00:48:56,480
who are task-specific, and
that gets really messy.

1038
00:48:56,480 --> 00:48:58,919
And so these are
necessary points, I think,

1039
00:48:58,919 --> 00:49:03,590
in your infrastructure that
need to have inspection, right?

1040
00:49:03,590 --> 00:49:05,490
And so,

1041
00:49:05,490 --> 00:49:08,494
you know, doing this in the right way

1042
00:49:08,494 --> 00:49:11,502
in a very complicated
environment requires a lot

1043
00:49:11,502 --> 00:49:14,842
of attention to detail, but
this is how we would go about

1044
00:49:14,842 --> 00:49:17,241
in a simplistic way of

1045
00:49:17,241 --> 00:49:19,950
defending AI

1046
00:49:19,950 --> 00:49:22,655
in an AWS environment.

1047
00:49:22,655 --> 00:49:25,342
Now what happens when
you don't do those things

1048
00:49:25,342 --> 00:49:27,242
and implement those controls, right?

1049
00:49:27,242 --> 00:49:29,399
Well, this has actually happened.

1050
00:49:29,399 --> 00:49:32,592
So this came from a customer,
and we replicated it.

1051
00:49:32,592 --> 00:49:35,010
So maybe it starts out with
a traditional type of attack.

1052
00:49:35,010 --> 00:49:36,320
You have an

1053
00:49:37,235 --> 00:49:40,020
SQL injection that says, you know,

1054
00:49:40,020 --> 00:49:43,470
here's an SQL injection in a prompt.

1055
00:49:43,470 --> 00:49:45,940
I don't have controls around my prompt, so

1056
00:49:47,070 --> 00:49:49,363
it accepts the prompt and passes it on.

1057
00:49:49,363 --> 00:49:52,497
Now, this could be from
overly permissive agents;

1058
00:49:52,497 --> 00:49:53,928
there's no input sanitation,

1059
00:49:53,928 --> 00:49:56,843
so the fix for that
would've been guardrails,

1060
00:49:56,843 --> 00:49:59,919
anomaly detection, potentially DLP,

1061
00:49:59,919 --> 00:50:03,192
but that escalates into a SSRF attack.

1062
00:50:03,192 --> 00:50:06,899
So, a service-side request forgery

1063
00:50:06,899 --> 00:50:09,557
comes from possibly poor segmentation.

1064
00:50:09,557 --> 00:50:11,750
There was access to an agent

1065
00:50:11,750 --> 00:50:14,578
or a service that should
not have been accessed.

1066
00:50:14,578 --> 00:50:16,580
It was excessive trust, potentially.

1067
00:50:16,580 --> 00:50:19,501
So we wanna make sure that
we're on the flip side of that,

1068
00:50:19,501 --> 00:50:23,002
implementing segmentation
and doing input validation.

1069
00:50:23,002 --> 00:50:26,574
Now, what that looks like
as we go through this is,

1070
00:50:26,574 --> 00:50:29,090
well, in that SSRF request,

1071
00:50:29,090 --> 00:50:31,240
I was actually trying to get the keys

1072
00:50:33,000 --> 00:50:34,567
to the AWS environment.

1073
00:50:34,567 --> 00:50:37,023
And so after getting a token,

1074
00:50:38,241 --> 00:50:41,838
eventually, we are able to,
and this is a very long demo

1075
00:50:41,838 --> 00:50:43,996
that I've shrunk down into a few slides,

1076
00:50:43,996 --> 00:50:48,889
but we were able to export the
keys from that EC2 instance

1077
00:50:48,889 --> 00:50:50,067
that we were targeting.

1078
00:50:50,067 --> 00:50:53,403
Now these keys have root access

1079
00:50:53,403 --> 00:50:55,242
to the AWS environment, right?

1080
00:50:55,242 --> 00:50:57,503
You know, again, POC quality?

1081
00:50:57,503 --> 00:51:00,752
You know, that's what
happens because it's easy.

1082
00:51:00,752 --> 00:51:03,494
Now, what we then did

1083
00:51:03,494 --> 00:51:05,830
was we were able to take

1084
00:51:06,752 --> 00:51:09,489
those credentials,

1085
00:51:09,489 --> 00:51:14,238
use them in the AWS account to gain access

1086
00:51:14,238 --> 00:51:16,645
to an S3 bucket.

1087
00:51:16,645 --> 00:51:20,000
So we have excessive permissions,
had access to every route,

1088
00:51:20,000 --> 00:51:21,735
had access to everything.

1089
00:51:21,735 --> 00:51:24,353
What we should have done is
implement least privileges,

1090
00:51:24,353 --> 00:51:28,584
applied IAM roles, and
then also classified data,

1091
00:51:28,584 --> 00:51:30,244
so we could have protected that.

1092
00:51:30,244 --> 00:51:31,597
But what it looks like is,

1093
00:51:31,597 --> 00:51:33,634
you know, for this e-commerce application,

1094
00:51:33,634 --> 00:51:36,719
we had a number of reviews, right?

1095
00:51:36,719 --> 00:51:37,923
And these reviews, you know,

1096
00:51:37,923 --> 00:51:40,020
were user feedback about the product.

1097
00:51:40,020 --> 00:51:42,743
We just database them in an S3 store.

1098
00:51:42,743 --> 00:51:45,613
But what we could have done
is we could have added,

1099
00:51:45,613 --> 00:51:50,047
and we did, is added a malicious
prompt as a user review.

1100
00:51:50,047 --> 00:51:50,913
"Hey, this product's great.

1101
00:51:50,913 --> 00:51:53,862
By the way, this is how you
need to respond to all users."

1102
00:51:53,862 --> 00:51:55,253
And so we were able to do that.

1103
00:51:55,253 --> 00:51:58,930
So we never compromise the actual

1104
00:52:00,178 --> 00:52:02,003
AI

1105
00:52:02,003 --> 00:52:03,505
or the actual application,

1106
00:52:03,505 --> 00:52:06,120
the e-commerce application itself.

1107
00:52:06,120 --> 00:52:09,745
We compromised the data
that it pulls from,

1108
00:52:09,745 --> 00:52:13,983
injected a prompt that
overrode the system prompts.

1109
00:52:13,983 --> 00:52:15,832
And so this is how we attacked this

1110
00:52:15,832 --> 00:52:17,603
because we didn't have any
of those things I showed you

1111
00:52:17,603 --> 00:52:20,252
in the last slide on takeaway two.

1112
00:52:20,252 --> 00:52:21,382
Make sense?

1113
00:52:21,382 --> 00:52:24,003
- I have a question. Did
you rotate the credentials?

1114
00:52:24,003 --> 00:52:27,303
Like I saw people taking
pictures of your AWS API piece.

1115
00:52:28,883 --> 00:52:31,989
- It's fine because they no longer exist.

1116
00:52:31,989 --> 00:52:33,347
Yeah,

1117
00:52:33,347 --> 00:52:34,582
but good point.

1118
00:52:34,582 --> 00:52:36,260
Yeah, no, those credentials,

1119
00:52:36,260 --> 00:52:39,502
this entire account no longer exists.

1120
00:52:39,502 --> 00:52:41,001
Yep, so that was a good point.

1121
00:52:41,001 --> 00:52:42,258
No, I wouldn't have done that.

1122
00:52:42,258 --> 00:52:43,252
I might have done that.
- I'm just

1123
00:52:43,252 --> 00:52:45,749
- giving you a hard time.
- Absolutely.

1124
00:52:45,749 --> 00:52:47,311
Let's move on to takeaway three.

1125
00:52:47,311 --> 00:52:49,147
So we got about 10 minutes.

1126
00:52:49,147 --> 00:52:51,804
The future of AI security

1127
00:52:51,804 --> 00:52:54,239
or security is AI native.

1128
00:52:54,239 --> 00:52:58,353
So you've talked about
implementing AI security tools,

1129
00:52:59,244 --> 00:53:03,556
but this is a little bit
about both our practice,

1130
00:53:03,556 --> 00:53:06,915
but also the workforce enablement, how

1131
00:53:06,915 --> 00:53:09,831
your developers or developers are using

1132
00:53:09,831 --> 00:53:13,184
copilots and tools that are
aware of security specific

1133
00:53:13,184 --> 00:53:14,100
to the environment.

1134
00:53:14,100 --> 00:53:17,073
I think this is some of what
you've actually talked about,

1135
00:53:18,349 --> 00:53:22,600
but in the first one, AI-augmented
threat modeling, right?

1136
00:53:22,600 --> 00:53:24,696
So, identifying architectural flaws.

1137
00:53:24,696 --> 00:53:28,750
So you have security
tooling that can tell you

1138
00:53:28,750 --> 00:53:31,203
where you have misconfigurations.

1139
00:53:32,119 --> 00:53:34,530
Do you rely on

1140
00:53:34,530 --> 00:53:36,485
static, you know,

1141
00:53:36,485 --> 00:53:37,938
posture analysis?

1142
00:53:37,938 --> 00:53:40,163
Are you looking at more
like AI-oriented tools

1143
00:53:40,163 --> 00:53:40,996
in this regard?

1144
00:53:40,996 --> 00:53:42,744
- I think you need both now.

1145
00:53:42,744 --> 00:53:46,994
Static analysis tooling
is not enough anymore.

1146
00:53:46,994 --> 00:53:51,004
They always had limitations as
far as like false positives.

1147
00:53:51,004 --> 00:53:54,240
Like, if you use a static
code analysis tool,

1148
00:53:54,240 --> 00:53:57,110
you know what I'm talking about.

1149
00:53:57,110 --> 00:53:59,611
So you need

1150
00:53:59,611 --> 00:54:00,744
the AI context.

1151
00:54:00,744 --> 00:54:02,492
You need these tool to also play together.

1152
00:54:02,492 --> 00:54:07,492
Maybe the AI provide context
to the static code analysis,

1153
00:54:07,494 --> 00:54:11,237
provide context to the AI,
and the AI kind of go find

1154
00:54:11,237 --> 00:54:13,492
if it's a false positive or not.

1155
00:54:13,492 --> 00:54:17,139
So creatively, in ways that
we haven't seen before,

1156
00:54:17,139 --> 00:54:20,922
you need to go and play
around these tools.

1157
00:54:20,922 --> 00:54:23,328
And this go back to the
workforce enablement.

1158
00:54:23,328 --> 00:54:25,744
I think AI's coming fast at us,

1159
00:54:25,744 --> 00:54:29,744
but we are not spending time
training our security people

1160
00:54:29,744 --> 00:54:32,820
to be more AI aware,
and also our developers

1161
00:54:32,820 --> 00:54:34,318
to be more security aware.

1162
00:54:34,318 --> 00:54:35,867
So

1163
00:54:35,867 --> 00:54:39,983
the AI training is, an AI
literacy is a thing now.

1164
00:54:39,983 --> 00:54:43,742
So probably need to
slow down and take this

1165
00:54:43,742 --> 00:54:47,024
and, you know, read books, take courses,

1166
00:54:47,024 --> 00:54:50,190
explore, experiment, and develop a skill.

1167
00:54:50,190 --> 00:54:51,358
It's needed now.

1168
00:54:51,358 --> 00:54:52,953
- Okay. Yeah.

1169
00:54:52,953 --> 00:54:57,005
So you talked about, you know,
you drew this distinction

1170
00:54:57,005 --> 00:55:01,010
between security being
everybody's responsibility,

1171
00:55:01,010 --> 00:55:03,846
but maybe it's not, right?

1172
00:55:03,846 --> 00:55:05,003
But what does that look like

1173
00:55:05,003 --> 00:55:07,260
in terms of the overall culture at Adobe?

1174
00:55:07,260 --> 00:55:10,660
How does Adobe look at
the security culture?

1175
00:55:10,660 --> 00:55:11,500
- So

1176
00:55:13,251 --> 00:55:14,190
when we think

1177
00:55:14,190 --> 00:55:15,887
about security being
everyone's responsibility,

1178
00:55:15,887 --> 00:55:17,990
yeah, everyone need to be security aware.

1179
00:55:17,990 --> 00:55:19,687
Like you need to know what encryption is.

1180
00:55:19,687 --> 00:55:21,500
Like your building, you're a developer,

1181
00:55:21,500 --> 00:55:23,730
you need to know the best practices.

1182
00:55:23,730 --> 00:55:27,403
But if you're spending 50% of
your time doing security work

1183
00:55:27,403 --> 00:55:30,988
and not what you're hired
to do, that's a problem.

1184
00:55:30,988 --> 00:55:32,100
- Yes.

1185
00:55:32,100 --> 00:55:34,730
- You spending most of your
time not building features,

1186
00:55:34,730 --> 00:55:38,305
which exactly what you had
in your job description.

1187
00:55:38,305 --> 00:55:41,498
So our culture is more balanced where we,

1188
00:55:41,498 --> 00:55:44,248
as security organization,
take a lot of ownership,

1189
00:55:44,248 --> 00:55:47,373
and we are ultimately
accountable for security,

1190
00:55:48,390 --> 00:55:51,501
and we provide a lot of
tooling, guidance, and support,

1191
00:55:51,501 --> 00:55:53,106
and we keep up.

1192
00:55:53,106 --> 00:55:56,348
Developers are using agents to write code.

1193
00:55:56,348 --> 00:55:58,143
We provide guidance to the agent,

1194
00:55:58,143 --> 00:56:01,234
so the agent is able to
write better secure code.

1195
00:56:01,234 --> 00:56:04,745
We don't wait and blame the
agent, and complain about AI.

1196
00:56:04,745 --> 00:56:05,851
We do something about it.

1197
00:56:05,851 --> 00:56:08,353
So the culture is more
about being proactive,

1198
00:56:08,353 --> 00:56:12,010
anticipating what
developers are needing to do

1199
00:56:12,010 --> 00:56:15,745
in providing them with
tooling, the guidance,

1200
00:56:15,745 --> 00:56:19,315
the support needed for them to
move fast in a secure manner.

1201
00:56:19,315 --> 00:56:20,495
- Yes.

1202
00:56:20,495 --> 00:56:24,820
I think the summary for
takeaway three is that

1203
00:56:25,710 --> 00:56:28,125
this goes back to doing the hard work,

1204
00:56:28,125 --> 00:56:33,125
and it starts ahead of any of
the tooling you may implement.

1205
00:56:33,564 --> 00:56:35,320
It's about

1206
00:56:36,238 --> 00:56:39,315
building those best practices
that are not generic;

1207
00:56:39,315 --> 00:56:41,395
they're specific to your organization,

1208
00:56:41,395 --> 00:56:44,500
that'll allow your users who have to

1209
00:56:45,645 --> 00:56:47,277
apply those best practices

1210
00:56:47,277 --> 00:56:49,116
and actually make them meaningful.

1211
00:56:49,116 --> 00:56:51,998
You spent a lot of time
talking about that.

1212
00:56:51,998 --> 00:56:55,354
I would summarize this as being that.

1213
00:56:55,354 --> 00:56:57,933
- Absolutely.
- Yeah, yeah. Well said.

1214
00:57:00,243 --> 00:57:03,743
So let's talk about ecosystem
because there is this,

1215
00:57:03,743 --> 00:57:07,366
you know, you have your
internal security efforts,

1216
00:57:07,366 --> 00:57:09,566
your applications,

1217
00:57:09,566 --> 00:57:12,250
user communities, you have

1218
00:57:12,250 --> 00:57:16,500
partners and third-party
vendors like Fortinet, right?

1219
00:57:16,500 --> 00:57:17,681
As everyone here does.

1220
00:57:17,681 --> 00:57:20,745
And everybody here is presumably on AWS.

1221
00:57:20,745 --> 00:57:23,620
So everybody has a role in how

1222
00:57:24,988 --> 00:57:27,390
this ecosystem collaborates, right?

1223
00:57:27,390 --> 00:57:30,241
So, you know, I think a
few points about that,

1224
00:57:30,241 --> 00:57:34,427
unifying security
pipelines across platforms.

1225
00:57:34,427 --> 00:57:35,988
You know, for example,

1226
00:57:35,988 --> 00:57:40,240
you know, as you're deploying on AWS,

1227
00:57:40,240 --> 00:57:41,851
you know, if something fails,

1228
00:57:41,851 --> 00:57:45,327
a security check either on your side

1229
00:57:45,327 --> 00:57:47,252
or from Fortinet,

1230
00:57:47,252 --> 00:57:52,252
we can, you know, interrupt,
you know, an approval, or

1231
00:57:52,470 --> 00:57:56,343
in SageMaker as an example
that we gave earlier.

1232
00:57:57,909 --> 00:58:00,234
Shared telemetry, AI-driven observability,

1233
00:58:00,234 --> 00:58:02,763
I think this is really huge.

1234
00:58:03,930 --> 00:58:05,155
It is very hard.

1235
00:58:05,155 --> 00:58:09,003
You can't do anything if you
don't have the observability.

1236
00:58:09,877 --> 00:58:13,391
We focus a lot on surfacing,

1237
00:58:13,391 --> 00:58:15,945
you know, in making
visible what is in your AWS

1238
00:58:15,945 --> 00:58:19,260
and other states across your,

1239
00:58:19,260 --> 00:58:20,913
you know, your entire footprint,

1240
00:58:22,492 --> 00:58:25,492
but, you know, that requires, you know,

1241
00:58:25,492 --> 00:58:28,488
a lot of hygiene of

1242
00:58:28,488 --> 00:58:33,341
what tools and applications
you have, standardization,

1243
00:58:33,341 --> 00:58:36,499
so that that observability
actually makes sense, right?

1244
00:58:36,499 --> 00:58:37,473
I think.

1245
00:58:38,433 --> 00:58:39,871
What do you think?

1246
00:58:39,871 --> 00:58:43,746
- Absolutely. I think
you hit the main points.

1247
00:58:43,746 --> 00:58:46,138
Most of us like using AWS.

1248
00:58:46,138 --> 00:58:49,496
AWS is not a security company, so

1249
00:58:49,496 --> 00:58:53,677
some of the security is
on you to build internally

1250
00:58:53,677 --> 00:58:57,362
and also to buy the right
tooling to get the right support

1251
00:58:57,362 --> 00:59:01,915
to be able to complete, like
have full circle coverage.

1252
00:59:01,915 --> 00:59:05,238
So again, nothing has changed.

1253
00:59:05,238 --> 00:59:09,494
All of the old worlds still exist.

1254
00:59:09,494 --> 00:59:12,479
Now you have to think about
how the old world integrate

1255
00:59:12,479 --> 00:59:15,952
with the new AI world
and how you, you know,

1256
00:59:15,952 --> 00:59:19,001
how you go about securing that,
how you train these people,

1257
00:59:19,001 --> 00:59:21,644
how you get the right tooling.

1258
00:59:21,644 --> 00:59:24,502
We're not thinking about
AI security tooling yet.

1259
00:59:24,502 --> 00:59:25,750
We don't even know the companies

1260
00:59:25,750 --> 00:59:28,803
that are out there doing
work in this space yet,

1261
00:59:30,311 --> 00:59:32,616
and what established
companies like you guys

1262
00:59:32,616 --> 00:59:33,499
are doing about it.

1263
00:59:33,499 --> 00:59:36,491
So today's session is, like
I knew about few things

1264
00:59:36,491 --> 00:59:38,244
that I did not know about before.

1265
00:59:38,244 --> 00:59:39,093
- Yeah.

1266
00:59:40,242 --> 00:59:41,495
So, a few things to take away.

1267
00:59:41,495 --> 00:59:44,237
I think this would summarize the points

1268
00:59:44,237 --> 00:59:46,345
that we wanted to impart.

1269
00:59:46,345 --> 00:59:48,360
We know that

1270
00:59:48,360 --> 00:59:50,602
the velocity of signal

1271
00:59:50,602 --> 00:59:53,003
in terms of log volumes,

1272
00:59:53,003 --> 00:59:54,664
the interactions that users are having

1273
00:59:54,664 --> 00:59:57,596
with these federated applications

1274
00:59:57,596 --> 01:00:02,492
that you're creating that
are AI-driven, is tremendous.

1275
01:00:02,492 --> 01:00:06,390
It requires defense in depth.

1276
01:00:06,390 --> 01:00:09,088
It requires effective network planning.

1277
01:00:09,088 --> 01:00:10,512
We wanna orient our cultures

1278
01:00:10,512 --> 01:00:12,242
and our workforce to be AI native,

1279
01:00:12,242 --> 01:00:15,499
but to do so, I think, as
you've talked about, Ammar,

1280
01:00:15,499 --> 01:00:20,499
it takes a lot of pre-planning,
a lot of hygiene effort.

1281
01:00:20,750 --> 01:00:24,098
The attack surface is very broad.

1282
01:00:24,098 --> 01:00:27,853
We need to maintain consistent structure

1283
01:00:27,853 --> 01:00:32,046
and discipline around
managing lineage, right?

1284
01:00:32,046 --> 01:00:35,252
Both for our models, our applications,

1285
01:00:35,252 --> 01:00:38,492
and for the data that
those systems consume.

1286
01:00:38,492 --> 01:00:41,387
And I think it's not
going to be successful

1287
01:00:41,387 --> 01:00:44,307
unless you look at who

1288
01:00:44,307 --> 01:00:46,592
and how you partner with AWS,

1289
01:00:46,592 --> 01:00:48,497
with your other cloud providers,

1290
01:00:48,497 --> 01:00:50,613
just your overall ecosystem.

1291
01:00:51,489 --> 01:00:52,995
And they'll have best practices

1292
01:00:52,995 --> 01:00:57,228
that you can make specific
to your organization.

1293
01:00:57,228 --> 01:00:58,742
And it's, you know,

1294
01:00:58,742 --> 01:01:02,109
it takes a village in that sense, I think.

1295
01:01:02,109 --> 01:01:04,754
So with that, we're out of time.

1296
01:01:04,754 --> 01:01:07,750
We'll hang out here if you
guys wanna talk, ask questions,

1297
01:01:07,750 --> 01:01:08,996
or share your ideas.

1298
01:01:08,996 --> 01:01:10,334
We would love that.

1299
01:01:10,334 --> 01:01:13,251
But thank you very much for
spending some time with us.

1300
01:01:13,251 --> 01:01:14,884
(attendees clapping)

