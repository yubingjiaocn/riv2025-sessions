# AWS re:Invent 2025 AI安全会议总结

## 会议概述

本次AWS re:Invent 2025分组会议聚焦于AI时代的安全挑战与最佳实践。会议由Fortinet的云、SaaS和AI工程负责人与Adobe的DevOps团队负责人Omar共同主持,两位演讲者从安全工具提供商和企业AI应用实践者的不同视角,探讨了AI应用安全的演变。

会议强调,AI的引入并未取代传统安全基础,而是在原有安全体系之上增加了新的攻击面。演讲者指出,从2019年到2030年这段时期将成为人类历史上的重要时刻,AI技术的快速发展正在从根本上改变应用程序的构建、攻击和防御方式。与传统静态、确定性的应用环境不同,AI系统具有推理能力,输出结果具有不确定性,这要求安全团队在保持传统安全措施(如VPC、IAM策略、纵深防御)的同时,还需应对模型投毒、未授权访问、恶意提示和数据泄露等新型威胁。

会议特别强调了从"质量保证"向"治理"转变的重要性,提出了三大核心要点:模型完整性、数据卫生和信任边界。演讲者通过Adobe的实际案例,展示了如何将AI代理视为用户进行权限管理,如何实施数据成熟度模型,以及如何利用AI工具本身来提升安全运营效率。会议还讨论了MCP服务器的安全风险、零信任架构在AI环境中的应用,以及如何通过自动化威胁建模和安全审查来减轻开发人员的安全负担,使安全成为业务推动者而非阻碍者。

## 详细时间线与关键要点

### 开场与背景介绍 (0:00-5:30)
- **0:00** - 会议开始,演讲者介绍本次会议主题:AI如何从根本上改变安全实践
- **1:15** - 现场调查:大部分参会者负责保护AI工作负载或被要求使用AI工具
- **2:20** - Omar强调2019-2030年将成为人类历史的重要时刻,AI的影响堪比电力、互联网的发明
- **3:10** - 讨论AI应用部署速度过快,安全团队常常后知后觉的现状
- **4:00** - Omar介绍自己作为Adobe DevOps团队负责人和AWS社区建设者的背景

### AI安全的新挑战 (5:30-12:00)
- **5:30** - 演讲者说明AI为应用增加了新的推理层,但传统安全问题依然存在
- **6:45** - Omar强调基础安全原则未改变:纵深防御、AWS账户配置、VPC、IAM策略仍然重要
- **7:30** - 介绍典型AI技术栈:数据管道、代理(Agents)、LLM智能
- **8:20** - 讨论攻击面扩大:AI系统真正实现了无边界化
- **9:00** - 列举主要风险:模型投毒、未授权访问、恶意提示、数据泄露
- **10:15** - 现场调查:了解参会者中有多少在内部构建模型,多少使用现成模型
- **11:00** - Omar指出使用第三方AI工具时的安全关注点:数据泄露、访问控制、向量数据库安全

### MCP服务器安全讨论 (12:00-16:30)
- **12:00** - 讨论MCP(Model Context Protocol)服务器的便利性与风险
- **12:45** - 演讲者询问Adobe如何看待供应商提供的MCP与开源MCP的区别
- **13:20** - Omar强调信任供应商的MCP与使用未经审查的远程开源MCP的差异
- **14:10** - 警告:未经审查的MCP可能导致OS注入攻击,窃取凭证
- **15:00** - 建议:谨慎对待开源远程MCP,就像对待不可信的第三方库一样

### OWASP LLM Top 10与安全成熟度 (16:30-22:00)
- **16:30** - 介绍OWASP针对LLM和生成式AI的Top 10安全风险
- **17:15** - 讨论两类AI应用成熟度:POC级别与生产级别
- **18:00** - POC级别问题:代理间通信未验证、推理循环未验证、缺乏遥测和可观测性
- **19:20** - 强调审计的重要性:需要审计基础设施和代理推理过程
- **20:30** - 生产级别最佳实践:隔离代理、控制推理链、持续日志记录
- **21:15** - Omar介绍Adobe将代理视为用户的安全理念

### 代理安全的三个维度 (22:00-28:00)
- **22:00** - Omar提出代理安全的三个关键问题:数据来源、访问权限、输出目的地
- **23:00** - 案例:Zendesk票据中的恶意指令可能被复制到内部Jira系统
- **24:15** - 攻击场景:代理可能被诱导将机密信息输出到公共GitHub仓库
- **25:30** - 提出"过度代理权限"概念:单个代理不应同时拥有获取数据、访问系统和导出数据的全部权限
- **26:45** - 建议使用成熟的代理开发工具包(如Google ADK),内置安全最佳实践
- **27:30** - 强调代理应通过"代理卡片"向其他代理声明自己的功能和权限

### 零信任架构应用于AI (28:00-31:00)
- **28:00** - 讨论将零信任原则应用于AI代理
- **28:45** - 将代理视为用户,仅在需要时提供服务和工具访问权限
- **29:30** - 检查代理运行环境的安全态势:OS漏洞、历史行为
- **30:15** - 双向通信监控:确保通信双方都没有漏洞
- **30:45** - 现场调查:很少有人考虑过AI与零信任的结合

### 核心要点一:从质量到治理 (31:00-40:00)
- **31:00** - 提出从质量保证向治理转变的重要性
- **31:45** - 模型完整性:强制模型验证、管理漂移、红队测试
- **32:30** - 讨论AI红队测试:与传统渗透测试完全不同,需要创造性地编写提示
- **33:45** - Omar说明红队测试需要提供完整信息,采用透明方式
- **34:30** - 强调捕获安全相关参数的重要性:温度、top-P、top-K值、令牌使用、上下文限制
- **35:45** - 这些参数从质量调优转变为审计需求,用于追溯推理过程
- **37:00** - Omar指出大多数参会者使用现成模型,需关注应用架构的变化
- **38:15** - 强调AI增加了新的攻击面,但基础安全工作仍需做好
- **39:00** - 2024年有40万个CVE,安全团队人手不足,需要AI来扩展能力

### 核心要点二:数据卫生与成熟度 (40:00-48:00)
- **40:00** - Fortinet视角:为安全工具构建内部模型
- **41:00** - 数据卫生:可能是最大的机会领域
- **41:45** - 问题:代理常常访问不应访问的数据(网络资源、SharePoint站点)
- **42:30** - 成功案例:实施数据成熟度的奖章模型(Medallion Model)
- **43:15** - 数据分层:原始日志 → 半原始数据 → 参数化/标记/分类的黄金标准数据
- **44:00** - 关键实践:识别PII,创建黄金标准,但在运行时使用副本而非黄金数据
- **45:00** - 数据血缘:能够回溯到先前版本,应对数据损坏
- **46:30** - 强调安全卫生的重要性:如果基础安全卫生差,AI项目将面临巨大困难

### 利用AI提升安全运营 (48:00-56:00)
- **48:00** - Omar分享Adobe如何使用AI改善安全运营
- **48:45** - 安全分析师的日常工作:从多个数据源整合信息(Wiki、GitHub、PDF政策)
- **49:30** - AI擅长处理大量文本信息,这占分析师工作的90%
- **50:15** - 案例:自动化威胁建模和安全审查
- **51:00** - 过去问题:威胁建模团队无法扩展,开发者不了解合规要求
- **52:00** - 开发者困惑:应该使用KMS加密还是S3默认加密?需要满足哪些合规要求(PCI、HIPAA)?
- **53:15** - 解决方案:使用AI代理进行威胁建模和安全审查
- **54:00** - 策划公司最佳实践并文档化,通过RAG或MCP服务器提供给代理
- **54:45** - 自助服务:开发者上传工件和问题,系统询问多个问题后生成定制化安全要求

### 安全作为推动者而非阻碍者 (56:00-62:00)
- **56:00** - 代理根据公司特定上下文提供逐步指导
- **56:45** - 输出包括:认证库链接、Terraform模板、部署说明
- **57:30** - 开发者能够从零到完成,符合内部政策和合规要求
- **58:15** - 前提:需要策划正确的Wiki,确保代理只访问准确的最新文档
- **59:00** - 演讲者评论:这将安全负担从开发者身上移除
- **59:45** - Omar的观点:"安全是每个人的责任"这句话只有安全部门在说
- **60:30** - 其他部门(法务、财务)都明确自己是专家,只有安全部门推卸责任
- **61:15** - 不能让昂贵的机器学习工程师花50%时间处理安全工单
- **61:45** - 安全应该成为推动者,而非阻碍者

### 核心要点三:信任边界 (62:00-结束)
- **62:00** - 讨论数据安全态势管理(DSPM)和数据泄露防护(DLP)
- **62:45** - 建议:在端点和网络上实施DLP,使用AI驱动的工具实现轻量级但有效的保护
- **63:30** - 信任边界:虽然没有固定边界,但可以在代理间交互中进行拦截
- **64:15** - 介绍LLM代理和LLM防火墙:下一代防火墙的重生
- **65:00** - 功能:限制允许的提示类型,过滤数据出口,审计用户与工具的交互
- **65:45** - 现场调查:少数人了解LLM防火墙
- **66:30** - 强调Adobe在Web应用防火墙(WAF)和API保护方面的自动化实践

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


会议核心结论:
1. AI安全需要在传统安全基础上增加新的治理层
2. 将代理视为用户,实施最小权限原则和零信任架构
3. 数据成熟度和卫生是成功的关键
4. 利用AI本身来自动化安全运营,使安全成为业务推动者
5. 安全团队应该承担专家责任,而不是将责任推给开发者