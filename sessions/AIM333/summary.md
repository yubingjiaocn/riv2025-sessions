# AWS re:Invent 2025 会议总结：可持续且高效的生成式 AI 与智能体工作流

## 会议概述

本次 AWS re:Invent 2025 分会场聚焦于如何构建可持续且成本高效的生成式 AI 系统。两位 AWS 高级解决方案架构师 Isha Dua 和 Parth Patel 深入探讨了人工智能发展带来的环境挑战，以及如何在生成式 AI 的整个生命周期中实施优化策略。

会议指出，尽管 AI 模型承诺解决重大挑战，但其发展本身却导致了严重的环境危机。数据中心的能源消耗在 2021 年后急剧增加，模型训练规模在过去几年中增长了 35 万倍。Goldman Sachs 的研究预测，到 2025 年 8 月，约 60% 的 AI 电力需求将通过燃烧化石燃料满足，预计产生 2.15-2.2 亿吨二氧化碳排放。面对这一严峻形势，演讲者强调了开发者、科学家和云服务提供商的共同责任，需要通过硬件效率、算法优化、数据中心设计和冷却技术等多方面的创新来缓解碳足迹的快速增长。

会议详细介绍了生成式 AI 生命周期的四个关键阶段（问题定义、模型训练/适配、模型部署/推理、监控优化），并在每个阶段提供了具体的可持续性优化建议。特别强调了 Amazon Bedrock 等托管服务的优势，以及智能体 AI 系统在实现复杂目标导向任务中的应用价值。

## 详细时间线与关键要点

### 开场介绍 (00:00 - 02:30)
- **00:00** - 会议开始，Isha Dua 和 Parth Patel 介绍自己为 AWS 高级解决方案架构师
- **01:15** - 会议主题确定：可持续且成本高效的生成式 AI 与智能体工作流
- **02:00** - 强调 AI 发展带来的环境危机悖论

### 生成式 AI 的环境影响 (02:30 - 06:00)
- **02:45** - 数据中心能源消耗历史：十多年来维持在 100 太瓦时左右
- **03:20** - 2021 年后能源消耗急剧上升的转折点
- **03:45** - 模型训练规模增长 35 万倍的惊人数据
- **04:10** - Goldman Sachs 研究：60% 的 AI 电力需求将由化石燃料满足
- **04:35** - 预计产生 2.15-2.2 亿吨二氧化碳排放
- **05:00** - 类比说明：燃油车行驶 5000 英里产生约 1 吨二氧化碳
- **05:30** - 世界经济论坛数据：能源需求每 100 天翻倍

### AWS 的可持续性承诺 (06:00 - 08:30)
- **06:15** - 2019 年 AWS 签署气候承诺
- **06:45** - 2023 年实现 100% 可再生能源运营目标
- **07:20** - AWS 云比本地部署能效高 4.1 倍
- **07:50** - 硬件效率、优化芯片、冷却技术、低碳混凝土等创新
- **08:10** - 迁移到 AWS 可降低高达 90% 的碳足迹

### 生成式 AI 生命周期概述 (08:30 - 10:00)
- **08:45** - 四个主要阶段介绍
- **09:00** - 阶段一：问题定义（Problem Framing）
- **09:15** - 阶段二：模型训练或适配（Model Training/Adaptation）
- **09:30** - 阶段三：模型部署与推理（Deployment & Inference）
- **09:45** - 阶段四：持续监控与优化（Monitoring & Optimization）

### 阶段一：问题定义优化 (10:00 - 14:30)
- **10:15** - 核心问题：是否真的需要生成式 AI？
- **10:45** - 评估标准：是否可用简单规则引擎或传统机器学习解决
- **11:20** - 推荐使用托管服务如 Amazon Bedrock
- **11:50** - Bedrock 提供 200+ 模型，包括 Anthropic、Amazon、Cohere、Llama、Stability、Meta、Mistral 等
- **12:30** - Bedrock 功能：微调、RAG、护栏、负责任 AI
- **13:00** - 模型选择原则：最大最亮的模型不一定是最佳选择
- **13:30** - 选择标准：开源 vs 专有、多语言支持、参数规模、通用 vs 领域特定
- **14:00** - 案例：Stanford Alpaca（70 亿参数）与 ChatGPT-3.5（1750 亿参数）性能相似

### 模型选择与评估 (14:30 - 17:00)
- **14:45** - Nova 模型系列成本对比示例
- **15:15** - Bedrock Evaluations 功能介绍
- **15:45** - 三种评估方式：LLM 作为评判者、传统指标（BLEU、F1）、人工评估
- **16:20** - 评估流程：定义任务类型、自定义提示、设置评估指标、比较结果

### 阶段二：模型训练与适配策略 (17:00 - 22:00)
- **17:15** - 渐进式优化策略图表介绍
- **17:45** - 第一步：提示工程（Prompt Engineering）- 最低成本和碳排放
- **18:20** - 第二步：检索增强生成（RAG）- 提供专有信息和上下文
- **18:50** - RAG 应用案例：汽车公司使用服务手册作为知识库
- **19:20** - 第三步：参数高效微调（PEFT）如 LoRA、前缀调优
- **19:50** - 第四步：全量微调（Full Fine-tuning）
- **20:20** - 最后选择：从头训练模型 - 最资源密集、最昂贵、最耗时
- **21:00** - Bedrock 视角的决策树：静态数据用 RAG，实时数据用 Agents

### 从头训练的最佳实践 (22:00 - 24:30)
- **22:15** - 必须从头训练时的建议
- **22:40** - 使用托管服务：SageMaker、SageMaker HyperPod、EKS
- **23:10** - SageMaker HyperPod 支持 Slurm 编排，EKS 支持 Kubernetes 编排
- **23:45** - 选择正确的芯片：Trainium 系列
- **24:00** - Trainium 1 比同类 EC2 实例能效高 25%
- **24:15** - Trainium 2 比 Trainium 1 能效高 3 倍

### 阶段三：模型部署与推理优化 (24:30 - 29:00)
- **24:45** - 推理阶段的芯片选择重要性
- **25:10** - Inferentia 系列：每瓦性能提升 50%
- **25:40** - Graviton 实例：能效提高 60%，适用于小型模型和分类器
- **26:10** - 推理优化技术概览
- **26:35** - 模型压缩、分布式处理、权重剪枝
- **27:00** - 知识蒸馏（Distillation）和量化（Quantization）
- **27:30** - 相关库：DeepSpeed、Hugging Face Accelerate、Faster Transformer
- **28:00** - 这些库已集成在 AWS 大语言模型推理容器中

### Bedrock 推理优化功能 (29:00 - 33:30)
- **29:15** - 模型蒸馏（Model Distillation）功能
- **29:45** - 从大型教师模型向小型学生模型转移知识
- **30:20** - 提供自定义提示进行微调
- **30:50** - 实现 98% 准确率，节省 75% 成本
- **31:20** - 提示缓存（Prompt Caching）功能
- **31:50** - 避免重复模式和匹配前缀的重新计算
- **32:20** - 降低成本高达 90%，减少延迟 80-85%
- **32:50** - 应用场景：代码助手、重复系统指令

### 智能提示路由 (33:30 - 35:30)
- **33:45** - Intelligent Prompt Routing 功能介绍
- **34:10** - 选择多个模型（如 Nova、Claude、Llama）作为路由器
- **34:40** - Bedrock 根据提示复杂度智能路由请求
- **35:00** - 简单提示路由到成本效益高的小模型，复杂提示路由到大模型
- **35:15** - 可减少约 30% 费用，所有请求可追溯

### 阶段四：监控与优化 (35:30 - 37:30)
- **35:45** - 强调监控应贯穿整个生命周期，而非事后考虑
- **36:10** - 监控工具：CloudWatch、SageMaker Profiler
- **36:35** - SageMaker Profiler 可查看训练指标、数据分布、损失、准确率
- **37:00** - Neuron Monitor 专注于神经网络训练监控
- **37:15** - NVIDIA SMI 用于 GPU 指标监控和瓶颈识别

### 智能体 AI 系统介绍 (37:30 - 42:00)
- **37:45** - Parth Patel 接手讲解智能体 AI
- **38:00** - 生成式 AI vs 智能体 AI 的区别
- **38:30** - 生成式 AI：图像生成、文章生成、内容摘要、翻译
- **39:00** - 智能体 AI：目标导向、决策主观、非标准路径
- **39:30** - 智能体 AI 能充分发挥 LLM 潜力
- **40:00** - AI 智能体定义：能像代理人一样自主决策以实现目标
- **40:30** - 智能体工作流程：目标 → 工具 → 上下文 → 规划 → 行动 → 分析 → 迭代
- **41:15** - 智能体利用底层大语言模型生成执行计划
- **41:45** - 智能体是无状态的，需要提供上下文和工具

### 会议总结 (42:00 - 结束)
- **42:00** - 创建智能体的关键要素回顾
- **42:20** - 强调提供上下文、工具和状态信息的重要性
- **42:40** - 会议结束

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


关键要点总结：
- 在 AWS 上构建 AI 系统可自动降低碳足迹高达 90%
- 遵循渐进式优化策略：提示工程 → RAG → PEFT → 全量微调 → 从头训练
- 优先使用托管服务（Bedrock、SageMaker）以获得内置的效率优化
- 选择合适规模的模型，避免过度使用大型模型
- 利用 Bedrock 的评估、蒸馏、缓存和智能路由功能优化成本和性能
- 使用 Trainium 和 Inferentia 等优化芯片提高能效
- 智能体 AI 适用于需要自主决策的目标导向任务