# AWS re:Invent 2025 分组会议总结

## 会议概述

本次会议由 Tines 的现场 CTO Brad Rump 主讲,重点探讨了如何在 IT 基础设施管理中战略性地治理 AI 驱动的工作流。演讲者分享了他在过去 25 年中从事模型驱动工具、API 网关和机器学习的经验,特别是近三年深入研究生成式 AI 和 AI 代理的心得。

会议核心内容围绕如何将确定性工作流与动态代理工作流相结合,以及如何在适当的时候加入人工判断。演讲者强调,现代 IT 环境面临的挑战不是是否使用 AI,而是如何安全、战略性、经济高效地部署 AI,同时保持完全的可审计性。根据与 Forrester 合作调研的 400 多位 IT 高管的数据显示,86% 的 IT 领导者认为编排对于扩展 AI 至关重要。

演讲通过一个实际案例演示了 Tines 平台如何与 AWS 基础设施集成,实现智能工作流自动化。该案例展示了当 EC2 实例 CPU 利用率超过阈值时,系统如何通过 AI 代理自动创建案例、通过 Slack 请求人工审批,并根据批准自动调整实例大小。整个过程体现了确定性流程、AI 代理决策和人工监督的无缝结合。

## 详细时间线

00:00 - 开场介绍
- 演讲者 Brad Rump 自我介绍,担任 Tines 现场 CTO
- 分享 25 年行业经验,近三年专注于生成式 AI 和 AI 代理

01:30 - 技术演进背景
- 讨论当前技术格局的快速变化:RAG 几乎成为过去式,MCP(模型上下文协议)、ACP 协议以及 A2A 协议的出现
- 强调需要跟上各种新兴协议和代理协议的发展

02:45 - 会议主题阐述
- 核心议题:如何战略性地治理 AI 驱动的工作流
- 探讨如何混合固定确定性工作流与高度动态的代理工作流
- 讨论人工判断在何处以及如何发挥最大作用

04:00 - IT 面临的挑战
- AI 发展速度极快,被要求承担更多任务
- IT 团队需要扩展系统、管理合规性并将 AI 整合到现有流程中
- 挑战在于如何安全、战略性、经济高效地部署 AI 并保持可审计性

05:30 - 代理工作流的价值
- 定义代理工作流为跨多种工具自主运行的系统
- 引用调研数据:86% 的 IT 领导者认为编排对扩展 AI 至关重要
- 该数据来自与 Forrester 合作调研的 400 多位高管

07:00 - 现代 IT 环境的三大支柱
- **基础设施层**:数字架构,包括系统、数据、API 和工具(AWS、SaaS 平台、混合云或本地环境),每天产生数百万信号、警报和事件
- **AI 代理层**:能够推理和行动,但需要边界以确保安全运行;Tines 作为控制平面确保每个智能操作都受到治理
- **人员层**:战略操作者和决策者,处理战略优先级、管理关键异常并承担最终责任;Tines 将人工判断嵌入工作流中

10:00 - 工作流演进
- 确定性工作流:固定逻辑、可预测结果,适用于配置/取消配置等任务
- 代理工作流:当上下文变化或需要基于细微差别和判断做决策时发挥作用,能够解释、推理和适应
- 目标不是用代理工作流替代确定性工作流,而是将两者结合

12:30 - Tines 中的 AI 代理概念
- 代理的定义和要求因供应商而异
- Tines 不强制定义 AI 代理的样子,而是提供工具让用户构建自己的代理
- 代理应该是工作流程的一部分,需要大量编排,尤其是在全公司范围内推广时
- 提供预构建的故事(加速器)、模板和 API 集成,允许客户根据需求定制

15:00 - 工作流类型选择标准
- **风险容忍度**:如果任务关键、必须每次完美、高度可预测,应使用确定性工作流
- **灵活性**:如果结果可以变化,代理工作流可能提供速度和适应性
- Tines 混合两种方法:可以编写规则、添加推理层,并在必要时插入人工检查点

16:30 - 人工参与的重要性
- 人类可以处理灰色地带、优先级和异常情况
- 人工参与不是故障保护措施,而是一种深思熟虑的设计选择
- 用户可以选择哪些流程自动运行、哪些需要审查
- Tines 提供基于聊天的代理(人工可以参与交互)或完全基于任务的自主运行

18:00 - 用例介绍
- 演示从 Tines 库中提取的故事(工作流)
- 场景:监控领先金融科技应用的 EC2 实例警报,重点关注高 CPU 利用率
- 如果使用率正常,运行自主流程;如果异常(如超过 96%),则需要人工参与
- 通过 Slack 向值班工程师发送通知,由其决定是否批准调整实例大小的请求

20:00 - 实时演示开始
- 展示 Hooli 公司的 prod-1 实例,当前运行状态,实例类型为 T2 large
- 进入 Tines 故事界面,显示从 AWS CloudWatch 获取警报的流程

21:00 - 工作流逻辑展示
- 条件触发器:CPU 利用率在 90%-96% 之间走左侧路径,超过 96% 走右侧路径
- 右侧路径:创建案例 → 在 Slack 中发送审批请求 → 如果批准则更新案例 → 在 EC2 中调整实例大小

22:30 - 警报处理演示
- CloudWatch 警报显示 CPU 利用率超过 96%
- 使用 AI 代理在 Tines 中创建案例,包含系统指令和简单提示
- 展示代理在运行时做出的决策,包括创建案例和添加 EC2 实例的所有元数据

24:00 - Slack 审批流程
- 案例创建完成后,向 Slack 中的值班工程师发送审批请求
- Slack 通知显示:异常 EC2 实例超过 96%、实例名称、实例 ID 以及案例详情链接
- 工程师点击批准

25:30 - 实例调整决策
- 审批后,流程继续确定应该使用的实例大小
- 展示简单的提示指令(演讲者承认偷懒硬编码了实例 ID,但之前通过元数据提取)
- 显示实例详情:当前类型 T2 large、VPC、子网等信息

27:00 - AI 代理决策过程
- 展示代理的扩展决策和实施过程
- 代理决定将实例从 T2 large 升级到 T2 2xlarge
- 显示操作摘要和根本原因分析

28:30 - 案例更新和审计
- 更新 Tines 案例,展示代理的思考过程
- 提供案例更新摘要、解决方案信息和根本原因
- 强调所有事件都被存储,可随时检索,确保可审计性和治理能力

30:00 - 案例详情回顾
- 案例自动添加标签,由代理根据事件生成
- 显示案例回顾:检测到高 CPU 利用率、之前的状态、配置、解决方案和升级建议

31:00 - 验证结果
- 返回 EC2 控制台查看 Hooli prod-1 实例
- 确认实例现在正在运行,已升级到 T2 2xlarge

32:00 - 演示总结
- 展示了如何无缝构建确定性和代理工作流,并加入人工监督
- 在 Tines 中配置 AI 代理非常简单,编写提示只需几分钟
- 直接与 Amazon CLI 集成完成所有调整操作
- Tines 的案例管理功能使值班工程师或组织内任何人都能协作处理案例,清楚了解发生了什么

34:30 - 平台信任和安全特性
- Tines 的所有 AI 功能以信任为核心构建
- AI 运行无状态、私有、区域内、租户范围
- 不进行网络传输、训练、存储或记录任何用户数据
- 可使用 Tines 托管模型(与 Anthropic 合作,运行在 AWS Bedrock 上)或自带模型(OpenAI、Google Gemini、Mistral、Llama)

36:00 - 关键要点
- 这不是关于启动单个 AI 代理,而是端到端治理每个工作流
- IT 从守门人转变为编排者,实现安全、智能的大规模执行
- AWS 和 Tines 结合用户的政策、SOP 和提示,在不失控的情况下获得速度
- AWS 提供可靠性,Tines 提供控制,用户的政策和提示定义如何将一切整合在一起

38:00 - 结束思考
- 提出问题:从基础设施角度,哪些流程可以完全自主运行而不受治理?哪些流程需要人工监督?
- 这就是编排与机遇的交汇点

39:00 - 行动号召
- 鼓励参会者访问 1849 号展位了解更多信息
- 欢迎继续对话或回答任何问题
- 感谢参会者并祝愿大会愉快