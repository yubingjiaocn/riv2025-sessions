# AWS re:Invent 2025 - Shell 与 AWS 高性能计算(HPC)合作案例分享

## 会议概述

本次会议由 AWS 能源与公用事业部门 CTO Hussein Sha 和 Shell 全球 HPC 工程与运营负责人 Michael Gujerol 共同主持,深入分享了 Shell 与 AWS 在高性能计算领域长达五年以上的合作历程。

Shell 作为全球能源巨头,在 70 个国家拥有超过 93,000 名员工,2022 年生产了 6600 万吨液化天然气和每日 2800 桶石油当量。在上游业务中,Shell 需要处理海量的地震数据来进行地下成像,这需要极其强大的计算能力。传统的地震勘探需要将声波发送到海底数英里深处,在 40 公里外接收信号,产生 PB 级别的数据。这些数据需要通过复杂的物理算法进行处理,而随着勘探区域越来越复杂,所需的计算量呈指数级增长。

从 2017 年到 2022 年,Shell 经历了漫长而艰难的云端 HPC 探索期。最初的尝试包括使用 Spot 实例、异构 SKU 等方案,但都未能达到预期效果,主要原因是团队试图在云端复制本地部署的做法。2021-2022 年的转折点是"10 倍挑战"——如果能实现 10 倍的墙上时钟时间改进,将从根本上改变业务运作方式。这促使团队重新思考,不再简单复制本地架构,而是充分利用云的特性。关键突破包括:全波形反演(FWI)算法从 CPU 迁移到 GPU、P4DE 和 A100 80GB 实例的推出、以及将计算视为"磁铁"而非数据作为"重力锚"的思维转变。

2022 年 12 月 23 日,Shell 正式在 AWS 上线生产环境。虽然初期使用 P4DE 实例实现了约 3 倍加速,但容量获取仍是挑战。2024 年迁移到 P5 实例和 Nvidia H200 后,特别是采用 EC2 容量块(Capacity Blocks)功能,实现了可预测的突发容量管理,目前稳定达到 3-5 倍加速。截至目前,Shell 通过 AWS 云端 HPC 已累计节省了 2.5 年的墙上时钟时间,这对业务产生了重大影响。

## 详细时间线与关键要点

[00:00 - 02:30] 开场介绍
- Hussein Sha(AWS 能源与公用事业 CTO)介绍会议主题和演讲嘉宾
- Michael Gujerol(Shell 全球 HPC 工程与运营负责人)感谢参会者
- 强调这是一段超过 5 年的合作旅程,期间经历了许多挑战

[02:30 - 05:00] Shell 公司背景介绍
- Shell 在 70 个国家拥有 93,000 名员工
- 2022 年生产 6600 万吨液化天然气
- 每日生产超过 2800 桶石油当量
- 业务涵盖综合能源解决方案,包括数据中心供电等领域

[05:00 - 08:30] 上游业务技术战略
- Shell 正在从专有系统转向集成化解决方案
- 重点是简化工作流程,将孤立的应用程序整合
- 将 AI 嵌入到深度技术工作流程中
- 在云端实现集成是自然选择
- 与 AWS 的合作始于 OSDU(现为 AWS EDI)数据平台

[08:30 - 12:00] HPC 需求分析
- Shell 是 Top 20 超级计算机榜单的常客
- 地震勘探:将声波发送到海底数英里深处,在 40 公里外接收信号
- 产生 PB 级数据需要大量计算处理
- 使用的算法已有数十年历史,但从未有足够的计算能力
- 随着勘探区域复杂度增加,需要指数级增长的计算资源
- 工作负载是"令人尴尬的并行"(embarrassingly parallel),更多容量等于更快结果

[12:00 - 15:30] 为什么选择云端 HPC
- HPC 在业务关键路径上,直接影响收入
- 需要根据业务决策灵活调整计算容量,而非提前猜测
- 传统采购周期长,决策后需承担多年
- 硬件采购越来越困难(AI 热潮、电力供应、供应链挑战)
- 云端提供了可变性和灵活性

[15:30 - 22:00] 2017-2022 年的探索阶段
- 2017 年谈论云端 HPC 时,人们认为"不可行"
- 尝试了 Spot 实例,但无法承受中断
- 尝试了异构 SKU,但效果不佳
- 主要问题:试图在云端复制本地部署的做法
- 关键转折点:"10 倍挑战"——如果能实现 10 倍墙上时钟时间改进,将从根本上改变行为
- 决定将技术和商业分开:先证明技术可行性,再讨论成本

[22:00 - 26:00] 突破性进展
- 全波形反演(FWI)算法从 CPU 迁移到 GPU
- 2022 年 P4DE 和 A100 80GB 实例推出,节点架构与本地类似
- 重新思考数据引力:计算可以是"磁铁"而非数据是"锚"
- 解构工作流程,针对云进行优化
- 10Gbps 和 100Gbps Direct Connect 成本变得可承受

[26:00 - 30:00] 2022 年生产上线
- 2022 年 12 月 23 日正式上线
- 使用 P4DE 实例,几分钟内队列就满了
- 实现了约 3 倍加速(而非目标的 10 倍)
- 主要挑战:P4DE 容量获取困难

[30:00 - 35:00] 2024 年的飞跃
- 迁移到 P5 实例和 Nvidia H200
- H200 的 HBM 内存对工作负载非常有利
- EC2 容量块(Capacity Blocks)成为游戏规则改变者
- 提供可预测性:提前数周预订容量
- 工程师点击几次即可完成过去需要 6-18 个月的工作
- 目前稳定实现 3-5 倍加速,累计节省 2.5 年墙上时钟时间

[35:00 - 40:00] 技术架构详解
- PB 级数据在本地进行预处理和去填充
- 输入文件从 PB 级缩减到约 10TB
- 10TB 数据通过 Direct Connect 传输到 AWS
- 使用大量 P5 实例运行 FWI
- 最近迁移到 PCS(Parallel Cluster Service)管理的 Slurm
- 输出约 1TB,传回本地(有出口成本但可接受)
- 数据被视为临时的,用完即删除

[40:00 - 45:00] 多区域和多可用区架构
- 当前在三个不同区域运行(独立运行,尚未跨区域)
- 在单个区域内跨多个可用区运行
- 工作负载非紧密耦合,可跨多个 AZ 运行
- 使用 S3 支持的 FSX Lustre
- 只在 FSX 上保留最新版本模型,旧版本归档到 S3
- 所有资源视为临时,项目结束后删除

[45:00 - 48:00] PCS 的优势
- AWS 管理的 Slurm 服务
- 可以无缝更新集群(添加实例类型等)
- 无需像 Parallel Cluster 那样停机重新部署
- 集群可在几分钟到一小时内启动
- 通过 API 网关和自定义工具(代号"Hamster")提交作业

[48:00 - 52:00] 完整技术栈视图
- 底层:HPC 基础设施(本次会议重点)
- 中层:数据管理、应用访问、工作流集成
- 上层:用户体验、创新、AI/GenAI 能力
- 强调需要端到端集成,而非仅关注计算
- 多个团队在不同层面工作,需要无缝协作

[52:00 - 55:00] 协同创新成果
- HPC Orchestrator:低代码/无代码工具
- 由 Shell、AWS 和其他运营商共同开发
- 使云端 HPC 更加无缝,降低复杂性和采用门槛
- 用户可以快速构建工作负载和模板
- 支持 HPC、AI 和各种模拟工作负载
- 模板实现了异步性和智能存储使用
- 促进行业协作,共享最佳实践

[55:00 - 58:00] 业务影响总结
- 自 2022 年以来累计节省 2.5 年墙上时钟时间
- 提供了前所未有的灵活性和可变性
- 实现了 2017 年 PR/FAQ 中设想的目标
- 可以快速测试新硬件(如当天宣布的 GB300)
- 工程师可以轻松扩展容量,但需要控制支出
- 价格性能比仍是首要目标
- 持续追求更高的加速比和优化

[58:00 - 结束] 未来展望
- 目标:实现真正的多区域工作负载
- 探索更多 Spot 实例使用场景
- 继续优化价格性能比
- 将更多用例迁移到云端(R&D、生产、AI/GenAI)
- 减少本地和云端之间的数据传输
- 实现更完整的云原生工作流程
- 继续与 AWS 协同创新