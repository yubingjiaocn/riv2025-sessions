1
00:00:00,240 --> 00:00:02,100
- Hope everyone had a great Thanksgiving.

2
00:00:02,100 --> 00:00:03,840
Thanks for joining us today.

3
00:00:03,840 --> 00:00:08,310
Hope your AWS re:Invent
is off to a great start.

4
00:00:08,310 --> 00:00:13,310
I have the pleasure today of
having Sathwik from ServiceNow

5
00:00:13,680 --> 00:00:16,680
and Jamie from SLB,

6
00:00:16,680 --> 00:00:19,530
they're formerly called
Schlumberger, with us today.

7
00:00:19,530 --> 00:00:23,040
But before we get to the
panel session, just wanna go

8
00:00:23,040 --> 00:00:24,900
through the agenda.

9
00:00:24,900 --> 00:00:27,570
I'm just gonna give a quick overview

10
00:00:27,570 --> 00:00:30,180
of what we're seeing in the market today.

11
00:00:30,180 --> 00:00:34,020
Then talk about the
NVIDIA-AWS partnership.

12
00:00:34,020 --> 00:00:36,390
Just tell you what DGX Cloud is.

13
00:00:36,390 --> 00:00:38,387
Have any of you heard what DGX Cloud is?

14
00:00:38,387 --> 00:00:40,920
NVIDIA DGX Cloud?

15
00:00:40,920 --> 00:00:43,770
Okay, cool, so I'll explain what that is,

16
00:00:43,770 --> 00:00:47,970
and Sathwik and Jamie will be here to kind

17
00:00:47,970 --> 00:00:49,230
of talk about their experience

18
00:00:49,230 --> 00:00:52,920
with DGX Cloud, NVIDIA AI on AWS,

19
00:00:52,920 --> 00:00:55,530
and we'll have a little bit of maybe time

20
00:00:55,530 --> 00:00:57,270
to do some informal Q&A.

21
00:00:57,270 --> 00:01:00,450
This isn't quite the right setup for that,

22
00:01:00,450 --> 00:01:02,193
but we'll see what we could do.

23
00:01:03,270 --> 00:01:06,870
Okay, so AI adoption is everywhere.

24
00:01:06,870 --> 00:01:09,360
Is everyone already doing some sort

25
00:01:09,360 --> 00:01:11,850
of AI, like either developing

26
00:01:11,850 --> 00:01:14,553
or already implementing AI today?

27
00:01:15,510 --> 00:01:17,580
Hands, all right, cool.

28
00:01:17,580 --> 00:01:18,783
Looks like the majority.

29
00:01:20,160 --> 00:01:24,240
So, this is really a new
industrial revolution

30
00:01:24,240 --> 00:01:26,550
where it's powered by AI factories.

31
00:01:26,550 --> 00:01:28,110
And what we're here to do is talk

32
00:01:28,110 --> 00:01:30,120
about AI factories in the Cloud.

33
00:01:30,120 --> 00:01:31,560
And AWS really is one

34
00:01:31,560 --> 00:01:34,590
of the biggest AI factories
that you could use.

35
00:01:34,590 --> 00:01:37,740
And you could see it spans
across all industries.

36
00:01:37,740 --> 00:01:39,240
And today, we're gonna be talking

37
00:01:39,240 --> 00:01:41,790
about two very distinct
industries, and they'll talk

38
00:01:41,790 --> 00:01:46,790
about their exciting use
cases on how they're using AI

39
00:01:47,640 --> 00:01:49,707
and how the AI factory

40
00:01:49,707 --> 00:01:54,707
and DGX Cloud is helping
them develop their AI.

41
00:01:56,490 --> 00:01:58,080
So there's...

42
00:01:58,080 --> 00:02:00,450
What we're seeing is,
we're seeing the emergence

43
00:02:00,450 --> 00:02:04,200
of three scaling laws for AI.

44
00:02:04,200 --> 00:02:08,460
We really started with
pre-training scaling,

45
00:02:08,460 --> 00:02:12,450
which is really teaching a
model from the internet, right?

46
00:02:12,450 --> 00:02:14,730
So if you think about
surfing the internet,

47
00:02:14,730 --> 00:02:17,640
you could get a lot of
information that way,

48
00:02:17,640 --> 00:02:20,430
but then you wanna take
it to the next level.

49
00:02:20,430 --> 00:02:24,060
That's just consuming the
data that you're seeing.

50
00:02:24,060 --> 00:02:25,920
But then you wanna think about it.

51
00:02:25,920 --> 00:02:30,360
So, like when we go to
post-training scaling,

52
00:02:30,360 --> 00:02:33,720
this is really where the
model goes to school,

53
00:02:33,720 --> 00:02:36,660
and it learns thinking, right?

54
00:02:36,660 --> 00:02:40,560
And then, kind of the last
part is really the idea

55
00:02:40,560 --> 00:02:41,760
of reasoning.

56
00:02:41,760 --> 00:02:44,070
And so we call this test-time scaling.

57
00:02:44,070 --> 00:02:46,320
So this is a long thinking.

58
00:02:46,320 --> 00:02:47,250
It's not just thinking

59
00:02:47,250 --> 00:02:50,400
of like what answer it's gonna
give back, but it's thinking

60
00:02:50,400 --> 00:02:52,920
before it gives back the answer,

61
00:02:52,920 --> 00:02:56,310
and reasons to see if
that's the best response

62
00:02:56,310 --> 00:02:57,753
to give back to you.

63
00:02:58,800 --> 00:03:02,970
And as the intelligence
of the model increases,

64
00:03:02,970 --> 00:03:05,310
there's a higher demand for compute.

65
00:03:05,310 --> 00:03:08,100
And so, this is where the AI factory,

66
00:03:08,100 --> 00:03:09,690
especially AI factory in the Cloud,

67
00:03:09,690 --> 00:03:13,533
where you could scale out as
your AI projects get bigger.

68
00:03:14,370 --> 00:03:16,173
You could scale that very easily.

69
00:03:18,330 --> 00:03:22,260
And I think everyone is,
when they think of NVIDIA,

70
00:03:22,260 --> 00:03:26,790
they think about
infrastructure and NVIDIA GPUs.

71
00:03:26,790 --> 00:03:28,440
It's actually the full-Stack

72
00:03:28,440 --> 00:03:32,010
that really makes all this happen.

73
00:03:32,010 --> 00:03:34,950
It's the software layer on up.

74
00:03:34,950 --> 00:03:36,090
I'll show you in the next slide,

75
00:03:36,090 --> 00:03:39,540
but I wanted to talk
about, we're integrated

76
00:03:39,540 --> 00:03:41,790
with AWS in our partnership.

77
00:03:41,790 --> 00:03:46,020
So from CUDA Libraries, if
you're familiar with those,

78
00:03:46,020 --> 00:03:49,650
having those available in AWS.

79
00:03:49,650 --> 00:03:51,930
But it's also the full platforms

80
00:03:51,930 --> 00:03:55,260
that we have available in
AWS, like in the Marketplace.

81
00:03:55,260 --> 00:03:57,060
So anywhere from DGX Cloud,

82
00:03:57,060 --> 00:03:59,700
which I'll talk about in the next slide.

83
00:03:59,700 --> 00:04:04,590
NVIDIA AI Enterprise, which
is our Enterprise AI suite

84
00:04:04,590 --> 00:04:08,193
of software, Omniverse,
if you've heard of that.

85
00:04:09,270 --> 00:04:13,770
We have NVIDIA NIM, which
are inference microservices.

86
00:04:13,770 --> 00:04:16,860
And there's other sessions
that NVIDIA has here

87
00:04:16,860 --> 00:04:20,010
that we'll go a little
bit deeper into that.

88
00:04:20,010 --> 00:04:24,000
And then not only that, but
all our libraries are software.

89
00:04:24,000 --> 00:04:27,720
They're integrated into
various AWS services,

90
00:04:27,720 --> 00:04:31,500
so you could consume them throughout AWS,

91
00:04:31,500 --> 00:04:34,950
and kind of all this is
built upon the infrastructure

92
00:04:34,950 --> 00:04:36,900
that you know, and you're familiar with,

93
00:04:36,900 --> 00:04:39,933
which are the NVIDIA GPUs and networking.

94
00:04:41,430 --> 00:04:45,420
Okay, so DGX Cloud, what we've done

95
00:04:45,420 --> 00:04:50,420
with DGX Cloud is NVIDIA
looked at what are...

96
00:04:50,730 --> 00:04:53,940
What's the kind of AI factory

97
00:04:53,940 --> 00:04:56,520
or infrastructure that NVIDIA needs

98
00:04:56,520 --> 00:04:59,340
to accomplish our own AI goals?

99
00:04:59,340 --> 00:05:03,330
And so, we reached out to, you know,

100
00:05:03,330 --> 00:05:06,427
one of our biggest
partners, like AWS, to say,

101
00:05:06,427 --> 00:05:07,650
"Let's co-engineer this

102
00:05:07,650 --> 00:05:09,783
because NVIDIA had some requirements.

103
00:05:10,677 --> 00:05:12,630
AWS has technology.

104
00:05:12,630 --> 00:05:14,310
How do we co-engineer this

105
00:05:14,310 --> 00:05:17,880
and marry the best of the
technologies together?"

106
00:05:17,880 --> 00:05:21,000
So we start with the infrastructure.

107
00:05:21,000 --> 00:05:24,780
If you look at GB200's, the latest,

108
00:05:24,780 --> 00:05:29,780
I know B300 was announced
not too long ago.

109
00:05:30,030 --> 00:05:33,540
So, keep an eye out on what's available,

110
00:05:33,540 --> 00:05:35,700
and what may be coming next.

111
00:05:35,700 --> 00:05:37,770
But there's high-performance networking

112
00:05:37,770 --> 00:05:40,980
and also Lustre storage.

113
00:05:40,980 --> 00:05:43,230
So that's at the infrastructure layer.

114
00:05:43,230 --> 00:05:48,120
And then we optimize EKS on DGX Cloud.

115
00:05:48,120 --> 00:05:50,550
So from an infrastructure
management standpoint,

116
00:05:50,550 --> 00:05:52,260
that's optimized as well.

117
00:05:52,260 --> 00:05:55,470
We take it to another level,
and we've included Run.ai.

118
00:05:55,470 --> 00:05:59,130
Has anyone heard about
Run:ai GPU Orchestration?

119
00:05:59,130 --> 00:06:03,960
So the idea here is, you
have high-performance GPUs

120
00:06:03,960 --> 00:06:06,690
that you know, you're
paying some money for,

121
00:06:06,690 --> 00:06:09,990
and you wanna make sure that
those GPUs are fully optimized.

122
00:06:09,990 --> 00:06:13,440
You're getting the most out
of what you're paying for.

123
00:06:13,440 --> 00:06:16,230
So Run:ai will really help you

124
00:06:16,230 --> 00:06:18,840
use the GPUs effectively.

125
00:06:18,840 --> 00:06:21,690
I know Sathwik has a testimony on that.

126
00:06:21,690 --> 00:06:24,720
So, it'll be exciting to hear from him

127
00:06:24,720 --> 00:06:29,130
on how he's used Run:ai and
enterprise-grade software.

128
00:06:29,130 --> 00:06:32,010
So, a lot of the AI software

129
00:06:32,010 --> 00:06:34,260
you may be using is open source,

130
00:06:34,260 --> 00:06:35,730
but there may become a time,

131
00:06:35,730 --> 00:06:38,400
where you're gonna roll
out your AI application

132
00:06:38,400 --> 00:06:39,450
into production.

133
00:06:39,450 --> 00:06:41,670
So you want something
that's enterprise-grade

134
00:06:41,670 --> 00:06:46,020
that's supported, has very
set-like production branching

135
00:06:46,020 --> 00:06:47,280
and releases.

136
00:06:47,280 --> 00:06:50,910
And so, we offer that with DGX Cloud.

137
00:06:50,910 --> 00:06:55,200
And then, kind of, lastly,
is really access to NVIDIA AI

138
00:06:55,200 --> 00:06:56,790
and Cloud experts.

139
00:06:56,790 --> 00:06:59,790
So in this DGX Cloud service,

140
00:06:59,790 --> 00:07:02,190
we provide technical account managers

141
00:07:02,190 --> 00:07:05,490
and 24-by-7 Enterprise Support.

142
00:07:05,490 --> 00:07:08,640
And then, all this translates into is

143
00:07:08,640 --> 00:07:12,450
that you have a platform that provides

144
00:07:12,450 --> 00:07:16,890
the best of NVIDIA AI and
an optimized full-Stack

145
00:07:16,890 --> 00:07:20,343
that's on co-engineered infrastructure.

146
00:07:21,420 --> 00:07:24,210
Okay, and so now that
you have the background

147
00:07:24,210 --> 00:07:29,210
on where NVIDIA sees the
market is, what DGX Cloud is,

148
00:07:29,430 --> 00:07:32,520
I want to introduce our spotlight panel.

149
00:07:32,520 --> 00:07:35,550
So, I'll let you guys introduce yourself,

150
00:07:35,550 --> 00:07:39,510
and maybe we start with who
are you, who's your company,

151
00:07:39,510 --> 00:07:41,040
and what do you do for them?

152
00:07:41,040 --> 00:07:42,570
So, I'll start with Sathwik.

153
00:07:42,570 --> 00:07:44,220
- Okay, sounds good.

154
00:07:44,220 --> 00:07:47,190
Yeah, that's me up on
the screen on top of one

155
00:07:47,190 --> 00:07:48,330
with me. (laughs)

156
00:07:48,330 --> 00:07:51,960
But how many of you have heard

157
00:07:51,960 --> 00:07:52,890
of ServiceNow?

158
00:07:52,890 --> 00:07:53,940
Quick Show fans?

159
00:07:53,940 --> 00:07:55,500
Okay, everybody knows.

160
00:07:55,500 --> 00:07:58,470
So I am a Principal
Scientist at ServiceNow.

161
00:07:58,470 --> 00:08:00,843
I lead the Foundation Model Lab,

162
00:08:01,980 --> 00:08:05,130
and my team is responsible

163
00:08:05,130 --> 00:08:10,130
for the mid-training and
the post-training of models.

164
00:08:10,170 --> 00:08:11,880
We try to train, like,

165
00:08:11,880 --> 00:08:16,880
or actually, we train
really small language models

166
00:08:18,120 --> 00:08:21,690
that are on par with most
of the frontier models.

167
00:08:21,690 --> 00:08:26,430
And our goal is to be able to
service all of the workloads

168
00:08:26,430 --> 00:08:28,263
that we see on a day-to-day basis.

169
00:08:29,760 --> 00:08:33,393
Yeah, so I think that's what
I do at a high level, so.

170
00:08:35,100 --> 00:08:37,020
- Hi, everybody, my name's Jamie.

171
00:08:37,020 --> 00:08:39,750
I'm gonna ask the same question
and expect fewer hands.

172
00:08:39,750 --> 00:08:41,253
Who's heard of SLB?

173
00:08:42,840 --> 00:08:44,640
Well, there's some at least, that's good.

174
00:08:44,640 --> 00:08:48,930
So we are a technology company
in the energy industry.

175
00:08:48,930 --> 00:08:50,100
We're one

176
00:08:50,100 --> 00:08:53,520
of the world's largest oil
and gas service companies,

177
00:08:53,520 --> 00:08:57,420
but we also have a substantial
new energy business as well.

178
00:08:57,420 --> 00:09:00,630
So we deal with the full
spectrum of the energy business.

179
00:09:00,630 --> 00:09:03,120
Everything from producing
oil and glass globally,

180
00:09:03,120 --> 00:09:07,080
we operate in over 120 countries,
as well as helping people

181
00:09:07,080 --> 00:09:08,220
with their new energy needs.

182
00:09:08,220 --> 00:09:13,220
And our goal really is to
enable people to produce energy,

183
00:09:13,290 --> 00:09:15,000
the growing energy demand of the planet,

184
00:09:15,000 --> 00:09:18,990
but safely and cleanly over time.

185
00:09:18,990 --> 00:09:22,530
Now, our business is divided
up into different divisions.

186
00:09:22,530 --> 00:09:24,420
Some of those visions are

187
00:09:24,420 --> 00:09:27,000
heavy industrial divisions doing things

188
00:09:27,000 --> 00:09:29,940
like drilling wells, managing production.

189
00:09:29,940 --> 00:09:33,060
But we also have a digital
division, which is where I work,

190
00:09:33,060 --> 00:09:35,590
where we produce technology

191
00:09:36,720 --> 00:09:39,990
that can help us and our customers

192
00:09:39,990 --> 00:09:43,403
who are typically the large
energy companies' plan,

193
00:09:45,450 --> 00:09:50,190
produce models, simulations,
as well as operate responsibly

194
00:09:50,190 --> 00:09:52,800
and very sort of efficiently.

195
00:09:52,800 --> 00:09:55,260
Most of our business is
science and engineering.

196
00:09:55,260 --> 00:09:57,780
So it's a heavily vertical business.

197
00:09:57,780 --> 00:10:00,933
So everybody, you know, a lot
of people in our business,

198
00:10:02,130 --> 00:10:04,140
you know, are very specialist scientists

199
00:10:04,140 --> 00:10:05,700
or engineers and the different divisions.

200
00:10:05,700 --> 00:10:07,890
They might have even gone
to different departments

201
00:10:07,890 --> 00:10:09,063
at universities.

202
00:10:09,990 --> 00:10:13,290
And so, ours is not really a
very transactional business.

203
00:10:13,290 --> 00:10:15,420
It's a sort of high-science business.

204
00:10:15,420 --> 00:10:19,830
And so, we are using AI to try

205
00:10:19,830 --> 00:10:22,470
and augment the workforce

206
00:10:22,470 --> 00:10:24,030
that does this very important work,

207
00:10:24,030 --> 00:10:26,040
especially as perhaps
there's less people coming

208
00:10:26,040 --> 00:10:28,410
into the industry these days.

209
00:10:28,410 --> 00:10:30,420
My role as the Business Line Director is

210
00:10:30,420 --> 00:10:33,210
to provide our internal
data and AI platform.

211
00:10:33,210 --> 00:10:38,040
We use that to power our
own TurnKey applications

212
00:10:38,040 --> 00:10:40,020
that we sell to our customers.

213
00:10:40,020 --> 00:10:42,450
And we also sell the
platform itself directly

214
00:10:42,450 --> 00:10:44,853
to our customers to help
them do their business.

215
00:10:45,930 --> 00:10:47,910
- Energy is really in the spotlight,

216
00:10:47,910 --> 00:10:50,430
especially with building
out all these data centers

217
00:10:50,430 --> 00:10:51,930
and AI factories, so. (laughs)

218
00:10:51,930 --> 00:10:56,100
- Yeah, yeah, sometimes
they say, you know, to do AI

219
00:10:56,100 --> 00:10:57,960
for energy, which is what we need, we have

220
00:10:57,960 --> 00:10:59,687
to have energy for AI.
- Yeah.

221
00:10:59,687 --> 00:11:03,090
- It's a kind of bit of a,
hopefully, a virtuous circle,

222
00:11:03,090 --> 00:11:06,300
but it's kind of interesting that many

223
00:11:06,300 --> 00:11:08,220
of our customers are
really in the business

224
00:11:08,220 --> 00:11:10,350
of providing energy for AI as well.

225
00:11:10,350 --> 00:11:13,203
So it's become an increasingly
important concern.

226
00:11:14,040 --> 00:11:19,040
- All right, so what are
your goals in developing AI?

227
00:11:19,650 --> 00:11:22,500
So you're here, you're using DGX Cloud,

228
00:11:22,500 --> 00:11:26,640
but before we get into
the DGX Cloud part, what,

229
00:11:26,640 --> 00:11:31,640
like before you needed
something like DGX Cloud, what,

230
00:11:31,650 --> 00:11:32,760
like what were your goals?

231
00:11:32,760 --> 00:11:36,570
Like, what did you set
forth to say, "Okay, this is

232
00:11:36,570 --> 00:11:39,390
what I need to do, this is
the AI we're developing."

233
00:11:39,390 --> 00:11:41,640
And because of that then you had to look

234
00:11:41,640 --> 00:11:42,690
for the infrastructure.

235
00:11:42,690 --> 00:11:45,720
So, could you just share
a little bit of, you know,

236
00:11:45,720 --> 00:11:48,510
what your goals for developing AI?

237
00:11:48,510 --> 00:11:49,510
- Yeah, sounds good.

238
00:11:50,460 --> 00:11:53,160
So I guess everybody's
familiar with ServiceNow,

239
00:11:53,160 --> 00:11:55,680
but just to recap a little bit,

240
00:11:55,680 --> 00:11:58,170
ServiceNow is basically
an enterprise company

241
00:11:58,170 --> 00:12:02,580
that hosts most of your, maybe IT, SM,

242
00:12:02,580 --> 00:12:06,270
ITOM, ITAM, CSM, HR, Legal Compliance,

243
00:12:06,270 --> 00:12:07,980
whatever kind of data.

244
00:12:07,980 --> 00:12:09,360
There's tons of processes

245
00:12:09,360 --> 00:12:12,360
that perhaps nobody
wants to do these days.

246
00:12:12,360 --> 00:12:14,610
Everybody's trying to automate it.

247
00:12:14,610 --> 00:12:18,637
Maybe 15, 20 years ago, you
know, the trend was that,

248
00:12:18,637 --> 00:12:21,780
"Hey, let's code up some
workflows and get it working."

249
00:12:21,780 --> 00:12:25,920
And then with traditional
machine learning,

250
00:12:25,920 --> 00:12:28,590
it kind of changed,
like smarter workflows.

251
00:12:28,590 --> 00:12:31,440
So at this point, it's like
Agentic, AI applications

252
00:12:31,440 --> 00:12:34,713
that are running a lot of these use cases.

253
00:12:35,700 --> 00:12:37,500
A really cool way to think about it.

254
00:12:38,670 --> 00:12:42,300
So, Anthropic introduced this
concept about MCP, right?

255
00:12:42,300 --> 00:12:43,710
- Yeah.
- So,

256
00:12:43,710 --> 00:12:47,790
you just have like this huge list of tools

257
00:12:47,790 --> 00:12:49,380
and functions that you can call,

258
00:12:49,380 --> 00:12:52,230
and if a person were to sit
there calling the right tools

259
00:12:52,230 --> 00:12:54,240
and functions in the right order,

260
00:12:54,240 --> 00:12:56,403
you could accomplish just about any task.

261
00:12:57,450 --> 00:13:00,900
The challenge with
models is really twofold.

262
00:13:00,900 --> 00:13:04,980
One is, will they be able
to accomplish the task?

263
00:13:04,980 --> 00:13:06,840
And the second one is the cost, right?

264
00:13:06,840 --> 00:13:11,010
So if you try to use a
frontier model for this,

265
00:13:11,010 --> 00:13:13,350
maybe GPT-5.1, or maybe GPT-6,

266
00:13:13,350 --> 00:13:14,460
whenever it comes out, (chuckles)

267
00:13:14,460 --> 00:13:16,620
I'm sure it's gonna do a really great job.

268
00:13:16,620 --> 00:13:18,750
But then, it's not really practical

269
00:13:18,750 --> 00:13:22,050
because if you start using, you know,

270
00:13:22,050 --> 00:13:25,080
the most expensive model
for every single use case,

271
00:13:25,080 --> 00:13:28,080
for every single employee,
like, I don't know,

272
00:13:28,080 --> 00:13:31,500
I'm here in Vegas trying
to book a whole trip,

273
00:13:31,500 --> 00:13:34,620
and then I just go ask the
system to do this for me,

274
00:13:34,620 --> 00:13:36,870
it's gonna start costing a lot more

275
00:13:36,870 --> 00:13:39,570
than actually having people do this job.

276
00:13:39,570 --> 00:13:43,380
So you need to really build
efficient Agentic systems,

277
00:13:43,380 --> 00:13:44,213
at the same time,

278
00:13:44,213 --> 00:13:46,320
make sure the models are efficient.

279
00:13:46,320 --> 00:13:50,880
So the goal of, at least my team, is

280
00:13:50,880 --> 00:13:54,120
to build really powerful foundation models

281
00:13:54,120 --> 00:13:55,830
that can power most of the use cases

282
00:13:55,830 --> 00:13:57,513
across the ServiceNow platform.

283
00:13:58,590 --> 00:14:01,170
And so that the customers
can enjoy the same level

284
00:14:01,170 --> 00:14:04,020
of performance as a frontier model,

285
00:14:04,020 --> 00:14:07,050
but not really be bogged
down by the costs.

286
00:14:07,050 --> 00:14:08,160
- Yep.

287
00:14:08,160 --> 00:14:12,780
- And what we try to do is,
inspired by the use cases,

288
00:14:12,780 --> 00:14:15,810
design some custom post-training recipes,

289
00:14:15,810 --> 00:14:17,520
but at a high level,

290
00:14:17,520 --> 00:14:19,893
our model is not really any
different from a DeepSeek,

291
00:14:19,893 --> 00:14:21,773
or a Quinn, or any other model.

292
00:14:21,773 --> 00:14:23,880
We also open-source most of our models

293
00:14:23,880 --> 00:14:25,230
so that anybody can use it.

294
00:14:26,220 --> 00:14:27,840
But yeah, that's at a high level

295
00:14:27,840 --> 00:14:29,070
what we're trying to accomplish.

296
00:14:29,070 --> 00:14:33,720
And DGX and AWS makes
it a whole lot easier.

297
00:14:33,720 --> 00:14:34,740
Maybe we can get into that.

298
00:14:34,740 --> 00:14:35,700
- Yeah.

299
00:14:35,700 --> 00:14:37,560
And, Jamie, how are you guys?

300
00:14:37,560 --> 00:14:40,710
Like, what were your goals
or what are your goals?

301
00:14:40,710 --> 00:14:44,670
- Yeah, yeah, well, our
business is kind of interesting.

302
00:14:44,670 --> 00:14:45,503
How it works is

303
00:14:45,503 --> 00:14:50,453
that we, very expensively,
acquire vast amounts of data.

304
00:14:51,360 --> 00:14:52,920
And we'll show you later on what some

305
00:14:52,920 --> 00:14:53,970
of that data looks like.

306
00:14:53,970 --> 00:14:55,770
Seismic data, geophysical data,

307
00:14:55,770 --> 00:15:00,120
so we conduct surveys in the
field to explore for data.

308
00:15:00,120 --> 00:15:05,040
And seismic is where we shoot
very large geographic areas

309
00:15:05,040 --> 00:15:07,260
of data to try and characterize
what's underground.

310
00:15:07,260 --> 00:15:09,660
'Cause if we want to lift oil and gas,

311
00:15:09,660 --> 00:15:12,300
or if we want to sequester carbon,

312
00:15:12,300 --> 00:15:13,980
we need to understand
what's going on underground.

313
00:15:13,980 --> 00:15:15,150
We can't do that, so we have

314
00:15:15,150 --> 00:15:19,170
to build models based on
very large volumes of data.

315
00:15:19,170 --> 00:15:21,930
Similarly, we sometimes wanna
know a bit more specific

316
00:15:21,930 --> 00:15:23,100
about a particular area.

317
00:15:23,100 --> 00:15:24,810
And so we'll drill a well bore,

318
00:15:24,810 --> 00:15:28,350
and get petrophysical data
about the actual structure

319
00:15:28,350 --> 00:15:31,260
of the layer cake, the
formations that sit underground.

320
00:15:31,260 --> 00:15:33,030
And with that information,

321
00:15:33,030 --> 00:15:36,390
geologists and geophysicists
can build models, if you like,

322
00:15:36,390 --> 00:15:39,300
architectural drawings of
what's going on underground.

323
00:15:39,300 --> 00:15:41,790
And there's a lot of
uncertainty in those models.

324
00:15:41,790 --> 00:15:43,770
And so for maybe 30 or 40 years,

325
00:15:43,770 --> 00:15:46,110
we've been using various techniques

326
00:15:46,110 --> 00:15:48,240
from complex deterministic physics

327
00:15:48,240 --> 00:15:51,390
and mathematics to be able
to predict the structure

328
00:15:51,390 --> 00:15:53,010
of the subsurface and its behavior,

329
00:15:53,010 --> 00:15:54,840
and simulate the flow

330
00:15:54,840 --> 00:15:57,903
of fluids in the porous
media, that is the rocks.

331
00:15:58,800 --> 00:16:00,330
But over time,

332
00:16:00,330 --> 00:16:02,730
we've been using more
data-driven techniques.

333
00:16:02,730 --> 00:16:04,410
We've been using specific models,

334
00:16:04,410 --> 00:16:05,850
machine learning, and things like that.

335
00:16:05,850 --> 00:16:07,800
And obviously, in the last few years,

336
00:16:07,800 --> 00:16:10,020
we've seen there's a great opportunity

337
00:16:10,020 --> 00:16:13,440
to use more general-purpose
foundational models,

338
00:16:13,440 --> 00:16:16,140
But we are not really in the business

339
00:16:16,140 --> 00:16:19,320
of just going from text
to text like coding

340
00:16:19,320 --> 00:16:21,840
or even for process automation.

341
00:16:21,840 --> 00:16:23,940
We need to be able to synthesize

342
00:16:23,940 --> 00:16:28,113
and generate responses,
synthetic responses,

343
00:16:28,950 --> 00:16:29,790
from the subsurface.

344
00:16:29,790 --> 00:16:33,390
So we use foundation models for seismic

345
00:16:33,390 --> 00:16:36,060
and time series data,

346
00:16:36,060 --> 00:16:38,460
and for petrophysical
data that would allow us

347
00:16:38,460 --> 00:16:40,510
to predict scientific responses

348
00:16:41,918 --> 00:16:43,680
as if we'd acquired the data directly.

349
00:16:43,680 --> 00:16:47,190
So we call these the
main foundation models,

350
00:16:47,190 --> 00:16:49,200
and that's what we've been
using the technology for.

351
00:16:49,200 --> 00:16:51,180
And ultimately, we expect to combine those

352
00:16:51,180 --> 00:16:53,520
with the other forms
of data-driven modeling

353
00:16:53,520 --> 00:16:55,170
and physics-based modeling,

354
00:16:55,170 --> 00:16:56,340
and then the orchestration

355
00:16:56,340 --> 00:16:59,730
that you are talking about in
the agentic world to be able

356
00:16:59,730 --> 00:17:02,850
to provide assistance to geologists,

357
00:17:02,850 --> 00:17:04,920
geoscientist engineers that are a bit

358
00:17:04,920 --> 00:17:07,200
like the coding assistance
that you would get

359
00:17:07,200 --> 00:17:08,160
in your regular world.

360
00:17:08,160 --> 00:17:08,993
But we've gotta bring all

361
00:17:08,993 --> 00:17:10,950
of these pieces together
for it to make sense.

362
00:17:10,950 --> 00:17:12,240
- Yeah.

363
00:17:12,240 --> 00:17:14,310
So kind of two key themes, you know,

364
00:17:14,310 --> 00:17:17,670
building models, Agentic AI.

365
00:17:17,670 --> 00:17:20,790
How many of you in the
audience are building models?

366
00:17:20,790 --> 00:17:22,980
Like, are you training fine-tuning models?

367
00:17:22,980 --> 00:17:24,090
Okay, cool.

368
00:17:24,090 --> 00:17:27,513
And then, how many are creating AI agents?

369
00:17:28,770 --> 00:17:30,480
Oh, quite a few, okay.

370
00:17:30,480 --> 00:17:31,620
Cool, that's awesome.

371
00:17:31,620 --> 00:17:35,430
And so, you know, we talked
about DGX Cloud as kind

372
00:17:35,430 --> 00:17:40,430
of like this TurnKey, you
know, full-Stack platform.

373
00:17:40,740 --> 00:17:45,030
How did DGX Cloud on AWS help you achieve

374
00:17:45,030 --> 00:17:47,970
those goals that you set out
to do that you guys just,

375
00:17:47,970 --> 00:17:49,980
you know, described?

376
00:17:49,980 --> 00:17:51,600
- Yeah, makes sense.

377
00:17:51,600 --> 00:17:53,430
I'll maybe like give a high-level first,

378
00:17:53,430 --> 00:17:55,470
and then we can go into the details more.

379
00:17:55,470 --> 00:17:56,940
- Right.

380
00:17:56,940 --> 00:18:00,600
- I think prior to us
using DGX Cloud on AWS,

381
00:18:00,600 --> 00:18:03,820
we obviously bought a bunch
of hardware from NVIDIA.

382
00:18:03,820 --> 00:18:06,933
- Yeah.
- And installed it in-house,

383
00:18:07,770 --> 00:18:10,410
had our own orchestration frameworks,

384
00:18:10,410 --> 00:18:11,943
job management, et cetera.

385
00:18:12,900 --> 00:18:16,410
I think, I mean, it was
great, but obviously,

386
00:18:16,410 --> 00:18:18,990
like maintaining extremely
large clusters is

387
00:18:18,990 --> 00:18:20,013
a full-time job.

388
00:18:21,120 --> 00:18:24,197
And we decided to like
switch to something that DGX

389
00:18:24,197 --> 00:18:29,100
and AWS offers, just because
it's like maybe more reliable.

390
00:18:29,100 --> 00:18:32,640
And also, I think if you
buy hardware, you're stuck

391
00:18:32,640 --> 00:18:34,020
to using it for a while, right?

392
00:18:34,020 --> 00:18:36,630
So we can keep switching
out newer hardware

393
00:18:36,630 --> 00:18:37,630
when it's available.

394
00:18:39,450 --> 00:18:42,870
And on top of this, I think one

395
00:18:42,870 --> 00:18:45,183
of your older slides
captured it perfectly.

396
00:18:46,860 --> 00:18:51,030
The cluster that we are using
right now comes with Lustre,

397
00:18:51,030 --> 00:18:52,410
comes with Run:ai.

398
00:18:52,410 --> 00:18:55,500
- Yep, go back to that slide just so...

399
00:18:55,500 --> 00:18:58,500
- Yeah, so it comes with
Luster, comes with Run:ai,

400
00:18:58,500 --> 00:19:00,150
obviously, networking is super important

401
00:19:00,150 --> 00:19:02,853
because we don't wanna be
wasting any time at all.

402
00:19:03,720 --> 00:19:05,913
So, I think these are super important.

403
00:19:06,810 --> 00:19:11,400
One reason, at least, why we
really, really like Run:ai

404
00:19:11,400 --> 00:19:12,810
to the point where we don't wanna use

405
00:19:12,810 --> 00:19:14,790
a cluster without it is

406
00:19:14,790 --> 00:19:19,260
because we wanna maximize

407
00:19:19,260 --> 00:19:21,603
the cluster usage as much as possible.

408
00:19:22,710 --> 00:19:25,890
And earlier, we used to like come up

409
00:19:25,890 --> 00:19:28,560
with custom job schedulers that try

410
00:19:28,560 --> 00:19:32,040
to like use the compute
whenever there's downtime.

411
00:19:32,040 --> 00:19:34,980
I think this is made
super easy with Run:ai

412
00:19:34,980 --> 00:19:37,680
because of the way we can prioritize jobs,

413
00:19:37,680 --> 00:19:38,850
and stuff like that, so...

414
00:19:38,850 --> 00:19:42,300
We are able to get almost
like 100% utilization

415
00:19:42,300 --> 00:19:43,740
either with training models

416
00:19:43,740 --> 00:19:46,082
or synthesizing data or evaluating.

417
00:19:46,082 --> 00:19:51,082
So, I think along with this, obviously,

418
00:19:52,800 --> 00:19:55,323
we've had like over the last year or so,

419
00:19:56,160 --> 00:19:57,870
close to like zero downtime,

420
00:19:57,870 --> 00:19:59,640
like maybe a few hours on one day

421
00:19:59,640 --> 00:20:01,214
when you guys were upgrading the cluster.

422
00:20:01,214 --> 00:20:02,850
(Charlie laughs)

423
00:20:02,850 --> 00:20:05,610
But I think that's what
is really important

424
00:20:05,610 --> 00:20:07,710
because you can't afford to lose any time.

425
00:20:07,710 --> 00:20:11,250
- Yep, and then, I can't
remember if I mentioned,

426
00:20:11,250 --> 00:20:13,410
but if you wanna use Run:ai,

427
00:20:13,410 --> 00:20:17,250
so all of this we made
available through AWS.

428
00:20:17,250 --> 00:20:20,490
You don't have to use this
specifically in DGX Cloud.

429
00:20:20,490 --> 00:20:24,420
So all of this is available
through the AWS Marketplace.

430
00:20:24,420 --> 00:20:26,010
So you could kind of mix

431
00:20:26,010 --> 00:20:28,800
and match, like what,
you know, this Stack,

432
00:20:28,800 --> 00:20:33,240
but know that everything's
really optimized together.

433
00:20:33,240 --> 00:20:36,270
So I just kind of
summarized it in this slide

434
00:20:36,270 --> 00:20:40,050
what Sathwik just talked
about, what he just shared.

435
00:20:40,050 --> 00:20:42,483
But turning to you, Jamie,

436
00:20:43,608 --> 00:20:48,240
how did you guys use, you
know, NVIDIA DGX Cloud

437
00:20:48,240 --> 00:20:51,300
and AWS to accomplish your goals

438
00:20:51,300 --> 00:20:53,010
that you just described to us?

439
00:20:53,010 --> 00:20:55,650
- Yeah, yeah, so we've
got a long relationship,

440
00:20:55,650 --> 00:20:58,230
and we've often had quite a lot

441
00:20:58,230 --> 00:21:01,080
of in-house infrastructure
for running HPC workflows

442
00:21:01,080 --> 00:21:03,540
for simulation and seismic processing.

443
00:21:03,540 --> 00:21:06,960
So we kind of start off with
having some infrastructure,

444
00:21:06,960 --> 00:21:10,050
and when we were building
and training these models,

445
00:21:10,050 --> 00:21:13,860
we had some, 100 infrastructure
that we ran locally

446
00:21:13,860 --> 00:21:16,800
that kind of got us off
the ground, I suppose.

447
00:21:16,800 --> 00:21:19,680
But then, the world's moving
very quickly, you know,

448
00:21:19,680 --> 00:21:23,220
and we've just done two major
project product releases,

449
00:21:23,220 --> 00:21:26,820
Generative AI and Agentic
Assistant in the last two years.

450
00:21:26,820 --> 00:21:29,400
And so, given how quickly
the world was moving,

451
00:21:29,400 --> 00:21:32,400
we decided to leverage
our relationship with AWS

452
00:21:32,400 --> 00:21:37,230
and within NVIDIA to use
DGX Cloud to bring stuff

453
00:21:37,230 --> 00:21:39,420
to market much quicker
than we would've done

454
00:21:39,420 --> 00:21:42,030
if we were just using
our own infrastructure.

455
00:21:42,030 --> 00:21:46,290
So we were really able to
accelerate the development

456
00:21:46,290 --> 00:21:49,830
of these models, these
domain-specific models,

457
00:21:49,830 --> 00:21:51,660
by using this TurnKey Stack

458
00:21:51,660 --> 00:21:54,270
where everything worked
beautifully out of the box.

459
00:21:54,270 --> 00:21:57,450
The team was able to work
on what mattered to them,

460
00:21:57,450 --> 00:22:02,450
and then we were able to depend
on the performance quality

461
00:22:02,670 --> 00:22:05,310
and support that we got,

462
00:22:05,310 --> 00:22:08,340
and the ability to not have
to purchase some, you know,

463
00:22:08,340 --> 00:22:09,690
new hardware and everything else used

464
00:22:09,690 --> 00:22:12,960
in the elastic compute capability of AWS

465
00:22:12,960 --> 00:22:15,900
along with that
beautifully optimized Stack

466
00:22:15,900 --> 00:22:19,380
to really let us focus on
producing these domain models.

467
00:22:19,380 --> 00:22:22,980
And we were able to make
great progress, you know?

468
00:22:22,980 --> 00:22:26,220
And then we were able to
partner, DGX Cloud was able

469
00:22:26,220 --> 00:22:28,530
to be optimized through
the support that we had

470
00:22:28,530 --> 00:22:32,190
to get increases in throughput
from the same hardware

471
00:22:32,190 --> 00:22:34,920
as we moved from a 2D
model to a two-and-a-half-D

472
00:22:34,920 --> 00:22:38,760
to a 3D model for the
Seismic Foundation model.

473
00:22:38,760 --> 00:22:41,700
So, really, it's been a
brilliant support for us

474
00:22:41,700 --> 00:22:45,120
as we are trying to bring
products to market quickly

475
00:22:45,120 --> 00:22:47,280
and not having to worry
about the infrastructure,

476
00:22:47,280 --> 00:22:50,433
and being able to tap into
the AWS and DGX Cloud.

477
00:22:51,300 --> 00:22:52,293
- Okay, great.

478
00:22:54,547 --> 00:22:57,510
Sathwik, you are talking
about your, you know,

479
00:22:57,510 --> 00:22:59,223
the Apriel models.

480
00:23:01,080 --> 00:23:04,080
How do the models, like the models

481
00:23:04,080 --> 00:23:05,820
that you're building,

482
00:23:05,820 --> 00:23:08,550
tell us a little bit more about Apriel,

483
00:23:08,550 --> 00:23:10,200
you know, family models,

484
00:23:10,200 --> 00:23:15,200
and how it plays into
ServiceNow's overall strategy,

485
00:23:15,720 --> 00:23:17,400
and kind of portfolio offering.

486
00:23:17,400 --> 00:23:21,840
- Yeah, so we've been
training models for about two,

487
00:23:21,840 --> 00:23:23,223
two-and-a-half years now.

488
00:23:24,120 --> 00:23:27,300
And we decided to
open-source all the models

489
00:23:27,300 --> 00:23:30,693
that we train starting this year, Jan,

490
00:23:31,620 --> 00:23:33,780
just because it brings more awareness

491
00:23:33,780 --> 00:23:35,040
about what we are doing.

492
00:23:35,040 --> 00:23:37,140
And also, at the same time,

493
00:23:37,140 --> 00:23:38,760
the model by itself can't do much

494
00:23:38,760 --> 00:23:41,610
without all the agentic orchestrators

495
00:23:41,610 --> 00:23:44,130
and the tools, and the
data, and whatnot, right?

496
00:23:44,130 --> 00:23:47,460
So, and this year,

497
00:23:47,460 --> 00:23:50,220
we've done three model releases so far.

498
00:23:50,220 --> 00:23:53,220
There was a 5-billion-parameter
model that we trained,

499
00:23:53,220 --> 00:23:56,580
and then we trained a
15-billion-parameter reasoning model.

500
00:23:56,580 --> 00:23:57,870
And then we also upgraded

501
00:23:57,870 --> 00:23:59,880
the same 15-billion-parameter
reasoning model,

502
00:23:59,880 --> 00:24:03,300
which is like a multimodal model.

503
00:24:03,300 --> 00:24:05,943
It consumes images,
texts, and outputs text.

504
00:24:07,800 --> 00:24:10,470
And our goal here is
obviously not to compete

505
00:24:10,470 --> 00:24:13,203
with Frontier Labs.

506
00:24:14,040 --> 00:24:16,770
It's really about how can we build

507
00:24:16,770 --> 00:24:20,620
Frontier-level reasoning performance

508
00:24:22,350 --> 00:24:24,570
on a single GPU scale, right?

509
00:24:24,570 --> 00:24:28,080
Because if I can have a
very small model that's able

510
00:24:28,080 --> 00:24:30,540
to do like the most complex tasks,

511
00:24:30,540 --> 00:24:32,610
it means that I can service a large amount

512
00:24:32,610 --> 00:24:36,060
of workloads without spending a lot.

513
00:24:36,060 --> 00:24:37,800
And this will really allow us,

514
00:24:37,800 --> 00:24:39,690
allow our customers to
like pick and choose.

515
00:24:39,690 --> 00:24:42,060
Like, if they have the
most complex use cases,

516
00:24:42,060 --> 00:24:45,780
they can reserve all of the,
whatever OpenAI cloud credits

517
00:24:45,780 --> 00:24:47,250
for those kind of tasks,

518
00:24:47,250 --> 00:24:49,470
and then just be able to
default to like our models

519
00:24:49,470 --> 00:24:51,420
for most of the other use cases.

520
00:24:51,420 --> 00:24:52,253
- Yeah.

521
00:24:53,430 --> 00:24:56,440
- So if we look at a couple
of slides further down.

522
00:24:56,440 --> 00:24:58,540
- Oh, yeah.

523
00:24:58,540 --> 00:25:02,130
- Yeah, so this is from
a model that we released,

524
00:25:02,130 --> 00:25:04,380
like maybe a couple of months ago,

525
00:25:04,380 --> 00:25:05,980
maybe one-and-a-half months ago.

526
00:25:07,560 --> 00:25:09,810
Our model is highlighted in the red box.

527
00:25:09,810 --> 00:25:14,550
If you can see, it's kind
of on par with DeepSeek R1,

528
00:25:14,550 --> 00:25:17,790
and you know, Gemini Flash.

529
00:25:17,790 --> 00:25:20,790
And for, you know, just talking
about how big our model is,

530
00:25:20,790 --> 00:25:22,920
we are at 15-billion-parameter scale.

531
00:25:22,920 --> 00:25:25,470
DeepSeek R1 is about 600 billion.

532
00:25:25,470 --> 00:25:27,720
And then Quinn is about, you know,

533
00:25:27,720 --> 00:25:31,200
you see it's about like 235 billion.

534
00:25:31,200 --> 00:25:33,600
I don't know how big Gemini
Flash is, honestly. (laughs)

535
00:25:33,600 --> 00:25:38,010
But our model is like kind
of on par with a model

536
00:25:38,010 --> 00:25:42,000
that's like 30 times larger than its size.

537
00:25:42,000 --> 00:25:44,670
And the open-source community
also seems to love it

538
00:25:44,670 --> 00:25:47,880
because we got like close
to 100,000 downloads.

539
00:25:47,880 --> 00:25:50,430
People are using it, and
we bring the same model

540
00:25:50,430 --> 00:25:53,520
into production, so people
can actually leverage it

541
00:25:53,520 --> 00:25:55,530
for whatever use cases they might have.

542
00:25:55,530 --> 00:25:56,480
- Awesome.
- Yeah.

543
00:25:57,510 --> 00:25:58,343
- Great.

544
00:26:00,810 --> 00:26:05,730
Jamie, you mentioned, you
know, as we're prepping,

545
00:26:05,730 --> 00:26:09,750
there's some unique
challenges that you guys faced

546
00:26:09,750 --> 00:26:14,750
as you were, you know, training
and developing your AI.

547
00:26:14,803 --> 00:26:17,430
Do you wanna share a little
bit about those challenges

548
00:26:17,430 --> 00:26:18,300
because-
- Yeah-

549
00:26:18,300 --> 00:26:20,880
- Some folks in the audience
might be facing similar one-

550
00:26:20,880 --> 00:26:22,290
- So, maybe we go forward to the slide

551
00:26:22,290 --> 00:26:24,190
that has some of the Seismic on there.

552
00:26:25,410 --> 00:26:28,440
So it's very important for
us, as I said earlier on,

553
00:26:28,440 --> 00:26:30,180
that our...

554
00:26:30,180 --> 00:26:33,240
What we are doing here is introducing

555
00:26:33,240 --> 00:26:36,570
generative AI technology into a portfolio

556
00:26:36,570 --> 00:26:37,590
of existing technology.

557
00:26:37,590 --> 00:26:38,967
A bit like the tools that
you have in, you know,

558
00:26:38,967 --> 00:26:41,600
the MCP tools that you have in ServiceNow.

559
00:26:41,600 --> 00:26:45,600
So we will have physics-based
simulators, algorithms,

560
00:26:45,600 --> 00:26:47,970
we'll have machine learning-type models

561
00:26:47,970 --> 00:26:50,790
for doing things like automating fault

562
00:26:50,790 --> 00:26:52,350
and horizon interpretation

563
00:26:52,350 --> 00:26:54,387
that can take months
and months and months.

564
00:26:54,387 --> 00:26:57,480
And so we saw an
opportunity here to be able

565
00:26:57,480 --> 00:27:00,210
to build what's effectively
a multimodal model

566
00:27:00,210 --> 00:27:02,820
that's specific for our industry

567
00:27:02,820 --> 00:27:05,460
that would really accelerate
the work of the people.

568
00:27:05,460 --> 00:27:08,730
So, you know, we do another
example where we have data

569
00:27:08,730 --> 00:27:10,170
that we want to bring into one

570
00:27:10,170 --> 00:27:12,780
of our traditional applications,

571
00:27:12,780 --> 00:27:14,340
but there's some gaps in the data

572
00:27:14,340 --> 00:27:16,020
because the acquisition wasn't clean

573
00:27:16,020 --> 00:27:17,760
or the processing wasn't clean.

574
00:27:17,760 --> 00:27:19,740
And we can call down on this model,

575
00:27:19,740 --> 00:27:23,190
what would normally
have taken weeks or days

576
00:27:23,190 --> 00:27:24,450
or even months sometimes

577
00:27:24,450 --> 00:27:27,060
to reconstruct the
missing data with a human.

578
00:27:27,060 --> 00:27:30,150
We can actually just call on
an agent now to reconstruct

579
00:27:30,150 --> 00:27:33,480
that missing data within
certain constraints

580
00:27:33,480 --> 00:27:35,490
and really accelerate a workflow

581
00:27:35,490 --> 00:27:37,530
and give a really complete
picture of the Earth.

582
00:27:37,530 --> 00:27:41,460
And as you can see here, this
is not just generating text,

583
00:27:41,460 --> 00:27:43,800
it's text to images, images to text,

584
00:27:43,800 --> 00:27:45,720
and ultimately to models.

585
00:27:45,720 --> 00:27:49,740
So, really, this technology for us is

586
00:27:49,740 --> 00:27:51,090
very non-transactional.

587
00:27:51,090 --> 00:27:53,430
It's an almost creative
process that we're trying

588
00:27:53,430 --> 00:27:55,560
to support here amongst scientists.

589
00:27:55,560 --> 00:27:57,120
And really importantly for us,

590
00:27:57,120 --> 00:28:00,210
this has to sit in their
portfolio of tools,

591
00:28:00,210 --> 00:28:02,940
and we have to produce something

592
00:28:02,940 --> 00:28:05,520
that's good enough for
them to trust, right?

593
00:28:05,520 --> 00:28:08,340
You know, with all of their
Ph.D. years of experience,

594
00:28:08,340 --> 00:28:10,050
this tool has to sit along with them

595
00:28:10,050 --> 00:28:12,240
and say, "I can use this assistant

596
00:28:12,240 --> 00:28:14,460
because I know it's been
trained on the data,

597
00:28:14,460 --> 00:28:17,220
I know I can trust the
people that have trained it."

598
00:28:17,220 --> 00:28:20,313
And so, we started off
training it with public data,

599
00:28:21,540 --> 00:28:24,420
and that produced a certain
level of capability.

600
00:28:24,420 --> 00:28:26,220
And now, we've started augmenting that

601
00:28:26,220 --> 00:28:29,640
with proprietary data
from our own acquisitions.

602
00:28:29,640 --> 00:28:30,690
And then, I think one of the things

603
00:28:30,690 --> 00:28:32,790
that's really interesting from
us is that we'll be working

604
00:28:32,790 --> 00:28:35,040
with our customers for that trust thing.

605
00:28:35,040 --> 00:28:36,600
They need to train it and fine-tune it

606
00:28:36,600 --> 00:28:38,220
with their own data as well.

607
00:28:38,220 --> 00:28:40,650
So that's a kind of unique
thing in our business,

608
00:28:40,650 --> 00:28:43,440
is that every one of our major
customers will either take

609
00:28:43,440 --> 00:28:44,430
the off-the-shelf model,

610
00:28:44,430 --> 00:28:47,010
but more likely, they'll combine that

611
00:28:47,010 --> 00:28:48,450
with their own data as well.

612
00:28:48,450 --> 00:28:50,913
So they'll have their
own fine-tuned model.

613
00:28:51,750 --> 00:28:53,640
So, that represents the basins

614
00:28:53,640 --> 00:28:57,030
and the geological settings
that they operate within

615
00:28:57,030 --> 00:28:58,020
to build that trust

616
00:28:58,020 --> 00:29:00,120
that it will provide accurate predictions.

617
00:29:01,590 --> 00:29:03,723
- So, in both your cases, then,

618
00:29:05,370 --> 00:29:08,970
you're offering these models
for your customers to kind

619
00:29:08,970 --> 00:29:13,970
of fine-tune it and kind of
include some of their data

620
00:29:14,250 --> 00:29:16,080
to add the intelligence to it.

621
00:29:16,080 --> 00:29:19,530
So, are you seeing more
customers doing fine-tuning

622
00:29:19,530 --> 00:29:22,170
or doing like a RAG?

623
00:29:22,170 --> 00:29:25,620
Like does everyone
understand what RAG is, what,

624
00:29:25,620 --> 00:29:27,720
or are you familiar what RAG is?

625
00:29:27,720 --> 00:29:30,270
Retrieval Augmented Generation.

626
00:29:30,270 --> 00:29:32,970
Okay, it's basically taking a model

627
00:29:32,970 --> 00:29:34,920
and then going out

628
00:29:34,920 --> 00:29:39,920
to retrieve additional data
from like a vector database

629
00:29:40,200 --> 00:29:41,910
to supplement the knowledge

630
00:29:41,910 --> 00:29:43,440
of the foundation model.

631
00:29:43,440 --> 00:29:45,180
So, are you guys seeing more

632
00:29:45,180 --> 00:29:48,390
like customers taking your model

633
00:29:48,390 --> 00:29:52,050
and then fine-tuning
it or doing like a RAG?

634
00:29:52,050 --> 00:29:55,410
- So, for us, we are not in
the business, as you said,

635
00:29:55,410 --> 00:29:57,450
of building general purpose, you know,

636
00:29:57,450 --> 00:29:59,370
foundational frontier models.

637
00:29:59,370 --> 00:30:01,830
So when it comes to interacting

638
00:30:01,830 --> 00:30:04,740
with the customer's corporate memory,

639
00:30:04,740 --> 00:30:07,320
they don't take ChatGPT and fine-tune it

640
00:30:07,320 --> 00:30:09,060
by sticking their documents in it.

641
00:30:09,060 --> 00:30:11,280
They'll use a RAG-type approach for that.

642
00:30:11,280 --> 00:30:13,140
So the data in the AI platform

643
00:30:13,140 --> 00:30:18,140
that we produce will often
go back through decades

644
00:30:18,360 --> 00:30:21,360
of old documents and
report from the '50s, '60s,

645
00:30:21,360 --> 00:30:22,290
sometimes even back

646
00:30:22,290 --> 00:30:24,750
to the 19th century,
that shows the early days

647
00:30:24,750 --> 00:30:26,370
of oil field expiration.

648
00:30:26,370 --> 00:30:27,977
It's kind of funny if you
read these documents, right?

649
00:30:27,977 --> 00:30:31,320
'Cause the language has
changed a lot over 100 years.

650
00:30:31,320 --> 00:30:34,350
And then what we'll do is
when we ingest that data,

651
00:30:34,350 --> 00:30:37,020
we have to use fancy
techniques for the OCR-ing

652
00:30:37,020 --> 00:30:38,100
of the old data, right?

653
00:30:38,100 --> 00:30:41,040
To capture the semantic
meaning of those old documents.

654
00:30:41,040 --> 00:30:44,100
We'll create pipelines to ingest
that into the environment,

655
00:30:44,100 --> 00:30:45,990
and then automatically vectorize it

656
00:30:45,990 --> 00:30:49,320
so that we have out-the-box
RAG going along.

657
00:30:49,320 --> 00:30:53,430
But then, in the case of
these specialty domains,

658
00:30:53,430 --> 00:30:57,300
petrophysics, geophysics, seismic data,

659
00:30:57,300 --> 00:30:59,070
then we'll actually fine-tune it.

660
00:30:59,070 --> 00:31:02,280
So, texts, reports, documents,

661
00:31:02,280 --> 00:31:06,030
RAG, proper scientific output models,

662
00:31:06,030 --> 00:31:09,270
we'll use the domain foundation
models to create an edge.

663
00:31:09,270 --> 00:31:12,063
- Yeah, I think it's a
little different for us.

664
00:31:13,590 --> 00:31:15,660
If you roll back a couple of slides,

665
00:31:15,660 --> 00:31:18,900
I think you had a nice illustration, yeah,

666
00:31:18,900 --> 00:31:21,810
of how the entire Stack looks like.

667
00:31:21,810 --> 00:31:23,970
So you have like a whole
bunch of documents.

668
00:31:23,970 --> 00:31:28,230
You have like policies,
triggers, tools, whatever else.

669
00:31:28,230 --> 00:31:31,140
And then the large language model is

670
00:31:31,140 --> 00:31:32,850
just a small part of the whole, you know-

671
00:31:32,850 --> 00:31:34,481
- [Charlie] Yeah.

672
00:31:34,481 --> 00:31:35,580
- Whole thing.

673
00:31:35,580 --> 00:31:36,840
So what ends up happening is,

674
00:31:36,840 --> 00:31:40,953
for the most part, when
people start using our system,

675
00:31:41,880 --> 00:31:44,220
it works because,

676
00:31:44,220 --> 00:31:47,550
I mean, how different can, I don't know,

677
00:31:47,550 --> 00:31:52,110
like one customer's
flight ordering, you know,

678
00:31:52,110 --> 00:31:53,490
like flight booking

679
00:31:53,490 --> 00:31:56,370
versus like whatever
food ordering system be

680
00:31:56,370 --> 00:31:57,270
from another customer, right?

681
00:31:57,270 --> 00:32:00,420
So the reason why it gets
complex between customer

682
00:32:00,420 --> 00:32:02,340
to customer is because
they have different ways

683
00:32:02,340 --> 00:32:04,380
of implementing their own policies,

684
00:32:04,380 --> 00:32:06,570
and sometimes the model
just does not understand

685
00:32:06,570 --> 00:32:07,440
what it's doing.

686
00:32:07,440 --> 00:32:11,520
So ServiceNow actually allows people

687
00:32:11,520 --> 00:32:15,810
to customize the agentic, you know,

688
00:32:15,810 --> 00:32:19,230
the agentic scaffolding.
- Yeah.

689
00:32:19,230 --> 00:32:21,090
- You can have custom policies defined,

690
00:32:21,090 --> 00:32:23,010
you can have guardrails.

691
00:32:23,010 --> 00:32:25,773
And for the most part,
we see that this works.

692
00:32:26,850 --> 00:32:30,630
And I mean, if there are
enough customers asking

693
00:32:30,630 --> 00:32:34,200
for custom models, maybe
that's gonna be a thing.

694
00:32:34,200 --> 00:32:39,150
But yeah, I think it's for
the most part not necessary.

695
00:32:39,150 --> 00:32:40,950
- Okay, great.

696
00:32:40,950 --> 00:32:43,650
Then, like, where do
you guys go from here?

697
00:32:43,650 --> 00:32:46,650
So, how will you move
forward with your projects

698
00:32:46,650 --> 00:32:49,350
after using DGX Cloud on AWS?

699
00:32:49,350 --> 00:32:51,630
So kind of what's next?

700
00:32:51,630 --> 00:32:56,310
Like you have your model,
how are you gonna kind

701
00:32:56,310 --> 00:32:58,530
of deploy, are you gonna
come back to DGX Cloud?

702
00:32:58,530 --> 00:33:02,400
Are you gonna use AWS
infrastructure service,

703
00:33:02,400 --> 00:33:04,110
a mix of on-prem?

704
00:33:04,110 --> 00:33:05,910
Like, what's next for you guys?

705
00:33:05,910 --> 00:33:09,063
- Yeah, I think from what
I can definitely say,

706
00:33:11,070 --> 00:33:12,720
I mean, you think about NVIDIA,

707
00:33:12,720 --> 00:33:16,590
and then it's like, you know,
you guys are a pioneer in AI,

708
00:33:16,590 --> 00:33:19,410
think about AWS, it's, you know, arguably,

709
00:33:19,410 --> 00:33:22,590
one of the best clouds in the world.

710
00:33:22,590 --> 00:33:24,180
So you don't wanna let go of both.

711
00:33:24,180 --> 00:33:26,130
You wanna have both
(laughs) of them combined

712
00:33:26,130 --> 00:33:29,130
in the right manner, so to say.

713
00:33:29,130 --> 00:33:30,480
But, I think, you know,

714
00:33:30,480 --> 00:33:32,760
DGX has been super useful,

715
00:33:32,760 --> 00:33:36,720
and at the same time, DGX
has been hosted on AWS,

716
00:33:36,720 --> 00:33:40,980
and we've seen that it's super reliable,

717
00:33:40,980 --> 00:33:45,420
scalable, quick, and I think we'd hope

718
00:33:45,420 --> 00:33:48,090
to like continue with the same thing.

719
00:33:48,090 --> 00:33:51,393
But at the same time, like
you said, Run:ai is on AWS,

720
00:33:53,650 --> 00:33:55,567
you know, Lustre is from AWS,

721
00:33:56,880 --> 00:33:59,490
there is existing
infrastructure that would

722
00:33:59,490 --> 00:34:04,140
obviously encourage us to
explore that option, too.

723
00:34:04,140 --> 00:34:07,410
I think, you know,
ideally, we want both, but-

724
00:34:07,410 --> 00:34:08,823
- Yeah, awesome.

725
00:34:09,960 --> 00:34:11,880
- Yeah, I think for us, DGX Cloud

726
00:34:11,880 --> 00:34:13,800
and our partnership with AWS

727
00:34:13,800 --> 00:34:16,440
and NVIDIA was fantastic for that kind

728
00:34:16,440 --> 00:34:17,970
of early-stage product development.

729
00:34:17,970 --> 00:34:20,763
It's given them, us, the
velocity that we needed.

730
00:34:21,660 --> 00:34:24,900
I think when it comes to
us scaling out globally,

731
00:34:24,900 --> 00:34:26,550
we'll use a variety of techniques.

732
00:34:26,550 --> 00:34:29,520
Some customers are so sensitive
about their proprietary data

733
00:34:29,520 --> 00:34:31,680
that they're gonna wanna deal
with that on-prem, right?

734
00:34:31,680 --> 00:34:34,500
So, you know, we do that.

735
00:34:34,500 --> 00:34:37,500
Similarly, we offer a lot of services

736
00:34:37,500 --> 00:34:39,780
as a SaaS to a global market.

737
00:34:39,780 --> 00:34:43,170
So we'll be able to leverage
the commodity infrastructure

738
00:34:43,170 --> 00:34:47,250
and commit to, you know, the
services that you get from AWS

739
00:34:47,250 --> 00:34:51,870
or other providers to be able
to deliver solutions globally.

740
00:34:51,870 --> 00:34:55,920
But I think we always remind
ourselves that this is really,

741
00:34:55,920 --> 00:34:58,560
we are really at the early
stages of this revolution.

742
00:34:58,560 --> 00:35:00,810
You know, we're out there
talking to customers,

743
00:35:00,810 --> 00:35:02,370
discovering what they need.

744
00:35:02,370 --> 00:35:04,920
So something like DGX
Cloud is super important

745
00:35:04,920 --> 00:35:06,990
so that we can respond to what we learn

746
00:35:06,990 --> 00:35:08,760
from the customers in the market,

747
00:35:08,760 --> 00:35:13,410
and then as we effectively
establish a pattern

748
00:35:13,410 --> 00:35:16,380
and we wanna develop and
mature that, then we can move

749
00:35:16,380 --> 00:35:19,020
towards more commodity
infrastructure as well.

750
00:35:19,020 --> 00:35:21,000
But I think it's gonna be very dynamic

751
00:35:21,000 --> 00:35:22,800
over the next few years to understand

752
00:35:22,800 --> 00:35:24,480
where the world's going with all of this.

753
00:35:24,480 --> 00:35:26,010
- Yeah.
- Especially in our industry,

754
00:35:26,010 --> 00:35:27,480
because they're not just looking at it

755
00:35:27,480 --> 00:35:29,280
for process automation.

756
00:35:29,280 --> 00:35:30,870
In our industry, people are saying

757
00:35:30,870 --> 00:35:34,920
that we want to use agents
to retire uncertainty,

758
00:35:34,920 --> 00:35:38,700
to explore more options than
they would've been able to do

759
00:35:38,700 --> 00:35:40,770
with their previous resourcing levels.

760
00:35:40,770 --> 00:35:42,060
They want to...

761
00:35:42,060 --> 00:35:44,130
They don't just wanna do RAG

762
00:35:44,130 --> 00:35:46,050
on their existing corporate documents

763
00:35:46,050 --> 00:35:49,050
because then their future
organization would always behave

764
00:35:49,050 --> 00:35:50,850
like their past organization.
- Yeah.

765
00:35:50,850 --> 00:35:53,340
- They want to kind of have a diversity

766
00:35:53,340 --> 00:35:54,390
of sources coming in.

767
00:35:54,390 --> 00:35:57,480
So I think it's gonna be a
really interesting period

768
00:35:57,480 --> 00:36:00,330
and we're gonna need all kinds
of infrastructure support,

769
00:36:00,330 --> 00:36:03,450
but definitely with the
scale that you get from AWS,

770
00:36:03,450 --> 00:36:06,810
and the elastic capability,
and the kind of precision,

771
00:36:06,810 --> 00:36:08,460
and beautifully integrated Stack

772
00:36:08,460 --> 00:36:10,300
that you get from NVIDIA DGX.

773
00:36:10,300 --> 00:36:12,300
- Yeah, it's amazing, 'cause you're saying

774
00:36:12,300 --> 00:36:15,480
how like your industry
started like in the 1900s.

775
00:36:15,480 --> 00:36:17,010
- Yeah, yeah.
- It seems like AI's

776
00:36:17,010 --> 00:36:18,780
really like making it go fast now,

777
00:36:18,780 --> 00:36:20,190
even though it's a mature market.

778
00:36:20,190 --> 00:36:21,720
- And it took us 100 years to get there.

779
00:36:21,720 --> 00:36:22,590
- Yeah. (laughs)

780
00:36:22,590 --> 00:36:24,990
- We're celebrating 100 years, next year.

781
00:36:24,990 --> 00:36:27,157
2026 is SLB's 100th anniversary.

782
00:36:27,157 --> 00:36:28,530
- Yeah.
- So, yeah.

783
00:36:28,530 --> 00:36:30,300
- Yeah, and I think, you know,

784
00:36:30,300 --> 00:36:32,130
something we touch upon is

785
00:36:32,130 --> 00:36:34,650
the NVIDIA, like full-Stack Ecosystem,

786
00:36:34,650 --> 00:36:39,390
whether you're using it, you
know, on-prem, in the Cloud,

787
00:36:39,390 --> 00:36:40,590
it's really portable.

788
00:36:40,590 --> 00:36:41,910
So you have that flexibility,

789
00:36:41,910 --> 00:36:45,300
and again, that whole
ecosystem's available on AWS,

790
00:36:45,300 --> 00:36:47,790
through the Marketplace,
embedded in their services.

791
00:36:47,790 --> 00:36:50,400
So that portability adds a lot of value

792
00:36:50,400 --> 00:36:52,833
and flexibility to customers.

793
00:36:54,060 --> 00:36:56,400
We have some time left.

794
00:36:56,400 --> 00:36:59,220
I don't know if anyone has questions.

795
00:36:59,220 --> 00:37:02,790
This isn't the most conducive
way of asking questions.

796
00:37:02,790 --> 00:37:05,970
Does anyone have a question
you could just ask?

797
00:37:05,970 --> 00:37:08,343
I could repeat it so
everyone could hear it.

798
00:37:09,210 --> 00:37:11,880
If not, there's
opportunity to come to talk

799
00:37:11,880 --> 00:37:13,320
to us after.

800
00:37:13,320 --> 00:37:17,370
And I also, oh,

801
00:37:17,370 --> 00:37:21,000
did you wanna cover this
one real quick, Jamie?

802
00:37:21,000 --> 00:37:24,120
- I mean, I think this is really
just describing our journey

803
00:37:24,120 --> 00:37:26,970
with DGX, and how it was
able to match our needs,

804
00:37:26,970 --> 00:37:30,030
as we innovated over a two-year period.

805
00:37:30,030 --> 00:37:34,300
And as we move from rudimentary models

806
00:37:35,460 --> 00:37:39,180
and moved up from a sort
of 2D model to a 3D model

807
00:37:39,180 --> 00:37:41,373
to be able to build.

808
00:37:42,510 --> 00:37:44,160
And again, we are really
just at the beginning

809
00:37:44,160 --> 00:37:45,087
of this journey, right?
- Yeah.

810
00:37:45,087 --> 00:37:48,150
- But now we are starting
to get foundation models

811
00:37:48,150 --> 00:37:51,180
that produce really
plausible generative results

812
00:37:51,180 --> 00:37:53,550
that we can incorporate into workflows

813
00:37:53,550 --> 00:37:56,730
alongside our existing machine
learning-based approaches

814
00:37:56,730 --> 00:37:58,680
and our existing physics,

815
00:37:58,680 --> 00:38:01,500
and you know, strict
mathematical-based approaches as well.

816
00:38:01,500 --> 00:38:04,350
So these are gonna become
a very important part

817
00:38:04,350 --> 00:38:06,030
of our toolkit going forward.

818
00:38:06,030 --> 00:38:09,000
And you can see, you know, that we've been

819
00:38:09,000 --> 00:38:11,580
through quite a steep
learning curve, and AWS

820
00:38:11,580 --> 00:38:14,160
and NVIDIA have very much
supported our learning curve,

821
00:38:14,160 --> 00:38:16,410
the velocity that we needed.

822
00:38:16,410 --> 00:38:19,440
- Great, thank you so
much for attending today.

823
00:38:19,440 --> 00:38:21,090
Really appreciate you.

824
00:38:21,090 --> 00:38:22,080
Enjoy the show.

