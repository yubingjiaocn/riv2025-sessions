1
00:00:00,691 --> 00:00:05,010
- Welcome to Vegas.
Welcome to re:Invent 2025.

2
00:00:05,010 --> 00:00:07,740
You are in ANT 307,

3
00:00:07,740 --> 00:00:12,740
operating and scaling managed
Apache Kafka and Flink.

4
00:00:13,050 --> 00:00:15,120
My name is Ashish Palekar.

5
00:00:15,120 --> 00:00:18,540
I take care of our Kafka, Flink,

6
00:00:18,540 --> 00:00:21,150
and Firehose services here at AWS,

7
00:00:21,150 --> 00:00:24,930
which means that I spend
time talking to customers,

8
00:00:24,930 --> 00:00:27,240
but also building the service,

9
00:00:27,240 --> 00:00:28,590
but also operating the service.

10
00:00:28,590 --> 00:00:29,760
With me is...

11
00:00:29,760 --> 00:00:31,890
- I'm Sai Maddali, I
lead the product teams

12
00:00:31,890 --> 00:00:33,450
for our Amazon managed streaming

13
00:00:33,450 --> 00:00:35,910
for Apache Kafka, managed
service for Apache Flink

14
00:00:35,910 --> 00:00:37,203
and Amazon Data Firehose.

15
00:00:38,070 --> 00:00:38,903
- Very cool.

16
00:00:38,903 --> 00:00:42,150
So today we are going to cover a bunch

17
00:00:42,150 --> 00:00:45,750
of what we are doing with
our Kafka and Flink services.

18
00:00:45,750 --> 00:00:47,606
We're gonna walk you through our learnings

19
00:00:47,606 --> 00:00:49,200
and compare and contrast,

20
00:00:49,200 --> 00:00:51,450
give you a sense of what we've learned

21
00:00:51,450 --> 00:00:56,450
and hopefully we can cover a
lot of details in the session.

22
00:00:56,850 --> 00:00:58,710
So let's get started.

23
00:00:58,710 --> 00:00:59,640
As we go through it,

24
00:00:59,640 --> 00:01:02,550
a lot of customers often
start with why streaming data

25
00:01:02,550 --> 00:01:04,380
and why now?

26
00:01:04,380 --> 00:01:06,240
It really boils down to four things

27
00:01:06,240 --> 00:01:08,130
that we hear from customers.

28
00:01:08,130 --> 00:01:10,950
It's about unlocking
real value from your data

29
00:01:10,950 --> 00:01:13,140
in real time as it flows,

30
00:01:13,140 --> 00:01:15,600
helps you make decisions in real time

31
00:01:15,600 --> 00:01:19,890
and shorten the time to
actually get to insights.

32
00:01:19,890 --> 00:01:23,610
You can get continuous
intelligence from that data.

33
00:01:23,610 --> 00:01:24,840
And last, but not the least,

34
00:01:24,840 --> 00:01:28,800
as we are continually seeing
now with AI workloads,

35
00:01:28,800 --> 00:01:30,150
you need more contextualized data.

36
00:01:30,150 --> 00:01:32,040
You need more fresh data.

37
00:01:32,040 --> 00:01:34,473
And streaming technologies
help you get that.

38
00:01:36,000 --> 00:01:39,600
Here at AWS, we love Kafka and Flink.

39
00:01:39,600 --> 00:01:42,780
We have had Kafka and Flink services

40
00:01:42,780 --> 00:01:45,570
for well over five years at this point.

41
00:01:45,570 --> 00:01:50,310
And in fact have been operating
workloads for customers.

42
00:01:50,310 --> 00:01:52,077
We have customers who also
use self-managed Kafka

43
00:01:52,077 --> 00:01:54,150
and Flink in addition to ours.

44
00:01:54,150 --> 00:01:57,120
And there's certainly other
partner solutions as well.

45
00:01:57,120 --> 00:02:00,960
But really, we see a large

46
00:02:00,960 --> 00:02:03,903
and wide variety of
workloads across the board.

47
00:02:05,460 --> 00:02:08,310
So one of the things I
get asked by customers

48
00:02:08,310 --> 00:02:11,490
is what are the outcomes
that customers look for

49
00:02:11,490 --> 00:02:13,350
when running at scale?

50
00:02:13,350 --> 00:02:15,600
What do customers really care about?

51
00:02:15,600 --> 00:02:18,780
It really boils down to price performance,

52
00:02:18,780 --> 00:02:23,400
boils down to reliability,
boils down to security

53
00:02:23,400 --> 00:02:25,050
and boils down to performance.

54
00:02:25,050 --> 00:02:27,060
These seem like basics,

55
00:02:27,060 --> 00:02:30,900
but at the same time, at
scale, these are magnified.

56
00:02:30,900 --> 00:02:33,920
And every one of you
that is operating a Kafka

57
00:02:33,920 --> 00:02:36,180
or Flink service knows that.

58
00:02:36,180 --> 00:02:37,140
Just by show of hands,

59
00:02:37,140 --> 00:02:39,213
how many of you operate a Kafka service?

60
00:02:40,800 --> 00:02:42,810
Vast majority of you. Awesome.

61
00:02:42,810 --> 00:02:44,340
So that this helps Sai later on,

62
00:02:44,340 --> 00:02:45,783
how many of you use Flink?

63
00:02:46,740 --> 00:02:50,344
Few of you. We'll talk about that too.

64
00:02:50,344 --> 00:02:53,010
Thank you for being our customers.

65
00:02:53,010 --> 00:02:54,570
These are some other customers.

66
00:02:54,570 --> 00:02:56,700
Customers make our world go round

67
00:02:56,700 --> 00:03:01,170
and this is absolutely super
helpful for us to understand

68
00:03:01,170 --> 00:03:02,420
what customers are doing.

69
00:03:03,270 --> 00:03:05,420
So let's talk about
running Kafka at scale.

70
00:03:07,124 --> 00:03:09,240
Always love to start
with a customer example.

71
00:03:09,240 --> 00:03:14,240
Nexthink, Nexthink is a customer
based out of Switzerland

72
00:03:15,420 --> 00:03:20,420
and really focus on how to go
build developer experience.

73
00:03:20,460 --> 00:03:21,570
Their core problem

74
00:03:21,570 --> 00:03:26,570
was how to help scale their
Kafka business, switch to MSK.

75
00:03:26,670 --> 00:03:28,140
They were running on premises,

76
00:03:28,140 --> 00:03:31,500
switch to MSK on AWS, and
they can process now trillions

77
00:03:31,500 --> 00:03:34,710
of events a day, reaching
five gigabytes per second

78
00:03:34,710 --> 00:03:36,287
of aggregated throughput.

79
00:03:36,287 --> 00:03:38,760
Really has been compelling
to watch their journey

80
00:03:38,760 --> 00:03:40,680
in scaling from 200 megabytes

81
00:03:40,680 --> 00:03:41,910
to five gigabytes per second.

82
00:03:41,910 --> 00:03:46,080
And that has taught them,

83
00:03:46,080 --> 00:03:48,330
as well as us a whole bunch of lessons

84
00:03:48,330 --> 00:03:50,943
and as we observe workloads
across our customers.

85
00:03:52,740 --> 00:03:55,203
So when we think about
the spectrum of Kafka,

86
00:03:56,430 --> 00:03:59,193
and I'll speak to sort
of the services we offer,

87
00:04:00,330 --> 00:04:03,660
we think of it across a
two-pronged spectrum, right?

88
00:04:03,660 --> 00:04:07,410
Like, on the left-hand side,
you have more Kafka control

89
00:04:07,410 --> 00:04:10,563
and on the right-hand side,
you have more Kafka automation.

90
00:04:11,550 --> 00:04:14,790
In the more Kafka control
case, we offer standard brokers

91
00:04:14,790 --> 00:04:15,903
for Amazon MSK.

92
00:04:16,740 --> 00:04:20,100
This is the case when you're migrating

93
00:04:20,100 --> 00:04:21,990
from an existing Kafka setup.

94
00:04:21,990 --> 00:04:24,850
You need fine grained control for Kafka

95
00:04:26,611 --> 00:04:29,280
and have deep know-how
about how Kafka works.

96
00:04:29,280 --> 00:04:31,890
And that becomes important.

97
00:04:31,890 --> 00:04:36,060
On the other end of the spectrum
is Amazon MSK Serverless

98
00:04:36,060 --> 00:04:38,910
where you can quickly
deploy and scale up Kafka.

99
00:04:38,910 --> 00:04:41,070
You don't need Kafka
management and you don't need

100
00:04:41,070 --> 00:04:43,353
or care about the nuances
of managing Kafka.

101
00:04:44,940 --> 00:04:47,670
And in between, this is
something we launched last year,

102
00:04:47,670 --> 00:04:50,560
last November, is Express brokers for MSK

103
00:04:51,808 --> 00:04:54,270
where you value performance and elasticity

104
00:04:54,270 --> 00:04:57,960
where you want or need
lower control over Kafka.

105
00:04:57,960 --> 00:05:01,110
And typically what we see is
this is a set of customers

106
00:05:01,110 --> 00:05:02,763
that is managing Kafka at scale.

107
00:05:05,100 --> 00:05:07,830
And this is something
I provide as guidance

108
00:05:07,830 --> 00:05:09,630
to customers when I talk to them.

109
00:05:09,630 --> 00:05:11,820
Unless you know differently,

110
00:05:11,820 --> 00:05:13,710
always recommend you start from Express.

111
00:05:13,710 --> 00:05:15,300
It's a good place to
start for your workloads

112
00:05:15,300 --> 00:05:17,283
and then decide where to go.

113
00:05:19,080 --> 00:05:24,080
So across this family of products,

114
00:05:25,080 --> 00:05:28,500
we see a diversity of Kafka workloads

115
00:05:28,500 --> 00:05:31,560
and it gives us really,
really interesting insights.

116
00:05:31,560 --> 00:05:34,890
We see customers operating
at small scale, large scale.

117
00:05:34,890 --> 00:05:37,110
We see customers operating
with a high partition count,

118
00:05:37,110 --> 00:05:40,470
low partition count, combinations of both.

119
00:05:40,470 --> 00:05:44,215
And that entails different things.

120
00:05:44,215 --> 00:05:46,890
One of the first areas
that I'll talk about today

121
00:05:46,890 --> 00:05:48,480
is about storage management.

122
00:05:48,480 --> 00:05:50,610
And this starts to get tricky,

123
00:05:50,610 --> 00:05:52,083
especially at scale.

124
00:05:53,550 --> 00:05:56,670
Specifically, storage scaling takes time

125
00:05:56,670 --> 00:05:58,830
and as we started looking at it,

126
00:05:58,830 --> 00:06:00,420
you can go from four terabytes

127
00:06:00,420 --> 00:06:01,770
to eight terabytes to 12 terabytes.

128
00:06:01,770 --> 00:06:03,450
All of this is possible.

129
00:06:03,450 --> 00:06:06,000
One of the things we
consistently see is customers

130
00:06:06,000 --> 00:06:08,763
who are not monitoring
their storage utilization.

131
00:06:09,630 --> 00:06:12,300
In fact, your storage
utilization can spike.

132
00:06:12,300 --> 00:06:15,960
You can start to start to see

133
00:06:15,960 --> 00:06:19,080
that grow as workloads change.

134
00:06:19,080 --> 00:06:22,830
If you haven't already, there
is something MSK offers,

135
00:06:22,830 --> 00:06:25,050
you should subscribe to disk full alerts.

136
00:06:25,050 --> 00:06:28,680
You get alerts at 60% full, at 80% full

137
00:06:28,680 --> 00:06:31,140
and then when it's actually full.

138
00:06:31,140 --> 00:06:33,270
But that will alert you to make sure

139
00:06:33,270 --> 00:06:35,643
that your capacity is
actually taken care of.

140
00:06:36,810 --> 00:06:41,160
One thing we noticed is it
is easy to scale up capacity,

141
00:06:41,160 --> 00:06:42,840
but you don't have a capacity scale-down.

142
00:06:42,840 --> 00:06:45,300
And that is something
that trips up customers.

143
00:06:45,300 --> 00:06:48,030
And so customers often
delay making a decision

144
00:06:48,030 --> 00:06:50,880
about scaling up and
something that is a tension

145
00:06:50,880 --> 00:06:53,373
that you need to wrestle
with as customers.

146
00:06:55,020 --> 00:06:57,450
Recognizing that, one of the things we did

147
00:06:57,450 --> 00:06:59,850
is when we built Express brokers,

148
00:06:59,850 --> 00:07:02,543
we eliminated storage management.

149
00:07:02,543 --> 00:07:06,210
What we operated with is really started

150
00:07:06,210 --> 00:07:09,090
with not having any storage configuration.

151
00:07:09,090 --> 00:07:10,920
Just tell us your attention period

152
00:07:10,920 --> 00:07:12,990
and we are off to the races.

153
00:07:12,990 --> 00:07:16,530
You get virtually unlimited
storage capacity per broker,

154
00:07:16,530 --> 00:07:19,950
which means you really don't
have this conceptual notion

155
00:07:19,950 --> 00:07:22,170
of what a disk full looks like.

156
00:07:22,170 --> 00:07:26,370
Your storage is provisioned
per cluster versus per broker

157
00:07:26,370 --> 00:07:28,740
and that obviously has cost savings,

158
00:07:28,740 --> 00:07:30,660
but equally importantly makes it easier

159
00:07:30,660 --> 00:07:35,190
to sort of imagine what your
overall workload size is

160
00:07:35,190 --> 00:07:36,720
and then you pay for what you use

161
00:07:36,720 --> 00:07:39,000
versus needing provisioned capacities.

162
00:07:39,000 --> 00:07:41,310
And last but not the
least, you get hands free

163
00:07:41,310 --> 00:07:45,090
and instant scaling on the storage side,

164
00:07:45,090 --> 00:07:46,800
and that is also super useful.

165
00:07:46,800 --> 00:07:49,770
So if you really look at
sort of the core tenets

166
00:07:49,770 --> 00:07:51,870
of how we worked on storage management,

167
00:07:51,870 --> 00:07:54,000
if you think about it
in the Express context,

168
00:07:54,000 --> 00:07:57,053
our focus was we wanted to
eliminate storage management

169
00:07:57,053 --> 00:08:01,473
for you and that entailed
doing all these five things.

170
00:08:03,570 --> 00:08:05,560
The other area that that we see

171
00:08:06,450 --> 00:08:07,800
where customers are challenged with

172
00:08:07,800 --> 00:08:09,720
is around failure handling.

173
00:08:09,720 --> 00:08:12,000
And so you say, "Well,
what does that mean?"

174
00:08:12,000 --> 00:08:15,450
Well, here what we have
is a three-broker cluster.

175
00:08:15,450 --> 00:08:16,770
You have producers, you have consumers,

176
00:08:16,770 --> 00:08:18,750
you have consumers in the consumer group.

177
00:08:18,750 --> 00:08:21,810
The producer is producing
to two brokers here.

178
00:08:21,810 --> 00:08:24,720
So what does the basic traffic look like?

179
00:08:24,720 --> 00:08:27,660
You have producer traffic,
you have consumer traffic,

180
00:08:27,660 --> 00:08:29,761
you have replication traffic,

181
00:08:29,761 --> 00:08:32,610
and depending on your workload,

182
00:08:32,610 --> 00:08:34,610
you have partition compute needs, right?

183
00:08:35,520 --> 00:08:37,380
Very rarely we do encounter workloads

184
00:08:37,380 --> 00:08:40,530
or I guess not so rarely,
we do encounter workloads

185
00:08:40,530 --> 00:08:41,850
that are partition bound.

186
00:08:41,850 --> 00:08:43,650
And so you have to
account for that as well.

187
00:08:43,650 --> 00:08:46,323
And this is the basic configuration

188
00:08:46,323 --> 00:08:49,050
that as customers you need to account for,

189
00:08:49,050 --> 00:08:50,820
which is what's my producer traffic?

190
00:08:50,820 --> 00:08:52,260
What's my consumer traffic?

191
00:08:52,260 --> 00:08:53,940
What's my replication traffic

192
00:08:53,940 --> 00:08:55,940
and what are my partition compute needs?

193
00:08:57,090 --> 00:08:58,413
And then failures happen.

194
00:08:59,400 --> 00:09:01,410
Let's say a broker dies.

195
00:09:01,410 --> 00:09:02,733
What happens in that case?

196
00:09:04,080 --> 00:09:07,500
You need buffers for
handling broker failures.

197
00:09:07,500 --> 00:09:08,400
How does that look like?

198
00:09:08,400 --> 00:09:09,960
Your producer swaps,

199
00:09:09,960 --> 00:09:13,293
your replications switches,
your leadership changes,

200
00:09:14,790 --> 00:09:16,830
and then the broker comes back,

201
00:09:16,830 --> 00:09:18,660
which means your first broker
has to actually account

202
00:09:18,660 --> 00:09:21,330
for the throughput of
two producers, right?

203
00:09:21,330 --> 00:09:22,660
Now your broker comes back

204
00:09:23,760 --> 00:09:26,010
and now there's different workloads

205
00:09:26,010 --> 00:09:27,240
that you need to account for.

206
00:09:27,240 --> 00:09:28,920
What is your catchup replication?

207
00:09:28,920 --> 00:09:31,770
What does that look like, right?

208
00:09:31,770 --> 00:09:36,330
And eventually, then as
the broker rebalances

209
00:09:36,330 --> 00:09:39,390
and producer reswitches,
you also need to account

210
00:09:39,390 --> 00:09:41,880
for what happens when there's
a consumer rebalancing.

211
00:09:41,880 --> 00:09:44,370
And there is some
interesting new innovation

212
00:09:44,370 --> 00:09:46,590
that is happening in the
Kafka space around us.

213
00:09:46,590 --> 00:09:50,850
But all of these are things
that you have to build in

214
00:09:50,850 --> 00:09:52,800
when planning your workloads.

215
00:09:52,800 --> 00:09:55,440
Too often we encounter customers

216
00:09:55,440 --> 00:09:58,950
who have workloads that work fine

217
00:09:58,950 --> 00:10:00,120
when things are going fine,

218
00:10:00,120 --> 00:10:01,860
but when failures happen,

219
00:10:01,860 --> 00:10:03,420
that's when they encounter problems.

220
00:10:03,420 --> 00:10:07,470
And these are some things
that we ask customers

221
00:10:07,470 --> 00:10:08,310
to sort of think through.

222
00:10:08,310 --> 00:10:10,893
What does your failure
handling actually look like?

223
00:10:13,380 --> 00:10:15,630
But failure recovery is also time taking.

224
00:10:15,630 --> 00:10:18,030
So it's not just about having the space

225
00:10:18,030 --> 00:10:20,910
and buffers to actually
account for these failures.

226
00:10:20,910 --> 00:10:23,100
It's also accounting for time.

227
00:10:23,100 --> 00:10:24,270
And specifically in this case,

228
00:10:24,270 --> 00:10:27,870
what happens is in the
standard Kafka case,

229
00:10:27,870 --> 00:10:30,720
you're scaling compute
and storage together,

230
00:10:30,720 --> 00:10:34,320
and especially after a
node recovers from failure,

231
00:10:34,320 --> 00:10:36,330
it has to catch up.

232
00:10:36,330 --> 00:10:37,950
This process is time consuming,

233
00:10:37,950 --> 00:10:40,050
but it's also non-deterministic.

234
00:10:40,050 --> 00:10:41,340
What does that mean?

235
00:10:41,340 --> 00:10:44,340
It's dependent on what is
your storage throughput?

236
00:10:44,340 --> 00:10:46,650
What is your storage capacity?

237
00:10:46,650 --> 00:10:50,220
What is your compute to local
storage network throughput?

238
00:10:50,220 --> 00:10:52,680
So you have all these
different factors that are sort

239
00:10:52,680 --> 00:10:56,670
of competing for attention
in that infrastructure,

240
00:10:56,670 --> 00:10:58,920
which means your recovery time

241
00:10:58,920 --> 00:11:01,230
is going to be dependent on that.

242
00:11:01,230 --> 00:11:04,350
Interestingly, Kafka is a
remarkably stable system

243
00:11:04,350 --> 00:11:06,060
until failures happen.

244
00:11:06,060 --> 00:11:08,940
And at the point that failures happen,

245
00:11:08,940 --> 00:11:11,490
then the thing that
you can do as customers

246
00:11:11,490 --> 00:11:12,840
is to wait for recovery.

247
00:11:12,840 --> 00:11:15,330
And that often is where a lot

248
00:11:15,330 --> 00:11:17,100
of our customer conversations happen

249
00:11:17,100 --> 00:11:19,470
is around how have you
thought about failure recovery

250
00:11:19,470 --> 00:11:22,023
and failure recovery in these modes?

251
00:11:24,210 --> 00:11:26,850
On the Express side, looking at that,

252
00:11:26,850 --> 00:11:29,550
what we ended up doing
is really rethinking

253
00:11:29,550 --> 00:11:31,113
how failure recovery happens.

254
00:11:31,950 --> 00:11:34,170
Because we separated our resources,

255
00:11:34,170 --> 00:11:37,110
what that means is your recovery

256
00:11:37,110 --> 00:11:39,930
is up to 90% faster, right?

257
00:11:39,930 --> 00:11:41,661
And that fundamentally means

258
00:11:41,661 --> 00:11:44,970
that you're getting high resilience

259
00:11:44,970 --> 00:11:47,790
because your mean time to recovery is low.

260
00:11:47,790 --> 00:11:50,910
And that is a phenomenally important thing

261
00:11:50,910 --> 00:11:54,000
when you're designing
resilient distributor systems

262
00:11:54,000 --> 00:11:56,610
is how do you keep your recovery time low

263
00:11:56,610 --> 00:11:58,530
so that you can build
resilience for your systems.

264
00:11:58,530 --> 00:12:00,657
And I'll walk you through some examples

265
00:12:00,657 --> 00:12:02,460
of what that looks like.

266
00:12:02,460 --> 00:12:05,973
But that is how Express
brokers is different.

267
00:12:07,860 --> 00:12:10,830
What does that mean
for horizontal scaling?

268
00:12:10,830 --> 00:12:13,170
Everyone has a plan until they have

269
00:12:13,170 --> 00:12:15,540
to rebalance partitions, right?

270
00:12:15,540 --> 00:12:18,543
And that is what Kafka
horizontal scaling looks like.

271
00:12:19,590 --> 00:12:20,970
You add three brokers,

272
00:12:20,970 --> 00:12:23,460
you're going to go move partitions across.

273
00:12:23,460 --> 00:12:26,910
You have to reserve enough
bandwidth for rebalancing.

274
00:12:26,910 --> 00:12:30,120
You have to carefully
orchestrate the movement

275
00:12:30,120 --> 00:12:32,970
so that it does not impact
your existing workloads.

276
00:12:32,970 --> 00:12:34,140
And last but not the least,

277
00:12:34,140 --> 00:12:37,260
you're continuously
monitoring your infrastructure

278
00:12:37,260 --> 00:12:41,523
so that if there's a need
to change the plan, you can.

279
00:12:42,690 --> 00:12:43,980
And that's what happens.

280
00:12:43,980 --> 00:12:47,550
Rebalancing can take hours
and again is variable.

281
00:12:47,550 --> 00:12:50,883
And that is how the system behaves.

282
00:12:52,740 --> 00:12:55,890
On Express brokers, because we
have separation of resources,

283
00:12:55,890 --> 00:12:58,580
what that fundamentally
means is you can get up

284
00:12:58,580 --> 00:13:03,580
to 20x more elasticity
compared to standard brokers.

285
00:13:04,290 --> 00:13:06,690
I often get this question from customers,

286
00:13:06,690 --> 00:13:10,803
which is what does elasticity mean?

287
00:13:12,000 --> 00:13:13,863
So let's look at an example.

288
00:13:14,880 --> 00:13:17,745
How fast can I rebalance my partitions

289
00:13:17,745 --> 00:13:21,183
after adding brokers while
traffic is still climbing?

290
00:13:22,230 --> 00:13:23,880
Here's an experiment that we ran.

291
00:13:23,880 --> 00:13:28,470
We had three brokers, one
topic, 2,000 partitions,

292
00:13:28,470 --> 00:13:30,273
four terabytes of data per broker.

293
00:13:31,380 --> 00:13:34,080
What we did is we had three brokers

294
00:13:34,080 --> 00:13:37,260
and we added three brokers,
rebalanced 1,000 partitions,

295
00:13:37,260 --> 00:13:40,260
all this while producing
90 megabytes per second .

296
00:13:40,260 --> 00:13:42,120
Pretty typical for what we see.

297
00:13:42,120 --> 00:13:44,430
And what we did is compare
standard to Express

298
00:13:44,430 --> 00:13:47,853
and I'm just gonna show you a
couple of CloudWatch graphs.

299
00:13:50,040 --> 00:13:51,720
So here's what standard looks like.

300
00:13:51,720 --> 00:13:55,110
You have three brokers
that are at the top.

301
00:13:55,110 --> 00:13:59,250
On the left red line is
where we issued the command

302
00:13:59,250 --> 00:14:01,620
to add three brokers.

303
00:14:01,620 --> 00:14:04,140
You can instantly see
the throughput drops.

304
00:14:04,140 --> 00:14:07,680
And the throughput drops
and continues dropping

305
00:14:07,680 --> 00:14:11,670
and eventually the new three
brokers start to pick up.

306
00:14:11,670 --> 00:14:14,010
And you can see the throughput sort

307
00:14:14,010 --> 00:14:16,260
of gets throttled further

308
00:14:16,260 --> 00:14:18,870
and eventually the throughput stabilizes

309
00:14:18,870 --> 00:14:22,260
and behaves as if it's six brokers, right?

310
00:14:22,260 --> 00:14:24,330
So you get producer degradation

311
00:14:24,330 --> 00:14:26,160
until the throughput recovers

312
00:14:26,160 --> 00:14:31,020
and that entire process takes
about 175 minutes, right?

313
00:14:31,020 --> 00:14:33,690
And so you are going through
this partition rebalancing

314
00:14:33,690 --> 00:14:34,740
and adding three brokers

315
00:14:34,740 --> 00:14:38,703
until you get productive six
brokers for about 175 minutes.

316
00:14:39,870 --> 00:14:42,300
Here's what this looks
like for Express brokers.

317
00:14:42,300 --> 00:14:45,360
The left is where we
added the three brokers.

318
00:14:45,360 --> 00:14:49,500
Yep, the brokers went
to the new throughput

319
00:14:49,500 --> 00:14:50,700
and within 10 minutes,

320
00:14:50,700 --> 00:14:52,410
the remaining three brokers were added

321
00:14:52,410 --> 00:14:55,230
and they joined the cluster
and produced the traffic.

322
00:14:55,230 --> 00:14:56,880
Again, from a customer standpoint,

323
00:14:56,880 --> 00:14:59,430
and for you as users of this,

324
00:14:59,430 --> 00:15:02,040
what that means is
you're spending less time

325
00:15:02,040 --> 00:15:03,300
doing partition rebalancing,

326
00:15:03,300 --> 00:15:05,520
which is giving you a
more resilient system,

327
00:15:05,520 --> 00:15:08,310
which also means you can scale
up and scale down faster.

328
00:15:08,310 --> 00:15:09,780
You can run this experiment

329
00:15:09,780 --> 00:15:12,003
and see what your results look like.

330
00:15:14,190 --> 00:15:15,483
But wait, there's more.

331
00:15:16,530 --> 00:15:19,800
What we announced a few weeks ago

332
00:15:19,800 --> 00:15:23,490
for Express brokers is
intelligent rebalancing.

333
00:15:23,490 --> 00:15:27,300
What we've now done is you
get always-on rebalancing,

334
00:15:27,300 --> 00:15:29,100
you get auto partition placement,

335
00:15:29,100 --> 00:15:31,710
you can do fully automated
horizontal scaling

336
00:15:31,710 --> 00:15:34,620
with zero click automated heat management

337
00:15:34,620 --> 00:15:36,880
and that gives you
improved price performance

338
00:15:38,070 --> 00:15:40,170
from a cluster standpoint.

339
00:15:40,170 --> 00:15:42,720
And here's what intelligent
rebalancing looks like.

340
00:15:42,720 --> 00:15:46,020
You get up to 180x faster rebalancing,

341
00:15:46,020 --> 00:15:49,710
which means shorter recovery
windows and higher resilience,

342
00:15:49,710 --> 00:15:51,910
and that is as compared
to standard brokers.

343
00:15:52,770 --> 00:15:55,514
One of the interesting
things the team did,

344
00:15:55,514 --> 00:15:58,410
which really is sort
of well thought through

345
00:15:58,410 --> 00:16:01,440
is you get built-in operational awareness.

346
00:16:01,440 --> 00:16:04,560
In other words, we detect
when there's healing going on,

347
00:16:04,560 --> 00:16:06,210
when there's patching going on

348
00:16:06,210 --> 00:16:08,910
and we prevent unsafe overlap.

349
00:16:08,910 --> 00:16:10,383
And last but not the least,

350
00:16:11,700 --> 00:16:14,220
we apply all our best
practices for scale-in

351
00:16:14,220 --> 00:16:16,080
and scale-out intelligence

352
00:16:16,080 --> 00:16:18,360
before resizing our clusters, right?

353
00:16:18,360 --> 00:16:21,390
And so that becomes enormously helpful

354
00:16:21,390 --> 00:16:23,340
in terms of giving you a signal

355
00:16:23,340 --> 00:16:26,760
of what workloads your brokers can accept.

356
00:16:26,760 --> 00:16:29,130
So super happy that this
is in customer hands,

357
00:16:29,130 --> 00:16:31,500
it's available for Express brokers

358
00:16:31,500 --> 00:16:34,053
and it's starting I think two weeks ago.

359
00:16:35,640 --> 00:16:39,480
So one of the other thing
was we had to rethink

360
00:16:39,480 --> 00:16:41,280
what resilience looks like.

361
00:16:41,280 --> 00:16:43,530
And part of this is to
help you understand sort

362
00:16:43,530 --> 00:16:45,210
of how we think about resilience

363
00:16:45,210 --> 00:16:47,490
and all the work that we had to do to sort

364
00:16:47,490 --> 00:16:49,470
of build in resilience.

365
00:16:49,470 --> 00:16:52,080
Here's what standard
Kafka behavior looks like.

366
00:16:52,080 --> 00:16:54,690
You have a broker, I sort of modeled it

367
00:16:54,690 --> 00:16:57,360
as you have a broker with
partitions, you have memory,

368
00:16:57,360 --> 00:17:00,010
you have compute, you have
network, you have storage.

369
00:17:00,960 --> 00:17:04,380
Kafka classically is an
allocate when asked system.

370
00:17:04,380 --> 00:17:08,580
You sort of can request capacity,

371
00:17:08,580 --> 00:17:09,413
it'll give you capacity,

372
00:17:09,413 --> 00:17:12,120
you can create a partition,
it'll create a partition.

373
00:17:12,120 --> 00:17:16,710
And what happens is the
onus is on Kafka clients

374
00:17:16,710 --> 00:17:20,640
and the users to not overload the system.

375
00:17:20,640 --> 00:17:22,530
And the challenge with that

376
00:17:22,530 --> 00:17:25,380
is you only find out you've
overloaded the system

377
00:17:25,380 --> 00:17:28,110
by monitoring it well,
by having heuristics,

378
00:17:28,110 --> 00:17:30,930
by having experience of
managing your workloads.

379
00:17:30,930 --> 00:17:35,430
But when that overloading
happens, it causes broker failures

380
00:17:35,430 --> 00:17:39,270
and so you are in the mode
of recovery at the point

381
00:17:39,270 --> 00:17:41,610
that you've overloaded the brokers.

382
00:17:41,610 --> 00:17:44,010
So one of the things
that we did in Express

383
00:17:44,010 --> 00:17:47,040
is you have the same model for a broker,

384
00:17:47,040 --> 00:17:51,510
but for each of those, we
have added safe throttles

385
00:17:51,510 --> 00:17:56,130
safe dynamic throttles on
compute, memory and networking.

386
00:17:56,130 --> 00:18:00,240
And what that means is we
can start to minimize sort

387
00:18:00,240 --> 00:18:01,740
of the impact on the broker

388
00:18:01,740 --> 00:18:04,203
and protect the broker from failures.

389
00:18:05,070 --> 00:18:07,410
In fact, the team has
also had to think through

390
00:18:07,410 --> 00:18:09,450
what does it mean to
survive storage failures?

391
00:18:09,450 --> 00:18:12,370
Now, you can't survive storage failures

392
00:18:14,310 --> 00:18:16,080
for an infinite amount of time,

393
00:18:16,080 --> 00:18:18,930
but still it builds in resilience

394
00:18:18,930 --> 00:18:21,480
and gives you the capacity,
at least for a while,

395
00:18:21,480 --> 00:18:24,780
to survive without storage being there.

396
00:18:24,780 --> 00:18:26,220
And last but not the least,

397
00:18:26,220 --> 00:18:30,450
especially as we throttle,
your client can then react

398
00:18:30,450 --> 00:18:32,520
to the throttling behavior it sees

399
00:18:32,520 --> 00:18:35,070
instead of just seeing the failure

400
00:18:35,070 --> 00:18:36,780
and then reacting to the failure.

401
00:18:36,780 --> 00:18:39,360
So what that means is
from a design standpoint,

402
00:18:39,360 --> 00:18:42,900
you actually have the ability
to design your system,

403
00:18:42,900 --> 00:18:45,780
to take cognizance of like
the system being overloaded

404
00:18:45,780 --> 00:18:47,340
and actually accounting
for it differently.

405
00:18:47,340 --> 00:18:50,190
And that is something that
is fundamentally different

406
00:18:50,190 --> 00:18:52,230
about what we had to do

407
00:18:52,230 --> 00:18:54,243
in order to re-architect for resilience.

408
00:18:56,940 --> 00:19:00,333
So it goes further, deeper.

409
00:19:01,650 --> 00:19:03,510
One of the other things
that we did with Express

410
00:19:03,510 --> 00:19:05,520
is we made it such

411
00:19:05,520 --> 00:19:08,403
that you did not need a
maintenance window for patching.

412
00:19:09,750 --> 00:19:13,380
We also built in partition-level fairness

413
00:19:13,380 --> 00:19:16,080
and what does that mean
is you get protection

414
00:19:16,080 --> 00:19:17,040
from noisy workloads.

415
00:19:17,040 --> 00:19:21,510
So you can't have a single partition

416
00:19:21,510 --> 00:19:23,490
taking up all the
throughput of your broker

417
00:19:23,490 --> 00:19:26,280
and you get better protection on that.

418
00:19:26,280 --> 00:19:28,770
Last but not the least, one of the things

419
00:19:28,770 --> 00:19:30,540
that the team has also
had to think through

420
00:19:30,540 --> 00:19:34,800
is what does it mean to stop
potential cascading faults

421
00:19:34,800 --> 00:19:37,290
and how do you isolate them by design?

422
00:19:37,290 --> 00:19:40,500
Nothing's perfect, but
there's a lot of thinking

423
00:19:40,500 --> 00:19:43,440
that had to go in in
terms of building systems

424
00:19:43,440 --> 00:19:45,000
that can survive.

425
00:19:45,000 --> 00:19:48,390
And so part of like
walking you through this

426
00:19:48,390 --> 00:19:50,160
is to help you understand

427
00:19:50,160 --> 00:19:52,230
what does it mean to actually operate

428
00:19:52,230 --> 00:19:55,443
and run these systems at scale?

429
00:19:57,210 --> 00:19:58,890
Now, there are some customers who'll come

430
00:19:58,890 --> 00:20:01,770
and tell us we want even lower management.

431
00:20:01,770 --> 00:20:04,290
And so all of this infrastructure

432
00:20:04,290 --> 00:20:07,740
and all of that knowledge
we built into MSK Serverless

433
00:20:07,740 --> 00:20:11,310
and there you're just operating
at the level of scaling up,

434
00:20:11,310 --> 00:20:14,670
scaling down, you're doing
zero Kafka management

435
00:20:14,670 --> 00:20:17,220
and normally we recommend
it for new to Kafka

436
00:20:17,220 --> 00:20:19,323
or new to streaming customers.

437
00:20:21,540 --> 00:20:23,220
I debated putting this slide up

438
00:20:23,220 --> 00:20:26,130
and I debated very, very deeply

439
00:20:26,130 --> 00:20:30,150
about like, it seems remedial

440
00:20:30,150 --> 00:20:34,320
and yet it's one of the more
common failures that we see

441
00:20:34,320 --> 00:20:37,620
with customers is monitoring Kafka.

442
00:20:37,620 --> 00:20:40,200
What I'll show you on the
next slide will seem obvious,

443
00:20:40,200 --> 00:20:44,670
but it's remarkable how
customers, like a lot of customers

444
00:20:44,670 --> 00:20:47,400
are not set up for
actually monitoring these.

445
00:20:47,400 --> 00:20:50,660
So these are the things
we recommend you monitor

446
00:20:50,660 --> 00:20:51,783
in your Kafka setup.

447
00:20:53,250 --> 00:20:56,430
So I'll start with the per
broker, per cluster things.

448
00:20:56,430 --> 00:21:00,450
It's partitions per broker,
total partitions per cluster,

449
00:21:00,450 --> 00:21:03,390
it's connections per broker,
monitor these, right?

450
00:21:03,390 --> 00:21:05,430
It's super important to make sure

451
00:21:05,430 --> 00:21:06,990
that these are within the bounds

452
00:21:06,990 --> 00:21:11,613
and in fact set alerting so
that you can react to this.

453
00:21:12,690 --> 00:21:14,940
And then on the usage side,

454
00:21:14,940 --> 00:21:17,040
think about your broker CPU usage,

455
00:21:17,040 --> 00:21:19,740
your disk usage, your memory usage,

456
00:21:19,740 --> 00:21:21,390
your throughput usage.

457
00:21:21,390 --> 00:21:24,540
It is amazing how these simple metrics

458
00:21:24,540 --> 00:21:29,540
will give you a view on what
it means for the service

459
00:21:30,450 --> 00:21:31,750
and the system to operate.

460
00:21:32,760 --> 00:21:34,800
Super important that you balance

461
00:21:34,800 --> 00:21:38,370
not just the operational
side of running the system,

462
00:21:38,370 --> 00:21:40,560
but also the monitoring

463
00:21:40,560 --> 00:21:43,260
and making sure that you're
doing the right thing.

464
00:21:43,260 --> 00:21:47,040
That is what it means
to run Kafka at scale.

465
00:21:47,040 --> 00:21:49,230
Up next, Sai will tell
you about what it means

466
00:21:49,230 --> 00:21:50,553
to run Flink at scale.

467
00:21:52,980 --> 00:21:54,810
- Well, thank you so much, Ashish.

468
00:21:54,810 --> 00:21:58,260
So now that you've got
all the data streamed

469
00:21:58,260 --> 00:22:01,170
in Apache Kafka, you need to process it

470
00:22:01,170 --> 00:22:04,470
and that is where running
Apache Flink at scale

471
00:22:04,470 --> 00:22:05,733
comes to fruition.

472
00:22:07,860 --> 00:22:10,320
So how many of you have
some of these use cases,

473
00:22:10,320 --> 00:22:13,080
anomaly detection where
you're transforming data

474
00:22:13,080 --> 00:22:15,810
before you're loading
that into an OLAP system?

475
00:22:15,810 --> 00:22:17,370
How many of you're supporting building

476
00:22:17,370 --> 00:22:19,410
event-driven applications?

477
00:22:19,410 --> 00:22:21,420
If you're using any of those use cases,

478
00:22:21,420 --> 00:22:23,370
or all those three use cases,

479
00:22:23,370 --> 00:22:26,430
then you should be using Apache Flink.

480
00:22:26,430 --> 00:22:31,430
There are four reasons
why. First, it's real time.

481
00:22:31,440 --> 00:22:36,060
Second, it's great at
handling dynamic datasets.

482
00:22:36,060 --> 00:22:41,060
Number three, it's stateful and
finally, it is programmable.

483
00:22:41,850 --> 00:22:46,200
Let's dive deeper into each
one of these using an example.

484
00:22:46,200 --> 00:22:50,820
Imagine you are building
a fleet monitoring system

485
00:22:50,820 --> 00:22:53,400
and your goal is to detect anomalies

486
00:22:53,400 --> 00:22:54,960
as quickly as you find them

487
00:22:54,960 --> 00:22:57,750
so that way you can improve
the customer experience.

488
00:22:57,750 --> 00:23:00,540
So I start with a few nodes

489
00:23:00,540 --> 00:23:03,960
and within no time, my fleet
grows and now I have tens

490
00:23:03,960 --> 00:23:06,360
and hundreds of nodes and
in no time, I have thousands

491
00:23:06,360 --> 00:23:08,910
of nodes to monitor and detect.

492
00:23:08,910 --> 00:23:10,500
What is equally important to remember

493
00:23:10,500 --> 00:23:13,440
is as your customers are
creating new resources,

494
00:23:13,440 --> 00:23:15,060
you have new nodes to monitor

495
00:23:15,060 --> 00:23:16,980
and when they're deleting resources,

496
00:23:16,980 --> 00:23:19,560
you no longer have to monitor those nodes.

497
00:23:19,560 --> 00:23:23,523
So this set of data that you're
monitoring changes rapidly.

498
00:23:24,390 --> 00:23:26,460
Somewhere along the line
you realize that, "Look,

499
00:23:26,460 --> 00:23:28,260
my anomaly detection can be better

500
00:23:28,260 --> 00:23:31,710
if I also include storage
monitoring into the mix."

501
00:23:31,710 --> 00:23:35,190
And then eventually
software versions, regions.

502
00:23:35,190 --> 00:23:38,130
So very quickly what you see

503
00:23:38,130 --> 00:23:42,063
is a big increase in
complexity of your data.

504
00:23:42,990 --> 00:23:45,810
This is where Flink's
continuous processing

505
00:23:45,810 --> 00:23:49,200
is a lot better than using
batch-based processing.

506
00:23:49,200 --> 00:23:51,723
A batch is like capturing a photo.

507
00:23:52,590 --> 00:23:56,100
A photo captures what's
true in the moment.

508
00:23:56,100 --> 00:23:58,350
You cannot track what happened before

509
00:23:58,350 --> 00:24:00,990
or potentially what has happened after.

510
00:24:00,990 --> 00:24:05,220
Comparatively a video captures
every frame, every detail.

511
00:24:05,220 --> 00:24:08,070
It gives you all the rich
context available for you.

512
00:24:08,070 --> 00:24:10,980
You can go pause that, go
back to a point in time,

513
00:24:10,980 --> 00:24:12,120
compare different things

514
00:24:12,120 --> 00:24:15,273
and get to the insight in
a more accurate fashion.

515
00:24:17,760 --> 00:24:19,200
We also talked about one

516
00:24:19,200 --> 00:24:21,510
of Flink's strength being it's stateful.

517
00:24:21,510 --> 00:24:25,950
So in our example, you're able
to capture the state per key,

518
00:24:25,950 --> 00:24:28,410
per server, per software type.

519
00:24:28,410 --> 00:24:30,390
And as new events come in,

520
00:24:30,390 --> 00:24:33,450
that state is incrementally
updated by Flink.

521
00:24:33,450 --> 00:24:36,840
And what it does, it waits
for patterns to emerge

522
00:24:36,840 --> 00:24:39,570
and either decides, "Well, this is noise,

523
00:24:39,570 --> 00:24:42,330
I'm gonna suppress it
or it's a valid signal,

524
00:24:42,330 --> 00:24:43,710
let me act on it."

525
00:24:43,710 --> 00:24:46,770
So in our example, it could
be a breach in threshold

526
00:24:46,770 --> 00:24:47,947
where you say,

527
00:24:47,947 --> 00:24:50,820
"Well, I wanna monitor if I
have more than five faults

528
00:24:50,820 --> 00:24:54,060
in any given minute and if
it breaches that threshold,

529
00:24:54,060 --> 00:24:56,430
I want to trigger an automated action,

530
00:24:56,430 --> 00:24:59,250
which is replacing that faulty
node before the customer

531
00:24:59,250 --> 00:25:00,600
is actually seeing impact."

532
00:25:01,500 --> 00:25:05,220
So being stateful gives you
that rich memory for you

533
00:25:05,220 --> 00:25:07,743
to make more context-aware decisions.

534
00:25:08,880 --> 00:25:10,560
The last piece is it's programmable.

535
00:25:10,560 --> 00:25:12,480
So in our example of fleet monitoring,

536
00:25:12,480 --> 00:25:15,300
you can start with a
simple if-then-else logic.

537
00:25:15,300 --> 00:25:17,190
If this happens, I'm gonna do this.

538
00:25:17,190 --> 00:25:18,300
But over time you realize,

539
00:25:18,300 --> 00:25:20,280
well, I wanna also monitor my storage

540
00:25:20,280 --> 00:25:21,600
so it can evolve your logic

541
00:25:21,600 --> 00:25:23,973
to now also include other metrics.

542
00:25:25,110 --> 00:25:29,130
You can also map the data to
a table in a database table

543
00:25:29,130 --> 00:25:31,350
so that you can actually
enrich that context.

544
00:25:31,350 --> 00:25:33,270
And finally, you can
start with simple actions.

545
00:25:33,270 --> 00:25:36,330
In my fleet monitoring
example, that customer started

546
00:25:36,330 --> 00:25:38,700
with creating an alarm
so that a human can react

547
00:25:38,700 --> 00:25:40,350
to that alarm and replace that node,

548
00:25:40,350 --> 00:25:43,230
but over time they grew confidence
in operating that system

549
00:25:43,230 --> 00:25:47,490
and started taking automated
action using that workflow.

550
00:25:47,490 --> 00:25:49,890
So this gives you that ability

551
00:25:49,890 --> 00:25:52,503
to constantly evolve your application.

552
00:25:53,340 --> 00:25:57,630
The combination of
real-time, statefulness,

553
00:25:57,630 --> 00:26:01,230
being able to handle dynamic datasets

554
00:26:01,230 --> 00:26:03,900
and programmability is also the reason

555
00:26:03,900 --> 00:26:05,970
why customers are turning to Flink

556
00:26:05,970 --> 00:26:08,853
to build agentic AI applications.

557
00:26:11,280 --> 00:26:12,570
So what does it take

558
00:26:12,570 --> 00:26:16,470
to do more data processing
workloads real time?

559
00:26:16,470 --> 00:26:19,560
When we talk to a wide
variety of customers,

560
00:26:19,560 --> 00:26:22,500
three particular patterns emerge.

561
00:26:22,500 --> 00:26:26,100
First, it requires a change
in your operating model.

562
00:26:26,100 --> 00:26:29,220
Second, you need resilient
Flink infrastructure

563
00:26:29,220 --> 00:26:33,450
and finally, build programming
logic that is robust.

564
00:26:33,450 --> 00:26:35,853
It sounds obvious but it's very important.

565
00:26:36,690 --> 00:26:38,490
Let's start with what do we mean

566
00:26:38,490 --> 00:26:40,020
by changing the operating model?

567
00:26:40,020 --> 00:26:42,090
And a good way to understand
that is to compare that

568
00:26:42,090 --> 00:26:44,070
with batch-based processing,

569
00:26:44,070 --> 00:26:47,610
something that has been
popular over the years.

570
00:26:47,610 --> 00:26:51,330
In the batch world, your
data is largely fixed.

571
00:26:51,330 --> 00:26:53,970
So you're processing data
that is either days old

572
00:26:53,970 --> 00:26:55,710
or a few hours old

573
00:26:55,710 --> 00:26:58,260
and the analyst is now running
different set of queries

574
00:26:58,260 --> 00:26:59,790
to find that insight.

575
00:26:59,790 --> 00:27:02,370
And then essentially
also leaning on a human

576
00:27:02,370 --> 00:27:04,950
to generally take an action.

577
00:27:04,950 --> 00:27:06,780
Compare that in a streaming system.

578
00:27:06,780 --> 00:27:09,390
Data is getting continuously generated.

579
00:27:09,390 --> 00:27:12,930
And then on this set of
continuous generating data,

580
00:27:12,930 --> 00:27:15,370
you're applying a set of
generally static rules

581
00:27:16,410 --> 00:27:21,150
to understand insights and
almost automate the action.

582
00:27:21,150 --> 00:27:23,850
So in our fleet example,
the automation there

583
00:27:23,850 --> 00:27:26,583
is replacing that faulty
node or storage device.

584
00:27:27,840 --> 00:27:30,180
Time is explicit in the dashboard.

585
00:27:30,180 --> 00:27:32,700
When you take a photo,
the snapshot tells you

586
00:27:32,700 --> 00:27:34,680
that this was taken at
this particular time.

587
00:27:34,680 --> 00:27:36,060
But when it comes to video,

588
00:27:36,060 --> 00:27:38,940
you have to specify that time explicitly.

589
00:27:38,940 --> 00:27:40,710
I wanna go to this particular timeframe

590
00:27:40,710 --> 00:27:41,640
and then compare things.

591
00:27:41,640 --> 00:27:44,553
So time is explicit in streaming systems.

592
00:27:45,480 --> 00:27:47,670
So that is what we mean by
changing operating model.

593
00:27:47,670 --> 00:27:52,380
You're moving away from
dynamic queries on static data

594
00:27:52,380 --> 00:27:55,413
to static queries largely on dynamic data.

595
00:27:57,840 --> 00:28:00,180
That also means that as developers,

596
00:28:00,180 --> 00:28:03,060
there are some new
concepts for you to learn.

597
00:28:03,060 --> 00:28:04,470
First is event time,

598
00:28:04,470 --> 00:28:07,470
which actually tells you when
the actual event has happened,

599
00:28:07,470 --> 00:28:09,450
not when it's processed.

600
00:28:09,450 --> 00:28:12,120
Sometimes as an example of
fleet monitoring system,

601
00:28:12,120 --> 00:28:14,130
you could get events related to storage

602
00:28:14,130 --> 00:28:16,170
before you get events related to server.

603
00:28:16,170 --> 00:28:17,820
If you end up using processing time,

604
00:28:17,820 --> 00:28:22,200
you would miss processing
events related to your server

605
00:28:22,200 --> 00:28:25,170
and that means your action
would not be accurate.

606
00:28:25,170 --> 00:28:28,500
So leaning on event time
becomes very important.

607
00:28:28,500 --> 00:28:30,480
The second key concept is Windows.

608
00:28:30,480 --> 00:28:33,330
Because you have this
continuous flow of data,

609
00:28:33,330 --> 00:28:36,240
Windows allows you to group this events

610
00:28:36,240 --> 00:28:38,880
into small buckets for analysis.

611
00:28:38,880 --> 00:28:41,970
The next important
concept is partitioning.

612
00:28:41,970 --> 00:28:44,580
That essentially is
how data is distributed

613
00:28:44,580 --> 00:28:47,640
so that you can parallelize
your processing.

614
00:28:47,640 --> 00:28:50,790
Now, because Flink is
trying to process data

615
00:28:50,790 --> 00:28:52,710
at really high throughput and low latency,

616
00:28:52,710 --> 00:28:55,230
partitioning becomes very important.

617
00:28:55,230 --> 00:28:58,260
Lastly, one of Flink's strong calling card

618
00:28:58,260 --> 00:29:00,870
is its support for
exactly once processing,

619
00:29:00,870 --> 00:29:04,050
which means that as a
developer, I get the confidence

620
00:29:04,050 --> 00:29:06,210
that I'm not worried about duplicates

621
00:29:06,210 --> 00:29:07,680
when it comes to processing.

622
00:29:07,680 --> 00:29:10,593
So I'm processing each event exactly once.

623
00:29:12,930 --> 00:29:17,400
So how does Apache Flink
support high throughput data

624
00:29:17,400 --> 00:29:20,460
at low latency with
remarkable consistency?

625
00:29:20,460 --> 00:29:23,520
The answer lies in its architecture.

626
00:29:23,520 --> 00:29:27,780
The job manager is like a
brain for the Flink system.

627
00:29:27,780 --> 00:29:32,070
It is planning, scheduling,
coordinating the work.

628
00:29:32,070 --> 00:29:33,240
And then you have task manager

629
00:29:33,240 --> 00:29:34,830
where the actual processing is happening

630
00:29:34,830 --> 00:29:38,460
and the task manager is further
broken down into task slots,

631
00:29:38,460 --> 00:29:41,040
which aids for parallel processing.

632
00:29:41,040 --> 00:29:42,720
So here's how it works.

633
00:29:42,720 --> 00:29:45,240
So you deploy, you build your logic,

634
00:29:45,240 --> 00:29:46,770
you deploy it as a JAR,

635
00:29:46,770 --> 00:29:49,290
and then job manager takes the code,

636
00:29:49,290 --> 00:29:52,350
first translate that into
a logical unit of work

637
00:29:52,350 --> 00:29:54,840
and then breaks that into
physical units of work

638
00:29:54,840 --> 00:29:57,990
and places those work in task slots.

639
00:29:57,990 --> 00:30:01,650
Why? Because it wants to
guarantee parallelism.

640
00:30:01,650 --> 00:30:03,390
Flink also captures the state,

641
00:30:03,390 --> 00:30:05,070
we've talked about how important that is,

642
00:30:05,070 --> 00:30:07,650
and periodically
checkpoints its processing

643
00:30:07,650 --> 00:30:09,630
into a durable store within S3.

644
00:30:09,630 --> 00:30:13,020
And the reason it's doing that
is to give you the guarantee

645
00:30:13,020 --> 00:30:14,610
of exactly one's processing,

646
00:30:14,610 --> 00:30:16,860
but also be resilience
when failures happens.

647
00:30:16,860 --> 00:30:19,080
So when a job fails, when
infrastructure fails,

648
00:30:19,080 --> 00:30:20,340
it needs to know where to start

649
00:30:20,340 --> 00:30:23,640
and how to start those
operators processing data again.

650
00:30:23,640 --> 00:30:28,200
So this combination of
orchestration with job manager,

651
00:30:28,200 --> 00:30:30,630
parallelism driven by task manager,

652
00:30:30,630 --> 00:30:33,180
as well as checkpoints give
you the right set of perimeters

653
00:30:33,180 --> 00:30:34,380
for you to run at scale.

654
00:30:35,430 --> 00:30:37,380
But as an administrator,

655
00:30:37,380 --> 00:30:39,960
what are all the activities
I'm responsible for

656
00:30:39,960 --> 00:30:41,910
to run these systems at scale?

657
00:30:41,910 --> 00:30:43,710
They largely fall into three categories.

658
00:30:43,710 --> 00:30:46,590
First is deployment, second is monitoring,

659
00:30:46,590 --> 00:30:48,663
and the last is scaling and evolution.

660
00:30:50,160 --> 00:30:51,300
So your developer comes to you,

661
00:30:51,300 --> 00:30:52,770
they wanna build an application.

662
00:30:52,770 --> 00:30:55,830
So starting point is you pick
an infrastructure provider,

663
00:30:55,830 --> 00:30:57,330
Kubernetes-based system.

664
00:30:57,330 --> 00:30:58,770
Then you have a choice to make,

665
00:30:58,770 --> 00:31:01,230
whether you wanna run
that in application mode

666
00:31:01,230 --> 00:31:02,850
where you have a dedicated
set of infrastructure

667
00:31:02,850 --> 00:31:05,100
for that job or you
wanna run in session mode

668
00:31:05,100 --> 00:31:06,660
where you can run multiple jobs

669
00:31:06,660 --> 00:31:08,370
on that same set of infrastructure.

670
00:31:08,370 --> 00:31:11,250
And for most at-scale applications,

671
00:31:11,250 --> 00:31:13,530
you choose the application mode.

672
00:31:13,530 --> 00:31:14,790
Then we're off to monitoring

673
00:31:14,790 --> 00:31:16,230
once you've deployed the infrastructure.

674
00:31:16,230 --> 00:31:18,480
And we'll dive deeper into this subject,

675
00:31:18,480 --> 00:31:20,760
but the core goal there is to make sure

676
00:31:20,760 --> 00:31:23,010
that you're always processing data.

677
00:31:23,010 --> 00:31:26,370
And finally, scaling the
system is super important.

678
00:31:26,370 --> 00:31:27,960
And we've talked about how programmability

679
00:31:27,960 --> 00:31:30,570
and evolution are so key
perimeters for Flink.

680
00:31:30,570 --> 00:31:34,320
And so your goal there is to
monitor when you need to scale,

681
00:31:34,320 --> 00:31:39,120
do the scaling event, also
support deploying new code.

682
00:31:39,120 --> 00:31:41,400
So that's what it looks
like as a life cycle

683
00:31:41,400 --> 00:31:45,030
of a Flink job and the
activities around it.

684
00:31:45,030 --> 00:31:47,580
Now, for developers running applications,

685
00:31:47,580 --> 00:31:49,623
this is a fairly involved process.

686
00:31:50,580 --> 00:31:55,020
So at AWS, we offer managed
service for Apache Flink

687
00:31:55,020 --> 00:31:57,060
that provides the
easiest way for customers

688
00:31:57,060 --> 00:31:59,103
to build resilient Flink applications.

689
00:32:00,510 --> 00:32:01,980
So the developer experience

690
00:32:01,980 --> 00:32:05,550
with our managed services
is far simpler compared

691
00:32:05,550 --> 00:32:08,130
to the deployment example
that I gave you before.

692
00:32:08,130 --> 00:32:10,980
So in here, there's no
infrastructure set up.

693
00:32:10,980 --> 00:32:13,470
You get built in multi-AZ resiliency

694
00:32:13,470 --> 00:32:15,180
and there is no configuration tuning.

695
00:32:15,180 --> 00:32:16,590
And here is how it works.

696
00:32:16,590 --> 00:32:20,220
You go to your favorite
IDE, build the application,

697
00:32:20,220 --> 00:32:21,690
get a JAR file out of it,

698
00:32:21,690 --> 00:32:24,900
create an application
within the managed service,

699
00:32:24,900 --> 00:32:27,843
and then you're off to the
races to start processing data.

700
00:32:30,540 --> 00:32:31,740
There's no computer managed,

701
00:32:31,740 --> 00:32:34,083
there's no configurations
for you to set up.

702
00:32:36,210 --> 00:32:38,580
Now you've got this thing up and running,

703
00:32:38,580 --> 00:32:39,720
now you have to operate it.

704
00:32:39,720 --> 00:32:42,690
And what I'm gonna do
next is kind of walk you

705
00:32:42,690 --> 00:32:46,530
through our learnings operating
Flink applications at scale

706
00:32:46,530 --> 00:32:49,410
and how you can potentially
benefit from it.

707
00:32:49,410 --> 00:32:51,930
And I'm gonna focus on
two specific learnings.

708
00:32:51,930 --> 00:32:55,140
The first one that we've
learned is in Flink,

709
00:32:55,140 --> 00:32:57,120
a significant change can lead

710
00:32:57,120 --> 00:32:59,100
to processing being interrupted.

711
00:32:59,100 --> 00:33:00,720
So what is a significant change?

712
00:33:00,720 --> 00:33:03,570
Could be you're trying
to scale the system.

713
00:33:03,570 --> 00:33:06,630
Could be you are trying
to handle a node failure

714
00:33:06,630 --> 00:33:08,520
or it could be you're doing patching

715
00:33:08,520 --> 00:33:09,420
and software upgrades.

716
00:33:09,420 --> 00:33:12,397
In each of this case, what
happens is Flink says,

717
00:33:12,397 --> 00:33:15,330
"Okay, well, I detect
a change in the system,

718
00:33:15,330 --> 00:33:18,210
let me pause everything,
let me reassign things,

719
00:33:18,210 --> 00:33:19,980
and then resume processing."

720
00:33:19,980 --> 00:33:23,340
So our first goal in operating
the system is making sure

721
00:33:23,340 --> 00:33:25,690
that we are minimizing
these processing delays.

722
00:33:27,330 --> 00:33:28,590
How do we do that?

723
00:33:28,590 --> 00:33:31,860
The key to do that is to
separate the time it takes

724
00:33:31,860 --> 00:33:33,840
to spin up EC2 instances

725
00:33:33,840 --> 00:33:37,620
and other prerequisites from
the overall job downtime.

726
00:33:37,620 --> 00:33:38,820
So you separate those things out,

727
00:33:38,820 --> 00:33:41,940
and we do that with two
specific techniques,

728
00:33:41,940 --> 00:33:43,620
which is one is blue-green deployments,

729
00:33:43,620 --> 00:33:45,513
the other is having a warm pool.

730
00:33:46,470 --> 00:33:47,730
With blue-green deployments,

731
00:33:47,730 --> 00:33:51,840
we do not stop the job until we set up

732
00:33:51,840 --> 00:33:54,330
and verify the prerequisites.

733
00:33:54,330 --> 00:33:55,500
Here is how it works.

734
00:33:55,500 --> 00:33:58,920
First, we spin up the
necessary EC2 instances.

735
00:33:58,920 --> 00:34:03,750
Next, we verify your job configuration,

736
00:34:03,750 --> 00:34:05,790
we'll make sure all the
prerequisites are met.

737
00:34:05,790 --> 00:34:07,890
And at that point is when
we are switching over

738
00:34:07,890 --> 00:34:10,800
from the old infrastructure
to the new infrastructure

739
00:34:10,800 --> 00:34:13,530
and resuming processing
from the exactly same point

740
00:34:13,530 --> 00:34:15,680
at which you stopped
processing previously.

741
00:34:16,980 --> 00:34:18,840
The next key concept is warm pools.

742
00:34:18,840 --> 00:34:22,110
So instead of waiting for
EC2 instances to spin up

743
00:34:22,110 --> 00:34:23,700
and the amount of time it takes,

744
00:34:23,700 --> 00:34:26,940
we maintain a warm pool of infrastructure,

745
00:34:26,940 --> 00:34:29,970
thereby we get an instance
that is ready to go.

746
00:34:29,970 --> 00:34:32,250
So the combination of
blue-green deployments

747
00:34:32,250 --> 00:34:35,520
and warm pools is how we reduce the time

748
00:34:35,520 --> 00:34:37,650
and how we reduce a job downtime

749
00:34:37,650 --> 00:34:39,450
when there's a change in the system.

750
00:34:41,730 --> 00:34:43,800
Another key aspect that we've talked about

751
00:34:43,800 --> 00:34:48,030
is how Flink allows you to
change and evolve your logic.

752
00:34:48,030 --> 00:34:49,380
So our fundamental goal

753
00:34:49,380 --> 00:34:51,540
is to how do we make
this whole process simple

754
00:34:51,540 --> 00:34:54,540
for our developers or for our developers?

755
00:34:54,540 --> 00:34:57,330
We wanna be repeatable, fail proof

756
00:34:57,330 --> 00:35:00,333
and quick so that they can
consistently make changes.

757
00:35:01,800 --> 00:35:02,880
So how does this work?

758
00:35:02,880 --> 00:35:06,930
Well, a developer decides that
you wanna go make changes,

759
00:35:06,930 --> 00:35:07,950
build a new JAR file

760
00:35:07,950 --> 00:35:09,870
with their code changes and they submit

761
00:35:09,870 --> 00:35:11,790
to the managed service.

762
00:35:11,790 --> 00:35:14,220
And what we detect that
there's a new deployment

763
00:35:14,220 --> 00:35:17,730
that is happening and we do
not stop the job right away.

764
00:35:17,730 --> 00:35:21,150
We take a snapshot of
the current running job,

765
00:35:21,150 --> 00:35:23,070
durably store that in S3

766
00:35:23,070 --> 00:35:25,680
and then the managed
service sets up this new job

767
00:35:25,680 --> 00:35:27,090
with the configuration,

768
00:35:27,090 --> 00:35:29,820
sets up the new infrastructure,
including EC2 instances,

769
00:35:29,820 --> 00:35:32,610
make sure they're spinned
up and they're running.

770
00:35:32,610 --> 00:35:35,760
Sets up the job configuration,
validates the things

771
00:35:35,760 --> 00:35:38,370
and then restores the state

772
00:35:38,370 --> 00:35:42,720
from what it has stored within S3.

773
00:35:42,720 --> 00:35:47,010
So now your operators are
running with the preserved state

774
00:35:47,010 --> 00:35:50,700
and that is when you switch
over to the new infrastructure

775
00:35:50,700 --> 00:35:52,143
and you resume processing.

776
00:35:53,010 --> 00:35:56,130
We also pair this with smart guardrails.

777
00:35:56,130 --> 00:35:59,640
The goal there is to detect
any known code issues

778
00:35:59,640 --> 00:36:02,400
and thereby doesn't impact job processing.

779
00:36:02,400 --> 00:36:05,220
So the way this guardrails
work is as an example,

780
00:36:05,220 --> 00:36:06,377
imagine you upload a new code

781
00:36:06,377 --> 00:36:08,760
and it has some null pointer exceptions.

782
00:36:08,760 --> 00:36:11,190
It detects that this
code is having issues,

783
00:36:11,190 --> 00:36:14,490
it automatically reverses back
to the last known good state

784
00:36:14,490 --> 00:36:17,433
of this application and starts
to resume the processing.

785
00:36:18,780 --> 00:36:21,990
So a combination of automation

786
00:36:21,990 --> 00:36:22,980
and the orchestration

787
00:36:22,980 --> 00:36:25,980
of how we deploy new code,
blue-green deployments

788
00:36:25,980 --> 00:36:27,660
and smart guardrails

789
00:36:27,660 --> 00:36:30,180
is how we give developers the confidence

790
00:36:30,180 --> 00:36:32,640
to constantly evolve their applications

791
00:36:32,640 --> 00:36:34,203
in a highly resilient way.

792
00:36:36,630 --> 00:36:37,653
The second learning, the first learning

793
00:36:37,653 --> 00:36:39,960
that we talked about
is any change in Flink

794
00:36:39,960 --> 00:36:41,340
means there is a job downtime

795
00:36:41,340 --> 00:36:42,720
and how do we minimize it, right?

796
00:36:42,720 --> 00:36:45,780
The second key learning
we've had is a lot of times,

797
00:36:45,780 --> 00:36:48,240
developers and administrators in Flink

798
00:36:48,240 --> 00:36:50,820
are working with different abstractions.

799
00:36:50,820 --> 00:36:54,720
Developers are thinking
about core logical operators

800
00:36:54,720 --> 00:36:57,150
and then admins are
thinking about resources,

801
00:36:57,150 --> 00:37:00,300
its utilization, and they have
no visibility into the core.

802
00:37:00,300 --> 00:37:02,910
And same way, developers
have no visibility

803
00:37:02,910 --> 00:37:04,473
into the actual infrastructure.

804
00:37:05,340 --> 00:37:07,590
So we recognize there is a need for them

805
00:37:07,590 --> 00:37:11,163
to have a common mental model
and how to reason about Flink.

806
00:37:12,600 --> 00:37:15,210
And there are two key shared mental models

807
00:37:15,210 --> 00:37:16,830
that we recommend customers.

808
00:37:16,830 --> 00:37:18,450
First is fixed unit.

809
00:37:18,450 --> 00:37:21,120
The second is how do we
think about job availability

810
00:37:21,120 --> 00:37:23,170
and not just infrastructure availability?

811
00:37:24,210 --> 00:37:26,250
Let's talk about fixed units.

812
00:37:26,250 --> 00:37:28,470
Typically it's very hard

813
00:37:28,470 --> 00:37:31,560
or very unpredictable
to map the Flink code

814
00:37:31,560 --> 00:37:34,920
to the actual resources like
task managers and task slots.

815
00:37:34,920 --> 00:37:36,873
It's very unpredictable, hard, complex.

816
00:37:37,860 --> 00:37:40,380
And the reason is that is
different task managers

817
00:37:40,380 --> 00:37:42,630
can have different
performance characteristics

818
00:37:42,630 --> 00:37:44,760
and depending on how you've created slots,

819
00:37:44,760 --> 00:37:46,770
that can have different
performance characteristics.

820
00:37:46,770 --> 00:37:49,290
So you have a pretty unpredictable system.

821
00:37:49,290 --> 00:37:50,700
And the goal with fixed units

822
00:37:50,700 --> 00:37:52,850
is to bring predictability
into the system.

823
00:37:53,940 --> 00:37:56,490
So in our managed
service, the smallest unit

824
00:37:56,490 --> 00:38:00,540
of provisioning is a KPU,
which gives you a one vCPU,

825
00:38:00,540 --> 00:38:04,290
four gigabytes of memory
and 50 gigabytes of storage.

826
00:38:04,290 --> 00:38:05,123
So what it does

827
00:38:05,123 --> 00:38:07,760
is now you get deterministic
performance per parallelism.

828
00:38:08,934 --> 00:38:10,590
Each lane is also isolated.

829
00:38:10,590 --> 00:38:13,653
So the trouble with noisy
neighbors is no longer an issue.

830
00:38:14,640 --> 00:38:16,140
It also makes debugging easier.

831
00:38:16,140 --> 00:38:17,820
So when you have hot slots

832
00:38:17,820 --> 00:38:19,690
or issues, it's very easy to detect

833
00:38:19,690 --> 00:38:22,230
where exactly it is
happening as an administrator

834
00:38:22,230 --> 00:38:24,063
and resolve that very quickly.

835
00:38:25,290 --> 00:38:26,760
Lastly, it simplifies scaling.

836
00:38:26,760 --> 00:38:28,530
So if you want to add more capacity,

837
00:38:28,530 --> 00:38:30,693
you simply add more parallelism units.

838
00:38:32,250 --> 00:38:33,960
And then you also get
predictable state slices.

839
00:38:33,960 --> 00:38:35,800
So things like checkpointing

840
00:38:37,050 --> 00:38:40,440
and backpressure management
becomes a lot more consistent

841
00:38:40,440 --> 00:38:41,703
for application admins.

842
00:38:42,600 --> 00:38:43,950
So what does fixed units do?

843
00:38:43,950 --> 00:38:47,340
For developers, what it means
is your workflows are simple.

844
00:38:47,340 --> 00:38:50,190
Now you can design your
code so that they fit

845
00:38:50,190 --> 00:38:51,780
in a fixed budget.

846
00:38:51,780 --> 00:38:52,710
And then once you figure out

847
00:38:52,710 --> 00:38:55,140
what that deployment profile looks like,

848
00:38:55,140 --> 00:38:58,620
then you can scale that by
simply adding more KPUs.

849
00:38:58,620 --> 00:39:01,560
And for administrators, by
enforcing these guardrails,

850
00:39:01,560 --> 00:39:03,960
you are being more proactive
rather than being reactive

851
00:39:03,960 --> 00:39:06,420
when it comes to handling issues.

852
00:39:06,420 --> 00:39:09,753
So that is a role of the fixed units.

853
00:39:10,590 --> 00:39:13,740
The second common way that you want people

854
00:39:13,740 --> 00:39:14,850
to reason about Flink

855
00:39:14,850 --> 00:39:17,160
is to think about job availability

856
00:39:17,160 --> 00:39:19,470
rather than infrastructure availability.

857
00:39:19,470 --> 00:39:23,760
Now, job availability tracking
in Flink is very hard.

858
00:39:23,760 --> 00:39:26,550
Flink states whether the job is running,

859
00:39:26,550 --> 00:39:29,163
doesn't always mean that
data is getting processed.

860
00:39:30,900 --> 00:39:32,130
Why is that the case?

861
00:39:32,130 --> 00:39:33,960
There are three reasons
why that may happen.

862
00:39:33,960 --> 00:39:37,260
First is the boundaries between user code.

863
00:39:37,260 --> 00:39:40,500
Flink runtime and external
systems are not always clear.

864
00:39:40,500 --> 00:39:42,870
So debugging is very complex.

865
00:39:42,870 --> 00:39:45,750
Second is restarts and
recovery means a lot

866
00:39:45,750 --> 00:39:47,790
of times the underlying
root cause is masked.

867
00:39:47,790 --> 00:39:51,420
The second run, which starts
producing different errors,

868
00:39:51,420 --> 00:39:52,560
will mask the errors

869
00:39:52,560 --> 00:39:55,440
that were actually caused
by the original problem.

870
00:39:55,440 --> 00:39:57,660
That makes troubleshooting very hard.

871
00:39:57,660 --> 00:39:59,730
Finally, issues can happen

872
00:39:59,730 --> 00:40:02,010
that are external to the Flink runtime.

873
00:40:02,010 --> 00:40:03,900
Think about node failures,
storage failures.

874
00:40:03,900 --> 00:40:06,810
So it's important to track
them and address them.

875
00:40:06,810 --> 00:40:10,363
So what we recognize is we need
a smarter detection system,

876
00:40:10,363 --> 00:40:13,740
a system that can detect that
there's an issue, classify it

877
00:40:13,740 --> 00:40:16,640
and be very surgical about the
action it's trying to take.

878
00:40:18,690 --> 00:40:20,160
So what we built is a system

879
00:40:20,160 --> 00:40:23,790
that consistently monitors a Flink job,

880
00:40:23,790 --> 00:40:27,180
looks to classify whether
an issue is something

881
00:40:27,180 --> 00:40:30,750
that is related to user code
or is a system-driven one.

882
00:40:30,750 --> 00:40:34,320
A user-driven issue could look
like issues with your code,

883
00:40:34,320 --> 00:40:36,450
like a null pointer exception,

884
00:40:36,450 --> 00:40:38,250
things that have resource exhaustion

885
00:40:38,250 --> 00:40:40,000
that is created from the code base.

886
00:40:40,931 --> 00:40:41,850
A good example of that

887
00:40:41,850 --> 00:40:43,290
is you've opened too many connections,

888
00:40:43,290 --> 00:40:44,910
you've not closed them

889
00:40:44,910 --> 00:40:47,250
or it could be incorrect configurations

890
00:40:47,250 --> 00:40:48,570
that you picked for your job.

891
00:40:48,570 --> 00:40:51,780
All of these are in the category

892
00:40:51,780 --> 00:40:53,370
that are related to user code.

893
00:40:53,370 --> 00:40:55,980
And then you have system-related issues.

894
00:40:55,980 --> 00:40:59,700
And these could look like
node failures, Flink bugs

895
00:40:59,700 --> 00:41:02,820
or generally issues with connectors.

896
00:41:02,820 --> 00:41:06,300
The automatic healer
identifies error causes,

897
00:41:06,300 --> 00:41:09,960
classifies them, and then
the reason the classification

898
00:41:09,960 --> 00:41:12,480
is important is it can be very surgical

899
00:41:12,480 --> 00:41:14,070
about the fix it wants to do.

900
00:41:14,070 --> 00:41:15,330
As an example, if it detects

901
00:41:15,330 --> 00:41:17,970
that there are incorrect configurations,

902
00:41:17,970 --> 00:41:19,860
dynamically, it can change
those configurations

903
00:41:19,860 --> 00:41:23,220
and thereby restart becomes much faster.

904
00:41:23,220 --> 00:41:24,750
And the whole purpose of the system

905
00:41:24,750 --> 00:41:27,543
is to reduce the mean time
to recover from the failure.

906
00:41:28,560 --> 00:41:31,470
Let's dive deeper using a few examples.

907
00:41:31,470 --> 00:41:34,560
The first one is performance degradation.

908
00:41:34,560 --> 00:41:36,550
Imagine you have built an application

909
00:41:37,808 --> 00:41:40,170
for the fault system that
I talked about previously.

910
00:41:40,170 --> 00:41:42,357
It works great for 100 records per second,

911
00:41:42,357 --> 00:41:44,460
100,000 records per second,

912
00:41:44,460 --> 00:41:46,290
but now suddenly you wanna scale that

913
00:41:46,290 --> 00:41:47,850
to 500,000 records per second.

914
00:41:47,850 --> 00:41:49,650
And those specific static configurations

915
00:41:49,650 --> 00:41:52,530
that you picked no longer
work for this increased scale

916
00:41:52,530 --> 00:41:55,350
and Flink gives you 400 plus
configurations to choose from

917
00:41:55,350 --> 00:41:57,570
and that makes the whole process harder.

918
00:41:57,570 --> 00:42:00,360
So what the detection
system does is it detects

919
00:42:00,360 --> 00:42:02,850
that there's an issue with
the incorrect configuration,

920
00:42:02,850 --> 00:42:04,290
fixes that dynamically

921
00:42:04,290 --> 00:42:06,930
and thereby recovers a job very quickly

922
00:42:06,930 --> 00:42:09,120
from the performance degradation.

923
00:42:09,120 --> 00:42:11,190
The second example is something

924
00:42:11,190 --> 00:42:14,100
that we see very typically
is with connectors.

925
00:42:14,100 --> 00:42:16,470
A good scenario for
this is Flink is looking

926
00:42:16,470 --> 00:42:18,930
to restart the job to
recover from another failure.

927
00:42:18,930 --> 00:42:19,860
And then what it realizes

928
00:42:19,860 --> 00:42:22,080
is that there is this process
related to this connector

929
00:42:22,080 --> 00:42:24,660
that is not responsive.

930
00:42:24,660 --> 00:42:26,580
So what the detector does is it detects

931
00:42:26,580 --> 00:42:29,070
that there's an issue with
this connector process,

932
00:42:29,070 --> 00:42:30,960
kills that process externally,

933
00:42:30,960 --> 00:42:33,630
thereby the job can restart very quickly.

934
00:42:33,630 --> 00:42:35,700
Here's an example once
again where the goal

935
00:42:35,700 --> 00:42:38,220
is to recover faster from an issue.

936
00:42:38,220 --> 00:42:40,980
Finally, failures can happen
outside the Flink job,

937
00:42:40,980 --> 00:42:42,090
which we've talked about.

938
00:42:42,090 --> 00:42:43,740
A good example is node failures.

939
00:42:43,740 --> 00:42:46,260
Failures do happen,
infrastructure does fail.

940
00:42:46,260 --> 00:42:49,170
And when it fails, we detect
that there's an issue.

941
00:42:49,170 --> 00:42:52,140
Pick a node from the warm pool
that I mentioned previously

942
00:42:52,140 --> 00:42:53,400
and then accelerate

943
00:42:53,400 --> 00:42:56,220
the recovery process very
quickly for customers.

944
00:42:56,220 --> 00:42:57,330
So again, three examples

945
00:42:57,330 --> 00:43:00,060
where having a detection
system, classifying it,

946
00:43:00,060 --> 00:43:02,910
being very surgical
with what we are fixing

947
00:43:02,910 --> 00:43:05,403
reduces the mean time to
recover from failures.

948
00:43:07,320 --> 00:43:11,190
Now, what we've also
recognized is availability

949
00:43:11,190 --> 00:43:14,100
is also the function of your code.

950
00:43:14,100 --> 00:43:17,850
Issues such as high CPU, out of memory,

951
00:43:17,850 --> 00:43:20,550
this throttling can also come in terms

952
00:43:20,550 --> 00:43:22,650
of how the code is structured.

953
00:43:22,650 --> 00:43:24,390
Let's understand this using an example.

954
00:43:24,390 --> 00:43:27,420
Imagine a customer says,
a developer says, "Look,

955
00:43:27,420 --> 00:43:29,070
I have this high CPU issue."

956
00:43:29,070 --> 00:43:31,230
And you start dive deeping
into that job graph.

957
00:43:31,230 --> 00:43:34,320
And what you realize is
that job has morphed itself

958
00:43:34,320 --> 00:43:38,160
into a wide variety of
subtasks, 1,600 plus subtasks,

959
00:43:38,160 --> 00:43:41,640
and they're trying to
fit that into 10 KPUs.

960
00:43:41,640 --> 00:43:43,020
Now, one way to solve the problem

961
00:43:43,020 --> 00:43:46,050
is to horizontally scale, add more KPUs.

962
00:43:46,050 --> 00:43:48,840
And you're almost like
throwing money at the problem.

963
00:43:48,840 --> 00:43:49,710
The other way to do that

964
00:43:49,710 --> 00:43:52,560
is to look at is the
code structured properly?

965
00:43:52,560 --> 00:43:56,040
A couple of ways to
think about that is one,

966
00:43:56,040 --> 00:43:59,460
is there excessive branching
happening in this code?

967
00:43:59,460 --> 00:44:01,530
Now, back to our fleet monitoring example,

968
00:44:01,530 --> 00:44:04,830
one way to branch is by alarm type.

969
00:44:04,830 --> 00:44:06,600
It's almost like I'm
executing the same logic

970
00:44:06,600 --> 00:44:08,437
and I want to execute
that for each alarm type.

971
00:44:08,437 --> 00:44:11,670
So I have 20 alarm types,
I have 20 branches.

972
00:44:11,670 --> 00:44:14,070
Another way to do it is
hey, is there something

973
00:44:14,070 --> 00:44:16,170
that is common across these 20 branches?

974
00:44:16,170 --> 00:44:19,650
And potentially you can
organize that by window sizes.

975
00:44:19,650 --> 00:44:22,080
You could have one-minute
windows, five-minute windows,

976
00:44:22,080 --> 00:44:23,190
and maybe three minute windows.

977
00:44:23,190 --> 00:44:26,130
So you can go from having 20
branches to three branches.

978
00:44:26,130 --> 00:44:28,800
So instead of throwing
infrastructure the problem,

979
00:44:28,800 --> 00:44:30,150
you are reorganizing the core

980
00:44:30,150 --> 00:44:32,340
so that way you have lesser subtasks

981
00:44:32,340 --> 00:44:34,020
and there you can fit into the 10 KPU

982
00:44:34,020 --> 00:44:35,220
that we've talked about.

983
00:44:36,300 --> 00:44:38,010
Another example is parallelism.

984
00:44:38,010 --> 00:44:41,460
Sometimes what you see is not
all task managers are busy.

985
00:44:41,460 --> 00:44:43,260
There are some that are
running extremely hot

986
00:44:43,260 --> 00:44:45,330
and there are some that are idle.

987
00:44:45,330 --> 00:44:47,160
And that means that you've
picked an operator parallelism

988
00:44:47,160 --> 00:44:48,630
that doesn't work well consistently

989
00:44:48,630 --> 00:44:50,400
across the entire pipeline.

990
00:44:50,400 --> 00:44:52,140
And that is a case where you
could work with a developer

991
00:44:52,140 --> 00:44:53,820
to make sure they care very specific

992
00:44:53,820 --> 00:44:55,830
about the operator
parallelism they're picking

993
00:44:55,830 --> 00:44:58,230
across different parts of the job.

994
00:44:58,230 --> 00:44:59,550
So these are a couple of examples

995
00:44:59,550 --> 00:45:01,560
where how your layout core

996
00:45:01,560 --> 00:45:04,980
can have an interesting side
effect on the infrastructure.

997
00:45:04,980 --> 00:45:06,180
So what it comes down to

998
00:45:06,180 --> 00:45:08,490
is you need another layer of defense

999
00:45:08,490 --> 00:45:12,120
to make sure you're detecting
these issues very quickly.

1000
00:45:12,120 --> 00:45:14,100
Now, Flink gives you a raft of metrics

1001
00:45:14,100 --> 00:45:16,680
and I'm not gonna spend time
walking through every metric,

1002
00:45:16,680 --> 00:45:18,630
but what I wanted to share with you,

1003
00:45:18,630 --> 00:45:21,150
a mental model around
what our customers use

1004
00:45:21,150 --> 00:45:23,580
when they operate Flink at high scale.

1005
00:45:23,580 --> 00:45:26,370
The first category is application health.

1006
00:45:26,370 --> 00:45:29,460
And the goal here is not
just the actual uptime,

1007
00:45:29,460 --> 00:45:31,800
but also more importantly
is the job making progress?

1008
00:45:31,800 --> 00:45:32,633
Because at the end of the day,

1009
00:45:32,633 --> 00:45:34,560
it's all about processing data.

1010
00:45:34,560 --> 00:45:36,810
The second category is checkpoints.

1011
00:45:36,810 --> 00:45:40,200
Checkpoints are Flink's safety
net to recover from failure.

1012
00:45:40,200 --> 00:45:42,870
So you wanna have a robust
monitoring mechanism

1013
00:45:42,870 --> 00:45:45,194
for these checkpointing data.

1014
00:45:45,194 --> 00:45:47,760
So you're looking at
things like is the duration

1015
00:45:47,760 --> 00:45:49,020
of checkpointing long?

1016
00:45:49,020 --> 00:45:51,300
Are the sizes pretty high?

1017
00:45:51,300 --> 00:45:54,300
So you wanna make sure
that system is very robust.

1018
00:45:54,300 --> 00:45:58,320
The third important
monitoring area is latency.

1019
00:45:58,320 --> 00:46:01,140
At the end of the day,
Flink is a real-time system

1020
00:46:01,140 --> 00:46:02,040
and you wanna make sure

1021
00:46:02,040 --> 00:46:05,220
you're always processing
the freshest data.

1022
00:46:05,220 --> 00:46:08,040
And so one way to do that is
to compare your watermarks

1023
00:46:08,040 --> 00:46:09,810
and see if they are slow or fast.

1024
00:46:09,810 --> 00:46:12,330
A slow watermark means there
is lag getting built up,

1025
00:46:12,330 --> 00:46:16,740
which means that eventually
you have stalled task managers.

1026
00:46:16,740 --> 00:46:18,960
So the goal there is to
compare, as an example,

1027
00:46:18,960 --> 00:46:21,180
your watermarks with your processing time

1028
00:46:21,180 --> 00:46:22,890
to see how behind you are

1029
00:46:22,890 --> 00:46:25,233
with the latest data
that is being processed.

1030
00:46:26,130 --> 00:46:27,870
The fourth dimension is throughput,

1031
00:46:27,870 --> 00:46:29,370
not just the aggregate throughput,

1032
00:46:29,370 --> 00:46:30,660
that is easier to monitor,

1033
00:46:30,660 --> 00:46:33,090
but also to monitor throughput

1034
00:46:33,090 --> 00:46:35,250
to make sure there's
not enough backpressure

1035
00:46:35,250 --> 00:46:37,350
being built into the system

1036
00:46:37,350 --> 00:46:39,540
'cause say as an example,
there's one part of the workflow

1037
00:46:39,540 --> 00:46:40,770
that is getting backed up.

1038
00:46:40,770 --> 00:46:42,570
Then what it means is that spreads

1039
00:46:42,570 --> 00:46:44,280
across the entire pipeline.

1040
00:46:44,280 --> 00:46:46,500
So goal of that is to monitor throughput

1041
00:46:46,500 --> 00:46:48,930
at the operator level,
at the sub-task level,

1042
00:46:48,930 --> 00:46:50,040
thereby you have the insights

1043
00:46:50,040 --> 00:46:51,930
on where exactly within the pipeline

1044
00:46:51,930 --> 00:46:54,540
you're having those
backpressure challenges.

1045
00:46:54,540 --> 00:46:56,490
So those are the four different categories

1046
00:46:56,490 --> 00:46:58,890
on how you can build a
robust monitoring mechanism

1047
00:46:58,890 --> 00:47:00,290
for your Flink applications.

1048
00:47:01,170 --> 00:47:02,420
You also wanna understand what are some

1049
00:47:02,420 --> 00:47:04,440
of the best practices that we can share

1050
00:47:04,440 --> 00:47:05,640
with the development needs?

1051
00:47:05,640 --> 00:47:07,380
One of the successful patterns we've seen

1052
00:47:07,380 --> 00:47:09,690
with customers is where
they've democratized this

1053
00:47:09,690 --> 00:47:12,300
on how to build Flink applications
into their enterprise.

1054
00:47:12,300 --> 00:47:15,600
So what is a good core and
behaviors and when it doesn't

1055
00:47:15,600 --> 00:47:17,970
and what does the anti-patterns
look like on infrastructure?

1056
00:47:17,970 --> 00:47:20,130
The first area is timers and watermarks.

1057
00:47:20,130 --> 00:47:23,490
Now, we've talked about how
event time is super critical

1058
00:47:23,490 --> 00:47:25,230
and so when you don't use event time,

1059
00:47:25,230 --> 00:47:26,670
you end up using processing time.

1060
00:47:26,670 --> 00:47:28,117
The typical complaint you see is,

1061
00:47:28,117 --> 00:47:29,910
"Well, my aggregations are off."

1062
00:47:29,910 --> 00:47:33,180
Well, that tells you that
somewhere in the code

1063
00:47:33,180 --> 00:47:35,700
people are using processing
time versus event time.

1064
00:47:35,700 --> 00:47:39,900
Another scenario with timers
is your watermarks are slow.

1065
00:47:39,900 --> 00:47:41,430
So if your watermarks are slow,

1066
00:47:41,430 --> 00:47:43,200
this means there's too much lag.

1067
00:47:43,200 --> 00:47:44,310
What if they're too fast?

1068
00:47:44,310 --> 00:47:46,770
Well, if they're too fast,
you're not waiting long enough

1069
00:47:46,770 --> 00:47:49,890
for data that is trickling in slowly.

1070
00:47:49,890 --> 00:47:51,330
So you need to find the right balance

1071
00:47:51,330 --> 00:47:53,790
between fast and being too slow.

1072
00:47:53,790 --> 00:47:55,380
The second area is state hygiene.

1073
00:47:55,380 --> 00:47:59,070
And again, state is such
a crucial aspect of Flink,

1074
00:47:59,070 --> 00:48:01,200
but you don't wanna keep
everything in that state

1075
00:48:01,200 --> 00:48:02,643
for all the time.

1076
00:48:03,540 --> 00:48:06,120
What you want is to enforce TTLs,

1077
00:48:06,120 --> 00:48:09,330
thereby your evicting state,
as and when it's necessary.

1078
00:48:09,330 --> 00:48:11,220
So getting your state management

1079
00:48:11,220 --> 00:48:13,320
is super critical in your code.

1080
00:48:13,320 --> 00:48:15,870
The third big area is avoiding data skew.

1081
00:48:15,870 --> 00:48:18,270
One of the calling cards
of Flink is how you're able

1082
00:48:18,270 --> 00:48:19,740
to partition the data,

1083
00:48:19,740 --> 00:48:21,570
process each of that chunk independently.

1084
00:48:21,570 --> 00:48:24,060
And you do that by using keyBy operators.

1085
00:48:24,060 --> 00:48:25,140
Now, what type of operators,

1086
00:48:25,140 --> 00:48:27,840
what type of data patterns you wanna use?

1087
00:48:27,840 --> 00:48:30,150
You certainly wanna avoid
low cardinality analytic keys

1088
00:48:30,150 --> 00:48:32,250
because what happens with
low cardinality cases,

1089
00:48:32,250 --> 00:48:34,470
you have some task managers
that are running hot

1090
00:48:34,470 --> 00:48:36,770
and some task managers that
are running inefficiently.

1091
00:48:36,770 --> 00:48:39,630
So you wanna pick a high
cardinality each time.

1092
00:48:39,630 --> 00:48:41,760
Also, you wanna reduce the
number of shuffles you do.

1093
00:48:41,760 --> 00:48:44,070
Shuffles are critical because
you wanna shuffle data

1094
00:48:44,070 --> 00:48:45,870
because you wanna get data based

1095
00:48:45,870 --> 00:48:48,420
on one particular key,
process that data differently.

1096
00:48:48,420 --> 00:48:49,890
So you would end up using shuffles,

1097
00:48:49,890 --> 00:48:52,950
but using too many means data
is getting shuffled too much.

1098
00:48:52,950 --> 00:48:55,560
That also impacts how much serialized time

1099
00:48:55,560 --> 00:48:57,030
is spent on serialization.

1100
00:48:57,030 --> 00:48:59,820
And that leads to CPU being busy,

1101
00:48:59,820 --> 00:49:02,580
garbage collection being slow
and things of that nature.

1102
00:49:02,580 --> 00:49:07,320
Lastly, serialization and
schemas play a very pivotal role.

1103
00:49:07,320 --> 00:49:09,630
Not all use cases would benefit

1104
00:49:09,630 --> 00:49:11,220
from the default serialization.

1105
00:49:11,220 --> 00:49:13,410
And when you end up using
the default serialization,

1106
00:49:13,410 --> 00:49:15,210
especially for CPU-intense workloads

1107
00:49:15,210 --> 00:49:16,290
by doing transformations

1108
00:49:16,290 --> 00:49:17,820
and complex transformations,

1109
00:49:17,820 --> 00:49:21,780
that ends up again being
an infrastructure issue.

1110
00:49:21,780 --> 00:49:23,340
Schemas also play a very important role.

1111
00:49:23,340 --> 00:49:24,570
Instead of getting all the data,

1112
00:49:24,570 --> 00:49:26,880
then validating it for the quality,

1113
00:49:26,880 --> 00:49:30,360
schemas allow you to enforce
that on the producer side

1114
00:49:30,360 --> 00:49:34,320
so that the Flink consuming
code is confident that the data

1115
00:49:34,320 --> 00:49:37,920
that it's getting is
actually qualitative enough.

1116
00:49:37,920 --> 00:49:42,810
In summary, writing the optimal Flink code

1117
00:49:42,810 --> 00:49:44,160
will make sure the applicants

1118
00:49:44,160 --> 00:49:48,213
are fast, resilient and reliable.

1119
00:49:50,130 --> 00:49:52,710
So that brings us to how

1120
00:49:52,710 --> 00:49:56,430
and what it takes for us
to run Kafka at scale.

1121
00:49:56,430 --> 00:49:58,350
Now, if you want all these capabilities

1122
00:49:58,350 --> 00:50:03,240
without the overhead, we
offer our managed services.

1123
00:50:03,240 --> 00:50:04,710
So I wanna bring Ashish.

1124
00:50:04,710 --> 00:50:06,090
Ashish.
- Yep.

1125
00:50:06,090 --> 00:50:07,767
- We've talked about what
it takes to run Kafka

1126
00:50:07,767 --> 00:50:09,240
and Flink at scale.

1127
00:50:09,240 --> 00:50:11,730
What are some of the top
key takeaways from this?

1128
00:50:11,730 --> 00:50:15,540
- Yeah, I think it's a
really pertinent point.

1129
00:50:15,540 --> 00:50:18,300
One of our motivations
in doing this session

1130
00:50:18,300 --> 00:50:21,900
was actually sharing our experience.

1131
00:50:21,900 --> 00:50:24,450
And a lot of the discussions,

1132
00:50:24,450 --> 00:50:26,580
I know Sai does as well and I do,

1133
00:50:26,580 --> 00:50:29,640
are about customers who know Kafka

1134
00:50:29,640 --> 00:50:32,400
but at the same time,
the effects of scale,

1135
00:50:32,400 --> 00:50:34,163
when they encounter running at scale

1136
00:50:34,163 --> 00:50:37,140
or when they encounter failures
at scale are different.

1137
00:50:37,140 --> 00:50:40,593
And one of our learnings
from that was oftentimes,

1138
00:50:41,460 --> 00:50:46,460
the only place that you
actually learn about failures

1139
00:50:46,560 --> 00:50:49,200
and how you handle them
is when failures happen.

1140
00:50:49,200 --> 00:50:50,550
And that's probably the worst time

1141
00:50:50,550 --> 00:50:52,320
to actually learn those failures.

1142
00:50:52,320 --> 00:50:54,900
And so what we've tried
to do is explain some

1143
00:50:54,900 --> 00:50:57,810
of our thinking in terms
of our best practices,

1144
00:50:57,810 --> 00:51:02,550
but also explain how we are
building the system ground up

1145
00:51:02,550 --> 00:51:04,433
to make sure that these
things are accounted for.

1146
00:51:04,433 --> 00:51:06,090
You saw this on the Kafka end

1147
00:51:06,090 --> 00:51:10,020
as we transition from standard
to serverless to Express,

1148
00:51:10,020 --> 00:51:11,280
and you're seeing this on the Flink end

1149
00:51:11,280 --> 00:51:13,320
on how we are applying that.

1150
00:51:13,320 --> 00:51:14,610
Part of why we are sharing this

1151
00:51:14,610 --> 00:51:17,010
is as you are making your choices

1152
00:51:17,010 --> 00:51:18,840
about running your infrastructure,

1153
00:51:18,840 --> 00:51:21,210
are able to make a decision

1154
00:51:21,210 --> 00:51:22,890
on which of these to apply,

1155
00:51:22,890 --> 00:51:25,752
how you'll apply it and how you'll run it.

1156
00:51:25,752 --> 00:51:28,380
The last sort of big takeaway from me

1157
00:51:28,380 --> 00:51:30,780
and definitely looking
for learning from you

1158
00:51:30,780 --> 00:51:35,400
on the Flink side as well, is too often,

1159
00:51:35,400 --> 00:51:37,020
customers are running infrastructure

1160
00:51:37,020 --> 00:51:39,480
but actually not monitoring the things

1161
00:51:39,480 --> 00:51:41,640
that can cause the failures.

1162
00:51:41,640 --> 00:51:45,840
And so what happens is
oftentimes when failures happen

1163
00:51:45,840 --> 00:51:49,000
or the SOPs are not functional,

1164
00:51:49,000 --> 00:51:51,540
then what happens is you discover

1165
00:51:51,540 --> 00:51:55,470
that your system is not running
as stably as you thought.

1166
00:51:55,470 --> 00:51:56,910
And a part of this

1167
00:51:56,910 --> 00:51:59,610
is that there is a shared
responsibility boundary

1168
00:51:59,610 --> 00:52:01,260
in terms of managing the infrastructure,

1169
00:52:01,260 --> 00:52:03,300
which we will do and we will own.

1170
00:52:03,300 --> 00:52:05,760
And equally importantly,
managing the operational side

1171
00:52:05,760 --> 00:52:10,140
of Kafka or Flink, which
then you and us as customers

1172
00:52:10,140 --> 00:52:12,930
have to have to
participate and partner on.

1173
00:52:12,930 --> 00:52:15,660
And that, Sai, is my key takeaway.

1174
00:52:15,660 --> 00:52:19,650
Partly what I'm hoping here
is that we can help customers

1175
00:52:19,650 --> 00:52:22,590
as they're thinking about their
choices, run better systems.

1176
00:52:22,590 --> 00:52:25,800
Anything on the Flink side
that you'd like to add?

1177
00:52:25,800 --> 00:52:27,983
- It's very similar to
what we've spoken on Kafka.

1178
00:52:27,983 --> 00:52:29,310
I think the three things

1179
00:52:29,310 --> 00:52:31,080
are like knowing your shared boundaries.

1180
00:52:31,080 --> 00:52:33,090
Now, with Flink, the
shared boundary also means

1181
00:52:33,090 --> 00:52:34,560
you're running code, arbitrary code.

1182
00:52:34,560 --> 00:52:38,070
So that has a interesting
effects that we talked about.

1183
00:52:38,070 --> 00:52:40,320
Second is picking the
right offering, right?

1184
00:52:40,320 --> 00:52:42,900
And sometimes you can learn
from our best practice,

1185
00:52:42,900 --> 00:52:44,910
our learnings that we
built into our products

1186
00:52:44,910 --> 00:52:47,070
and build infrastructure on your own

1187
00:52:47,070 --> 00:52:48,300
or use some of our services.

1188
00:52:48,300 --> 00:52:49,500
So I think it's very similar

1189
00:52:49,500 --> 00:52:51,450
to our learnings on Kafka side as well.

1190
00:52:53,040 --> 00:52:55,530
Awesome. Well, that brings to
the end of the presentation.

1191
00:52:55,530 --> 00:52:59,130
Now you can try it for yourself,

1192
00:52:59,130 --> 00:53:00,720
both MSK Express brokers,

1193
00:53:00,720 --> 00:53:02,490
as well as deploy your Flink applications

1194
00:53:02,490 --> 00:53:04,500
or managed service for Apache Flink

1195
00:53:04,500 --> 00:53:05,670
because at the end of the day,

1196
00:53:05,670 --> 00:53:07,413
seeing and trying is believing.

1197
00:53:08,250 --> 00:53:10,163
- [Ashish] With that, thank you so much.

