1
00:00:00,060 --> 00:00:00,960
- Thank you all so much

2
00:00:00,960 --> 00:00:02,520
for coming this early in the morning.

3
00:00:02,520 --> 00:00:03,990
I really appreciate it.

4
00:00:03,990 --> 00:00:06,660
And how many of you,
or for how many of you,

5
00:00:06,660 --> 00:00:08,040
this is the very first session

6
00:00:08,040 --> 00:00:10,230
of their very first re:Invent ever?

7
00:00:10,230 --> 00:00:12,000
Wow.

8
00:00:12,000 --> 00:00:14,220
A lot of first timers here.

9
00:00:14,220 --> 00:00:17,400
Well, you are in for a treat
and quite a bit of walking

10
00:00:17,400 --> 00:00:19,323
as you might have already noticed.

11
00:00:20,580 --> 00:00:21,413
Right.

12
00:00:28,710 --> 00:00:31,560
Imagine that you have built this

13
00:00:31,560 --> 00:00:34,440
simple serverless
architecture in the cloud.

14
00:00:34,440 --> 00:00:36,330
You've picked the
services you want to use,

15
00:00:36,330 --> 00:00:37,740
you connect them together,

16
00:00:37,740 --> 00:00:40,713
and everything just works like magic.

17
00:00:41,790 --> 00:00:42,930
So my show that you, of course,

18
00:00:42,930 --> 00:00:44,793
decide to go to production with it,

19
00:00:45,750 --> 00:00:48,000
and all of a sudden hell breaks loose

20
00:00:48,000 --> 00:00:51,630
and things start to fail in
all possible shapes and forms.

21
00:00:51,630 --> 00:00:53,880
Now you are convinced that you personally

22
00:00:53,880 --> 00:00:56,550
have that absolutely nothing wrong

23
00:00:56,550 --> 00:00:57,690
except for maybe not reading

24
00:00:57,690 --> 00:01:01,260
all the extensive documentation
about all the services

25
00:01:01,260 --> 00:01:02,610
and all the components that you are using.

26
00:01:02,610 --> 00:01:05,523
But let's be real, who does
that nowadays anyway, right?

27
00:01:06,420 --> 00:01:09,303
So what's the next logical step?

28
00:01:10,830 --> 00:01:13,620
Maybe you swear off using the architecture

29
00:01:13,620 --> 00:01:18,120
or services ever again because
well, they just don't work.

30
00:01:18,120 --> 00:01:21,300
And honestly, what's wrong with the cloud?

31
00:01:21,300 --> 00:01:22,890
Why doesn't it work?

32
00:01:22,890 --> 00:01:26,040
Maybe serverless is just
another expensive fad.

33
00:01:26,040 --> 00:01:28,050
Maybe we should just all go back on-prem

34
00:01:28,050 --> 00:01:29,583
and use good old monoliths.

35
00:01:31,110 --> 00:01:34,680
But then again, purely
statistically speaking,

36
00:01:34,680 --> 00:01:38,790
we should consider that maybe
the problem not in the cloud

37
00:01:38,790 --> 00:01:39,780
or the cloud providers.

38
00:01:39,780 --> 00:01:42,690
Maybe it's not even us or
the services that we picked,

39
00:01:42,690 --> 00:01:45,000
not even the architecture.

40
00:01:45,000 --> 00:01:46,383
So what is it then?

41
00:01:48,780 --> 00:01:50,347
As Murphy's Law says,

42
00:01:50,347 --> 00:01:54,030
"Anything that can go
wrong will go wrong,"

43
00:01:54,030 --> 00:01:56,700
though I personally prefer the
more extended version of it

44
00:01:56,700 --> 00:02:00,840
that says, "Anything that
can go wrong will go wrong,

45
00:02:00,840 --> 00:02:02,877
and at the worst possible time."

46
00:02:06,360 --> 00:02:07,620
My name is Anahit.

47
00:02:07,620 --> 00:02:11,010
I'm cloud architecture and
engineering lead at F-Secure.

48
00:02:11,010 --> 00:02:13,470
This is a global cybersecurity
and privacy company

49
00:02:13,470 --> 00:02:16,533
with over 35 years of
experience in the field.

50
00:02:17,550 --> 00:02:19,650
And I'm also an AWS Hero.

51
00:02:19,650 --> 00:02:21,450
And there's a funny thing I noticed

52
00:02:21,450 --> 00:02:24,570
after becoming an AWS
Hero several years back

53
00:02:24,570 --> 00:02:26,340
that people started to come with me

54
00:02:26,340 --> 00:02:29,310
or to me with this smirks on their faces

55
00:02:29,310 --> 00:02:32,760
and saying, "So tell us now
what's wrong with the cloud?

56
00:02:32,760 --> 00:02:34,107
Why doesn't it just work?"

57
00:02:35,160 --> 00:02:37,713
Well, today, I'm finally
here to answer that.

58
00:02:38,970 --> 00:02:40,740
Well, maybe not exactly that,

59
00:02:40,740 --> 00:02:42,750
but I want us to look
together at something

60
00:02:42,750 --> 00:02:46,503
that we as humans don't usually
feel comfortable looking at.

61
00:02:47,940 --> 00:02:48,783
Failures.

62
00:02:49,860 --> 00:02:52,170
And I hope that this talk helps you

63
00:02:52,170 --> 00:02:55,230
to become a bit more aware and curious,

64
00:02:55,230 --> 00:02:58,173
to spot patterns that others
don't necessarily see.

65
00:02:59,220 --> 00:03:01,830
To have the tools and to ask the questions

66
00:03:01,830 --> 00:03:04,890
to make conscious critical decisions

67
00:03:04,890 --> 00:03:06,600
rather than believing in magic,

68
00:03:06,600 --> 00:03:08,673
taking controls in your own hands,

69
00:03:09,690 --> 00:03:14,070
and finally becoming
a little bit paranoid,

70
00:03:14,070 --> 00:03:15,690
but in a good way,

71
00:03:15,690 --> 00:03:17,947
because to borrow words
of Martin Kleppmann,

72
00:03:17,947 --> 00:03:20,760
"In distributed systems,
suspicion, pessimism,

73
00:03:20,760 --> 00:03:22,947
and paranoia pay off."

74
00:03:25,080 --> 00:03:27,930
Now, before we start talking
about distributed systems

75
00:03:27,930 --> 00:03:29,430
and failures any further,

76
00:03:29,430 --> 00:03:32,220
let's briefly go back
to our fictional story

77
00:03:32,220 --> 00:03:34,950
about failing serverless architecture.

78
00:03:34,950 --> 00:03:37,083
It actually had a prequel to it.

79
00:03:38,220 --> 00:03:40,230
So once upon a time,

80
00:03:40,230 --> 00:03:42,570
you were a developer who
started developing software

81
00:03:42,570 --> 00:03:46,140
that was probably supposed
to run on a single machine

82
00:03:46,140 --> 00:03:48,090
somewhere in non-prem data center.

83
00:03:48,090 --> 00:03:50,730
So all you cared about were the so-called

84
00:03:50,730 --> 00:03:53,640
functional requirements
so that your code works,

85
00:03:53,640 --> 00:03:55,710
that's exactly what it's supposed to,

86
00:03:55,710 --> 00:03:59,220
and of course, has as little
box and failures as possible.

87
00:03:59,220 --> 00:04:01,863
That was your definition of reliability.

88
00:04:03,210 --> 00:04:04,200
Now, there could have been

89
00:04:04,200 --> 00:04:05,940
some occasional hardware failures,

90
00:04:05,940 --> 00:04:08,550
but usually they didn't
worry about them too much.

91
00:04:08,550 --> 00:04:11,070
Things either worked or they didn't.

92
00:04:11,070 --> 00:04:12,903
Everything was nicely deterministic.

93
00:04:15,420 --> 00:04:18,510
Next thing you know, you
find yourself in the cloud

94
00:04:18,510 --> 00:04:21,060
maybe using virtual machines

95
00:04:21,060 --> 00:04:23,280
and maybe also start developing software

96
00:04:23,280 --> 00:04:26,250
that requires you to
think about certain levels

97
00:04:26,250 --> 00:04:29,100
of so-called non-functional requirements.

98
00:04:29,100 --> 00:04:32,280
So certain levels of
availability and scalability,

99
00:04:32,280 --> 00:04:36,330
also reliability and resilience
get a whole new meaning.

100
00:04:36,330 --> 00:04:38,160
Now, you still need to take care

101
00:04:38,160 --> 00:04:39,750
of your functional requirements,

102
00:04:39,750 --> 00:04:40,950
make sure that your code works

103
00:04:40,950 --> 00:04:43,290
and has as little failures as possible.

104
00:04:43,290 --> 00:04:45,840
But the complexity level
just went up a notch,

105
00:04:45,840 --> 00:04:48,693
and now you need to
worry about so much more.

106
00:04:50,760 --> 00:04:53,640
And failures are also
becoming a bit more pronounced

107
00:04:53,640 --> 00:04:55,503
and a bit less deterministic.

108
00:04:56,880 --> 00:04:58,980
Welcome to the dark side,

109
00:04:58,980 --> 00:05:01,980
the wonderful world of distributed systems

110
00:05:01,980 --> 00:05:05,343
where with great power
comes great responsibility.

111
00:05:08,310 --> 00:05:09,840
But things didn't stop there.

112
00:05:09,840 --> 00:05:10,920
And before you know it,

113
00:05:10,920 --> 00:05:13,770
you jump over to the serverless world,

114
00:05:13,770 --> 00:05:15,840
their things start to look simple again,

115
00:05:15,840 --> 00:05:19,260
you just pick services,
you connect them together,

116
00:05:19,260 --> 00:05:20,860
and everything works like magic.

117
00:05:21,750 --> 00:05:24,750
You don't really see any
machines around anymore.

118
00:05:24,750 --> 00:05:26,580
And the term serverless actually suggests

119
00:05:26,580 --> 00:05:29,100
that you don't need to be
looking for any machines,

120
00:05:29,100 --> 00:05:31,890
you don't need to be
caring about any machines

121
00:05:31,890 --> 00:05:36,120
and the cloud providers take
care of this ilities for you.

122
00:05:36,120 --> 00:05:39,150
So reliability, scalability, availability,

123
00:05:39,150 --> 00:05:42,240
and you are back to just
worrying about your own code,

124
00:05:42,240 --> 00:05:44,890
working properly and not
having a worry in the world.

125
00:05:45,930 --> 00:05:48,780
Of course, we do know that's
not exactly how things went,

126
00:05:49,710 --> 00:05:53,523
because everything that
can go wrong will go wrong.

127
00:05:54,780 --> 00:05:57,483
So what is it that can go wrong exactly?

128
00:05:59,340 --> 00:06:00,180
To set the stage,

129
00:06:00,180 --> 00:06:02,730
let's talk about cloud
distributed systems,

130
00:06:02,730 --> 00:06:05,280
serverless in very simplified terms.

131
00:06:05,280 --> 00:06:06,810
And if the things I'm gonna cover

132
00:06:06,810 --> 00:06:09,450
for the next couple of
minutes are obvious to you,

133
00:06:09,450 --> 00:06:12,213
just bear with me and
maybe enjoy the animations.

134
00:06:13,230 --> 00:06:15,090
But in really simplified terms,

135
00:06:15,090 --> 00:06:19,110
this is the distributed system
is just a bunch of machines

136
00:06:19,110 --> 00:06:20,403
connected by a network.

137
00:06:22,350 --> 00:06:24,420
And while it provides a lot of new

138
00:06:24,420 --> 00:06:28,350
and exciting ways to build
solutions and solve problems,

139
00:06:28,350 --> 00:06:30,030
it also provides a lot of new

140
00:06:30,030 --> 00:06:32,223
and exciting ways for things to go wrong.

141
00:06:34,020 --> 00:06:36,900
Because resources you
are using are not limited

142
00:06:36,900 --> 00:06:38,610
to a single machine anymore.

143
00:06:38,610 --> 00:06:41,730
They're spread around multiple
servers, data centers,

144
00:06:41,730 --> 00:06:43,740
maybe even geolocations.

145
00:06:43,740 --> 00:06:46,470
And then instead of just
one machine that can fail,

146
00:06:46,470 --> 00:06:47,583
now you have plenty.

147
00:06:48,720 --> 00:06:51,150
And all those failures can
happen on different levels.

148
00:06:51,150 --> 00:06:55,470
It can be operating system,
maybe the CPU, GPU, memory,

149
00:06:55,470 --> 00:06:57,870
I know load balancers, you name it.

150
00:06:57,870 --> 00:06:59,220
And all of those failures

151
00:06:59,220 --> 00:07:02,040
can happen completely
independently from each other

152
00:07:02,040 --> 00:07:04,113
in a most non-deterministic way possible.

153
00:07:05,490 --> 00:07:07,950
But the worst thing here is that,

154
00:07:07,950 --> 00:07:11,940
those machines are talking to
each other over the network.

155
00:07:11,940 --> 00:07:14,190
The network is known for
one thing in particular,

156
00:07:14,190 --> 00:07:17,760
wherever any communication
happens over the network,

157
00:07:17,760 --> 00:07:19,803
it will eventually fail.

158
00:07:22,560 --> 00:07:26,100
Now any cloud is built on top
of such distributed systems.

159
00:07:26,100 --> 00:07:28,770
That's where their superpowers come from.

160
00:07:28,770 --> 00:07:31,470
The cloud providers take care
of the most difficult part

161
00:07:31,470 --> 00:07:33,720
of handling the underlying complexity

162
00:07:33,720 --> 00:07:35,580
of the distributed architecture,

163
00:07:35,580 --> 00:07:38,070
obstructing that complexity away from you

164
00:07:38,070 --> 00:07:42,180
while giving you access to
this fast pool of resources

165
00:07:42,180 --> 00:07:44,493
that no individual user
could ever achieve.

166
00:07:45,480 --> 00:07:48,060
But especially on the bigger scale,

167
00:07:48,060 --> 00:07:51,210
if something has a tiny
little chance of happening,

168
00:07:51,210 --> 00:07:52,360
it most certainly will.

169
00:07:54,840 --> 00:07:58,260
Now, serverless managed
services are a step up

170
00:07:58,260 --> 00:08:00,480
in the obstruction ladder.

171
00:08:00,480 --> 00:08:02,670
They make the underlying infrastructure

172
00:08:02,670 --> 00:08:04,710
seem almost invisible,

173
00:08:04,710 --> 00:08:05,733
almost magical,

174
00:08:06,720 --> 00:08:09,483
so much so that we might
even forget it's there.

175
00:08:10,380 --> 00:08:12,390
But by using the serverless services

176
00:08:12,390 --> 00:08:13,470
and fully managed services,

177
00:08:13,470 --> 00:08:16,830
we didn't just magically
teleport to a different reality.

178
00:08:16,830 --> 00:08:20,310
We are still living in a very
same messy physical world

179
00:08:20,310 --> 00:08:23,703
with all its underlying complexities.

180
00:08:25,020 --> 00:08:27,600
And this higher level of
abstraction with serverless

181
00:08:27,600 --> 00:08:29,880
definitely makes a lot of things easier,

182
00:08:29,880 --> 00:08:32,883
just like a higher level
programming language does.

183
00:08:34,500 --> 00:08:36,720
But it also comes with a danger.

184
00:08:36,720 --> 00:08:39,240
Being seemingly simple to use,

185
00:08:39,240 --> 00:08:42,513
it can also give us this
false sense of security,

186
00:08:43,410 --> 00:08:45,960
which will make spotting
those potential issues

187
00:08:45,960 --> 00:08:46,793
that much harder

188
00:08:46,793 --> 00:08:49,540
because after all, they're
also abstracted away from us.

189
00:08:51,690 --> 00:08:54,930
And the reality is, those
failures didn't go anywhere.

190
00:08:54,930 --> 00:08:56,430
They are still there embedded

191
00:08:56,430 --> 00:08:59,130
in the very same distributed system,

192
00:08:59,130 --> 00:09:02,070
underlying distributed system
just waiting to show up.

193
00:09:02,070 --> 00:09:06,273
And as Leslie Lamport
said, it already, 1987,

194
00:09:07,192 --> 00:09:10,140
"But the distributed system
is one in which the failure

195
00:09:10,140 --> 00:09:12,780
of a computer you didn't even know existed

196
00:09:12,780 --> 00:09:16,800
can render your own computer unusable."

197
00:09:16,800 --> 00:09:19,680
And we could rephrase it for serverless.

198
00:09:19,680 --> 00:09:23,190
So a serverless architecture
is one in which the failure

199
00:09:23,190 --> 00:09:26,280
of the computer you definitely
didn't know was there

200
00:09:26,280 --> 00:09:29,013
can render your entire
architecture unusable.

201
00:09:31,320 --> 00:09:32,820
But with serverless,

202
00:09:32,820 --> 00:09:35,850
rather than seeing
those hardware failures,

203
00:09:35,850 --> 00:09:37,020
maybe blue screens,

204
00:09:37,020 --> 00:09:40,320
we see failures manifest in a different

205
00:09:40,320 --> 00:09:42,333
somewhat less obvious ways.

206
00:09:45,720 --> 00:09:49,440
Now let's climb one last step
in our obstruction ladder

207
00:09:49,440 --> 00:09:52,920
and let's focus on building
distributed applications

208
00:09:52,920 --> 00:09:56,100
on top of serverless and
fully managed services.

209
00:09:56,100 --> 00:09:58,110
So in essence, we are
splitting the problem

210
00:09:58,110 --> 00:10:00,300
that we are fixing into smaller pieces.

211
00:10:00,300 --> 00:10:04,170
For each piece, we're picking
a service or a resource,

212
00:10:04,170 --> 00:10:06,030
and then we're connecting all of them

213
00:10:06,030 --> 00:10:10,140
with things like events,
messages, HTTP requests,

214
00:10:10,140 --> 00:10:13,563
all of which are using the
network in some shape or form.

215
00:10:16,020 --> 00:10:18,360
So in essence, distributed architectures

216
00:10:18,360 --> 00:10:21,840
are actually mirroring the
underlying distributed systems.

217
00:10:21,840 --> 00:10:24,330
They also give us this great power

218
00:10:24,330 --> 00:10:27,243
of building applications in
a completely different ways.

219
00:10:28,200 --> 00:10:30,750
But just like the underlying
distributed systems,

220
00:10:30,750 --> 00:10:33,813
they are susceptible to
various same trade-offs.

221
00:10:34,980 --> 00:10:36,480
The architectures that you're gonna build

222
00:10:36,480 --> 00:10:38,373
are likely gonna be complex.

223
00:10:39,930 --> 00:10:42,840
Every piece can fail at any given moment

224
00:10:42,840 --> 00:10:45,003
in a completely non-deterministic way.

225
00:10:46,050 --> 00:10:48,240
And whenever there is any communication

226
00:10:48,240 --> 00:10:52,233
happening over the network,
it will eventually fail.

227
00:10:54,330 --> 00:10:56,670
Now a special case of these
distributed architectures

228
00:10:56,670 --> 00:10:58,953
are so-called data applications.

229
00:10:59,910 --> 00:11:02,040
With data applications,
we are basically dealing

230
00:11:02,040 --> 00:11:04,770
with large volumes of
data we want to store,

231
00:11:04,770 --> 00:11:05,850
collect, and process them.

232
00:11:05,850 --> 00:11:08,760
And the data itself
can really be anything.

233
00:11:08,760 --> 00:11:11,850
Log data, website
clickstreams, gaming data,

234
00:11:11,850 --> 00:11:12,780
and you name it.

235
00:11:12,780 --> 00:11:14,223
The volume is what matters.

236
00:11:15,360 --> 00:11:18,240
And on one hand, that volume
makes it somewhat easier

237
00:11:18,240 --> 00:11:19,620
to spot those issues,

238
00:11:19,620 --> 00:11:21,510
after all, on a bigger scale,

239
00:11:21,510 --> 00:11:24,660
if things have a chance
of happening, they will.

240
00:11:24,660 --> 00:11:26,940
But also with data applications,

241
00:11:26,940 --> 00:11:30,180
usually the failures are
somewhat less obvious

242
00:11:30,180 --> 00:11:32,553
than let's say with
cloud basic applications.

243
00:11:33,390 --> 00:11:35,670
And quite often if there is a failure

244
00:11:35,670 --> 00:11:38,340
we processing the incoming data,

245
00:11:38,340 --> 00:11:41,100
nowadays is probably gonna
resent that data to you.

246
00:11:41,100 --> 00:11:42,783
Once it's gone, it's gone.

247
00:11:45,750 --> 00:11:49,020
So how do we deal with all that failures

248
00:11:49,020 --> 00:11:50,460
in distributed architectures?

249
00:11:50,460 --> 00:11:52,620
How do we make our architectures

250
00:11:52,620 --> 00:11:56,010
such as data applications more resilient?

251
00:11:56,010 --> 00:11:58,860
Now we are mirroring the
underlying distributed systems.

252
00:11:58,860 --> 00:12:01,560
So let's take a look at
how the cloud providers

253
00:12:01,560 --> 00:12:04,510
are dealing with all those
failures of distributed systems.

254
00:12:05,460 --> 00:12:07,620
Now of course, there's a
lot of complex algorithms

255
00:12:07,620 --> 00:12:08,580
and mechanisms at play

256
00:12:08,580 --> 00:12:10,803
when we talk about the cloud resilience,

257
00:12:11,670 --> 00:12:15,300
but surprisingly, two of
the most effective tools

258
00:12:15,300 --> 00:12:18,513
for better resilience are
also seemingly simple.

259
00:12:20,269 --> 00:12:22,243
They are timeouts and retries.

260
00:12:25,590 --> 00:12:27,060
And those are also the things

261
00:12:27,060 --> 00:12:29,130
that we absolutely need to be aware

262
00:12:29,130 --> 00:12:31,500
when we are building our
distributed applications.

263
00:12:31,500 --> 00:12:34,410
I call them these hidden superpowers,

264
00:12:34,410 --> 00:12:37,260
because while they can
be extremely powerful

265
00:12:37,260 --> 00:12:39,573
with helping us with the resiliency,

266
00:12:40,590 --> 00:12:42,600
they can also backfire

267
00:12:42,600 --> 00:12:45,330
if we are not careful of how we use them.

268
00:12:45,330 --> 00:12:46,880
And we'll soon see what I mean.

269
00:12:49,170 --> 00:12:50,640
Now you might have noticed

270
00:12:50,640 --> 00:12:54,330
that so far I haven't been
mentioning any cloud providers,

271
00:12:54,330 --> 00:12:56,280
any services at all

272
00:12:56,280 --> 00:12:59,670
because those things are
universal to all of them.

273
00:12:59,670 --> 00:13:02,340
But now it's time to finally move on

274
00:13:02,340 --> 00:13:03,930
from our fictional service

275
00:13:03,930 --> 00:13:06,720
about failing serverless architecture.

276
00:13:06,720 --> 00:13:08,610
And it's also time for me to confess

277
00:13:08,610 --> 00:13:11,910
that the story wasn't
that fictional after all.

278
00:13:11,910 --> 00:13:13,980
It's actually something
that happened to me,

279
00:13:13,980 --> 00:13:16,860
at least to some extent several years ago.

280
00:13:16,860 --> 00:13:21,720
So I was working on this simple
powerful data architecture

281
00:13:21,720 --> 00:13:26,190
for near real time data
streaming or pretty large scale.

282
00:13:26,190 --> 00:13:29,460
So there we had a producer
that received our data

283
00:13:29,460 --> 00:13:31,500
that we wanted to store and collect.

284
00:13:31,500 --> 00:13:35,430
And for that purpose, we took
Amazon Kinesis Data Streams.

285
00:13:35,430 --> 00:13:38,220
On one end, we connected
it to our producer,

286
00:13:38,220 --> 00:13:41,193
and on the other end, we
connected AWS Lambda to it.

287
00:13:42,360 --> 00:13:45,600
Just like that, we got ourselves simple,

288
00:13:45,600 --> 00:13:48,030
powerful data processing pipeline.

289
00:13:48,030 --> 00:13:49,500
We're extremely happy with it.

290
00:13:49,500 --> 00:13:50,883
It was working perfectly.

291
00:13:52,530 --> 00:13:54,720
Until one day we realized

292
00:13:54,720 --> 00:13:57,630
that we were actually losing
data in that pipeline.

293
00:13:57,630 --> 00:14:00,783
And the best part was we had
no idea it was happening,

294
00:14:02,010 --> 00:14:04,110
thanks to the higher level of obstruction.

295
00:14:05,010 --> 00:14:07,173
So what exactly was going on there?

296
00:14:08,940 --> 00:14:12,000
Now, briefly, what is
Amazon Kinesis Data Streams?

297
00:14:12,000 --> 00:14:14,700
It's a fully managed and
massively scalable service

298
00:14:14,700 --> 00:14:15,800
to stream data on AWS.

299
00:14:17,220 --> 00:14:19,350
After you write your data to the stream,

300
00:14:19,350 --> 00:14:21,540
it appears there within milliseconds,

301
00:14:21,540 --> 00:14:24,870
and it's available for you
to read for up to 24 hours

302
00:14:24,870 --> 00:14:27,840
or up to a year if you
configure it to be so.

303
00:14:27,840 --> 00:14:30,630
And during that time, you
can read process the data,

304
00:14:30,630 --> 00:14:32,490
replayed in any way that you want,

305
00:14:32,490 --> 00:14:34,110
as many times as you want,

306
00:14:34,110 --> 00:14:36,750
but you cannot delete
the data from the stream.

307
00:14:36,750 --> 00:14:41,103
Once it gets there, it stays
there for at least 24 hours.

308
00:14:41,970 --> 00:14:44,580
Now Kinesis is a very powerful tool.

309
00:14:44,580 --> 00:14:47,940
It doesn't have any servers
or clusters for you to manage

310
00:14:47,940 --> 00:14:49,953
and also scales massively.

311
00:14:51,120 --> 00:14:53,250
And to achieve that massive scalability,

312
00:14:53,250 --> 00:14:55,230
Kinesis used as a concept of a shard.

313
00:14:55,230 --> 00:14:58,800
And you can just think
of it as a ordered queue

314
00:14:58,800 --> 00:14:59,940
within your stream.

315
00:14:59,940 --> 00:15:01,620
And then your stream will be composed

316
00:15:01,620 --> 00:15:05,160
of multiple such queues, multiple shards,

317
00:15:05,160 --> 00:15:08,280
and the chart will come
with capacity limitations.

318
00:15:08,280 --> 00:15:10,500
So you can only write one megabyte

319
00:15:10,500 --> 00:15:15,033
or 1,000 records of data
per second in each shard.

320
00:15:16,350 --> 00:15:18,960
Though each shard comes
with limited capacity,

321
00:15:18,960 --> 00:15:21,600
but the number of shards
you can have in the stream

322
00:15:21,600 --> 00:15:23,760
is virtually unlimited.

323
00:15:23,760 --> 00:15:25,770
So you can add as many shard as you want

324
00:15:25,770 --> 00:15:28,473
to stream as much data as you need.

325
00:15:30,180 --> 00:15:33,540
Now to get all that data to Kinesis,

326
00:15:33,540 --> 00:15:36,450
there are essentially
two different API calls.

327
00:15:36,450 --> 00:15:39,000
You can either write individual records

328
00:15:39,000 --> 00:15:41,940
or you can batch up to 500 records

329
00:15:41,940 --> 00:15:46,572
and send them as an individual
put records request.

330
00:15:46,572 --> 00:15:49,170
And batching in general is a more powerful

331
00:15:49,170 --> 00:15:52,830
and more resource effective
way of making API calls,

332
00:15:52,830 --> 00:15:56,460
especially in this data
intensive applications

333
00:15:56,460 --> 00:15:58,440
where the number of individual requests

334
00:15:58,440 --> 00:16:00,603
can get really high really quickly.

335
00:16:02,070 --> 00:16:04,080
Well, once again, with great power

336
00:16:04,080 --> 00:16:06,060
comes great responsibility,

337
00:16:06,060 --> 00:16:07,980
and we will see very soon what it means

338
00:16:07,980 --> 00:16:09,543
in the context of batching.

339
00:16:12,600 --> 00:16:14,070
Now, we have established by now

340
00:16:14,070 --> 00:16:16,110
those that failures in distributed systems

341
00:16:16,110 --> 00:16:18,453
and architectures are
pretty much inevitable,

342
00:16:19,440 --> 00:16:20,730
especially at a bigger scale.

343
00:16:20,730 --> 00:16:23,190
But how do those failures manifest

344
00:16:23,190 --> 00:16:25,140
at this higher level of obstruction

345
00:16:25,140 --> 00:16:27,183
with services like Kinesis, for example?

346
00:16:28,050 --> 00:16:29,670
it's actually pretty straightforward.

347
00:16:29,670 --> 00:16:32,160
When you interact with the
service from your code,

348
00:16:32,160 --> 00:16:33,990
you're usually making API calls,

349
00:16:33,990 --> 00:16:35,943
and every API call can fail.

350
00:16:37,350 --> 00:16:39,480
Now the good news is that,

351
00:16:39,480 --> 00:16:43,620
if you are using AWS SDK
to make those API calls,

352
00:16:43,620 --> 00:16:47,151
it will take care of most
of those failures for you.

353
00:16:47,151 --> 00:16:48,900
Of course, AWS knows firsthand

354
00:16:48,900 --> 00:16:50,760
that the failures will happen.

355
00:16:50,760 --> 00:16:53,940
So they have built into
the SDK this essential tool

356
00:16:53,940 --> 00:16:58,410
for better resiliency or
superpower as we know it,

357
00:16:58,410 --> 00:16:59,380
the retries.

358
00:17:01,050 --> 00:17:04,530
Now, the trouble with
the retries in general

359
00:17:04,530 --> 00:17:07,860
is that they have a potential of turning

360
00:17:07,860 --> 00:17:11,430
small intermittent problem
like a network glitch

361
00:17:11,430 --> 00:17:12,633
into a massive one,

362
00:17:14,400 --> 00:17:17,880
because retries can have
unexpected blast radius.

363
00:17:17,880 --> 00:17:20,940
They can cause this ripple
effect of cascading failure

364
00:17:20,940 --> 00:17:22,290
through your system

365
00:17:22,290 --> 00:17:25,413
and ultimately bring
the entire system down,

366
00:17:27,480 --> 00:17:31,050
because retries are inherently selfish,

367
00:17:31,050 --> 00:17:33,660
just like hitting that
refresh button in a browser,

368
00:17:33,660 --> 00:17:36,810
we all know we shouldn't do
that, but we do that anyway.

369
00:17:36,810 --> 00:17:39,960
Retries implied that our
request is more valuable,

370
00:17:39,960 --> 00:17:43,260
more important than anything else,

371
00:17:43,260 --> 00:17:48,260
and we are willing to put
resources to use extra capacity

372
00:17:48,810 --> 00:17:51,600
to maybe incorrect the cost
on the downstream system

373
00:17:51,600 --> 00:17:54,000
just to make sure that
our request goes through.

374
00:17:55,740 --> 00:17:58,620
But the retries are not
even always effective,

375
00:17:58,620 --> 00:17:59,853
neither are they safe.

376
00:18:01,860 --> 00:18:05,553
To start with, which failures
are we even retrying?

377
00:18:06,720 --> 00:18:09,720
If the downstream system
is under a lot of load

378
00:18:09,720 --> 00:18:12,240
and for example, it's an API or a database

379
00:18:12,240 --> 00:18:13,530
that is heavily overloaded

380
00:18:13,530 --> 00:18:15,120
and that's what causing the failure,

381
00:18:15,120 --> 00:18:18,213
well, retrying might
just make matters worse.

382
00:18:19,830 --> 00:18:22,260
Or if there was a timeout,

383
00:18:22,260 --> 00:18:24,660
but you are not really ready to wait

384
00:18:24,660 --> 00:18:26,190
for the retry to complete,

385
00:18:26,190 --> 00:18:28,830
for example, you have
your own SLA requirements,

386
00:18:28,830 --> 00:18:31,260
then retrying is plain selfish.

387
00:18:31,260 --> 00:18:33,060
It's just like hitting
that refresh button,

388
00:18:33,060 --> 00:18:35,280
closing your window altogether.

389
00:18:35,280 --> 00:18:37,353
You just wasted resources for nothing.

390
00:18:39,810 --> 00:18:44,100
And what if the underlying
system also has retries built in,

391
00:18:44,100 --> 00:18:47,430
maybe even on various
levels of the architecture?

392
00:18:47,430 --> 00:18:51,297
Well, that can amplify
and multiply the retries

393
00:18:51,297 --> 00:18:53,133
and make things even more dangerous,

394
00:18:54,150 --> 00:18:59,150
especially if the underlying
system is under a lot of load

395
00:18:59,640 --> 00:19:01,770
and you are starting to retry right away

396
00:19:01,770 --> 00:19:04,113
without giving it the
chance to recover first.

397
00:19:05,970 --> 00:19:08,550
And what if the operation
that you're retrying

398
00:19:08,550 --> 00:19:11,790
has side effects like database update?

399
00:19:11,790 --> 00:19:16,200
Well, then retry can have
unexpected side effects

400
00:19:16,200 --> 00:19:17,613
and unexpected results.

401
00:19:18,510 --> 00:19:20,340
So there are many different
considerations here,

402
00:19:20,340 --> 00:19:23,370
but the bottom line is,
we need to be very mindful

403
00:19:23,370 --> 00:19:26,740
about how we use this
superpower, the retries.

404
00:19:28,560 --> 00:19:32,580
Now AWS SDK comes with this
built-in safety measures.

405
00:19:32,580 --> 00:19:35,880
So if I request to a service like Kinesis

406
00:19:35,880 --> 00:19:39,284
or other services fails, for some reason,

407
00:19:39,284 --> 00:19:43,290
AWS SDK will handle only the
so-called retryable errors,

408
00:19:43,290 --> 00:19:46,170
transient failures like
service unavailable,

409
00:19:46,170 --> 00:19:48,303
other 500 errors timeouts.

410
00:19:49,140 --> 00:19:51,330
And for those errors,

411
00:19:51,330 --> 00:19:54,180
it will retry the failed
requests on your behalf

412
00:19:54,180 --> 00:19:55,680
behind the scenes,

413
00:19:55,680 --> 00:19:58,713
but it'll stop on after
certain number of attempts.

414
00:20:00,000 --> 00:20:01,920
And in between those attempts,

415
00:20:01,920 --> 00:20:05,640
it will use the so-called
exponential backoff

416
00:20:05,640 --> 00:20:08,250
where the time between retry attempts

417
00:20:08,250 --> 00:20:09,813
is increasing exponentially.

418
00:20:12,990 --> 00:20:16,140
And those are seemingly simple things,

419
00:20:16,140 --> 00:20:19,200
but they're crucial if
we want to make sure

420
00:20:19,200 --> 00:20:23,260
that retries are serving us as
a tool for better resiliency

421
00:20:24,510 --> 00:20:27,183
because they can actually do the opposite.

422
00:20:28,890 --> 00:20:33,330
So we only want to retry if
it can help the situation,

423
00:20:33,330 --> 00:20:35,340
so only the transient failures.

424
00:20:35,340 --> 00:20:37,050
And when we do retry,

425
00:20:37,050 --> 00:20:40,380
we want to stop when it doesn't
help the situation anymore

426
00:20:40,380 --> 00:20:43,290
to avoid that ripple effect
of cascading failures

427
00:20:43,290 --> 00:20:45,453
and avoid killing the underlying system.

428
00:20:46,620 --> 00:20:49,230
And we also want to spread retry attempts

429
00:20:49,230 --> 00:20:51,210
as uniformly as possible,

430
00:20:51,210 --> 00:20:53,490
not to overwhelm the underlying system,

431
00:20:53,490 --> 00:20:56,463
not to send those bursts
of retries right away.

432
00:20:58,740 --> 00:21:02,220
And with AWS SDK, you are
given those safety measures,

433
00:21:02,220 --> 00:21:05,520
but you also have a
possibility to configure

434
00:21:05,520 --> 00:21:07,140
some of those parameters.

435
00:21:07,140 --> 00:21:09,510
And here's an example
of how you would do that

436
00:21:09,510 --> 00:21:11,610
with JavaScript SDK.

437
00:21:11,610 --> 00:21:13,440
Now every language will
have their own ways

438
00:21:13,440 --> 00:21:17,070
to configure those parameters
and different defaults,

439
00:21:17,070 --> 00:21:20,040
but all of them will give
you to configure some of them

440
00:21:20,040 --> 00:21:21,483
just as they will give you

441
00:21:21,483 --> 00:21:24,240
just to configure the other superpower,

442
00:21:24,240 --> 00:21:26,730
the timeout related values.

443
00:21:26,730 --> 00:21:29,670
Now, if the timeout doesn't
sound like a superpower at all

444
00:21:29,670 --> 00:21:31,710
and you think that it's not a big deal,

445
00:21:31,710 --> 00:21:33,720
I have bad news for you again,

446
00:21:33,720 --> 00:21:35,640
because in distributed systems,

447
00:21:35,640 --> 00:21:38,013
timeouts are pretty much a given.

448
00:21:39,600 --> 00:21:42,660
So let's once again briefly glance

449
00:21:42,660 --> 00:21:44,940
under the hood in simplified terms.

450
00:21:44,940 --> 00:21:47,430
When we interact with
services from our code,

451
00:21:47,430 --> 00:21:50,610
we use API calls that are abstracted away

452
00:21:50,610 --> 00:21:52,203
as SDK method calls.

453
00:21:53,040 --> 00:21:55,170
And those SDK method calls

454
00:21:55,170 --> 00:21:59,430
look exactly like any local
method invocation would.

455
00:21:59,430 --> 00:22:01,530
But let's not let that fool us

456
00:22:01,530 --> 00:22:04,800
because we know that the
network is still there.

457
00:22:04,800 --> 00:22:07,083
You just abstracted away from us.

458
00:22:08,970 --> 00:22:13,970
And any request that goes over the network

459
00:22:14,280 --> 00:22:16,560
like API call to Kinesis

460
00:22:16,560 --> 00:22:20,160
can fail for many various
different reasons.

461
00:22:20,160 --> 00:22:22,890
Moreover, it's almost impossible to tell

462
00:22:22,890 --> 00:22:25,140
if the request actually
went through or not,

463
00:22:25,140 --> 00:22:28,440
because the failure can happen
on many different levels.

464
00:22:28,440 --> 00:22:30,690
Maybe sending the request failed,

465
00:22:30,690 --> 00:22:34,050
maybe receiving or processing
the request failed,

466
00:22:34,050 --> 00:22:36,150
or maybe the request was processed,

467
00:22:36,150 --> 00:22:38,880
but then you never got the response back.

468
00:22:38,880 --> 00:22:41,400
Or maybe your request is
just waiting in the queue

469
00:22:41,400 --> 00:22:44,640
because the downstream
system is overwhelmed.

470
00:22:44,640 --> 00:22:47,460
In any case, the result is still the same.

471
00:22:47,460 --> 00:22:49,710
You might be stuck waiting for something

472
00:22:49,710 --> 00:22:51,363
that might never happen.

473
00:22:52,380 --> 00:22:54,810
So this can happen to any service,

474
00:22:54,810 --> 00:22:57,330
no matter how serverless or not it is.

475
00:22:57,330 --> 00:22:59,280
And to prevent this from happening,

476
00:22:59,280 --> 00:23:01,800
to prevent waiting forever,

477
00:23:01,800 --> 00:23:03,600
AWS has built into the SDK,

478
00:23:03,600 --> 00:23:06,933
this other tool for better
resiliency, the timeouts.

479
00:23:07,885 --> 00:23:10,410
And the ability to
configure those timeouts

480
00:23:10,410 --> 00:23:13,083
is a superpower that is given to us.

481
00:23:15,300 --> 00:23:17,190
But just like with the retries,

482
00:23:17,190 --> 00:23:19,350
we need to be extremely careful

483
00:23:19,350 --> 00:23:21,660
of how we use this superpower,

484
00:23:21,660 --> 00:23:25,110
because picking the right timeout value

485
00:23:25,110 --> 00:23:27,540
is not an easy task at all.

486
00:23:27,540 --> 00:23:30,000
Just like any decision
in your application,

487
00:23:30,000 --> 00:23:32,550
in your architecture, it
will come with trade-offs.

488
00:23:33,570 --> 00:23:37,320
If you pick two long timeouts,
they might be ineffective

489
00:23:37,320 --> 00:23:39,300
and consumer resources.

490
00:23:39,300 --> 00:23:41,040
Two short timeouts

491
00:23:41,040 --> 00:23:43,440
might mean you are
starting to retry too early

492
00:23:43,440 --> 00:23:46,503
without giving the original
request a chance to complete.

493
00:23:48,120 --> 00:23:50,730
Moreover, the appropriate timeout values

494
00:23:50,730 --> 00:23:53,070
will depend on the service or the API call

495
00:23:53,070 --> 00:23:53,910
that you're using.

496
00:23:53,910 --> 00:23:55,860
They will be different for all of them.

497
00:23:56,820 --> 00:23:59,160
Now, for the longest time,
I've been scaring people

498
00:23:59,160 --> 00:24:01,830
by telling that for all the requests,

499
00:24:01,830 --> 00:24:05,790
AWS SDK, JavaScript SDK in particular

500
00:24:05,790 --> 00:24:08,820
will wait for two entire minutes

501
00:24:08,820 --> 00:24:10,593
before timing out the request.

502
00:24:11,610 --> 00:24:14,520
Just think about it for a second.

503
00:24:14,520 --> 00:24:17,820
We're usually dealing with low
latency systems like Kinesis

504
00:24:17,820 --> 00:24:19,980
or maybe DynamoDB.

505
00:24:19,980 --> 00:24:23,520
We are expecting the
response within milliseconds.

506
00:24:23,520 --> 00:24:26,010
And here we are stuck for two minutes

507
00:24:26,010 --> 00:24:28,413
just waiting for it to time out.

508
00:24:30,570 --> 00:24:33,900
But since then things have
changed, things have evolved.

509
00:24:33,900 --> 00:24:35,970
And JavaScript SDK has transitioned

510
00:24:35,970 --> 00:24:38,400
from version 2 to version 3.

511
00:24:38,400 --> 00:24:39,390
We have seen some changes

512
00:24:39,390 --> 00:24:41,910
to the timeout default values as well.

513
00:24:41,910 --> 00:24:46,323
So nowadays, the default
timeout value is infinite.

514
00:24:47,910 --> 00:24:49,800
So either be prepared to be stuck

515
00:24:49,800 --> 00:24:51,240
for a really long time

516
00:24:51,240 --> 00:24:54,190
waiting for something that
might not actually happen

517
00:24:55,050 --> 00:24:57,750
or much better take
control into your own hands

518
00:24:57,750 --> 00:25:00,543
and configure those
timeout values yourself.

519
00:25:03,720 --> 00:25:06,840
Now here we finally
get to the first reason

520
00:25:06,840 --> 00:25:09,243
of losing data in my story,

521
00:25:10,380 --> 00:25:12,090
not configuring the timeouts,

522
00:25:12,090 --> 00:25:14,610
just blindly going with a default.

523
00:25:14,610 --> 00:25:17,370
Waiting for too long for
the requested timeout

524
00:25:17,370 --> 00:25:19,710
can actually exhaust the resources

525
00:25:19,710 --> 00:25:21,300
of your producer application

526
00:25:21,300 --> 00:25:25,320
and make it not being capable
to process new incoming data,

527
00:25:25,320 --> 00:25:27,843
which ultimately means losing data.

528
00:25:28,740 --> 00:25:31,593
And well, that's exactly
what we saw in our story.

529
00:25:32,520 --> 00:25:35,910
So because of likely a
temporary glitch with a service

530
00:25:35,910 --> 00:25:38,940
or a network that caused
the timeout to begin with,

531
00:25:38,940 --> 00:25:42,210
we ended up with a complete system outage,

532
00:25:42,210 --> 00:25:43,500
which is the opposite

533
00:25:43,500 --> 00:25:45,510
from what the resilience system should be.

534
00:25:45,510 --> 00:25:48,450
We need to mask the intermittent failures

535
00:25:48,450 --> 00:25:49,860
instead of amplifying them,

536
00:25:49,860 --> 00:25:51,860
we need to be able to recover from them.

537
00:25:54,480 --> 00:25:56,550
Now obviously this doesn't sound too good,

538
00:25:56,550 --> 00:25:58,117
but if your first thought is,

539
00:25:58,117 --> 00:26:00,960
"Let's just set them the
timeouts to a really low value,"

540
00:26:00,960 --> 00:26:03,360
well again, I have bad news for you

541
00:26:03,360 --> 00:26:05,370
because in my opinion,

542
00:26:05,370 --> 00:26:08,073
two short timeouts can
be even more dangerous.

543
00:26:09,210 --> 00:26:11,130
Because having two short timeouts,

544
00:26:11,130 --> 00:26:14,430
the request might be retried to early

545
00:26:14,430 --> 00:26:16,800
before it had the chance to complete,

546
00:26:16,800 --> 00:26:18,990
which inevitably will add extra load

547
00:26:18,990 --> 00:26:20,610
on the underlying system,

548
00:26:20,610 --> 00:26:22,770
which can cause all sorts of fun things

549
00:26:22,770 --> 00:26:24,960
like increase the load,
increase the costs,

550
00:26:24,960 --> 00:26:26,217
increase latencies,

551
00:26:26,217 --> 00:26:29,220
but ultimately causing that
ripple effect of failures

552
00:26:29,220 --> 00:26:31,683
and bringing the entire system down.

553
00:26:32,940 --> 00:26:37,620
And again, if our goal is
to build a resilient system,

554
00:26:37,620 --> 00:26:39,270
we should do the exact opposite.

555
00:26:39,270 --> 00:26:41,910
We should recover from
individual failures.

556
00:26:41,910 --> 00:26:42,900
And this is especially true

557
00:26:42,900 --> 00:26:44,820
when timeouts are paired with the retries.

558
00:26:44,820 --> 00:26:47,163
We need to be extremely careful.

559
00:26:55,020 --> 00:26:58,700
So this is where wrongly
configured timeout

560
00:26:58,700 --> 00:27:03,270
and retries value can actually
become a match made in hell.

561
00:27:03,270 --> 00:27:05,880
And instead of being a better
tool for better resiliency,

562
00:27:05,880 --> 00:27:07,430
they can do the exact opposite.

563
00:27:08,820 --> 00:27:10,827
So once again, even though timeouts

564
00:27:10,827 --> 00:27:13,260
and retries are extremely powerful,

565
00:27:13,260 --> 00:27:16,920
we need to be very mindful
about how we use them,

566
00:27:16,920 --> 00:27:20,310
and we should never just
blindly go with the defaults

567
00:27:20,310 --> 00:27:22,950
because defaults are dangerous.

568
00:27:22,950 --> 00:27:25,590
So when you go back to
your code, please go ahead,

569
00:27:25,590 --> 00:27:28,050
check all the requests
that go over the network.

570
00:27:28,050 --> 00:27:31,320
Maybe it's SDK calls,
maybe some other API calls.

571
00:27:31,320 --> 00:27:33,780
Make sure that you know what
those timeout values are.

572
00:27:33,780 --> 00:27:35,610
Make sure that you are controlling them.

573
00:27:35,610 --> 00:27:38,820
Don't just blindly trust
it and go with a default,

574
00:27:38,820 --> 00:27:42,430
especially if those timeouts
are paired with the retries.

575
00:27:45,690 --> 00:27:47,640
Now so far I've been
talking about those failures

576
00:27:47,640 --> 00:27:50,400
that are inherent to
distributed systems in general,

577
00:27:50,400 --> 00:27:52,290
but there is another kind of failures

578
00:27:52,290 --> 00:27:55,323
that are actually caused by
the cloud providers on purpose,

579
00:27:56,310 --> 00:27:58,110
and those are failures that are related

580
00:27:58,110 --> 00:28:00,603
to service limits and throttling.

581
00:28:03,060 --> 00:28:06,630
So this can be especially
confusing in a serverless world

582
00:28:06,630 --> 00:28:09,093
because we are promised scalability.

583
00:28:10,020 --> 00:28:11,910
Somehow when we hear scalability,

584
00:28:11,910 --> 00:28:15,450
we tend to assume infinite scalability.

585
00:28:15,450 --> 00:28:17,760
Of course, if something
is too good to be true,

586
00:28:17,760 --> 00:28:19,380
is that just that,

587
00:28:19,380 --> 00:28:22,590
because no resource is scaling infinitely,

588
00:28:22,590 --> 00:28:25,020
and sooner or later we
better face the reality.

589
00:28:25,020 --> 00:28:26,400
And the reality is,

590
00:28:26,400 --> 00:28:30,060
we don't have the entire
cloud at our disposal.

591
00:28:30,060 --> 00:28:34,203
We are sharing the underlying
resources with everybody else,

592
00:28:35,430 --> 00:28:37,470
which of course, has its trade offs.

593
00:28:37,470 --> 00:28:38,303
So on one hand,

594
00:28:38,303 --> 00:28:40,860
we do have this vast
pool of resources to use

595
00:28:40,860 --> 00:28:42,960
like compute storage network,

596
00:28:42,960 --> 00:28:45,540
but this also means
that an individual user

597
00:28:45,540 --> 00:28:47,580
can try to monopolize resources,

598
00:28:47,580 --> 00:28:49,920
and this will inevitably cause degradation

599
00:28:49,920 --> 00:28:52,140
of services for others.

600
00:28:52,140 --> 00:28:54,720
So service limits are actually there

601
00:28:54,720 --> 00:28:56,760
to prevent that from happening.

602
00:28:56,760 --> 00:29:00,630
And throttling is a tool to
enforce those service limits.

603
00:29:00,630 --> 00:29:02,310
So if you remember in case of Kinesis,

604
00:29:02,310 --> 00:29:04,710
we had this shard level limits,

605
00:29:04,710 --> 00:29:08,460
which were one megabyte or
1,000 records per second.

606
00:29:08,460 --> 00:29:11,940
And once you hit that limit,
you start get throttled.

607
00:29:11,940 --> 00:29:13,490
So your requests start to fail.

608
00:29:16,230 --> 00:29:18,090
And this brings us to the second reason

609
00:29:18,090 --> 00:29:19,653
for losing data in my story.

610
00:29:20,580 --> 00:29:23,850
So if you remember, I said that AWS SDK

611
00:29:23,850 --> 00:29:26,583
takes care of the most
of the failures for you,

612
00:29:27,720 --> 00:29:29,280
but of course, there's a catch.

613
00:29:29,280 --> 00:29:31,170
Because in case of batch operations,

614
00:29:31,170 --> 00:29:33,120
like we have put records here,

615
00:29:33,120 --> 00:29:37,410
instead of just handling the
failure of the entire request,

616
00:29:37,410 --> 00:29:41,310
we should also handle the
so-called partial failures.

617
00:29:41,310 --> 00:29:44,160
Because you see those batch
operations, they're not atomic,

618
00:29:44,160 --> 00:29:48,120
they are not either all
succeeds or all fails.

619
00:29:48,120 --> 00:29:50,220
Part of your batch might go through

620
00:29:50,220 --> 00:29:52,290
while the other part fails,

621
00:29:52,290 --> 00:29:54,720
but you are still getting
the success response

622
00:29:54,720 --> 00:29:56,790
back from the SDK.

623
00:29:56,790 --> 00:29:58,950
So it's your responsibility

624
00:29:58,950 --> 00:30:02,310
to detect those failures
and to handle them.

625
00:30:02,310 --> 00:30:04,050
And the main reason for those failures

626
00:30:04,050 --> 00:30:06,270
is exceeding service limit,

627
00:30:06,270 --> 00:30:08,250
for example, because of a traffic spike.

628
00:30:08,250 --> 00:30:12,090
So maybe you could ride
the start of the batch

629
00:30:12,090 --> 00:30:13,260
to the stream successfully,

630
00:30:13,260 --> 00:30:16,323
but then the limit was hit, and
the rest of the batch fails.

631
00:30:17,760 --> 00:30:19,590
Now luckily, we already know

632
00:30:19,590 --> 00:30:21,360
that there is this wonderful superpower

633
00:30:21,360 --> 00:30:23,670
for better resilience that we can use

634
00:30:23,670 --> 00:30:25,830
that can help us with
those transient errors

635
00:30:25,830 --> 00:30:28,710
such as intermittent spike in traffic,

636
00:30:28,710 --> 00:30:31,860
and that's of course, the retries.

637
00:30:31,860 --> 00:30:34,500
And we also know that
when implementing retries

638
00:30:34,500 --> 00:30:36,960
for any failures, we
should be very mindful,

639
00:30:36,960 --> 00:30:40,320
and there are three key things
that we need to keep in mind.

640
00:30:40,320 --> 00:30:42,120
So let's go over them one more time.

641
00:30:43,320 --> 00:30:45,050
So we only want to be retrying

642
00:30:45,050 --> 00:30:47,253
if it can actually help the situation.

643
00:30:48,540 --> 00:30:51,930
We always want to set an
upper limit of retries

644
00:30:51,930 --> 00:30:55,320
to stop retrying where
it doesn't help anymore.

645
00:30:55,320 --> 00:30:59,370
And we want to use exponential backoff

646
00:30:59,370 --> 00:31:00,873
between retry attempts.

647
00:31:02,190 --> 00:31:05,983
Or even better so, use
exponential backoff and jitter.

648
00:31:05,983 --> 00:31:08,820
And jitter is just this random component

649
00:31:08,820 --> 00:31:10,590
that you add to the exponential backoff

650
00:31:10,590 --> 00:31:14,430
to spread the retry
attempts more uniformly.

651
00:31:14,430 --> 00:31:16,620
And what you're trying to achieve

652
00:31:16,620 --> 00:31:19,140
is that you don't want
to put an extra load

653
00:31:19,140 --> 00:31:20,190
on the underlying system,

654
00:31:20,190 --> 00:31:22,200
because if you're hitting a service limit,

655
00:31:22,200 --> 00:31:24,690
you're probably already
quite close to the edge,

656
00:31:24,690 --> 00:31:27,150
so you don't want to be pushing
the system over the edge.

657
00:31:27,150 --> 00:31:29,610
So you want to spread
those retry attempts.

658
00:31:29,610 --> 00:31:31,830
And the jitter or exponential
backoff and jitter

659
00:31:31,830 --> 00:31:35,100
in particular, is a very simple trick

660
00:31:35,100 --> 00:31:38,250
that can actually dramatically
increase the success rate

661
00:31:38,250 --> 00:31:39,570
of your retries.

662
00:31:39,570 --> 00:31:42,570
And this is in fact something
that SDK uses under the hood,

663
00:31:42,570 --> 00:31:46,170
I just didn't mention the
jitter in the previous slides.

664
00:31:46,170 --> 00:31:49,830
So very simple trick, very powerful.

665
00:31:49,830 --> 00:31:54,000
So if so far from this talk
you remember anything at all,

666
00:31:54,000 --> 00:31:59,000
let it be timeout, partial
failures of batch operations,

667
00:31:59,940 --> 00:32:03,630
and retries with exponential
backoff and jitter.

668
00:32:03,630 --> 00:32:06,030
Those things can save
you a lot of headaches

669
00:32:06,030 --> 00:32:08,583
in all sorts of unexpected situations.

670
00:32:10,020 --> 00:32:13,507
And to borrow one of my favorite
quotes from Gregor Hohpe,

671
00:32:13,507 --> 00:32:16,410
"Retries have brought more
distributed systems down

672
00:32:16,410 --> 00:32:18,807
than all the other causes together."

673
00:32:20,550 --> 00:32:23,220
Of course, this doesn't mean
that we shouldn't retry,

674
00:32:23,220 --> 00:32:26,280
but again, it means that
we need to be very mindful

675
00:32:26,280 --> 00:32:27,960
about how we do this,

676
00:32:27,960 --> 00:32:30,423
not to kill the system
that we are trying to fix.

677
00:32:33,270 --> 00:32:36,750
Speaking of which, let's now
take a look at another example

678
00:32:36,750 --> 00:32:39,600
of what can happen if we
just let the matter slide

679
00:32:39,600 --> 00:32:41,790
and go with the good old defaults.

680
00:32:41,790 --> 00:32:44,340
And this one is from the
other end of our architecture.

681
00:32:44,340 --> 00:32:45,660
So if you remember,

682
00:32:45,660 --> 00:32:48,573
we had the Lambda function
there reading from our stream,

683
00:32:49,410 --> 00:32:52,800
and it turns out that things
can escalate pretty quickly

684
00:32:52,800 --> 00:32:54,750
on that end as well.

685
00:32:54,750 --> 00:32:55,803
So let's take a look.

686
00:32:57,630 --> 00:33:00,420
So Lambda itself is actually
a prime representative

687
00:33:00,420 --> 00:33:02,670
or distributed architectures.

688
00:33:02,670 --> 00:33:05,400
It's made of many hidden components

689
00:33:05,400 --> 00:33:07,170
that work together behind the scenes

690
00:33:07,170 --> 00:33:09,480
to make it so very powerful.

691
00:33:09,480 --> 00:33:11,730
And one of those hidden components

692
00:33:11,730 --> 00:33:13,590
is called the event source mapping.

693
00:33:13,590 --> 00:33:16,740
The chances are high, you have
never heard about it before,

694
00:33:16,740 --> 00:33:19,200
and the event source
mapping is hidden well under

695
00:33:19,200 --> 00:33:21,600
the Lambda obstruction layer.

696
00:33:21,600 --> 00:33:23,190
But when you are using Lambda

697
00:33:23,190 --> 00:33:25,590
with event sources like
Kinesis for example,

698
00:33:25,590 --> 00:33:28,140
or DynamoDB Streams or some others,

699
00:33:28,140 --> 00:33:29,850
it's in fact event source mapping

700
00:33:29,850 --> 00:33:32,010
that will be attached to that stream

701
00:33:32,010 --> 00:33:34,440
and that will be reading
records from the stream

702
00:33:34,440 --> 00:33:36,120
and it'll be batching those records

703
00:33:36,120 --> 00:33:39,573
and invoking your Lambda
function with that batch for you.

704
00:33:41,880 --> 00:33:45,450
Now the events mapping reads
records from the stream

705
00:33:45,450 --> 00:33:48,030
from all the shards in
the stream in parallel.

706
00:33:48,030 --> 00:33:51,900
So you would have the
same amount of Lambdas

707
00:33:51,900 --> 00:33:55,440
reading concurrently from your
stream as you have shards.

708
00:33:55,440 --> 00:33:58,530
Unless you are using one of the features

709
00:33:58,530 --> 00:33:59,670
that event source mapping provides,

710
00:33:59,670 --> 00:34:01,620
which called Parallelization Factor,

711
00:34:01,620 --> 00:34:04,860
which where you can actually
have up to 10 Lambdas

712
00:34:04,860 --> 00:34:06,933
reading from each shard in the stream.

713
00:34:08,130 --> 00:34:10,830
Now this is a great example of the power

714
00:34:10,830 --> 00:34:13,680
of parallel processing where
we can just speed things up

715
00:34:13,680 --> 00:34:16,023
by throwing more Lambdas at each shard.

716
00:34:17,040 --> 00:34:19,803
But of course, we all know
what comes with great power.

717
00:34:20,880 --> 00:34:25,200
And we need to remember that
no resource scales infinitely,

718
00:34:25,200 --> 00:34:26,640
not even Lambda.

719
00:34:26,640 --> 00:34:27,810
And here, we have a chance

720
00:34:27,810 --> 00:34:30,900
of hitting one such
important service limit

721
00:34:30,900 --> 00:34:33,153
called Lambda concurrency limit.

722
00:34:34,380 --> 00:34:36,210
And this one basically says that

723
00:34:36,210 --> 00:34:38,280
or means that we can have a limited number

724
00:34:38,280 --> 00:34:41,160
of Lambda invocations,
concurrent Lambda invocations

725
00:34:41,160 --> 00:34:43,590
in the same account, in the same region.

726
00:34:43,590 --> 00:34:46,770
And by default, this
number is set to 1,000.

727
00:34:46,770 --> 00:34:48,900
Though I've heard
stories that new accounts

728
00:34:48,900 --> 00:34:53,250
only get around 100, which
is extremely low for Lambda.

729
00:34:53,250 --> 00:34:54,270
And this is a soft limit.

730
00:34:54,270 --> 00:34:57,420
You can increase it by making a request,

731
00:34:57,420 --> 00:34:59,673
but there still is going to be a limit.

732
00:35:00,570 --> 00:35:02,400
And once you hit that limit,

733
00:35:02,400 --> 00:35:04,860
all the new Lambda
invocations will be throttled,

734
00:35:04,860 --> 00:35:05,693
you'll fail.

735
00:35:06,750 --> 00:35:10,260
So imagine you have a Kinesis
stream with 100 shards

736
00:35:10,260 --> 00:35:12,630
and then you set
Parallelization Factor to 10,

737
00:35:12,630 --> 00:35:14,520
and here you have 1,000 Lambdas

738
00:35:14,520 --> 00:35:17,400
just reading from your
stream at all times,

739
00:35:17,400 --> 00:35:19,920
which probably is not a problem at all

740
00:35:19,920 --> 00:35:23,070
until somewhere else in your
account, in your region,

741
00:35:23,070 --> 00:35:25,740
some other Lambda that has
nothing to do with the stream

742
00:35:25,740 --> 00:35:29,220
starts to fail for very unclear reasons.

743
00:35:29,220 --> 00:35:32,850
And the reason is that your
stream and your stream consumer

744
00:35:32,850 --> 00:35:35,010
has used the entire
Lambda concurrency limit

745
00:35:35,010 --> 00:35:37,170
for that account, that region.

746
00:35:37,170 --> 00:35:38,250
So this is a limit

747
00:35:38,250 --> 00:35:40,470
that can actually have a blast radius

748
00:35:40,470 --> 00:35:43,380
well beyond your own
architecture and your own system.

749
00:35:43,380 --> 00:35:45,903
So you need to be
extremely mindful about it.

750
00:35:47,790 --> 00:35:51,000
Now let's go back to reading
the records from the stream.

751
00:35:51,000 --> 00:35:53,250
So what happens if Lambda fails

752
00:35:53,250 --> 00:35:56,160
to read a record from your Kinesis stream?

753
00:35:56,160 --> 00:35:59,790
Once again, I come with
good news and bad news.

754
00:35:59,790 --> 00:36:02,800
So the good news is that
the event source mapping

755
00:36:03,660 --> 00:36:06,363
comes with extensive air
handling capabilities.

756
00:36:07,710 --> 00:36:11,217
Now, to use them, you
need to be aware of them

757
00:36:11,217 --> 00:36:13,470
and you need to know where to look.

758
00:36:13,470 --> 00:36:16,470
So the bad news is that you're very likely

759
00:36:16,470 --> 00:36:19,200
to just blindly go with the defaults.

760
00:36:19,200 --> 00:36:21,950
And we know by now that
defaults can be very dangerous.

761
00:36:25,740 --> 00:36:28,470
Excuse me, went the other way.

762
00:36:28,470 --> 00:36:30,150
So what happens by default

763
00:36:30,150 --> 00:36:32,700
if Lambda fails to process
a batch of records?

764
00:36:32,700 --> 00:36:35,580
Let's say there was a bad
record with some corrupted data,

765
00:36:35,580 --> 00:36:37,860
Lambda could process
it, we didn't catch it.

766
00:36:37,860 --> 00:36:38,760
Lambda throws an error.

767
00:36:38,760 --> 00:36:39,663
What happens next?

768
00:36:41,340 --> 00:36:43,590
So by default, even
though in this situation,

769
00:36:43,590 --> 00:36:46,470
no amount of retries will
actually help anything

770
00:36:46,470 --> 00:36:49,050
because there's a bad
record, you can't process it.

771
00:36:49,050 --> 00:36:52,620
But by default, Lambda will
be retrying the bad batch

772
00:36:52,620 --> 00:36:56,220
of records over and over
and over and over again

773
00:36:56,220 --> 00:36:58,020
until the leader succeeds,

774
00:36:58,020 --> 00:37:00,510
which again, we know is not gonna happen

775
00:37:00,510 --> 00:37:04,440
or until the records in the batch expire,

776
00:37:04,440 --> 00:37:08,223
which in case of Kinesis
happens in at least 24 hours.

777
00:37:09,540 --> 00:37:11,700
So it's at least one day

778
00:37:11,700 --> 00:37:15,480
of absolutely useless retries from Lambda.

779
00:37:15,480 --> 00:37:17,850
And you can imagine all
those useless invocations,

780
00:37:17,850 --> 00:37:19,740
and mind you, they are not free.

781
00:37:19,740 --> 00:37:21,240
You are still paying for them.

782
00:37:23,190 --> 00:37:24,870
But that's not the only problem there

783
00:37:24,870 --> 00:37:28,590
because all those retries
will likely cause reprocessing

784
00:37:28,590 --> 00:37:30,390
of the same data,

785
00:37:30,390 --> 00:37:31,800
because you see from perspective

786
00:37:31,800 --> 00:37:33,300
the event source mapping here,

787
00:37:33,300 --> 00:37:37,233
either the entire batch succeeds
or the entire batch fails.

788
00:37:38,220 --> 00:37:40,800
So even if the Lambda succeeded to process

789
00:37:40,800 --> 00:37:43,860
some part of that batch
and then it failed,

790
00:37:43,860 --> 00:37:46,020
the entire batch will be failed by default

791
00:37:46,020 --> 00:37:49,740
and the entire batch will be
retried over and over again.

792
00:37:49,740 --> 00:37:51,150
Like records 1, 2, 3 there,

793
00:37:51,150 --> 00:37:53,650
you will probably reprocess
them a bunch of times.

794
00:37:56,010 --> 00:37:57,540
But that's not it.

795
00:37:57,540 --> 00:37:58,500
There's more.

796
00:37:58,500 --> 00:37:59,700
Things get worse.

797
00:37:59,700 --> 00:38:03,180
Because while all those
useless retries are happening,

798
00:38:03,180 --> 00:38:07,113
no other records are being
processed from that shard.

799
00:38:07,950 --> 00:38:09,480
That shard is technically stuck.

800
00:38:09,480 --> 00:38:12,990
It's just waiting for something
that will never happen.

801
00:38:12,990 --> 00:38:16,290
So because of one bad record,

802
00:38:16,290 --> 00:38:19,593
now we have a shard that is
completely non-functional,

803
00:38:20,820 --> 00:38:23,820
which is why it's often referred
to as a poison pill record.

804
00:38:25,500 --> 00:38:26,333
Now,

805
00:38:28,290 --> 00:38:30,033
after 24 hours pass,

806
00:38:31,350 --> 00:38:33,360
your Lambda finally can go on.

807
00:38:33,360 --> 00:38:36,870
The data is expiring from the stream,

808
00:38:36,870 --> 00:38:38,070
of course, part of the batch

809
00:38:38,070 --> 00:38:39,450
is leaving the stream unprocessed,

810
00:38:39,450 --> 00:38:41,670
but that's life, what we can do about it.

811
00:38:41,670 --> 00:38:42,900
Nothing at this point.

812
00:38:42,900 --> 00:38:44,820
At least Lambda can now catch up.

813
00:38:44,820 --> 00:38:47,343
It can continue processing
data from the shard.

814
00:38:48,480 --> 00:38:50,580
Now the problem here is that,

815
00:38:50,580 --> 00:38:52,980
by that point of time, your
shard is probably filled

816
00:38:52,980 --> 00:38:55,500
with records that were
written to the stream

817
00:38:55,500 --> 00:38:59,310
around the same time
as the expired records,

818
00:38:59,310 --> 00:39:02,943
which means that they also
expire around the same time.

819
00:39:04,260 --> 00:39:05,340
Which means that your Lambda

820
00:39:05,340 --> 00:39:07,830
might not even have a chance to catch up.

821
00:39:07,830 --> 00:39:10,290
The records will keep
expiring and expiring

822
00:39:10,290 --> 00:39:11,700
and you will keep losing data.

823
00:39:11,700 --> 00:39:14,640
So I often bring this
overflowing sink analogy.

824
00:39:14,640 --> 00:39:16,800
When we pour water too quickly,

825
00:39:16,800 --> 00:39:19,950
we can't drain it quick enough,
so the water just overflows.

826
00:39:19,950 --> 00:39:21,603
That happens to our data.

827
00:39:23,430 --> 00:39:26,763
So even though we started
with just one bad record,

828
00:39:27,810 --> 00:39:30,780
we might have end up losing a lot of valid

829
00:39:30,780 --> 00:39:32,133
and valuable data.

830
00:39:33,240 --> 00:39:34,080
Once again, opposite

831
00:39:34,080 --> 00:39:36,080
of what the resilience system should be.

832
00:39:37,763 --> 00:39:39,000
And you might have guessed,

833
00:39:39,000 --> 00:39:42,300
this is exactly what we saw in my story.

834
00:39:42,300 --> 00:39:44,247
Just like with those
poorly configured timeouts

835
00:39:44,247 --> 00:39:46,080
and retries earlier,

836
00:39:46,080 --> 00:39:48,090
which are in the small localized problem,

837
00:39:48,090 --> 00:39:51,750
one bad record into a full blown outage.

838
00:39:51,750 --> 00:39:54,930
And in the process, we
ended up losing data,

839
00:39:54,930 --> 00:39:57,360
added latencies, incurring duplicates,

840
00:39:57,360 --> 00:40:00,390
incurring extra costs, spending resources,

841
00:40:00,390 --> 00:40:02,460
and all of that were absolutely nothing,

842
00:40:02,460 --> 00:40:04,563
leading absolutely nowhere.

843
00:40:05,640 --> 00:40:08,820
And all of that because
we didn't know any better

844
00:40:08,820 --> 00:40:12,420
and we just blindly went
with good old defaults.

845
00:40:12,420 --> 00:40:15,750
And here again, the wonderful
quote by Gregor reminds us

846
00:40:15,750 --> 00:40:18,543
to be very careful with the retries.

847
00:40:19,620 --> 00:40:22,410
Luckily, there are many simple ways

848
00:40:22,410 --> 00:40:25,320
to be more mindful about
failures with Lambda.

849
00:40:25,320 --> 00:40:26,340
And first and foremost,

850
00:40:26,340 --> 00:40:28,500
we need to configure those parameters

851
00:40:28,500 --> 00:40:31,860
and those capabilities that
event source mapping comes with.

852
00:40:31,860 --> 00:40:35,700
Now, we know by now that the
most important thing we can do

853
00:40:35,700 --> 00:40:40,440
is to configure timeouts
and set limits for retries.

854
00:40:40,440 --> 00:40:42,060
And you can actually do both of that

855
00:40:42,060 --> 00:40:43,360
with event source mapping.

856
00:40:44,220 --> 00:40:47,700
But both of them are set
to minus one by default,

857
00:40:47,700 --> 00:40:49,173
which means no limits.

858
00:40:50,190 --> 00:40:52,800
And this is precisely
what we saw in our story.

859
00:40:52,800 --> 00:40:56,280
So make sure you configure those defaults.

860
00:40:56,280 --> 00:41:00,210
And there are also a lot
of other very helpful,

861
00:41:00,210 --> 00:41:01,230
very important settings.

862
00:41:01,230 --> 00:41:03,270
I'm not gonna go through them today,

863
00:41:03,270 --> 00:41:04,650
but knowing about them,

864
00:41:04,650 --> 00:41:07,620
knowing how to use them
can be extremely helpful

865
00:41:07,620 --> 00:41:11,910
and can save you a lot of
gray hair in the future.

866
00:41:11,910 --> 00:41:16,170
And you can combine those
settings in any way that you want.

867
00:41:16,170 --> 00:41:18,840
Use them in any combination that you want.

868
00:41:18,840 --> 00:41:22,863
Just whatever you do, please
do not go with a default.

869
00:41:30,150 --> 00:41:31,590
So we have seen today

870
00:41:31,590 --> 00:41:34,350
that sometimes we can cause more problems

871
00:41:34,350 --> 00:41:36,480
while trying to fix them.

872
00:41:36,480 --> 00:41:39,330
And this is especially true
if we don't make conscious,

873
00:41:39,330 --> 00:41:43,230
critical informed decisions
about handling failures.

874
00:41:43,230 --> 00:41:44,397
And things like timeouts

875
00:41:44,397 --> 00:41:47,610
and retries can be extremely powerful

876
00:41:47,610 --> 00:41:49,140
if we put a thought into it.

877
00:41:49,140 --> 00:41:52,320
But if we just let the matter slide,

878
00:41:52,320 --> 00:41:53,850
they can turn against us

879
00:41:53,850 --> 00:41:56,940
and can make our
architecture less resilient

880
00:41:56,940 --> 00:41:58,440
instead of doing the opposite.

881
00:41:59,790 --> 00:42:03,030
So next time you build a
distributed application,

882
00:42:03,030 --> 00:42:04,870
I encourage you to be brave

883
00:42:06,360 --> 00:42:08,580
to face the messy reality
of the real world,

884
00:42:08,580 --> 00:42:10,470
to take control into your own hands

885
00:42:10,470 --> 00:42:12,180
rather than believing in magic

886
00:42:12,180 --> 00:42:13,950
because things are not magical,

887
00:42:13,950 --> 00:42:15,363
and that's a good thing.

888
00:42:17,610 --> 00:42:19,050
And distributed systems

889
00:42:19,050 --> 00:42:21,180
and architectures are extremely powerful,

890
00:42:21,180 --> 00:42:22,590
but they're also complex,

891
00:42:22,590 --> 00:42:25,893
which doesn't make them neither
inherently good nor bad.

892
00:42:26,970 --> 00:42:29,070
And the cloud, especially serverless

893
00:42:29,070 --> 00:42:32,130
abstracts away a lot of
that complexity from us.

894
00:42:32,130 --> 00:42:35,520
But that doesn't mean that
complexity is not there anymore,

895
00:42:35,520 --> 00:42:38,790
which again, doesn't make
them neither good or bad.

896
00:42:38,790 --> 00:42:40,980
And while we absolutely don't need to know

897
00:42:40,980 --> 00:42:43,920
every single detail about
every single service,

898
00:42:43,920 --> 00:42:45,780
that's pretty much impossible.

899
00:42:45,780 --> 00:42:47,910
There are some fundamental things

900
00:42:47,910 --> 00:42:49,560
that are inherent to the cloud

901
00:42:49,560 --> 00:42:51,660
and distributed systems in general.

902
00:42:51,660 --> 00:42:55,320
So things like service
limits, partial failures,

903
00:42:55,320 --> 00:42:58,262
timeouts, retries, backoffs,

904
00:42:58,262 --> 00:42:59,610
and those are all the fundamentals

905
00:42:59,610 --> 00:43:02,220
that we absolutely need to understand.

906
00:43:02,220 --> 00:43:04,140
Otherwise, we're just moving in the dark

907
00:43:04,140 --> 00:43:05,370
with our eyes closed

908
00:43:05,370 --> 00:43:07,370
and hoping that everything will be fine.

909
00:43:08,910 --> 00:43:12,360
Now, on an even more philosophical note,

910
00:43:12,360 --> 00:43:15,360
distributed systems and
architectures are hard,

911
00:43:15,360 --> 00:43:18,660
but they can also teach
us a very valuable skill,

912
00:43:18,660 --> 00:43:21,663
to embrace the chaos of the real world,

913
00:43:22,890 --> 00:43:25,800
because each failure is an
opportunity to do things better,

914
00:43:25,800 --> 00:43:28,620
to make our systems even more resilient.

915
00:43:28,620 --> 00:43:31,590
And even though we can
never build something

916
00:43:31,590 --> 00:43:34,320
that never fails despite our best effort,

917
00:43:34,320 --> 00:43:35,910
there's one thing that we can do.

918
00:43:35,910 --> 00:43:38,373
We can learn and grow from each failure.

919
00:43:39,690 --> 00:43:43,507
And as that Dr. Werner
Vogels likes to remind us,

920
00:43:43,507 --> 00:43:45,960
"Everything fails all the time."

921
00:43:45,960 --> 00:43:47,340
That's just a reality of things.

922
00:43:47,340 --> 00:43:49,170
So either in life in general

923
00:43:49,170 --> 00:43:52,410
or with AWS services in particular,

924
00:43:52,410 --> 00:43:55,860
I'd say that the best thing
that we can do is to keep calm

925
00:43:55,860 --> 00:43:58,533
and be prepared when
those failures happen.

926
00:44:00,330 --> 00:44:01,560
And that's it for me for today.

927
00:44:01,560 --> 00:44:03,300
Thank you all so much for listening,

928
00:44:03,300 --> 00:44:06,570
and I hope I will get
feedback from you very soon.

929
00:44:06,570 --> 00:44:07,403
Thank you.

930
00:44:07,403 --> 00:44:10,455
(audience applauds)

