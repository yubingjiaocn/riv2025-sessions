1
00:00:00,150 --> 00:00:00,990
- Hi, I am Leo Brunnick.

2
00:00:00,990 --> 00:00:03,630
I'm the Chief Product Officer at Cloudera.

3
00:00:03,630 --> 00:00:05,553
Thank you for coming to this session.

4
00:00:06,720 --> 00:00:08,550
You know, everybody talks about AI, right?

5
00:00:08,550 --> 00:00:11,730
You have to end every sentence
with the word AI, I think.

6
00:00:11,730 --> 00:00:13,920
But we're gonna show you something today

7
00:00:13,920 --> 00:00:16,320
that some really smart people did

8
00:00:16,320 --> 00:00:19,980
to actually help people that
are doing good out there.

9
00:00:19,980 --> 00:00:21,240
To me, it's pretty inspirational.

10
00:00:21,240 --> 00:00:23,910
So I'm gonna introduce the
two smart people, my two Als,

11
00:00:23,910 --> 00:00:25,680
that's Alicia and Alastair.

12
00:00:25,680 --> 00:00:26,760
Alicia, come on up.

13
00:00:26,760 --> 00:00:28,710
Alicia's with Mercy Corps.

14
00:00:28,710 --> 00:00:32,070
And Alastair, Alastair's
with the Cloudera.

15
00:00:32,070 --> 00:00:36,270
Two brilliant people who help
bring this solution to life.

16
00:00:36,270 --> 00:00:39,303
So I'll let you guys introduce
yourselves more fully.

17
00:00:42,960 --> 00:00:43,793
So...

18
00:00:46,890 --> 00:00:47,820
- Freak mode there.

19
00:00:47,820 --> 00:00:49,740
- All right, so that
says, "Walk on slide."

20
00:00:49,740 --> 00:00:50,760
I think we're already here.

21
00:00:50,760 --> 00:00:52,950
All right.
(Alastair laughs)

22
00:00:52,950 --> 00:00:53,783
Honestly, thanks.

23
00:00:53,783 --> 00:00:55,590
I mean, I've had the chance to see

24
00:00:55,590 --> 00:00:57,060
this what's been done on this project

25
00:00:57,060 --> 00:00:58,710
and it's inspirational.

26
00:00:58,710 --> 00:01:02,040
So, Alicia, why don't you
introduce yourself more fully?

27
00:01:02,040 --> 00:01:03,630
- Yeah, my name is Alicia Morrison

28
00:01:03,630 --> 00:01:06,390
and I'm the Senior Director
for Technology for Development

29
00:01:06,390 --> 00:01:07,620
at Mercy Corps.

30
00:01:07,620 --> 00:01:09,540
So Mercy Corps is a global

31
00:01:09,540 --> 00:01:12,060
nonprofit humanitarian organization,

32
00:01:12,060 --> 00:01:13,920
and our mission is to alleviate suffering,

33
00:01:13,920 --> 00:01:14,970
poverty, and oppression

34
00:01:14,970 --> 00:01:17,520
by helping people build secured, just,

35
00:01:17,520 --> 00:01:19,770
and productive communities.

36
00:01:19,770 --> 00:01:22,710
So we work in 35 plus
countries around the world.

37
00:01:22,710 --> 00:01:25,140
We have more than 4,000 team members.

38
00:01:25,140 --> 00:01:27,870
Most of those team members
are from the countries

39
00:01:27,870 --> 00:01:29,730
in which they live and work,

40
00:01:29,730 --> 00:01:31,380
because we do have a
really strong commitment

41
00:01:31,380 --> 00:01:33,573
to localization for aid and development.

42
00:01:34,470 --> 00:01:38,790
So Mercy Corps has a
specific value proposition

43
00:01:38,790 --> 00:01:41,160
amongst international NGOs,

44
00:01:41,160 --> 00:01:43,590
and that's called Crisis Analysis.

45
00:01:43,590 --> 00:01:46,773
And what Crisis Analysis
is, is really sort of,

46
00:01:47,640 --> 00:01:50,400
a team of people in a particular country

47
00:01:50,400 --> 00:01:54,210
that wants to support
better humanitarian outcomes

48
00:01:54,210 --> 00:01:56,940
by providing high-level analyses,

49
00:01:56,940 --> 00:01:59,280
often qualitative, sometimes quantitative,

50
00:01:59,280 --> 00:02:01,950
often a combination of
both of those things.

51
00:02:01,950 --> 00:02:04,800
And providing products to
humanitarian decision-makers

52
00:02:04,800 --> 00:02:08,130
to help them decide when and
where to apply humanitarian aid

53
00:02:08,130 --> 00:02:12,450
or development resources,
whatever the case is.

54
00:02:12,450 --> 00:02:15,690
So they can do a number of
different types of products,

55
00:02:15,690 --> 00:02:17,250
things like context monitoring,

56
00:02:17,250 --> 00:02:20,280
so looking at things
like politics, conflict,

57
00:02:20,280 --> 00:02:22,530
what's happening in the country,

58
00:02:22,530 --> 00:02:24,630
but also different humanitarian themes

59
00:02:24,630 --> 00:02:28,260
like what's going on with agriculture.

60
00:02:28,260 --> 00:02:31,020
Can we glean some information about

61
00:02:31,020 --> 00:02:34,710
how agricultural production
is going this year

62
00:02:34,710 --> 00:02:37,560
by looking at things like satellite data.

63
00:02:37,560 --> 00:02:39,480
We also look at data products.

64
00:02:39,480 --> 00:02:42,360
So again, sort of geospatial analytics,

65
00:02:42,360 --> 00:02:45,810
as well as analytics on things
like conflict information.

66
00:02:45,810 --> 00:02:47,220
Try to draw out patterns,

67
00:02:47,220 --> 00:02:50,460
try to do analysis with social media,

68
00:02:50,460 --> 00:02:52,350
and really, kind of just try to provide

69
00:02:52,350 --> 00:02:53,700
as much information as possible

70
00:02:53,700 --> 00:02:55,980
to the humanitarian community at large

71
00:02:55,980 --> 00:02:57,630
in a particular country,

72
00:02:57,630 --> 00:02:59,910
and make sure they have all
the information that they need

73
00:02:59,910 --> 00:03:02,700
in order to make critical
decisions on the ground.

74
00:03:02,700 --> 00:03:05,610
And this is particularly
important in contexts

75
00:03:05,610 --> 00:03:10,470
that are very fast-moving,
changing very rapidly.

76
00:03:10,470 --> 00:03:13,560
It's something like 80 some percent

77
00:03:13,560 --> 00:03:16,290
of humanitarian decision-makers say

78
00:03:16,290 --> 00:03:19,530
that data silos impact their
ability to make decisions

79
00:03:19,530 --> 00:03:21,390
on a regular basis.

80
00:03:21,390 --> 00:03:24,660
And so they try to bring a lot
of that information together

81
00:03:24,660 --> 00:03:27,060
in order to provide insights

82
00:03:27,060 --> 00:03:29,730
that will drive humanitarian
decision-making.

83
00:03:29,730 --> 00:03:32,280
- I think you guys could
tell from that description

84
00:03:32,280 --> 00:03:35,340
what a great use case
this is gonna be for AI.

85
00:03:35,340 --> 00:03:36,210
Explain the...

86
00:03:36,210 --> 00:03:38,250
Al, why don't you introduce
yourself more fully?

87
00:03:38,250 --> 00:03:40,200
- Hi. Yeah, so, I'm Al.

88
00:03:40,200 --> 00:03:43,710
I'm the director of one of our
professional services teams

89
00:03:43,710 --> 00:03:45,633
based in Northern Europe.

90
00:03:47,130 --> 00:03:48,090
I should kind of say actually,

91
00:03:48,090 --> 00:03:49,740
I'm a bit of the B team here today

92
00:03:49,740 --> 00:03:52,230
because the person that
should be sitting here, Rob,

93
00:03:52,230 --> 00:03:55,050
who's in my team, who's
really the clever guy,

94
00:03:55,050 --> 00:03:56,460
I'm not the clever guy,

95
00:03:56,460 --> 00:03:59,250
he's been working on
this project with Alicia,

96
00:03:59,250 --> 00:04:02,100
in fact, he's been working
with Alicia and her team now

97
00:04:02,100 --> 00:04:05,820
for a couple of years, or
at least well over a year,

98
00:04:05,820 --> 00:04:07,620
a year and a half, I think actually.

99
00:04:08,730 --> 00:04:10,860
He was due to be here to
talk about the solution

100
00:04:10,860 --> 00:04:12,630
that he's kind of designed and built.

101
00:04:12,630 --> 00:04:15,630
But unfortunately, a few days ago,

102
00:04:15,630 --> 00:04:18,450
his son was born somewhat prematurely

103
00:04:18,450 --> 00:04:21,540
and somewhat surprisingly, only 27 weeks,

104
00:04:21,540 --> 00:04:23,280
but he's doing well.

105
00:04:23,280 --> 00:04:25,140
So I had to drop in in his place.

106
00:04:25,140 --> 00:04:27,840
So yeah, but it's great to be here.

107
00:04:27,840 --> 00:04:31,060
And, you know, I've worked with
Alicia and her teams as well

108
00:04:32,220 --> 00:04:33,420
for a good year or so now,

109
00:04:33,420 --> 00:04:35,070
and it's a real pleasure
to work with them.

110
00:04:35,070 --> 00:04:39,220
And we've had a great
relationship with Mercy Corps now

111
00:04:40,080 --> 00:04:41,373
for quite some time,

112
00:04:42,240 --> 00:04:44,670
which I think is quite a good
fit, really, Alicia, isn't it?

113
00:04:44,670 --> 00:04:47,580
Because, I mean, Alicia
here has got some amazing,

114
00:04:47,580 --> 00:04:50,530
innovative ideas, really
stretching the boundaries

115
00:04:52,270 --> 00:04:56,220
of what humanitarian
organizations can do with AI.

116
00:04:56,220 --> 00:04:57,330
And obviously, at Cloudera,

117
00:04:57,330 --> 00:04:59,760
we are sort of innovating
in that space as well.

118
00:04:59,760 --> 00:05:02,310
And I think, you know, we sort of...

119
00:05:02,310 --> 00:05:04,050
We kinda hit it off pretty well

120
00:05:04,050 --> 00:05:06,720
and it's been an enjoyable partnership.

121
00:05:06,720 --> 00:05:08,862
So it's been great to be part of that.

122
00:05:08,862 --> 00:05:11,970
- Why don't you take us through
the history of the project?

123
00:05:11,970 --> 00:05:15,453
- Yeah, so back in July '24,

124
00:05:16,350 --> 00:05:18,600
there was a tech to the
rescue and organization

125
00:05:18,600 --> 00:05:21,720
that kind of did a sort of
speed dating type process

126
00:05:21,720 --> 00:05:25,260
to match up tech companies

127
00:05:25,260 --> 00:05:28,350
with organizations like Mercy Corps.

128
00:05:28,350 --> 00:05:29,640
And as Rob would always say,

129
00:05:29,640 --> 00:05:31,530
he said, "We had a few okay dates,

130
00:05:31,530 --> 00:05:36,530
but then we had a really
good one with Mercy Corps."

131
00:05:37,500 --> 00:05:40,260
And so, this time last year,

132
00:05:40,260 --> 00:05:44,520
Rob and Alicia were here
talking about a GenAI solution,

133
00:05:44,520 --> 00:05:48,750
which also used RAG to kinda help

134
00:05:48,750 --> 00:05:50,580
do general Mercy Corps internal people

135
00:05:50,580 --> 00:05:52,110
to sort of do general research

136
00:05:52,110 --> 00:05:56,430
on using natural language interfaces,

137
00:05:56,430 --> 00:06:00,060
so sort of classic GenAI-type project.

138
00:06:00,060 --> 00:06:02,557
And then Alicia sort of started thinking,

139
00:06:02,557 --> 00:06:03,600
"Okay, what's next?"

140
00:06:03,600 --> 00:06:06,030
And obviously, I think like many people,

141
00:06:06,030 --> 00:06:08,820
sort of, there was the GenAI phase

142
00:06:08,820 --> 00:06:11,760
and people are now moving
on to the agentic AI phase.

143
00:06:11,760 --> 00:06:13,110
So Alicia came to us

144
00:06:13,110 --> 00:06:16,050
with a series of kind
of problem statements.

145
00:06:16,050 --> 00:06:18,780
I think there were about 250
words each, weren't there?

146
00:06:18,780 --> 00:06:20,850
I think you had about four or five ideas.

147
00:06:20,850 --> 00:06:22,110
Like, these are things that we reckon

148
00:06:22,110 --> 00:06:24,333
might be a good fit for agentic AI.

149
00:06:25,260 --> 00:06:26,280
And one of them stood out,

150
00:06:26,280 --> 00:06:29,610
which was the story that
we're gonna talk about today

151
00:06:29,610 --> 00:06:32,580
around Crisis Analysis.

152
00:06:32,580 --> 00:06:34,050
Now, in parallel to that,

153
00:06:34,050 --> 00:06:37,410
I run an initiative with
the London Business School

154
00:06:37,410 --> 00:06:39,030
and some of their masters

155
00:06:39,030 --> 00:06:42,180
in international management students.

156
00:06:42,180 --> 00:06:45,270
So they come and do a
project with us every year,

157
00:06:45,270 --> 00:06:46,620
and it's great 'cause you get

158
00:06:46,620 --> 00:06:50,640
two teams of six very, very
smart, intelligent people

159
00:06:50,640 --> 00:06:52,920
who've got 13 weeks to
do some work for you.

160
00:06:52,920 --> 00:06:54,937
And so I went to Alicia and said,

161
00:06:54,937 --> 00:06:57,330
"How do you fancy having
two teams of smart students

162
00:06:57,330 --> 00:06:58,170
doing some work for you?"

163
00:06:58,170 --> 00:07:00,330
She was like, "Bring it on." (chuckles)

164
00:07:00,330 --> 00:07:03,314
So we asked them to look at two things,

165
00:07:03,314 --> 00:07:05,100
and we'll talk about these in a bit more

166
00:07:05,100 --> 00:07:06,360
as we go through the deck.

167
00:07:06,360 --> 00:07:08,350
But we asked one team to look at

168
00:07:09,810 --> 00:07:12,900
to take Alicia's 250-word product,

169
00:07:12,900 --> 00:07:14,400
sort of problem statement,

170
00:07:14,400 --> 00:07:17,253
and turn it into a series of user stories.

171
00:07:18,390 --> 00:07:21,360
So they sat down with
the Crisis Analysis teams

172
00:07:21,360 --> 00:07:23,130
and tried to understand a bit more

173
00:07:23,130 --> 00:07:25,740
about how those teams work.

174
00:07:25,740 --> 00:07:27,187
And then we also thought,

175
00:07:27,187 --> 00:07:29,520
"Well, if Mercy Corps
was doing this kind of

176
00:07:29,520 --> 00:07:30,600
for real as it were,

177
00:07:30,600 --> 00:07:33,180
without the support of AWS and Cloudera,

178
00:07:33,180 --> 00:07:36,403
what would the business case
look like, you know, to..."

179
00:07:38,923 --> 00:07:41,850
'Cause the process, the
solution that we're providing,

180
00:07:41,850 --> 00:07:43,080
saves a lot of time.

181
00:07:43,080 --> 00:07:44,610
So let's monetize that.

182
00:07:44,610 --> 00:07:46,590
Let's make sure we really
understand the business case

183
00:07:46,590 --> 00:07:48,270
behind this solution.

184
00:07:48,270 --> 00:07:49,440
So they did a great job

185
00:07:49,440 --> 00:07:51,510
and you can see there,

186
00:07:51,510 --> 00:07:53,430
you know, they presented
all of that to us.

187
00:07:53,430 --> 00:07:55,500
One thing I'll say, if you get to my age,

188
00:07:55,500 --> 00:08:00,330
don't ever have your photograph
taken with 12 really young,

189
00:08:00,330 --> 00:08:02,880
bright, intelligent,
young master students.

190
00:08:02,880 --> 00:08:04,680
'Cause if you really wanna
make yourself feel depressed,

191
00:08:04,680 --> 00:08:06,600
that's the way to do it, trust me.

192
00:08:06,600 --> 00:08:08,070
But it was a great piece of work,

193
00:08:08,070 --> 00:08:09,900
and I think you got a
lot of value from that.

194
00:08:09,900 --> 00:08:11,130
And then of course, out the back of that,

195
00:08:11,130 --> 00:08:14,130
we had the user stories for the solution

196
00:08:14,130 --> 00:08:15,130
that we're building,

197
00:08:17,340 --> 00:08:20,640
and we're here today now to
talk about it to you guys.

198
00:08:20,640 --> 00:08:22,470
- So you've mentioned this use case

199
00:08:22,470 --> 00:08:23,760
and why you thought it would be ideal.

200
00:08:23,760 --> 00:08:25,650
Tell us about the use case.

201
00:08:25,650 --> 00:08:29,130
- Yeah, so Crisis
Analysis as we mentioned,

202
00:08:29,130 --> 00:08:31,350
you know, develops a number of products.

203
00:08:31,350 --> 00:08:34,230
And those products can
be on a monthly basis,

204
00:08:34,230 --> 00:08:35,640
they can be on a quarterly basis,

205
00:08:35,640 --> 00:08:37,200
they can be a page long,

206
00:08:37,200 --> 00:08:40,530
they can be many, many pages long.

207
00:08:40,530 --> 00:08:43,290
But by and large what takes time,

208
00:08:43,290 --> 00:08:47,550
is developing the information
base for those reports, right?

209
00:08:47,550 --> 00:08:50,640
And I think we surveyed
six different countries,

210
00:08:50,640 --> 00:08:52,110
six different Crisis Analysis teams

211
00:08:52,110 --> 00:08:53,310
across six different countries,

212
00:08:53,310 --> 00:08:57,750
and it was something like 790 hours

213
00:08:57,750 --> 00:09:00,573
are spent each month on research alone.

214
00:09:01,500 --> 00:09:04,470
And so, the objective
was really kind of like

215
00:09:04,470 --> 00:09:05,640
to come from this position of,

216
00:09:05,640 --> 00:09:10,640
can we reduce that amount of
time spent on research alone?

217
00:09:10,860 --> 00:09:13,440
And I think London Business
School was pretty ambitious,

218
00:09:13,440 --> 00:09:16,080
and said, "Can we reduce it by 50%?",

219
00:09:16,080 --> 00:09:19,710
and what would that look like
if we were able to do that?

220
00:09:19,710 --> 00:09:23,280
So it's really kind of that acceleration,

221
00:09:23,280 --> 00:09:26,250
you know, the humanitarian sector

222
00:09:26,250 --> 00:09:29,883
has undergone drastic
financial transition this year,

223
00:09:30,900 --> 00:09:34,440
and Mercy Corps has been
pretty heavily impacted

224
00:09:34,440 --> 00:09:35,990
by that transition.
- Yeah.

225
00:09:35,990 --> 00:09:38,910
- So the question isn't
how we do more with less,

226
00:09:38,910 --> 00:09:41,760
but if we're not going to have funding,

227
00:09:41,760 --> 00:09:44,340
what can we do with the
people that we have?

228
00:09:44,340 --> 00:09:46,863
How can we best leverage their talents?

229
00:09:47,850 --> 00:09:50,760
A lot of times, as funding gets cut,

230
00:09:50,760 --> 00:09:53,313
analysis is the first
thing that goes, right?

231
00:09:54,180 --> 00:09:56,220
And so, now you end up with data silos,

232
00:09:56,220 --> 00:09:59,340
you're making decisions

233
00:09:59,340 --> 00:10:02,880
with very little information in places,

234
00:10:02,880 --> 00:10:05,330
where again, like information
is really critical.

235
00:10:06,210 --> 00:10:07,860
And so, the question is really,

236
00:10:07,860 --> 00:10:09,600
how do we maintain,

237
00:10:09,600 --> 00:10:12,360
if we're not getting any
new funding, moving forward?

238
00:10:12,360 --> 00:10:14,370
And that was really kind of like the basis

239
00:10:14,370 --> 00:10:16,170
for our user stories.

240
00:10:16,170 --> 00:10:17,370
- Yeah, we're talking about this earlier.

241
00:10:17,370 --> 00:10:21,330
I was struck by the timing, right?

242
00:10:21,330 --> 00:10:23,460
I mean, we started talking two years ago

243
00:10:23,460 --> 00:10:24,720
and started working a year ago,

244
00:10:24,720 --> 00:10:26,370
and we're demoing it tomorrow,

245
00:10:26,370 --> 00:10:27,900
and now, suddenly,

246
00:10:27,900 --> 00:10:30,300
it's essential just to keep doing the job.

247
00:10:30,300 --> 00:10:31,920
- Yeah, for sure.

248
00:10:31,920 --> 00:10:34,800
I think it's one of these things where

249
00:10:34,800 --> 00:10:37,350
you can't be behind the
power curve right now with AI

250
00:10:37,350 --> 00:10:38,812
because there's so much promise-

251
00:10:38,812 --> 00:10:39,810
- Right.
- you know.

252
00:10:39,810 --> 00:10:42,030
And again, kind of thinking
about the benefit we got

253
00:10:42,030 --> 00:10:45,450
out of that LBS study that the
London Business School work,

254
00:10:45,450 --> 00:10:48,360
is ultimately, what that enabled us to do,

255
00:10:48,360 --> 00:10:51,030
is really run those different
financial scenarios, right?

256
00:10:51,030 --> 00:10:53,580
And so, I work for the
chief financial officer.

257
00:10:53,580 --> 00:10:54,450
It's really important to know

258
00:10:54,450 --> 00:10:55,770
what we're spending our money on

259
00:10:55,770 --> 00:10:57,900
and how that's going to ultimately,

260
00:10:57,900 --> 00:11:00,270
sort of, save us dollars in the long run

261
00:11:00,270 --> 00:11:02,250
because there's not a lot to go around.

262
00:11:02,250 --> 00:11:03,750
- Cool.

263
00:11:03,750 --> 00:11:05,790
All right. Cool in this way.

264
00:11:05,790 --> 00:11:10,790
- Yeah, and obviously, so
when we took the use case,

265
00:11:12,390 --> 00:11:15,360
we started to think about how
this was gonna be developed

266
00:11:15,360 --> 00:11:17,103
as a technical solution.

267
00:11:18,960 --> 00:11:23,130
You heard earlier that Alicia
talked about different themes.

268
00:11:23,130 --> 00:11:26,280
So the analysts work very much,

269
00:11:26,280 --> 00:11:29,220
you know, looking at all
these different themes.

270
00:11:29,220 --> 00:11:32,280
So the agentic bit was really around,

271
00:11:32,280 --> 00:11:36,450
let's make the agents behind
the solution domain experts

272
00:11:38,640 --> 00:11:39,473
in each of their themes.

273
00:11:39,473 --> 00:11:41,640
And there's different
themes, aren't there?

274
00:11:41,640 --> 00:11:43,380
So I think there's humanitarian themes,

275
00:11:43,380 --> 00:11:45,810
which I think are things
like sort of water security,

276
00:11:45,810 --> 00:11:47,670
food security, so things that,

277
00:11:47,670 --> 00:11:49,113
you know, obviously affect,

278
00:11:50,460 --> 00:11:53,580
you know, people's humanitarian situation.

279
00:11:53,580 --> 00:11:55,860
And then there's what they
call contextual themes,

280
00:11:55,860 --> 00:11:59,223
which are things like conflict
and the political situation.

281
00:12:00,420 --> 00:12:02,910
And I think you were
saying earlier, Alicia,

282
00:12:02,910 --> 00:12:05,760
that when the agents have been using

283
00:12:05,760 --> 00:12:07,350
sort of things like ChatGPT,

284
00:12:07,350 --> 00:12:10,083
the analysts have been
using things like ChatGPT,

285
00:12:12,300 --> 00:12:13,740
they don't really get the results back

286
00:12:13,740 --> 00:12:15,570
that they're looking for.

287
00:12:15,570 --> 00:12:19,230
So the idea of using the
agentic solution was,

288
00:12:19,230 --> 00:12:21,810
you know, we can make each
of the agentic workflows

289
00:12:21,810 --> 00:12:22,800
a domain expert.

290
00:12:22,800 --> 00:12:27,630
So one agentic workflow will
be an expert in food security,

291
00:12:27,630 --> 00:12:30,030
and it will prioritize data sources

292
00:12:30,030 --> 00:12:32,580
related to food security
over its kind of...

293
00:12:32,580 --> 00:12:34,380
The LLM won't be going

294
00:12:34,380 --> 00:12:36,300
to its kind of core knowledge base first.

295
00:12:36,300 --> 00:12:39,630
It'll be going to a much more
specialized knowledge base.

296
00:12:39,630 --> 00:12:41,100
And obviously, over time,

297
00:12:41,100 --> 00:12:43,440
we can build up the expertise

298
00:12:43,440 --> 00:12:45,060
in each of those agentic workflows

299
00:12:45,060 --> 00:12:47,160
so they can get better and better

300
00:12:47,160 --> 00:12:50,280
based on what we learn as
we go through the process.

301
00:12:50,280 --> 00:12:52,770
So it all sits just on
a kind of platform level

302
00:12:52,770 --> 00:12:56,463
within Cloudera's AI solution.

303
00:12:59,598 --> 00:13:02,733
And it reach, sort of,
running on AWS obviously,

304
00:13:03,750 --> 00:13:06,300
on our past platform in the cloud.

305
00:13:06,300 --> 00:13:09,780
And it we will reach out to Bedrock,

306
00:13:09,780 --> 00:13:12,080
to use the Bedrock
capabilities there as well.

307
00:13:13,290 --> 00:13:14,430
So, yeah, but it's...

308
00:13:14,430 --> 00:13:18,030
I mentioned our Agent Studio offering.

309
00:13:18,030 --> 00:13:19,140
Leo, you are our CPO,

310
00:13:19,140 --> 00:13:22,260
you're probably better placed
to talk about it than I am.

311
00:13:22,260 --> 00:13:23,093
- I've heard of it.

312
00:13:23,093 --> 00:13:26,733
So, everybody understands
the context, right?

313
00:13:27,967 --> 00:13:30,240
"Suddenly," and I put that in quotes

314
00:13:30,240 --> 00:13:33,120
because it was really
just, you know, hyperbolic.

315
00:13:33,120 --> 00:13:34,350
You know the story of lily pads?

316
00:13:34,350 --> 00:13:35,700
Let me tell you that one real quick.

317
00:13:35,700 --> 00:13:39,240
Imagine you live on a giant
pond in a little house,

318
00:13:39,240 --> 00:13:40,650
and across the pond somewhere,

319
00:13:40,650 --> 00:13:42,420
you can't even see there's a lily pad,

320
00:13:42,420 --> 00:13:44,580
and overnight, the lily
pad doubles to two.

321
00:13:44,580 --> 00:13:46,380
The next night it doubles to four.

322
00:13:46,380 --> 00:13:47,850
It goes on and on and on like this.

323
00:13:47,850 --> 00:13:50,250
And in 100 days, the lake is full.

324
00:13:50,250 --> 00:13:55,060
But you don't see that it's
filling until day 98 or day 99.

325
00:13:55,060 --> 00:13:56,040
Okay?

326
00:13:56,040 --> 00:13:58,590
That's how hyperbolic works, right?

327
00:13:58,590 --> 00:13:59,850
It springs out on you.

328
00:13:59,850 --> 00:14:02,370
That's what happened a
few years ago with this,

329
00:14:02,370 --> 00:14:07,020
when OpenAI released that
first, you know, GenAI model.

330
00:14:07,020 --> 00:14:09,600
They said, "You know, look,
it's not ready. It has bias.

331
00:14:09,600 --> 00:14:11,250
It hallucinates. Ah heck!",

332
00:14:11,250 --> 00:14:12,330
and they released it.

333
00:14:12,330 --> 00:14:13,687
And then eight other companies were like,

334
00:14:13,687 --> 00:14:15,630
"Oh, we have one too. Let's go."

335
00:14:15,630 --> 00:14:18,270
So we all reacted to it very quickly.

336
00:14:18,270 --> 00:14:20,497
The first thing that
everybody did was say,

337
00:14:20,497 --> 00:14:23,700
"Look, you know, put AI in our name,

338
00:14:23,700 --> 00:14:25,470
put AI in the name of our product,

339
00:14:25,470 --> 00:14:27,390
put a chatbot using an LLM

340
00:14:27,390 --> 00:14:29,580
in whatever product that you have, (claps)

341
00:14:29,580 --> 00:14:32,190
we're all AI enabled now, okay?

342
00:14:32,190 --> 00:14:34,110
And then we started
getting good at it, right?

343
00:14:34,110 --> 00:14:36,000
It says, "It's not about just the LLM.

344
00:14:36,000 --> 00:14:38,767
It's about retrieval
augment generation." So RAG.

345
00:14:38,767 --> 00:14:40,890
"Everyone's gonna do RAG.
Let's release RAG studios."

346
00:14:40,890 --> 00:14:42,450
So everybody did that.

347
00:14:42,450 --> 00:14:44,370
And then we said, "Okay,
it's still not good enough.

348
00:14:44,370 --> 00:14:45,450
Everyone's gonna need agents."

349
00:14:45,450 --> 00:14:47,193
So everyone goes and does that.

350
00:14:48,300 --> 00:14:52,800
And in the context of all that going on,

351
00:14:52,800 --> 00:14:54,810
the business users were in the same place.

352
00:14:54,810 --> 00:14:56,910
They were like, "Nobody cares anymore

353
00:14:56,910 --> 00:14:57,780
that we're in year seven

354
00:14:57,780 --> 00:14:59,730
of our three-year journey to the cloud.

355
00:15:00,810 --> 00:15:02,670
We gotta go with what we have now,

356
00:15:02,670 --> 00:15:04,470
so let's make this thing happen."

357
00:15:04,470 --> 00:15:06,030
It's in the context of all that,

358
00:15:06,030 --> 00:15:09,243
that Cloudera has been
building its AI solution.

359
00:15:10,170 --> 00:15:12,480
We did an acquihire, year before last,

360
00:15:12,480 --> 00:15:14,580
while this was going on,
of a company called Verta,

361
00:15:14,580 --> 00:15:19,580
and brought in some significant
expertise in the space.

362
00:15:20,400 --> 00:15:23,370
And they've helped lead us
to a place where, frankly,

363
00:15:23,370 --> 00:15:25,530
we think we have the
best solution out there

364
00:15:25,530 --> 00:15:27,660
for high code,

365
00:15:27,660 --> 00:15:30,060
Jupyter Notebook connected
directly into the system

366
00:15:30,060 --> 00:15:30,990
to do this stuff,

367
00:15:30,990 --> 00:15:32,790
those guys don't want your agents,

368
00:15:32,790 --> 00:15:34,170
they don't want your anything,

369
00:15:34,170 --> 00:15:36,360
'cause theirs is gonna
be better than yours,

370
00:15:36,360 --> 00:15:38,160
all the way to no code.

371
00:15:38,160 --> 00:15:39,690
So, you know, drag and drop

372
00:15:39,690 --> 00:15:42,210
and plain language and et cetera.

373
00:15:42,210 --> 00:15:44,670
And, you know, this set
of studios, frankly,

374
00:15:44,670 --> 00:15:48,600
is right at the leading edge
of the things that can be done,

375
00:15:48,600 --> 00:15:50,760
productized, out in the marketplace.

376
00:15:50,760 --> 00:15:53,850
So that's what you guys were looking at.

377
00:15:53,850 --> 00:15:54,683
- Cool.

378
00:15:54,683 --> 00:15:55,830
And I think that the no-code bits

379
00:15:55,830 --> 00:15:57,480
quite important for you, isn't it, Alicia,

380
00:15:57,480 --> 00:15:59,730
because you're, you know, again,

381
00:15:59,730 --> 00:16:01,920
talking about how limited resources.

382
00:16:01,920 --> 00:16:03,060
- Yeah, I mean...

383
00:16:03,060 --> 00:16:06,210
And in particular, sort of
technical resources, right?

384
00:16:06,210 --> 00:16:08,580
Like our business is humanitarian aid,

385
00:16:08,580 --> 00:16:12,240
so there's not a lot of
resources for IT or technology,

386
00:16:12,240 --> 00:16:13,920
what we would call
technology for development,

387
00:16:13,920 --> 00:16:17,370
which is more focused on our
humanitarian programming.

388
00:16:17,370 --> 00:16:21,030
So our T4D team is two people. (chuckles)

389
00:16:21,030 --> 00:16:24,940
So our ability to kind of
both build and manage systems

390
00:16:25,860 --> 00:16:28,500
is pretty limited.

391
00:16:28,500 --> 00:16:32,760
So the ability to go and use
sort of a low-code solution,

392
00:16:32,760 --> 00:16:35,370
even if we don't like necessarily have to,

393
00:16:35,370 --> 00:16:38,220
even if we have the skillset
to use a high-code solution,

394
00:16:38,220 --> 00:16:39,600
it does save time.

395
00:16:39,600 --> 00:16:43,980
It does help us retain
some of our human resources

396
00:16:43,980 --> 00:16:47,220
for other things like onboarding
people into the system,

397
00:16:47,220 --> 00:16:51,300
building up, you know, the
usage of the system itself

398
00:16:51,300 --> 00:16:53,760
and the adoption of the system
itself out in the field,

399
00:16:53,760 --> 00:16:55,380
which is arguably,

400
00:16:55,380 --> 00:16:57,720
kind of the more important
role that we play.

401
00:16:57,720 --> 00:16:59,130
- Right.
- And so I think

402
00:16:59,130 --> 00:17:01,500
that sort of diversity
of the Cloudera solution

403
00:17:01,500 --> 00:17:03,630
has been really beneficial to us where,

404
00:17:03,630 --> 00:17:06,780
ultimately, we can choose to
go to your high-code solution

405
00:17:06,780 --> 00:17:08,520
if we decide we need to,

406
00:17:08,520 --> 00:17:10,800
but for the moment, you know,

407
00:17:10,800 --> 00:17:12,780
we're doing what we can
with the drag and drop

408
00:17:12,780 --> 00:17:15,090
because that's all we
really have time for.

409
00:17:15,090 --> 00:17:16,170
- That's right.
- Yeah.

410
00:17:16,170 --> 00:17:19,020
- [Leo] You know, do you
wanna show the solution?

411
00:17:19,020 --> 00:17:19,853
Do we have the...

412
00:17:19,853 --> 00:17:20,691
Yeah, there it is.

413
00:17:22,380 --> 00:17:23,213
- [Alastair] Yeah, and I think...

414
00:17:23,213 --> 00:17:25,140
I mean, one of the things I noticed,

415
00:17:25,140 --> 00:17:26,130
'cause I mentioned at the start

416
00:17:26,130 --> 00:17:28,833
that Rob had to stop work quite suddenly.

417
00:17:29,850 --> 00:17:34,470
So we had to hand over
the work that he was doing

418
00:17:34,470 --> 00:17:37,530
to somebody else in my team,
professional services team.

419
00:17:37,530 --> 00:17:38,970
My team were mostly busy.

420
00:17:38,970 --> 00:17:40,170
I have one guy in the team,

421
00:17:40,170 --> 00:17:42,060
he'd never worked with
Agent Studio before,

422
00:17:42,060 --> 00:17:44,790
just 'cause he works on
other parts of our stack,

423
00:17:44,790 --> 00:17:45,623
but he was available.

424
00:17:45,623 --> 00:17:46,920
But it was great because he was able

425
00:17:46,920 --> 00:17:49,200
to pick up the work that Rob did

426
00:17:49,200 --> 00:17:50,940
and get it deployed in Agent Studio.

427
00:17:50,940 --> 00:17:52,770
He had to build a couple more MCP servers

428
00:17:52,770 --> 00:17:53,966
and get them deployed.

429
00:17:53,966 --> 00:17:55,470
I mean, he's a smart guy

430
00:17:55,470 --> 00:17:57,930
'cause he's professional services guy,

431
00:17:57,930 --> 00:18:00,000
but even so, he was able
to sort of pick it up

432
00:18:00,000 --> 00:18:01,530
in a couple of days and, you know,

433
00:18:01,530 --> 00:18:02,760
the interface makes that easy.

434
00:18:02,760 --> 00:18:05,670
So our hope is that when
we've kind of completed

435
00:18:05,670 --> 00:18:08,730
the first phase of the project,

436
00:18:08,730 --> 00:18:11,250
we can hand over the solution
to Alicia and her team

437
00:18:11,250 --> 00:18:13,650
and they will easily be able
to pick up and run with it

438
00:18:13,650 --> 00:18:15,000
and develop it further.

439
00:18:15,000 --> 00:18:17,490
- And one of the things that Cloudera did

440
00:18:17,490 --> 00:18:19,170
was connect all the products that we have.

441
00:18:19,170 --> 00:18:21,840
So we have a whole lot
of products for ingestion

442
00:18:21,840 --> 00:18:23,430
and for storage and for et cetera.

443
00:18:23,430 --> 00:18:24,930
Whether it's our data engineering stuff

444
00:18:24,930 --> 00:18:26,940
or our data warehousing stuff,

445
00:18:26,940 --> 00:18:30,630
our flow stuff using, you
know, all of our streaming,

446
00:18:30,630 --> 00:18:34,020
we set all those up as agents
inside the Agent Studio.

447
00:18:34,020 --> 00:18:37,200
So you're starting off with
a whole set of capabilities

448
00:18:37,200 --> 00:18:38,910
as you continue to build agents

449
00:18:38,910 --> 00:18:42,120
to create some pretty elegant
solutions very quickly.

450
00:18:42,120 --> 00:18:43,440
- Yeah, no, it's been pretty quick

451
00:18:43,440 --> 00:18:45,600
to get those agents built.

452
00:18:45,600 --> 00:18:48,450
As I said, we kind of
mentioned it already,

453
00:18:48,450 --> 00:18:52,758
but, you know, the beauty of
using the agentic workflows

454
00:18:52,758 --> 00:18:55,470
is that for each of the...
and we'll see it in a minute,

455
00:18:55,470 --> 00:18:57,480
we'll talk a little bit about
the front end a bit more,

456
00:18:57,480 --> 00:19:02,480
but you'll see that the
information that the AI produces

457
00:19:04,050 --> 00:19:05,790
comes back kind of categorized

458
00:19:05,790 --> 00:19:08,490
into these different themes
that we talked about,

459
00:19:08,490 --> 00:19:11,460
and each of those themes and these cards

460
00:19:11,460 --> 00:19:15,270
that you'll see on the
next slide are driven by,

461
00:19:15,270 --> 00:19:16,830
you know, an agentic workflow.

462
00:19:16,830 --> 00:19:19,650
So we've got, as I say, by
the end of the solution,

463
00:19:19,650 --> 00:19:21,120
we'll have a whole bunch of agents-

464
00:19:21,120 --> 00:19:22,170
- So-
- all running.

465
00:19:23,169 --> 00:19:25,050
- you know, I talk about technology a lot,

466
00:19:25,050 --> 00:19:28,380
but when I was talking with
Alicia about what she's facing

467
00:19:28,380 --> 00:19:29,820
and I'm thinking, "Oh, here's a solution,

468
00:19:29,820 --> 00:19:31,290
here's a solution, here's a solution."

469
00:19:31,290 --> 00:19:33,030
Like, all we're talking with about

470
00:19:33,030 --> 00:19:34,830
was how you get people to use it.

471
00:19:34,830 --> 00:19:36,992
I mean, you're talking
about how many countries?

472
00:19:36,992 --> 00:19:38,016
- 35 plus.

473
00:19:38,016 --> 00:19:39,185
- And how many language?s

474
00:19:39,185 --> 00:19:40,760
- A lot. (chuckles)
- Yeah, a lot.

475
00:19:40,760 --> 00:19:42,000
So just the concept

476
00:19:42,000 --> 00:19:44,160
of getting people to
understand what it is,

477
00:19:44,160 --> 00:19:46,860
trust it, be able to use it,

478
00:19:46,860 --> 00:19:48,480
that was not something that,

479
00:19:48,480 --> 00:19:50,240
honestly, I spend as
much time thinking about,

480
00:19:50,240 --> 00:19:51,900
so that was very enlightening to me.

481
00:19:51,900 --> 00:19:54,960
- [Alicia] Yeah, so adoption is really

482
00:19:54,960 --> 00:19:57,780
sort of the key to
success in any technology,

483
00:19:57,780 --> 00:20:00,150
product, or project, right?

484
00:20:00,150 --> 00:20:01,950
And so, for us at Mercy Corps,

485
00:20:01,950 --> 00:20:05,520
our objective is really to
create some of these tools

486
00:20:05,520 --> 00:20:07,800
that people will actually
be putting to use.

487
00:20:07,800 --> 00:20:11,250
If you create something that
then sits there with no users,

488
00:20:11,250 --> 00:20:13,200
then you're not realizing the ROI

489
00:20:13,200 --> 00:20:14,670
that London Business School

490
00:20:14,670 --> 00:20:16,770
so kindly calculated for us, right?

491
00:20:16,770 --> 00:20:18,060
And there's really no point to it.

492
00:20:18,060 --> 00:20:18,893
It's not saving you money,

493
00:20:18,893 --> 00:20:21,510
it's just costing you
money in the long run.

494
00:20:21,510 --> 00:20:22,710
In the short one, really.

495
00:20:22,710 --> 00:20:26,190
And so, really, it's about how
do we engage with our users

496
00:20:26,190 --> 00:20:28,470
to determine what their workflows are

497
00:20:28,470 --> 00:20:31,230
so that the platform
fits into that workflow.

498
00:20:31,230 --> 00:20:34,440
And they're very clear about
what they want from it.

499
00:20:34,440 --> 00:20:37,200
Sometimes it doesn't
always translate directly

500
00:20:37,200 --> 00:20:39,210
to technical capability,

501
00:20:39,210 --> 00:20:42,390
or they don't express it until
they see it on the screen

502
00:20:42,390 --> 00:20:45,960
and they realize that's not
actually what my workflow is.

503
00:20:45,960 --> 00:20:47,430
But they have very clear ideas

504
00:20:47,430 --> 00:20:50,220
about what they want out of a platform.

505
00:20:50,220 --> 00:20:53,040
Al mentioned, you know, we
have had analysts try to use

506
00:20:53,040 --> 00:20:56,070
sort of publicly available
LLM-type platforms,

507
00:20:56,070 --> 00:20:57,780
and they have a lot of opinions, right?

508
00:20:57,780 --> 00:20:59,310
And one of those opinions is that

509
00:20:59,310 --> 00:21:03,090
the data that gets surfaced
is often whatever's sponsored

510
00:21:03,090 --> 00:21:06,450
by corporate sponsor
underneath the hood, right?

511
00:21:06,450 --> 00:21:08,520
It's the same if you
go to a search engine,

512
00:21:08,520 --> 00:21:09,960
you know, usually, it's whoever's paying

513
00:21:09,960 --> 00:21:12,420
for those top line resources,

514
00:21:12,420 --> 00:21:15,300
that's what comes to
the top of your search.

515
00:21:15,300 --> 00:21:17,670
Or it can be based on frequency.

516
00:21:17,670 --> 00:21:20,100
What are the resources people
are going to most often

517
00:21:20,100 --> 00:21:24,540
that does not make them the
most accurate resources, right?

518
00:21:24,540 --> 00:21:25,890
And so very often,

519
00:21:25,890 --> 00:21:28,440
what's surfaced through those public tools

520
00:21:28,440 --> 00:21:29,940
is not what analysts wanna see.

521
00:21:29,940 --> 00:21:31,710
And they're very clear about

522
00:21:31,710 --> 00:21:34,950
wanting to be able to plug
their own resources in,

523
00:21:34,950 --> 00:21:36,570
to look across those resources,

524
00:21:36,570 --> 00:21:39,000
for those resources to
be organized thematically

525
00:21:39,000 --> 00:21:41,100
to support their report writing process.

526
00:21:41,100 --> 00:21:43,650
But they're also very clear
they want kind of like

527
00:21:43,650 --> 00:21:45,240
to stop at a certain point

528
00:21:45,240 --> 00:21:48,720
because this is not designed
to replace analysts.

529
00:21:48,720 --> 00:21:52,440
You can't replace the sort of
nuanced contextual information

530
00:21:52,440 --> 00:21:53,940
that somebody who's living and breathing

531
00:21:53,940 --> 00:21:57,990
the humanitarian world has, right?

532
00:21:57,990 --> 00:21:59,970
When you're sitting in that country

533
00:21:59,970 --> 00:22:01,740
and you're doing key informant interviews

534
00:22:01,740 --> 00:22:04,020
and you're combining all
this information together,

535
00:22:04,020 --> 00:22:05,850
that's when real insights happen.

536
00:22:05,850 --> 00:22:09,900
And that platform is probably
never gonna get to that point.

537
00:22:09,900 --> 00:22:11,460
So we wanna be clear

538
00:22:11,460 --> 00:22:13,500
on what the platform can do and can't do,

539
00:22:13,500 --> 00:22:16,550
and we want the workflows to support that.

540
00:22:16,550 --> 00:22:19,590
And all of that has to
be really hashed out

541
00:22:19,590 --> 00:22:21,363
in an iterative process.

542
00:22:22,320 --> 00:22:24,090
We have to tell Rob to do one thing

543
00:22:24,090 --> 00:22:26,760
and then probably tell him
to undo it the next week

544
00:22:26,760 --> 00:22:29,430
because you've gotta kind of
like work through these things.

545
00:22:29,430 --> 00:22:31,080
But if it doesn't support that workflow,

546
00:22:31,080 --> 00:22:33,480
then there's no actual
confidence in the platform.

547
00:22:33,480 --> 00:22:34,620
And so, really,

548
00:22:34,620 --> 00:22:37,890
I think like we've worked
really closely with Al and Rob

549
00:22:37,890 --> 00:22:40,740
to get that workflow sort of in a way,

550
00:22:40,740 --> 00:22:43,620
that adoption is going to happen naturally

551
00:22:43,620 --> 00:22:45,930
because it's a tool the users
have designed themselves.

552
00:22:45,930 --> 00:22:47,070
And that's been a really

553
00:22:47,070 --> 00:22:49,050
important part of our collaboration.

554
00:22:49,050 --> 00:22:51,120
And it's the thing that
we think about the most,

555
00:22:51,120 --> 00:22:52,830
is less about the technical build

556
00:22:52,830 --> 00:22:55,050
and more about the adoption,

557
00:22:55,050 --> 00:22:56,700
how people are gonna trust the platform,

558
00:22:56,700 --> 00:22:58,740
making sure that it
fits into our workflows

559
00:22:58,740 --> 00:23:00,690
so that the sustainment of the platform

560
00:23:00,690 --> 00:23:02,820
makes sense in the long run.

561
00:23:02,820 --> 00:23:03,780
- [Leo] Yeah, I mean,

562
00:23:03,780 --> 00:23:05,613
I was overwhelmed by some of the things

563
00:23:05,613 --> 00:23:06,930
that you were saying.

564
00:23:06,930 --> 00:23:10,800
Simple example, is you
guys have to rely on

565
00:23:10,800 --> 00:23:12,510
what's happening in social media

566
00:23:12,510 --> 00:23:14,250
for a sense of what's
going on in the country,

567
00:23:14,250 --> 00:23:17,190
what's going on in the
ground, latest stuff,

568
00:23:17,190 --> 00:23:19,500
and then you were in
disinformation, right?

569
00:23:19,500 --> 00:23:23,160
So if you've got an LLM out
trying to do that for you,

570
00:23:23,160 --> 00:23:24,450
it's not gonna know the difference.

571
00:23:24,450 --> 00:23:25,410
- [Alicia] Yeah.

572
00:23:25,410 --> 00:23:26,243
- [Leo] So yeah,

573
00:23:26,243 --> 00:23:28,770
I always thought that was
pretty daunting stuff.

574
00:23:28,770 --> 00:23:31,110
And the ability to tell an agent

575
00:23:31,110 --> 00:23:33,060
what sources to trust and et cetera,

576
00:23:33,060 --> 00:23:34,710
I mean, that was interesting.

577
00:23:34,710 --> 00:23:36,930
- Yeah, I mean, this is in particular

578
00:23:36,930 --> 00:23:39,540
Democratic Republic of the Congo.

579
00:23:39,540 --> 00:23:41,550
Unfortunately, there's a lot
of violence against NGOs,

580
00:23:41,550 --> 00:23:44,190
specifically because there's a
lot of rumors on social media

581
00:23:44,190 --> 00:23:45,030
and on the internet.

582
00:23:45,030 --> 00:23:47,280
And so, what our team does there

583
00:23:47,280 --> 00:23:48,570
is looks at both social medias

584
00:23:48,570 --> 00:23:50,250
as well as traditional media sources,

585
00:23:50,250 --> 00:23:51,570
triangulates those things,

586
00:23:51,570 --> 00:23:53,490
and is able to kind of then combat

587
00:23:53,490 --> 00:23:54,570
some of that misinformation,

588
00:23:54,570 --> 00:23:56,190
make it safer for implementation,

589
00:23:56,190 --> 00:23:58,080
and also identify when it's not safe

590
00:23:58,080 --> 00:23:59,883
to do humanitarian implementation.

591
00:24:00,810 --> 00:24:04,020
But that's a lot of sources
to go after at one time.

592
00:24:04,020 --> 00:24:05,670
And collecting that all in one place,

593
00:24:05,670 --> 00:24:07,740
enabling them to scan across,

594
00:24:07,740 --> 00:24:09,690
sort of all of those different resources,

595
00:24:09,690 --> 00:24:12,030
is something that's really
powerful in terms of time saving

596
00:24:12,030 --> 00:24:14,730
and their ability to spend
their time on analysis

597
00:24:14,730 --> 00:24:15,923
versus information gathering.

598
00:24:15,923 --> 00:24:17,730
- Got it. Got it.
- Yeah.

599
00:24:17,730 --> 00:24:19,350
- Nice.
- So, as I was saying,

600
00:24:19,350 --> 00:24:20,836
it's something that I think

601
00:24:20,836 --> 00:24:22,920
we've been learning really
quickly through this process,

602
00:24:22,920 --> 00:24:25,890
is actually getting the right data sources

603
00:24:25,890 --> 00:24:28,110
for each of the different themes,

604
00:24:28,110 --> 00:24:30,450
and then understanding, you know,

605
00:24:30,450 --> 00:24:32,430
the nuances between those data sources

606
00:24:32,430 --> 00:24:34,380
and how that might change and how...

607
00:24:34,380 --> 00:24:36,930
You know, ultimately, we're not there yet,

608
00:24:36,930 --> 00:24:39,900
but a scenario where the analysts

609
00:24:39,900 --> 00:24:42,603
can maybe add more data sources into,

610
00:24:44,040 --> 00:24:46,620
you know, themselves dynamically so that,

611
00:24:46,620 --> 00:24:48,930
you know, if there's new
data sources that comes along

612
00:24:48,930 --> 00:24:51,300
or they hear something
on a social media feed

613
00:24:51,300 --> 00:24:52,860
that they weren't using previously,

614
00:24:52,860 --> 00:24:54,660
they can bring those in as well.

615
00:24:54,660 --> 00:24:56,820
So it's a very dynamic situation,

616
00:24:56,820 --> 00:24:59,823
and trying to understand, as I say,

617
00:25:00,660 --> 00:25:03,000
get the way that the system

618
00:25:03,000 --> 00:25:05,310
brings the data back to the users

619
00:25:05,310 --> 00:25:07,830
in a way that they can
interact and understand.

620
00:25:07,830 --> 00:25:09,720
You know, we don't want it,

621
00:25:09,720 --> 00:25:13,710
for example, to over summarize
some of the stuff because,

622
00:25:13,710 --> 00:25:16,500
you know, they need to see, like you said,

623
00:25:16,500 --> 00:25:19,200
more of the detail so that they can then

624
00:25:19,200 --> 00:25:20,970
actually understand what that means

625
00:25:20,970 --> 00:25:23,550
and triangulate the
various different sources.

626
00:25:23,550 --> 00:25:26,070
So it's gonna be an ongoing journey.

627
00:25:26,070 --> 00:25:26,903
But I think they've engaged

628
00:25:26,903 --> 00:25:28,200
really well with it so far, haven't they?

629
00:25:28,200 --> 00:25:29,906
We've had some good feedback already from-

630
00:25:29,906 --> 00:25:31,460
- [Alicia] (chuckles) Yeah, we have.

631
00:25:31,460 --> 00:25:33,160
Both good and bad. (laughs)

632
00:25:33,160 --> 00:25:35,007
- Yeah.
- We've had a lot of feedback.

633
00:25:35,007 --> 00:25:36,180
- Yeah.
- Good.

634
00:25:36,180 --> 00:25:37,620
- [Alicia] And we'll
get there, eventually.

635
00:25:37,620 --> 00:25:41,040
But yeah, I think it
just emphasizes sort of,

636
00:25:41,040 --> 00:25:44,130
you know, one of flexibility
of the platform on the back end

637
00:25:44,130 --> 00:25:46,470
that we're able to kind
of craft those agents

638
00:25:46,470 --> 00:25:49,980
in a way where they're
pretty easily configurable.

639
00:25:49,980 --> 00:25:54,180
And then also that sort of
user-centered design process

640
00:25:54,180 --> 00:25:55,770
that we've been using, I think.

641
00:25:55,770 --> 00:25:57,960
Those two pieces are really highlighting

642
00:25:57,960 --> 00:26:00,570
how this project is gonna
ultimately be a success.

643
00:26:00,570 --> 00:26:01,403
- [Alastair] Cool.

644
00:26:01,403 --> 00:26:02,310
And essentially, I mean,

645
00:26:02,310 --> 00:26:04,020
the flow's fairly straightforward really

646
00:26:04,020 --> 00:26:05,910
is because the analyst will know

647
00:26:05,910 --> 00:26:07,830
what they want to do initially.

648
00:26:07,830 --> 00:26:09,390
They'll know what
questions they want to ask,

649
00:26:09,390 --> 00:26:12,930
what information they're
after, so they can...

650
00:26:12,930 --> 00:26:15,270
You know, they just need to
select their region first

651
00:26:15,270 --> 00:26:17,640
and then it'll bring back everything

652
00:26:17,640 --> 00:26:19,170
related to all the different themes,

653
00:26:19,170 --> 00:26:20,760
and then they can start to drill down

654
00:26:20,760 --> 00:26:22,740
into the area that they're interested in.

655
00:26:22,740 --> 00:26:24,345
They can then have

656
00:26:24,345 --> 00:26:26,610
a natural language
conversation with the agent

657
00:26:26,610 --> 00:26:29,100
to ask it more specific questions.

658
00:26:29,100 --> 00:26:30,390
So it's kind of a...

659
00:26:30,390 --> 00:26:32,370
I kinda see it as a big funnel,

660
00:26:32,370 --> 00:26:34,410
you know, and it's just slowly

661
00:26:34,410 --> 00:26:36,357
kind of refining down the information.

662
00:26:36,357 --> 00:26:39,270
And they can just get it to a point where

663
00:26:39,270 --> 00:26:41,220
it's where they need

664
00:26:41,220 --> 00:26:44,250
to either lift and shift
it into their report

665
00:26:44,250 --> 00:26:47,520
or kind of do more
analysis on specific bits

666
00:26:47,520 --> 00:26:50,640
and then add their own
conclusions from the data.

667
00:26:50,640 --> 00:26:53,220
So, it's really just a three-step flow

668
00:26:53,220 --> 00:26:56,730
to kinda help them, say,
triangulate and narrow down.

669
00:26:56,730 --> 00:26:58,680
It's pretty straightforward, isn't it?

670
00:26:58,680 --> 00:26:59,513
- [Leo] Yep.

671
00:27:02,370 --> 00:27:03,210
- [Alastair] So I think we're kinda

672
00:27:03,210 --> 00:27:04,273
looking to future now a bit now.

673
00:27:04,273 --> 00:27:05,700
- Yeah.
- Yeah, so-

674
00:27:05,700 --> 00:27:06,660
- Let's talk a little bit about

675
00:27:06,660 --> 00:27:08,110
where we are going from here.

676
00:27:09,690 --> 00:27:12,630
This fun slide is so we
can start talking about

677
00:27:12,630 --> 00:27:17,610
where we believe the
world is going, all right?

678
00:27:17,610 --> 00:27:22,200
You know, when we think
about the big data, right,

679
00:27:22,200 --> 00:27:24,270
termed 15 years ago.

680
00:27:24,270 --> 00:27:25,830
We think of the first era of big data

681
00:27:25,830 --> 00:27:29,040
being from 15 years ago to
about seven or eight years ago,

682
00:27:29,040 --> 00:27:31,090
and then we call that the era of control.

683
00:27:31,980 --> 00:27:35,670
And it was exactly that control
of cost, control of process,

684
00:27:35,670 --> 00:27:37,260
control of a number of things,

685
00:27:37,260 --> 00:27:40,080
and getting control of
large amounts of data

686
00:27:40,080 --> 00:27:41,370
for the first time, when back then,

687
00:27:41,370 --> 00:27:42,930
we were talking about terabytes.

688
00:27:42,930 --> 00:27:44,850
Then we get into the next era

689
00:27:44,850 --> 00:27:47,580
from seven or eight years ago until now.

690
00:27:47,580 --> 00:27:51,000
And that second era, we call
the era of convenience, right?

691
00:27:51,000 --> 00:27:52,680
It was about ease of use.

692
00:27:52,680 --> 00:27:55,620
It was about getting quickly to some value

693
00:27:55,620 --> 00:28:00,090
and not going through the old
IT processes of the old days.

694
00:28:00,090 --> 00:28:01,680
And, you know, with convenience

695
00:28:01,680 --> 00:28:03,300
came at least some loss of control.

696
00:28:03,300 --> 00:28:05,040
You couldn't do some of
the things you wanted to

697
00:28:05,040 --> 00:28:06,150
the way you wanted to do them.

698
00:28:06,150 --> 00:28:07,890
You had to do them the way
they were out of the box.

699
00:28:07,890 --> 00:28:10,110
You lost control of some of the processes

700
00:28:10,110 --> 00:28:11,640
and some of the costs.

701
00:28:11,640 --> 00:28:13,110
And we believe that the world

702
00:28:13,110 --> 00:28:15,090
is now coming to an era of convergence

703
00:28:15,090 --> 00:28:18,120
where those two things
have to be true, right?

704
00:28:18,120 --> 00:28:20,970
And in order to do that,
you have to be able to,

705
00:28:20,970 --> 00:28:23,250
number one, the cloud experience

706
00:28:23,250 --> 00:28:26,640
is what the world expects from
all of its stuff now, right?

707
00:28:26,640 --> 00:28:29,820
I want a SaaS or a SaaS
adjacent like software product.

708
00:28:29,820 --> 00:28:31,800
I want it to be easy to use.

709
00:28:31,800 --> 00:28:33,240
I want it to...

710
00:28:33,240 --> 00:28:34,800
I don't wanna think about where stuff is,

711
00:28:34,800 --> 00:28:37,080
it just magically happens out there.

712
00:28:37,080 --> 00:28:39,270
So that cloud experience
has to be delivered,

713
00:28:39,270 --> 00:28:40,410
it has to be consistent,

714
00:28:40,410 --> 00:28:41,910
and it has to be consistent

715
00:28:41,910 --> 00:28:44,760
across each of the public clouds

716
00:28:44,760 --> 00:28:47,010
and across private clouds,

717
00:28:47,010 --> 00:28:49,230
air-gapped environments data centers.

718
00:28:49,230 --> 00:28:50,680
Okay? That's the first thing.

719
00:28:53,070 --> 00:28:55,950
Second thing is, it has to...

720
00:28:55,950 --> 00:28:57,960
You have to be able to do all of that

721
00:28:57,960 --> 00:29:02,880
in such a way that you can
get to value in minutes,

722
00:29:02,880 --> 00:29:06,240
nevermind months or
weeks, in minutes, okay?

723
00:29:06,240 --> 00:29:08,100
And we're achieving that with something

724
00:29:08,100 --> 00:29:10,770
that we're calling,
Anywhere Cloud, all right?

725
00:29:10,770 --> 00:29:12,750
We've done a series of
acquisitions over the past year.

726
00:29:12,750 --> 00:29:16,380
I mentioned an acquisition
of the AI company.

727
00:29:16,380 --> 00:29:18,810
We also acquired a
company called, Octopai,

728
00:29:18,810 --> 00:29:23,490
which is for a data
lineage and cataloging.

729
00:29:23,490 --> 00:29:25,830
And we acquired a company called, Taikun.

730
00:29:25,830 --> 00:29:30,780
And Taikun is a full
Kubernetes container system,

731
00:29:30,780 --> 00:29:34,110
but it's also a environment
management system.

732
00:29:34,110 --> 00:29:34,943
And we're putting that

733
00:29:34,943 --> 00:29:37,360
together with the data service that we had

734
00:29:38,865 --> 00:29:40,173
in this Anywhere Cloud.

735
00:29:41,070 --> 00:29:42,690
In Q1, it's in tech preview.

736
00:29:42,690 --> 00:29:45,000
In Q2, it releases GA,

737
00:29:45,000 --> 00:29:50,000
and it is the first ever
data platform for doing AI,

738
00:29:51,120 --> 00:29:53,520
but it's a disaggregated platform

739
00:29:53,520 --> 00:29:57,390
because each of these services
that's fully containerized,

740
00:29:57,390 --> 00:29:59,940
has a unified data fabric inside it

741
00:29:59,940 --> 00:30:02,670
so they all work together,
they all talk to one another,

742
00:30:02,670 --> 00:30:04,800
but they deploy independently,

743
00:30:04,800 --> 00:30:07,500
and they deploy in
minutes from an interface.

744
00:30:07,500 --> 00:30:09,930
And that is, we believe,

745
00:30:09,930 --> 00:30:13,740
going to be game-changing
for what people need to do.

746
00:30:13,740 --> 00:30:15,240
Because more and more,

747
00:30:15,240 --> 00:30:17,527
it's complex data state of lots of,

748
00:30:17,527 --> 00:30:21,210
you know, different vendors,
in lots of different places.

749
00:30:21,210 --> 00:30:23,280
You're not moving your
data around anymore.

750
00:30:23,280 --> 00:30:25,560
You've gotta be able to
do this stuff on the edge.

751
00:30:25,560 --> 00:30:27,090
You've gotta be able to do it everywhere.

752
00:30:27,090 --> 00:30:28,860
And we think this is the first platform

753
00:30:28,860 --> 00:30:30,480
that the world has ever seen

754
00:30:30,480 --> 00:30:32,430
that's gonna be able to do that.

755
00:30:32,430 --> 00:30:33,960
And I like that

756
00:30:33,960 --> 00:30:37,110
because when I look at the use
cases that you have, and...

757
00:30:37,110 --> 00:30:40,680
I mean, you guys are
literally all over the world,

758
00:30:40,680 --> 00:30:41,970
literally all over the world,

759
00:30:41,970 --> 00:30:43,650
having to do things in environments

760
00:30:43,650 --> 00:30:46,710
that are just blow me away, right?

761
00:30:46,710 --> 00:30:49,200
And the things that we're
going to be able to do

762
00:30:49,200 --> 00:30:52,290
for organizations that
have such a complex task,

763
00:30:52,290 --> 00:30:55,200
I think, is very, very exciting.

764
00:30:55,200 --> 00:30:56,940
- [Alicia] Yeah, that's actually
super interestingly, Leo,

765
00:30:56,940 --> 00:31:00,630
because the sort of multi-cloud
conversation amongst INGOs

766
00:31:00,630 --> 00:31:03,360
has been going on for
a number of years now.

767
00:31:03,360 --> 00:31:05,130
We are across all of those clouds,

768
00:31:05,130 --> 00:31:06,540
and then we also have a super challenging

769
00:31:06,540 --> 00:31:07,740
regulatory environment.

770
00:31:07,740 --> 00:31:08,573
We have places where

771
00:31:08,573 --> 00:31:10,080
you can't move data outside the country,

772
00:31:10,080 --> 00:31:11,340
it needs to be on data centers

773
00:31:11,340 --> 00:31:13,890
inside those borders and so on.

774
00:31:13,890 --> 00:31:17,910
So I think things like
that are kind of necessary

775
00:31:17,910 --> 00:31:19,110
for the type of work that we do,

776
00:31:19,110 --> 00:31:21,480
for the type of diversity that we have

777
00:31:21,480 --> 00:31:22,620
across our organization.

778
00:31:22,620 --> 00:31:24,450
And certainly-
- I can only imagine, right?

779
00:31:24,450 --> 00:31:26,670
You guys hear the whole sovereign
cloud conversation, yeah?

780
00:31:26,670 --> 00:31:28,590
You might have heard that.

781
00:31:28,590 --> 00:31:31,230
But the fact that you are in
all those different countries,

782
00:31:31,230 --> 00:31:33,690
when each of those countries
has a different rule

783
00:31:33,690 --> 00:31:36,060
on sovereignty, that is just...

784
00:31:36,060 --> 00:31:36,893
That's mind boggling.

785
00:31:36,893 --> 00:31:37,920
- [Alicia] Well, and the rules about AI

786
00:31:37,920 --> 00:31:38,820
are changing as well.

787
00:31:38,820 --> 00:31:41,370
The regulatory environment
around AI, specifically,

788
00:31:41,370 --> 00:31:42,203
will change as well.

789
00:31:42,203 --> 00:31:44,070
So the governance around those tools

790
00:31:44,070 --> 00:31:48,750
is going to be evolving rapidly
over the next few years,

791
00:31:48,750 --> 00:31:52,170
and we'll have to be keeping
an eye on those things as well.

792
00:31:52,170 --> 00:31:54,120
Yeah, so those types of products, I think,

793
00:31:54,120 --> 00:31:55,680
are really exciting to see those

794
00:31:55,680 --> 00:32:00,330
starting to actually come
out and available generally.

795
00:32:00,330 --> 00:32:01,163
- [Leo] Yeah.

796
00:32:01,163 --> 00:32:05,550
Look, we're coming to the
end of our prepared remarks.

797
00:32:05,550 --> 00:32:09,120
We do have two microphones
wandering around in the back

798
00:32:09,120 --> 00:32:10,953
or walking down the center aisle.

799
00:32:11,790 --> 00:32:16,293
If anybody wants to ask any
questions before we let you go.

800
00:32:21,270 --> 00:32:22,920
Please.

801
00:32:22,920 --> 00:32:24,960
Come on.
- The mic's just coming.

802
00:32:24,960 --> 00:32:27,010
Here it comes. (chuckles)
- There we go.

803
00:32:30,780 --> 00:32:32,310
- [Audience] Hi, I was wondering,

804
00:32:32,310 --> 00:32:37,110
do you guys have a particular,
like, use case or a story

805
00:32:37,110 --> 00:32:39,030
of where, someone on your team,

806
00:32:39,030 --> 00:32:42,150
has used this and it's made a difference?

807
00:32:42,150 --> 00:32:44,850
- Yeah, that's a great
question. (chuckles)

808
00:32:44,850 --> 00:32:49,320
So as Al mentioned,
our development process

809
00:32:49,320 --> 00:32:51,600
was interrupted a bit by the arrival

810
00:32:51,600 --> 00:32:54,960
of a charming new baby boy. (chuckles)

811
00:32:54,960 --> 00:32:57,000
So we're not in a position

812
00:32:57,000 --> 00:33:00,660
where we've completed as much
as we wanted to by today,

813
00:33:00,660 --> 00:33:04,230
but there is currently an effort
to start using the platform

814
00:33:04,230 --> 00:33:07,320
to develop some reporting for Sudan.

815
00:33:07,320 --> 00:33:10,683
So our Sudan Crisis Analysis
team is a single analyst,

816
00:33:11,520 --> 00:33:13,920
so he does not have a lot of bandwidth

817
00:33:13,920 --> 00:33:15,510
to get done what he wants to do.

818
00:33:15,510 --> 00:33:20,510
The Sudan context is extremely
dynamic, extremely volatile,

819
00:33:20,730 --> 00:33:23,070
it's just extremely fragmented.

820
00:33:23,070 --> 00:33:24,960
So there's a lot of different actors

821
00:33:24,960 --> 00:33:28,320
in many different places doing
a lot of different things.

822
00:33:28,320 --> 00:33:30,840
So they experienced some
pretty severe data silos,

823
00:33:30,840 --> 00:33:32,490
information silos.

824
00:33:32,490 --> 00:33:34,950
There's no sort of, like,
unified information platform

825
00:33:34,950 --> 00:33:37,680
across that humanitarian effort, right?

826
00:33:37,680 --> 00:33:38,880
So everybody's doing their own thing.

827
00:33:38,880 --> 00:33:41,550
So there's a huge risk
of duplication of effort.

828
00:33:41,550 --> 00:33:46,170
There's a huge risk of of
resource waste in that context.

829
00:33:46,170 --> 00:33:48,270
So what Mercy Corps is planning to do

830
00:33:48,270 --> 00:33:50,700
is to look at a report that
we've been wanting to do

831
00:33:50,700 --> 00:33:52,290
for many months,

832
00:33:52,290 --> 00:33:54,903
have not had the bandwidth
for that analyst to do.

833
00:33:55,830 --> 00:33:59,250
It's gonna look at food
security across Sudan,

834
00:33:59,250 --> 00:34:02,550
both how to evaluate current
food security situation

835
00:34:02,550 --> 00:34:05,770
as well as be forward-looking
and preventing

836
00:34:06,780 --> 00:34:09,840
food security problems moving forward.

837
00:34:09,840 --> 00:34:11,310
And so that is sort of our goal,

838
00:34:11,310 --> 00:34:14,160
is to release a report on that topic,

839
00:34:14,160 --> 00:34:17,910
hopefully in the next four to six weeks.

840
00:34:17,910 --> 00:34:19,410
But yeah, sorry about that. (chuckles)

841
00:34:19,410 --> 00:34:23,100
We had planned to have a product done,

842
00:34:23,100 --> 00:34:26,160
but unfortunately, you can't
always account for life.

843
00:34:26,160 --> 00:34:29,670
We know that in
humanitarian world, so yeah.

844
00:34:29,670 --> 00:34:31,080
- Cool.
- And can I just say,

845
00:34:31,080 --> 00:34:33,060
please do support these guys.

846
00:34:33,060 --> 00:34:36,090
I've worked with Alicia and
her team for 18 months now,

847
00:34:36,090 --> 00:34:39,120
and it's humbling working with them.

848
00:34:39,120 --> 00:34:41,640
They're amazing people doing amazing work.

849
00:34:41,640 --> 00:34:43,680
The ideas that Alicia has

850
00:34:43,680 --> 00:34:46,227
to really innovate with
technology, are phenomenal.

851
00:34:46,227 --> 00:34:48,120
The the whole team...

852
00:34:48,120 --> 00:34:51,120
You know, I'm always humbled and inspired

853
00:34:51,120 --> 00:34:55,500
by the way that the Mercy
Corps team go about their work,

854
00:34:55,500 --> 00:34:58,200
you know, in difficult,
challenging circumstances.

855
00:34:58,200 --> 00:35:00,870
And it's an absolute
pleasure and a privilege

856
00:35:00,870 --> 00:35:01,740
to work with them.

857
00:35:01,740 --> 00:35:05,917
So yeah, please do support
the team as much as you can.

858
00:35:05,917 --> 00:35:09,120
- (chuckles) So just so you know,

859
00:35:09,120 --> 00:35:11,430
when you're working with
an Alicia and an Alastair,

860
00:35:11,430 --> 00:35:12,930
and they both go by Al,

861
00:35:12,930 --> 00:35:15,120
and when you type Al, it looks like AI,

862
00:35:15,120 --> 00:35:17,026
it's impossible to write an email.

863
00:35:17,026 --> 00:35:19,440
(Alastair and Alicia laughing)

864
00:35:19,440 --> 00:35:21,900
So anyway, Alicia, Alastair,
thank you very much.

865
00:35:21,900 --> 00:35:23,460
Thank you all for coming. Appreciate it.

866
00:35:23,460 --> 00:35:26,703
- Thank you.
(audience clapping)

