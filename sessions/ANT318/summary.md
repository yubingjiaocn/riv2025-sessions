# AWS re:Invent 2025 Redshift 多数据仓库架构会议总结

## 会议概述

本次会议深入探讨了 Amazon Redshift 的多数据仓库架构设计模式和最佳实践。会议由 AWS Redshift 工程总监 Nar Chanani、Vanguard 数据工程总监 Alex Rabinovich 和 AWS 高级专家架构师 Anusha Chala 共同主讲。

会议首先提出了一个常见的业务场景：当数据科学团队在周末启动大型训练任务时，会导致 CEO 的仪表板无法加载，这种资源争用问题在单体计算架构中非常普遍。为解决这一挑战，演讲者介绍了两种主要的多数据仓库架构模式：Hub and Spoke（中心辐射）模式和 Data Mesh（数据网格）模式。这些架构通过将单一的大型计算集群分解为多个独立的端点，实现了工作负载隔离、独立扩展和成本分摊。

Vanguard 分享了他们从数据沼泽演进到集中式数据仓库，再到多数据仓库架构的完整旅程。他们管理着超过 20TB 的 Redshift 数据和 150TB 的 S3 数据湖数据，支持 100 多个活跃用户每月执行超过 50 万次查询。通过采用多数据仓库架构，Vanguard 显著改善了 SLA、用户体验和数据治理能力。会议最后通过实际演示展示了如何快速构建端到端的多数据仓库解决方案，包括零 ETL 集成、Iceberg 支持和生成式 AI 应用集成。

## 详细时间线

### 开场与问题陈述 (0:00 - 5:30)

0:00 - 1:15 - 会议开场场景设定
- 演讲者描述了一个典型问题：周一早晨 CEO 因仪表板无法加载而致电，原因是数据科学团队在周末启动了大型训练任务占用了相同的计算资源
- 引出本次会议主题：使用 Redshift 多数据仓库架构进行扩展

1:15 - 2:30 - 演讲者介绍
- Nar Chanani - Redshift 工程总监
- Alex Rabinovich - Vanguard 数据工程总监
- Anusha Chala - AWS 高级专家架构师

2:30 - 4:00 - 会议流程概览
- 多数据仓库架构设计模式概述
- Redshift 多数据仓库架构的底层技术
- Vanguard 的实际应用案例
- 现场演示和最佳实践

4:00 - 5:30 - 现场调查与问题定义
- 询问现场有多少人已在使用多数据仓库架构
- 展示单体架构的问题：一个大型计算集群运行流式注入、批量注入、数据科学和仪表板等多种应用
- 核心挑战：工作负载干扰和资源争用

### 架构模式介绍 (5:30 - 15:00)

5:30 - 8:00 - Hub and Spoke 模式
- 将大型单体集群分解为多个较小的独立端点
- 每个工作负载获得专属的计算资源和端点
- 优势：完全的工作负载隔离、独立扩展能力、成本分摊
- 中心是 Redshift 托管存储，所有端点共享同一份数据副本（无需复制数据）
- 支持快速添加新端点以应对季度末处理等临时需求

8:00 - 10:00 - 多区域 Hub and Spoke 变体
- 计算集群可以分布在不同的 AWS 区域
- 适用于多租户 ISV 提供商
- 租户可以使用距离更近的计算资源，降低网络延迟
- 主区域存储单一数据副本
- 支持为不同客户提供差异化的服务质量

10:00 - 13:00 - Data Mesh 模式
- 针对大型企业内不同团队（财务、市场、人力资源）的场景
- 每个业务单元拥有自己的端点和数据所有权
- 数据所有者决定与谁共享数据以及共享哪些数据
- 支持数据库、模式、表级别的共享，甚至可以细化到行或列级别
- 实现清晰的成本分摊和业务单元独立性

13:00 - 15:00 - 底层技术架构
- 存储层：Redshift 托管存储，采用高性能列式格式和专有编码
- 计算层：支持 Provisioned 和 Serverless 混合架构
- 新兴模式：将 Provisioned 用于稳定可预测的工作负载，Serverless 用于零星访问和峰值负载
- 支持跨账户和跨区域部署

### 新功能发布 (15:00 - 18:00)

15:00 - 18:00 - Federated Permissions（联合权限）
- 上周刚发布的新功能，统一多数据仓库架构的治理
- 解决了之前需要在多个计算集群上复制权限的痛点
- 示例：财务团队创建行级安全策略，限制用户只能访问其所在区域的客户数据
- 实现单一数据副本和单一权限副本的统一管理
- 支持数据主权合规要求

### Iceberg 和生态系统集成 (18:00 - 23:00)

18:00 - 20:30 - Apache Iceberg 支持
- 超过一半的大型客户同时使用数据仓库和数据湖
- Iceberg 提供事务性保证和开放标准互操作性
- 可以在同一查询中联接 Redshift 数据和 Iceberg/Parquet 数据
- 今年以来 Iceberg 查询性能提升超过 2 倍
- 几周前发布了 Iceberg 写入功能（追加工作负载）

20:30 - 23:00 - SageMaker Unified Studio 集成
- 数据和 AI 的一站式平台
- 支持 SQL notebook、Jupyter notebook 和自然语言查询
- 存储层包括 Redshift 数据、Iceberg（自管理或 S3 Tables）
- S3 Tables 通过自动压缩提供更好的性能
- SageMaker Catalog 用于数据发现和治理
- 支持 Athena、Spark 等多种引擎
- 通过 Iceberg REST Catalog API 实现开放互操作

23:00 - 25:00 - 生成式 AI 用例
- 使用 Amazon Q 进行自然语言 SQL 生成
- Redshift 数据可作为 Bedrock 应用的知识库
- 支持从 SQL 命令行直接调用 Bedrock 模型（如 Anthropic Claude）
- 示例：对评论表进行情感分析
- 支持 Model Context Protocol (MCP) 服务器，便于代理应用集成

### Vanguard 案例分享 (25:00 - 40:00)

25:00 - 27:00 - Vanguard 公司介绍
- 全球领先的金融投资公司，提供低成本共同基金、ETF 等产品
- Alex Rabinovich 支持财务咨询服务部门
- B2B 业务模式，为银行、保险公司、注册投资公司等中介机构提供服务

27:00 - 30:00 - Client 360 系统和初始挑战
- 构建了 Client 360 系统，聚合内外部中介机构数据
- 用例：分析和商业智能、预测智能（客户细分、通话转录、情感分析）、实时客户体验（超个性化）
- 初始架构：数据存储在 S3 数据湖的各个文件夹中，采用 Parquet 和 CSV 格式
- 问题：数据分析师难以构建洞察、多个版本的真相、工作重复、性能差、报告不一致、扩展困难、缺乏统一的黄金记录

30:00 - 33:00 - 第一波现代化：集中式数据仓库
- 在 Redshift Provisioned 平台上构建企业级数据仓库 Client 360
- 使用 AWS Glue 转换数据湖数据并加载到 Redshift
- 解锁了商业智能、分析和数据科学用例
- 收益：黄金数据源、显著提升的性能、业务信任度提高、解锁新用例（如比较产品分析，促使 Vanguard 推出新产品）

33:00 - 35:00 - 数据规模
- Redshift 托管存储中超过 20TB 数据
- S3 数据湖中超过 150TB 数据
- 超过 600 个表和 400 个视图
- 约 100 个活跃用户（分析师、数据工程师、数据科学家）
- 每月超过 50 万次查询
- 由数千个批处理作业驱动

35:00 - 37:00 - 成功带来的新挑战
- 数据库对象数量、存储和用例呈指数级增长
- 数据库对象数量每年翻倍
- 成为自身成功的受害者
- 新问题：资源争用（ETL 作业与分析工作负载竞争表锁）、高峰时段性能问题、工作负载管理复杂性（ETL 优先级高导致分析师体验差）、某些数据库对象重建时间长（物化视图需要在周末重建）

37:00 - 40:00 - 第二波现代化：Hub and Spoke 架构
- 从集中式单体架构转向分散式多数据仓库架构
- 左侧保持不变：通过 AWS Glue 将 S3 数据导入 Redshift Provisioned
- 右侧配置多个 Serverless 实例，按工作负载类型划分（分析、商业智能、数据科学）
- 使用 Data Share 机制向各工作负载公开数据
- 收益：改善的 SLA（减少争用）、显著提升的分析师体验（专用计算、最高优先级）、启用沙箱概念（分析师可创建永久表进行复杂分析，实现自助分析）

### Vanguard 未来架构和经验教训 (40:00 - 45:00)

40:00 - 42:00 - 持续存在的挑战
- 集中式数据所有权带来复杂性（数据治理）
- 写入的单一端点（ETL 作业之间仍存在竞争和锁定）
- 跨域相互依赖（如物化视图）降低了敏捷性

42:00 - 44:00 - 未来状态：Data Mesh 架构（进行中）
- 将数据加载到 S3 存储桶
- 使用 AWS Glue 将数据转换为 Iceberg 开放文件格式
- 关键差异：将数据域分离到独立的 Iceberg 表中，以便并行运行 ETL 作业
- 使用增量物化视图实现高性能
- 从 Iceberg 加载数据到 Redshift Serverless 实例
- Redshift 托管存储中的数据通过 Data Share 共享给消费者
- 消费者按工作负载分区（商业智能、分析、数据科学）
- 实现数据生产者和消费者的完全扇出

44:00 - 45:00 - 经验教训
- 从简单开始：从单个 Provisioned 或 Serverless 架构开始，逐步成长
- 准备好重新架构：当达到架构极限时，与 AWS 解决方案合作伙伴密切合作
- 保持灵活和开放：采用新功能（如 Data Share、Redshift Serverless）
- 跟踪指标衡量成功：活跃用户数、表数量、存储、成本、查询数、查询超时
- 演进路径总结：数据沼泽 → 集中式数据仓库 → Hub and Spoke → Data Mesh

### 演示部分 (45:00 - 结束)

45:00 - 47:00 - 演示引入和问题可视化
- 展示单体架构的查询排队图表（大量红色表示高争用）
- 重新架构后的多数据仓库图表显示几乎没有红色（争用大幅减少）
- 演示用例：虚构公司 Any Company 的端到端多数据仓库架构

47:00 - 50:00 - Any Company 用例概述
- 两个主要数据源：Oracle 销售数据库和网站点击流
- 三个主要用例：
  1. 数据注入和转换（应用业务逻辑提取洞察）
  2. 报告（支持业务决策者）
  3. 数据民主化（通过自然语言界面提供生成式 AI 访问）
- 关键要求：三个用例完全隔离，互不干扰
- 解决方案：为每个工作负载创建独立的端点

50:00 - 55:00 - 架构实现演示
- 创建三个独立的 Redshift Serverless 数据仓库：
  1. 数据加载和转换仓库
  2. 报告仓库
  3. 生成式 AI 仓库
- 使用零 ETL 集成从 Oracle 19c 销售数据库复制数据
- Oracle 数据库包含 sales schema，其中有 24 个表
- 演示创建零 ETL 集成的步骤：命名集成、选择源数据库、配置复制过滤器（仅复制 sales schema）
- 数据以列式格式近实时复制到 Redshift

55:00 - 结束 - 完整架构总结
- 点击流数据通过 Firehose 以 Apache Iceberg 格式写入 S3 Tables
- 形成湖仓一体架构（数据仓库 + 数据湖）
- 使用 SageMaker Catalog 进行编目和权限管理
- 报告仓库用于报告工作负载
- 生成式 AI 仓库用于自然语言查询应用
- 完整流程：注入 → 编目 → 权限管理 → 消费（报告和生成式 AI）