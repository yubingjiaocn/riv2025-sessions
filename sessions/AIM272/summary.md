# AWS re:Invent 2025 - 使用 SageMaker 进行 AI 模型开发

## 会议概述

本次会议由 Ankur 和 Mark Andrews 主讲,重点介绍了如何使用 Amazon SageMaker 进行 AI 模型开发和定制化。演讲者首先指出了当前企业面临的核心挑战:虽然生成式 AI 模型变得易于访问,但由于所有人都在使用相同的通用模型,企业很难建立差异化竞争优势。解决方案在于创建能够深入理解企业自身业务、领域知识和数据的定制化模型。

会议详细阐述了模型学习的完整生命周期,从预训练(Pre-training)到后训练(Post-training)的各个阶段,并将其类比为人类的学习过程。在预训练阶段,模型通过海量数据学习通用知识;在指令微调阶段学习如何遵循指令;通过偏好优化学习判断力和同理心;通过强化学习掌握推理能力;最后在实际应用中持续学习和改进。AWS 推出了多项创新功能来解决大规模模型训练中的关键挑战,包括弹性恢复、资源利用率优化和可观测性等问题。

会议还重点介绍了 SageMaker 的模型定制化能力,包括监督微调、强化学习(RLHF、RLAIF、RLVR)和直接偏好优化(DPO)等多种技术。AWS 提供了三种使用路径:基于代码的 SDK、可视化 UI 界面,以及 AI 代理引导的自动化流程,让不同技术背景的用户都能轻松定制模型。所有这些能力都以完全托管的无服务器方式提供,大幅降低了基础设施管理的复杂度。

## 详细时间线

### 开场与核心挑战 (00:00 - 05:00)
- **00:00** - 会议开始,Ankur 和 Mark Andrews 介绍使用 SageMaker 进行 AI 模型开发的主题
- **01:30** - 提出关键挑战:客户反馈虽然访问生成式 AI 模型变得容易,但所有人(包括竞争对手)都在使用相同的模型
- **02:15** - 核心问题:如何建立差异化?通用模型不了解企业的业务、领域知识、数据模式和业务约束
- **03:30** - 解决方案:需要让模型深入学习和理解企业特定的知识和需求

### 模型学习原理 (05:00 - 12:00)
- **05:00** - 介绍模型学习的阶段性过程:从通用知识到专业知识,再到任务执行能力
- **05:45** - 将模型学习类比为人类学习过程
- **06:30** - 预训练阶段:模型像儿童通过沉浸式学习语言,消化海量文本、图像等数据,学习预测下一个 token
- **07:45** - 指令微调阶段:类似中学生学习写作和遵循指令,模型学习如何保持主题、提供结构化解释
- **08:30** - 偏好优化阶段:模型学习如何不仅正确而且优秀,理解人类认为简洁、清晰和符合社会规范的回答
- **09:15** - 强化学习阶段:类似大学教育从记忆转向推理,模型练习多步骤思考和问题分解
- **10:00** - 实际应用阶段:模型从学习转向实践,可通过 LoRA 等参数高效微调技术持续学习

### 预训练详解与挑战 (12:00 - 25:00)
- **12:00** - 深入讲解预训练:模型在海量 token 上训练,学习数据模式、语法、事实并建立内部表示
- **13:00** - 指出预训练的复杂性和多重挑战
- **13:30** - 挑战一:高效扩展 - 模型通常无法放入单个 AI 加速器,需要在大规模 GPU 或 AWS Trainium 集群上训练
- **14:15** - 挑战二:弹性恢复 - 分布式训练中单个 GPU 故障会导致整个训练停止,需要强大的容错能力
- **15:00** - 挑战三:利用率 - AI 加速器集群成本高昂,低利用率会导致浪费和成本超支
- **15:45** - 挑战四:生产力 - 工程师应专注于增值工作而非基础设施管理
- **16:30** - 挑战五:可观测性 - 需要深入了解训练过程中发生的情况
- **17:00** - 挑战六:可组合性 - 需要能够使用新兴的开源工具

### SageMaker 训练方案 (25:00 - 35:00)
- **25:00** - 介绍 SageMaker 的两种训练方式
- **25:30** - SageMaker Training Jobs:临时训练作业,自动管理基础设施生命周期
- **26:15** - SageMaker HyperPod:持久化 AI 加速器集群,提供完全控制和灵活性
- **27:00** - HyperPod 详细功能:快速启动集群,支持 Kubernetes 和 Slurm 编排
- **28:00** - 集成 TensorBoard,提供实时调度和优先级管理
- **28:45** - 内置容错能力,可快速从故障中恢复
- **29:30** - 高度可定制:支持多种编排选项、作业提交方式、可观测性工具
- **30:30** - 支持所有主流 AI 框架(PyTorch、TensorFlow、Nemo、Jax)和 AWS AI 加速实例

### 自愈能力与无检查点训练 (35:00 - 45:00)
- **35:00** - 讨论弹性恢复挑战:集群规模越大,故障频率越高
- **36:00** - 传统故障恢复流程耗时:诊断、替换节点、从检查点恢复、重启训练进程,可能需要数小时
- **37:30** - HyperPod 自愈能力:自动检测、诊断、替换故障节点并恢复训练
- **38:45** - 传统方法的问题:全有或全无的级联停止、顺序恢复步骤、基于检查点的恢复成本高
- **40:00** - 重大发布:无检查点训练(Checkpointless Training) - 在昨天的主题演讲中宣布
- **41:00** - 工作原理:故障发生时保持训练进程运行,通过点对点机制从邻近节点恢复模型状态
- **42:00** - 效果:无需重启基础设施或训练进程,在几秒钟内从故障中恢复
- **43:30** - 实际案例:所有最新的 Nova 模型都使用此功能训练,实现了 95% 的良好运行时间

### 无检查点训练的四大创新 (45:00 - 50:00)
- **45:00** - 创新一:优化的集合通信初始化 - 消除中央根服务器瓶颈,采用点对点节点发现机制,将初始化时间从分钟降至秒级
- **46:30** - 创新二:内存映射数据加载 - 通过共享内存缓存训练数据,训练恢复时可立即访问数据
- **47:30** - 创新三:进程内恢复 - 故障时不停止训练进程,训练只是暂停后恢复
- **48:30** - 创新四:无检查点恢复 - 通过点对点方式从健康加速器恢复模型和优化器状态

### 基础设施利用率优化 (50:00 - 58:00)
- **50:00** - 讨论基础设施利用率不足的问题
- **50:45** - 空闲计算的挑战:导致浪费、成本超支、优先级不当、生产力下降
- **52:00** - 解决方案:HyperPod 任务治理 - 根据优先级自动运行作业,支持实时优先级调整
- **53:00** - 提供实时可观测性,监控集群、作业和团队级别的利用率
- **54:00** - 功能详解:设置不同任务类型(训练、微调、实验、推理)及其权重
- **55:00** - 定义计算分配:为团队或项目分配计算限制
- **56:00** - 空闲计算分配策略:先到先得或基于权重的公平共享
- **56:45** - 借贷规则:团队间自动借用和出借计算容量
- **57:30** - 高优先级任务可抢占低优先级任务

### 弹性训练 (58:00 - 62:00)
- **58:00** - 讨论分布式训练的不灵活性:作业启动后无法更改节点配置
- **59:00** - 传统方法的问题:需要完全停止、重新配置、重启训练作业
- **60:00** - 重大发布:弹性训练(Elastic Training) - 昨天宣布
- **60:45** - 功能:定义训练作业的扩展规则,根据可用容量自动扩展或缩减
- **61:30** - 演示:训练作业从初始配置自动扩展到更多节点,然后根据需要缩减,整个过程不影响模型收敛

### 可观测性 (62:00 - 65:00)
- **62:00** - 强调可观测性的重要性
- **62:30** - 案例:AWS 科学团队曾因 GPU 温度波动导致训练性能下降,花费数天才找到根因
- **63:30** - 训练栈的复杂性:从训练代码到框架、计算、网络和硬件的多层架构
- **64:00** - HyperPod 可观测性:一键式集成 Amazon Managed Prometheus 和 Grafana
- **64:30** - 提供跨栈所有层的预配置指标:作业级、计算层、网络层和硬件层
- **65:00** - 随集群规模自动扩展

### 模型定制化技术 (65:00 - 75:00)
- **65:00** - 从预训练转向后训练和模型定制化,这是创造真正价值和差异化的关键
- **66:00** - 监督微调(Supervised Fine-tuning):模型从标注的输入输出数据中直接学习,适用于有明确真实标准的场景
- **67:00** - 应用场景:客户支持问答、摘要任务、领域适配(医疗、法律、金融术语)
- **68:00** - 强化学习(Reinforcement Learning):模型生成多个输出并接收奖励或惩罚,适用于长篇推理和多规则策略遵循
- **69:00** - RL 工作原理:策略模型生成输出,奖励函数计算奖励,优化算法更新模型
- **70:00** - RL 变体:RLHF(基于人类反馈)、RLAIF(基于 AI 反馈)、RLVR(基于可验证奖励)
- **71:30** - RLVR 适用于可编程验证准确性的场景,如编码任务
- **72:30** - 直接偏好优化(DPO):模型学习人类偏好,适用于主观或风格学习
- **73:30** - DPO 应用:学习品牌声音、价值观、聊天机器人语气,实现简单无需完整 RL 设置

### SageMaker 模型定制化平台 (75:00 - 85:00)
- **75:00** - 实施这些技术的挑战:基础设施设置、模型评估、企业级治理和血缘追踪
- **76:30** - SageMaker 作为统一模型定制化平台
- **77:00** - 支持广泛的模型选择:Amazon Nova、Llama、Qwen、DeepSeek 等开源模型
- **77:45** - 支持所有主流微调技术:强化学习、监督微调、直接偏好优化
- **78:30** - 完全托管的流程,无需基础设施管理
- **79:00** - 重大发布:无服务器训练作业(Serverless Training Jobs)
- **79:45** - 使用方式:选择数据和模型,通过 API 或 UI 启动完全无服务器的训练作业
- **80:30** - 模型评估能力:通过 API 和 UI 提供
- **81:00** - 支持多种评估模式:行业标准基准、LLM 作为评判者、自定义指标
- **82:00** - 无服务器 MLflow:本周宣布,用于实验跟踪和指标记录
- **83:00** - 无服务器训练作业的指标自动显示在 MLflow 中

### 三种使用路径 (85:00 - 110:00)
- **85:00** - SageMaker 提供三种使用方式
- **85:30** - 路径一:基于代码 - 使用 SDK 轻松定制模型
- **86:00** - 路径二:UI 界面 - 点击式可视化界面端到端定制模型
- **86:30** - 路径三:AI 代理引导 - 代理协作设计和执行定制任务

#### 基于代码的路径演示 (87:00 - 88:30)
- **87:00** - 使用 SageMaker AI SDK 几分钟内用几行代码定制模型
- **87:45** - 可在任何 IDE 中编写代码,也可使用 SageMaker 内置的 JupyterLab 和 VS Code
- **88:15** - 支持代码和 UI 之间自由切换

#### UI 引导微调演示 (88:30 - 95:00)
- **88:30** - 选择模型并选择使用 UI 定制
- **89:00** - 命名项目,选择微调技术(示例中使用 RLVR)
- **89:45** - 选择预先创建的奖励函数和数据
- **90:15** - 提交训练作业并开始执行
- **91:00** - 监控训练性能
- **91:30** - 创建评估作业:选择 LLM 作为评判者方法,选择评判模型和评估指标
- **92:30** - 提供自定义数据集和提示进行评估
- **93:00** - 评估作业完全无服务器,在后台执行
- **93:45** - 监控训练指标和评估进度
- **94:30** - 查看评估结果,可在 UI 上查看或通过 S3 下载

#### 模型部署演示 (95:00 - 98:00)
- **95:00** - 评估完成后点击部署按钮
- **95:30** - 选择部署到 SageMaker 推理端点或导入到 Bedrock
- **96:00** - 示例中选择 SageMaker 端点
- **96:30** - 部署完成后打开 Playground 测试模型
- **97:00** - 输入示例文本验证模型响应
- **97:30** - 查看模型血缘:所有变更、使用的数据、运行的作业、审批记录、评估历史
- **98:00** - 查看训练日志,在训练执行期间实时可用

#### AI 代理引导路径演示 (98:00 - 108:00)
- **98:00** - 选择使用 AI 代理定制模型
- **98:30** - 为对话命名,用简单语言描述用例
- **99:00** - 代理提问以澄清用例,要求选择基础模型
- **99:45** - 代理生成用例规范,描述用例和成功标准(用于后续评估)
- **100:30** - 基于用例生成数据示例,可编辑和改进
- **101:15** - 生成数据生成规范,确定如何生成定制化数据
- **102:00** - 使用示例或上下文数据自动生成合成数据
- **102:45** - 查看合成数据样本
- **103:15** - 获取数据质量指标:数据多样性、统计信息、负责任 AI 指标
- **104:00** - 因为代理推荐 RLVR,提供基于用例的奖励函数模板,可进一步编辑
- **104:45** - 通过与代理对话启动训练作业
- **105:15** - 在同一界面监控训练进度
- **105:45** - 训练完成后审查和修订评估标准
- **106:30** - 批准后代理运行评估
- **107:00** - 查看评估结果:微调模型在多个指标上明显优于基础模型
- **107:45** - 从模型页面部署到 SageMaker 或 Bedrock

### 总结 (108:00 - 110:00)
- **108:00** - SageMaker AI 模型开发的三大核心支柱
- **108:30** - 选择性:提供多种模型、定制技术和界面(UI、SDK、代理)的选择
- **109:00** - 效率:无服务器体验消除基础设施管理,将定制时间从数月缩短至数天
- **109:30** - 安全性:内置治理和血缘追踪能力,确保大规模 AI 的安全合规使用
- **110:00** - 会议结束