1
00:00:00,210 --> 00:00:01,043
- Awesome.

2
00:00:01,043 --> 00:00:02,910
Thanks everyone for coming out today.

3
00:00:02,910 --> 00:00:03,870
My name is Vishal.

4
00:00:03,870 --> 00:00:06,660
I'm the product manager
for EC2 Mac at AWS.

5
00:00:06,660 --> 00:00:08,250
I'm super excited to be joined today

6
00:00:08,250 --> 00:00:11,010
with two of my customers that
I work very closely with.

7
00:00:11,010 --> 00:00:14,907
We have Miranda from Riot and
we have Toni from Supercell.

8
00:00:14,907 --> 00:00:17,790
And so super excited for
you guys to hear from them

9
00:00:17,790 --> 00:00:20,850
as well about how they
use EC2 Mac to help build

10
00:00:20,850 --> 00:00:24,240
and test their own applications
for their organizations.

11
00:00:24,240 --> 00:00:25,530
So I'm going to kick us off today

12
00:00:25,530 --> 00:00:28,260
with a little bit of
the history of EC2 Mac

13
00:00:28,260 --> 00:00:32,790
and specifically, how we
came about EC2 Mac on AWS,

14
00:00:32,790 --> 00:00:34,110
what are some of the big pain points

15
00:00:34,110 --> 00:00:36,660
and key struggles customers
told us they faced,

16
00:00:36,660 --> 00:00:39,810
how we, at Amazon, use EC2 Mac internally

17
00:00:39,810 --> 00:00:42,840
and then we'll actually pass
it over to Miranda and Toni

18
00:00:42,840 --> 00:00:45,270
to actually give us insights
into their own organizations

19
00:00:45,270 --> 00:00:48,270
about how they've implemented EC2 Mac

20
00:00:48,270 --> 00:00:50,940
and some of the benefits
that they've seen.

21
00:00:50,940 --> 00:00:51,990
Cool, I'm just going to make sure

22
00:00:51,990 --> 00:00:53,490
that everyone can still hear me all right.

23
00:00:53,490 --> 00:00:55,190
You guys good? All right, awesome.

24
00:00:56,340 --> 00:00:58,620
So let's take a little step
back around understanding

25
00:00:58,620 --> 00:01:02,400
the application development
lifecycle for Apple platforms.

26
00:01:02,400 --> 00:01:03,570
In the earlier stages,

27
00:01:03,570 --> 00:01:05,790
we have the design,
code and develop stage.

28
00:01:05,790 --> 00:01:08,760
These necessarily aren't macOS-dependent,

29
00:01:08,760 --> 00:01:11,100
but as we go into the
build stage and onwards,

30
00:01:11,100 --> 00:01:13,710
you need Xcode, which everyone knows,

31
00:01:13,710 --> 00:01:16,320
Xcode needs to work on Mac hardware

32
00:01:16,320 --> 00:01:18,150
and that unfortunately means

33
00:01:18,150 --> 00:01:20,400
that you absolutely need to
buy Mac hardware and scale

34
00:01:20,400 --> 00:01:23,130
as your applications increase as well.

35
00:01:23,130 --> 00:01:26,700
So it's this dependency
between Xcode and macOS

36
00:01:26,700 --> 00:01:30,900
that made Apple development
on any hyperscaler impossible

37
00:01:30,900 --> 00:01:33,813
until we introduced EC2 Mac back in 2020.

38
00:01:35,970 --> 00:01:39,390
Today, the total market
for this opportunity

39
00:01:39,390 --> 00:01:41,400
is well over 34 million developers,

40
00:01:41,400 --> 00:01:42,930
many of you who are sitting in this room

41
00:01:42,930 --> 00:01:46,230
or will be watching on
YouTube when this gets posted.

42
00:01:46,230 --> 00:01:47,700
And the last time I made this deck,

43
00:01:47,700 --> 00:01:49,170
I think it was about a million apps.

44
00:01:49,170 --> 00:01:50,040
I think that we've now scaled

45
00:01:50,040 --> 00:01:51,810
to 2 million apps on the App Store

46
00:01:51,810 --> 00:01:54,750
and more than 2 billion
active devices as well.

47
00:01:54,750 --> 00:01:58,230
And Apple's introduced
a lot of new platforms,

48
00:01:58,230 --> 00:02:02,100
including visionOS that came
about a year or two ago.

49
00:02:02,100 --> 00:02:05,670
And today, with EC2 Mac, we
have customers across the board,

50
00:02:05,670 --> 00:02:07,470
different industries, different functions,

51
00:02:07,470 --> 00:02:09,840
building, testing and
developing applications

52
00:02:09,840 --> 00:02:11,343
for each of these platforms.

53
00:02:14,850 --> 00:02:17,040
I want to share with you today
some of the key struggles

54
00:02:17,040 --> 00:02:18,760
that some of our customers told us

55
00:02:20,225 --> 00:02:22,092
when they were giving us
feedback around EC2 Mac

56
00:02:22,092 --> 00:02:24,810
and the business case
as we start to do it.

57
00:02:24,810 --> 00:02:27,210
The first thing was
infrastructure overhead.

58
00:02:27,210 --> 00:02:30,030
Miranda's going to talk a
little about this in the future,

59
00:02:30,030 --> 00:02:32,880
but I'm super excited to talk to you guys

60
00:02:32,880 --> 00:02:36,060
about how the actual
ability to go and deal

61
00:02:36,060 --> 00:02:38,190
with physical hardware
in their data centers,

62
00:02:38,190 --> 00:02:39,270
customers absolutely hated it.

63
00:02:39,270 --> 00:02:40,920
They had to drive multiple hours,

64
00:02:40,920 --> 00:02:43,110
fly to different data centers, unplug,

65
00:02:43,110 --> 00:02:44,730
deal with data center technicians,

66
00:02:44,730 --> 00:02:48,120
all that headache cost time,
money and other resources.

67
00:02:48,120 --> 00:02:50,430
Pinterest here give us
a really good quote here

68
00:02:50,430 --> 00:02:54,030
around how the physical challenge

69
00:02:54,030 --> 00:02:55,710
of actually going to physical data centers

70
00:02:55,710 --> 00:02:56,910
was a real big struggle for them

71
00:02:56,910 --> 00:03:00,000
and that's one of the big
reasons why they use EC2 Mac.

72
00:03:00,000 --> 00:03:03,150
The next thing was the actual inability

73
00:03:03,150 --> 00:03:06,930
to go and have automatic fleet management.

74
00:03:06,930 --> 00:03:10,620
Groupon here told us about
this definitely increased

75
00:03:10,620 --> 00:03:12,450
the time for their time to market

76
00:03:12,450 --> 00:03:13,740
and every time something went wrong,

77
00:03:13,740 --> 00:03:15,060
they had to get IT involved

78
00:03:15,060 --> 00:03:16,260
and this was a really big struggle

79
00:03:16,260 --> 00:03:18,900
that they've solved by moving to EC2 Mac.

80
00:03:18,900 --> 00:03:20,640
And the last thing was inability to scale.

81
00:03:20,640 --> 00:03:23,820
Sometimes your workloads require
less number of resources,

82
00:03:23,820 --> 00:03:25,020
sometimes they need more.

83
00:03:25,020 --> 00:03:26,730
We see a lot of customers on the weekends,

84
00:03:26,730 --> 00:03:29,400
maybe, not having as many builds or tests,

85
00:03:29,400 --> 00:03:32,160
so they scale down and then
they scale back up on weekdays.

86
00:03:32,160 --> 00:03:36,030
This was one of the big benefits
that iQVIA saw in EC2 Mac

87
00:03:36,030 --> 00:03:38,550
and how they are optimizing using various

88
00:03:38,550 --> 00:03:40,500
different resources
like Auto Scaling Groups

89
00:03:40,500 --> 00:03:42,003
to come into EC2 Mac.

90
00:03:44,070 --> 00:03:46,200
All in all, this reduces time to market

91
00:03:46,200 --> 00:03:49,620
and essentially slows down
innovation for your organization.

92
00:03:49,620 --> 00:03:52,740
So this is where we brought in EC2 Mac

93
00:03:52,740 --> 00:03:55,560
back in 2020 here at Re:Invent actually.

94
00:03:55,560 --> 00:03:59,190
So this was the picture that
we always use for EC2 Mac.

95
00:03:59,190 --> 00:04:02,400
As you can probably tell,
this is a 2018 Intel Mac Mini,

96
00:04:02,400 --> 00:04:04,860
which was our first ever Mac hardware

97
00:04:04,860 --> 00:04:07,650
that we retrofit in our AWS data centers.

98
00:04:07,650 --> 00:04:10,170
These are connected with different PCIE

99
00:04:10,170 --> 00:04:12,630
to thunderbolt cables and we essentially,

100
00:04:12,630 --> 00:04:14,280
this is an example of one droplet,

101
00:04:14,280 --> 00:04:17,940
as we call them on AWS, but
essentially, it's one server.

102
00:04:17,940 --> 00:04:21,000
And so when you, as a
customer, use EC2 Mac,

103
00:04:21,000 --> 00:04:23,400
you have the full access
to the underlying hardware

104
00:04:23,400 --> 00:04:27,030
offered by Apple as
well and what they have.

105
00:04:27,030 --> 00:04:31,110
So essentially, the PCIE
to thunderbolt connections

106
00:04:31,110 --> 00:04:34,170
allow us to do implement with AWS Nitro.

107
00:04:34,170 --> 00:04:36,960
So that gives you all the
networking and EBS bandwidth

108
00:04:36,960 --> 00:04:40,140
that you get and enjoy
with the rest of AWS.

109
00:04:40,140 --> 00:04:44,430
And so our engineering teams
had to do a lot of manual work

110
00:04:44,430 --> 00:04:47,760
to make sure that Apple
hardware works with EC2 hardware

111
00:04:47,760 --> 00:04:49,950
and we've even gone in so far as some

112
00:04:49,950 --> 00:04:52,650
of these older platforms actually
even have robotic fingers

113
00:04:52,650 --> 00:04:54,510
that actually press and
hold the power button

114
00:04:54,510 --> 00:04:56,010
to turn the machines on and off.

115
00:04:56,010 --> 00:04:57,840
So it's a lot of huge credit that I give

116
00:04:57,840 --> 00:05:01,170
to my engineering teams to
go in and build the patents

117
00:05:01,170 --> 00:05:03,900
and everything that's needed
to operate these machines.

118
00:05:03,900 --> 00:05:05,250
But this photo's too outdated.

119
00:05:05,250 --> 00:05:08,370
So I decided to bring in some new photos

120
00:05:08,370 --> 00:05:13,370
and today, here we see, some
of these are our M2 Pro, M2

121
00:05:13,410 --> 00:05:15,186
and the most recently announced M4

122
00:05:15,186 --> 00:05:17,670
and M4 Pro Mac Minis as well.

123
00:05:17,670 --> 00:05:19,680
And this is exactly how it
looks in our data center.

124
00:05:19,680 --> 00:05:21,330
So on the upper left-hand
side, you can see

125
00:05:21,330 --> 00:05:23,730
that the form factor
remains about the same.

126
00:05:23,730 --> 00:05:26,400
We still have PCIE to
Thunderbolt connections,

127
00:05:26,400 --> 00:05:28,650
but the Mac has changed.

128
00:05:28,650 --> 00:05:30,840
As you know, the M4 and M4 Pro Mac minis

129
00:05:30,840 --> 00:05:34,230
have gotten almost to the size
of an Apple TV essentially

130
00:05:34,230 --> 00:05:35,100
and as many of you know,

131
00:05:35,100 --> 00:05:36,870
the power button has gone to the bottom.

132
00:05:36,870 --> 00:05:38,400
So there was a lot of engineering needed

133
00:05:38,400 --> 00:05:41,160
to make sure that the same
hardware functionality,

134
00:05:41,160 --> 00:05:43,533
the reboot mechanisms, all that work.

135
00:05:44,682 --> 00:05:45,870
So some of these slides,
you might not be able

136
00:05:45,870 --> 00:05:48,270
to see it on the screen,
but the M4 and M4 Pro also,

137
00:05:48,270 --> 00:05:51,180
which we announced, I think,
on September 12th come

138
00:05:51,180 --> 00:05:53,430
with new internal SSD drives

139
00:05:53,430 --> 00:05:55,140
that a lot of our customers are using.

140
00:05:55,140 --> 00:05:57,090
I know Miranda and I talk
a lot about this as well,

141
00:05:57,090 --> 00:06:00,390
but this is something that we've added,

142
00:06:00,390 --> 00:06:02,040
it's not really visible
in the pictures here,

143
00:06:02,040 --> 00:06:04,440
but it definitely gives
customers a lot more performance

144
00:06:04,440 --> 00:06:06,303
for local caching mechanisms as well.

145
00:06:08,190 --> 00:06:11,430
So want to just quickly cover

146
00:06:11,430 --> 00:06:15,210
why customers continue to use EC2 Mac

147
00:06:15,210 --> 00:06:17,670
and continue to stay with
EC2 over the course of,

148
00:06:17,670 --> 00:06:19,740
now what's going to be, about six years.

149
00:06:19,740 --> 00:06:21,480
So number one, one of the pain points

150
00:06:21,480 --> 00:06:23,400
that we talked about earlier, with iQVIA,

151
00:06:23,400 --> 00:06:25,560
Groupon and Pinterest
was they really wanted

152
00:06:25,560 --> 00:06:27,270
to improve their automation story.

153
00:06:27,270 --> 00:06:30,720
And so without going
to much of the details

154
00:06:30,720 --> 00:06:32,550
around every single spec that we have,

155
00:06:32,550 --> 00:06:34,710
we've now built automation
for some of the highest

156
00:06:34,710 --> 00:06:36,240
requested features that customers have.

157
00:06:36,240 --> 00:06:39,000
This includes the ability
to disable and enable SIP,

158
00:06:39,000 --> 00:06:43,047
which many developers need
to test their custom code.

159
00:06:43,047 --> 00:06:44,070
And for those that don't know,

160
00:06:44,070 --> 00:06:45,870
SIP is System Integrity Protection.

161
00:06:45,870 --> 00:06:46,950
It's one of the most painful things

162
00:06:46,950 --> 00:06:49,740
about working with Mac hardware and macOS.

163
00:06:49,740 --> 00:06:51,360
And so our engineering teams have done

164
00:06:51,360 --> 00:06:52,410
a really cool job to do.

165
00:06:52,410 --> 00:06:54,390
So just a little look behind the scenes

166
00:06:54,390 --> 00:06:56,010
of what SIP actually involves.

167
00:06:56,010 --> 00:06:57,750
We actually have custom software

168
00:06:57,750 --> 00:07:01,647
that goes in and mimics
what a mouse movement

169
00:07:01,647 --> 00:07:03,900
and GUI interaction looks like

170
00:07:03,900 --> 00:07:05,580
when you actually click in on a user.

171
00:07:05,580 --> 00:07:09,210
And so every time we change
a particular macOS version,

172
00:07:09,210 --> 00:07:11,400
we have to make sure
that that microservice

173
00:07:11,400 --> 00:07:13,860
that we actually have is able to recognize

174
00:07:13,860 --> 00:07:15,630
the newest GUI elements.

175
00:07:15,630 --> 00:07:18,120
So for example, with the
latest release of Tahoe

176
00:07:18,120 --> 00:07:20,040
that we just announced a few weeks ago,

177
00:07:20,040 --> 00:07:22,590
liquid glass made
everything very tough for us

178
00:07:22,590 --> 00:07:25,650
with different pixels,
different placement.

179
00:07:25,650 --> 00:07:28,980
The way that the user icon
actually shows up on the screen.

180
00:07:28,980 --> 00:07:30,810
Our engineering teams had
to spend a lot of time

181
00:07:30,810 --> 00:07:32,910
to rework everything to
make sure that it works

182
00:07:32,910 --> 00:07:34,350
and meets our security standards.

183
00:07:34,350 --> 00:07:36,390
So SIP is just one of
those example features

184
00:07:36,390 --> 00:07:38,130
that we've had to do a lot of effort on

185
00:07:38,130 --> 00:07:40,410
to make sure that it works as effectively

186
00:07:40,410 --> 00:07:42,693
as it did on Sonoma or Sequoia before.

187
00:07:43,530 --> 00:07:44,730
We talked a little bit about operational

188
00:07:44,730 --> 00:07:47,310
efficiency struggles that
customers had before.

189
00:07:47,310 --> 00:07:49,740
One of the big things that we
introduced a year or two ago

190
00:07:49,740 --> 00:07:53,550
was the ability to integrate
with Image Builder on AWS.

191
00:07:53,550 --> 00:07:57,270
And so customers today
have both Intel machines

192
00:07:57,270 --> 00:08:00,630
that run on x86 AMIs but then we also have

193
00:08:00,630 --> 00:08:02,850
Apple Silicon AMIs and
they've been able to use that

194
00:08:02,850 --> 00:08:05,940
for using various different
services like Image Builder,

195
00:08:05,940 --> 00:08:07,350
but you can also use Packer and whatnot

196
00:08:07,350 --> 00:08:09,360
to make your custom images.

197
00:08:09,360 --> 00:08:11,820
And then a few years ago, we
introduced replace root volume,

198
00:08:11,820 --> 00:08:13,140
which allows you to kind of provision

199
00:08:13,140 --> 00:08:15,723
fresh new macOS environments very quickly.

200
00:08:17,910 --> 00:08:21,030
A lot of customers also have
a very important monitoring

201
00:08:21,030 --> 00:08:23,580
and logging story and so obviously,

202
00:08:23,580 --> 00:08:24,930
CloudWatch is natively integrated,

203
00:08:24,930 --> 00:08:27,960
but then we also have other integrations

204
00:08:27,960 --> 00:08:29,970
with other monitoring services.

205
00:08:29,970 --> 00:08:34,050
And lastly is everything is
secured through your Amazon VPC.

206
00:08:34,050 --> 00:08:36,690
And so with IAM controls, access,

207
00:08:36,690 --> 00:08:39,843
it works just like any other
EC2 instance that we have.

208
00:08:42,360 --> 00:08:45,003
I'm excited to share what
we've delivered this year.

209
00:08:46,470 --> 00:08:48,360
Firstly, we talked a
little bit about this,

210
00:08:48,360 --> 00:08:51,000
but M4 and M4 PRO are now GA,

211
00:08:51,000 --> 00:08:53,610
have been GA for about
two and a half months now.

212
00:08:53,610 --> 00:08:55,110
We have a really cool video on our website

213
00:08:55,110 --> 00:08:57,560
if you guys want to go
check that out afterwards.

214
00:08:58,590 --> 00:09:00,570
We also improved our resiliency story

215
00:09:00,570 --> 00:09:03,630
by introducing support for
dedicated host auto recovery

216
00:09:03,630 --> 00:09:06,183
and reboot-based migration for instances.

217
00:09:07,920 --> 00:09:10,890
Hardware will fail, as our CTO
always says in our keynotes,

218
00:09:10,890 --> 00:09:12,630
but essentially, anytime it does,

219
00:09:12,630 --> 00:09:15,210
we've now introduced
better resiliency measures,

220
00:09:15,210 --> 00:09:18,210
so that your instances can
reboot onto other hardware

221
00:09:18,210 --> 00:09:20,760
and you don't need to
worry about maintaining

222
00:09:20,760 --> 00:09:22,620
that transition of when an instance

223
00:09:22,620 --> 00:09:24,220
or a hardware goes down as well.

224
00:09:25,170 --> 00:09:28,380
And going back to number one here,

225
00:09:28,380 --> 00:09:31,620
we talked a little bit about
why I want to point out

226
00:09:31,620 --> 00:09:34,350
the two terabyte instance
store volume is historically,

227
00:09:34,350 --> 00:09:38,430
Apple gives us an internal
SSD, but unfortunately,

228
00:09:38,430 --> 00:09:41,193
due to the way that we do
our terminations and reboots,

229
00:09:42,210 --> 00:09:43,350
if something goes wrong, we won't be able

230
00:09:43,350 --> 00:09:46,666
to capture that data and
move it to another instance.

231
00:09:46,666 --> 00:09:50,343
With the two terabyte instances,
sorry, local store volume,

232
00:09:51,270 --> 00:09:53,130
we're essentially giving you more space

233
00:09:53,130 --> 00:09:54,420
for your caching mechanisms,

234
00:09:54,420 --> 00:09:57,720
all at no additional charge
to what we have organically

235
00:09:57,720 --> 00:10:00,690
with our pricing mechanisms with EC2 Mac

236
00:10:00,690 --> 00:10:03,030
and this has been one of
our biggest customer asks.

237
00:10:03,030 --> 00:10:04,380
You still can use EBS volumes,

238
00:10:04,380 --> 00:10:06,750
but this is essentially
free storage for you guys

239
00:10:06,750 --> 00:10:09,273
to go and optimize using your AMIs.

240
00:10:11,220 --> 00:10:12,360
Just, I think, two weeks ago,

241
00:10:12,360 --> 00:10:15,420
we introduced Amazon
DCV support for EC2 Mac.

242
00:10:15,420 --> 00:10:18,750
DCV, you may know it as
Amazon DCV previously.

243
00:10:18,750 --> 00:10:20,790
It's a high display resolution protocol

244
00:10:20,790 --> 00:10:22,770
that can give you up to 4K resolution

245
00:10:22,770 --> 00:10:25,050
when you access Mac instances via GUI.

246
00:10:25,050 --> 00:10:27,420
And so this is currently free
to use and is GA as well.

247
00:10:27,420 --> 00:10:29,760
So a lot of customers have been using DCV

248
00:10:29,760 --> 00:10:33,930
for better simulator-based
testing or unit tests for any

249
00:10:33,930 --> 00:10:36,423
of their applications
that need a GUI interface.

250
00:10:37,620 --> 00:10:39,720
We delivered, as I said,
System Integrity Protection

251
00:10:39,720 --> 00:10:41,760
configurations earlier this year

252
00:10:41,760 --> 00:10:45,450
and obviously, most recently,
we did deliver macOS 26

253
00:10:45,450 --> 00:10:48,240
as Amazon Machine Images as well.

254
00:10:48,240 --> 00:10:50,220
So here is the current lay of the land

255
00:10:50,220 --> 00:10:52,203
around where our platforms are today.

256
00:10:53,130 --> 00:10:56,580
You can see we continue to support Intel.

257
00:10:56,580 --> 00:11:00,090
Oops, we continue to
support Intel Macs as well.

258
00:11:00,090 --> 00:11:03,150
As we all know, Apple is
transitioning away from Intel,

259
00:11:03,150 --> 00:11:07,230
but we still support those
with Sonoma and Sequoia images.

260
00:11:07,230 --> 00:11:12,090
Oops, and then along with
the latest M4 and M4 Pro,

261
00:11:12,090 --> 00:11:14,040
which now comes as two terabytes discs

262
00:11:14,040 --> 00:11:16,440
and highly recommend you guys to tune

263
00:11:16,440 --> 00:11:19,440
into Matt Garman's keynote
tomorrow for some additional

264
00:11:19,440 --> 00:11:21,870
future announcements as
well coming on EC2 Mac.

265
00:11:21,870 --> 00:11:25,500
So super proud and also happy to share

266
00:11:25,500 --> 00:11:27,990
that these are all just
a handful of customers

267
00:11:27,990 --> 00:11:30,510
that are using EC2 Mac today.

268
00:11:30,510 --> 00:11:31,770
As you can see, there are customers

269
00:11:31,770 --> 00:11:33,240
across different platforms,

270
00:11:33,240 --> 00:11:35,850
across different industries, verticals

271
00:11:35,850 --> 00:11:38,370
and we have a good selection
of partners as well

272
00:11:38,370 --> 00:11:41,130
that we can help you with to make sure

273
00:11:41,130 --> 00:11:43,803
that you get the right and
best usage out of EC2 Mac.

274
00:11:46,050 --> 00:11:48,150
So at a high level, these
were some of the benefits

275
00:11:48,150 --> 00:11:49,500
that customers have shared with us

276
00:11:49,500 --> 00:11:52,593
and this is also available
on our public pages.

277
00:11:54,270 --> 00:11:56,460
I think the one that really speaks to me

278
00:11:56,460 --> 00:11:58,740
is the reduction in build time

279
00:11:58,740 --> 00:12:01,860
as well as the reduction
in build failures.

280
00:12:01,860 --> 00:12:04,080
This is one of the biggest
reasons why customers continue

281
00:12:04,080 --> 00:12:07,080
to come to EC2 Mac is because they view

282
00:12:07,080 --> 00:12:09,720
the entire AWS ecosystem
with the networking

283
00:12:09,720 --> 00:12:11,850
and the resiliency measures
to be one of the best,

284
00:12:11,850 --> 00:12:13,770
compared to a lot of our customers

285
00:12:13,770 --> 00:12:15,690
have had their own data centers go down

286
00:12:15,690 --> 00:12:16,957
and so they are like,

287
00:12:16,957 --> 00:12:18,630
"I never wanna face that challenge again."

288
00:12:18,630 --> 00:12:20,700
And they come to AWS and
they have been very happy

289
00:12:20,700 --> 00:12:24,213
with the way that the resiliency
aspect of it especially.

290
00:12:25,290 --> 00:12:27,870
I think all in all, we continue to invest

291
00:12:27,870 --> 00:12:29,730
in this platform very heavily.

292
00:12:29,730 --> 00:12:31,950
Looking forward, we're
continuing to always look forward

293
00:12:31,950 --> 00:12:34,170
and to support the latest MAC hardware,

294
00:12:34,170 --> 00:12:37,410
increase our regional
availability, increase our global,

295
00:12:37,410 --> 00:12:39,990
just in general, global
availability of Mac hardware

296
00:12:39,990 --> 00:12:42,360
across different types and as always

297
00:12:42,360 --> 00:12:43,230
and as a product manager,

298
00:12:43,230 --> 00:12:45,180
we always work backwards
from the customer.

299
00:12:45,180 --> 00:12:47,850
So if any of you have feedback and,

300
00:12:47,850 --> 00:12:50,220
or interest in trying out EC2 Mac,

301
00:12:50,220 --> 00:12:52,320
there's no room, time
for Q and A on stage,

302
00:12:52,320 --> 00:12:54,920
but I'm happy to chat with
anyone afterwards as well

303
00:12:55,800 --> 00:12:56,760
to discuss your interests

304
00:12:56,760 --> 00:12:59,880
and how we can get you
started with EC2 Mac as well.

305
00:12:59,880 --> 00:13:01,770
With that being said, I'm
super excited to pass it off

306
00:13:01,770 --> 00:13:03,180
to Miranda, who's going to
talk to you a little bit

307
00:13:03,180 --> 00:13:05,043
about Riots Game with EC2 Mac.

308
00:13:09,210 --> 00:13:11,160
- Hi, I'm Miranda Pearson.

309
00:13:11,160 --> 00:13:12,630
I'm an IT systems engineer

310
00:13:12,630 --> 00:13:14,490
on the IT infrastructure team at Riot

311
00:13:14,490 --> 00:13:16,740
and we support the build farm

312
00:13:16,740 --> 00:13:19,050
by providing infrastructure
as a service to those teams,

313
00:13:19,050 --> 00:13:20,820
so they don't have to
think about build infra

314
00:13:20,820 --> 00:13:23,910
and they can just focus
on what they do best,

315
00:13:23,910 --> 00:13:24,873
building games.

316
00:13:29,010 --> 00:13:32,400
This journey, we're going to
start from our starting point.

317
00:13:32,400 --> 00:13:34,350
We're going to work
through the journey we took

318
00:13:34,350 --> 00:13:37,350
to get there, how we
rebuilt, the choices we made,

319
00:13:37,350 --> 00:13:40,293
what we got out of that and what's next.

320
00:13:42,450 --> 00:13:45,090
At Riot, just to give context,

321
00:13:45,090 --> 00:13:47,310
we use Apple Development workflows

322
00:13:47,310 --> 00:13:48,570
for three different things.

323
00:13:48,570 --> 00:13:50,970
We use them for signing workflows,

324
00:13:50,970 --> 00:13:53,973
game builds and audio asset processing.

325
00:13:54,990 --> 00:13:56,730
Those three workflows
have different shapes,

326
00:13:56,730 --> 00:13:58,860
different requirements, different needs

327
00:13:58,860 --> 00:14:01,980
and that ultimately shapes
how we meet those needs

328
00:14:01,980 --> 00:14:02,943
with EC Mac.

329
00:14:05,940 --> 00:14:07,950
Our story starts in Vegas,

330
00:14:07,950 --> 00:14:09,480
actually at Switch Datacenter.

331
00:14:09,480 --> 00:14:13,980
We had a pool of about
60 hardware Macs on prem.

332
00:14:13,980 --> 00:14:16,350
We were losing about 2% a year

333
00:14:16,350 --> 00:14:18,063
and we were plagued with issues.

334
00:14:18,900 --> 00:14:20,463
So let's dig into that.

335
00:14:22,500 --> 00:14:25,020
We hit the limits of what
we were able to patch out,

336
00:14:25,020 --> 00:14:27,270
performance-wise, when
we started coming up

337
00:14:27,270 --> 00:14:30,150
against the constraints
of the data center design

338
00:14:30,150 --> 00:14:34,653
and the custom mounts that
we had to use in that space.

339
00:14:38,550 --> 00:14:41,160
That was actually a picture
of our on prem fleet,

340
00:14:41,160 --> 00:14:43,833
the cheese graters in the
rack on the previous slide.

341
00:14:46,110 --> 00:14:49,470
And this next one is also the trash can

342
00:14:49,470 --> 00:14:51,483
from our original on prem fleet.

343
00:14:52,890 --> 00:14:55,770
We had drives literally melting,

344
00:14:55,770 --> 00:14:59,160
not an exaggeration at
all, literally melting,

345
00:14:59,160 --> 00:15:01,740
VMs kept running, if storage
was gone, we didn't know

346
00:15:01,740 --> 00:15:03,177
until someone else told us they were gone

347
00:15:03,177 --> 00:15:04,727
and the builds weren't working.

348
00:15:06,060 --> 00:15:10,830
Doing one set of repair took
away about 8% of the fleet

349
00:15:10,830 --> 00:15:13,233
every time we had to repair.

350
00:15:16,860 --> 00:15:18,630
Next, we'll get into the forcing functions

351
00:15:18,630 --> 00:15:21,840
and the pain that pushed us into a point

352
00:15:21,840 --> 00:15:23,740
where we had to do something about it.

353
00:15:28,440 --> 00:15:32,850
As we talked about earlier,
the heating, cooling, I/O,

354
00:15:32,850 --> 00:15:36,690
storage, compute limits were being hit

355
00:15:36,690 --> 00:15:39,300
and that was trickling
down into developers,

356
00:15:39,300 --> 00:15:42,750
which impacted build times,
which impacted build velocity,

357
00:15:42,750 --> 00:15:44,430
which impacted the way we were able

358
00:15:44,430 --> 00:15:46,593
to deliver games and changes to players.

359
00:15:49,440 --> 00:15:52,620
The biggest pain for
our team was the on prem

360
00:15:52,620 --> 00:15:55,920
physically being here
to maintain our stack,

361
00:15:55,920 --> 00:15:59,490
to do a firmware update, to
do a patch, to do a quick fix.

362
00:15:59,490 --> 00:16:00,990
We had to get on a plane and actually come

363
00:16:00,990 --> 00:16:02,133
to Vegas to do that.

364
00:16:05,280 --> 00:16:07,380
And all of that just became unsustainable.

365
00:16:09,810 --> 00:16:12,120
The first trigger that started our journey

366
00:16:12,120 --> 00:16:13,710
was that Riot made the call to get out

367
00:16:13,710 --> 00:16:15,960
of data centers as a business.

368
00:16:15,960 --> 00:16:18,390
We were no longer going to be
maintaining on prem hardware,

369
00:16:18,390 --> 00:16:21,060
so we had to start the
journey of moving out.

370
00:16:21,060 --> 00:16:24,210
The second was a forcing
function of a security incident

371
00:16:24,210 --> 00:16:26,880
that required us to rebuild
completely from the ground up

372
00:16:26,880 --> 00:16:29,760
and we couldn't reuse any of
our original infrastructure

373
00:16:29,760 --> 00:16:31,440
and we had to rebuild in a safe space.

374
00:16:31,440 --> 00:16:35,430
So AWS was a great landing
spot for us for that.

375
00:16:35,430 --> 00:16:37,440
Another issue was future incompatibility.

376
00:16:37,440 --> 00:16:38,880
We were on VMware at the time

377
00:16:38,880 --> 00:16:42,150
and ESXi 8 was dropping support for Mac,

378
00:16:42,150 --> 00:16:43,563
so we also had no choice.

379
00:16:46,950 --> 00:16:49,530
Pretty much speaks for itself,
but we hit the breaking point

380
00:16:49,530 --> 00:16:53,460
where it was not going to
scale for us to get on a plane

381
00:16:53,460 --> 00:16:56,370
and physically come in
person to maintain a fleet.

382
00:16:56,370 --> 00:16:59,040
That wasn't going to scale with
the workflows and workloads

383
00:16:59,040 --> 00:17:00,780
of developers that are building games

384
00:17:00,780 --> 00:17:02,283
and experiences for players.

385
00:17:06,030 --> 00:17:07,923
Next we'll get into how we rebuilt.

386
00:17:10,440 --> 00:17:13,888
EC2 Mac was our savior.

387
00:17:13,888 --> 00:17:15,900
AWS had our back with the capacity

388
00:17:15,900 --> 00:17:17,970
that we couldn't get easily on-prem.

389
00:17:17,970 --> 00:17:21,000
We were able to stretch
and expand that as needed

390
00:17:21,000 --> 00:17:22,530
and we no longer had to get on a plane

391
00:17:22,530 --> 00:17:25,233
to come here and physically
maintain our infra.

392
00:17:26,100 --> 00:17:28,920
So the turnaround time for
lifecycle was a lot more smooth.

393
00:17:28,920 --> 00:17:30,520
We were able to automate things.

394
00:17:32,820 --> 00:17:34,770
Terraform became our lever to get out

395
00:17:34,770 --> 00:17:36,810
of our trashcan trauma cycle

396
00:17:36,810 --> 00:17:40,290
and turn our physical fragility

397
00:17:40,290 --> 00:17:43,143
into something that we
can maintain as code.

398
00:17:45,600 --> 00:17:48,480
For our customers, the journey starts

399
00:17:48,480 --> 00:17:51,750
when a customer submits
a PR to a GitHub repo

400
00:17:51,750 --> 00:17:54,053
that triggers Jenkins to run a build

401
00:17:54,053 --> 00:17:59,053
to do a Terraform plan to
provision those resources.

402
00:18:01,590 --> 00:18:05,760
Once that plan goes into place,
it starts to pull in an AMI,

403
00:18:05,760 --> 00:18:08,386
which is maintained by
our product security team

404
00:18:08,386 --> 00:18:10,050
in a centralized account

405
00:18:10,050 --> 00:18:12,720
and shared out with customer accounts.

406
00:18:12,720 --> 00:18:16,200
So once that Terraform
hits the customer account,

407
00:18:16,200 --> 00:18:20,320
it'll use that AMI, which has
our baked in certificates,

408
00:18:22,350 --> 00:18:24,600
security features and basic tooling

409
00:18:24,600 --> 00:18:28,083
that product security mandates
for our production workloads.

410
00:18:29,280 --> 00:18:34,280
In that account, once it's
launched or sorry. (chuckles)

411
00:18:35,100 --> 00:18:38,130
Jenkins uses STS to
assume a centralized role

412
00:18:38,130 --> 00:18:40,470
that we share and maintain,

413
00:18:40,470 --> 00:18:41,970
so that teams don't
have to do that locally

414
00:18:41,970 --> 00:18:44,280
in their accounts and there's a codified

415
00:18:44,280 --> 00:18:46,353
representation of that access.

416
00:18:47,460 --> 00:18:49,080
With that temporary credential,

417
00:18:49,080 --> 00:18:50,490
they're able to go into the account

418
00:18:50,490 --> 00:18:52,950
with that secure base AMI,

419
00:18:52,950 --> 00:18:55,050
launch the instance in the account.

420
00:18:55,050 --> 00:18:58,800
And then from there, we have
event driven automation,

421
00:18:58,800 --> 00:19:01,320
which will pick up, oh hey,
there's a new instance,

422
00:19:01,320 --> 00:19:04,110
I should bootstrap it or
do whatever it needs to do

423
00:19:04,110 --> 00:19:06,793
in response to that new
instance spinning up.

424
00:19:06,793 --> 00:19:09,660
If there are any failures
there, that will go down

425
00:19:09,660 --> 00:19:12,210
to CloudWatch and we'll get notified.

426
00:19:12,210 --> 00:19:15,780
The bootstrap is done via Lambda

427
00:19:15,780 --> 00:19:18,190
and we're able to do deterministic

428
00:19:19,950 --> 00:19:23,637
and dynamic bootstrapping with SSM.

429
00:19:23,637 --> 00:19:27,900
The SSM documents are
maintained and shared

430
00:19:27,900 --> 00:19:30,150
from a centralized account as well,

431
00:19:30,150 --> 00:19:32,340
which is a tooling account.

432
00:19:32,340 --> 00:19:34,770
And those are shared down
from our customer accounts,

433
00:19:34,770 --> 00:19:36,720
so that we can maintain
a single source of truth

434
00:19:36,720 --> 00:19:39,663
for those bootstrap
documents, patching documents.

435
00:19:42,810 --> 00:19:46,293
So what changed after we
made the lift and shift?

436
00:19:48,330 --> 00:19:52,953
Our first shift from on
prem Intel to EC2 Mac Intel,

437
00:19:53,820 --> 00:19:58,820
3x our primary build time,
signing increased by 2x

438
00:20:00,090 --> 00:20:02,733
and code build, two-and-a-half.

439
00:20:04,500 --> 00:20:06,240
Just the mirror lift and shift,

440
00:20:06,240 --> 00:20:09,120
we were able to get rid
of a lot of the noise

441
00:20:09,120 --> 00:20:11,430
that we were seeing with
on prem hardware failures

442
00:20:11,430 --> 00:20:13,953
and really see the signal.

443
00:20:20,970 --> 00:20:24,663
Our first shift after migration
was to move to Silicon.

444
00:20:26,010 --> 00:20:31,010
We chose and we elected to do a hardware

445
00:20:33,390 --> 00:20:35,970
and software upgrade at the same time,

446
00:20:35,970 --> 00:20:38,130
which was able to amplify our gains

447
00:20:38,130 --> 00:20:41,670
and get us faster, cheaper, better

448
00:20:41,670 --> 00:20:44,133
scalable infrastructure
for our build teams.

449
00:20:49,170 --> 00:20:53,310
For us, fleet diversity isn't
just an exercise for fun.

450
00:20:53,310 --> 00:20:55,830
We have a lot of different
shapes of workloads

451
00:20:55,830 --> 00:20:58,380
and these are how we map the
shapes of those workloads

452
00:20:58,380 --> 00:21:02,880
to the different EC2 Mac instance
types and when we switch.

453
00:21:02,880 --> 00:21:05,790
And the greatest thing about
EC2 Mac that we get now

454
00:21:05,790 --> 00:21:07,350
is that teams don't have to lock in

455
00:21:07,350 --> 00:21:08,700
to a specific instance type.

456
00:21:08,700 --> 00:21:10,920
They're able to evolve as their workloads,

457
00:21:10,920 --> 00:21:14,130
as their workflows do, as pipelines do

458
00:21:14,130 --> 00:21:17,190
to meet the needs of
what those builds are.

459
00:21:17,190 --> 00:21:19,930
So something like TFT, for instance

460
00:21:21,390 --> 00:21:25,480
or Unreal might rely on M4, M4 Pro

461
00:21:27,450 --> 00:21:29,490
and we're continuing to see how

462
00:21:29,490 --> 00:21:31,893
to evolve our fleet for that.

463
00:21:33,396 --> 00:21:35,133
Where we're going and what's next.

464
00:21:38,460 --> 00:21:41,730
As we continue to evolve
and operationalize,

465
00:21:41,730 --> 00:21:45,660
optimize our fleet, our next steps are

466
00:21:45,660 --> 00:21:50,610
to explore shared capacity
to see how we can make,

467
00:21:50,610 --> 00:21:52,980
have that capacity feel
more elastic for teams

468
00:21:52,980 --> 00:21:55,413
rather than being tied
into a specific node.

469
00:21:56,850 --> 00:22:01,850
Switching more of our ARM
workloads to M4, M4 Pro

470
00:22:01,960 --> 00:22:04,650
to get better performance,

471
00:22:04,650 --> 00:22:07,203
to get increased build throughput,

472
00:22:09,690 --> 00:22:12,060
asset caching, because we have huge-

473
00:22:12,060 --> 00:22:13,800
One of the biggest issues we face

474
00:22:13,800 --> 00:22:16,080
is that we have huge per force depots

475
00:22:16,080 --> 00:22:18,690
of about two terabytes for a build

476
00:22:18,690 --> 00:22:21,630
and those can get really size-heavy.

477
00:22:21,630 --> 00:22:24,930
So anything that we can do to cache

478
00:22:24,930 --> 00:22:27,210
those assets ahead of time makes it easier

479
00:22:27,210 --> 00:22:29,793
for build engineers and developers.

480
00:22:31,740 --> 00:22:34,720
Finally, we want to
explore unlocking better

481
00:22:37,080 --> 00:22:39,750
storage bottlenecks by using local NVME

482
00:22:39,750 --> 00:22:41,223
across different workloads.

483
00:22:44,160 --> 00:22:46,620
Now that I've shared our
journey about what we've done

484
00:22:46,620 --> 00:22:49,390
with EC2 Mac, I'll hand it to Toni

485
00:22:51,060 --> 00:22:53,400
to talk about how Supercell
did the same thing

486
00:22:53,400 --> 00:22:55,170
a slightly different way.

487
00:22:55,170 --> 00:22:57,706
- Excellent, thank you, Miranda.

488
00:22:57,706 --> 00:23:01,567
Let's go into looking into
a little bit different.

489
00:23:01,567 --> 00:23:02,850
(chuckles)

490
00:23:02,850 --> 00:23:04,036
There you go, Miranda.

491
00:23:04,036 --> 00:23:07,036
(audience clapping)

492
00:23:08,910 --> 00:23:11,430
So let's next take a
look what Supercell did

493
00:23:11,430 --> 00:23:14,373
in terms of the journey to using E2 Mac.

494
00:23:15,210 --> 00:23:18,390
Supercell is a fitness-based
gaming company,

495
00:23:18,390 --> 00:23:20,756
well known for Brawl Stars, Clash Royale

496
00:23:20,756 --> 00:23:23,280
and Clash of Clans, of course.

497
00:23:23,280 --> 00:23:27,150
And we kind of had the whole
similar sign type of thing.

498
00:23:27,150 --> 00:23:30,990
We didn't escape from a Nevada desert,

499
00:23:30,990 --> 00:23:34,290
we escaped from our own basement in fact

500
00:23:34,290 --> 00:23:36,990
where we had a lot of
Macs running the same way,

501
00:23:36,990 --> 00:23:40,020
those cheese graters
and all the other stuff.

502
00:23:40,020 --> 00:23:41,340
My name is Toni Syvanen,

503
00:23:41,340 --> 00:23:45,660
I'm a senior cloud governance
engineer working for Supercell

504
00:23:45,660 --> 00:23:48,990
and first off, I want to
acknowledge on this presentation

505
00:23:48,990 --> 00:23:50,730
that my colleague, Jani Munen Mackey,

506
00:23:50,730 --> 00:23:54,450
who actually led the
creation of this solution

507
00:23:54,450 --> 00:23:57,360
and also created this
presentation as well.

508
00:23:57,360 --> 00:24:01,113
And my part in this was actually
work on the architecture,

509
00:24:02,580 --> 00:24:05,760
then working out on
troubleshooting the problems

510
00:24:05,760 --> 00:24:07,473
from the setup itself.

511
00:24:09,300 --> 00:24:11,340
But as a background, we had a lot

512
00:24:11,340 --> 00:24:15,480
of those Intel-based
Macs downstairs as well.

513
00:24:15,480 --> 00:24:19,290
And a lot of these teams,
what we call cells,

514
00:24:19,290 --> 00:24:23,340
hence the names Supercell, are
really, really independent.

515
00:24:23,340 --> 00:24:25,560
So each of those teams
had their own hardware

516
00:24:25,560 --> 00:24:28,320
that our central IT
team and the build team

517
00:24:28,320 --> 00:24:31,227
was maintaining for these teams as well.

518
00:24:31,227 --> 00:24:36,210
And because those cells are
super independent as well,

519
00:24:36,210 --> 00:24:38,760
they, of course, had
quite a different-looking

520
00:24:38,760 --> 00:24:40,110
build infrastructure as well,

521
00:24:40,110 --> 00:24:41,960
which was part of the challenge here.

522
00:24:43,020 --> 00:24:44,370
But let's go through the story.

523
00:24:44,370 --> 00:24:45,900
So we have similar story,

524
00:24:45,900 --> 00:24:47,760
we had a lot of zombies in the basement.

525
00:24:47,760 --> 00:24:50,520
They were growing in the
dark, moist environment.

526
00:24:50,520 --> 00:24:52,680
I don't know how they got there.

527
00:24:52,680 --> 00:24:56,310
We're going to look how did
we go through getting them

528
00:24:56,310 --> 00:24:59,010
quarantined basically,
what was the solution?

529
00:24:59,010 --> 00:25:01,440
We look a little bit deeper
into the architectures,

530
00:25:01,440 --> 00:25:03,270
just like Miranda did.

531
00:25:03,270 --> 00:25:04,890
We do have a little bit different kind

532
00:25:04,890 --> 00:25:08,220
of architecture though, so bear with me.

533
00:25:08,220 --> 00:25:10,080
We'll look at the results
and then learnings

534
00:25:10,080 --> 00:25:12,573
and what are we actually
going to build next.

535
00:25:13,650 --> 00:25:16,170
But let's start for the infestation.

536
00:25:16,170 --> 00:25:20,523
The on premises was all
Intel Macs back in 2023.

537
00:25:22,080 --> 00:25:25,710
They were just going fine
in there in the darkness,

538
00:25:25,710 --> 00:25:29,430
but there was a lot of problems
with the hardware itself.

539
00:25:29,430 --> 00:25:31,620
So we didn't have to fly somewhere,

540
00:25:31,620 --> 00:25:33,150
we had to just go downstairs,

541
00:25:33,150 --> 00:25:35,040
but still it was taking
quite a lot of time

542
00:25:35,040 --> 00:25:39,480
for our IT engineers just
reinstalling the Macs,

543
00:25:39,480 --> 00:25:41,970
trying to troubleshoot them,
troubleshoot the hardware

544
00:25:41,970 --> 00:25:43,473
and so on and so on.

545
00:25:44,580 --> 00:25:49,580
Also, like with Riots, the
VMware was basically saying

546
00:25:49,770 --> 00:25:51,600
that they're not going to be supporting

547
00:25:51,600 --> 00:25:54,993
the ESXi on Mac hardware,
especially on the Mac,

548
00:25:55,920 --> 00:25:57,270
the Apple Silicon.

549
00:25:57,270 --> 00:25:58,800
They're not going to support that at all.

550
00:25:58,800 --> 00:26:00,720
So we have to find some kind of solution.

551
00:26:00,720 --> 00:26:04,863
How do we go on running our
build infrastructure as well?

552
00:26:05,850 --> 00:26:08,700
And in worst days, it
could be that one-third

553
00:26:08,700 --> 00:26:11,760
of the whole Mac fleet, we
had multiple, multiple racks

554
00:26:11,760 --> 00:26:15,090
of this hardware was
actually not operable at all.

555
00:26:15,090 --> 00:26:18,330
So our game teams, those
sales were suffering,

556
00:26:18,330 --> 00:26:20,610
because the build times were
getting longer and longer,

557
00:26:20,610 --> 00:26:22,740
they had a lot of builds in the queue,

558
00:26:22,740 --> 00:26:25,650
so it was causing quite
a lot of problem as well.

559
00:26:25,650 --> 00:26:27,630
And at the same time,
while we had one-third

560
00:26:27,630 --> 00:26:31,620
of the fleet broken, they wanted more.

561
00:26:31,620 --> 00:26:33,480
We had new game teams popping up.

562
00:26:33,480 --> 00:26:37,770
They wanted to be able to
develop, sign, build their games

563
00:26:37,770 --> 00:26:40,770
and also the game teams
themselves, the live games,

564
00:26:40,770 --> 00:26:42,270
something like Brawl
Stars and Clash Royale,

565
00:26:42,270 --> 00:26:44,580
they were growing, they to do more build.

566
00:26:44,580 --> 00:26:46,950
So we had a whole conflict, this friction

567
00:26:46,950 --> 00:26:49,860
of broken hardware and, at the same time,

568
00:26:49,860 --> 00:26:51,963
high demand for new things.

569
00:26:53,340 --> 00:26:55,530
So we had either option.

570
00:26:55,530 --> 00:26:57,210
One option was that we started looking,

571
00:26:57,210 --> 00:26:59,400
do we start building a
data center somewhere

572
00:26:59,400 --> 00:27:02,220
to actually get out from the basement?

573
00:27:02,220 --> 00:27:05,550
But then we remembered back
in 2023 that a wise man

574
00:27:05,550 --> 00:27:09,420
had told us friends don't let
friends build data centers.

575
00:27:09,420 --> 00:27:14,420
This is a quote from 2013,
it's still valid on 2023

576
00:27:14,460 --> 00:27:16,590
and it's still valid today as well.

577
00:27:16,590 --> 00:27:20,650
So instead, we did go with
looking at the EC2 Mac,

578
00:27:21,600 --> 00:27:23,490
which already had launched
at that point, as said,

579
00:27:23,490 --> 00:27:24,990
multiple years earlier.

580
00:27:24,990 --> 00:27:27,990
But we, in Supercell,
hadn't looked at them

581
00:27:27,990 --> 00:27:32,170
until the MAC instances actually
became available on EC2 Mac

582
00:27:33,960 --> 00:27:35,670
or the Apple Silicon instances.

583
00:27:35,670 --> 00:27:38,980
So our solution is based
on these four pillars

584
00:27:40,170 --> 00:27:41,940
that, basically, the weapons that we use

585
00:27:41,940 --> 00:27:44,580
to start slaying the
zombies in the basement.

586
00:27:44,580 --> 00:27:47,880
First off, of course I said, EC2 Mac,

587
00:27:47,880 --> 00:27:50,040
getting, especially
the Apple Silicon ones,

588
00:27:50,040 --> 00:27:52,440
running right out of gate.

589
00:27:52,440 --> 00:27:55,980
So that would actually a,
improve the performance

590
00:27:55,980 --> 00:27:58,290
like we saw from Miranda's numbers

591
00:27:58,290 --> 00:28:01,380
and also we don't have to
go to the basement anymore.

592
00:28:01,380 --> 00:28:03,810
We can actually look into
the sky and to the clouds

593
00:28:03,810 --> 00:28:05,913
and just maintain it that way.

594
00:28:06,780 --> 00:28:10,020
Unlike the Riot Games,
we actually ended up

595
00:28:10,020 --> 00:28:14,550
using virtualization
on top of the EC2 Mac.

596
00:28:14,550 --> 00:28:15,930
I'll go into details why,

597
00:28:15,930 --> 00:28:20,280
but we use Cirrus Labs'
Tart virtualization,

598
00:28:20,280 --> 00:28:22,830
which is based on the Apple's official

599
00:28:22,830 --> 00:28:24,570
virtualization framework.

600
00:28:24,570 --> 00:28:26,580
So it's actually using Apple's

601
00:28:26,580 --> 00:28:30,480
own macOS native virtualization

602
00:28:30,480 --> 00:28:34,920
to actually spawn officially
supported virtual macOS

603
00:28:34,920 --> 00:28:37,383
on top of the Mac hardware as well.

604
00:28:38,910 --> 00:28:42,840
The reason for that is
that the EC2 Mac still have

605
00:28:42,840 --> 00:28:46,080
that if you switch the AMI,
it has this scrubbing dime

606
00:28:46,080 --> 00:28:49,410
that takes quite a while
for that to go round.

607
00:28:49,410 --> 00:28:51,870
There is, of course, now the
quick replacement mechanism

608
00:28:51,870 --> 00:28:53,970
as well, but back when
we started developing

609
00:28:53,970 --> 00:28:56,340
this solution, that was not available yet.

610
00:28:56,340 --> 00:28:58,710
So we went with the virtualization

611
00:28:58,710 --> 00:29:00,780
and the benefit of that
is that we can actually

612
00:29:00,780 --> 00:29:05,490
really quickly switch between
different Tart VM images,

613
00:29:05,490 --> 00:29:07,830
which more or less
behave, if you're familiar

614
00:29:07,830 --> 00:29:10,663
with containers, it behaves
like containers as well.

615
00:29:10,663 --> 00:29:14,223
So you can quickly start
the machine as well.

616
00:29:15,150 --> 00:29:18,660
On top of that, of
course, we use Terraform

617
00:29:18,660 --> 00:29:20,940
to manage this whole infrastructure

618
00:29:20,940 --> 00:29:23,010
and we use the Packer to create

619
00:29:23,010 --> 00:29:25,203
those Tart VM images as well.

620
00:29:26,130 --> 00:29:30,420
And last part, the fourth pillar is,

621
00:29:30,420 --> 00:29:32,340
I'm not going to pronounce this correct,

622
00:29:32,340 --> 00:29:34,710
it's, I guess, French, Mise-en-place.

623
00:29:34,710 --> 00:29:37,200
So it's a nice tool that
you can use to define

624
00:29:37,200 --> 00:29:40,110
what kind of tools you
want to have installed

625
00:29:40,110 --> 00:29:42,150
in the operating system itself.

626
00:29:42,150 --> 00:29:44,610
So you can list it I want
this version of Xcode,

627
00:29:44,610 --> 00:29:47,640
I want this version of
whatever other tools

628
00:29:47,640 --> 00:29:50,910
that you want to use, like
AWS SDK, you can list those

629
00:29:50,910 --> 00:29:53,190
and then just run the mise-en-place

630
00:29:53,190 --> 00:29:56,460
to customize the image on the fly.

631
00:29:56,460 --> 00:29:58,260
And this happens on every build actually.

632
00:29:58,260 --> 00:30:00,600
So when a build starts
running, the mise-en-place

633
00:30:00,600 --> 00:30:03,750
customizes quickly the machine on the fly,

634
00:30:03,750 --> 00:30:06,693
just before the build
itself starts as well.

635
00:30:09,780 --> 00:30:11,880
And lastly, what I want
to maybe mention also

636
00:30:11,880 --> 00:30:15,420
why the Amazon EC2 Mac
was natural for Supercell

637
00:30:15,420 --> 00:30:18,450
is that Supercell actually
born in the cloud.

638
00:30:18,450 --> 00:30:20,613
So when we were founded 2010,

639
00:30:22,350 --> 00:30:25,140
already everything was
build on AWS as well.

640
00:30:25,140 --> 00:30:28,320
So we had years and
years of AWS experience

641
00:30:28,320 --> 00:30:31,950
and especially really good
experience on using EC2

642
00:30:31,950 --> 00:30:34,773
and all the other
surrounding services as well.

643
00:30:36,180 --> 00:30:38,470
But then let's look
how did we actually put

644
00:30:40,100 --> 00:30:42,330
these tools, these pillars in the work?

645
00:30:42,330 --> 00:30:45,000
Well, everyone's familiar,
we had AWS Region,

646
00:30:45,000 --> 00:30:49,200
we had the VPC and multiple AZs as well.

647
00:30:49,200 --> 00:30:52,380
And on top of that, we have
the Auto Scaling Group.

648
00:30:52,380 --> 00:30:55,230
What is kinda special with the EC2 Mac,

649
00:30:55,230 --> 00:30:57,780
concerning Auto Scaling
Group, is that if you only put

650
00:30:57,780 --> 00:31:01,263
an Auto Scaling Group
in place, it won't work.

651
00:31:02,340 --> 00:31:05,040
And the reason for that is that EC2 Mac

652
00:31:05,040 --> 00:31:07,680
are actually dedicated hosts.

653
00:31:07,680 --> 00:31:11,460
So you actually have to go in
and provision a dedicated host

654
00:31:11,460 --> 00:31:12,600
and then on top of that,

655
00:31:12,600 --> 00:31:15,510
you can go and provision an EC2 instance.

656
00:31:15,510 --> 00:31:18,840
So there's like an extra
lifecycle step here,

657
00:31:18,840 --> 00:31:20,940
but luckily, AWS has another service

658
00:31:20,940 --> 00:31:23,700
that can help you manage the relationship

659
00:31:23,700 --> 00:31:25,620
with the Auto Scaling Group instances

660
00:31:25,620 --> 00:31:29,010
and the physical on-demand
machines as well.

661
00:31:29,010 --> 00:31:32,220
And that is the AWS License Manager.

662
00:31:32,220 --> 00:31:36,180
It's maybe not directly clear
to you why it does that,

663
00:31:36,180 --> 00:31:38,100
but the License Manager has a feature

664
00:31:38,100 --> 00:31:41,340
called Host Resource Group,

665
00:31:41,340 --> 00:31:44,760
So it can actually
automatically provision you

666
00:31:44,760 --> 00:31:48,570
on-demand machines based on
the Auto Scaling Group saying

667
00:31:48,570 --> 00:31:51,090
that I need a new hardware to run on.

668
00:31:51,090 --> 00:31:53,730
And then this License Manager goes in

669
00:31:53,730 --> 00:31:56,490
and actually provisions
the machine for you.

670
00:31:56,490 --> 00:31:58,080
What is really neat about it as well

671
00:31:58,080 --> 00:32:01,140
is that if you don't have
any instance running on that,

672
00:32:01,140 --> 00:32:02,880
on demand machine for a while,

673
00:32:02,880 --> 00:32:06,300
it will try to get rid
of it as well for you.

674
00:32:06,300 --> 00:32:11,300
And with EC2 Mac, that means
that after the 24 hours,

675
00:32:11,610 --> 00:32:14,370
it's gone, which is the
Apple-demanded minimum time

676
00:32:14,370 --> 00:32:18,120
to have the on-demand
machine allocated to you.

677
00:32:18,120 --> 00:32:19,590
The License Manager will make sure

678
00:32:19,590 --> 00:32:22,590
that that gets thrown away and basically,

679
00:32:22,590 --> 00:32:24,630
the cost for that Mac instance

680
00:32:24,630 --> 00:32:26,070
will stop at that, not instance,

681
00:32:26,070 --> 00:32:29,040
but the dedicated host
will stop at that point.

682
00:32:29,040 --> 00:32:31,470
And the magical glue there, how you attach

683
00:32:31,470 --> 00:32:34,950
the Auto Scaling Group
to the License Manager

684
00:32:34,950 --> 00:32:37,110
is through the EC2 Launch Template.

685
00:32:37,110 --> 00:32:38,250
In there, you're basically saying

686
00:32:38,250 --> 00:32:41,220
I want to use host resource group

687
00:32:41,220 --> 00:32:43,140
to be the source of the hardware

688
00:32:43,140 --> 00:32:45,003
for this Auto Scaling Group.

689
00:32:46,020 --> 00:32:49,260
And then later on, because
we ended up licensing also

690
00:32:49,260 --> 00:32:53,400
the Tart virtualization
engine, which is open source,

691
00:32:53,400 --> 00:32:55,290
but if you want to have official support,

692
00:32:55,290 --> 00:32:57,270
you can license it as well,

693
00:32:57,270 --> 00:32:59,100
the License Manager is
a nice way to make sure

694
00:32:59,100 --> 00:33:01,605
that we never go above
the number of licenses

695
00:33:01,605 --> 00:33:02,880
that we have purchased as well.

696
00:33:02,880 --> 00:33:06,720
So it actually came pretty
handy for us as well.

697
00:33:06,720 --> 00:33:07,740
But then let's go forward.

698
00:33:07,740 --> 00:33:12,740
Now, we can get those physical
machines, those EC2 Mac,

699
00:33:12,990 --> 00:33:16,800
so it will launch an EC2
instance and we just use

700
00:33:16,800 --> 00:33:21,800
those out-of-the-box default
AMIs that AWS provides us.

701
00:33:22,710 --> 00:33:25,920
We don't actually do any
customization of them

702
00:33:25,920 --> 00:33:27,990
in terms of AMI.

703
00:33:27,990 --> 00:33:32,130
We do use the user data though
and what the user data does

704
00:33:32,130 --> 00:33:35,710
is when we launch, for
example now the latest AMI

705
00:33:36,870 --> 00:33:41,310
from AWS, the user data
will actually make sure

706
00:33:41,310 --> 00:33:44,310
that the Cirrus Lab Tart gets installed

707
00:33:44,310 --> 00:33:46,230
and then it quickly kicks in

708
00:33:46,230 --> 00:33:47,970
the image that we want to kick in

709
00:33:47,970 --> 00:33:51,600
on top of that EC2 instance as well.

710
00:33:51,600 --> 00:33:54,600
So in the user data, that
we just quickly launch

711
00:33:54,600 --> 00:33:55,623
a virtual machine.

712
00:33:58,020 --> 00:34:01,620
And in that virtual machine,
what comes out of the image,

713
00:34:01,620 --> 00:34:04,230
the Tart VM image that we custom built

714
00:34:04,230 --> 00:34:06,750
with the Terraform Packer,
it has several things.

715
00:34:06,750 --> 00:34:09,990
It has, first of all, it
has the GitHub actions

716
00:34:09,990 --> 00:34:12,390
and it has the GitHub access runner

717
00:34:12,390 --> 00:34:14,640
and it has the Jenkins agent.

718
00:34:14,640 --> 00:34:16,620
That's because we are
now in the transition

719
00:34:16,620 --> 00:34:19,720
from Jenkins to GitHub
actions more and more

720
00:34:20,820 --> 00:34:22,290
per team, per those cells.

721
00:34:22,290 --> 00:34:25,503
So each image has
support for both of them.

722
00:34:26,460 --> 00:34:28,770
To make that decision
which one is being used,

723
00:34:28,770 --> 00:34:31,560
we actually coded our
own little agent called

724
00:34:31,560 --> 00:34:34,860
the coco agent, which is our
own little scripting code

725
00:34:34,860 --> 00:34:37,680
as well, that it looks at
the metadata and then knows,

726
00:34:37,680 --> 00:34:41,040
oh, I belong to this team,
this team uses Jenkins,

727
00:34:41,040 --> 00:34:44,010
the Jenkins controller
is in this IP address.

728
00:34:44,010 --> 00:34:46,020
I'm going to connect this there.

729
00:34:46,020 --> 00:34:49,860
Or is it GitHub actions runner, it knows,

730
00:34:49,860 --> 00:34:52,260
oh, this team is actually
using the runner,

731
00:34:52,260 --> 00:34:55,860
let's connect to the github.com
to actually get the jobs

732
00:34:55,860 --> 00:34:58,233
and add the machines into the queue.

733
00:34:59,490 --> 00:35:02,790
Also into the image we have
built, of course, Xcode.

734
00:35:02,790 --> 00:35:06,270
We have all the other command
line tools there as well

735
00:35:06,270 --> 00:35:08,820
and any other default tooling you need

736
00:35:08,820 --> 00:35:11,130
to do the signing and so on.

737
00:35:11,130 --> 00:35:13,840
And of course, we have
the mise-en-pace in there

738
00:35:13,840 --> 00:35:16,650
that the teams themselves can customize

739
00:35:16,650 --> 00:35:20,793
whatever they want at the
runtime point as well.

740
00:35:22,080 --> 00:35:25,593
So that's what's in here and
how does this all get built?

741
00:35:27,897 --> 00:35:29,250
The Supercell Developer Services,

742
00:35:29,250 --> 00:35:31,170
which is the team taking care

743
00:35:31,170 --> 00:35:33,450
of the running of this environment,

744
00:35:33,450 --> 00:35:35,640
they use GitHub access themself

745
00:35:35,640 --> 00:35:38,973
with the Packer to the
build the Tart VM images.

746
00:35:40,110 --> 00:35:43,680
Those VM images are then saved on EFS,

747
00:35:43,680 --> 00:35:46,794
the Elastic File Storage, which is mounted

748
00:35:46,794 --> 00:35:51,794
to the EC2 Mac instance
itself on the base layer macOS

749
00:35:53,100 --> 00:35:55,440
and that's how the Tart can quickly switch

750
00:35:55,440 --> 00:35:57,690
between any kind of Xcode versions,

751
00:35:57,690 --> 00:36:00,060
macOS versions, et cetera, et cetera.

752
00:36:00,060 --> 00:36:02,700
We have all of those different variations,

753
00:36:02,700 --> 00:36:05,910
different combinations
built on the EFS storage,

754
00:36:05,910 --> 00:36:08,703
allowing us to quickly take them into use.

755
00:36:09,810 --> 00:36:12,840
Some scripts are stored in S3 as well.

756
00:36:12,840 --> 00:36:14,730
And what's kind of unique for us as well

757
00:36:14,730 --> 00:36:17,250
is that what you don't see
in this picture at all,

758
00:36:17,250 --> 00:36:20,430
and it's actually missing, is
we don't have any EBS volume

759
00:36:20,430 --> 00:36:24,240
other than the AMI locked into this,

760
00:36:24,240 --> 00:36:27,600
because we use the local NVME storage

761
00:36:27,600 --> 00:36:31,020
as the disk for the Tart VMs as well.

762
00:36:31,020 --> 00:36:32,880
We could use EBS for it,

763
00:36:32,880 --> 00:36:35,463
but we actually found that the EC2 Mac,

764
00:36:36,751 --> 00:36:39,270
the NVME is really, really high performing

765
00:36:39,270 --> 00:36:42,390
and as Vishal said, it is comes for free,

766
00:36:42,390 --> 00:36:44,400
so why not use it as well?

767
00:36:44,400 --> 00:36:48,120
So we're taking the full
advantage of that local NVME

768
00:36:48,120 --> 00:36:50,170
to make the builds really, really snappy.

769
00:36:51,660 --> 00:36:55,350
We also use the parameter
store to store any secrets,

770
00:36:55,350 --> 00:36:58,200
like how do you sign the applications,

771
00:36:58,200 --> 00:37:00,000
because all of our games are mobile games,

772
00:37:00,000 --> 00:37:03,480
so all the time, we need to
sign them officially as well.

773
00:37:03,480 --> 00:37:07,050
And also none of the
people have direct access

774
00:37:07,050 --> 00:37:09,720
into the EC2 Mac or even the Tart VM.

775
00:37:09,720 --> 00:37:13,770
I said we are running the
Tart VM on top of a macOS

776
00:37:13,770 --> 00:37:15,450
and we do need to sometimes go

777
00:37:15,450 --> 00:37:18,030
with the VNC inside the Tart VM

778
00:37:18,030 --> 00:37:20,730
and how we achieve that
is that we actually use

779
00:37:20,730 --> 00:37:24,570
the system manager to tunnel ourselves in

780
00:37:24,570 --> 00:37:25,860
into the macOS itself.

781
00:37:25,860 --> 00:37:28,470
So nothing is exposed
to the outside world.

782
00:37:28,470 --> 00:37:31,950
You have to have AWS
access and you have to have

783
00:37:31,950 --> 00:37:36,060
the permissions given to
you through the SSM and IAM

784
00:37:36,060 --> 00:37:38,613
to be able to even connect
to the machine itself.

785
00:37:39,990 --> 00:37:43,770
So this is how we run overall
the whole infrastructure.

786
00:37:43,770 --> 00:37:45,800
And we do use the CloudWatch logs

787
00:37:45,800 --> 00:37:48,480
and the CloudWatch metrics
to get basic stuff out.

788
00:37:48,480 --> 00:37:52,590
But on top of that, our guys
in the Developer Services

789
00:37:52,590 --> 00:37:55,770
are also using Telegraf and Open Telemetry

790
00:37:55,770 --> 00:37:57,930
to get really detailed tracing

791
00:37:57,930 --> 00:38:00,750
of how long does each
stage of the build take

792
00:38:00,750 --> 00:38:03,390
and what kind of things
happen there as well.

793
00:38:03,390 --> 00:38:06,300
And that is something we
have developed in-house.

794
00:38:06,300 --> 00:38:09,270
So we are using both CloudWatch

795
00:38:09,270 --> 00:38:11,040
and we are using Grafana Prometheus

796
00:38:11,040 --> 00:38:15,240
to kinda have our own metrics as well.

797
00:38:15,240 --> 00:38:18,660
And this is how we run
majority of the build farm now

798
00:38:18,660 --> 00:38:23,340
for building our games for
iPhone, for iPad and so on,

799
00:38:23,340 --> 00:38:25,740
is run by this Auto Scaling Group.

800
00:38:25,740 --> 00:38:29,100
There are some standalone machines as well

801
00:38:29,100 --> 00:38:30,840
for really, really corner cases

802
00:38:30,840 --> 00:38:34,080
where they actually need to
get the hardware directly.

803
00:38:34,080 --> 00:38:38,670
For example, if they need the
GPU, we cannot use the Tart VM

804
00:38:38,670 --> 00:38:42,060
because GPUs are not exposed directly

805
00:38:42,060 --> 00:38:43,620
into the virtual machine itself.

806
00:38:43,620 --> 00:38:47,793
So we have some cases of even
standalone machines as well.

807
00:38:50,790 --> 00:38:53,520
So after we got this solution running,

808
00:38:53,520 --> 00:38:57,300
our house, our life after
the zombie apocalypse

809
00:38:57,300 --> 00:39:00,720
was dealt with, we did
manage to escape basement.

810
00:39:00,720 --> 00:39:04,020
I think we only have
few of those Intel Macs

811
00:39:04,020 --> 00:39:08,310
still running in there for
some really old build shops,

812
00:39:08,310 --> 00:39:12,390
because we still have some developers

813
00:39:12,390 --> 00:39:15,120
who still believe in the
Intel MacBook pros as well.

814
00:39:15,120 --> 00:39:17,550
So we kind have to still have couple

815
00:39:17,550 --> 00:39:20,460
of Intel-based builders
just for those guys

816
00:39:20,460 --> 00:39:22,620
until we can convince them to move

817
00:39:22,620 --> 00:39:24,423
towards the Apple Silicon as well.

818
00:39:25,500 --> 00:39:27,120
We do use the Auto Scaling Group

819
00:39:27,120 --> 00:39:30,870
so we have now an automation
that every weekend,

820
00:39:30,870 --> 00:39:33,150
we shed the load, we scale down

821
00:39:33,150 --> 00:39:35,970
to minimum number of machines as well

822
00:39:35,970 --> 00:39:38,490
and then on Monday or actually nowadays,

823
00:39:38,490 --> 00:39:40,320
bit also on the Sunday side,

824
00:39:40,320 --> 00:39:44,220
we start scaling up the fleet of builders.

825
00:39:44,220 --> 00:39:47,973
So we can get some cost
optimization into play as well.

826
00:39:50,100 --> 00:39:52,050
At least our IT is really aesthetic,

827
00:39:52,050 --> 00:39:55,050
because they don't have to go
to the basement anymore at all

828
00:39:55,050 --> 00:39:58,770
and go and give some
daylight into the Macs

829
00:39:58,770 --> 00:40:02,010
and switch the cable around
and now it works type of thing.

830
00:40:02,010 --> 00:40:04,050
So we actually reduced

831
00:40:04,050 --> 00:40:06,360
the operational overhead significantly.

832
00:40:06,360 --> 00:40:09,840
There used to be like
multiple guys from IT

833
00:40:09,840 --> 00:40:12,780
just going downstairs
to do the physical work

834
00:40:12,780 --> 00:40:14,550
on fixing the Macs.

835
00:40:14,550 --> 00:40:17,100
Now we just have basically one person

836
00:40:17,100 --> 00:40:22,100
in taking care of the whole
thousands of machines on AWS,

837
00:40:22,260 --> 00:40:24,810
which is a really, really
good improvement as well.

838
00:40:26,250 --> 00:40:28,020
And in terms of numbers, I don't have

839
00:40:28,020 --> 00:40:30,330
as detailed numbers as Miranda had,

840
00:40:30,330 --> 00:40:34,110
but even for us, we now
have 10x more build shops

841
00:40:34,110 --> 00:40:36,840
than before taking this solution into use.

842
00:40:36,840 --> 00:40:39,060
But we only had three times

843
00:40:39,060 --> 00:40:41,790
the number of Macs needed as well.

844
00:40:41,790 --> 00:40:46,080
So that is a really,
really good, good result,

845
00:40:46,080 --> 00:40:47,280
at least from our point of view.

846
00:40:47,280 --> 00:40:50,643
And also considering that one
person is maintaining this.

847
00:40:53,068 --> 00:40:56,130
We used to have 150 build shops per day

848
00:40:56,130 --> 00:40:59,550
on max in the basement in the zombieland

849
00:40:59,550 --> 00:41:00,870
and nowadays in the cloud,

850
00:41:00,870 --> 00:41:05,040
we have over 1,800 builds happening daily.

851
00:41:05,040 --> 00:41:07,680
So as you can see, there's
quite a lot of growth

852
00:41:07,680 --> 00:41:11,220
that we were able to
achieve with this solution.

853
00:41:11,220 --> 00:41:13,740
And also now we can, a lot quicker, take,

854
00:41:13,740 --> 00:41:15,000
which is not on the list here,

855
00:41:15,000 --> 00:41:16,813
but we can take new EC2, not EC2

856
00:41:17,817 --> 00:41:19,950
but we can take new versions of the macOS

857
00:41:19,950 --> 00:41:21,960
into use quite quickly as well,

858
00:41:21,960 --> 00:41:23,640
because everything is virtualized,

859
00:41:23,640 --> 00:41:26,280
so we can, even without updating

860
00:41:26,280 --> 00:41:28,500
the underlying MAC host itself,

861
00:41:28,500 --> 00:41:30,450
we can, in the Tart VM, already switch

862
00:41:30,450 --> 00:41:33,960
to the latest and
greatest version of macOS,

863
00:41:33,960 --> 00:41:37,473
even before the official
AMI is released as well.

864
00:41:39,540 --> 00:41:41,580
So what did we learn in this journey

865
00:41:41,580 --> 00:41:43,383
in the last two to three years?

866
00:41:44,280 --> 00:41:47,430
In the beginning back in 2023,

867
00:41:47,430 --> 00:41:50,820
a lot of this stuff was
completely undocumented.

868
00:41:50,820 --> 00:41:54,900
There was no prior
experience on how to use the-

869
00:41:54,900 --> 00:41:57,030
Well, there was some
experience on the EC2 Mac,

870
00:41:57,030 --> 00:41:59,910
but because we wanted to
do the virtualization,

871
00:41:59,910 --> 00:42:03,210
that was more or less no documentation.

872
00:42:03,210 --> 00:42:06,150
So there was a lot of trial
and error of figuring out

873
00:42:06,150 --> 00:42:10,413
how the Tart VMs worked
in production as well.

874
00:42:11,940 --> 00:42:16,200
Also, as I said, the macOS,
Apple can always give us

875
00:42:16,200 --> 00:42:18,540
a really, really, a lot of curve balls

876
00:42:18,540 --> 00:42:21,720
in terms of the macOS updates as well.

877
00:42:21,720 --> 00:42:25,057
So when we try the new version,
that has crippled like,

878
00:42:25,057 --> 00:42:28,140
"Oh, there's a new security
feature that we have to glow

879
00:42:28,140 --> 00:42:31,857
and click on every machine
to enable it as well."

880
00:42:33,660 --> 00:42:36,720
And it has helped us that
we have worked closely

881
00:42:36,720 --> 00:42:39,930
with Vishal and our AWS account team

882
00:42:39,930 --> 00:42:42,720
to plan out our capacity as well.

883
00:42:42,720 --> 00:42:46,500
We are mostly European-based
with some studios also

884
00:42:46,500 --> 00:42:49,320
in Shanghai and also in North America.

885
00:42:49,320 --> 00:42:52,200
It has helped us immensely
to communicate clearly that,

886
00:42:52,200 --> 00:42:55,290
oh, we're going to need this
many Mac machines as well.

887
00:42:55,290 --> 00:42:57,843
So that has helped us to go forward,

888
00:42:59,280 --> 00:43:04,280
but overall, we can say
that it's not cheap solution

889
00:43:05,820 --> 00:43:07,107
and overall, the EC2 Mac

890
00:43:07,107 --> 00:43:10,200
are not the cheapest
instance types available.

891
00:43:10,200 --> 00:43:12,600
First off, being
dedicated host, of course,

892
00:43:12,600 --> 00:43:15,660
but neither is the manual
work we were doing downstairs.

893
00:43:15,660 --> 00:43:17,400
I said we went for, let's say,

894
00:43:17,400 --> 00:43:19,110
five to seven people maintaining

895
00:43:19,110 --> 00:43:20,423
this environment in the basement

896
00:43:20,423 --> 00:43:23,430
to just one-and-a-half
people basically maintaining

897
00:43:23,430 --> 00:43:26,550
this bigger environment into the cloud.

898
00:43:26,550 --> 00:43:31,140
So for us overall, it was
still a win-win situation

899
00:43:31,140 --> 00:43:36,030
and it had a huge impact
and unlocked a lot of things

900
00:43:36,030 --> 00:43:38,820
in the game teams themselves
to be able to develop faster,

901
00:43:38,820 --> 00:43:41,373
try new things faster as well.

902
00:43:45,150 --> 00:43:48,660
And then let's look at what
is the future bringing us

903
00:43:48,660 --> 00:43:50,640
beyond the zombie apocalypse.

904
00:43:50,640 --> 00:43:52,200
So what are we building next?

905
00:43:52,200 --> 00:43:54,480
We are really excited of the new M4s

906
00:43:54,480 --> 00:43:57,810
and the two terabyte local NVMEs,

907
00:43:57,810 --> 00:44:00,660
because it allows us to
make the images bigger.

908
00:44:00,660 --> 00:44:05,660
The old machines had 256 gigabytes of disc

909
00:44:06,180 --> 00:44:09,450
and if you look at any kind
of modern game building,

910
00:44:09,450 --> 00:44:11,130
luckily, we're a mobile game company,

911
00:44:11,130 --> 00:44:12,360
we can still fit into that,

912
00:44:12,360 --> 00:44:14,850
but I would imagine a
lot of like Riot Games,

913
00:44:14,850 --> 00:44:17,100
they're not going to fit into 256 gigs

914
00:44:17,100 --> 00:44:19,440
to build anything at all.

915
00:44:19,440 --> 00:44:20,940
She's shaking her head.

916
00:44:20,940 --> 00:44:22,620
So we're kinda lucky
with the mobile games,

917
00:44:22,620 --> 00:44:26,040
they're reasonably smaller
than your average PC game

918
00:44:26,040 --> 00:44:28,710
or console game as well.

919
00:44:28,710 --> 00:44:31,500
But we're still looking
forward for the two terabytes,

920
00:44:31,500 --> 00:44:33,930
because that would unlock
us, for the first time,

921
00:44:33,930 --> 00:44:38,220
to run two VMs per physical EC2 Mac.

922
00:44:38,220 --> 00:44:41,610
So we're basically going to
be able to double our capacity

923
00:44:41,610 --> 00:44:45,783
without any extra cost as well
using the VM approach here.

924
00:44:47,190 --> 00:44:49,440
What we don't have right now as well

925
00:44:49,440 --> 00:44:52,050
is we don't have fully
dynamic auto scaling.

926
00:44:52,050 --> 00:44:54,330
Right now, it's basically on calendar,

927
00:44:54,330 --> 00:44:55,830
so it knows that every Monday,

928
00:44:55,830 --> 00:44:57,540
it must scale up to this number

929
00:44:57,540 --> 00:44:59,940
and every Friday, it has to scale down.

930
00:44:59,940 --> 00:45:02,070
But in the future, we will have,

931
00:45:02,070 --> 00:45:05,130
through the coco agent
that was shown there,

932
00:45:05,130 --> 00:45:09,750
we will have dynamic following
of the size of the queues.

933
00:45:09,750 --> 00:45:12,150
So we'll be able to automatically,

934
00:45:12,150 --> 00:45:14,040
with our own little coordinator tool,

935
00:45:14,040 --> 00:45:17,610
to deploy new machines
and retire them quickly

936
00:45:17,610 --> 00:45:21,963
if the queue size of the
builds is at zero for example.

937
00:45:22,966 --> 00:45:26,220
And in general, this has also now unlocked

938
00:45:26,220 --> 00:45:27,600
the people to do more work

939
00:45:27,600 --> 00:45:30,780
on the actual improvement
of the pipelines themselves

940
00:45:30,780 --> 00:45:33,510
instead of trying to do the
troubleshooting day to day

941
00:45:33,510 --> 00:45:34,470
on the fleet as well.

942
00:45:34,470 --> 00:45:36,960
So there will be better pipelines coming

943
00:45:36,960 --> 00:45:38,880
and we going to be now be able to extend

944
00:45:38,880 --> 00:45:41,250
with all the automation
in place, the Terraforms,

945
00:45:41,250 --> 00:45:43,470
the Packers and all this stuff,

946
00:45:43,470 --> 00:45:47,700
we can now easily expand
it to new regions as well.

947
00:45:47,700 --> 00:45:50,790
For example, we are now
deploying it in US as well,

948
00:45:50,790 --> 00:45:54,660
because we have couple of
game teams now based in US

949
00:45:54,660 --> 00:45:57,810
in Seattle and and Los Angeles.

950
00:45:57,810 --> 00:46:00,990
We can now quickly, with the
already built Terraforms,

951
00:46:00,990 --> 00:46:04,590
just bring up the whole
environment for them in US as well

952
00:46:04,590 --> 00:46:08,523
that they can have quick
and snappy builds in US.

953
00:46:12,150 --> 00:46:14,797
So lastly, on the zombie team, it's like,

954
00:46:14,797 --> 00:46:16,590
"They're coming for you, Barbara,"

955
00:46:16,590 --> 00:46:20,760
so if you're not careful,
the zombie apocalypse

956
00:46:20,760 --> 00:46:22,590
can also happen to you
if you're still stuck

957
00:46:22,590 --> 00:46:27,590
on your Intel Mac somewhere
in the basement or closet,

958
00:46:28,860 --> 00:46:31,833
hiding in the dark corners of the world.

959
00:46:33,060 --> 00:46:35,520
Excellent, I'm going to
actually hand it back to Vishal

960
00:46:35,520 --> 00:46:39,210
and he's going to tell you
more about what else is coming

961
00:46:39,210 --> 00:46:41,730
in terms of the EC2 Mac presentations,

962
00:46:41,730 --> 00:46:43,710
but other than that, you survived

963
00:46:43,710 --> 00:46:46,938
the zombie apocalypse
with me and thank you.

964
00:46:46,938 --> 00:46:49,830
(audience clapping)

965
00:46:49,830 --> 00:46:51,000
- Thank you.

966
00:46:51,000 --> 00:46:55,500
(audience clapping continues)

967
00:46:55,500 --> 00:46:56,333
Awesome.

968
00:47:01,830 --> 00:47:03,210
Before we wrap up here guys,

969
00:47:03,210 --> 00:47:05,430
thank you so much for spending
time with us here today.

970
00:47:05,430 --> 00:47:08,490
Thank you to Toni and
Miranda for working with me

971
00:47:08,490 --> 00:47:09,780
through the multiple months that we've had

972
00:47:09,780 --> 00:47:11,160
to put this together.

973
00:47:11,160 --> 00:47:13,380
Before I let you guys go,
I did want to tell you

974
00:47:13,380 --> 00:47:15,000
what else to expect at re:Invent

975
00:47:15,000 --> 00:47:18,210
for EC2 Mac and just macOS in general.

976
00:47:18,210 --> 00:47:21,840
So first thing is, as I've
hinted, please make sure

977
00:47:21,840 --> 00:47:25,620
to not miss our AWS
CEO's keynote tomorrow.

978
00:47:25,620 --> 00:47:29,010
Matt Garman will be speaking,
I believe, at around 8:00 AM

979
00:47:29,010 --> 00:47:31,230
up until 10:30, so please tune in

980
00:47:31,230 --> 00:47:35,550
for some exciting news on EC2
Mac during his presentations.

981
00:47:35,550 --> 00:47:37,470
Secondly, we do have a few sessions

982
00:47:37,470 --> 00:47:38,700
that I wanted to call out

983
00:47:38,700 --> 00:47:40,530
and make sure that they're on your radar.

984
00:47:40,530 --> 00:47:43,680
So the first one is going to be actually

985
00:47:43,680 --> 00:47:46,800
on Wednesday, the third.

986
00:47:46,800 --> 00:47:51,800
The ID is CMP 306 and that
one is actually going to be

987
00:47:51,840 --> 00:47:54,210
a hands-on workshop where you
guys can actually play around

988
00:47:54,210 --> 00:47:56,370
with a lot of the features
that we talked about today,

989
00:47:56,370 --> 00:48:00,120
such as system integrity
protection, replace root volume.

990
00:48:00,120 --> 00:48:02,310
And so super excited to
actually get your laptops out

991
00:48:02,310 --> 00:48:03,690
and actually play around with that

992
00:48:03,690 --> 00:48:07,080
and two of my colleagues will
be presenting that as well.

993
00:48:07,080 --> 00:48:08,880
On the same day, we have another session

994
00:48:08,880 --> 00:48:12,900
that's called CMP 346 and this
one is actually really cool,

995
00:48:12,900 --> 00:48:14,100
'cause it's the first time
we're gonna be talking

996
00:48:14,100 --> 00:48:17,640
about how we can do ML and
inference using EC2 Mac

997
00:48:17,640 --> 00:48:21,210
and the amazing GPU power
that comes with Apple Silicon

998
00:48:21,210 --> 00:48:23,430
and some of my colleagues

999
00:48:23,430 --> 00:48:24,263
are going to be presenting
on that as well.

1000
00:48:24,263 --> 00:48:25,740
It's the first time that we're going

1001
00:48:25,740 --> 00:48:28,470
to be talking about running actual ML

1002
00:48:28,470 --> 00:48:30,750
and inference workloads
using Apple Silicon chips.

1003
00:48:30,750 --> 00:48:32,220
So make sure not to miss that.

1004
00:48:32,220 --> 00:48:33,540
Then if you want to see me again,

1005
00:48:33,540 --> 00:48:38,540
I'll be talking at CMP 344,
which is again on Wednesday.

1006
00:48:39,300 --> 00:48:41,280
And that is actually, me and my colleague

1007
00:48:41,280 --> 00:48:44,160
will actually go through
and actually do a live demo

1008
00:48:44,160 --> 00:48:48,150
on using EC2 Mac and GitHub
actions or GitLab CircleCI,

1009
00:48:48,150 --> 00:48:50,610
whatever automation tool that you guys use

1010
00:48:50,610 --> 00:48:52,050
and he'll actually be going through

1011
00:48:52,050 --> 00:48:56,230
and running an actual build
change using a live demo Xcode

1012
00:48:57,330 --> 00:48:58,980
to see how it actually runs on EC2 Mac

1013
00:48:58,980 --> 00:49:00,690
and you'll be able to see the live change

1014
00:49:00,690 --> 00:49:05,160
on his test flight app that
we'll be screen-sharing as well.

1015
00:49:05,160 --> 00:49:08,400
So three other sessions that
I encourage you guys to join

1016
00:49:08,400 --> 00:49:11,070
as well as Matt Garman's keynote tomorrow

1017
00:49:11,070 --> 00:49:13,110
and any of the other keynotes as well.

1018
00:49:13,110 --> 00:49:15,480
So with that being said,
I think a few of us

1019
00:49:15,480 --> 00:49:17,610
will hang around if
you have any questions,

1020
00:49:17,610 --> 00:49:19,080
but thank you so much for coming

1021
00:49:19,080 --> 00:49:21,510
and please make sure to
complete the session survey

1022
00:49:21,510 --> 00:49:23,634
in the app as well, thank you.

1023
00:49:23,634 --> 00:49:25,892
(audience clapping)

