# AWS re:Invent 2025 - Amazon S3 深度解析：高可用性设计

## 会议概述

本次会议由 Seth Markle 和 James Bournehol 主讲，深入探讨了 Amazon S3 如何在架构和实现层面设计高可用性系统。这是 S3 深度解析系列讲座的延续，前两年分别讲解了 S3 的基础原理和如何利用规模优势，今年的重点是可用性设计。

会议从两个视角展开：首先，Seth 从系统架构层面阐述了如何在设计中考虑故障处理，并以 S3 实现读后写一致性（read-after-write consistency）为例进行说明。其次，James 从服务器实现层面讲解了如何在代码层面处理各种故障模式。核心思想是通过基于 quorum 的算法、冗余设计、动态重配置等机制，确保在面对硬件故障、网络问题、负载过高等各种失败场景时，S3 仍能保持 99.99% 的可用性和强一致性保证。

S3 管理着跨 38 个区域、120 个可用区的数千万块硬盘和数百万台服务器，每秒处理数亿次请求，存储超过 500 万亿个对象。在如此大规模下实现高可用性，需要在架构设计、故障域隔离、一致性协议、故障检测和恢复等多个层面进行精心设计。

## 详细时间线与关键要点

### 开场与背景介绍
时间戳：开始
- Seth Markle 和 James Bournehol 介绍本次深度解析主题：Amazon S3 的高可用性设计
- 这是系列讲座的第三年，前两年分别讲解了 S3 基础和规模优势

### 定义可用性与故障
时间戳：约 1-3 分钟
- 可用性的核心是处理故障（dealing with failure）
- 需要定义两个概念：什么是故障，以及如何应对故障
- S3 的概念视图：存储超过 500 万亿个对象，数百 EB 数据，每秒数亿次请求
- S3 的物理视图：由磁盘、服务器、机架、建筑物组成，管理数千万块硬盘，分布在 120 个可用区、38 个区域

### 故障域的类型
时间戳：约 3-5 分钟
- 故障可能发生在多个层面：磁盘表面缺陷、单个驱动器失效、服务器故障、机架断电、建筑物火灾等
- 故障分为永久性损失和暂时性不可用（电源、网络、过载等问题）

### S3 的设计目标
时间戳：约 5-6 分钟
- 设计目标：99.99% 可用性、11 个 9 的持久性（99.999999999%）
- 提供读后写一致性（read-after-write consistency）
- 重要历史：S3 直到 2020 年才实现读后写一致性，之前允许在故障时违反一致性保证

### 索引子系统与 Quorum 算法
时间戳：约 6-10 分钟
- S3 的索引子系统保存所有对象的元数据（名称、标签、创建时间等）
- 每个数据平面请求（GET、PUT、LIST、HEAD、DELETE）都会访问索引
- 索引使用基于 quorum 的算法，数据跨多个副本存储
- Quorum 的核心规则：读写操作只需命中大多数服务器即可成功
- 副本分布在不同可用区，避免单一故障域的关联性

### Quorum 工作原理演示
时间戳：约 10-12 分钟
- 写入值 A：成功写入所有节点
- 写入值 B：一个节点失败，但仍在大多数节点上成功，无可用性影响
- 读取操作：即使一个服务器失败，仍能从其他节点读取最新值 B
- 通过时间戳进行冲突解决
- Quorum 的关键特性：多个节点可接收请求，允许部分失败

### 2020 年前的缓存设计问题
时间戳：约 12-15 分钟
- 在 2020 年一致性发布前，S3 使用缓存层来提高性能
- 问题：缓存节点之间没有重叠，导致不一致读取
- 示例：写入 C 通过一个缓存节点，但后续读取可能路由到另一个缓存节点，返回旧值 B
- 与 quorum 不同，缓存中的读写操作不重叠，因此无法保证一致性

### 复制日志（Replicated Journal）解决方案
时间戳：约 15-18 分钟
- 为实现一致性，构建了缓存一致性协议，使用复制日志
- 日志是分布式数据结构，节点链式连接，写入按顺序流经节点
- 每个写入分配递增的序列号，建立明确的顺序
- 存储节点学习序列号，缓存可以询问："此序列号之后是否有新写入？"

### Witness 系统
时间戳：约 18-20 分钟
- Witness 系统用于跟踪写入的高水位标记
- 简化假设：Witness 只需保存序列号，不需要保存实际数据
- Witness 可以保守估计（高估序列号），如果告知客户端数据过期，客户端会从存储读取
- Witness 是内存中的数据结构（整数数组），位于日志旁边
- 新的读写算法：写入经过日志和 Witness，读取先查询 Witness 判断缓存是否过期

### 动态重配置
时间戳：约 20-23 分钟
- 问题：日志链中的节点失败会导致整个系统停止（与 quorum 不同）
- 解决方案：引入动态重配置
- 节点持续监控彼此的可用性，发现问题时请求基于 quorum 的配置系统重新配置日志
- 重配置在节点失败后的毫秒级内完成
- 高可用性系统最终都依赖 quorum，即使在链式复制算法中也是如此

### 一致性发布的成果
时间戳：约 23-24 分钟
- 通过这些设计，S3 在 2020 年实现了读后写一致性
- 在保持高可用性的同时实现了强一致性
- 系统级可用性设计总结：需要多个服务器可选择，只需部分成功，能够快速重配置

### James 接手：实现层面的故障处理
时间戳：约 24-25 分钟
- James Bournehol 开始讲解服务器实现层面的故障设计
- 重点：节点本身如何处理故障

### 关联故障（Correlated Failures）
时间戳：约 25-28 分钟
- 故障不仅是单个节点失败，更重要的是关联故障
- 物理故障域：单个硬盘、整台服务器（所有硬盘同时不可用）、整个机架、整个可用区
- 逻辑故障域：软件部署批次（同一版本的服务器可能因 bug 同时失败）
- 设计关键：确保工作负载暴露在多个故障域中，避免所有副本在同一故障域

### 数据复制与故障域隔离
时间戳：约 28-30 分钟
- S3 将对象复制到多个可用区
- 复制不仅为了持久性（11 个 9），也为了可用性
- 即使一个可用区失败，数据仍在其他位置可用

### 故障的类型：Fail-Stop 故障
时间戳：约 30-33 分钟
- Fail-Stop 故障：最简单的故障类型，如电源断开
- 特点：服务器完全停止工作，易于检测和应对
- 但在网络组件（如交换机）中，fail-stop 可能表现为部分请求成功、部分失败
- 解决方案：冗余设计，多个交换机，可用区之间形成环形连接
- 如果直接链路失败，可以绕远路到达目标（将可用性问题转化为延迟问题）

### 崩溃一致性（Crash Consistency）
时间戳：约 33-36 分钟
- 在有状态系统中，fail-stop 故障会导致系统进入原本不可达的状态
- 示例：写入两行文本的程序，如果在中间崩溃，文件只有一行
- 崩溃一致性：系统在 fail-stop 故障后应返回一致状态
- ShardStore 论文讨论了如何在并发和故障情况下推理系统状态

### 灰色故障（Gray Failures）
时间戳：约 36-40 分钟
- 灰色故障：不是简单的电源故障，而是部分功能异常
- 示例：前端服务器接受请求，但无法到达部分下游存储节点
- 服务器在工作但不是有效工作，返回错误但未完全失败
- 难以检测，因为服务器未真正失败，只是行为异常

### 重试策略
时间戳：约 40-43 分钟
- 重试是应对灰色故障的强大机制
- 重试可能路由到不同的服务器，绕过有问题的节点
- AWS SDK 具有复杂的重试策略，会故意在不同 IP 地址上重试
- 但重试也有危险：在多层服务架构中，重试会指数级放大（如 3^3 = 27 倍）
- 解决方案：在服务栈的不同层级有意设计不同的重试策略，下层可能不重试或少重试

### 超时与负载故障
时间戳：约 43-45 分钟
- 当故障由负载引起时（服务器过载而非断开），表现为请求变慢
- 使用超时机制：客户端应在请求过慢时超时并重试到其他服务器
- 再次强调：希望重试到不同的服务器以避开过载节点

### 总结
时间戳：约 45 分钟后
- S3 通过多层次的设计实现高可用性：
  - 系统架构层：quorum 算法、复制日志、动态重配置
  - 实现层：故障域隔离、重试策略、超时机制
  - 将不同类型的故障转化为可管理的问题
- 最终实现 99.99% 可用性和强一致性的设计目标