# AWS re:Invent 2025 - LLM可观测性技术会议总结

## 会议概述

本次技术会议聚焦于大语言模型(LLM)的可观测性挑战与解决方案。演讲者来自Groundcover公司，深入探讨了在使用AWS Bedrock、OpenAI、Anthropic等LLM服务时面临的监控难题。随着AI应用从简单的单轮对话发展为复杂的多步骤代理、检索增强生成(RAG)管道和工具增强工作流，传统的监控方法已无法满足需求。

会议重点介绍了Groundcover基于eBPF技术和"自带云"架构的创新解决方案。该方案能够在不修改应用代码的情况下，实现对LLM应用的全面监控，包括令牌使用量、响应延迟、错误率和LLM响应质量等关键指标。通过将数据存储在客户自己的AWS环境中，确保了数据隐私和安全性，同时提供了SaaS级别的用户体验。

## 详细时间线与关键要点

### 0:00-2:30 - LLM可观测性的重要性
• 从简单的单轮查询发展为复杂的多步骤工作流
• 多轮代理、检索管道、工具增强等复杂场景
• 任何环节的静默失败都会影响整个流程

### 2:30-5:00 - 核心监控指标
• 令牌使用量: 与定价模型直接相关，需要持续监控
• 响应延迟: AI集成到生产API后，延迟问题会被放大
• 错误率: 模型结构问题或其他故障的及时发现
• LLM响应质量: 幻觉检测和响应正确性验证

### 5:00-7:30 - 当前挑战分析
• 技术栈变化速度: AI工具引入速度超过监控能力
• 数据敏感性: 用户输入可能包含敏感信息
• 50%的公司不确定生产环境中使用的具体模型
• 数据存储、处理和第三方依赖的合规性问题

### 7:30-10:00 - Groundcover解决方案架构
• 自带云架构: 在客户AWS账户中部署管理的可观测性后端
• eBPF技术: 内核级别的应用程序监控，无需代码修改
• 控制平面与数据平面分离，确保数据隐私
• 自动发现和即时监控新部署的AI应用

### 10:00-12:30 - 实时演示：基础监控
• Kubernetes集群中的服务依赖关系可视化
• Bedrock API调用的自动检测和监控
• 模型使用情况、延迟和吞吐量的实时统计
• 无需任何代码修改即可获得完整的AI监控能力

### 12:30-15:00 - 实时演示：深度分析
• 完整的请求-响应链路追踪
• 提示词和响应内容的详细查看
• 令牌使用量和原始请求数据的展示
• 与日志、基础设施监控的关联分析
• 错误场景的详细故障排查

### 15:00-17:30 - 高级功能展示
• P90延迟分析和模型性能对比
• 令牌使用量的跨模型统计分析
• SLA违规的自动检测和告警设置
• 自定义仪表板和监控指标的创建
• 生产环境的实时监控和业务价值关联

### 17:30-17:50 - 总结与资源
• eBPF传感器30秒内完成生产环境覆盖
• play.groundcover.com提供在线演示环境
• 现场展台提供进一步技术交流机会