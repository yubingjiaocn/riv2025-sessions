# AWS re:Invent 2025 - Amazon S3 Tables 会议总结

## 会议概述

本次会议由AWS S3团队的产品经理Adita Kalan Krishnan (Adi)主持,联合Indeed公司数据平台高级经理Min Lee和AWS S3首席工程师Yuri Zarubin共同演讲。会议重点介绍了Amazon S3 Tables在过去一年中的重大进展和新功能发布。

S3 Tables是AWS在去年re:Invent大会上推出的服务,允许客户直接在S3中创建完全托管的Apache Iceberg表。该服务专为大规模存储表格数据而设计,提供优化的性能和规模,并通过自动表维护持续优化表的性能和成本。在过去一年中,S3 Tables取得了显著增长,客户已创建超过40万张表,并在32个AWS区域可用,单个账户可支持多达10万张表。

会议重点介绍了三项最新发布的核心能力:Iceberg V3规范支持、智能分层存储(Intelligent Tiering)以及S3 Tables复制功能。此外,Indeed公司分享了其将85 PB数据湖迁移到S3 Tables的实践经验,展示了在数据治理、生产力提升和成本优化方面取得的显著成效。这些新功能和客户案例充分证明了S3 Tables正在成为AWS客户构建数据湖的核心基础设施。

## 详细时间线与关键要点

### 开场介绍 (0:00-2:30)
- **0:00** - 会议开始,Adi介绍演讲团队成员
- **1:15** - 介绍会议议程:S3 Tables概述、过去一年的发布更新、三项新功能深入讲解、Indeed迁移案例分享、最佳实践和演示

### S3 Tables产品概述 (2:30-5:00)
- **2:30** - 回顾S3 Tables核心价值:完全托管的Apache Iceberg表、优化的性能和规模、简化的安全控制、自动表维护
- **3:45** - 强调S3 Tables与AWS服务的深度集成:Glue数据目录、Athena、EMR、Kinesis Data Firehose、QuickSight等
- **4:30** - 介绍Iceberg REST目录接口,提供开放的访问方式

### 过去一年的功能发布回顾 (5:00-7:30)
- **5:00** - 展示过去一年的快速迭代成果
- **5:30** - 性能和规模优化:高级压缩技术(sort和z-order)、扩展到32个AWS区域、支持每账户10万张表
- **6:15** - 安全控制增强:表级KMS加密、基于资源标签的属性访问控制(ABAC)
- **6:45** - 开放性提升:Athena直接访问、SageMaker Unified Studio集成、合作伙伴工具支持(如DuckDB)
- **7:15** - 客户采用情况:已创建超过40万张表

### 新功能一:Iceberg V3支持 (7:30-12:00)
- **7:30** - 宣布Iceberg V3功能正式可用
- **8:00** - 删除向量(Deletion Vectors)详解:
  - 传统V2方式:每次删除操作创建位置删除文件(小型Parquet文件),随时间累积导致查询性能下降
  - V3改进:将删除信息整合到单个Puffin文件的位图向量中,查询引擎可快速识别已删除数据
  - 附加优势:减少压缩处理需求,提高成本效益
- **10:00** - 行血缘(Row Lineage)详解:
  - 每行添加行ID和序列号字段
  - 可追踪表中行的变化历史
  - 支持使用SQL直接查询数据变更
- **11:15** - SageMaker Unified Studio集成:一键从S3控制台访问笔记本环境,支持SQL、Python和自然语言查询

### 新功能二:智能分层存储 (12:00-18:30)
- **12:00** - 宣布智能分层存储功能(周二Matt Garman主题演讲中发布)
- **12:30** - 核心价值:表存储成本最高可节省80%
- **13:00** - 客户面临的三大挑战:
  1. 数据量持续增长需要成本优化
  2. 不想手动管理生命周期策略
  3. 避免维护操作意外提升存储成本
- **14:00** - 工作原理:
  - 三个访问层级:频繁访问层(起始层)→ 非频繁访问层(30天无访问后,成本降低40%)→ 归档即时访问层(再60天无访问后,成本再降低68%)
  - 文件级粒度:同一表内可有不同访问层级的数据
  - 自动优化访问模式变化:数据被访问时自动回到频繁访问层,无性能下降,无检索费用
- **16:00** - 表维护感知特性(关键创新):
  - 压缩、快照过期、未引用文件删除等维护操作读取的文件不会触发层级变更
  - 压缩仅在频繁访问层的活跃数据上运行,优化投资回报
  - 冷数据保持在低成本层级,不受维护操作影响
- **17:30** - 配置方式:创建表时设置存储类为智能分层,或在存储桶级别设置默认存储类

### 客户案例:Zeta Global (18:30-19:30)
- **18:30** - Zeta Global使用S3 Tables作为PB级lakehouse基础,包含数千张Iceberg表
- **19:00** - 成果:数据新鲜度延迟降低近80%,洞察时间从15分钟压缩到几分钟

### 客户案例:Indeed深度分享 (19:30-35:00)
- **19:30** - Min Lee上台介绍Indeed背景和使命:帮助人们找到工作
- **20:30** - 数据规模:85 PB数据湖、超过15,000个数据集、每天17万次查询、每天摄入550 TB新数据
- **21:30** - 展示复杂的数据湖架构:数百个AWS账户、多种技术栈、多种摄入模式、多种查询引擎(Athena、Trino、Spark、Snowflake)
- **23:00** - 迁移到Iceberg的原因:
  1. 互操作性:同一数据支持多种引擎
  2. 性能优势:更好的元数据处理和分区能力,查询更快、计算成本更低
  3. 高级功能:模式演进、时间旅行、回滚
- **24:30** - 采用S3 Tables前的四大挑战:
  1. 运维负担:每年花费2000+开发小时维护基于Spark的Iceberg维护作业
  2. 客户入驻缓慢:每个团队入驻需要超过1天,有350+团队需要入驻
  3. 访问不可靠:高峰期遇到S3读取限制,导致多次SEV1和SEV2事故
  4. 访问控制复杂:基于S3对象标签的方法缓慢、昂贵且难以审计
- **26:30** - 迁移到S3 Tables的业务影响:
  1. 简化数据治理:重新分类6亿个S3对象从数周缩短到几分钟
  2. 提高生产力:团队入驻时间从1天减少到10分钟以内
  3. 降低云成本:年度AWS成本节省超过10%
  4. 释放平台团队:每年节省2000开发小时(4个开发月)
- **28:00** - 三阶段迁移方法:
  1. 审计和优先级排序:分析查询日志,识别关键业务工作负载
  2. 增量迁移:构建双写管道,从Hive转换到S3 Tables中的Iceberg,无用户中断
  3. 自动化和优化:新数据集默认直接迁移到S3 Tables的Iceberg格式
- **29:30** - 迁移策略详解:
  - 86 PB数据分为两个主要阶段
  - 阶段1:67 PB Hive ORC格式迁移到Iceberg Parquet
  - 阶段2:19 PB已有Iceberg数据从通用S3桶迁移到S3 Tables
  - 进一步细分为多个批次,首先迁移未被自定义Spark应用访问的表
  - 从少量POC数据集开始,然后是10 PB生产批次,逐步推进
- **31:30** - 经验教训:
  1. 简化访问控制:使用S3 Tables资源策略替代数十亿对象标签
  2. 准备Lake Formation权限:访问通过Lake Formation管理而非标准IAM策略
  3. 主动审计和更新查询模式:重构依赖自定义插件或优化的查询
- **33:00** - 实际业务影响数据(来自Indeed MDNA团队):
  - Hiring Insights团队:报告速度提升75%
  - Smart Sourcing团队:成本降低65%
  - Indeed Interviews团队:复杂度降低88%
  - Partner Analytics团队:SLO改善98%

### 最佳实践指南 (35:00-42:00)
- **35:00** - Yuri开始分享最佳实践
- **35:30** - 分区策略:
  - 选择正确的分区对查询性能和成本至关重要
  - 两种常见方案:基于时间的分区(适合应用日志)、哈希桶分区(适合基于客户ID查询)
  - Iceberg支持后期更改分区方案,不是单向门决策
  - 建议:深入思考查询模式,做出最优分区决策
- **37:00** - 压缩设置:
  - 目标文件大小:建议保持默认值
  - 四种压缩模式:auto、bin-pack、sort、z-order
  - 建议:大多数客户保持auto模式(有排序顺序时使用sort,否则使用bin-pack)
  - 考虑z-order:当查询在多个列上过滤时(如产品表按大小、类型、位置过滤)
- **38:30** - 快照过期:
  - 最大快照数量:保持默认120个
  - 最大快照年龄:
    - 批处理ETL工作负载:保持3天默认值
    - 流式工作负载:强烈建议减少到24小时或更少
  - 原因:高频流式工作负载每分钟提交一次,快照数量可达数千,根元数据文件膨胀到数十至数百MB,严重影响读写性能
- **40:00** - 未引用文件删除:
  - 通过清理失败提交节省存储成本
  - 建议:保持3天默认值
  - 特殊情况:工作负载频繁失败时可考虑减少,但优先修复失败原因
- **41:00** - 最佳实践总结回顾

### 新功能三:S3 Tables复制 (42:00-48:00)
- **42:00** - 宣布S3 Tables复制功能
- **42:30** - 复制的三大原因:
  1. 性能:将数据复制到靠近查询位置(如新加坡数据科学家访问弗吉尼亚数据)
  2. 合规性:受监管行业(医疗、金融)的冗余要求
  3. 数据保护:防止意外删除或恶意覆盖
- **43:30** - 传统方案的问题:
  - 使用S3复制:元数据文件需要重写(包含源区域特定路径)、表维护不同步、需要手动协调
  - 自建解决方案:需要构建和维护复杂的复制管道
- **44:30** - S3 Tables复制的优势:
  - 完全托管:AWS处理所有复制逻辑
  - 元数据自动重写:目标表元数据自动更新为正确路径
  - 表维护同步:源表和目标表的维护操作协调一致
  - 简单配置:通过控制台、CLI或API启用
- **46:00** - 复制模式:
  - 持续复制:实时同步变更
  - 一次性复制:创建时间点副本
- **47:00** - 使用场景示例:灾难恢复、多区域分析、数据本地化

### 演示:使用DuckDB构建自然语言接口 (48:00-53:00)
- **48:00** - Yuri开始演示
- **48:30** - 演示目标:展示如何轻松使用S3 Tables构建应用
- **49:00** - 技术栈:
  - DuckDB:轻量级分析数据库,支持Iceberg REST目录
  - Claude(Anthropic):大语言模型,将自然语言转换为SQL
  - Python:粘合代码
- **50:00** - 演示流程:
  1. 用户用自然语言提问(如"显示销售额最高的前10个产品")
  2. Claude将问题转换为SQL查询
  3. DuckDB通过Iceberg REST目录接口查询S3 Tables
  4. 返回结果并可视化
- **51:30** - 关键要点:
  - 无需复杂设置
  - DuckDB原生支持Iceberg REST目录
  - 几行代码即可实现自然语言查询界面
- **52:30** - 演示成功完成,展示查询结果

### 总结与问答 (53:00-55:00)
- **53:00** - Adi总结会议要点:
  - Iceberg V3支持提供更高效的数据修改和追踪
  - 智能分层存储最高节省80%存储成本
  - S3 Tables复制简化多区域数据管理
  - Indeed案例证明大规模迁移的可行性和价值
- **54:00** - 邀请观众会后交流,团队将在会场内外回答问题
- **54:30** - 鼓励观众探索S3 Tables的新功能
- **55:00** - 会议结束