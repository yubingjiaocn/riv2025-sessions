1
00:00:01,890 --> 00:00:02,940
- [Vivek] Hi everyone.

2
00:00:02,940 --> 00:00:05,073
Good morning. Welcome to Vegas.

3
00:00:06,090 --> 00:00:08,400
Welcome to Advanced RAG Architectures.

4
00:00:08,400 --> 00:00:12,423
It's a 400-level talk.

5
00:00:13,440 --> 00:00:15,360
I'm Vivek Mittal.

6
00:00:15,360 --> 00:00:17,400
I am AWS solution architect,

7
00:00:17,400 --> 00:00:21,120
being here with AWS for around
three and a half years now

8
00:00:21,120 --> 00:00:23,100
and based out of Tampa.

9
00:00:23,100 --> 00:00:26,220
I'm part of AI/ML specialist group

10
00:00:26,220 --> 00:00:30,690
and my focus area is building
applications using RAG

11
00:00:30,690 --> 00:00:32,730
or retrieval-augmented generations.

12
00:00:32,730 --> 00:00:34,710
So that's where we are.

13
00:00:34,710 --> 00:00:36,960
I'll hand it over to
Pallavi, my co-speaker

14
00:00:36,960 --> 00:00:38,610
so that she can start the session.

15
00:00:38,610 --> 00:00:39,443
Thank you.

16
00:00:39,443 --> 00:00:42,570
- [Pallavi] Fantastic. Thank you Vivek.

17
00:00:42,570 --> 00:00:45,390
I should've done my speech
exercises this morning.

18
00:00:45,390 --> 00:00:48,360
Good morning everyone. How is
everyone doing this morning?

19
00:00:48,360 --> 00:00:49,230
Great?

20
00:00:49,230 --> 00:00:52,470
Yeah. Do you feel energized
to be at re:Invent?

21
00:00:52,470 --> 00:00:54,510
Yeah, it's always fun thing.

22
00:00:54,510 --> 00:00:57,360
I mean, whenever I walk
through that hallway,

23
00:00:57,360 --> 00:01:00,240
it's such a fun thing to do
when the music is going on,

24
00:01:00,240 --> 00:01:03,390
you feel so precious and
it's just a fun time.

25
00:01:03,390 --> 00:01:05,280
So my name is Pallavi Nargund.

26
00:01:05,280 --> 00:01:09,480
I am a principal solutions
architect at AWS.

27
00:01:09,480 --> 00:01:13,680
I have been in the IT industry
for about 25 plus years

28
00:01:13,680 --> 00:01:15,990
and out of that,

29
00:01:15,990 --> 00:01:19,380
around seven and a half
years I have been with AWS.

30
00:01:19,380 --> 00:01:22,710
Like Vivek I'm part of the
AI/ML specialist group,

31
00:01:22,710 --> 00:01:26,370
so I have been working
with Amazon SageMaker

32
00:01:26,370 --> 00:01:27,330
for five plus years

33
00:01:27,330 --> 00:01:29,160
and Bedrock for two plus years.

34
00:01:29,160 --> 00:01:30,630
And one of the things

35
00:01:30,630 --> 00:01:32,610
that I'm most passionate about

36
00:01:32,610 --> 00:01:33,990
is the RAG architecture,

37
00:01:33,990 --> 00:01:36,000
which is retrieval-augmented generation.

38
00:01:36,000 --> 00:01:38,910
And that's what we are
going to talk about today.

39
00:01:38,910 --> 00:01:40,710
But before I begin,

40
00:01:40,710 --> 00:01:45,360
I just wanted to do a quick
check from the audience.

41
00:01:45,360 --> 00:01:48,393
How many of you are familiar with RAG?

42
00:01:49,800 --> 00:01:51,330
Excellent.

43
00:01:51,330 --> 00:01:56,330
How many of you have put RAG
architectures in production?

44
00:01:57,510 --> 00:01:58,680
Fantastic.

45
00:01:58,680 --> 00:02:01,503
How many of you are struggling
with the RAG accuracy?

46
00:02:02,561 --> 00:02:04,650
(Pallavi and Vivek chuckling)

47
00:02:04,650 --> 00:02:08,940
Yes. So that's what we are
here to talk about today.

48
00:02:08,940 --> 00:02:10,350
So the agenda is

49
00:02:10,350 --> 00:02:13,620
first of all, this is a
400-level code talk session.

50
00:02:13,620 --> 00:02:16,020
We're now going to be
presenting a lot on PowerPoint

51
00:02:16,020 --> 00:02:18,960
and since the audience is fairly familiar

52
00:02:18,960 --> 00:02:20,340
with RAG architectures,

53
00:02:20,340 --> 00:02:22,650
we're not going to spend
too much time on the slides.

54
00:02:22,650 --> 00:02:25,050
We will be going directly to the code.

55
00:02:25,050 --> 00:02:27,360
We are going to have a quick overview

56
00:02:27,360 --> 00:02:29,370
of Amazon Bedrock Knowledge Bases

57
00:02:29,370 --> 00:02:33,630
since that's what we are
using to showcase our RAG

58
00:02:33,630 --> 00:02:35,880
or how to improve the RAG accuracy.

59
00:02:35,880 --> 00:02:37,530
How many of you are familiar

60
00:02:37,530 --> 00:02:40,590
with Amazon Bedrock Knowledge Bases?

61
00:02:40,590 --> 00:02:43,020
Okay, a few, which is good.

62
00:02:43,020 --> 00:02:45,240
So we will have a brief overview

63
00:02:45,240 --> 00:02:46,320
but throughout the code

64
00:02:46,320 --> 00:02:47,723
we will be explaining the different APIs

65
00:02:47,723 --> 00:02:49,170
and the different features

66
00:02:49,170 --> 00:02:52,230
that are with the Bedrock Knowledge Bases.

67
00:02:52,230 --> 00:02:54,600
Then we are going to discuss
advanced RAG technique

68
00:02:54,600 --> 00:02:57,210
and we are going to do
the code walkthrough.

69
00:02:57,210 --> 00:03:00,150
Now I know this is a RAG architecture

70
00:03:00,150 --> 00:03:03,180
and improving the
accuracy of the responses.

71
00:03:03,180 --> 00:03:06,240
I feel it's a science and art by itself.

72
00:03:06,240 --> 00:03:09,389
I really love solving complex problems.

73
00:03:09,389 --> 00:03:11,010
You will have questions.

74
00:03:11,010 --> 00:03:13,200
We may not get to all the questions today

75
00:03:13,200 --> 00:03:17,010
because we do wanna talk a
lot about RAG techniques,

76
00:03:17,010 --> 00:03:19,530
but we are going to be
outside in the hallway.

77
00:03:19,530 --> 00:03:23,190
So if we don't get to your
questions during the session,

78
00:03:23,190 --> 00:03:25,260
feel free to reach out to us.

79
00:03:25,260 --> 00:03:27,190
And if you are in between sessions

80
00:03:28,074 --> 00:03:30,480
we are available on LinkedIn.

81
00:03:30,480 --> 00:03:31,830
Send a direct message

82
00:03:31,830 --> 00:03:34,530
and we'll meet you and
answer your questions.

83
00:03:34,530 --> 00:03:37,410
But this is something Vivek
and I are passionate about.

84
00:03:37,410 --> 00:03:39,300
We talk to our customers a lot

85
00:03:39,300 --> 00:03:41,010
about solving different problems.

86
00:03:41,010 --> 00:03:43,713
So we are happy to do that.

87
00:03:44,850 --> 00:03:49,290
So the goal as I mentioned
is to improve the accuracy

88
00:03:49,290 --> 00:03:50,820
of your RAG architectures.

89
00:03:50,820 --> 00:03:52,710
Now why is it important?

90
00:03:52,710 --> 00:03:54,090
Because A, first of all,

91
00:03:54,090 --> 00:03:56,430
you are putting your enterprise data set

92
00:03:56,430 --> 00:03:59,040
in front of in your
generative AI applications

93
00:03:59,040 --> 00:04:01,200
and you're making certain decisions on it.

94
00:04:01,200 --> 00:04:03,780
And now the concept of
user is also changed.

95
00:04:03,780 --> 00:04:05,670
It's not only just a human

96
00:04:05,670 --> 00:04:08,970
who's going to be maybe querying the RAG,

97
00:04:08,970 --> 00:04:11,040
but it is also autonomous systems.

98
00:04:11,040 --> 00:04:12,510
Your agent DKI systems

99
00:04:12,510 --> 00:04:15,300
are also querying the RAG architectures.

100
00:04:15,300 --> 00:04:17,640
In those cases, it's important

101
00:04:17,640 --> 00:04:22,620
to make sure your retrieval
quality is improved

102
00:04:22,620 --> 00:04:24,750
as well as your response is improved.

103
00:04:24,750 --> 00:04:28,590
And that's the idea that we
are going to talk about today.

104
00:04:28,590 --> 00:04:30,570
So everyone knows RAG,

105
00:04:30,570 --> 00:04:33,540
so we're not going to dive
what is RAG in action.

106
00:04:33,540 --> 00:04:37,920
Just a reminder, RAG is again
retrieval and generation,

107
00:04:37,920 --> 00:04:39,210
two main components,

108
00:04:39,210 --> 00:04:42,030
but let's not forget the
ingestion of the documents.

109
00:04:42,030 --> 00:04:44,730
And now for purpose of this session,

110
00:04:44,730 --> 00:04:46,890
we are going to be focused
on unstructured data

111
00:04:46,890 --> 00:04:50,580
because that's where we see
a lot of issues that occur

112
00:04:50,580 --> 00:04:53,340
with respect to improving
your RAG accuracy.

113
00:04:53,340 --> 00:04:55,920
And unstructured could be
documents, could be images,

114
00:04:55,920 --> 00:04:57,180
could be your videos,

115
00:04:57,180 --> 00:05:00,240
or it could be a mixture of those things.

116
00:05:00,240 --> 00:05:02,970
So document the data ingestion workflow

117
00:05:02,970 --> 00:05:04,620
is extremely important.

118
00:05:04,620 --> 00:05:05,880
There are certain techniques

119
00:05:05,880 --> 00:05:09,570
that you can apply during
the data ingestion workflow

120
00:05:09,570 --> 00:05:11,130
so that the information

121
00:05:11,130 --> 00:05:15,270
that is getting into the
vector store is stored well.

122
00:05:15,270 --> 00:05:16,410
So chunking strategy,

123
00:05:16,410 --> 00:05:20,280
maybe doing more transformation
on the chunks, et cetera.

124
00:05:20,280 --> 00:05:22,890
We won't get time to focus on that today.

125
00:05:22,890 --> 00:05:26,490
We'll focus on the retrieval
and the generation part of it.

126
00:05:26,490 --> 00:05:29,280
So the next is again,
when the retrieval part,

127
00:05:29,280 --> 00:05:31,020
when the users are asking questions,

128
00:05:31,020 --> 00:05:33,780
you are retrieving specific chunks

129
00:05:33,780 --> 00:05:36,900
and then you are applying a model,

130
00:05:36,900 --> 00:05:41,250
sending to LLM to generate
the response for the user.

131
00:05:41,250 --> 00:05:43,950
So having said that,

132
00:05:43,950 --> 00:05:45,270
for those who are not familiar

133
00:05:45,270 --> 00:05:47,670
with Amazon Bedrock Knowledge Bases,

134
00:05:47,670 --> 00:05:50,520
it is a managed feature,

135
00:05:50,520 --> 00:05:53,880
it's a managed service for
your end-to-end RAG workflow.

136
00:05:53,880 --> 00:05:55,530
So as we saw earlier,

137
00:05:55,530 --> 00:05:58,560
when you put together RAG architecture,

138
00:05:58,560 --> 00:06:01,230
you need to have select
an embedding model.

139
00:06:01,230 --> 00:06:03,480
You need to select chunking strategy,

140
00:06:03,480 --> 00:06:05,820
you need to select what
kind of vector store

141
00:06:05,820 --> 00:06:07,830
you are going to use.

142
00:06:07,830 --> 00:06:10,470
You need to select a LLM

143
00:06:10,470 --> 00:06:12,570
that is going to generate the information.

144
00:06:12,570 --> 00:06:15,390
So there are few components
that come into picture

145
00:06:15,390 --> 00:06:17,790
and they need to
integrate with each other.

146
00:06:17,790 --> 00:06:19,920
So Bedrock Knowledge Bases

147
00:06:19,920 --> 00:06:22,830
gives you that end-to-end RAG workflow.

148
00:06:22,830 --> 00:06:25,350
With few configurations

149
00:06:25,350 --> 00:06:27,540
you can put that together very quickly.

150
00:06:27,540 --> 00:06:29,550
And from the data source perspective,

151
00:06:29,550 --> 00:06:31,710
S3 is a main data source,

152
00:06:31,710 --> 00:06:32,543
but again,

153
00:06:32,543 --> 00:06:34,800
there are multiple data
sources you can connect to

154
00:06:34,800 --> 00:06:37,203
such as SharePoint,
confluence types, et cetera.

155
00:06:39,180 --> 00:06:41,220
And we are going to see a lot about

156
00:06:41,220 --> 00:06:43,440
Knowledge Bases in the code.

157
00:06:43,440 --> 00:06:46,170
So now we have, we defined,

158
00:06:46,170 --> 00:06:48,510
okay, we have a RAG architecture.

159
00:06:48,510 --> 00:06:50,820
Now majority of the times,

160
00:06:50,820 --> 00:06:52,320
initially when you get started,

161
00:06:52,320 --> 00:06:54,690
maybe in the POC phase et cetera,

162
00:06:54,690 --> 00:06:57,960
you are going to have
your unstructured data,

163
00:06:57,960 --> 00:06:59,400
put that in the vector store

164
00:06:59,400 --> 00:07:01,020
and start asking questions.

165
00:07:01,020 --> 00:07:01,890
Standard RAG.

166
00:07:01,890 --> 00:07:05,340
So some of you may know
it as naive RAG as well.

167
00:07:05,340 --> 00:07:07,380
So basically at that point in time

168
00:07:07,380 --> 00:07:10,486
we are not doing additional pre-processing

169
00:07:10,486 --> 00:07:15,486
or any post-processing after
that context is retrieved.

170
00:07:15,510 --> 00:07:19,770
However, and this works fine
if you have in certain cases,

171
00:07:19,770 --> 00:07:21,690
especially if you have,

172
00:07:21,690 --> 00:07:23,850
in my experience, if you have let's say

173
00:07:23,850 --> 00:07:25,950
not a huge volume of documents

174
00:07:25,950 --> 00:07:28,500
or the documents are
fairly straightforward,

175
00:07:28,500 --> 00:07:30,690
they are not interconnected
with each other

176
00:07:30,690 --> 00:07:33,420
or maybe there's not too
much proprietary data

177
00:07:33,420 --> 00:07:35,610
or abbreviations that are around it,

178
00:07:35,610 --> 00:07:37,740
standard RAG works just fine.

179
00:07:37,740 --> 00:07:42,330
However, as you move towards
complex applications,

180
00:07:42,330 --> 00:07:45,090
then it all depends on your,

181
00:07:45,090 --> 00:07:47,460
well how complex your documents are.

182
00:07:47,460 --> 00:07:49,800
Do you have large number of documents?

183
00:07:49,800 --> 00:07:52,890
Sometimes you may have
more than 10,000 documents

184
00:07:52,890 --> 00:07:55,050
and suddenly things
start getting interesting

185
00:07:55,050 --> 00:07:57,000
with respect to RAG architectures.

186
00:07:57,000 --> 00:07:59,940
You may have your users,

187
00:07:59,940 --> 00:08:02,640
their usage pattern is
also hugely dependent

188
00:08:02,640 --> 00:08:06,300
because they may be asking some
complex queries, et cetera.

189
00:08:06,300 --> 00:08:08,940
So how those RAG systems are being used,

190
00:08:08,940 --> 00:08:10,230
that's also important.

191
00:08:10,230 --> 00:08:13,650
So in all those cases, then
things start getting interesting

192
00:08:13,650 --> 00:08:16,020
and that's where you
need to start focusing on

193
00:08:16,020 --> 00:08:19,623
the quality of retrieval and responses.

194
00:08:20,520 --> 00:08:22,740
So this is where advanced
RAG architecture pattern

195
00:08:22,740 --> 00:08:24,210
comes into picture.

196
00:08:24,210 --> 00:08:25,680
So advanced RAG is again,

197
00:08:25,680 --> 00:08:29,070
it's a technique that's going
to enhance your standard RAG

198
00:08:29,070 --> 00:08:31,500
and the idea is to enrich your retrieval

199
00:08:31,500 --> 00:08:33,390
and generation responses.

200
00:08:33,390 --> 00:08:36,450
Now there are two main
prominent categories

201
00:08:36,450 --> 00:08:37,770
that are out there.

202
00:08:37,770 --> 00:08:40,710
Again, these are common,
there are others also,

203
00:08:40,710 --> 00:08:43,140
and this is a constantly evolving field,

204
00:08:43,140 --> 00:08:46,500
so there are new papers that
are published all the time.

205
00:08:46,500 --> 00:08:47,640
But these are the things

206
00:08:47,640 --> 00:08:49,560
that are the most common patterns,

207
00:08:49,560 --> 00:08:51,540
is going to be a conditional branching

208
00:08:51,540 --> 00:08:53,580
and parallel branching.

209
00:08:53,580 --> 00:08:56,670
Let's take a quick look at
what that before we proceed.

210
00:08:56,670 --> 00:08:58,050
So conditional branching now.

211
00:08:58,050 --> 00:09:02,190
So as you start putting more generic

212
00:09:02,190 --> 00:09:05,460
or more complex generative
AI applications,

213
00:09:05,460 --> 00:09:09,603
you're not restricted to data
within just one vector store.

214
00:09:10,814 --> 00:09:12,270
You will have applications

215
00:09:12,270 --> 00:09:14,490
where you will have multiple vector stores

216
00:09:14,490 --> 00:09:16,110
that you need to query.

217
00:09:16,110 --> 00:09:17,580
In those cases,

218
00:09:17,580 --> 00:09:20,760
you need to basically your
generative AI applications

219
00:09:20,760 --> 00:09:22,080
or it could be an agent

220
00:09:22,080 --> 00:09:23,580
that needs to make a decision,

221
00:09:23,580 --> 00:09:26,520
well which vector store
do I need to query from?

222
00:09:26,520 --> 00:09:28,320
And that is where the
conditional branching

223
00:09:28,320 --> 00:09:29,700
will come into picture.

224
00:09:29,700 --> 00:09:31,080
Let's take an example.

225
00:09:31,080 --> 00:09:34,410
I hope everyone was shopping
during the Thanksgiving.

226
00:09:34,410 --> 00:09:36,240
Let's say you have a query about a product

227
00:09:36,240 --> 00:09:41,070
and there is a customer
support generative AI agent

228
00:09:41,070 --> 00:09:42,900
that's answering your questions.

229
00:09:42,900 --> 00:09:45,930
If there is a specific
query about the product,

230
00:09:45,930 --> 00:09:47,970
the agent should be intelligent enough

231
00:09:47,970 --> 00:09:51,450
to go to that particular
product-related vector store.

232
00:09:51,450 --> 00:09:52,710
But if you have,

233
00:09:52,710 --> 00:09:53,850
let's say a question about

234
00:09:53,850 --> 00:09:55,890
well what is the return policy

235
00:09:55,890 --> 00:09:58,440
for that particular
item that you're buying?

236
00:09:58,440 --> 00:10:00,540
In those cases it will go around

237
00:10:00,540 --> 00:10:02,490
the policy-related vector store.

238
00:10:02,490 --> 00:10:04,890
So that's the conditional branching.

239
00:10:04,890 --> 00:10:08,280
However, things are not so binary.

240
00:10:08,280 --> 00:10:10,770
It's not so black and white anymore.

241
00:10:10,770 --> 00:10:13,290
You want to have data coming in

242
00:10:13,290 --> 00:10:15,420
from multiple vector stores

243
00:10:15,420 --> 00:10:17,760
and then making decisions from it.

244
00:10:17,760 --> 00:10:20,280
For example, if you are, let's say,

245
00:10:20,280 --> 00:10:23,130
let's take a manufacturing example.

246
00:10:23,130 --> 00:10:24,589
On the factory floor,

247
00:10:24,589 --> 00:10:28,650
maybe an instrument is
showing an error code

248
00:10:28,650 --> 00:10:30,660
or somebody notices a condition

249
00:10:30,660 --> 00:10:33,780
that certain equipment is not working well

250
00:10:33,780 --> 00:10:36,120
and you have a generative AI application

251
00:10:36,120 --> 00:10:39,000
that's going to A, give you a root cause

252
00:10:39,000 --> 00:10:41,250
for that particular error code.

253
00:10:41,250 --> 00:10:44,010
But would you stop there?
Why would you stop there?

254
00:10:44,010 --> 00:10:45,780
Once you know what is the root cause

255
00:10:45,780 --> 00:10:48,210
for that particular error code,

256
00:10:48,210 --> 00:10:50,070
you are going to get,

257
00:10:50,070 --> 00:10:51,720
well how to fix it.

258
00:10:51,720 --> 00:10:53,670
Is there any step by step instruction?

259
00:10:53,670 --> 00:10:55,890
Is there an instruction manual around it?

260
00:10:55,890 --> 00:10:58,590
So you will want to get
that information as well

261
00:10:58,590 --> 00:11:00,120
and present it to the user.

262
00:11:00,120 --> 00:11:02,130
You may also take an action upon it

263
00:11:02,130 --> 00:11:05,640
saying that okay, this might
be a potential root cause

264
00:11:05,640 --> 00:11:08,370
and this may be a part that is required.

265
00:11:08,370 --> 00:11:10,830
Can I order it? Do I have that in stock?

266
00:11:10,830 --> 00:11:13,110
So you can see that there are multiple,

267
00:11:13,110 --> 00:11:16,260
you are getting the data from multiple

268
00:11:16,260 --> 00:11:17,820
enterprise data sources.

269
00:11:17,820 --> 00:11:19,890
Then you are ranking and pooling that data

270
00:11:19,890 --> 00:11:22,623
and giving the right
information to your user.

271
00:11:23,550 --> 00:11:25,170
So that's where the parallel branching

272
00:11:25,170 --> 00:11:26,790
will come into picture.

273
00:11:26,790 --> 00:11:30,000
Now, well we said yes,

274
00:11:30,000 --> 00:11:32,670
there are different vector
stores we can connect to

275
00:11:32,670 --> 00:11:34,080
and now fantastic,

276
00:11:34,080 --> 00:11:35,730
I'm getting my chunks

277
00:11:35,730 --> 00:11:37,980
but does that still improve your retrieval

278
00:11:37,980 --> 00:11:40,200
and generation quality?

279
00:11:40,200 --> 00:11:42,270
No. So there are certain
going to be again,

280
00:11:42,270 --> 00:11:44,850
what is the pattern of your usage,

281
00:11:44,850 --> 00:11:46,980
how your users are querying that pattern

282
00:11:46,980 --> 00:11:49,050
and that is where additional techniques

283
00:11:49,050 --> 00:11:50,250
that need to be applied.

284
00:11:50,250 --> 00:11:51,510
Now we are going to walk through

285
00:11:51,510 --> 00:11:53,370
a couple of techniques in the code,

286
00:11:53,370 --> 00:11:55,080
but query reformulation

287
00:11:55,080 --> 00:11:58,230
is one of the most common
techniques that we have seen.

288
00:11:58,230 --> 00:12:00,120
And again, there are additional techniques

289
00:12:00,120 --> 00:12:02,190
you're going to be
re-ranking results et cetera.

290
00:12:02,190 --> 00:12:04,260
We'll cover a few of them at the end.

291
00:12:04,260 --> 00:12:05,880
But the query reformulation

292
00:12:05,880 --> 00:12:08,931
is one of the most common
practices that we have seen

293
00:12:08,931 --> 00:12:10,800
our customers employ.

294
00:12:10,800 --> 00:12:13,080
And what is the query formulation?

295
00:12:13,080 --> 00:12:15,360
Basically from your usage patterns,

296
00:12:15,360 --> 00:12:16,980
you will see that if the query

297
00:12:16,980 --> 00:12:20,400
and majority of the time that
query will have subqueries

298
00:12:20,400 --> 00:12:22,140
or it's a multi-part query

299
00:12:22,140 --> 00:12:24,750
or a complex query that is associated.

300
00:12:24,750 --> 00:12:25,680
In those cases,

301
00:12:25,680 --> 00:12:29,520
that query will be broken
down into multiple pieces,

302
00:12:29,520 --> 00:12:32,880
then all the queries would be fired up

303
00:12:32,880 --> 00:12:34,530
against the vector store.

304
00:12:34,530 --> 00:12:37,380
It will collect the relevant context

305
00:12:37,380 --> 00:12:39,540
or chunks from the vector store

306
00:12:39,540 --> 00:12:42,330
and then it is going to rank
and pull the right response.

307
00:12:42,330 --> 00:12:45,900
So this is where the query
reformulation comes into picture

308
00:12:45,900 --> 00:12:48,240
and Amazon Bedrock Knowledge Bases

309
00:12:48,240 --> 00:12:49,470
does have a feature

310
00:12:49,470 --> 00:12:50,760
where you can configure

311
00:12:50,760 --> 00:12:52,470
this particular orchestration feature

312
00:12:52,470 --> 00:12:54,060
and get started with it.

313
00:12:54,060 --> 00:12:57,363
So having said that, we are
going to go to the code.

314
00:12:59,430 --> 00:13:03,570
Okay, so for the purpose of this code now,

315
00:13:03,570 --> 00:13:04,403
okay, thank you.

316
00:13:04,403 --> 00:13:05,430
Thank you, Vivek.

317
00:13:05,430 --> 00:13:08,913
So we are going to execute
the code in Jupyter Notebook.

318
00:13:11,539 --> 00:13:14,310
So first of all, for this particular code

319
00:13:14,310 --> 00:13:18,960
we have taken a example of
a financial analyst company.

320
00:13:18,960 --> 00:13:21,900
So Octank is a fictitious company.

321
00:13:21,900 --> 00:13:25,080
It has produced a 10-K report

322
00:13:25,080 --> 00:13:28,290
and the 10-K report is
also generated by LLMs.

323
00:13:28,290 --> 00:13:30,930
It's all, it's completely synthetic data.

324
00:13:30,930 --> 00:13:34,410
So idea is we have put together

325
00:13:34,410 --> 00:13:36,390
generative AI application

326
00:13:36,390 --> 00:13:39,810
that is going to help
some analysts ask question

327
00:13:39,810 --> 00:13:41,700
around that 10-K document.

328
00:13:41,700 --> 00:13:43,380
Now in order to do that,

329
00:13:43,380 --> 00:13:45,390
we definitely need a few things.

330
00:13:45,390 --> 00:13:47,790
We need to A, first
upload that 10-K document

331
00:13:47,790 --> 00:13:48,960
to an S3 bucket.

332
00:13:48,960 --> 00:13:51,270
So which we have already pre-provision.

333
00:13:51,270 --> 00:13:53,820
We also have pre-provision
in Knowledge Base

334
00:13:53,820 --> 00:13:55,740
because it does take two to five minutes

335
00:13:55,740 --> 00:13:57,390
for the knowledge base to come up

336
00:13:58,260 --> 00:14:00,750
with all the different components

337
00:14:00,750 --> 00:14:02,730
and the data to be ingested.

338
00:14:02,730 --> 00:14:05,640
And again we are at the
mercy of internet God,

339
00:14:05,640 --> 00:14:08,010
so I didn't wanna take a chance
of something going wrong.

340
00:14:08,010 --> 00:14:10,860
So the knowledge base is
already pre-populated.

341
00:14:10,860 --> 00:14:13,160
Having said that, we'll
step through the code.

342
00:14:14,100 --> 00:14:18,870
So this is the agentic RAG
notebook that we have seen.

343
00:14:18,870 --> 00:14:21,600
Now one thing is there

344
00:14:21,600 --> 00:14:25,500
and we will clarify why there
is a DynamoDB table also

345
00:14:25,500 --> 00:14:27,030
that we have provisioned.

346
00:14:27,030 --> 00:14:31,910
The DynamoDB table is going to
be storing glossary of text.

347
00:14:31,910 --> 00:14:34,920
So we have some proprietary abbreviations

348
00:14:34,920 --> 00:14:36,690
that our company uses.

349
00:14:36,690 --> 00:14:38,580
So those that the glossary of terms

350
00:14:38,580 --> 00:14:40,350
has been stored in DynamoDB.

351
00:14:40,350 --> 00:14:43,260
We have chosen DynamoDB for
the demonstration purpose.

352
00:14:43,260 --> 00:14:46,470
You could choose any
any different storage,

353
00:14:46,470 --> 00:14:47,640
like you could have it in S3

354
00:14:47,640 --> 00:14:50,820
or anywhere or in the memory itself.

355
00:14:50,820 --> 00:14:55,770
So we are going to install
the necessary libraries.

356
00:14:55,770 --> 00:14:59,190
And just quick look at
the requirement TXT,

357
00:14:59,190 --> 00:15:00,222
we have boto3,

358
00:15:00,222 --> 00:15:01,950
OpenSearch is the underlying vector store

359
00:15:01,950 --> 00:15:03,330
that we are using

360
00:15:03,330 --> 00:15:06,000
and the different
frameworks that are there.

361
00:15:06,000 --> 00:15:07,980
And we're going to talk about
some of these frameworks

362
00:15:07,980 --> 00:15:10,083
during our conversation.

363
00:15:14,340 --> 00:15:16,889
So this part, since the requirement .TXT

364
00:15:16,889 --> 00:15:19,200
and the notebook we have already started,

365
00:15:19,200 --> 00:15:22,440
so let's focus on the next part.

366
00:15:22,440 --> 00:15:26,040
So now there are going to be
some configurations set up.

367
00:15:26,040 --> 00:15:29,550
We are using Haiku 4.5 as our model

368
00:15:29,550 --> 00:15:32,463
to generate the response on the context.

369
00:15:33,690 --> 00:15:37,740
Naturally, first thing we need
is the right AWS credentials.

370
00:15:37,740 --> 00:15:38,910
So we are just making sure

371
00:15:38,910 --> 00:15:40,830
there is nothing coming from the memory

372
00:15:40,830 --> 00:15:44,610
and then we are setting
up the right credentials.

373
00:15:44,610 --> 00:15:47,100
Now here we are going to be basically

374
00:15:47,100 --> 00:15:49,350
looking at the standard.

375
00:15:49,350 --> 00:15:51,270
First of all we need a boto3 library

376
00:15:51,270 --> 00:15:53,760
and then we are getting
additional libraries

377
00:15:53,760 --> 00:15:55,590
that are required.

378
00:15:55,590 --> 00:15:59,340
So we are getting the
handle on our AWS session

379
00:15:59,340 --> 00:16:01,890
and we are going to quickly make sure

380
00:16:01,890 --> 00:16:03,330
everything looks good

381
00:16:03,330 --> 00:16:06,030
from our connectivity purposes.

382
00:16:06,030 --> 00:16:07,560
And yup, I have the account,

383
00:16:07,560 --> 00:16:09,390
I have the right region

384
00:16:09,390 --> 00:16:12,240
and things are things look good.

385
00:16:12,240 --> 00:16:13,260
Now.

386
00:16:13,260 --> 00:16:15,600
So setting up and
creating a knowledge base.

387
00:16:15,600 --> 00:16:17,130
And this is already executed

388
00:16:17,130 --> 00:16:19,680
so I'm not going to execute
this particular code

389
00:16:19,680 --> 00:16:22,053
but I'm going to explain what this does.

390
00:16:23,010 --> 00:16:25,140
So this is where we are going to specify

391
00:16:25,140 --> 00:16:26,520
the knowledge base name

392
00:16:26,520 --> 00:16:27,810
and the description

393
00:16:27,810 --> 00:16:28,830
so that you have.

394
00:16:28,830 --> 00:16:31,290
Now the bucket name
that I'm specifying here

395
00:16:31,290 --> 00:16:33,270
is going to house my 10-K document.

396
00:16:33,270 --> 00:16:35,220
So that's where I'm
creating a bucket first

397
00:16:35,220 --> 00:16:37,503
and going to house my 10-K document.

398
00:16:39,180 --> 00:16:40,650
Once that is done,

399
00:16:40,650 --> 00:16:41,880
then I'm going to use

400
00:16:41,880 --> 00:16:44,160
the Bedrock create knowledge base API.

401
00:16:44,160 --> 00:16:45,690
Now here you will see

402
00:16:45,690 --> 00:16:47,850
that there are few parameters
that we are providing.

403
00:16:47,850 --> 00:16:49,860
Again, we set the name and description

404
00:16:49,860 --> 00:16:51,210
for the knowledge base.

405
00:16:51,210 --> 00:16:53,640
The data source is there, which is S3.

406
00:16:53,640 --> 00:16:56,370
Now the chunking strategy,
I'm not disturbing it.

407
00:16:56,370 --> 00:16:57,630
I have a 10-K document

408
00:16:57,630 --> 00:16:59,460
which I know is going to flow through.

409
00:16:59,460 --> 00:17:02,550
I'm going to use the
fixed-size chunking strategy.

410
00:17:02,550 --> 00:17:05,160
So I'm going to specify a few parameters

411
00:17:05,160 --> 00:17:07,650
for me to create the
Bedrock knowledge base.

412
00:17:07,650 --> 00:17:11,280
However, let's take a look
at what it initializes.

413
00:17:11,280 --> 00:17:12,812
So this is my,

414
00:17:12,812 --> 00:17:16,260
it's a utility, that knowledge_base.py.

415
00:17:16,260 --> 00:17:17,880
And then as you can see,

416
00:17:17,880 --> 00:17:22,880
there are a few things that
I've already initialized

417
00:17:23,280 --> 00:17:25,470
as part of my class initializer.

418
00:17:25,470 --> 00:17:26,656
So if you look at this,

419
00:17:26,656 --> 00:17:28,320
I have already selected

420
00:17:28,320 --> 00:17:30,540
what kind of embedding
model I want to choose.

421
00:17:30,540 --> 00:17:32,730
So I'm using Titan embedding.

422
00:17:32,730 --> 00:17:36,180
you can use Cohere also,
Cohere is also available.

423
00:17:36,180 --> 00:17:38,340
Then from the generation model,

424
00:17:38,340 --> 00:17:42,990
here by default we have selected
three, if nobody specifies,

425
00:17:42,990 --> 00:17:47,253
but we are overriding
that with the Haiku 4.5.

426
00:17:48,120 --> 00:17:50,520
And chunking strategy is also fixed-size.

427
00:17:50,520 --> 00:17:54,090
But I wanted to show
these arguments to you

428
00:17:54,090 --> 00:17:56,760
so that when you are
applying knowledge bases

429
00:17:56,760 --> 00:17:58,590
within your own systems,

430
00:17:58,590 --> 00:18:00,870
there are going to be
different decision points

431
00:18:00,870 --> 00:18:01,890
that you can make.

432
00:18:01,890 --> 00:18:04,410
You can choose your vector store as well.

433
00:18:04,410 --> 00:18:08,250
So knowledge bases support
OpenSearch as a vector store

434
00:18:08,250 --> 00:18:10,620
under which is the default one.

435
00:18:10,620 --> 00:18:12,960
But you can also have S3 vectors.

436
00:18:12,960 --> 00:18:16,236
You can have (speaking indistinctly)

437
00:18:16,236 --> 00:18:18,960
and we'll keep coming up
with the new connection.

438
00:18:18,960 --> 00:18:22,353
So you can definitely define
the vector store that you need.

439
00:18:23,850 --> 00:18:25,380
So this is where,

440
00:18:25,380 --> 00:18:28,080
and then again that is going
to be the chunking strategy.

441
00:18:28,080 --> 00:18:29,700
We do support fixed chunking.

442
00:18:29,700 --> 00:18:31,770
That is a default one that you can select,

443
00:18:31,770 --> 00:18:35,160
but you can also select semantic chunking

444
00:18:35,160 --> 00:18:39,180
or hierarchical chunking
based on your use case.

445
00:18:39,180 --> 00:18:40,920
And once we have done,

446
00:18:40,920 --> 00:18:44,460
so this is where all the
initializers that are happening.

447
00:18:44,460 --> 00:18:46,230
Now there is a lambda function,

448
00:18:46,230 --> 00:18:48,060
lambda client also that you see.

449
00:18:48,060 --> 00:18:51,240
So if you're looking to get
basically while chunking,

450
00:18:51,240 --> 00:18:54,750
if you need to pre-process
the chunks additionally

451
00:18:54,750 --> 00:18:57,090
to extract additional insights from that,

452
00:18:57,090 --> 00:18:59,550
you can do that by using lambda function.

453
00:18:59,550 --> 00:19:02,163
So that is an option that is available.

454
00:19:03,450 --> 00:19:05,160
So you set up your knowledge base

455
00:19:05,160 --> 00:19:07,290
and there are a bunch of other features

456
00:19:07,290 --> 00:19:10,800
but I think just I wanted
to highlight the main ones.

457
00:19:10,800 --> 00:19:14,490
So using that, now we have
created the knowledge base

458
00:19:14,490 --> 00:19:16,650
and this is where we are uploading

459
00:19:16,650 --> 00:19:19,710
the Octank financial 10-K document.

460
00:19:19,710 --> 00:19:22,320
So this is basically the 10-K document

461
00:19:22,320 --> 00:19:24,150
that our LLM has generated

462
00:19:24,150 --> 00:19:26,823
and that's the document
that we will be ingesting.

463
00:19:28,080 --> 00:19:30,960
Now the next step once you
create the knowledge base

464
00:19:30,960 --> 00:19:33,240
is to start the ingestion job.

465
00:19:33,240 --> 00:19:36,150
We are not purposefully
executing these cells

466
00:19:36,150 --> 00:19:38,850
because these do take a minute or so

467
00:19:38,850 --> 00:19:41,790
and we have limited time.

468
00:19:41,790 --> 00:19:44,970
So this is something basically
we have already executed

469
00:19:44,970 --> 00:19:47,610
but this is where from your data store

470
00:19:47,610 --> 00:19:49,170
if it is the first time

471
00:19:49,170 --> 00:19:51,270
it's going to ingest all the documents

472
00:19:51,270 --> 00:19:53,040
but subsequent runs,

473
00:19:53,040 --> 00:19:54,630
any incremental files

474
00:19:54,630 --> 00:19:56,790
that are dropped within the data source

475
00:19:56,790 --> 00:19:58,560
or if there is an update,

476
00:19:58,560 --> 00:20:02,580
that will be ingested when
you start the sync job.

477
00:20:02,580 --> 00:20:05,070
So once you ingest those documents,

478
00:20:05,070 --> 00:20:07,170
now our knowledge base is ready

479
00:20:07,170 --> 00:20:09,510
and we can start with the basic RAG flow.

480
00:20:09,510 --> 00:20:12,120
So I'm going to execute
this particular cell

481
00:20:12,120 --> 00:20:13,050
and as you can see,

482
00:20:13,050 --> 00:20:15,360
I have my knowledge base ID

483
00:20:15,360 --> 00:20:18,289
and DynamoDB which is already created.

484
00:20:18,289 --> 00:20:22,740
First, this is the DynamoDB
table that creates,

485
00:20:22,740 --> 00:20:24,600
and it's just dumps basically,

486
00:20:24,600 --> 00:20:27,300
inserts these particular glossary records

487
00:20:27,300 --> 00:20:30,033
into the DynamoDB table
that we will be using.

488
00:20:31,470 --> 00:20:34,803
So now let's execute the basic RAG flow.

489
00:20:36,660 --> 00:20:40,350
Okay, so now once you
have your knowledge base

490
00:20:40,350 --> 00:20:42,664
that is created,

491
00:20:42,664 --> 00:20:46,530
you have access to two different APIs.

492
00:20:46,530 --> 00:20:48,270
One is going to be retrieve API

493
00:20:48,270 --> 00:20:51,330
and the second one is going
to be retrieve and generate.

494
00:20:51,330 --> 00:20:53,640
So Bedrock Knowledge Bases retrieve API

495
00:20:53,640 --> 00:20:55,800
is going to give you just the handle

496
00:20:55,800 --> 00:20:58,080
to the context to the chunks

497
00:20:58,080 --> 00:20:59,610
and then you are free to basically

498
00:20:59,610 --> 00:21:01,350
if you wanna post process,

499
00:21:01,350 --> 00:21:03,900
if there is additional
steps that you wanna do

500
00:21:03,900 --> 00:21:05,910
or if you may have a small model

501
00:21:05,910 --> 00:21:07,170
that you have already defined

502
00:21:07,170 --> 00:21:08,760
or you already have an endpoint

503
00:21:08,760 --> 00:21:11,460
and then you want to generate
the responses using that,

504
00:21:11,460 --> 00:21:14,160
you can use the retrieve API.

505
00:21:14,160 --> 00:21:17,850
For our purposes, we are
focusing on retrieve and generate

506
00:21:17,850 --> 00:21:21,000
where it is going to not
only retrieve the data

507
00:21:21,000 --> 00:21:22,020
from the vector store

508
00:21:22,020 --> 00:21:25,140
but it's also going to use the
LLM that we have identified,

509
00:21:25,140 --> 00:21:26,400
which is the Haiku

510
00:21:26,400 --> 00:21:28,713
and generate those specific responses.

511
00:21:29,640 --> 00:21:32,220
So let's look at the
knowledge base configuration

512
00:21:32,220 --> 00:21:34,110
for retrieval purposes.

513
00:21:34,110 --> 00:21:37,620
So here we have set that
for retrieval configuration,

514
00:21:37,620 --> 00:21:39,030
the vector search configuration,

515
00:21:39,030 --> 00:21:41,910
the number of results
you can return is five.

516
00:21:41,910 --> 00:21:44,550
Five is the default. We
are keeping it as is.

517
00:21:44,550 --> 00:21:48,600
You can retrieve up to 99 different chunks

518
00:21:48,600 --> 00:21:50,130
from the vector store.

519
00:21:50,130 --> 00:21:52,980
But again, right, and then this
is a completely configurable

520
00:21:52,980 --> 00:21:55,260
but by default it is
going to retrieve five.

521
00:21:55,260 --> 00:21:57,690
I'm not specifying anything else

522
00:21:57,690 --> 00:21:59,910
within this particular
retrieval configuration

523
00:21:59,910 --> 00:22:02,883
to demonstrate what the
basic RAG flow looks like.

524
00:22:04,800 --> 00:22:08,910
So now, once we have
three different questions

525
00:22:08,910 --> 00:22:13,620
that we are going to ask
to this 10-K document.

526
00:22:13,620 --> 00:22:18,270
The first one is what is the
fair value of HTM portfolio?

527
00:22:18,270 --> 00:22:19,980
Then what are the main business segments

528
00:22:19,980 --> 00:22:21,330
of Octank Financial,

529
00:22:21,330 --> 00:22:24,600
and how many employees
does Octank Financial have?

530
00:22:24,600 --> 00:22:25,770
Fairly basic question,

531
00:22:25,770 --> 00:22:28,085
my financial analyst
doesn't trust the system.

532
00:22:28,085 --> 00:22:32,640
They said, "Okay, let me
just give it a test run

533
00:22:32,640 --> 00:22:35,580
and let me see what it does."

534
00:22:35,580 --> 00:22:36,570
So fantastic.

535
00:22:36,570 --> 00:22:38,700
We are going to execute this

536
00:22:38,700 --> 00:22:42,840
and let's see what our
RAG comes out to be.

537
00:22:42,840 --> 00:22:47,100
Okay, it is able to find
the HTM portfolio value

538
00:22:47,100 --> 00:22:50,343
and it is also able to generate the,

539
00:22:51,690 --> 00:22:54,600
so here it did, let me highlight that.

540
00:22:54,600 --> 00:22:56,850
So this is where it did find the answer

541
00:22:56,850 --> 00:22:59,040
for the HTM portfolio.

542
00:22:59,040 --> 00:23:00,270
For the second one also,

543
00:23:00,270 --> 00:23:03,540
what are the main segments
of Octank Financial?

544
00:23:03,540 --> 00:23:07,590
It did come up with fairly
comprehensive answer.

545
00:23:07,590 --> 00:23:09,150
And for how many employees,

546
00:23:09,150 --> 00:23:11,850
also it does have that information, right?

547
00:23:11,850 --> 00:23:15,330
So let's investigate what happened here.

548
00:23:15,330 --> 00:23:18,210
So in our document,

549
00:23:18,210 --> 00:23:19,650
I'm going to just type in

550
00:23:19,650 --> 00:23:22,410
to say whether HTM is existing.

551
00:23:22,410 --> 00:23:24,960
And as you can see,
within the text itself,

552
00:23:24,960 --> 00:23:27,000
HTM is clearly defined.

553
00:23:27,000 --> 00:23:28,980
So the standard RAG

554
00:23:28,980 --> 00:23:30,240
or the basic RAG

555
00:23:30,240 --> 00:23:32,880
had no trouble finding the right chunks

556
00:23:32,880 --> 00:23:35,493
and we were able to
retrieve those documents.

557
00:23:36,990 --> 00:23:41,130
Now our financial analysts
are feeling confident

558
00:23:41,130 --> 00:23:42,300
and they say okay,

559
00:23:42,300 --> 00:23:44,220
let us start querying the things

560
00:23:44,220 --> 00:23:48,000
that we basically do it most of the times

561
00:23:48,000 --> 00:23:50,730
that we are going to operationally use.

562
00:23:50,730 --> 00:23:52,917
So some of the test
questions that they have

563
00:23:52,917 --> 00:23:54,543
are a little bit more.

564
00:23:56,070 --> 00:23:57,180
Oops. Yeah, first one.

565
00:23:57,180 --> 00:23:58,013
- [Vivek] Yeah.

566
00:24:00,120 --> 00:24:03,630
- [Pallavi] So the first
question that we have

567
00:24:03,630 --> 00:24:05,520
is what is Octank Tower

568
00:24:05,520 --> 00:24:07,710
and how does the whistleblower scandal

569
00:24:07,710 --> 00:24:09,900
hurt the company and its image?

570
00:24:09,900 --> 00:24:12,810
Second one is provide list of DCMS,

571
00:24:12,810 --> 00:24:16,080
and provide list of DCMS and
how many regional offices?

572
00:24:16,080 --> 00:24:19,713
So I am going to execute
this part and let's see.

573
00:24:21,510 --> 00:24:23,160
Okay.

574
00:24:23,160 --> 00:24:25,800
So the first query, it did say

575
00:24:25,800 --> 00:24:29,760
it could not find any
information about Octank Tower,

576
00:24:29,760 --> 00:24:32,266
but it did find information

577
00:24:32,266 --> 00:24:37,050
specifically about the whistleblower.

578
00:24:37,050 --> 00:24:39,540
Now let's inspect our document.

579
00:24:39,540 --> 00:24:41,740
Let's see what we have
in the whistleblower.

580
00:24:44,880 --> 00:24:46,440
So there is a clearly section

581
00:24:46,440 --> 00:24:48,690
that identifies the
whistleblower document.

582
00:24:48,690 --> 00:24:50,430
So this is why

583
00:24:50,430 --> 00:24:54,584
partially, the RAG
system is able to answer,

584
00:24:54,584 --> 00:24:58,170
and does it have information
for the Octank Tower?

585
00:24:58,170 --> 00:24:59,400
Well, it does

586
00:24:59,400 --> 00:25:04,143
but it is not being pulled into your,

587
00:25:05,040 --> 00:25:08,130
so it does identify there's a headquarter

588
00:25:08,130 --> 00:25:09,300
at Octank Tower

589
00:25:09,300 --> 00:25:10,770
but that information is not present

590
00:25:10,770 --> 00:25:13,590
in your context that you have
retrieved from vector store.

591
00:25:13,590 --> 00:25:15,780
That's why that information is not present

592
00:25:15,780 --> 00:25:18,480
in the final output that you have given.

593
00:25:18,480 --> 00:25:20,760
So this is where we
need to then figure out,

594
00:25:20,760 --> 00:25:23,370
well, what are the techniques
that how we can improve

595
00:25:23,370 --> 00:25:25,920
and make sure all the user questions

596
00:25:25,920 --> 00:25:27,783
are relatively answered?

597
00:25:29,910 --> 00:25:33,780
And the third question
also, about the DCM,

598
00:25:33,780 --> 00:25:37,023
well, let's see if we
have anything on the DCM.

599
00:25:38,340 --> 00:25:41,040
So I was encouraged by HTM

600
00:25:41,040 --> 00:25:44,040
thinking DCM will also
be very well defined

601
00:25:44,040 --> 00:25:45,930
but I do not find anything on DCM

602
00:25:45,930 --> 00:25:48,360
because that's the company abbreviation

603
00:25:48,360 --> 00:25:51,420
of the proprietary data
that is being used.

604
00:25:51,420 --> 00:25:55,500
So now we want to improve
that RAG accuracy.

605
00:25:55,500 --> 00:25:59,370
So the first one that we are
going to employ the technique

606
00:25:59,370 --> 00:26:01,680
is going to be decompose and generate.

607
00:26:01,680 --> 00:26:04,800
And as we talked about it earlier,

608
00:26:04,800 --> 00:26:07,740
is we are going to reformulate the query,

609
00:26:07,740 --> 00:26:09,900
which is we are going to
break down those query

610
00:26:09,900 --> 00:26:11,610
into multiple parts

611
00:26:11,610 --> 00:26:14,730
and then query our RAG application.

612
00:26:14,730 --> 00:26:16,710
So if you look at this,

613
00:26:16,710 --> 00:26:18,420
at this point in time,

614
00:26:18,420 --> 00:26:21,180
my configuration that I'm going to supply

615
00:26:21,180 --> 00:26:24,772
to the knowledge base,

616
00:26:24,772 --> 00:26:28,350
I'm still keeping my vector
search configuration same,

617
00:26:28,350 --> 00:26:32,310
however, I'm adding new
orchestration configuration.

618
00:26:32,310 --> 00:26:33,840
Orchestration configuration

619
00:26:33,840 --> 00:26:37,560
is going to let the knowledge base know

620
00:26:37,560 --> 00:26:40,423
that before you send this response,

621
00:26:41,437 --> 00:26:43,558
you need to basically

622
00:26:43,558 --> 00:26:46,620
have additional enrichment steps

623
00:26:46,620 --> 00:26:49,530
onto that particular query.

624
00:26:49,530 --> 00:26:52,200
And this is where I'm
saying query transformation,

625
00:26:52,200 --> 00:26:54,360
use the type as query decomposition.

626
00:26:54,360 --> 00:26:56,490
So that's all I'm going to specify.

627
00:26:56,490 --> 00:26:59,520
I'm not going to have any additional steps

628
00:26:59,520 --> 00:27:02,880
or any additional piece of
code that I need to write.

629
00:27:02,880 --> 00:27:04,140
At this point in time,

630
00:27:04,140 --> 00:27:06,750
I'm going to have Bedrock Knowledge Bases

631
00:27:06,750 --> 00:27:08,550
use this managed service

632
00:27:08,550 --> 00:27:10,590
to decompose the query for me

633
00:27:10,590 --> 00:27:14,580
and we are going to then similar
retrieve and generate call

634
00:27:14,580 --> 00:27:17,400
the same API call that we executed.

635
00:27:17,400 --> 00:27:18,960
So that's what we have.

636
00:27:18,960 --> 00:27:22,260
Now we are going to just
test one question for now

637
00:27:22,260 --> 00:27:23,583
to see how it does.

638
00:27:26,190 --> 00:27:27,570
So the first question I ask,

639
00:27:27,570 --> 00:27:29,160
what is the Octank Tower

640
00:27:29,160 --> 00:27:32,403
and how does the whistleblower
scandal hurt its image?

641
00:27:35,060 --> 00:27:35,940
It has already said

642
00:27:35,940 --> 00:27:39,480
that I'm going to use the
decompose and generate

643
00:27:39,480 --> 00:27:42,540
and it is able to now associate

644
00:27:42,540 --> 00:27:44,340
what is my Octank Tower

645
00:27:44,340 --> 00:27:46,950
and how does it basically,

646
00:27:46,950 --> 00:27:50,070
the whistleblower scandal affect

647
00:27:50,070 --> 00:27:53,820
and we are able to sort of
synthesize the response.

648
00:27:53,820 --> 00:27:56,310
What do you think will
happen if I query DCM?

649
00:27:56,310 --> 00:27:57,760
Do you think it will find it?

650
00:27:59,760 --> 00:28:01,800
No, because at that point in time,

651
00:28:01,800 --> 00:28:03,927
even if I'm having DCM,

652
00:28:03,927 --> 00:28:05,850
DCM the query, it still doesn't know.

653
00:28:05,850 --> 00:28:07,920
So even the query decomposition feature

654
00:28:07,920 --> 00:28:09,260
at this point in time

655
00:28:09,260 --> 00:28:10,260
is not going to help

656
00:28:10,260 --> 00:28:12,930
because there is really, it's
not a multi-part question.

657
00:28:12,930 --> 00:28:14,490
So how do we solve that?

658
00:28:14,490 --> 00:28:17,520
And that is where we are going
to use the query expansion.

659
00:28:17,520 --> 00:28:19,110
Now query expansion,

660
00:28:19,110 --> 00:28:22,050
sure you're hearing all the
agentic tools, et cetera.

661
00:28:22,050 --> 00:28:24,930
So we are going to basically define a tool

662
00:28:24,930 --> 00:28:28,080
that is going to now do a lookup

663
00:28:28,080 --> 00:28:30,690
on our proprietary abbreviations,

664
00:28:30,690 --> 00:28:33,270
which is going to be in the DynamoDB table

665
00:28:33,270 --> 00:28:35,163
and get the relevant data.

666
00:28:36,210 --> 00:28:40,440
So we are using Strands Agent
for this particular purposes.

667
00:28:40,440 --> 00:28:44,850
It's again, it's our Bedrock
SDK, to create agents.

668
00:28:44,850 --> 00:28:46,350
It's fairly straightforward

669
00:28:46,350 --> 00:28:48,840
but you can choose any other framework

670
00:28:48,840 --> 00:28:50,760
to create that particular agent.

671
00:28:50,760 --> 00:28:52,560
So we are defining it at the tools.

672
00:28:52,560 --> 00:28:55,350
So that's one of the tools
that agent has access to.

673
00:28:55,350 --> 00:28:56,580
So look up chunk,

674
00:28:56,580 --> 00:28:58,680
you're going to be basically querying

675
00:28:58,680 --> 00:29:00,870
against the DynamoDB table

676
00:29:00,870 --> 00:29:04,230
and now I have given
the project expression

677
00:29:04,230 --> 00:29:05,940
as I need to expand upon those terms,

678
00:29:05,940 --> 00:29:08,850
so go get me the term definitions.

679
00:29:08,850 --> 00:29:12,960
So when I look at that, if
I'm going to expand the query,

680
00:29:12,960 --> 00:29:15,275
so the function query_expansion

681
00:29:15,275 --> 00:29:18,720
is going to expand the
query using term definition

682
00:29:18,720 --> 00:29:20,520
via intelligent agent-based lookup.

683
00:29:20,520 --> 00:29:21,630
So it's giving me that,

684
00:29:21,630 --> 00:29:25,113
okay, I need to go query
the tool right now.

685
00:29:26,130 --> 00:29:29,190
So here I have created my agent,

686
00:29:29,190 --> 00:29:30,840
I've provided the name,

687
00:29:30,840 --> 00:29:34,410
the model ID, I'm still using Haiku 4.5.

688
00:29:34,410 --> 00:29:38,370
And the system prompt, now
I'm letting the agent know

689
00:29:38,370 --> 00:29:40,710
that you have access
to this particular tool

690
00:29:40,710 --> 00:29:45,060
and in tools, I have also
defined that as a lookup term.

691
00:29:45,060 --> 00:29:46,920
I've given the information

692
00:29:46,920 --> 00:29:49,140
that you have access to
this particular tool.

693
00:29:49,140 --> 00:29:54,140
So now go and get the definition
from the term glossary

694
00:29:55,890 --> 00:29:57,660
and then expand upon it.

695
00:29:57,660 --> 00:30:00,240
And then there are specific instructions

696
00:30:00,240 --> 00:30:01,890
for this particular agent

697
00:30:01,890 --> 00:30:04,410
to call the lookup term for each relevant.

698
00:30:04,410 --> 00:30:06,120
And it can call multiple times

699
00:30:06,120 --> 00:30:08,613
because your query may
have multiple questions.

700
00:30:10,110 --> 00:30:12,840
So once that prompt gets executed,

701
00:30:12,840 --> 00:30:15,720
we are going to then
transform this question

702
00:30:15,720 --> 00:30:18,030
using relevant term definition.

703
00:30:18,030 --> 00:30:21,480
So let's execute and see what happens.

704
00:30:21,480 --> 00:30:23,340
So at that point in time,

705
00:30:23,340 --> 00:30:27,810
the question still remains,
provide the list of DCMs.

706
00:30:27,810 --> 00:30:29,640
Now it knows that the DCM

707
00:30:29,640 --> 00:30:32,280
is the term that it needs to expand.

708
00:30:32,280 --> 00:30:36,150
Now the result is disclosure
committee members.

709
00:30:36,150 --> 00:30:38,640
Oh, DCM stands for
disclosure committee members.

710
00:30:38,640 --> 00:30:41,370
That means I need to now
go look at the document

711
00:30:41,370 --> 00:30:43,200
and fetch those results.

712
00:30:43,200 --> 00:30:47,220
So that's where I got
these particular results.

713
00:30:47,220 --> 00:30:49,890
There are three particular
individuals though

714
00:30:49,890 --> 00:30:53,370
who are part of the
disclosure committee members.

715
00:30:53,370 --> 00:30:55,410
Now we walked through two techniques.

716
00:30:55,410 --> 00:30:56,649
Fantastic.

717
00:30:56,649 --> 00:31:00,390
Based on each user preference,

718
00:31:00,390 --> 00:31:04,350
can we define which technique
to use or instruct any user?

719
00:31:04,350 --> 00:31:09,350
No, we need a better way
of an agentic approach

720
00:31:09,390 --> 00:31:11,940
to identify which particular technique

721
00:31:11,940 --> 00:31:14,220
needs to be applied based on user query

722
00:31:14,220 --> 00:31:16,380
and that's where Vivek
is going to step through

723
00:31:16,380 --> 00:31:18,150
the self-corrective RAG.

724
00:31:18,150 --> 00:31:19,400
- [Vivek] Thanks Pallavi.

725
00:31:21,030 --> 00:31:23,040
So you saw the different techniques

726
00:31:23,040 --> 00:31:24,420
and like Pallavi said,

727
00:31:24,420 --> 00:31:28,950
we need a way that
based on the user query,

728
00:31:28,950 --> 00:31:31,350
it is automatically able to decide

729
00:31:31,350 --> 00:31:33,660
which particular technique
do I need to use?

730
00:31:33,660 --> 00:31:35,970
Whether I need to use the basic RAG

731
00:31:35,970 --> 00:31:39,030
or I need to use query expansion

732
00:31:39,030 --> 00:31:41,040
or I need to use a query decomposition

733
00:31:41,040 --> 00:31:42,690
or maybe some other technique.

734
00:31:42,690 --> 00:31:46,590
That's where self-corrective
agentic RAG come into picture.

735
00:31:46,590 --> 00:31:48,510
So you have a agent loop

736
00:31:48,510 --> 00:31:50,100
and then you have the
different components.

737
00:31:50,100 --> 00:31:51,360
These components are nothing

738
00:31:51,360 --> 00:31:54,780
but these are the different
techniques that you can utilize.

739
00:31:54,780 --> 00:31:58,290
And using that, we develop the
self-corrective agentic RAG.

740
00:31:58,290 --> 00:32:01,533
So with self-corrective agentic RAG,

741
00:32:02,460 --> 00:32:04,350
you have a user question

742
00:32:04,350 --> 00:32:07,890
which is supplied to a central agent.

743
00:32:07,890 --> 00:32:12,390
Now this central agent will
first retrieve the context

744
00:32:12,390 --> 00:32:14,730
out of the data source.

745
00:32:14,730 --> 00:32:17,310
This context will then be analyzed.

746
00:32:17,310 --> 00:32:18,420
It will be checked

747
00:32:18,420 --> 00:32:22,563
whether this context is
relevant to the user question.

748
00:32:23,520 --> 00:32:28,520
And based on whether
the context is relevant

749
00:32:28,729 --> 00:32:31,170
to the user question or not,

750
00:32:31,170 --> 00:32:34,110
it will select one of the strategies.

751
00:32:34,110 --> 00:32:35,880
It may be a query expansion,

752
00:32:35,880 --> 00:32:37,830
it can be a query decomposition,

753
00:32:37,830 --> 00:32:40,830
it can be a combination of the two.

754
00:32:40,830 --> 00:32:41,663
Yeah.

755
00:32:41,663 --> 00:32:46,590
And once we have selected
the appropriate technique,

756
00:32:46,590 --> 00:32:49,740
then the response needs to be generated

757
00:32:49,740 --> 00:32:53,370
after the context is
augmented to the user query

758
00:32:53,370 --> 00:32:55,530
and ask the LLM.

759
00:32:55,530 --> 00:32:57,540
Now once we have the response,

760
00:32:57,540 --> 00:33:00,660
we again want to check
whether this response

761
00:33:00,660 --> 00:33:02,310
is relevant to the user question.

762
00:33:02,310 --> 00:33:03,480
This is the second check.

763
00:33:03,480 --> 00:33:06,180
First we did the context relevance

764
00:33:06,180 --> 00:33:09,180
and now we are doing the
response relevance check.

765
00:33:09,180 --> 00:33:12,513
Now within the response
relevance check itself,

766
00:33:13,590 --> 00:33:16,810
we want to check the
relevance of the user query

767
00:33:18,087 --> 00:33:19,440
to the response.

768
00:33:19,440 --> 00:33:23,940
Then we also want to check the
completeness of the response

769
00:33:23,940 --> 00:33:26,580
and we also want to check
the factual accuracy

770
00:33:26,580 --> 00:33:27,780
of the response.

771
00:33:27,780 --> 00:33:29,430
And based on that,

772
00:33:29,430 --> 00:33:32,280
we will either again loop back

773
00:33:32,280 --> 00:33:34,680
to select the appropriate strategy again

774
00:33:34,680 --> 00:33:36,630
if the answer is not good enough

775
00:33:36,630 --> 00:33:37,890
or if the answer is good,

776
00:33:37,890 --> 00:33:39,720
then we have the answer directly

777
00:33:39,720 --> 00:33:42,840
and we will loop till
we get the right answer

778
00:33:42,840 --> 00:33:44,460
or we reach a maximum threshold

779
00:33:44,460 --> 00:33:46,530
so that it doesn't go into infinite loop.

780
00:33:46,530 --> 00:33:49,380
That's the self-corrective
agentic RAG architecture.

781
00:33:49,380 --> 00:33:52,440
Simple one that we are going
to walk through the code.

782
00:33:52,440 --> 00:33:53,880
Yeah.

783
00:33:53,880 --> 00:33:55,833
So let's look at some real code now.

784
00:33:57,630 --> 00:33:58,463
Thanks Pallavi.

785
00:34:00,570 --> 00:34:05,570
So Pallavi already covered
few of the techniques,

786
00:34:08,250 --> 00:34:09,333
the basic RAG,

787
00:34:10,350 --> 00:34:13,983
then the query expansion,
the query decomposition.

788
00:34:15,300 --> 00:34:18,390
We will be adding two
more techniques over here.

789
00:34:18,390 --> 00:34:20,820
One is retrieving the document.

790
00:34:20,820 --> 00:34:22,920
Pallavi touched based upon it earlier

791
00:34:22,920 --> 00:34:27,000
where using knowledge-based retrieve API,

792
00:34:27,000 --> 00:34:30,930
we can just retrieve the
context out of the vector store.

793
00:34:30,930 --> 00:34:32,490
So we will use this tool

794
00:34:32,490 --> 00:34:33,990
which is an additional tool

795
00:34:33,990 --> 00:34:36,720
and we are adding another
function over here

796
00:34:36,720 --> 00:34:41,190
which will evaluate the
quality of the response

797
00:34:41,190 --> 00:34:43,830
which is generated from the LLM.

798
00:34:43,830 --> 00:34:45,000
So this is another tool

799
00:34:45,000 --> 00:34:46,770
and as we discussed earlier,

800
00:34:46,770 --> 00:34:48,360
it will be based on the relevance,

801
00:34:48,360 --> 00:34:53,360
the factual accuracy and the
accuracy of the response.

802
00:34:56,760 --> 00:34:58,923
So let's look at it.

803
00:35:00,810 --> 00:35:03,750
So we will first create
all these five tools

804
00:35:03,750 --> 00:35:04,743
that we just see.

805
00:35:06,090 --> 00:35:08,763
The initial tool, retrieve documents tool.

806
00:35:10,410 --> 00:35:12,213
Here we are using retrieve API.

807
00:35:14,130 --> 00:35:15,570
This is a knowledge base API.

808
00:35:15,570 --> 00:35:17,880
We just provide the KPID and the question,

809
00:35:17,880 --> 00:35:21,240
it will be able to get the
response out of the vector store

810
00:35:21,240 --> 00:35:24,000
and provide the chunks to us.

811
00:35:24,000 --> 00:35:26,310
So that's the only thing it is doing.

812
00:35:26,310 --> 00:35:27,826
We are not using retrieve and generate,

813
00:35:27,826 --> 00:35:29,400
just the retrieve API.

814
00:35:29,400 --> 00:35:30,330
Yeah.

815
00:35:30,330 --> 00:35:32,370
This is also useful in some cases

816
00:35:32,370 --> 00:35:34,620
where there are certain LLMs

817
00:35:34,620 --> 00:35:35,970
which are provided by Knowledge Bases.

818
00:35:35,970 --> 00:35:38,100
But say you want to use your custom model.

819
00:35:38,100 --> 00:35:39,840
So in that case you can
retrieve the document

820
00:35:39,840 --> 00:35:41,220
using retrieve API

821
00:35:41,220 --> 00:35:45,930
and then generate the response
using your own custom LLM.

822
00:35:45,930 --> 00:35:47,160
Yeah.

823
00:35:47,160 --> 00:35:48,840
So this tool is defined now.

824
00:35:48,840 --> 00:35:49,740
Retrieve and generate.

825
00:35:49,740 --> 00:35:51,450
This is exactly the same tool

826
00:35:51,450 --> 00:35:53,460
that Pallavi already went over,

827
00:35:53,460 --> 00:35:57,630
so I'll skip over it.

828
00:35:57,630 --> 00:35:58,983
Retrieve and generate API.

829
00:36:00,600 --> 00:36:01,710
Decompose and generate.

830
00:36:01,710 --> 00:36:04,920
This is again the same tool.
Pallavi already went over it.

831
00:36:04,920 --> 00:36:07,230
We are using the same API,
retrieve and generate.

832
00:36:07,230 --> 00:36:09,990
The only change here
is query decomposition

833
00:36:09,990 --> 00:36:12,750
as the query transformation configuration.

834
00:36:12,750 --> 00:36:13,583
Yeah.

835
00:36:15,120 --> 00:36:17,400
Now, query expansion agent.

836
00:36:17,400 --> 00:36:19,530
So this query expansion agent,

837
00:36:19,530 --> 00:36:22,620
it's written using strengths agent

838
00:36:22,620 --> 00:36:27,420
which is open source SDK provided by AWS

839
00:36:27,420 --> 00:36:30,510
which is used for writing agents.

840
00:36:30,510 --> 00:36:33,090
You can write agent code
using the strengths agent.

841
00:36:33,090 --> 00:36:36,780
You have Creao AI, you have
LangChain which you can use.

842
00:36:36,780 --> 00:36:38,850
Over here we have used Strands Agent.

843
00:36:38,850 --> 00:36:40,620
So with Strands Agent,

844
00:36:40,620 --> 00:36:42,060
I have defined the agent,

845
00:36:42,060 --> 00:36:44,013
which is query_expansion_agent_tool.

846
00:36:46,050 --> 00:36:47,310
ModelID lookup_term.

847
00:36:47,310 --> 00:36:49,470
This is the same tool that
Pallavi already defined

848
00:36:49,470 --> 00:36:53,910
and lookup_term is the tool
for this query expansion agent.

849
00:36:53,910 --> 00:36:54,743
Yeah.

850
00:36:55,710 --> 00:36:58,710
So this, we already went over the code.

851
00:36:58,710 --> 00:37:02,940
So I will go to the next
tool, which is the last tool,

852
00:37:02,940 --> 00:37:05,280
evaluate the response quality with agent.

853
00:37:05,280 --> 00:37:08,160
Now here again, I'm using agent.

854
00:37:08,160 --> 00:37:12,150
This is a agent which is a tool, right?

855
00:37:12,150 --> 00:37:15,720
So I will come over how to use this

856
00:37:15,720 --> 00:37:16,980
within the central agent.

857
00:37:16,980 --> 00:37:19,260
So here again I define the agent.

858
00:37:19,260 --> 00:37:22,320
I provided the name of
the agent, the model,

859
00:37:22,320 --> 00:37:23,820
which model I want to use.

860
00:37:23,820 --> 00:37:26,640
So here, if you see the
model that I'm using,

861
00:37:26,640 --> 00:37:27,570
it's a different agent.

862
00:37:27,570 --> 00:37:29,610
It's a qualityCheckModelId.

863
00:37:29,610 --> 00:37:32,700
I'm using Claude Sonnet 4.5 here.

864
00:37:32,700 --> 00:37:35,550
So earlier you see for the basic RAG

865
00:37:35,550 --> 00:37:38,310
we are using Claude Haiku 4.5

866
00:37:38,310 --> 00:37:40,380
which is a lighter and a faster model.

867
00:37:40,380 --> 00:37:42,390
Here I wanted a reasoning model

868
00:37:42,390 --> 00:37:44,910
and I wanted a model
which has more parameters.

869
00:37:44,910 --> 00:37:47,790
So I'm using Claude Sonnet 4.5 over here.

870
00:37:47,790 --> 00:37:51,690
So depending on the use case,
you choose the right model.

871
00:37:51,690 --> 00:37:53,910
And then I'm providing a system prompt.

872
00:37:53,910 --> 00:37:57,270
Now here in the system prompt,
like we discussed earlier,

873
00:37:57,270 --> 00:38:00,090
I have provided a evaluation criteria

874
00:38:00,090 --> 00:38:03,870
where I wanted to check based
on the relevance, completeness

875
00:38:03,870 --> 00:38:07,080
and the factual accuracy of the response

876
00:38:07,080 --> 00:38:09,330
and provide that,

877
00:38:09,330 --> 00:38:12,090
okay this is the quality
score according to that

878
00:38:12,090 --> 00:38:13,830
and that's it.

879
00:38:13,830 --> 00:38:15,060
So this agent is defined.

880
00:38:15,060 --> 00:38:18,840
Now I have all my tools defined

881
00:38:18,840 --> 00:38:20,160
and you would have noticed

882
00:38:20,160 --> 00:38:24,120
some of the tools were mere functions

883
00:38:24,120 --> 00:38:27,360
and some of the tools
were actually subagents.

884
00:38:27,360 --> 00:38:29,940
Now, I need to create a central agent

885
00:38:29,940 --> 00:38:31,620
which can orchestrate the flow

886
00:38:31,620 --> 00:38:33,720
between all these different tools.

887
00:38:33,720 --> 00:38:36,180
That's where I will
create the central agent

888
00:38:36,180 --> 00:38:38,190
and again, I'm using Strands Agent

889
00:38:38,190 --> 00:38:39,690
for writing the central agent.

890
00:38:41,610 --> 00:38:44,190
So here, first I have
defined all the tools.

891
00:38:44,190 --> 00:38:45,660
The tools have already been defined here,

892
00:38:45,660 --> 00:38:47,760
I have just suggested
that these are the tools

893
00:38:47,760 --> 00:38:48,750
which are there.

894
00:38:48,750 --> 00:38:51,540
And then, same way I'm creating the agent,

895
00:38:51,540 --> 00:38:53,460
I'm defining the name of the agent,

896
00:38:53,460 --> 00:38:55,410
I'm defining that this is the model ID.

897
00:38:55,410 --> 00:38:58,500
Here also, I wanted to
use quality check model ID

898
00:38:58,500 --> 00:39:02,043
which is Claude Sonnet 4.5.

899
00:39:03,931 --> 00:39:06,069
These are the all the tools that you have.

900
00:39:06,069 --> 00:39:08,100
And then I'm providing a system prompt

901
00:39:08,100 --> 00:39:11,070
suggesting the same
flow which we discussed

902
00:39:11,070 --> 00:39:13,320
as part of the flow
diagram in the presentation

903
00:39:13,320 --> 00:39:16,230
where you have to first
retrieve the chunks

904
00:39:16,230 --> 00:39:20,610
then do the chunk relevancy check

905
00:39:20,610 --> 00:39:24,660
and this particular agent will do that.

906
00:39:24,660 --> 00:39:27,150
And here, if you would have noticed it,

907
00:39:27,150 --> 00:39:29,370
I'm using LLM-as-a-Judge concept

908
00:39:29,370 --> 00:39:32,100
for doing the context relevancy check

909
00:39:32,100 --> 00:39:36,060
and as well as later on for
quality relevance check.

910
00:39:36,060 --> 00:39:38,430
So both our LLM-as-a-Judge concept.

911
00:39:38,430 --> 00:39:41,280
There are different
tools which are available

912
00:39:41,280 --> 00:39:45,270
like RAG checker or RAGAs
which you can also use.

913
00:39:45,270 --> 00:39:46,620
Those are open-source tools

914
00:39:46,620 --> 00:39:48,750
for doing the context relevancy check

915
00:39:48,750 --> 00:39:50,370
and the response relevancy check.

916
00:39:50,370 --> 00:39:52,983
Here I'm using plain
LLM-as-a-Judge concept.

917
00:39:54,330 --> 00:39:57,600
And once I have defined
this central agent,

918
00:39:57,600 --> 00:39:59,460
so let's execute these cells, right?

919
00:39:59,460 --> 00:40:01,110
So first, I'll execute the cell

920
00:40:01,110 --> 00:40:03,340
where I'm creating all the tools

921
00:40:04,860 --> 00:40:09,813
and once I have all the
tools created or defined,

922
00:40:11,190 --> 00:40:13,470
let me execute the cell

923
00:40:13,470 --> 00:40:16,090
where it creates the central agent

924
00:40:17,790 --> 00:40:20,220
and now I need to kick
off the central agent.

925
00:40:20,220 --> 00:40:21,690
This piece of code,

926
00:40:21,690 --> 00:40:24,840
it just calling the central
agent that we just defined.

927
00:40:24,840 --> 00:40:28,440
Rest of the code is just
for the display purpose

928
00:40:28,440 --> 00:40:29,880
so that the output is displayed

929
00:40:29,880 --> 00:40:32,100
so that you can understand that.

930
00:40:32,100 --> 00:40:35,550
Here, I will be asking the same questions

931
00:40:35,550 --> 00:40:37,650
that Pallavi just went over.

932
00:40:37,650 --> 00:40:41,400
The first two questions are
plain and simple question

933
00:40:41,400 --> 00:40:44,400
and then the rest of the three questions

934
00:40:44,400 --> 00:40:48,090
are a little bit complex question.

935
00:40:48,090 --> 00:40:49,320
So we'll see how

936
00:40:49,320 --> 00:40:53,880
the corrective central
agent behaves over here.

937
00:40:53,880 --> 00:40:55,713
Let me execute this particular cell.

938
00:40:59,310 --> 00:41:01,980
Okay, so the first question,

939
00:41:01,980 --> 00:41:04,473
what is fair value of STM portfolio?

940
00:41:06,510 --> 00:41:10,950
It first used retrieve documents tool

941
00:41:10,950 --> 00:41:14,910
to retrieve the chunks out
of the vector database.

942
00:41:14,910 --> 00:41:17,700
Once it has the chunks out,

943
00:41:17,700 --> 00:41:19,983
it will do the chunk relevancy check.

944
00:41:21,000 --> 00:41:23,460
So here it checks. Excellent.

945
00:41:23,460 --> 00:41:26,670
The retrieved documents contain
highly relevant information

946
00:41:26,670 --> 00:41:28,710
that directly answers the question.

947
00:41:28,710 --> 00:41:30,300
So it is satisfied with that.

948
00:41:30,300 --> 00:41:33,510
So it checked which strategy should I use.

949
00:41:33,510 --> 00:41:35,010
I already have the relevant chunk.

950
00:41:35,010 --> 00:41:36,720
Let me use the basic RAG strategy

951
00:41:36,720 --> 00:41:39,390
where it used retrieve and generate tool

952
00:41:39,390 --> 00:41:40,470
and it found the answer,

953
00:41:40,470 --> 00:41:43,800
the fair value of
held-to-maturity portfolio

954
00:41:43,800 --> 00:41:47,910
was dollar 1.2 billion as
of December 31st, 2021.

955
00:41:47,910 --> 00:41:49,740
Now I have the response.

956
00:41:49,740 --> 00:41:54,180
I want to do the quality of
the response check as well.

957
00:41:54,180 --> 00:41:56,793
So I will check the response quality.

958
00:41:57,960 --> 00:42:00,960
So this is the quality inspection
agent which is triggered

959
00:42:00,960 --> 00:42:04,470
and it found that it is relevant.

960
00:42:04,470 --> 00:42:05,730
The completeness is also good

961
00:42:05,730 --> 00:42:08,190
and the factual accuracy is also good.

962
00:42:08,190 --> 00:42:10,410
So overall quality is good. Excellent.

963
00:42:10,410 --> 00:42:13,290
So it identified it as the final answer.

964
00:42:13,290 --> 00:42:15,630
It didn't go to the loop again.

965
00:42:15,630 --> 00:42:18,600
It found the answer. This is the answer.

966
00:42:18,600 --> 00:42:20,100
So the simple answer,

967
00:42:20,100 --> 00:42:23,100
it used basic RAG technique
and it got the answer.

968
00:42:23,100 --> 00:42:24,570
Now let's go to the second question

969
00:42:24,570 --> 00:42:27,750
which is what are the
main business segments

970
00:42:27,750 --> 00:42:29,850
of Octank Financial?

971
00:42:29,850 --> 00:42:34,530
So here again, retrieve
documents as the first tool.

972
00:42:34,530 --> 00:42:38,370
Got the chunks, let's check
the relevancy of these chunks.

973
00:42:38,370 --> 00:42:39,870
Corresponding to the question,

974
00:42:41,370 --> 00:42:44,130
the retrieve documents contain
highly relevant information

975
00:42:44,130 --> 00:42:45,270
about Octank financial.

976
00:42:45,270 --> 00:42:48,120
The context is clear and
directly addresses the question.

977
00:42:48,120 --> 00:42:50,520
So it determined that I need to use

978
00:42:50,520 --> 00:42:51,540
retrieve and generate,

979
00:42:51,540 --> 00:42:53,100
which is a basic RAG

980
00:42:53,100 --> 00:42:56,190
and it found the answer response

981
00:42:56,190 --> 00:42:57,480
saying that okay,

982
00:42:57,480 --> 00:43:00,450
these are the different
investment banking divisions

983
00:43:00,450 --> 00:43:01,283
which are there.

984
00:43:02,490 --> 00:43:03,720
Once it has the response,

985
00:43:03,720 --> 00:43:05,973
it again did the response quality check.

986
00:43:07,470 --> 00:43:10,070
The response is relevant, highly relevant,

987
00:43:10,070 --> 00:43:11,160
10 out of 10.

988
00:43:11,160 --> 00:43:13,920
Complete and factual
accuracy is also good.

989
00:43:13,920 --> 00:43:16,203
So the quality is good. Excellent.

990
00:43:17,130 --> 00:43:18,840
It used basic RAG

991
00:43:18,840 --> 00:43:21,300
and it found the answer
within one go itself.

992
00:43:21,300 --> 00:43:23,790
For the first two questions, we are good.

993
00:43:23,790 --> 00:43:25,833
Let's move to the next question,

994
00:43:26,940 --> 00:43:29,490
which is provide the list of DCMs.

995
00:43:29,490 --> 00:43:32,280
And as Pallavi showed earlier,

996
00:43:32,280 --> 00:43:34,770
DCM is not even defined in the PDF.

997
00:43:34,770 --> 00:43:36,900
So let's see how it behaves over here.

998
00:43:36,900 --> 00:43:40,770
It did the retrieve
documents, it found chunks,

999
00:43:40,770 --> 00:43:43,083
it did the chunk
relevancy check over here.

1000
00:43:44,790 --> 00:43:46,200
When it did the chunk relevancy,

1001
00:43:46,200 --> 00:43:49,680
it sees that I can see
that the retrieve documents

1002
00:43:49,680 --> 00:43:51,570
are about Octank Financial data centers

1003
00:43:51,570 --> 00:43:53,280
committee and corporate governance.

1004
00:43:53,280 --> 00:43:55,713
So this is how it internally expanded,

1005
00:43:56,610 --> 00:44:00,360
but they don't specifically
address DCMs as a list.

1006
00:44:00,360 --> 00:44:05,360
So the chunks are not
relevant to the question.

1007
00:44:06,360 --> 00:44:09,120
So it used query expansion agent.

1008
00:44:09,120 --> 00:44:12,870
Let me try to expand DCM.

1009
00:44:12,870 --> 00:44:17,730
So it used lookup term
query expansion subagent.

1010
00:44:17,730 --> 00:44:19,890
And within the query expansion subagent,

1011
00:44:19,890 --> 00:44:21,960
it used the lookup term.

1012
00:44:21,960 --> 00:44:26,340
It found the definition of DCM,
disclosure committee member

1013
00:44:26,340 --> 00:44:28,800
and it provided a new question saying that

1014
00:44:28,800 --> 00:44:31,290
provide the list of
disclosure committee members.

1015
00:44:31,290 --> 00:44:33,540
Now let's ask this question.

1016
00:44:33,540 --> 00:44:35,460
It used retrieve and generate

1017
00:44:35,460 --> 00:44:38,100
and it found the answers to the question.

1018
00:44:38,100 --> 00:44:39,960
And then once I have the answer,

1019
00:44:39,960 --> 00:44:42,600
I have to do the response relevance check.

1020
00:44:42,600 --> 00:44:45,630
So let's do the response relevant check.

1021
00:44:45,630 --> 00:44:48,210
Relevance is good,
completeness is also good.

1022
00:44:48,210 --> 00:44:50,370
Factual accuracy is okay.

1023
00:44:50,370 --> 00:44:51,360
The status is good,

1024
00:44:51,360 --> 00:44:53,310
overall quality is good.

1025
00:44:53,310 --> 00:44:57,150
So it selected this as the final answer

1026
00:44:57,150 --> 00:44:58,530
and suggested that okay,

1027
00:44:58,530 --> 00:45:00,360
I used query expansion,

1028
00:45:00,360 --> 00:45:01,920
then I used the basic RAG.

1029
00:45:01,920 --> 00:45:03,300
The quality is good.

1030
00:45:03,300 --> 00:45:06,630
Specifically, it's checking
the response relevance,

1031
00:45:06,630 --> 00:45:07,710
which is good.

1032
00:45:07,710 --> 00:45:11,100
And it found the answer to the question

1033
00:45:11,100 --> 00:45:13,983
with one attempt.

1034
00:45:14,820 --> 00:45:17,043
Now let's go to the fourth question.

1035
00:45:18,840 --> 00:45:20,430
What is Octank Tower

1036
00:45:20,430 --> 00:45:22,290
and how does the whistleblower scandal

1037
00:45:22,290 --> 00:45:24,780
hurt the company and its image?

1038
00:45:24,780 --> 00:45:26,400
Now again, it will do the same thing.

1039
00:45:26,400 --> 00:45:27,600
It will retrieve the documents,

1040
00:45:27,600 --> 00:45:30,180
it will check the relevancy of the chunks

1041
00:45:30,180 --> 00:45:31,180
which are retrieved.

1042
00:45:32,580 --> 00:45:36,480
It sees that it has two parts.

1043
00:45:36,480 --> 00:45:38,580
It is able to identify
that, what is Octank Tower

1044
00:45:38,580 --> 00:45:41,160
and how does whistleblower
scandal hurt the company?

1045
00:45:41,160 --> 00:45:46,160
It found that the whistleblower
scandal information is there

1046
00:45:46,560 --> 00:45:49,050
but it doesn't notice any information

1047
00:45:49,050 --> 00:45:50,550
related to Octank Tower.

1048
00:45:50,550 --> 00:45:53,460
Now since it identified
it's a multi-part question,

1049
00:45:53,460 --> 00:45:57,003
it straight away used
decompose and generate tool.

1050
00:45:58,500 --> 00:46:02,310
It found out the answer,
Octank Tower is this.

1051
00:46:02,310 --> 00:46:04,260
And then the whistleblower scandal also,

1052
00:46:04,260 --> 00:46:06,570
it found out the answer related to that.

1053
00:46:06,570 --> 00:46:10,860
The whistleblower scandal
involving person X, right?

1054
00:46:10,860 --> 00:46:12,870
Now, once I have this response

1055
00:46:12,870 --> 00:46:15,330
from decompose and generate,

1056
00:46:15,330 --> 00:46:17,640
I have to do the response relevance check.

1057
00:46:17,640 --> 00:46:21,750
So the response relevance check is done,

1058
00:46:21,750 --> 00:46:24,480
the relevance is high,
which is most important.

1059
00:46:24,480 --> 00:46:26,970
Completeness is good,
factual accuracy is good.

1060
00:46:26,970 --> 00:46:29,610
So it selected this as the final answer.

1061
00:46:29,610 --> 00:46:32,763
It used decompose and
generate and found the answer.

1062
00:46:34,290 --> 00:46:36,720
Now let's go to the last one.

1063
00:46:36,720 --> 00:46:39,663
Provide list of DCMs and
how many regional offices.

1064
00:46:40,890 --> 00:46:43,260
Again, it did the retrieve document.

1065
00:46:43,260 --> 00:46:45,753
Check the relevance of
the retrieved documents.

1066
00:46:46,650 --> 00:46:48,990
It doesn't found
information related to DCMs,

1067
00:46:48,990 --> 00:46:52,110
so it used query expansion tool

1068
00:46:52,110 --> 00:46:55,200
to find the information about DCM.

1069
00:46:55,200 --> 00:46:56,800
Disclosure the committee member.

1070
00:46:58,350 --> 00:47:00,960
Now here you see it didn't
use retrieve and generate

1071
00:47:00,960 --> 00:47:02,730
because it identified this,

1072
00:47:02,730 --> 00:47:05,160
it is a two-part question,
multi-part question.

1073
00:47:05,160 --> 00:47:07,200
So here, after query expansion,

1074
00:47:07,200 --> 00:47:09,630
it used decompose and generate

1075
00:47:09,630 --> 00:47:11,190
and it found out the answer

1076
00:47:11,190 --> 00:47:15,270
which is suggesting disclosure
committee members are these.

1077
00:47:15,270 --> 00:47:19,020
And then these are the regional offices

1078
00:47:19,020 --> 00:47:21,780
which are within North
America, Europe, Asia,

1079
00:47:21,780 --> 00:47:22,613
and Oceania.

1080
00:47:24,710 --> 00:47:28,560
And last I have to now do
the response quality check.

1081
00:47:28,560 --> 00:47:31,110
So relevance, the answer is in fact

1082
00:47:31,110 --> 00:47:33,060
relevant to the question,

1083
00:47:33,060 --> 00:47:34,050
it is complete.

1084
00:47:34,050 --> 00:47:35,910
Factual accuracy is also good.

1085
00:47:35,910 --> 00:47:38,490
So it identified it as a good candidate

1086
00:47:38,490 --> 00:47:41,550
and oh, it actually identified

1087
00:47:41,550 --> 00:47:43,710
some of the recommendations
for improvement.

1088
00:47:43,710 --> 00:47:46,780
So it again went for retrieve
and generate this time

1089
00:47:48,330 --> 00:47:51,030
and okay, it found,

1090
00:47:51,030 --> 00:47:52,140
okay, query expansion,

1091
00:47:52,140 --> 00:47:53,790
decomposition, basic RAG.

1092
00:47:53,790 --> 00:47:57,450
Again, the quality is similar
to what it was earlier

1093
00:47:57,450 --> 00:48:00,345
and it identified that okay,
I have the final answer.

1094
00:48:00,345 --> 00:48:02,880
I tried decompose and
generate and I got the answer.

1095
00:48:02,880 --> 00:48:05,130
This is also similar quality.

1096
00:48:05,130 --> 00:48:07,983
So it used that as the final answer,

1097
00:48:08,970 --> 00:48:11,160
which is disclosure
committee members are this

1098
00:48:11,160 --> 00:48:13,320
and these are the regional offices.

1099
00:48:13,320 --> 00:48:16,625
So yeah, this is how you see

1100
00:48:16,625 --> 00:48:19,770
how the self-corrective agentic RAG work

1101
00:48:19,770 --> 00:48:22,350
where based on the central agent,

1102
00:48:22,350 --> 00:48:25,440
it is able to utilize
the appropriate strategy.

1103
00:48:25,440 --> 00:48:28,050
And again, we have quality inspection

1104
00:48:28,050 --> 00:48:29,670
and the chunk inspection

1105
00:48:29,670 --> 00:48:31,110
as few of the strategies

1106
00:48:31,110 --> 00:48:33,510
that it is using for doing the looping.

1107
00:48:33,510 --> 00:48:37,590
Now these are a few of the
techniques that we have,

1108
00:48:37,590 --> 00:48:41,370
but there are several different
techniques which are there,

1109
00:48:41,370 --> 00:48:43,380
but we have limited time.

1110
00:48:43,380 --> 00:48:48,258
So that's where we have to actually,

1111
00:48:48,258 --> 00:48:50,970
I just want to touch upon
few of the other techniques

1112
00:48:50,970 --> 00:48:52,080
which are there as well.

1113
00:48:52,080 --> 00:48:56,370
So Pallavi touched upon ingestion flow

1114
00:48:56,370 --> 00:48:58,470
as well as the retrieval flow.

1115
00:48:58,470 --> 00:49:00,300
And within the ingestion flow,

1116
00:49:00,300 --> 00:49:03,570
you can enhance the quality of the chunks

1117
00:49:03,570 --> 00:49:05,460
and the embeddings,

1118
00:49:05,460 --> 00:49:08,610
which will be ultimately
stored in the vector database,

1119
00:49:08,610 --> 00:49:10,680
which helps in ultimately improving

1120
00:49:10,680 --> 00:49:12,060
the retrieval accuracy as well.

1121
00:49:12,060 --> 00:49:14,640
So some of the strategies
are chunking strategies.

1122
00:49:14,640 --> 00:49:16,890
We used fixed chunking over here,

1123
00:49:16,890 --> 00:49:18,390
but there are other chunking strategies

1124
00:49:18,390 --> 00:49:19,560
like semantic chunking

1125
00:49:19,560 --> 00:49:24,297
where it keeps the
semantically similar embeddings

1126
00:49:26,940 --> 00:49:27,773
near to each other

1127
00:49:27,773 --> 00:49:29,190
so that within the same chunk

1128
00:49:29,190 --> 00:49:30,033
you can find it.

1129
00:49:31,140 --> 00:49:34,050
Other strategies,
foundation model parsing.

1130
00:49:34,050 --> 00:49:38,520
So say you have a document
which has a lot of images,

1131
00:49:38,520 --> 00:49:41,370
graphs, these kind of things.

1132
00:49:41,370 --> 00:49:45,900
Then you might first want
to use foundation model

1133
00:49:45,900 --> 00:49:48,630
to actually ingest the
data out of the document

1134
00:49:48,630 --> 00:49:53,220
and then ingest that data
within the vector store.

1135
00:49:53,220 --> 00:49:56,370
So this is another
technique which can be used.

1136
00:49:56,370 --> 00:49:58,140
Multimodal parsing is another thing

1137
00:49:58,140 --> 00:50:01,410
where say you have images within your PDF

1138
00:50:01,410 --> 00:50:03,891
and when you are retrieving the documents

1139
00:50:03,891 --> 00:50:06,120
and we are generating the answer,

1140
00:50:06,120 --> 00:50:11,070
you want to show the images
also as along with the answer.

1141
00:50:11,070 --> 00:50:13,950
So that's where the multimodal
parsing come into picture.

1142
00:50:13,950 --> 00:50:16,140
Metadata labeling is another technique

1143
00:50:16,140 --> 00:50:18,450
where you can define that okay,

1144
00:50:18,450 --> 00:50:22,140
you have multiple documents
within your data source

1145
00:50:22,140 --> 00:50:23,430
and you want to label it

1146
00:50:23,430 --> 00:50:25,350
so that when you are asking question,

1147
00:50:25,350 --> 00:50:26,400
depending on your question,

1148
00:50:26,400 --> 00:50:27,240
it will identify

1149
00:50:27,240 --> 00:50:29,430
I have to use this
particular label document

1150
00:50:29,430 --> 00:50:32,130
and it can directly get
the answer from there.

1151
00:50:32,130 --> 00:50:34,410
These are few of the techniques
for the ingestion flow.

1152
00:50:34,410 --> 00:50:37,470
Then we have certain techniques
within the retrieval flow.

1153
00:50:37,470 --> 00:50:39,780
We touched upon several techniques here,

1154
00:50:39,780 --> 00:50:42,330
but the metadata filtering
is another technique

1155
00:50:42,330 --> 00:50:44,310
where we can use the metadata.

1156
00:50:44,310 --> 00:50:47,641
We can specify that say for example,

1157
00:50:47,641 --> 00:50:52,641
you have a scenario where you have say

1158
00:50:54,210 --> 00:50:55,043
- [Pallavi] Large documents.

1159
00:50:55,043 --> 00:50:56,400
- [Vivek] English,

1160
00:50:56,400 --> 00:50:59,880
say there it's related
to educational domain

1161
00:50:59,880 --> 00:51:02,190
where you want to get an answer

1162
00:51:02,190 --> 00:51:04,710
for English or science.

1163
00:51:04,710 --> 00:51:07,740
So based on your metadata,

1164
00:51:07,740 --> 00:51:09,240
it can use the particular document

1165
00:51:09,240 --> 00:51:12,030
from your knowledge source
because it is labeled.

1166
00:51:12,030 --> 00:51:13,203
Re-ranking is another technique.

1167
00:51:13,203 --> 00:51:16,980
When you get the chunks
out of the vector store,

1168
00:51:16,980 --> 00:51:19,080
you actually want to re-rank them

1169
00:51:19,080 --> 00:51:22,530
so that most relevant chunks
are on the top of the search

1170
00:51:22,530 --> 00:51:24,600
and then it can find out
the answer out of that.

1171
00:51:24,600 --> 00:51:26,130
Hybrid search is another technique

1172
00:51:26,130 --> 00:51:30,060
where you can use the
combination of semantic chunking,

1173
00:51:30,060 --> 00:51:32,700
semantic search and the keyword search.

1174
00:51:32,700 --> 00:51:33,960
So with semantic search,

1175
00:51:33,960 --> 00:51:35,910
you get the semantically similar answer,

1176
00:51:35,910 --> 00:51:38,070
but sometimes you want
to use the keyword search

1177
00:51:38,070 --> 00:51:39,510
for exact answers

1178
00:51:39,510 --> 00:51:42,030
so it can identify which
is the best technique

1179
00:51:42,030 --> 00:51:44,550
and it it can use in
that particular technique

1180
00:51:44,550 --> 00:51:46,140
for answering the question.

1181
00:51:46,140 --> 00:51:48,090
So these are a few of the
techniques which you can use

1182
00:51:48,090 --> 00:51:50,640
for further enhancing your RAG accuracy.

1183
00:51:50,640 --> 00:51:55,640
And these are some of the blogs and papers

1184
00:51:56,400 --> 00:51:59,520
that you would like to just have with you

1185
00:51:59,520 --> 00:52:02,520
and look at it for some further learning.

1186
00:52:02,520 --> 00:52:03,420
Yeah.

1187
00:52:03,420 --> 00:52:05,910
We are open for questions.

1188
00:52:05,910 --> 00:52:08,910
We have seven more minutes

1189
00:52:08,910 --> 00:52:12,840
and we'll try to answer as
many questions as we can,

1190
00:52:12,840 --> 00:52:15,240
but we have to leave
at the end of the hour

1191
00:52:15,240 --> 00:52:18,330
so we will be available outside
for any further questions.

1192
00:52:18,330 --> 00:52:20,700
- [Pallavi] And I think just to conclude,

1193
00:52:20,700 --> 00:52:24,180
I mean we did see the whole goal for us

1194
00:52:24,180 --> 00:52:28,800
was to mainly divide this into
first context relevancy check

1195
00:52:28,800 --> 00:52:30,750
and then the retrieval relevancy

1196
00:52:30,750 --> 00:52:32,970
to improve your RAG accuracy.

1197
00:52:32,970 --> 00:52:35,580
And that's where sort of the decisioning

1198
00:52:35,580 --> 00:52:38,220
with the self-corrective
RAG came into picture

1199
00:52:38,220 --> 00:52:39,240
is to identify.

1200
00:52:39,240 --> 00:52:41,790
So just when you are thinking about

1201
00:52:41,790 --> 00:52:44,640
how do I improve the accuracy of the RAG,

1202
00:52:44,640 --> 00:52:46,530
think the document ingestion,

1203
00:52:46,530 --> 00:52:48,720
think about the context relevancy.

1204
00:52:48,720 --> 00:52:50,310
That's the first thing you can check.

1205
00:52:50,310 --> 00:52:52,083
And the retrieval relevancy.

