# AWS re:Invent 2025 会议总结：构建生产级生成式AI和智能体应用的基础架构

## 会议概述

本次AWS re:Invent 2025分组会议由AWS的生成式AI专家Chaititra和Amna，以及来自Sage公司的Dave共同主讲，重点探讨了如何构建强大的基础架构来支持生成式AI和智能体应用的生产部署和规模化运营。

会议指出，虽然生成式AI应用看似简单（输入提示词，获得响应），但实际生产环境中的复杂性远超想象。随着企业从概念验证阶段转向大规模生产部署，需要面对性能优化、可扩展性、安全隔离、上下文管理、持续监控等多重技术挑战。为此，AWS提出了一套全面的基础架构框架，涵盖模型中心、智能体和工具中心、网关层、执行运行时、数据层、编排层以及三大支柱（运营卓越、可观测性和安全性）。

会议通过实际演示展示了如何将这些基础组件整合在一起，包括使用Amazon Bedrock和Amazon Bedrock Agent Core构建的客户服务智能体应用，该应用集成了LLM网关、工具网关、RAG检索、第三方API调用、护栏机制以及基于Langfuse的可观测性和离线评估系统。Sage公司的实践案例进一步验证了这套架构在企业级应用中的可行性。

## 详细时间线与关键要点

### 开场介绍 (00:00 - 02:30)
- **00:00** - 会议开始，主讲人Chaititra（AWS生成式AI专家）欢迎参会者
- **00:30** - Amna介绍自己为AWS高级生成式AI解决方案架构师
- **01:00** - Dave介绍自己来自Sage公司都柏林团队，负责数据和AI中心服务

### 会议主题与挑战 (02:30 - 06:00)
- **02:30** - 提出核心问题：从简单的聊天机器人到复杂的生产环境部署
- **03:00** - 强调现实中的复杂性：编排、智能体、RAG、护栏等多个层面
- **03:30** - 指出将多个应用投入生产的挑战和复杂性
- **04:00** - 现场调查：多数参会者已开发POC，部分已投入生产
- **04:30** - 列举主要挑战：性能（低延迟）、可扩展性、安全隔离、上下文管理
- **05:30** - 强调持续监控、评估和审计的重要性

### 基础架构框架 (06:00 - 12:00)
- **06:00** - 提出"强大基础架构"的概念：适用于单个或多个应用场景
- **06:30** - 介绍平台团队视角：集中化组件、共享服务、统一治理
- **07:00** - 展示综合基础架构图：模型中心、智能体和工具中心、网关层
- **07:30** - 数据层：构建注入管道、索引管道、向量存储、长短期记忆存储
- **08:00** - 编排层：工作流（已知步骤序列）vs 智能体（动态决策）
- **08:30** - 客户端访问层和三大支柱：运营卓越、可观测性、安全性
- **09:00** - 强调可观测性的重要性：洞察黑盒系统内部运作
- **10:00** - 介绍Amazon Bedrock：完全托管的生成式AI服务，提供多种模型访问
- **11:00** - 介绍Amazon Bedrock Agent Core：完全托管的智能体平台，提供安全运行时、记忆管理、工具网关

### 网关架构详解 (12:00 - 18:00)
- **12:00** - 三种网关模式：LLM网关、工具网关、智能体网关
- **12:30** - LLM网关功能：统一API、成本归因、速率限制、护栏应用
- **13:30** - 使用场景：跨多个提供商（Bedrock、SageMaker、EKS、第三方）访问模型
- **14:00** - 介绍LiteLLM解决方案：开源网关，AWS发布了部署方案
- **15:00** - 工具和智能体注册表：集中管理工具和智能体目录
- **15:30** - Agent Core Gateway示例：提供统一工具访问，支持API、Lambda、MCP服务器
- **16:30** - 介绍开源综合网关解决方案：支持MCP、智能体、企业级可观测性
- **17:00** - 支持M2M（JWT）和3LO身份验证

### 可观测性深度解析 (18:00 - 25:00)
- **18:00** - 可观测性范式转变：从"保持系统存活"到"保持系统对齐"
- **18:30** - 关注点转变：从正常运行时间、延迟、错误到质量、偏见、毒性、幻觉
- **19:00** - 四大监控维度：质量、成本、延迟、风险
- **19:30** - 质量指标：检索相关性、工具选择准确性、参数传递正确性、用户反馈
- **20:30** - 风险指标：PII泄露、毒性输出、偏见检测
- **21:00** - 可观测性系统架构：信号收集→聚合可视化→评估层→优化循环
- **22:00** - 评估类型：离线评估（开发阶段，黄金数据集）vs 在线评估（生产环境，实际用户交互）
- **23:00** - 三种评估方法：自动化评估（代码/正则表达式）、LLM作为评判者、人工评估
- **24:00** - 实施方式：SDK集成 vs OpenTelemetry收集器（标准化遥测数据）

### 实际演示 (25:00 - 42:00)
- **25:00** - Amna开始演示"Agentic AI Foundation Accelerator"开源加速器
- **25:30** - 架构组件：Bedrock Agent Core运行时、LiteLLM网关、Langfuse可观测性
- **26:00** - 演示用例：客户服务聊天应用（可适配任何行业）
- **26:30** - 智能体使用三个工具：RAG检索（Bedrock知识库）、支持工单API、网络搜索（Tavily）
- **27:30** - 前端应用：基于Streamlit构建，支持本地模式和Agent Core模式
- **28:00** - 演示开始：智能体响应"你好"，展示客户服务能力
- **28:30** - RAG检索演示：询问如何重置路由器，智能体检索相关文档并提供答案
- **29:00** - 显示元数据：使用的模型、工具、引用来源、文档页码、追踪ID
- **30:00** - 工单创建演示：智能体主动提出创建支持工单
- **30:30** - 智能体收集必要信息（邮箱、问题描述）并调用创建工单工具
- **31:30** - 护栏演示：询问投资建议，系统拒绝并提示违反政策
- **32:00** - 短期记忆演示：智能体记住之前讨论的设备信息
- **32:30** - 切换到Agent Core模式：从本地测试转向云端部署
- **33:00** - 提供智能体标识符和OAuth访问令牌进行身份验证
- **34:00** - LiteLLM UI展示：模型目录、API密钥管理、使用仪表板
- **35:00** - 成本归因功能：按团队、API密钥、模型、提供商追踪支出
- **36:00** - 日志功能：每次模型调用的令牌数、成本、成功/失败状态
- **37:00** - Langfuse可观测性演示：追踪智能体交互的详细信息
- **37:30** - 追踪过滤：按用户ID、项目ID、标签分类
- **38:00** - 时间线视图：识别每个步骤的耗时，优化延迟
- **39:00** - 元数据详情：工具调用参数、检索相关性分数、检索项目
- **40:00** - 用户反馈收集：点赞/点踩、自然语言评论
- **41:00** - 离线评估演示：使用黄金数据集、LLM作为评判者、创建指标（延迟、忠实度、正确性、工具准确性）
- **42:00** - 总结演示：LLM网关、工具网关、可观测性、离线评估的集成

### Sage公司案例与运营智能体 (42:00 - 结束)
- **42:00** - 过渡到Sage公司的实践经验分享
- 会议强调了开源资源的可用性，鼓励参会者试用和贡献

### 关键资源
- **开源加速器**：Agentic AI Foundation Accelerator（GitHub资源将在会后提供）
- **核心服务**：Amazon Bedrock、Amazon Bedrock Agent Core
- **网关解决方案**：LiteLLM、Kong AI Gateway、Envoy、OpenRouter
- **可观测性工具**：Langfuse、Amazon CloudWatch
- **评估框架**：离线评估脚本、LLM评判者模式