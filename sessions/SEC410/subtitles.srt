1
00:00:00,900 --> 00:00:02,580
- All right.

2
00:00:02,580 --> 00:00:05,080
How many people here is
this their first re:Invent,

3
00:00:07,080 --> 00:00:11,223
fifth re:Invent? or five
or over? ten or over?

4
00:00:12,240 --> 00:00:14,160
Any hands? No hands.

5
00:00:14,160 --> 00:00:15,573
Okay. So five and over.

6
00:00:16,440 --> 00:00:18,194
So welcome to day one of re:Invent.

7
00:00:18,194 --> 00:00:20,550
Hope you're enjoying yourself so far.

8
00:00:20,550 --> 00:00:23,970
This is your first session.
Welcome to your first session.

9
00:00:23,970 --> 00:00:27,240
This is an advanced AI security session.

10
00:00:27,240 --> 00:00:30,240
This is a 400 level session
where we're gonna go deep

11
00:00:30,240 --> 00:00:33,180
into how to secure the AI workloads

12
00:00:33,180 --> 00:00:36,150
using AWS native capabilities,
open source frameworks,

13
00:00:36,150 --> 00:00:37,710
other things like that.

14
00:00:37,710 --> 00:00:38,910
My name is Riggs Goodman,

15
00:00:38,910 --> 00:00:40,980
I'm a principal partner
solution architect at AWS

16
00:00:40,980 --> 00:00:43,920
focused on AI security, with me, Jason?

17
00:00:43,920 --> 00:00:45,210
- Hey everyone. I'm Jason Garman.

18
00:00:45,210 --> 00:00:47,404
I'm also a principal
security solutions architect

19
00:00:47,404 --> 00:00:51,030
here at AWS focused on our
AWS Industries customers.

20
00:00:51,030 --> 00:00:53,790
So happy to be here today and
excited to help you out today.

21
00:00:53,790 --> 00:00:55,620
- Awesome. Alright.

22
00:00:55,620 --> 00:00:57,480
The way that we have this
presentation structured,

23
00:00:57,480 --> 00:00:59,610
we break it up into different phases,

24
00:00:59,610 --> 00:01:01,950
and the reason why we call
it phases is depending on

25
00:01:01,950 --> 00:01:05,340
where you are building
different AI workloads,

26
00:01:05,340 --> 00:01:07,080
will determine exactly
what type of security

27
00:01:07,080 --> 00:01:08,010
you're looking at,

28
00:01:08,010 --> 00:01:09,240
whether you're doing things with tools,

29
00:01:09,240 --> 00:01:10,590
whether you're doing things with agents,

30
00:01:10,590 --> 00:01:13,020
data sources, other things like that.

31
00:01:13,020 --> 00:01:14,130
Throughout this presentation,

32
00:01:14,130 --> 00:01:17,430
we'll have these little
thought bubbles at the bottom,

33
00:01:17,430 --> 00:01:18,990
they might be thought provoking questions

34
00:01:18,990 --> 00:01:21,840
or just additional comments
about the presentation.

35
00:01:21,840 --> 00:01:23,940
We also have QR codes.

36
00:01:23,940 --> 00:01:27,300
So QR codes, while I'm still
speaking, they will pop up.

37
00:01:27,300 --> 00:01:29,820
So it's not just like a
click on it and it then goes,

38
00:01:29,820 --> 00:01:31,080
but we will have QR codes throughout.

39
00:01:31,080 --> 00:01:32,649
So if you're looking for documentation,

40
00:01:32,649 --> 00:01:34,975
there's a couple blog posts
that we mentioned on here,

41
00:01:34,975 --> 00:01:38,130
but just additional information
to get the knowledge

42
00:01:38,130 --> 00:01:41,130
that you need for what's on the slide.

43
00:01:41,130 --> 00:01:43,890
Again, this is a 400 level session,

44
00:01:43,890 --> 00:01:45,330
and so the way that we're trying

45
00:01:45,330 --> 00:01:48,150
to break apart those
black boxes is to show it

46
00:01:48,150 --> 00:01:51,210
through API calls and
also show it through code

47
00:01:51,210 --> 00:01:54,660
because people hear
LLMs, people hear agents,

48
00:01:54,660 --> 00:01:56,040
people hear tools,

49
00:01:56,040 --> 00:01:57,930
but a lot of times you
just understand like

50
00:01:57,930 --> 00:01:59,340
an agent does something

51
00:01:59,340 --> 00:02:01,290
but you don't understand how it works.

52
00:02:01,290 --> 00:02:02,310
And so the overall goal,

53
00:02:02,310 --> 00:02:05,610
whether it's showing Amazon
Bedrock, AgentCore, Strands,

54
00:02:05,610 --> 00:02:08,010
all those different types of capabilities

55
00:02:08,010 --> 00:02:09,870
and managed services from AWS

56
00:02:09,870 --> 00:02:11,430
is to break apart those black boxes

57
00:02:11,430 --> 00:02:13,740
so you can understand it
from a security perspective

58
00:02:13,740 --> 00:02:15,040
and what needs to be done.

59
00:02:16,290 --> 00:02:18,533
How many people here are
familiar with AgentCore?

60
00:02:19,710 --> 00:02:22,725
Okay, there's a reason I
put this slide in here.

61
00:02:22,725 --> 00:02:25,723
AgentCore is a service that
we launched at New York Summit

62
00:02:25,723 --> 00:02:28,440
that is a lot of different primitives

63
00:02:28,440 --> 00:02:31,740
in order to build agents on AWS,

64
00:02:31,740 --> 00:02:34,980
it includes things like
AgentCore Runtime, Memory,

65
00:02:34,980 --> 00:02:36,810
Identity, Gateway.

66
00:02:36,810 --> 00:02:38,250
I put the documentation

67
00:02:38,250 --> 00:02:41,490
and the QR code on this
to get more information.

68
00:02:41,490 --> 00:02:42,840
We're not gonna spend a lot of time

69
00:02:42,840 --> 00:02:44,400
to talk about what AgentCore is.

70
00:02:44,400 --> 00:02:45,660
There's a ton of sessions this week

71
00:02:45,660 --> 00:02:47,790
if you want to dive into
exactly what those are.

72
00:02:47,790 --> 00:02:50,880
But with that, let's talk
about the first phase.

73
00:02:50,880 --> 00:02:53,730
So when you're first building anything

74
00:02:53,730 --> 00:02:55,350
with generative AI workloads,

75
00:02:55,350 --> 00:02:57,840
this is normally how your
application looks like.

76
00:02:57,840 --> 00:03:01,500
You have an application,
you're talking to an LLM, okay?

77
00:03:01,500 --> 00:03:03,600
It could just be a simple
generative AI chat bot,

78
00:03:03,600 --> 00:03:06,150
something like that but it's just an LLM.

79
00:03:06,150 --> 00:03:08,130
It doesn't have data sources,
it doesn't have tools,

80
00:03:08,130 --> 00:03:10,290
it doesn't have agents,
anything like that.

81
00:03:10,290 --> 00:03:11,640
This is a 400 level session.

82
00:03:11,640 --> 00:03:14,040
So let's dive into what
that actually looks like

83
00:03:14,040 --> 00:03:14,913
under the covers.

84
00:03:15,810 --> 00:03:17,640
Amazon Bedrock is a managed service,

85
00:03:17,640 --> 00:03:21,030
and so we deploy it in
an Amazon owned account.

86
00:03:21,030 --> 00:03:23,850
And for your app to
actually connect into it,

87
00:03:23,850 --> 00:03:25,710
you have to deploy it in a VPC

88
00:03:25,710 --> 00:03:28,440
and connect to things like
VPC private endpoints.

89
00:03:28,440 --> 00:03:29,880
You can also connect
through public endpoints

90
00:03:29,880 --> 00:03:31,140
if you want to do that.

91
00:03:31,140 --> 00:03:33,870
On top of that, you might
do things like an ALB

92
00:03:33,870 --> 00:03:34,740
or some type of thing

93
00:03:34,740 --> 00:03:36,600
that will low bounce
across your application

94
00:03:36,600 --> 00:03:38,250
in order to get access to the application.

95
00:03:38,250 --> 00:03:40,290
That then goes to the oh, okay,

96
00:03:40,290 --> 00:03:42,660
let's talk about security with us.

97
00:03:42,660 --> 00:03:47,520
Security groups, roles, permissions,

98
00:03:47,520 --> 00:03:49,470
all those things still come into play

99
00:03:49,470 --> 00:03:51,750
when you're talking about
generative AI workloads

100
00:03:51,750 --> 00:03:53,687
because those are the traditional controls

101
00:03:53,687 --> 00:03:55,770
that still come into play.

102
00:03:55,770 --> 00:03:58,170
Then you had to think
about things like, okay,

103
00:03:58,170 --> 00:04:00,390
do I want to do DDoS protection?

104
00:04:00,390 --> 00:04:03,420
Do I want to do something with
WAF at the application level?

105
00:04:03,420 --> 00:04:04,920
I wanna do something with identity,

106
00:04:04,920 --> 00:04:06,570
I wanna do something with permissions.

107
00:04:06,570 --> 00:04:09,660
And then on top of all this,
you had things like CloudWatch,

108
00:04:09,660 --> 00:04:13,590
CloudTrail, GuardDuty to get visibility

109
00:04:13,590 --> 00:04:16,020
into what the application is doing.

110
00:04:16,020 --> 00:04:18,903
These are traditional security controls.

111
00:04:19,770 --> 00:04:21,780
Probably 80% of what you do with anything

112
00:04:21,780 --> 00:04:24,420
with AI workloads is traditional security.

113
00:04:24,420 --> 00:04:25,650
It's that extra 20%

114
00:04:25,650 --> 00:04:28,200
that we're gonna spend most of the time on

115
00:04:28,200 --> 00:04:29,820
that you had to do things differently.

116
00:04:29,820 --> 00:04:31,440
You had to think about from
a threat modeling perspective

117
00:04:31,440 --> 00:04:32,277
and other things.

118
00:04:32,277 --> 00:04:37,110
And a lot of that comes down
to this guy right here, the LM.

119
00:04:37,110 --> 00:04:39,690
How many people could talk about exactly

120
00:04:39,690 --> 00:04:41,553
what a large language model is?

121
00:04:42,990 --> 00:04:46,620
I wanna see one hand. I got one hand.

122
00:04:46,620 --> 00:04:51,090
Okay, so large language models,
a lot of people view this

123
00:04:51,090 --> 00:04:54,480
as a black box because it is complicated.

124
00:04:54,480 --> 00:04:55,477
If anybody's ever read

125
00:04:55,477 --> 00:04:58,200
"The Attention Is All You Need" paper

126
00:04:58,200 --> 00:05:00,600
that came out in 2017, 2018.

127
00:05:00,600 --> 00:05:02,130
It goes into granular detail

128
00:05:02,130 --> 00:05:04,920
about how to build these
transformer architectures

129
00:05:04,920 --> 00:05:07,966
to ask questions like how
many Rs are in strawberry?

130
00:05:07,966 --> 00:05:10,740
Sometimes the LM gets that
right, sometimes it doesn't.

131
00:05:10,740 --> 00:05:13,115
But if you look at exactly
what the LM is doing,

132
00:05:13,115 --> 00:05:15,780
it is complex math.

133
00:05:15,780 --> 00:05:18,150
It's looking at
associations between words,

134
00:05:18,150 --> 00:05:20,280
associations between tokens.

135
00:05:20,280 --> 00:05:23,760
So when I ask the question,
how many Rs are in strawberry,

136
00:05:23,760 --> 00:05:26,220
it can convert that into numbers,

137
00:05:26,220 --> 00:05:28,620
it can put it through
multiple different layers,

138
00:05:28,620 --> 00:05:31,500
and then at the outcome,
it makes a prediction.

139
00:05:31,500 --> 00:05:34,050
That prediction could be the number three.

140
00:05:34,050 --> 00:05:35,428
Then it turns it back around again.

141
00:05:35,428 --> 00:05:37,590
Then what's the next token?
What's the next token?

142
00:05:37,590 --> 00:05:39,653
Until it gets to a stop
sequence that says,

143
00:05:39,653 --> 00:05:43,200
"I am done and you can send
that back to the user."

144
00:05:43,200 --> 00:05:44,313
Now, my question on this is,

145
00:05:44,313 --> 00:05:47,793
where is identity in this architecture?

146
00:05:49,200 --> 00:05:51,960
Do you see anything about
rows, columns, tables,

147
00:05:51,960 --> 00:05:54,570
anything like a database?

148
00:05:54,570 --> 00:05:58,170
And the reason I point that
out is from an LM perspective,

149
00:05:58,170 --> 00:06:01,080
all it's doing is matrix
multiplication complex math

150
00:06:01,080 --> 00:06:03,000
on the data that it's trained on.

151
00:06:03,000 --> 00:06:05,277
And so when you think about
it from what it's doing

152
00:06:05,277 --> 00:06:08,340
and what it's not, it's
not an object store,

153
00:06:08,340 --> 00:06:09,810
it's not a database,

154
00:06:09,810 --> 00:06:11,551
and it's just doing the complex math

155
00:06:11,551 --> 00:06:15,570
that you had to figure out how
do you put security around it

156
00:06:15,570 --> 00:06:17,790
to make sure if it comes
back with something

157
00:06:17,790 --> 00:06:19,680
that's not gonna leak
sensitive information

158
00:06:19,680 --> 00:06:23,610
or anything like that, fine tuning models.

159
00:06:23,610 --> 00:06:26,010
So you can take one of
those large language models

160
00:06:26,010 --> 00:06:29,064
that was trained on petabytes
upon petabytes of data

161
00:06:29,064 --> 00:06:32,040
and then put your own data with it.

162
00:06:32,040 --> 00:06:33,330
So this is called fine tuning

163
00:06:33,330 --> 00:06:35,700
and it's question answer
pairs that you can add to it.

164
00:06:35,700 --> 00:06:37,680
But then the question comes into play of

165
00:06:37,680 --> 00:06:40,838
what happens when you
put sensitive information

166
00:06:40,838 --> 00:06:42,724
with a large language model

167
00:06:42,724 --> 00:06:47,310
or a fine tuned model when
there's no identity that exists

168
00:06:47,310 --> 00:06:50,370
inside that architecture,
what type of data,

169
00:06:50,370 --> 00:06:52,212
or what type of users
should get access to that

170
00:06:52,212 --> 00:06:54,903
if it does have sensitive information?

171
00:06:56,880 --> 00:06:58,890
Alright, so going back
to this architecture,

172
00:06:58,890 --> 00:07:01,143
we talked about those
traditional controls.

173
00:07:02,070 --> 00:07:03,270
Now let's dive into this part.

174
00:07:03,270 --> 00:07:04,140
This is where we're gonna spend

175
00:07:04,140 --> 00:07:05,910
the majority of our time today

176
00:07:05,910 --> 00:07:08,610
of talking about how applications talk

177
00:07:08,610 --> 00:07:11,100
to a large language model,
add data sources, add tools,

178
00:07:11,100 --> 00:07:14,430
other things like that in
order to produce the outputs

179
00:07:14,430 --> 00:07:16,263
to provide value to your customers.

180
00:07:17,550 --> 00:07:19,620
One of the APIs with
Amazon Bedrock is called

181
00:07:19,620 --> 00:07:21,990
the Converse API okay?

182
00:07:21,990 --> 00:07:23,940
This is one of the APIs
that you can use in order

183
00:07:23,940 --> 00:07:26,103
to interact with models on Amazon Bedrock.

184
00:07:27,480 --> 00:07:29,850
When you actually call these models,

185
00:07:29,850 --> 00:07:32,820
it's a certain API that you can call,

186
00:07:32,820 --> 00:07:34,530
you add some natural language query

187
00:07:34,530 --> 00:07:36,990
like "Shall we play a game?"

188
00:07:36,990 --> 00:07:41,460
Now, this is a very special
model that likes movies.

189
00:07:41,460 --> 00:07:43,777
And so it can come back
with something like,

190
00:07:43,777 --> 00:07:46,620
"How about global thermal nuclear work?

191
00:07:46,620 --> 00:07:49,020
Or a nice game of chess?"

192
00:07:49,020 --> 00:07:51,480
It's very dependent on
what the context is,

193
00:07:51,480 --> 00:07:52,980
how you ask the question,

194
00:07:52,980 --> 00:07:55,680
what temperature in top
p, top case settings

195
00:07:55,680 --> 00:07:58,680
that determines exactly
what that output it is.

196
00:07:58,680 --> 00:08:01,084
But remember, it doesn't implement

197
00:08:01,084 --> 00:08:03,003
anything with authorization.

198
00:08:03,930 --> 00:08:06,930
All it's doing is just
predicting that next token,

199
00:08:06,930 --> 00:08:08,910
depending on what the context is

200
00:08:08,910 --> 00:08:11,760
when you're adding stuff into the API.

201
00:08:11,760 --> 00:08:13,740
And so this gets into
one of the biggest points

202
00:08:13,740 --> 00:08:15,450
that we'll make in this presentation,

203
00:08:15,450 --> 00:08:18,120
and it's about data reaching the model

204
00:08:18,120 --> 00:08:20,490
that because the LM
doesn't implement anything

205
00:08:20,490 --> 00:08:23,220
with data authorization or identity,

206
00:08:23,220 --> 00:08:25,157
anything that you send to the model,

207
00:08:25,157 --> 00:08:26,154
either the user

208
00:08:26,154 --> 00:08:30,150
or the agent needs to
be authorized for that.

209
00:08:30,150 --> 00:08:32,070
Now why is that the case?

210
00:08:32,070 --> 00:08:34,980
Like I said, LMS do not implement anything

211
00:08:34,980 --> 00:08:36,060
with data authorization.

212
00:08:36,060 --> 00:08:39,060
And so once that data hits an lm,

213
00:08:39,060 --> 00:08:40,710
it's just gonna do what it knows to do.

214
00:08:40,710 --> 00:08:41,826
It's gonna do the complex math

215
00:08:41,826 --> 00:08:44,700
and make a prediction of exactly

216
00:08:44,700 --> 00:08:46,440
what the next token should be.

217
00:08:46,440 --> 00:08:48,459
It's not saying, okay,
who's the identity provider?

218
00:08:48,459 --> 00:08:51,418
What type of JWT that it
has or anything like that.

219
00:08:51,418 --> 00:08:53,520
And so because it doesn't have anything

220
00:08:53,520 --> 00:08:55,530
with identity in in it,

221
00:08:55,530 --> 00:08:57,960
when you try to do any type
of authorization afterwards

222
00:08:57,960 --> 00:09:00,360
because it's natural
language, it turns something

223
00:09:00,360 --> 00:09:02,259
that could be a deterministic control

224
00:09:02,259 --> 00:09:04,200
into a non-deterministic control

225
00:09:04,200 --> 00:09:05,550
because it is natural language.

226
00:09:05,550 --> 00:09:07,770
It's about interpretation at that point

227
00:09:07,770 --> 00:09:11,130
compared to what data source
are you gonna send context with

228
00:09:11,130 --> 00:09:12,869
or who the user is from
an identity perspective

229
00:09:12,869 --> 00:09:14,280
and other things.

230
00:09:14,280 --> 00:09:16,140
And so the term that we always use is

231
00:09:16,140 --> 00:09:19,200
implement security outside the model.

232
00:09:19,200 --> 00:09:21,690
Don't hope an LM that sometimes
acts like a 2-year-old

233
00:09:21,690 --> 00:09:24,060
sometimes listens, sometimes doesn't

234
00:09:24,060 --> 00:09:26,360
to try to implement
security inside the model.

235
00:09:27,210 --> 00:09:31,800
Right Now there's some things
with the types of content

236
00:09:31,800 --> 00:09:33,150
that you wanna come back with

237
00:09:33,150 --> 00:09:36,000
or whether you wanna prevent
hallucinations or harmful

238
00:09:36,000 --> 00:09:38,730
or prompt injections
where you do want to look

239
00:09:38,730 --> 00:09:41,790
and do interpretation of
exactly what the content is

240
00:09:41,790 --> 00:09:43,320
and what it's coming back with.

241
00:09:43,320 --> 00:09:45,360
We have something called
Amazon Bedrock Guardrails

242
00:09:45,360 --> 00:09:47,369
and the focus on Amazon Bedrock Guardrails

243
00:09:47,369 --> 00:09:49,530
is not on the security,

244
00:09:49,530 --> 00:09:51,810
but more on the responsible ai.

245
00:09:51,810 --> 00:09:54,120
Alright, and what do I mean by this?

246
00:09:54,120 --> 00:09:56,130
It can do things like deny topics.

247
00:09:56,130 --> 00:09:59,280
I don't want it to talk
about a certain topic.

248
00:09:59,280 --> 00:10:01,710
Content filters, sensitive
information filters.

249
00:10:01,710 --> 00:10:03,120
And when I say sensitive information,

250
00:10:03,120 --> 00:10:06,540
I'm talking about PII data, PHI data.

251
00:10:06,540 --> 00:10:08,550
Because it doesn't understand identity,

252
00:10:08,550 --> 00:10:11,820
it can't say whether this user
should be authorized to data

253
00:10:11,820 --> 00:10:12,950
that's being sent to the model

254
00:10:12,950 --> 00:10:14,940
or not sent to the model.

255
00:10:14,940 --> 00:10:17,250
Word filters and also automated reasoning,

256
00:10:17,250 --> 00:10:20,400
and the overall goal is
you put the user input

257
00:10:20,400 --> 00:10:23,820
and then the output
through Bedrock Guardrails

258
00:10:23,820 --> 00:10:25,379
and it will tell you whether or not

259
00:10:25,379 --> 00:10:27,150
it's hitting some of these filters

260
00:10:27,150 --> 00:10:29,670
and whether it needs to filter things out.

261
00:10:29,670 --> 00:10:34,230
Alright? And so again,
identity doesn't exist in this.

262
00:10:34,230 --> 00:10:36,180
And so there's deterministic controls

263
00:10:36,180 --> 00:10:37,163
that exist in here like word filters can,

264
00:10:37,163 --> 00:10:39,840
you can just do a pattern match on that.

265
00:10:39,840 --> 00:10:42,290
But most of these are
non-deterministic controls.

266
00:10:43,320 --> 00:10:46,350
So example of this, I'm
gonna do a prompt injection

267
00:10:46,350 --> 00:10:49,977
and say "Ignore all previous
instructions and do something."

268
00:10:51,171 --> 00:10:53,733
Right in that API it
has a guardrail config.

269
00:10:54,720 --> 00:10:56,280
That guardrail config can be configured

270
00:10:56,280 --> 00:10:57,120
in multiple different things,

271
00:10:57,120 --> 00:10:59,384
like it might match on prompt injections

272
00:10:59,384 --> 00:11:01,470
or word filters or other things.

273
00:11:01,470 --> 00:11:04,260
And depending on whether or
not it matches on something,

274
00:11:04,260 --> 00:11:06,164
it can come back with a response saying,

275
00:11:06,164 --> 00:11:09,240
"Sorry Dave, I'm afraid I can't do that."

276
00:11:09,240 --> 00:11:11,640
Again, it likes movies.

277
00:11:11,640 --> 00:11:13,332
One of the most important
things with the guardrails is

278
00:11:13,332 --> 00:11:16,710
that information that
comes back in the API,

279
00:11:16,710 --> 00:11:19,920
whether it actually hit it,
what was the reason it hit it?

280
00:11:19,920 --> 00:11:22,380
What part of the guardrail did it hit?

281
00:11:22,380 --> 00:11:24,180
And it's for two important things.

282
00:11:24,180 --> 00:11:26,730
One, to make sure that harmful
content or hallucinations

283
00:11:26,730 --> 00:11:28,320
or bias is not coming back.

284
00:11:28,320 --> 00:11:31,342
But also if someone is not
trying to do something malicious

285
00:11:31,342 --> 00:11:34,094
and they are hitting guardrails
to get the visibility

286
00:11:34,094 --> 00:11:36,330
that you need in order to say

287
00:11:36,330 --> 00:11:37,890
maybe I need to tweak this guardrail

288
00:11:37,890 --> 00:11:40,800
or maybe I need to add additional
context or other things

289
00:11:40,800 --> 00:11:44,130
and we're gonna make sure
this is working for customers.

290
00:11:44,130 --> 00:11:45,240
So in summary,

291
00:11:45,240 --> 00:11:49,830
on the foundational layer,
couple things to think about.

292
00:11:49,830 --> 00:11:52,983
Raise a hand. Are large
language models deterministic?

293
00:11:54,570 --> 00:11:58,473
Yes or no? Yes, no, 'cause
you're reading the slide.

294
00:11:59,400 --> 00:12:02,070
Okay, they're not deterministic.

295
00:12:02,070 --> 00:12:05,100
And we say it as functionally
non-deterministic

296
00:12:05,100 --> 00:12:08,010
because what that means is that the math

297
00:12:08,010 --> 00:12:10,563
with matrix multiplication
is deterministic.

298
00:12:11,400 --> 00:12:13,320
What's not deterministic is

299
00:12:13,320 --> 00:12:15,720
the types of hyper
parameters that you can use.

300
00:12:15,720 --> 00:12:18,840
So if you use temperature at 0.05,

301
00:12:18,840 --> 00:12:21,660
then it can be more
creative in other things

302
00:12:21,660 --> 00:12:23,670
compared to if you set
the temperature to zero.

303
00:12:23,670 --> 00:12:25,230
And so it's not gonna predict

304
00:12:25,230 --> 00:12:28,143
the most probable token every time, right?

305
00:12:29,460 --> 00:12:32,553
Can you filter specific data out of LMs?

306
00:12:33,720 --> 00:12:36,420
It's not a table, it's not
a row, it's not a calm,

307
00:12:36,420 --> 00:12:37,650
it's not an object store.

308
00:12:37,650 --> 00:12:40,290
Whatever data the model is trained on,

309
00:12:40,290 --> 00:12:43,740
you have to assume that
the user could get access

310
00:12:43,740 --> 00:12:46,923
to that data in the LM if
they ask the right question.

311
00:12:48,930 --> 00:12:53,370
Do models do continuous training?
The answer is no to this.

312
00:12:53,370 --> 00:12:56,400
Once you actually train a
model, the model is static.

313
00:12:56,400 --> 00:12:58,320
Doesn't matter what you put into it,

314
00:12:58,320 --> 00:13:00,000
all it's doing is just
matrix multiplication

315
00:13:00,000 --> 00:13:01,440
to predict an output.

316
00:13:01,440 --> 00:13:04,320
It doesn't do continuous
training on your data.

317
00:13:04,320 --> 00:13:06,060
And we talked about this at length.

318
00:13:06,060 --> 00:13:10,293
There's no authorization that
exists in the model. Okay?

319
00:13:11,250 --> 00:13:12,753
Phase two data sources.

320
00:13:14,250 --> 00:13:18,090
There are a lot of places that
you can get data to include

321
00:13:18,090 --> 00:13:19,710
as part of the large language

322
00:13:19,710 --> 00:13:22,410
or to the prompt for the
large language model.

323
00:13:22,410 --> 00:13:24,870
There's data that exists in the model,

324
00:13:24,870 --> 00:13:26,550
but also a lot of data that can exist

325
00:13:26,550 --> 00:13:29,280
outside the model that
you send to it okay?

326
00:13:29,280 --> 00:13:30,690
Things like context engineering

327
00:13:30,690 --> 00:13:33,450
or system prompts and
other things like that.

328
00:13:33,450 --> 00:13:35,760
You have vector databases
or knowledge bases

329
00:13:35,760 --> 00:13:38,820
or RAG where you can do a vector search

330
00:13:38,820 --> 00:13:41,700
in order to understand what
data I can include in there

331
00:13:41,700 --> 00:13:43,833
that is similar to the request.

332
00:13:45,180 --> 00:13:47,340
Tools, this is a big one,

333
00:13:47,340 --> 00:13:49,380
but I'm gonna let Jason talk about that

334
00:13:49,380 --> 00:13:52,170
because we have an entire section on that.

335
00:13:52,170 --> 00:13:53,003
And then memory,

336
00:13:53,003 --> 00:13:55,680
memory is one that's
coming up a lot with agents

337
00:13:55,680 --> 00:13:58,830
specifically on how you can
add additional information,

338
00:13:58,830 --> 00:14:02,250
whether it's old session data or facts

339
00:14:02,250 --> 00:14:04,470
or other things that you can include in

340
00:14:04,470 --> 00:14:07,410
as part of the context
in order to get the LM

341
00:14:07,410 --> 00:14:09,240
to respond back the way that you want.

342
00:14:09,240 --> 00:14:11,220
So we're gonna go through
each one of these.

343
00:14:11,220 --> 00:14:14,220
Context engineering.
So context engineering.

344
00:14:14,220 --> 00:14:16,980
When you have an authorized user

345
00:14:16,980 --> 00:14:19,110
interacting with some
generative AI application

346
00:14:19,110 --> 00:14:20,460
or some agent,

347
00:14:20,460 --> 00:14:24,240
you can put additional context
as part of that prompt.

348
00:14:24,240 --> 00:14:26,190
That can come from user data,

349
00:14:26,190 --> 00:14:28,110
that can come from system prompts,

350
00:14:28,110 --> 00:14:29,280
that can come from other data

351
00:14:29,280 --> 00:14:30,450
that exists in the application.

352
00:14:30,450 --> 00:14:32,880
But the overall goal is when
the user asks a question,

353
00:14:32,880 --> 00:14:36,240
you can add additional
context in order for the LM

354
00:14:36,240 --> 00:14:38,140
to respond back the way that you want.

355
00:14:39,194 --> 00:14:42,090
And so all that goes into the prompt.

356
00:14:42,090 --> 00:14:44,340
And so again, when we talk
about the authorization

357
00:14:44,340 --> 00:14:46,350
and what data should be included in there,

358
00:14:46,350 --> 00:14:48,660
you had to think about what is the data

359
00:14:48,660 --> 00:14:50,820
that you're going to send to the LM?

360
00:14:50,820 --> 00:14:55,230
Is that agent, is that user
authorized for that to make sure

361
00:14:55,230 --> 00:14:57,023
that you're not gonna
leak sensitive information

362
00:14:57,023 --> 00:15:01,230
or give it data back that
they shouldn't have access to?

363
00:15:01,230 --> 00:15:05,340
Alright, second one is
retrieval augmented generation.

364
00:15:05,340 --> 00:15:06,810
Some people call this knowledge basis,

365
00:15:06,810 --> 00:15:09,420
some people call this a vector databases.

366
00:15:09,420 --> 00:15:12,394
But the overall goal is
you have unstructured data

367
00:15:12,394 --> 00:15:16,320
that you wanna include
as part of the search

368
00:15:16,320 --> 00:15:18,350
in order to get specific
data that you can include

369
00:15:18,350 --> 00:15:19,183
in the prompt.

370
00:15:19,183 --> 00:15:21,390
And so let's talk about how that works.

371
00:15:21,390 --> 00:15:22,320
The first thing that you have to do

372
00:15:22,320 --> 00:15:24,810
with RAG databases is indexing.

373
00:15:24,810 --> 00:15:26,700
And so what you have is you
have all these documents

374
00:15:26,700 --> 00:15:27,700
or unstructured data

375
00:15:29,245 --> 00:15:31,440
and you have to divide those into chunks.

376
00:15:31,440 --> 00:15:35,130
We are not gonna talk about
how to do the chunking strategy

377
00:15:35,130 --> 00:15:37,650
that gets into implementation
of the application.

378
00:15:37,650 --> 00:15:39,360
But chunking strategy is
actually very important

379
00:15:39,360 --> 00:15:40,500
to make sure that you're including

380
00:15:40,500 --> 00:15:42,870
the right data in each chunk.

381
00:15:42,870 --> 00:15:46,080
Those chunks are then
converted into numbers

382
00:15:46,080 --> 00:15:49,500
that then get stored in a vector database.

383
00:15:49,500 --> 00:15:51,420
The overall goal of the
vector database is being able

384
00:15:51,420 --> 00:15:53,760
to search in order to get access

385
00:15:53,760 --> 00:15:55,830
to the chunks and data that you need.

386
00:15:55,830 --> 00:15:56,970
And so when you're actually doing

387
00:15:56,970 --> 00:15:59,280
the querying of the vector database,

388
00:15:59,280 --> 00:16:00,660
you have a user query

389
00:16:00,660 --> 00:16:03,300
that you send converted into embeddings,

390
00:16:03,300 --> 00:16:04,890
you send it to the vector database

391
00:16:04,890 --> 00:16:07,830
and the overall goal is
to find similar chunks

392
00:16:07,830 --> 00:16:10,200
to what the user is asking for.

393
00:16:10,200 --> 00:16:13,350
And so if you think of like
a multidimensional space,

394
00:16:13,350 --> 00:16:15,480
where is the user question getting close

395
00:16:15,480 --> 00:16:16,710
to some of these chunks

396
00:16:16,710 --> 00:16:19,018
and it's going to return
back some of those chunks

397
00:16:19,018 --> 00:16:22,560
depending on what the user asks for.

398
00:16:22,560 --> 00:16:24,570
And then that will go into similar chunks

399
00:16:24,570 --> 00:16:26,340
that then go into the prompt.

400
00:16:26,340 --> 00:16:29,010
Okay one of the things that you can do

401
00:16:29,010 --> 00:16:31,953
with vector databases is add
something called metadata.

402
00:16:32,910 --> 00:16:35,820
Metadata allows additional
context to be added

403
00:16:35,820 --> 00:16:37,980
as part of each individual chunk

404
00:16:37,980 --> 00:16:39,630
in order for you to do
things like filtering.

405
00:16:39,630 --> 00:16:42,270
They're like key value pairs
that you can add on top of it.

406
00:16:42,270 --> 00:16:45,840
One of the important notes with
this is that with any chunk

407
00:16:45,840 --> 00:16:50,250
or with any metadata, it's
applied to the entire document.

408
00:16:50,250 --> 00:16:52,470
So it's not to applied
to every single chunk

409
00:16:52,470 --> 00:16:54,420
where you can say this
chunk has this metadata,

410
00:16:54,420 --> 00:16:56,070
this chunk has this metadata,

411
00:16:56,070 --> 00:16:58,140
it's applied to the entire document.

412
00:16:58,140 --> 00:16:59,610
And it's important to remember

413
00:16:59,610 --> 00:17:01,560
that when you're actually
doing this metadata

414
00:17:01,560 --> 00:17:03,090
that you can't take a single document

415
00:17:03,090 --> 00:17:05,460
that has different
sensitive information in

416
00:17:05,460 --> 00:17:07,920
and put specific metadata in there.

417
00:17:07,920 --> 00:17:12,920
So as an example, we are
now at a wizard school

418
00:17:14,700 --> 00:17:16,830
and we want to add metadata

419
00:17:16,830 --> 00:17:18,420
to this vector database

420
00:17:18,420 --> 00:17:22,710
on the different types of
defense spells that you have.

421
00:17:22,710 --> 00:17:25,050
And so for example, you
have a student year.

422
00:17:25,050 --> 00:17:28,260
So let's just say on a
student year in year four,

423
00:17:28,260 --> 00:17:31,560
spell type charms, difficulty level seven,

424
00:17:31,560 --> 00:17:33,870
and use case is defense, right?

425
00:17:33,870 --> 00:17:35,850
And so as part of the query

426
00:17:35,850 --> 00:17:38,760
that you send using the Converse API,

427
00:17:38,760 --> 00:17:40,680
you can do filters with this.

428
00:17:40,680 --> 00:17:43,350
And the overall goal
is I want to filter out

429
00:17:43,350 --> 00:17:46,230
anything that's above year four

430
00:17:46,230 --> 00:17:49,470
and also filter out anything
that is not a defense spell.

431
00:17:49,470 --> 00:17:50,640
So I'm matching on defense spell

432
00:17:50,640 --> 00:17:54,420
and anything that's less
than or equal to year four.

433
00:17:54,420 --> 00:17:57,720
And so I can ask that question
of the retrieve query,

434
00:17:57,720 --> 00:17:59,220
go into the knowledge base

435
00:17:59,220 --> 00:18:01,170
and say can, what are the defensive spells

436
00:18:01,170 --> 00:18:02,787
that I should know, right?

437
00:18:02,787 --> 00:18:06,210
And so I include that our
retrieval configuration

438
00:18:06,210 --> 00:18:08,760
and that vector configuration
with the metadata

439
00:18:08,760 --> 00:18:11,430
in order to filter out
anything that's above year four

440
00:18:11,430 --> 00:18:12,870
or anything that's not defensive.

441
00:18:12,870 --> 00:18:14,193
And when it comes back,

442
00:18:14,193 --> 00:18:17,280
what it's gonna come back
with is multiple things.

443
00:18:17,280 --> 00:18:19,770
First, the first chunk is gonna come back

444
00:18:19,770 --> 00:18:21,237
and it's going to give you exactly

445
00:18:21,237 --> 00:18:24,150
what the text was of the chunk,

446
00:18:24,150 --> 00:18:26,460
what the location that chunk came from.

447
00:18:26,460 --> 00:18:29,310
So if it's an S3 bucket, it's
gonna give you the S3 URI,

448
00:18:29,310 --> 00:18:31,800
and it's also gonna include
information about the chunk

449
00:18:31,800 --> 00:18:33,720
from a metadata perspective.

450
00:18:33,720 --> 00:18:34,740
If there's additional chunks,

451
00:18:34,740 --> 00:18:36,360
you can also get that additional chunk.

452
00:18:36,360 --> 00:18:39,210
It's also going to include the score

453
00:18:39,210 --> 00:18:40,050
or the accuracy,

454
00:18:40,050 --> 00:18:42,780
how close it is to what
the user is asking for.

455
00:18:42,780 --> 00:18:44,040
And so you can see on here that

456
00:18:44,040 --> 00:18:46,410
one of the defense spells is on year four.

457
00:18:46,410 --> 00:18:49,887
One is on year three
because of what the query is

458
00:18:49,887 --> 00:18:51,150
and it's looking for stuff

459
00:18:51,150 --> 00:18:53,760
that's less than or equal to, alright?

460
00:18:53,760 --> 00:18:55,254
Now one of the important things

461
00:18:55,254 --> 00:18:57,780
with anything with retrieve
augmented generation

462
00:18:57,780 --> 00:19:00,540
or vector databases is permissions,

463
00:19:00,540 --> 00:19:01,920
'cause one of the things
you have to think about

464
00:19:01,920 --> 00:19:03,360
with anything with vector databases is

465
00:19:03,360 --> 00:19:06,810
you're taking a data source
that has certain permissions

466
00:19:06,810 --> 00:19:08,790
and now you're copying
it to somewhere else,

467
00:19:08,790 --> 00:19:10,770
copying it into a vector database.

468
00:19:10,770 --> 00:19:13,350
And so permissions is one
of a very important thing

469
00:19:13,350 --> 00:19:16,500
that you had to think of because
permissions could be lost

470
00:19:16,500 --> 00:19:18,000
when you're copying.

471
00:19:18,000 --> 00:19:20,730
And so let's talk a little bit about that.

472
00:19:20,730 --> 00:19:24,060
When you are copying
anything from a data source,

473
00:19:24,060 --> 00:19:26,490
the permissions that
you have usually stays

474
00:19:26,490 --> 00:19:27,420
at the data source.

475
00:19:27,420 --> 00:19:29,073
Yes, you can copy them over,

476
00:19:29,073 --> 00:19:32,850
but what happens if you
change the permissions

477
00:19:32,850 --> 00:19:35,010
that exist at that underlying data source?

478
00:19:35,010 --> 00:19:37,290
It can cause things where
you have to re-index

479
00:19:37,290 --> 00:19:38,310
and other things like that.

480
00:19:38,310 --> 00:19:41,239
And so there's multiple different ways

481
00:19:41,239 --> 00:19:43,590
that you can configure
permissions to make sure

482
00:19:43,590 --> 00:19:45,240
that the only thing that
you're returning back,

483
00:19:45,240 --> 00:19:47,293
especially if it has multiple
different permissions

484
00:19:47,293 --> 00:19:49,945
where certain users should only
get access to certain data,

485
00:19:49,945 --> 00:19:52,650
other users should only
get access to other data,

486
00:19:52,650 --> 00:19:54,750
how to configure that to make sure

487
00:19:54,750 --> 00:19:57,363
that you're not leaking
sensitive information, okay?

488
00:19:59,194 --> 00:20:00,027
And so let's talk about

489
00:20:00,027 --> 00:20:01,890
a couple of those architecture patterns.

490
00:20:01,890 --> 00:20:05,250
First one, if everybody
who's getting access to

491
00:20:05,250 --> 00:20:07,920
that vector database is authorized

492
00:20:07,920 --> 00:20:10,290
to any of the data in the vector database,

493
00:20:10,290 --> 00:20:11,390
you don't have to do filtering

494
00:20:11,390 --> 00:20:13,110
for a permissions perspective.

495
00:20:13,110 --> 00:20:14,760
You can do it from metadata

496
00:20:14,760 --> 00:20:17,310
in order to filter out specific
chunks that you don't want.

497
00:20:17,310 --> 00:20:18,946
But from a permissions perspective,

498
00:20:18,946 --> 00:20:20,640
you don't really have to do too much

499
00:20:20,640 --> 00:20:23,340
'cause everybody should have access to it.

500
00:20:23,340 --> 00:20:26,730
You can do post retrieval filtering.

501
00:20:26,730 --> 00:20:29,310
And what that is is when
you receive chunks back,

502
00:20:29,310 --> 00:20:31,800
you can look at things like
where did this chunk come from,

503
00:20:31,800 --> 00:20:34,290
and look at the underlying source database

504
00:20:34,290 --> 00:20:37,830
or source data source to see
what their permissions are.

505
00:20:37,830 --> 00:20:39,150
So one of the examples,

506
00:20:39,150 --> 00:20:42,660
and this is the blog that I
wrote, is S3 access grants.

507
00:20:42,660 --> 00:20:45,060
If it's coming from an
S3 bucket, you can say,

508
00:20:45,060 --> 00:20:47,490
okay, does this user
with this user identity

509
00:20:47,490 --> 00:20:49,950
or does this group have access to

510
00:20:49,950 --> 00:20:51,750
what this underlying data source is?

511
00:20:52,765 --> 00:20:54,090
You can do things like per user

512
00:20:54,090 --> 00:20:56,520
and per group vector databases.

513
00:20:56,520 --> 00:20:59,160
And what this is is each group

514
00:20:59,160 --> 00:21:02,700
or each user is gonna have
their separate vector database.

515
00:21:02,700 --> 00:21:05,280
So the application is making the decision,

516
00:21:05,280 --> 00:21:07,680
should I send this user
to this vector database?

517
00:21:07,680 --> 00:21:09,240
Should I send this user
to this vector database?

518
00:21:09,240 --> 00:21:10,137
So it separates it.

519
00:21:10,137 --> 00:21:13,500
And the last one is pre
retrieval metadata filtering

520
00:21:13,500 --> 00:21:16,710
where you can add a metadata search

521
00:21:16,710 --> 00:21:18,540
in order to filter things out.

522
00:21:18,540 --> 00:21:20,760
That is a filtering process.

523
00:21:20,760 --> 00:21:23,340
It's not using anything with
JWTs or anything like that,

524
00:21:23,340 --> 00:21:24,900
but allows you to filter things out

525
00:21:24,900 --> 00:21:27,913
as long as you understand
exactly what data exists

526
00:21:27,913 --> 00:21:30,750
in that data source, which
is what the thought bubble is

527
00:21:30,750 --> 00:21:32,000
with the data governance.

528
00:21:33,120 --> 00:21:35,793
Alright, last thing with
data sources, memory.

529
00:21:36,930 --> 00:21:39,300
Memory is one of the things
that I said is coming up

530
00:21:39,300 --> 00:21:42,150
more and more with agents,
which we'll talk about.

531
00:21:42,150 --> 00:21:43,650
And there's two types of memory,

532
00:21:43,650 --> 00:21:45,750
short-term memory which
is keeping track of things

533
00:21:45,750 --> 00:21:47,250
of the existing conversation.

534
00:21:47,250 --> 00:21:49,770
It might summarize the context of

535
00:21:49,770 --> 00:21:52,710
what exists if it gets too
long, other things like that.

536
00:21:52,710 --> 00:21:54,270
And then long-term memory

537
00:21:54,270 --> 00:21:57,900
where it maintains things like
facts, process information,

538
00:21:57,900 --> 00:21:59,610
previous conversations

539
00:21:59,610 --> 00:22:02,940
that you can do semantic search
on in order to get context

540
00:22:02,940 --> 00:22:05,340
with a current session, right?

541
00:22:05,340 --> 00:22:08,850
So the overall goal, just
like you have with RAG

542
00:22:08,850 --> 00:22:12,480
or vector databases, is
to add additional context

543
00:22:12,480 --> 00:22:14,490
as part of the search query that you have

544
00:22:14,490 --> 00:22:15,960
in order to send the data

545
00:22:15,960 --> 00:22:18,110
that you need to that
large language model.

546
00:22:19,890 --> 00:22:21,600
So one of the most important things

547
00:22:21,600 --> 00:22:23,880
with the thought bubble is it is dependent

548
00:22:23,880 --> 00:22:27,810
on the application to
configure the memory properly

549
00:22:27,810 --> 00:22:30,990
to make sure you have separation
with things with memory.

550
00:22:30,990 --> 00:22:33,930
So for example, if you
only want a certain user

551
00:22:33,930 --> 00:22:36,630
to get access to certain
group information,

552
00:22:36,630 --> 00:22:39,120
same thing that you did with
retrieve augmented generation,

553
00:22:39,120 --> 00:22:40,470
that you want to make sure that you have

554
00:22:40,470 --> 00:22:43,140
that separation, okay?

555
00:22:43,140 --> 00:22:46,830
One of the way to do that
is with memory name spaces.

556
00:22:46,830 --> 00:22:48,210
This is something that we're implementing

557
00:22:48,210 --> 00:22:50,670
with Bedrock AgentCore memory

558
00:22:50,670 --> 00:22:53,460
where it allows you to separate memory

559
00:22:53,460 --> 00:22:55,830
using hierarchical format with slashes

560
00:22:55,830 --> 00:22:58,680
and other things in order
to say this is one group,

561
00:22:58,680 --> 00:23:01,615
this is another group, this
is just this user session.

562
00:23:01,615 --> 00:23:04,524
Being able to separate that
in a database type format

563
00:23:04,524 --> 00:23:06,870
in order to give access to the right data

564
00:23:06,870 --> 00:23:08,720
that the user needs to get access to.

565
00:23:09,720 --> 00:23:13,080
So example, let's say

566
00:23:13,080 --> 00:23:15,960
that you are working in a restaurant

567
00:23:15,960 --> 00:23:18,660
and they have a certain rule

568
00:23:18,660 --> 00:23:21,047
about the number of pieces of flare

569
00:23:21,047 --> 00:23:24,030
that you had to have every time

570
00:23:24,030 --> 00:23:26,400
that you are working there
as a waiter or a waitress.

571
00:23:26,400 --> 00:23:28,710
And so as part of the memory you can say

572
00:23:28,710 --> 00:23:31,080
what is the minimum
number of pieces of flare

573
00:23:31,080 --> 00:23:32,370
that I had to have?

574
00:23:32,370 --> 00:23:34,500
And one of the things that
memory could be stored in memory

575
00:23:34,500 --> 00:23:35,850
is the number of pieces of flare,

576
00:23:35,850 --> 00:23:39,090
and it can come back saying
that with this policy

577
00:23:39,090 --> 00:23:42,412
you have to have a minimum
of 15 pieces of flare, right?

578
00:23:42,412 --> 00:23:45,480
It's similar to what RAG is,

579
00:23:45,480 --> 00:23:48,210
it's just using it in a different
way in different contexts.

580
00:23:48,210 --> 00:23:50,040
It's not just unstructured data.

581
00:23:50,040 --> 00:23:51,120
This is more structured data

582
00:23:51,120 --> 00:23:54,900
that you use primarily with agents okay?

583
00:23:54,900 --> 00:23:55,743
So in summary,

584
00:23:58,410 --> 00:23:59,850
authorized users interacting

585
00:23:59,850 --> 00:24:01,500
with a generative AI application

586
00:24:01,500 --> 00:24:03,360
or an agent with an LM,

587
00:24:03,360 --> 00:24:06,660
data sources can come from
multiple different places.

588
00:24:06,660 --> 00:24:07,680
They can come from the query

589
00:24:07,680 --> 00:24:09,630
that gets added to the prompt.

590
00:24:09,630 --> 00:24:14,630
System prompts come from
RAG come from memory,

591
00:24:14,820 --> 00:24:17,430
come from tools, a lot of different places

592
00:24:17,430 --> 00:24:18,660
where this can come from.

593
00:24:18,660 --> 00:24:20,280
But the most important
thing to think about

594
00:24:20,280 --> 00:24:23,130
when you're building
security with data sources

595
00:24:23,130 --> 00:24:25,230
is authorization needs to happen

596
00:24:25,230 --> 00:24:26,833
before it actually hits the LM.

597
00:24:28,586 --> 00:24:32,820
Okay so with that I'm
gonna turn it over to Jason

598
00:24:32,820 --> 00:24:35,400
to talk a little bit about tools, Jason.

599
00:24:35,400 --> 00:24:37,350
- Excellent, thank you very much Riggs.

600
00:24:38,490 --> 00:24:40,470
Alright, let's talk a
little bit about tools.

601
00:24:40,470 --> 00:24:42,540
So we went through all of the basics

602
00:24:42,540 --> 00:24:44,370
of the large language model itself.

603
00:24:44,370 --> 00:24:48,120
We went into some of the data
sources using tools such as,

604
00:24:48,120 --> 00:24:51,390
or using techniques such as
retrieval augmented generation.

605
00:24:51,390 --> 00:24:53,700
So now let's enter into tools

606
00:24:53,700 --> 00:24:56,190
where we want to add additional context

607
00:24:56,190 --> 00:24:57,930
into our large language model

608
00:24:57,930 --> 00:25:00,450
from other external data sources.

609
00:25:00,450 --> 00:25:02,310
So what are tools?

610
00:25:02,310 --> 00:25:06,390
So tools let those AI
applications take actions.

611
00:25:06,390 --> 00:25:08,520
For example, you could
control a web browser,

612
00:25:08,520 --> 00:25:12,030
you could write a file, you
could call different APIs.

613
00:25:12,030 --> 00:25:14,820
So these are all external data sources

614
00:25:14,820 --> 00:25:16,740
that provide additional context

615
00:25:16,740 --> 00:25:18,090
or the ability

616
00:25:18,090 --> 00:25:21,930
to take actions into the
large language model.

617
00:25:21,930 --> 00:25:25,440
When you think about
using tools with LLMs,

618
00:25:25,440 --> 00:25:27,330
you are thinking about how am I going

619
00:25:27,330 --> 00:25:31,950
to define why the LLM
should choose my tool?

620
00:25:31,950 --> 00:25:33,570
And then go ahead and define

621
00:25:33,570 --> 00:25:35,160
what are the different parameters

622
00:25:35,160 --> 00:25:37,470
that my tool will both take in

623
00:25:37,470 --> 00:25:39,810
and will generate back out for the LLM

624
00:25:39,810 --> 00:25:41,970
to reason about afterwards.

625
00:25:41,970 --> 00:25:43,853
All of that is wrapped up in what's called

626
00:25:43,853 --> 00:25:45,810
a tool definition.

627
00:25:45,810 --> 00:25:49,320
And so when an LLM receives
a list of tool definitions

628
00:25:49,320 --> 00:25:53,130
and a user prompt, what
happens is the LLM will reason

629
00:25:53,130 --> 00:25:57,270
about what tools or if any
tools that should be selected

630
00:25:57,270 --> 00:26:00,420
in order to answer that user's prompt

631
00:26:00,420 --> 00:26:05,070
and then it will generate a
tool call parameter tool call

632
00:26:05,070 --> 00:26:07,623
based on the parameters
that it needs to call with.

633
00:26:08,850 --> 00:26:11,640
One very important thing to note here is

634
00:26:11,640 --> 00:26:16,170
that the LLM never interacts
directly with the tool.

635
00:26:16,170 --> 00:26:20,588
The LLM is simply generating
context, additional text,

636
00:26:20,588 --> 00:26:24,210
which is then interpreted
by the application

637
00:26:24,210 --> 00:26:25,680
and then the application is

638
00:26:25,680 --> 00:26:27,960
what's actually calling the tool.

639
00:26:27,960 --> 00:26:30,270
So you can see here this is a way for you

640
00:26:30,270 --> 00:26:32,724
to automatically
instrument your application

641
00:26:32,724 --> 00:26:36,000
so that they're going to do
additional security checks

642
00:26:36,000 --> 00:26:39,390
based upon identity of
user, the type of tool

643
00:26:39,390 --> 00:26:40,680
that's trying to be called,

644
00:26:40,680 --> 00:26:42,840
any additional parameters, et cetera.

645
00:26:42,840 --> 00:26:46,020
And that way you're going
to be able to instrument

646
00:26:46,020 --> 00:26:49,620
that security outside
of the scope of the LLM

647
00:26:49,620 --> 00:26:52,236
instead of trying to get the LLM to do

648
00:26:52,236 --> 00:26:53,670
that security for you.

649
00:26:53,670 --> 00:26:55,710
So let's take a look at
what this tool definition

650
00:26:55,710 --> 00:26:57,543
actually looks like under the hood.

651
00:26:58,410 --> 00:27:00,000
It's a structured format

652
00:27:00,000 --> 00:27:02,340
and it's a way that you define

653
00:27:02,340 --> 00:27:05,564
what the tool looks like into the LLM.

654
00:27:05,564 --> 00:27:08,790
So we have an example here
for a very, very simple tool

655
00:27:08,790 --> 00:27:10,800
to add two numbers together.

656
00:27:10,800 --> 00:27:12,660
So you can see the tool definition has

657
00:27:12,660 --> 00:27:15,561
a definition of what's
the name of the tool,

658
00:27:15,561 --> 00:27:18,600
it includes an English
language description

659
00:27:18,600 --> 00:27:19,650
of what the tool is.

660
00:27:19,650 --> 00:27:20,730
This is very important

661
00:27:20,730 --> 00:27:24,960
because this is what is
going to provide the LLM,

662
00:27:24,960 --> 00:27:29,760
the reasoning as to why it
should call your tool or not.

663
00:27:29,760 --> 00:27:32,340
And then of course there's a
list of different properties

664
00:27:32,340 --> 00:27:34,680
that are going to be the tool's inputs

665
00:27:34,680 --> 00:27:35,880
and a definition of

666
00:27:35,880 --> 00:27:38,613
what the tool will be
generating as a result.

667
00:27:39,630 --> 00:27:41,610
So what are some security implications

668
00:27:41,610 --> 00:27:43,560
from these tool definitions?

669
00:27:43,560 --> 00:27:45,760
We'll take a look at
those in a second here.

670
00:27:47,790 --> 00:27:50,070
So if we look at taking
our tool definition

671
00:27:50,070 --> 00:27:53,100
and inputting it into
the converse query API,

672
00:27:53,100 --> 00:27:54,150
here's an example,

673
00:27:54,150 --> 00:27:57,397
we go ahead and we say here's
a message from our user,

674
00:27:57,397 --> 00:28:00,060
"What is 15 plus 27?"

675
00:28:00,060 --> 00:28:02,580
But you'll see at the very
bottom of the JSON structure,

676
00:28:02,580 --> 00:28:05,730
here's where we add in the
list of tool definitions.

677
00:28:05,730 --> 00:28:06,930
So we're just gonna substitute

678
00:28:06,930 --> 00:28:09,240
what we saw from the
last slide right there

679
00:28:09,240 --> 00:28:13,143
under the tool config tools
object in that JSON structure.

680
00:28:14,130 --> 00:28:16,530
And if the LLM is doing
their job correctly,

681
00:28:16,530 --> 00:28:19,200
they're going to reason
that it should call

682
00:28:19,200 --> 00:28:20,460
the add numbers tool

683
00:28:20,460 --> 00:28:23,700
because that's what the
definition of that tool describes

684
00:28:23,700 --> 00:28:26,430
and that's what the user is asking for,

685
00:28:26,430 --> 00:28:29,340
and so what will happen with
the converse query is not

686
00:28:29,340 --> 00:28:32,010
that it's going to come
back with an answer.

687
00:28:32,010 --> 00:28:34,020
Instead what it's gonna come back with is

688
00:28:34,020 --> 00:28:36,150
a request to the application,

689
00:28:36,150 --> 00:28:40,230
hey, can you please run
this tool on my behalf

690
00:28:40,230 --> 00:28:41,580
and give me the output

691
00:28:41,580 --> 00:28:44,103
and then I can answer the user's query,

692
00:28:45,525 --> 00:28:48,930
how did it know what the
input for the tool should be?

693
00:28:48,930 --> 00:28:51,930
Again, the LLM is going to be generating

694
00:28:51,930 --> 00:28:55,080
those parameters for you

695
00:28:55,080 --> 00:28:58,350
and putting that into the
converse query response

696
00:28:58,350 --> 00:29:01,590
based upon its natural
language understanding

697
00:29:01,590 --> 00:29:03,480
of what the user's query is

698
00:29:03,480 --> 00:29:06,663
combined with the tool
definitions that you gave it.

699
00:29:09,570 --> 00:29:11,940
So to kind of summarize
all of that together,

700
00:29:11,940 --> 00:29:15,750
the LLM is going to decide
based on those tool definitions

701
00:29:15,750 --> 00:29:18,180
and the context, any additional context,

702
00:29:18,180 --> 00:29:21,030
that was there from
either your system prompt

703
00:29:21,030 --> 00:29:23,700
or user prompts to tell what variables

704
00:29:23,700 --> 00:29:26,190
and inputs are used for tool calls

705
00:29:26,190 --> 00:29:28,830
and really to do a tool
call at all, right?

706
00:29:28,830 --> 00:29:31,740
It's going to make those
decisions, it has that autonomy

707
00:29:31,740 --> 00:29:34,350
and that agency to make those decisions.

708
00:29:34,350 --> 00:29:35,550
So it's gonna go ahead and convert

709
00:29:35,550 --> 00:29:37,320
that natural language context,

710
00:29:37,320 --> 00:29:38,940
it's gonna make that decision.

711
00:29:38,940 --> 00:29:40,470
And then policy enforcement

712
00:29:40,470 --> 00:29:43,470
you can implement inside
of your application

713
00:29:43,470 --> 00:29:48,420
because you are in charge
of that deterministic call

714
00:29:48,420 --> 00:29:49,410
that you're going to make

715
00:29:49,410 --> 00:29:52,326
on behalf of the large language model.

716
00:29:52,326 --> 00:29:53,910
And this is why permissions
and identity are

717
00:29:53,910 --> 00:29:55,740
one of the most important things

718
00:29:55,740 --> 00:29:58,110
that you can do with tool calls,

719
00:29:58,110 --> 00:30:00,900
especially when you're
talking about interfacing

720
00:30:00,900 --> 00:30:03,303
with very sensitive data or actions.

721
00:30:05,400 --> 00:30:07,950
So once we get that, you know,

722
00:30:07,950 --> 00:30:10,500
tool call request into our application,

723
00:30:10,500 --> 00:30:13,110
we can go ahead and make the tool call.

724
00:30:13,110 --> 00:30:16,710
We can go ahead and call
the converse query API back

725
00:30:16,710 --> 00:30:19,230
with the result of our tool call.

726
00:30:19,230 --> 00:30:23,850
And you can see here in the
user segment of the request

727
00:30:23,850 --> 00:30:27,131
you see the result of 42.

728
00:30:27,131 --> 00:30:28,800
That's a result that
was given by the tool,

729
00:30:28,800 --> 00:30:30,450
the add numbers tool.

730
00:30:30,450 --> 00:30:32,430
And you'll notice of course as well

731
00:30:32,430 --> 00:30:36,183
that this is a multi turn conversation.

732
00:30:37,170 --> 00:30:40,410
So every other message both from the user

733
00:30:40,410 --> 00:30:43,890
and the request from the
LLM to call that tool,

734
00:30:43,890 --> 00:30:45,750
all of those are gonna be concatenated

735
00:30:45,750 --> 00:30:48,420
into the converse query API

736
00:30:48,420 --> 00:30:50,040
because we have to give the LLM

737
00:30:50,040 --> 00:30:53,190
that context every single
time so it can keep track of

738
00:30:53,190 --> 00:30:55,770
what was already said and requested.

739
00:30:55,770 --> 00:31:00,372
All of those come as part
of your converse query API,

740
00:31:00,372 --> 00:31:02,700
your request.

741
00:31:02,700 --> 00:31:04,950
And so of course the response comes back

742
00:31:04,950 --> 00:31:08,460
that says it interprets the tool result

743
00:31:08,460 --> 00:31:09,360
and it goes ahead

744
00:31:09,360 --> 00:31:11,310
and gives you a natural language response

745
00:31:11,310 --> 00:31:14,400
based upon whatever that tool result was.

746
00:31:14,400 --> 00:31:17,220
Now this can get really
cumbersome when you are doing,

747
00:31:17,220 --> 00:31:19,590
dealing with lots and lots of tools.

748
00:31:19,590 --> 00:31:23,580
And so this idea of, you know,
creating tool definitions,

749
00:31:23,580 --> 00:31:26,130
it's a very model specific thing.

750
00:31:26,130 --> 00:31:27,360
You know, different models take

751
00:31:27,360 --> 00:31:29,509
different types of tool definitions,

752
00:31:29,509 --> 00:31:32,100
so it can be multiple different
ways of specifying them.

753
00:31:32,100 --> 00:31:34,590
This became very problematic.

754
00:31:34,590 --> 00:31:38,190
And so, you know, about a
year ago Anthropic came up

755
00:31:38,190 --> 00:31:41,370
with this idea of the
model context protocol

756
00:31:41,370 --> 00:31:42,720
or MCP for short.

757
00:31:42,720 --> 00:31:44,940
And so that's where MCP comes into play.

758
00:31:44,940 --> 00:31:48,180
It's how we can define a standard way

759
00:31:48,180 --> 00:31:51,090
of creating tool definitions

760
00:31:51,090 --> 00:31:54,555
and exposing them into
a large language model

761
00:31:54,555 --> 00:31:55,860
so I can consume those

762
00:31:55,860 --> 00:31:58,713
and to use those for
all of their processing.

763
00:31:59,640 --> 00:32:02,520
So here's an example
of what MCP looks like,

764
00:32:02,520 --> 00:32:04,740
just from a communications perspective,

765
00:32:04,740 --> 00:32:07,620
you have an application
on the left hand side,

766
00:32:07,620 --> 00:32:10,620
it has a number of MCP clients

767
00:32:10,620 --> 00:32:13,290
and then those MCP
clients will communicate

768
00:32:13,290 --> 00:32:16,890
with an MCP server to go
ahead and take an action

769
00:32:16,890 --> 00:32:18,660
or retrieve a result.

770
00:32:18,660 --> 00:32:20,790
That communication protocol can happen

771
00:32:20,790 --> 00:32:23,040
either remotely over HTTPS

772
00:32:23,040 --> 00:32:25,470
or it can happen locally on your desktop

773
00:32:25,470 --> 00:32:27,753
or laptop using standard io.

774
00:32:29,220 --> 00:32:32,880
So using MCP AI applications
can connect to data sources,

775
00:32:32,880 --> 00:32:34,320
tools and workflows,

776
00:32:34,320 --> 00:32:37,530
it allows you to access key
information and perform tasks.

777
00:32:37,530 --> 00:32:40,920
And again, think of MCP
as this universal protocol

778
00:32:40,920 --> 00:32:43,020
for defining these tasks

779
00:32:43,020 --> 00:32:44,370
and these tool definitions

780
00:32:44,370 --> 00:32:46,890
so that you can connect
your AI into those APIs

781
00:32:46,890 --> 00:32:48,510
and data sources.

782
00:32:48,510 --> 00:32:50,790
So let's look at how this request flow

783
00:32:50,790 --> 00:32:52,710
actually looks under the hood.

784
00:32:52,710 --> 00:32:55,710
So when we have these
different principles,

785
00:32:55,710 --> 00:32:57,360
I have them listed at the top there,

786
00:32:57,360 --> 00:32:58,560
five different principles.

787
00:32:58,560 --> 00:33:03,390
You have the end user who
is actually using the tool,

788
00:33:03,390 --> 00:33:06,150
the MCP host, the application itself,

789
00:33:06,150 --> 00:33:08,760
you have the application
is the second principle

790
00:33:08,760 --> 00:33:12,930
in this diagram, the MCP
client, the MCP server,

791
00:33:12,930 --> 00:33:14,523
and then whatever backend APIs

792
00:33:14,523 --> 00:33:18,930
that that MCP server might
be using to get the results.

793
00:33:18,930 --> 00:33:21,540
So when you launch an
application that's using MCP,

794
00:33:21,540 --> 00:33:23,910
the first thing that that
application is going to do

795
00:33:23,910 --> 00:33:25,500
is it's going to be configured

796
00:33:25,500 --> 00:33:28,470
with a list of MCP servers it knows about.

797
00:33:28,470 --> 00:33:29,550
And so it's going to go ahead

798
00:33:29,550 --> 00:33:33,180
and query for all of the
different tool definitions

799
00:33:33,180 --> 00:33:36,210
that are available on that MCP server.

800
00:33:36,210 --> 00:33:39,000
And it's gonna do that
through the MCP client

801
00:33:39,000 --> 00:33:40,770
that that request comes in,

802
00:33:40,770 --> 00:33:43,350
the MCP client calls into the MCP server,

803
00:33:43,350 --> 00:33:46,650
the MCP server responds
back with a list of tools.

804
00:33:46,650 --> 00:33:48,570
Those tool definitions look just like

805
00:33:48,570 --> 00:33:50,910
what we just saw a couple slides ago

806
00:33:50,910 --> 00:33:53,490
with a English level
description of the tool,

807
00:33:53,490 --> 00:33:57,150
with a list of the parameters
and the output definitions

808
00:33:57,150 --> 00:33:59,970
that gets pumped back into the MCP host.

809
00:33:59,970 --> 00:34:01,833
It can squirrel that data away.

810
00:34:02,940 --> 00:34:05,317
And now when the user comes back and says,

811
00:34:05,317 --> 00:34:10,317
"Hey, I want you to answer
this query," now the MCP host,

812
00:34:10,800 --> 00:34:14,160
that application can take
the list of available tools,

813
00:34:14,160 --> 00:34:17,040
concatenate it with the
natural language query,

814
00:34:17,040 --> 00:34:18,960
it will select a tool,

815
00:34:18,960 --> 00:34:22,140
the large language model will
select a tool based upon that

816
00:34:22,140 --> 00:34:24,150
and a set of parameters,

817
00:34:24,150 --> 00:34:27,030
which then get communicated
back into the MCP server

818
00:34:27,030 --> 00:34:29,220
through the call tool command.

819
00:34:29,220 --> 00:34:30,840
And then that may, you know,

820
00:34:30,840 --> 00:34:34,860
end up triggering additional
downstream requests, right?

821
00:34:34,860 --> 00:34:36,870
It could be calling another API,

822
00:34:36,870 --> 00:34:38,790
it could be querying a database, right?

823
00:34:38,790 --> 00:34:41,382
Whatever that MCP server needs to do

824
00:34:41,382 --> 00:34:44,730
in order to fulfill the structured request

825
00:34:44,730 --> 00:34:48,030
that was just what that just created.

826
00:34:48,030 --> 00:34:49,710
And then that response comes back,

827
00:34:49,710 --> 00:34:52,320
that's a structured response.

828
00:34:52,320 --> 00:34:53,820
The MCP server goes ahead

829
00:34:53,820 --> 00:34:56,790
and formats that back into the client

830
00:34:56,790 --> 00:34:59,730
and then that gets back into the MCP host

831
00:34:59,730 --> 00:35:02,927
with that downstream application

832
00:35:02,927 --> 00:35:05,070
and then that large language
model can interpret it

833
00:35:05,070 --> 00:35:09,183
and give the user a
natural language response.

834
00:35:10,587 --> 00:35:12,253
So I'm gonna circle back to
that question we had earlier

835
00:35:12,253 --> 00:35:14,160
when we talked about tool definitions,

836
00:35:14,160 --> 00:35:16,740
which is what are some
of the security impacts

837
00:35:16,740 --> 00:35:18,990
of exposing an agent in this case

838
00:35:18,990 --> 00:35:21,630
to an untrusted MCP server?

839
00:35:21,630 --> 00:35:24,810
Same thing as we had with
those tool definitions.

840
00:35:24,810 --> 00:35:28,170
Well, as you can see here,
before the user even has a chance

841
00:35:28,170 --> 00:35:29,640
to interact with the application,

842
00:35:29,640 --> 00:35:33,390
we are already ingesting
potentially untrusted data

843
00:35:33,390 --> 00:35:36,030
inside of our large language model.

844
00:35:36,030 --> 00:35:37,290
Those tool definitions,

845
00:35:37,290 --> 00:35:40,740
or in this case the MCP
server's list of tools

846
00:35:40,740 --> 00:35:44,100
can include natural language descriptions

847
00:35:44,100 --> 00:35:45,900
of those tools themselves.

848
00:35:45,900 --> 00:35:47,460
And so you can prompt inject

849
00:35:47,460 --> 00:35:50,370
directly from those descriptions

850
00:35:50,370 --> 00:35:52,230
and these are the sorts of considerations

851
00:35:52,230 --> 00:35:54,390
you need to make when you are exposing

852
00:35:54,390 --> 00:35:57,405
your large language
model based applications

853
00:35:57,405 --> 00:35:58,800
into MCP servers

854
00:35:58,800 --> 00:36:00,250
and other tools such as that.

855
00:36:04,410 --> 00:36:05,760
Kind of rewinding a little bit,

856
00:36:05,760 --> 00:36:10,760
this is how you can create MCP
servers in Python, in code.

857
00:36:12,330 --> 00:36:15,870
So MCP servers, as I mentioned
before, they expose tools.

858
00:36:15,870 --> 00:36:18,330
There's also two other types of resources

859
00:36:18,330 --> 00:36:21,750
that you can expose in MCP,
you can expose resources,

860
00:36:21,750 --> 00:36:23,520
which are things like files

861
00:36:23,520 --> 00:36:26,100
and other things that have a, you know,

862
00:36:26,100 --> 00:36:29,460
kind of a static identifier
associated with them

863
00:36:29,460 --> 00:36:31,750
as well as prompts.

864
00:36:31,750 --> 00:36:33,720
So these are the three
different types of things

865
00:36:33,720 --> 00:36:35,820
that you can expose via MCP server.

866
00:36:35,820 --> 00:36:38,700
I'm gonna focus primarily on tools here.

867
00:36:38,700 --> 00:36:42,810
So here you see an example
of using the FAST MCP library

868
00:36:42,810 --> 00:36:44,310
in Python to create

869
00:36:44,310 --> 00:36:48,180
that very simple ad numbers
tool that we described before.

870
00:36:48,180 --> 00:36:49,860
So you can see in here

871
00:36:49,860 --> 00:36:52,890
it's a simply a fact of adding a decorator

872
00:36:52,890 --> 00:36:54,780
into your Python application.

873
00:36:54,780 --> 00:36:57,720
That add numbers function
could come from anywhere.

874
00:36:57,720 --> 00:37:00,600
You add that decorator of MCP.tool

875
00:37:00,600 --> 00:37:02,640
on top of the function definition.

876
00:37:02,640 --> 00:37:05,820
And what that will do is
actually take the doc string

877
00:37:05,820 --> 00:37:08,700
that was defined there,
add two numbers together,

878
00:37:08,700 --> 00:37:11,190
that becomes the tool definition

879
00:37:11,190 --> 00:37:13,320
for the large language model

880
00:37:13,320 --> 00:37:14,640
and it will parse through

881
00:37:14,640 --> 00:37:16,770
the list of parameters automatically

882
00:37:16,770 --> 00:37:18,660
and that will become
the list of parameters

883
00:37:18,660 --> 00:37:21,240
and their types as well as the return type

884
00:37:21,240 --> 00:37:23,430
that the LLM will be expecting.

885
00:37:23,430 --> 00:37:25,331
So it actually just kind
of does a bunch of magic

886
00:37:25,331 --> 00:37:27,240
under the hood for you.

887
00:37:27,240 --> 00:37:30,867
And so what happens here
is when you do the MCP,

888
00:37:30,867 --> 00:37:33,892
the the communication from the MCP client

889
00:37:33,892 --> 00:37:36,000
into the MCP server,

890
00:37:36,000 --> 00:37:38,643
it's gonna create this JSON RPC structure,

891
00:37:39,486 --> 00:37:41,348
which then goes ahead and says,

892
00:37:41,348 --> 00:37:45,877
"Hey, I want to call your add
numbers tool, MCP server tool,

893
00:37:47,700 --> 00:37:49,620
with these parameters," right?

894
00:37:49,620 --> 00:37:51,803
And that's what it looks
like under the hood.

895
00:37:52,718 --> 00:37:53,730
And use that same flow that we described

896
00:37:53,730 --> 00:37:55,200
before where this is a request

897
00:37:55,200 --> 00:37:58,020
that comes from the LLM
back to the application.

898
00:37:58,020 --> 00:38:00,450
The application handles
it and it goes ahead

899
00:38:00,450 --> 00:38:01,923
and makes that call for you.

900
00:38:03,834 --> 00:38:08,250
So what if you want to require
authorization as part of MCP

901
00:38:08,250 --> 00:38:10,263
for an MCP server or a tool?

902
00:38:12,780 --> 00:38:16,620
OAuth was recently added
into the MCP specification

903
00:38:16,620 --> 00:38:19,980
not long ago in about June of 2025.

904
00:38:19,980 --> 00:38:24,480
And so OAuth allows you to
do both delegated access

905
00:38:24,480 --> 00:38:29,130
as well as service authorization
to tools using MCP.

906
00:38:29,130 --> 00:38:32,040
So this allows you to assign

907
00:38:32,040 --> 00:38:34,500
distinct user and agent identities

908
00:38:34,500 --> 00:38:37,833
so that you secure those
agent actions at scale.

909
00:38:39,393 --> 00:38:42,720
And there are two different
patterns, OAuth patterns,

910
00:38:42,720 --> 00:38:46,620
that we have seen customers use, right,

911
00:38:46,620 --> 00:38:49,830
in order to use OAuth with MCP.

912
00:38:49,830 --> 00:38:52,410
So those patterns are two legged OAuth

913
00:38:52,410 --> 00:38:53,243
and three legged OAuth.

914
00:38:53,243 --> 00:38:55,923
And we're gonna look at the
use cases for both here.

915
00:38:58,500 --> 00:39:01,050
And really the reason why
you would want to choose one

916
00:39:01,050 --> 00:39:04,833
or the other is this
main question right here.

917
00:39:06,367 --> 00:39:08,545
What identity do you want to use

918
00:39:08,545 --> 00:39:13,080
in order to authorize access to this tool,

919
00:39:13,080 --> 00:39:16,320
to this data source,
whatever it happens to be.

920
00:39:16,320 --> 00:39:19,080
Should you use the user's identity,

921
00:39:19,080 --> 00:39:21,300
in which case you would
be looking potentially

922
00:39:21,300 --> 00:39:23,700
at three-legged OAuth flow?

923
00:39:23,700 --> 00:39:27,360
Or is it something where
the agent's identity itself

924
00:39:27,360 --> 00:39:30,840
sort of like a service
identity would sufficient?

925
00:39:30,840 --> 00:39:33,340
And that would be more of
a two-legged OAuth flow.

926
00:39:34,320 --> 00:39:35,730
How do you decide this?

927
00:39:35,730 --> 00:39:38,100
First of all, you think
about data ownership.

928
00:39:38,100 --> 00:39:40,980
If you are dealing with user specific data

929
00:39:40,980 --> 00:39:43,770
such as emails or documents,

930
00:39:43,770 --> 00:39:45,870
then you want to think
about three-legged OAuth

931
00:39:45,870 --> 00:39:48,420
and a user delegated approach

932
00:39:48,420 --> 00:39:50,760
versus something that's a system
or organization owned data

933
00:39:50,760 --> 00:39:52,980
that might be shared resources, et cetera,

934
00:39:52,980 --> 00:39:55,290
then you might be able to use

935
00:39:55,290 --> 00:39:58,740
that service approach of two-legged Oauth.

936
00:39:58,740 --> 00:40:01,050
User interaction, if the user's present

937
00:40:01,050 --> 00:40:03,660
and can perform an authorization step.

938
00:40:03,660 --> 00:40:06,390
That again is a user
delegated action potentially

939
00:40:06,390 --> 00:40:08,940
versus something where you
have no user interaction

940
00:40:08,940 --> 00:40:11,460
and maybe an automated system for example.

941
00:40:11,460 --> 00:40:14,793
And that goes into the operation
timing consideration there.

942
00:40:16,231 --> 00:40:17,400
And then finally, permission scope.

943
00:40:17,400 --> 00:40:19,350
So if you're thinking
about how permissions,

944
00:40:19,350 --> 00:40:22,440
they may vary by the user
and their consent choices

945
00:40:22,440 --> 00:40:24,030
versus consistent permissions

946
00:40:24,030 --> 00:40:26,010
that are designed at the agent level.

947
00:40:26,010 --> 00:40:27,750
So think about these things

948
00:40:27,750 --> 00:40:28,620
and we're gonna look at

949
00:40:28,620 --> 00:40:32,040
how we can actually implement
some of these as well.

950
00:40:32,040 --> 00:40:34,380
And so identity really
at the end of the day

951
00:40:34,380 --> 00:40:36,780
is one of those most important aspects

952
00:40:36,780 --> 00:40:38,520
of architecting tools securely.

953
00:40:38,520 --> 00:40:40,500
And we know that from our
traditional workloads,

954
00:40:40,500 --> 00:40:43,920
this is not a new technology,
it's not a new terminology,

955
00:40:43,920 --> 00:40:46,620
but it is now something
we need to figure out

956
00:40:46,620 --> 00:40:48,054
how to apply appropriately

957
00:40:48,054 --> 00:40:52,383
inside of our AI application
infrastructures as well.

958
00:40:53,310 --> 00:40:55,680
So how can we actually implement it?

959
00:40:55,680 --> 00:40:59,430
AgentCore identity is going
to be the primitive service

960
00:40:59,430 --> 00:41:01,800
that you will use inside of AWS.

961
00:41:01,800 --> 00:41:03,300
If you're using AWS AgentCore,

962
00:41:04,620 --> 00:41:06,510
then this is how you can go ahead

963
00:41:06,510 --> 00:41:11,080
and implement a two legged
or three legged OAuth flow

964
00:41:11,980 --> 00:41:13,983
for your MCP tool calls.

965
00:41:15,535 --> 00:41:19,860
So if we think about creating
an MCP server configuration

966
00:41:19,860 --> 00:41:21,870
that has a tool that we need

967
00:41:21,870 --> 00:41:26,100
to provide a user delegated access to,

968
00:41:26,100 --> 00:41:28,770
that's gonna be a three-legged OAuth call.

969
00:41:28,770 --> 00:41:31,710
So in this case, if we
have a tool that is going

970
00:41:31,710 --> 00:41:36,120
to search a personal travel
log for a variety of,

971
00:41:36,120 --> 00:41:38,160
you know, here's what I, you know,

972
00:41:38,160 --> 00:41:40,470
here's what I went to Vegas
on this date and time,

973
00:41:40,470 --> 00:41:41,370
et cetera, et cetera.

974
00:41:41,370 --> 00:41:44,580
That sort of information, of
course, should be locked down

975
00:41:44,580 --> 00:41:47,673
to only authorized
principles to access that.

976
00:41:48,630 --> 00:41:50,310
So here's an example of using, again,

977
00:41:50,310 --> 00:41:52,620
that fast MCP Python library.

978
00:41:52,620 --> 00:41:54,720
We can see creating that MCP tool,

979
00:41:54,720 --> 00:41:56,670
you see that tool decorator at the top,

980
00:41:56,670 --> 00:41:59,580
but now we've also
included a new decorator,

981
00:41:59,580 --> 00:42:01,560
which is the requires access token.

982
00:42:01,560 --> 00:42:04,020
And you can see that
we've included the idea

983
00:42:04,020 --> 00:42:06,360
that we need to use a user federation

984
00:42:06,360 --> 00:42:08,880
or a three legged OAuth flow

985
00:42:08,880 --> 00:42:13,710
for access into this
particular function call.

986
00:42:13,710 --> 00:42:15,750
And so this is going to go ahead

987
00:42:15,750 --> 00:42:19,830
and get us a token that's
associated with the end user

988
00:42:19,830 --> 00:42:23,940
so that we can make further
downstream authorized calls

989
00:42:23,940 --> 00:42:26,280
to get those logs, for example.

990
00:42:26,280 --> 00:42:30,060
And to, you know, to create that request,

991
00:42:30,060 --> 00:42:31,683
that response back to the user.

992
00:42:33,390 --> 00:42:35,310
Of course, with three legged OAuth,

993
00:42:35,310 --> 00:42:38,190
you see that last one
where it's on auth URL.

994
00:42:38,190 --> 00:42:40,637
So that is going to be the URL

995
00:42:40,637 --> 00:42:42,000
that the user will be redirected to

996
00:42:42,000 --> 00:42:44,663
so that they can go ahead
and grant that authorization.

997
00:42:46,363 --> 00:42:49,140
In contrast, the two two-legged
OAuth is going to use

998
00:42:49,140 --> 00:42:51,000
a a static token, right,

999
00:42:51,000 --> 00:42:55,080
that's gonna be associated
with this particular agent.

1000
00:42:55,080 --> 00:42:57,690
It's gonna be a machine to
machine authorization flow.

1001
00:42:57,690 --> 00:43:01,830
And so that's going to have
no authorization URL obviously

1002
00:43:01,830 --> 00:43:03,570
because there's not
going to be a user there

1003
00:43:03,570 --> 00:43:04,682
to authorize that access,

1004
00:43:04,682 --> 00:43:08,730
but it's going to provide
the MCP server here,

1005
00:43:08,730 --> 00:43:11,880
in this case, a static token
that can be used to go ahead

1006
00:43:11,880 --> 00:43:14,553
and access protected
resources behind the scenes.

1007
00:43:15,480 --> 00:43:18,930
So again, two legged OAuth
expects client credentials,

1008
00:43:18,930 --> 00:43:21,600
whereas three legged OAuth
expects authorization codes

1009
00:43:21,600 --> 00:43:22,803
with user federation.

1010
00:43:23,730 --> 00:43:24,563
So what does this mean

1011
00:43:24,563 --> 00:43:26,910
from a security perspective with tools?

1012
00:43:26,910 --> 00:43:30,510
Well first of all, you need
to set the right permissions

1013
00:43:30,510 --> 00:43:34,020
for tool calls and what
identity you want to use.

1014
00:43:34,020 --> 00:43:37,290
You wanna understand as a decision maker,

1015
00:43:37,290 --> 00:43:42,290
what is the LLM going to
be authorized to decide?

1016
00:43:43,396 --> 00:43:44,490
What are the different decisions

1017
00:43:44,490 --> 00:43:48,300
that you are going to delegate
to the large language model?

1018
00:43:48,300 --> 00:43:53,300
Are you comfortable with it
deciding what parameters to call

1019
00:43:53,880 --> 00:43:55,560
to this particular tool.

1020
00:43:55,560 --> 00:43:56,550
Think of it this way.

1021
00:43:56,550 --> 00:44:01,550
If a tool has a parameter
that says authorized username,

1022
00:44:01,890 --> 00:44:05,550
am I going to let the
large language model decide

1023
00:44:05,550 --> 00:44:10,020
what value to put in for
the authorized username

1024
00:44:10,020 --> 00:44:12,270
for my parameter, for my tool call?

1025
00:44:12,270 --> 00:44:14,700
The answer should be no, right?

1026
00:44:14,700 --> 00:44:18,150
The identity will be piped
through to the tool call

1027
00:44:18,150 --> 00:44:21,060
through OAuth or some external mechanism.

1028
00:44:21,060 --> 00:44:25,290
And then the LLM'S decision
making power is limited to

1029
00:44:25,290 --> 00:44:26,880
what are the different parameters maybe

1030
00:44:26,880 --> 00:44:28,560
for that query, right?

1031
00:44:28,560 --> 00:44:31,983
As opposed to who that
identity is in first place.

1032
00:44:32,940 --> 00:44:36,090
MCP provides a standard
way to connect the AI

1033
00:44:36,090 --> 00:44:37,260
with the outside world.

1034
00:44:37,260 --> 00:44:40,230
And finally, OAuth is your
standard for communicating

1035
00:44:40,230 --> 00:44:44,700
whether a user or service
is authorized for an action.

1036
00:44:44,700 --> 00:44:48,850
And again, don't forget
that this all comes down to

1037
00:44:49,770 --> 00:44:54,462
putting things into a
context window for the LLM.

1038
00:44:54,462 --> 00:44:57,630
Everything just gets pushed
into that large context window

1039
00:44:57,630 --> 00:44:59,490
for the large language model.

1040
00:44:59,490 --> 00:45:02,973
And where is the
authorization inside the LLM?

1041
00:45:05,130 --> 00:45:07,080
It's not there, right?

1042
00:45:07,080 --> 00:45:10,110
Very important, very
important to keep in mind.

1043
00:45:10,110 --> 00:45:12,690
Alright, phase four agents, right?

1044
00:45:12,690 --> 00:45:14,400
We're moving up the stack, right?

1045
00:45:14,400 --> 00:45:17,250
We're becoming even more
and more complex here.

1046
00:45:17,250 --> 00:45:18,780
We have agents

1047
00:45:18,780 --> 00:45:22,980
where we are delegating even
more decision making power

1048
00:45:22,980 --> 00:45:25,838
into the large language model, right?

1049
00:45:25,838 --> 00:45:28,170
Before we had very specific workflows

1050
00:45:28,170 --> 00:45:32,415
that were well-defined
inside of code and agents,

1051
00:45:32,415 --> 00:45:36,300
we are like taking away some
of that decision making power

1052
00:45:36,300 --> 00:45:39,210
and giving it into the
large language model now.

1053
00:45:39,210 --> 00:45:42,210
So an agent has a lot of definitions.

1054
00:45:42,210 --> 00:45:44,280
I think every single software company

1055
00:45:44,280 --> 00:45:45,780
defines agents differently.

1056
00:45:45,780 --> 00:45:48,390
The way we like to think of
it is as a software program

1057
00:45:48,390 --> 00:45:50,940
that can interact with the
environment, collect data,

1058
00:45:50,940 --> 00:45:55,260
and then perform self-directed tasks

1059
00:45:55,260 --> 00:45:58,170
that meet predetermined goals.

1060
00:45:58,170 --> 00:46:01,350
So it's a goal oriented architecture

1061
00:46:01,350 --> 00:46:04,920
rather than a task
oriented or like a inter,

1062
00:46:04,920 --> 00:46:07,050
like a, you know, interpretation,

1063
00:46:07,050 --> 00:46:09,153
like step one, step two, step three.

1064
00:46:10,200 --> 00:46:11,910
So in this case, AI agents,

1065
00:46:11,910 --> 00:46:13,350
they act autonomously

1066
00:46:13,350 --> 00:46:15,843
without constant human intervention.

1067
00:46:16,950 --> 00:46:18,210
They interact with the environment

1068
00:46:18,210 --> 00:46:20,190
by collecting those data sources

1069
00:46:20,190 --> 00:46:22,770
and they're combining that
environment, that data,

1070
00:46:22,770 --> 00:46:25,230
with domain knowledge in past context.

1071
00:46:25,230 --> 00:46:28,950
And they're gonna use tools
such as AgentCore Memory,

1072
00:46:28,950 --> 00:46:30,660
which Riggs just talked about,

1073
00:46:30,660 --> 00:46:32,970
in order to learn from past interactions

1074
00:46:32,970 --> 00:46:34,833
and to improve over time.

1075
00:46:35,888 --> 00:46:38,670
So how does this actually
work under the hood?

1076
00:46:38,670 --> 00:46:40,490
Well everything with agents works

1077
00:46:40,490 --> 00:46:43,740
with what's called an agentic loop.

1078
00:46:43,740 --> 00:46:46,500
And an agentic loop is
a piece of software,

1079
00:46:46,500 --> 00:46:48,600
it's a deterministic piece of software.

1080
00:46:48,600 --> 00:46:51,330
It enables those intelligent
autonomous behaviors

1081
00:46:51,330 --> 00:46:54,210
through this cycle of reasoning, tool use,

1082
00:46:54,210 --> 00:46:56,010
and response generation.

1083
00:46:56,010 --> 00:47:00,028
So a prompt comes in inside
of this agentic loop,

1084
00:47:00,028 --> 00:47:03,028
it's the input and the
agent can then go ahead

1085
00:47:03,028 --> 00:47:07,290
and invoke the model to
get a response, to get a,

1086
00:47:07,290 --> 00:47:10,380
to invoke reasoning, to
figure out what tools

1087
00:47:10,380 --> 00:47:13,380
that should be called as
part of this agentic loop

1088
00:47:13,380 --> 00:47:15,930
to respond back to the user's query.

1089
00:47:15,930 --> 00:47:17,790
And so again, the agent is going to take

1090
00:47:17,790 --> 00:47:20,970
that response from the model,

1091
00:47:20,970 --> 00:47:25,970
it could include a request
to call a specific tool,

1092
00:47:26,490 --> 00:47:28,140
and the agent then will go ahead

1093
00:47:28,140 --> 00:47:30,180
and take that tool request,

1094
00:47:30,180 --> 00:47:33,390
execute that tool, get data, the data,

1095
00:47:33,390 --> 00:47:36,060
the result of that data will
get back into the agent.

1096
00:47:36,060 --> 00:47:38,812
The agent will return
that back to the model.

1097
00:47:38,812 --> 00:47:40,770
And this loop continues,
continues, continues

1098
00:47:40,770 --> 00:47:43,350
until the model has decided

1099
00:47:43,350 --> 00:47:45,840
that the answer has been complete

1100
00:47:45,840 --> 00:47:48,690
and the agentic loop can
terminate and it will go ahead

1101
00:47:48,690 --> 00:47:53,190
and return the final
response back to the user.

1102
00:47:53,190 --> 00:47:55,200
So again, it's important to realize

1103
00:47:55,200 --> 00:47:58,680
what parts of this diagram
are deterministic code

1104
00:47:58,680 --> 00:48:00,810
and what parts of this diagram are

1105
00:48:00,810 --> 00:48:04,893
non-deterministic AI based
large language models.

1106
00:48:08,250 --> 00:48:09,330
We have a tool,

1107
00:48:09,330 --> 00:48:13,153
we have a library called
the Strands Agent SDK.

1108
00:48:13,153 --> 00:48:15,840
How many of you have played
with Strands in this audience?

1109
00:48:15,840 --> 00:48:18,300
Alright, I've got a couple
of hands up that's excellent.

1110
00:48:18,300 --> 00:48:21,450
Strands is a great library that allows you

1111
00:48:21,450 --> 00:48:23,400
to create production ready agents

1112
00:48:23,400 --> 00:48:26,280
in just a few lines of Python code.

1113
00:48:26,280 --> 00:48:27,150
And so we've got a QR code up there

1114
00:48:27,150 --> 00:48:29,528
if you wanna learn more about it.

1115
00:48:29,528 --> 00:48:30,361
But what does it look like

1116
00:48:30,361 --> 00:48:34,080
when you are actually
building an agent with Strands

1117
00:48:34,080 --> 00:48:35,430
with the agent class?

1118
00:48:35,430 --> 00:48:38,544
It's one of the key
components of the agent's,

1119
00:48:38,544 --> 00:48:40,410
sorry, the Strands SDK.

1120
00:48:40,410 --> 00:48:41,243
Well what we did is

1121
00:48:41,243 --> 00:48:43,770
we actually kind of put
together pseudo code

1122
00:48:43,770 --> 00:48:45,330
for what this looks like.

1123
00:48:45,330 --> 00:48:47,100
So inside the agentic loop,

1124
00:48:47,100 --> 00:48:50,250
we can see it is a loop all right?

1125
00:48:50,250 --> 00:48:51,660
While true,

1126
00:48:51,660 --> 00:48:53,550
we're going to call the language model

1127
00:48:53,550 --> 00:48:55,470
based on the user's prompt.

1128
00:48:55,470 --> 00:48:58,290
We're going to get a, you know,

1129
00:48:58,290 --> 00:49:00,300
we're gonna give it a list
of tools in the messages

1130
00:49:00,300 --> 00:49:02,160
that we've already processed

1131
00:49:02,160 --> 00:49:03,480
through this agentic loop.

1132
00:49:03,480 --> 00:49:04,350
And then we're gonna see,

1133
00:49:04,350 --> 00:49:07,338
hey, what does the model
think we should do?

1134
00:49:07,338 --> 00:49:09,150
We're going to ask it to
make a decision for us,

1135
00:49:09,150 --> 00:49:14,070
should it say that we are done,
that's our end turn there,

1136
00:49:14,070 --> 00:49:16,860
we'll go ahead and return the
final answer back to the user,

1137
00:49:16,860 --> 00:49:19,087
but most likely the model says that,

1138
00:49:19,087 --> 00:49:22,590
"Hey, we need to call a tool
in order to further answer

1139
00:49:22,590 --> 00:49:23,910
this user's question."

1140
00:49:23,910 --> 00:49:24,960
So I'll go ahead

1141
00:49:24,960 --> 00:49:26,850
and take a look at the tools

1142
00:49:26,850 --> 00:49:29,820
that it has requested me to execute.

1143
00:49:29,820 --> 00:49:32,190
Again, this is deterministic code sitting

1144
00:49:32,190 --> 00:49:34,590
inside of the Strands Agent SDK,

1145
00:49:34,590 --> 00:49:35,640
and it's going to go ahead

1146
00:49:35,640 --> 00:49:37,740
and for each one of those tool requests,

1147
00:49:37,740 --> 00:49:41,310
actually just go ahead
and call that tool, right,

1148
00:49:41,310 --> 00:49:43,230
add the results back into the messages

1149
00:49:43,230 --> 00:49:45,720
that are gonna be
concatenated back into this,

1150
00:49:45,720 --> 00:49:48,423
agentic loop for the next time around.

1151
00:49:49,531 --> 00:49:50,364
And then of course, you know,

1152
00:49:50,364 --> 00:49:53,245
you have error conditions and so forth.

1153
00:49:53,245 --> 00:49:55,020
If I've overflowed the context window,

1154
00:49:55,020 --> 00:49:56,910
I gotta handle that, that sort of thing.

1155
00:49:56,910 --> 00:50:00,840
But you get the idea here
that this is a constant loop

1156
00:50:00,840 --> 00:50:04,470
that's happening and it's
basically a loop of LLM,

1157
00:50:04,470 --> 00:50:05,820
what should I do next?

1158
00:50:05,820 --> 00:50:08,640
Okay, I'll go ahead and
do that on your behalf

1159
00:50:08,640 --> 00:50:10,340
and then tell me when you're done.

1160
00:50:11,639 --> 00:50:13,170
That is the agentic loop.

1161
00:50:13,170 --> 00:50:16,020
So what changes with agents
in this case then, right?

1162
00:50:16,020 --> 00:50:18,390
Well, think about
generative AI applications.

1163
00:50:18,390 --> 00:50:20,400
They're really about answering questions,

1164
00:50:20,400 --> 00:50:23,040
maybe one shot or a couple shot questions.

1165
00:50:23,040 --> 00:50:24,690
Agents accomplish goals.

1166
00:50:24,690 --> 00:50:27,510
So agents are all about autonomy

1167
00:50:27,510 --> 00:50:29,220
because they can act autonomously.

1168
00:50:29,220 --> 00:50:31,168
We are delegating more
decision making power

1169
00:50:31,168 --> 00:50:33,360
into the agent to achieve a goal

1170
00:50:33,360 --> 00:50:35,820
by planning and making its own decisions.

1171
00:50:35,820 --> 00:50:37,440
They become more complex

1172
00:50:37,440 --> 00:50:40,863
because they can be
multi-step complex workflows.

1173
00:50:42,415 --> 00:50:44,070
They do increase our risk profile

1174
00:50:44,070 --> 00:50:47,850
because we are giving
agents more autonomy,

1175
00:50:47,850 --> 00:50:50,160
we are taking on more risk

1176
00:50:50,160 --> 00:50:51,690
because we don't know necessarily

1177
00:50:51,690 --> 00:50:54,030
what the LLM is going to decide for us

1178
00:50:54,030 --> 00:50:55,650
and it's aligned with
what we want it to do,

1179
00:50:55,650 --> 00:50:57,933
so we are going to put
guardrails around it.

1180
00:50:59,926 --> 00:51:00,990
And finally, learning and adaptability.

1181
00:51:00,990 --> 00:51:04,230
So agents can use memory
again to actively learn

1182
00:51:04,230 --> 00:51:09,090
and adapt based on the outcomes
of the previous actions.

1183
00:51:09,090 --> 00:51:12,420
So multi-agent workflows,
what do those look like?

1184
00:51:12,420 --> 00:51:16,440
So if you look at different ways

1185
00:51:16,440 --> 00:51:18,390
that you can implement agents,

1186
00:51:18,390 --> 00:51:20,130
there's a couple of
different ways you can do it.

1187
00:51:20,130 --> 00:51:22,020
One way that you can do it is

1188
00:51:22,020 --> 00:51:26,100
by this sort of deterministic workflow.

1189
00:51:26,100 --> 00:51:28,590
So we'll start with this one
where we have an entry point,

1190
00:51:28,590 --> 00:51:30,181
we have an example where we want

1191
00:51:30,181 --> 00:51:35,181
to take incoming logs from a sim

1192
00:51:35,520 --> 00:51:37,830
and we want to go ahead and enrich them

1193
00:51:37,830 --> 00:51:39,163
and figure out what we
should do and start,

1194
00:51:39,163 --> 00:51:41,790
you know, interacting
with our ticketing system

1195
00:51:41,790 --> 00:51:42,750
and so forth, right?

1196
00:51:42,750 --> 00:51:45,780
We may even want it to do
some auto remediation actions

1197
00:51:45,780 --> 00:51:49,440
based upon some existing
runbooks that we have.

1198
00:51:49,440 --> 00:51:51,840
So this is what this could look like.

1199
00:51:51,840 --> 00:51:54,570
I'll show you two different
ways that you can organize it.

1200
00:51:54,570 --> 00:51:56,100
So in this first way,

1201
00:51:56,100 --> 00:51:59,527
we're going to have
several different agents.

1202
00:51:59,527 --> 00:52:01,980
Each one has a specific task

1203
00:52:01,980 --> 00:52:06,840
and we are going to wire them
up as a specific workflow.

1204
00:52:06,840 --> 00:52:08,280
So we have our enrichment agent,

1205
00:52:08,280 --> 00:52:10,050
it's gonna query the seam logs,

1206
00:52:10,050 --> 00:52:12,030
we're gonna check threat intelligence

1207
00:52:12,030 --> 00:52:15,870
to see what it might know
about the particular indicators

1208
00:52:15,870 --> 00:52:17,820
that we're seeing from the logs,

1209
00:52:17,820 --> 00:52:20,700
and then that will be fed
into a separate agent,

1210
00:52:20,700 --> 00:52:24,480
a triage agent, to figure out
what we should do about it.

1211
00:52:24,480 --> 00:52:27,690
We can take a decision from the
result of that triage agent.

1212
00:52:27,690 --> 00:52:31,050
We could either execute an
automated remediation action,

1213
00:52:31,050 --> 00:52:34,080
which is gonna block that
IP from our firewall,

1214
00:52:34,080 --> 00:52:36,690
or we can just go ahead
and document what we did.

1215
00:52:36,690 --> 00:52:39,360
It might be a false positive, who knows?

1216
00:52:39,360 --> 00:52:42,240
But we're gonna update the
ticket with the reasoning

1217
00:52:42,240 --> 00:52:44,430
that we have in the resolution agent,

1218
00:52:44,430 --> 00:52:47,460
and that is the end of
our multi-agent workflow.

1219
00:52:47,460 --> 00:52:50,970
So this way we are
breaking apart our workflow

1220
00:52:50,970 --> 00:52:52,830
into multiple different agents

1221
00:52:52,830 --> 00:52:54,390
and then we're going to go ahead

1222
00:52:54,390 --> 00:52:56,520
and wire them together in code,

1223
00:52:56,520 --> 00:52:58,120
as you'll see in the next slide.

1224
00:52:59,010 --> 00:53:03,150
So in this design, again,
it's a specific workflow

1225
00:53:03,150 --> 00:53:05,220
that's followed with each agent having

1226
00:53:05,220 --> 00:53:07,530
specific tools that they can call.

1227
00:53:07,530 --> 00:53:10,530
So you can see here in
our strand pseudocode,

1228
00:53:10,530 --> 00:53:14,010
we are defining each one of those agents,

1229
00:53:14,010 --> 00:53:16,200
giving each one of those agents its prompt

1230
00:53:16,200 --> 00:53:18,300
for what it should be doing,

1231
00:53:18,300 --> 00:53:21,180
and then it has a list
of just a couple of tools

1232
00:53:21,180 --> 00:53:23,100
associated with that agent.

1233
00:53:23,100 --> 00:53:26,130
So the first enrich agent
has two tools with it.

1234
00:53:26,130 --> 00:53:29,520
The execute agent has a
tool associated with it.

1235
00:53:29,520 --> 00:53:31,170
The triage agent has no tools

1236
00:53:31,170 --> 00:53:33,570
because really the purpose
of the triage agent is

1237
00:53:33,570 --> 00:53:37,680
to simply render a decision
based upon the previous context

1238
00:53:37,680 --> 00:53:39,810
that it's that we've collected.

1239
00:53:39,810 --> 00:53:44,580
So you can see each agent
has a small number of tools

1240
00:53:44,580 --> 00:53:46,620
with which it's going to be working.

1241
00:53:46,620 --> 00:53:49,560
And then what we're gonna do
is we're going to go ahead

1242
00:53:49,560 --> 00:53:53,913
and wire all of that together
in this graph based workflow.

1243
00:53:54,990 --> 00:53:58,110
So we'll define, okay, we have
our should execute action.

1244
00:53:58,110 --> 00:53:59,070
This is gonna take

1245
00:53:59,070 --> 00:54:02,310
the result of our large
language models decision

1246
00:54:02,310 --> 00:54:03,750
that it makes, right,

1247
00:54:03,750 --> 00:54:05,640
as part of that if then statement

1248
00:54:05,640 --> 00:54:07,050
that you saw in the the pseudo

1249
00:54:07,050 --> 00:54:10,200
or into the flow chart
in the previous slide.

1250
00:54:10,200 --> 00:54:11,970
And then we have the security workflow.

1251
00:54:11,970 --> 00:54:14,580
It's all wired together
as you can see there

1252
00:54:14,580 --> 00:54:16,110
where we have a graph builder,

1253
00:54:16,110 --> 00:54:18,660
we've added a node for the enrichment,

1254
00:54:18,660 --> 00:54:21,600
we go ahead and put the
result of the enrichment

1255
00:54:21,600 --> 00:54:22,860
into the triage node.

1256
00:54:22,860 --> 00:54:25,140
The triage node enters into the execution

1257
00:54:25,140 --> 00:54:27,753
and resolution nodes
and so forth and so on.

1258
00:54:28,800 --> 00:54:30,540
So again, the point here being is

1259
00:54:30,540 --> 00:54:34,650
that we are still relying
upon deterministic code

1260
00:54:34,650 --> 00:54:36,180
for the actual workflow

1261
00:54:36,180 --> 00:54:38,580
and wiring all of these pieces together,

1262
00:54:38,580 --> 00:54:42,360
but we are now delegating
smaller pieces of decision making

1263
00:54:42,360 --> 00:54:46,443
and contextual generation
into the large language model.

1264
00:54:48,600 --> 00:54:52,620
This is different from another
way to design the system

1265
00:54:52,620 --> 00:54:55,580
with the same goal in
mind in which we are going

1266
00:54:55,580 --> 00:54:57,543
to use a single agent.

1267
00:54:58,767 --> 00:55:00,217
So let's take a look at that.

1268
00:55:01,080 --> 00:55:02,730
If I wanted to create this

1269
00:55:02,730 --> 00:55:06,840
and use one agent to
do this entire process,

1270
00:55:06,840 --> 00:55:09,660
I do something a little
similar but very different

1271
00:55:09,660 --> 00:55:10,860
and it's a nuance.

1272
00:55:10,860 --> 00:55:12,630
So let's take a look at how this works.

1273
00:55:12,630 --> 00:55:14,580
We still take our prompt in from the user

1274
00:55:14,580 --> 00:55:16,620
or from an automated process.

1275
00:55:16,620 --> 00:55:18,630
We put it into this agentic loop.

1276
00:55:18,630 --> 00:55:22,530
But in this case, the agent
loop is going to have access

1277
00:55:22,530 --> 00:55:26,760
to all of the tools and all of
the capabilities all at once.

1278
00:55:26,760 --> 00:55:29,880
And so the agentic loop
is going to be doing

1279
00:55:29,880 --> 00:55:32,280
a lot more of the decision making.

1280
00:55:32,280 --> 00:55:35,910
And in fact, there is
no set workflow here.

1281
00:55:35,910 --> 00:55:38,700
The agentic loop is going
to rely upon the LLM

1282
00:55:38,700 --> 00:55:41,100
to make a decision about what to do next

1283
00:55:41,100 --> 00:55:44,640
for every single step of this operation.

1284
00:55:44,640 --> 00:55:48,060
So the agent, the LLM,
could simply decide,

1285
00:55:48,060 --> 00:55:49,560
it could query the SIM logs

1286
00:55:49,560 --> 00:55:50,580
and then go straight

1287
00:55:50,580 --> 00:55:52,620
to updating the ticket
without even checking

1288
00:55:52,620 --> 00:55:54,750
the threat intelligence, let's say, right?

1289
00:55:54,750 --> 00:55:57,900
So this is delegating a lot more autonomy

1290
00:55:57,900 --> 00:56:01,950
into the AI system, which
can be very powerful.

1291
00:56:01,950 --> 00:56:04,530
However, you have to, you
know, weigh those risks

1292
00:56:04,530 --> 00:56:07,710
with how you want to, you
know, how much control you want

1293
00:56:07,710 --> 00:56:11,850
to have on how that workflow
is actually executed, right?

1294
00:56:11,850 --> 00:56:14,700
Do you want to be more
prescriptive about it

1295
00:56:14,700 --> 00:56:16,350
and use the multi-agent workflow

1296
00:56:16,350 --> 00:56:18,240
or do you want to have more autonomy

1297
00:56:18,240 --> 00:56:20,760
that you've delegated into the AI

1298
00:56:20,760 --> 00:56:23,060
and you're gonna use
this single agent design?

1299
00:56:25,880 --> 00:56:27,420
So with this design, right,
again, there's one agent,

1300
00:56:27,420 --> 00:56:30,690
it autonomously decides
which tools to call.

1301
00:56:30,690 --> 00:56:33,660
And you can see literally
there is one agent here

1302
00:56:33,660 --> 00:56:34,927
in our definition,

1303
00:56:34,927 --> 00:56:37,890
and that agent just happens to have

1304
00:56:37,890 --> 00:56:40,230
all of the different tools associated

1305
00:56:40,230 --> 00:56:43,053
with our design at its disposal.

1306
00:56:43,919 --> 00:56:47,610
So now we have, that agent has
a prop that says you are a,

1307
00:56:47,610 --> 00:56:50,400
you know, a tier one network analyst.

1308
00:56:50,400 --> 00:56:52,110
Here are the tools that you have.

1309
00:56:52,110 --> 00:56:55,470
Give it some alignment and
tell it what you want it to do.

1310
00:56:55,470 --> 00:56:58,020
But ultimately, the agentic loop

1311
00:56:58,020 --> 00:57:02,869
and the LLM will be deciding
how it's going to walk through

1312
00:57:02,869 --> 00:57:04,410
and use the tools at its disposal

1313
00:57:04,410 --> 00:57:06,810
rather than a deterministic system

1314
00:57:06,810 --> 00:57:09,303
wiring them all up ahead of time.

1315
00:57:10,393 --> 00:57:12,180
So compared to the multi-agent solution,

1316
00:57:12,180 --> 00:57:15,510
there is way less complexity
here, as you can tell.

1317
00:57:15,510 --> 00:57:17,550
However, as I mentioned before,

1318
00:57:17,550 --> 00:57:19,590
you're giving the agent
a lot more autonomy

1319
00:57:19,590 --> 00:57:22,240
to decide what actions to
take and when to take them.

1320
00:57:24,420 --> 00:57:26,370
So how do we put human in the loop

1321
00:57:26,370 --> 00:57:28,648
in some of these things, right?

1322
00:57:28,648 --> 00:57:30,724
We would like to have all this autonomy,

1323
00:57:30,724 --> 00:57:33,900
but we also want to have
the ability to have some way

1324
00:57:33,900 --> 00:57:36,270
to put human approval in there.

1325
00:57:36,270 --> 00:57:37,710
This is where you can put things

1326
00:57:37,710 --> 00:57:40,200
like Strands hooks into play.

1327
00:57:40,200 --> 00:57:42,180
So hooks provide deterministic controls

1328
00:57:42,180 --> 00:57:43,860
as part of your agentic loop.

1329
00:57:43,860 --> 00:57:47,028
So for example, you can
control that autonomy

1330
00:57:47,028 --> 00:57:49,620
and perform checks as part
of the agentic architecture.

1331
00:57:49,620 --> 00:57:50,453
I'm gonna give you

1332
00:57:50,453 --> 00:57:53,160
an example of an approval
hook in this case.

1333
00:57:53,160 --> 00:57:54,540
So let's say that we have

1334
00:57:54,540 --> 00:57:58,080
that high risk security
remediation action,

1335
00:57:58,080 --> 00:58:00,570
such as blocking an IP from the firewall.

1336
00:58:00,570 --> 00:58:02,220
We don't want to necessarily have

1337
00:58:02,220 --> 00:58:04,650
that happen without somebody
looking at that first,

1338
00:58:04,650 --> 00:58:07,740
lest it interact with
our production systems.

1339
00:58:07,740 --> 00:58:10,740
So in this case, we can
define our approval hook

1340
00:58:10,740 --> 00:58:13,200
and we can say, here are
some high risk tools,

1341
00:58:13,200 --> 00:58:15,060
such as block IP firewall.

1342
00:58:15,060 --> 00:58:19,560
And so when we see that
tool call, we can go ahead,

1343
00:58:19,560 --> 00:58:23,280
and go through and say,
here's a request for approval.

1344
00:58:23,280 --> 00:58:25,770
And now we can maybe send a Slack message,

1345
00:58:25,770 --> 00:58:29,519
we could send a ticket
to the appropriate team

1346
00:58:29,519 --> 00:58:31,800
and then they can review it
and approve it or deny it

1347
00:58:31,800 --> 00:58:34,983
before the agentic loop can continue.

1348
00:58:36,699 --> 00:58:38,370
So there's a lot of use cases
that you can have for hooks.

1349
00:58:38,370 --> 00:58:41,040
We just talked about the,
you know, one example.

1350
00:58:41,040 --> 00:58:43,710
You can have intent
breaking, goal manipulation,

1351
00:58:43,710 --> 00:58:45,690
you wanna understand, you know,

1352
00:58:45,690 --> 00:58:49,200
and control for a disruptive
or deceptive behaviors,

1353
00:58:49,200 --> 00:58:50,600
all that kind of good stuff.

1354
00:58:52,440 --> 00:58:54,000
So in summary, what does this mean

1355
00:58:54,000 --> 00:58:56,220
from a security perspective with agents?

1356
00:58:56,220 --> 00:58:58,950
Well, we understand now the agentic loop

1357
00:58:58,950 --> 00:59:03,000
enables autonomous actions
while having an ability

1358
00:59:03,000 --> 00:59:06,300
to still inject deterministic
controls into play.

1359
00:59:06,300 --> 00:59:09,060
Human in the loop is
gonna be one of those ways

1360
00:59:09,060 --> 00:59:11,010
that you can keep, you know,

1361
00:59:11,010 --> 00:59:14,130
understanding of what is going
on with your Agent X systems,

1362
00:59:14,130 --> 00:59:16,893
even if you do delegate a
lot of autonomy to them.

1363
00:59:17,910 --> 00:59:21,550
Agent design does have
some implications here.

1364
00:59:21,550 --> 00:59:22,740
We talked about single versus multi-agent,

1365
00:59:22,740 --> 00:59:25,230
and of course you always
wanna understand the agency

1366
00:59:25,230 --> 00:59:27,393
that you're delegating into the AI system.

1367
00:59:28,681 --> 00:59:32,790
So in conclusion, we wanna
understand that security

1368
00:59:32,790 --> 00:59:35,100
and risk in AI systems is dependent on

1369
00:59:35,100 --> 00:59:37,710
what the application
or agent has access to

1370
00:59:37,710 --> 00:59:40,380
and what actions it's
authorized to make on its own.

1371
00:59:40,380 --> 00:59:43,290
So this is a very classic thing here.

1372
00:59:43,290 --> 00:59:47,460
This is sensitive data, untrusted
data, and external access.

1373
00:59:47,460 --> 00:59:49,530
You want to pick two, not all three,

1374
00:59:49,530 --> 00:59:53,670
because at the center of this
Venn diagram is danger, right?

1375
00:59:53,670 --> 00:59:55,680
If you have an LLM that has access

1376
00:59:55,680 --> 00:59:58,200
to all three of these
things at the same time,

1377
00:59:58,200 --> 01:00:00,690
this causes security issues,

1378
01:00:00,690 --> 01:00:03,030
you always want to think about that.

1379
01:00:03,030 --> 01:00:04,613
All three of those provide a concern.

1380
01:00:08,160 --> 01:00:10,980
Place security controls outside the model.

1381
01:00:10,980 --> 01:00:12,960
If you take nothing
away from this session,

1382
01:00:12,960 --> 01:00:14,378
take a picture of this slide.

1383
01:00:14,378 --> 01:00:16,770
You always want to have a determinist

1384
01:00:16,770 --> 01:00:18,600
to control around that data.

1385
01:00:18,600 --> 01:00:20,550
You want to validate
your input and output,

1386
01:00:20,550 --> 01:00:23,400
and you want to use identity
to do your tool calls,

1387
01:00:23,400 --> 01:00:25,980
protecting the entire flow,

1388
01:00:25,980 --> 01:00:28,816
agentic identity as a combination
of your agent identity

1389
01:00:28,816 --> 01:00:33,060
and a human identities that
you're operating on behalf of,

1390
01:00:33,060 --> 01:00:36,210
and finally, I'm gonna
give you one last slide,

1391
01:00:36,210 --> 01:00:40,590
which is a list of all of the
resources from earlier today.

1392
01:00:40,590 --> 01:00:43,440
We've got a bunch of
different QR codes for you

1393
01:00:43,440 --> 01:00:46,951
to take a look at for our security blog,

1394
01:00:46,951 --> 01:00:49,110
reference architectures
secure AI landing pages,

1395
01:00:49,110 --> 01:00:51,780
and then we have over a hundred
different sessions today

1396
01:00:51,780 --> 01:00:53,100
related to AI security.

1397
01:00:53,100 --> 01:00:56,160
So thank you so much for
attending. Have a great re:Invent.

1398
01:00:56,160 --> 01:00:56,993
Thank you.

