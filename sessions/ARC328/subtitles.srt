1
00:00:00,578 --> 00:00:02,180
OK, super cool. Alright,

2
00:00:02,528 --> 00:00:05,009
um, welcome to privacy preserving AI primitives,

3
00:00:05,139 --> 00:00:06,980
uh, building blocks for regulated industry.

4
00:00:07,339 --> 00:00:09,339
Uh, this is ARC 328,

5
00:00:09,368 --> 00:00:11,089
and we're super happy to have you here.

6
00:00:11,419 --> 00:00:13,478
My name is Ruben Mertz. I'm a principal

7
00:00:13,478 --> 00:00:15,500
solutions architect, um, at EDBs, and

8
00:00:15,500 --> 00:00:16,500
I'm here with my colleague Jenny Bean.

9
00:00:18,609 --> 00:00:20,609
Hi y'all, my name is JD Bean.

10
00:00:20,690 --> 00:00:22,929
I'm a principal architect in the AWS,

11
00:00:23,048 --> 00:00:25,079
uh, Compute and ML services

12
00:00:25,079 --> 00:00:27,309
organization. I have the privilege of, uh,

13
00:00:27,329 --> 00:00:29,609
being embedded pretty deeply with our engineering and

14
00:00:29,609 --> 00:00:31,769
product teams, working on a wide range

15
00:00:31,769 --> 00:00:34,090
of services to help enable our customers

16
00:00:34,090 --> 00:00:36,450
to overcome their security, compliance,

17
00:00:36,478 --> 00:00:37,770
and privacy challenges.

18
00:00:39,069 --> 00:00:41,118
Thank you. All right, so thanks

19
00:00:41,118 --> 00:00:43,168
for being here. Um, so I've been working in

20
00:00:43,168 --> 00:00:45,429
regulated industries for, for many years now,

21
00:00:45,810 --> 00:00:48,009
and with AI fundamental need

22
00:00:48,009 --> 00:00:48,658
for data

23
00:00:48,929 --> 00:00:50,158
and growing regulation,

24
00:00:50,728 --> 00:00:52,770
protecting that data is more critical than ever.

25
00:00:53,289 --> 00:00:55,368
Uh, Both JD and I work with

26
00:00:55,368 --> 00:00:57,658
customers like you, regulated customers, exactly

27
00:00:57,658 --> 00:00:59,168
on that topic to help you

28
00:00:59,429 --> 00:01:01,478
adopt and leverage the cloud. And today we want to

29
00:01:01,478 --> 00:01:03,490
tell you about our experience doing exactly

30
00:01:03,490 --> 00:01:05,588
this. We want to give you

31
00:01:05,588 --> 00:01:07,650
essential building blocks for you to protect

32
00:01:07,650 --> 00:01:09,379
this data with confidence.

33
00:01:10,109 --> 00:01:12,459
And so by the end of this talk, we

34
00:01:12,459 --> 00:01:14,549
want you to understand what these building blocks

35
00:01:14,549 --> 00:01:16,609
are and how you can get started.

36
00:01:18,028 --> 00:01:20,430
Now, this is a level 300

37
00:01:20,430 --> 00:01:22,459
session, and we're assuming that you're

38
00:01:22,459 --> 00:01:23,709
familiar with some of

39
00:01:24,028 --> 00:01:25,879
Aba's core services across compute,

40
00:01:26,269 --> 00:01:27,808
database, and storage.

41
00:01:28,168 --> 00:01:30,308
Uh, you also know uh key management services,

42
00:01:30,418 --> 00:01:32,260
encryption address and in transit. Now,

43
00:01:32,709 --> 00:01:34,930
if you don't feel comfortable with this, don't worry,

44
00:01:35,109 --> 00:01:36,088
we'll get you covered.

45
00:01:36,388 --> 00:01:37,668
Uh, we'll go through the basics.

46
00:01:38,849 --> 00:01:40,900
And the most important is that you're

47
00:01:40,900 --> 00:01:41,430
building systems.

48
00:01:44,079 --> 00:01:45,939
So today we cover the following.

49
00:01:46,799 --> 00:01:49,000
We want to double down on the urgency of

50
00:01:49,000 --> 00:01:49,980
data privacy

51
00:01:50,469 --> 00:01:51,620
in today's landscape,

52
00:01:52,198 --> 00:01:54,418
and we'll establish our mental model

53
00:01:54,418 --> 00:01:56,439
for for AI and machine learning

54
00:01:56,439 --> 00:01:58,510
for this talk, as well as the reference scenario

55
00:01:58,510 --> 00:01:59,400
that we are going to use.

56
00:01:59,838 --> 00:02:01,879
Then we'll dive into the building

57
00:02:01,879 --> 00:02:02,418
blocks,

58
00:02:02,719 --> 00:02:04,739
and we'll close with Outlook

59
00:02:04,739 --> 00:02:06,480
and the next steps. So let's get started.

60
00:02:07,829 --> 00:02:09,219
Quick show of hands,

61
00:02:09,508 --> 00:02:11,588
who today here is working in one

62
00:02:11,588 --> 00:02:13,288
of these regulated industries?

63
00:02:14,838 --> 00:02:16,258
All right. Me too.

64
00:02:17,099 --> 00:02:19,610
So you're you're familiar

65
00:02:19,610 --> 00:02:21,538
with the growing regulation, right?

66
00:02:21,979 --> 00:02:24,179
Today, if you're handling regulated

67
00:02:24,179 --> 00:02:26,179
workloads, you have to account

68
00:02:26,179 --> 00:02:27,490
for cybersecurity,

69
00:02:27,860 --> 00:02:28,770
data protection,

70
00:02:29,139 --> 00:02:30,479
business continuity,

71
00:02:30,778 --> 00:02:31,879
and more recently,

72
00:02:32,179 --> 00:02:33,580
AI system regulation.

73
00:02:34,379 --> 00:02:36,618
Now AI systems regulation

74
00:02:36,618 --> 00:02:37,319
is a

75
00:02:37,580 --> 00:02:40,099
fast evolving and complex landscape

76
00:02:40,099 --> 00:02:40,778
to navigate.

77
00:02:41,099 --> 00:02:42,439
It's also super broad.

78
00:02:43,020 --> 00:02:45,599
It extends beyond cybersecurity

79
00:02:45,849 --> 00:02:47,360
into many topics that would each

80
00:02:48,008 --> 00:02:49,338
benefit from a full session.

81
00:02:50,399 --> 00:02:52,520
Now today we want to address

82
00:02:52,520 --> 00:02:54,159
data privacy and data protection.

83
00:02:54,719 --> 00:02:57,389
That's because these topics have emerged

84
00:02:57,389 --> 00:03:00,240
as a central focus. We see convergence

85
00:03:00,240 --> 00:03:01,338
across industries

86
00:03:03,000 --> 00:03:05,659
with data protection, data privacy, cybersecurity,

87
00:03:06,520 --> 00:03:09,179
merging into unified compliance requirements

88
00:03:10,000 --> 00:03:12,129
towards three core capabilities,

89
00:03:12,439 --> 00:03:14,038
essentially visibility.

90
00:03:15,058 --> 00:03:17,139
Secure access and control over your data.

91
00:03:18,580 --> 00:03:19,159
Now

92
00:03:19,740 --> 00:03:21,819
when you handle regulated

93
00:03:21,819 --> 00:03:22,368
data,

94
00:03:22,819 --> 00:03:24,520
assurance is mandatory.

95
00:03:24,979 --> 00:03:27,500
You have governance frameworks and

96
00:03:27,500 --> 00:03:28,960
accountability mechanisms

97
00:03:29,258 --> 00:03:31,659
that require you to have verifiable

98
00:03:31,659 --> 00:03:32,479
evidence

99
00:03:32,819 --> 00:03:34,889
that your data controls

100
00:03:34,899 --> 00:03:37,129
work as intended, and at AWS

101
00:03:37,129 --> 00:03:37,919
what we want.

102
00:03:38,479 --> 00:03:40,788
is to give you the tool and compliance

103
00:03:40,788 --> 00:03:42,879
certifications so that

104
00:03:42,879 --> 00:03:44,800
you have the delivery assurance

105
00:03:45,288 --> 00:03:46,020
so that

106
00:03:46,520 --> 00:03:47,219
you can meet

107
00:03:47,719 --> 00:03:49,758
your compliance requirements and at the same

108
00:03:49,758 --> 00:03:52,360
time benefit from the agility

109
00:03:52,360 --> 00:03:53,758
and innovation of the cloud.

110
00:03:55,889 --> 00:03:58,020
So the slide behind me, the picture is the

111
00:03:58,020 --> 00:04:00,189
well-known shared responsibility model.

112
00:04:00,580 --> 00:04:02,610
We take care of security of the cloud and you

113
00:04:02,610 --> 00:04:04,159
take care of the security in the cloud.

114
00:04:04,889 --> 00:04:05,419
And

115
00:04:05,860 --> 00:04:08,050
that is one, I mean for for this presentation,

116
00:04:08,058 --> 00:04:10,058
we have two tenets. The first one

117
00:04:10,058 --> 00:04:12,139
is we want

118
00:04:12,139 --> 00:04:13,800
to give you building blocks

119
00:04:14,058 --> 00:04:15,558
that provide you assurance,

120
00:04:16,059 --> 00:04:17,278
controls with assurance,

121
00:04:17,660 --> 00:04:18,480
and

122
00:04:19,100 --> 00:04:21,238
building blocks that provide you with verifiable evidence.

123
00:04:21,298 --> 00:04:23,338
So how are we doing this on our side of the

124
00:04:23,338 --> 00:04:24,899
shared responsibility model? Well,

125
00:04:26,649 --> 00:04:29,369
We provide you with contractual commitments,

126
00:04:29,939 --> 00:04:32,000
for example, customer agreement and data processing

127
00:04:32,000 --> 00:04:34,220
addendum. We have more than 140

128
00:04:35,178 --> 00:04:37,220
security certifications and compliance statements,

129
00:04:37,449 --> 00:04:39,108
and we have third party audits.

130
00:04:39,379 --> 00:04:41,559
Now on your side of that

131
00:04:42,678 --> 00:04:43,250
of that model.

132
00:04:43,579 --> 00:04:45,980
I'm sure you can find similar statements

133
00:04:45,980 --> 00:04:46,649
for your vendors.

134
00:04:47,100 --> 00:04:49,100
What we see across our

135
00:04:49,100 --> 00:04:51,199
customers, regulated customers, is very often

136
00:04:51,199 --> 00:04:53,000
for AI that you are using

137
00:04:53,459 --> 00:04:55,459
open source frameworks because they provide you

138
00:04:55,459 --> 00:04:57,579
with complete control and visibility

139
00:04:57,579 --> 00:04:59,259
into how your data is being processed.

140
00:05:01,579 --> 00:05:03,809
Um Now another topic,

141
00:05:04,588 --> 00:05:06,108
this is the AIML spectrum.

142
00:05:06,509 --> 00:05:08,629
There's, there's a broad spectrum, right?

143
00:05:09,509 --> 00:05:10,720
Some of you are using

144
00:05:10,988 --> 00:05:13,069
statistical models with just a few thousands,

145
00:05:13,350 --> 00:05:15,350
just a few 1000 parameters, all the

146
00:05:15,350 --> 00:05:17,379
way to foundation models that have billions

147
00:05:17,379 --> 00:05:18,298
of parameters.

148
00:05:18,588 --> 00:05:20,899
Now, not everyone here is using foundation

149
00:05:20,899 --> 00:05:23,230
models. You might also not be using deep

150
00:05:23,230 --> 00:05:24,009
learning, right?

151
00:05:24,470 --> 00:05:26,069
But you're all using data.

152
00:05:27,048 --> 00:05:29,199
And that's our second tenet.

153
00:05:29,600 --> 00:05:31,678
We want the building blocks that we provide you

154
00:05:31,678 --> 00:05:33,338
today to be broadly applicable

155
00:05:33,639 --> 00:05:35,119
in any of these situations.

156
00:05:37,928 --> 00:05:41,449
And That's

157
00:05:41,449 --> 00:05:43,569
our mental model for today

158
00:05:43,850 --> 00:05:45,928
is basically AI and ML

159
00:05:45,928 --> 00:05:48,048
systems have two core processes, training

160
00:05:48,048 --> 00:05:48,738
and inference,

161
00:05:49,129 --> 00:05:51,209
right? So during training, you have your training

162
00:05:51,209 --> 00:05:53,329
data flows through your training processes

163
00:05:53,329 --> 00:05:54,309
with code that you have written

164
00:05:54,649 --> 00:05:56,750
and gives you a model, right, that you know.

165
00:05:57,088 --> 00:05:59,088
Now during inference, you take this model, you take

166
00:05:59,088 --> 00:06:01,170
new data, it flows through the inference process, and

167
00:06:01,170 --> 00:06:02,009
you get an output.

168
00:06:03,540 --> 00:06:05,540
Now the bottom line here is that for a regulated

169
00:06:05,540 --> 00:06:07,869
environment, what we see is that every component

170
00:06:08,230 --> 00:06:10,209
represents potential sensitive data.

171
00:06:10,548 --> 00:06:12,709
Your training data sets, it can be your code

172
00:06:12,709 --> 00:06:14,709
for training, it can be your model wave, it

173
00:06:14,709 --> 00:06:16,730
can be inference prompts or the outputs,

174
00:06:16,939 --> 00:06:19,069
and depending on your regulatory

175
00:06:19,069 --> 00:06:19,809
requirements

176
00:06:20,428 --> 00:06:21,269
or threat model,

177
00:06:21,709 --> 00:06:23,778
each data type might require protections and

178
00:06:23,778 --> 00:06:24,910
appropriate controls.

179
00:06:26,639 --> 00:06:28,028
I also want to call out or

180
00:06:28,769 --> 00:06:30,970
make a link to the well-known generative AI

181
00:06:30,970 --> 00:06:32,209
security scoping matrix.

182
00:06:33,290 --> 00:06:35,379
This matrix maps 5 implementation

183
00:06:35,379 --> 00:06:37,379
patterns from consumer apps, for

184
00:06:37,379 --> 00:06:39,379
example, like Cloud all the way to enterprise solutions

185
00:06:39,379 --> 00:06:40,269
like Amazon Quick Suite,

186
00:06:40,660 --> 00:06:42,959
and as you move from scope 1

187
00:06:43,059 --> 00:06:43,769
to 5,

188
00:06:44,059 --> 00:06:46,338
you gain increasing control over training

189
00:06:46,338 --> 00:06:48,298
and inference model and data.

190
00:06:48,939 --> 00:06:51,040
And basically at scope 1, the provider

191
00:06:51,040 --> 00:06:53,259
has to handle security. At scope 5, you

192
00:06:53,259 --> 00:06:55,420
own it end to end, so all of it.

193
00:06:56,889 --> 00:06:57,459
OK,

194
00:06:57,759 --> 00:06:59,778
um. Now last slide before

195
00:06:59,778 --> 00:07:01,220
we move into the first building block,

196
00:07:01,540 --> 00:07:04,019
we'll consider 3 types of scenarios

197
00:07:04,019 --> 00:07:06,358
for today. The first one is

198
00:07:06,358 --> 00:07:08,778
our scenarios where you're using Amazon EC2

199
00:07:08,778 --> 00:07:09,540
instances.

200
00:07:10,439 --> 00:07:11,889
Directly or maybe with IKS

201
00:07:13,009 --> 00:07:15,119
for training or for inference in that

202
00:07:15,119 --> 00:07:17,369
scenario you maintain control over the compute

203
00:07:17,369 --> 00:07:19,189
layer. The second scenario

204
00:07:19,488 --> 00:07:21,528
shows serverless inference here with

205
00:07:21,528 --> 00:07:23,689
lambda with minimal infrastructure

206
00:07:23,689 --> 00:07:26,139
management. And the third scenario

207
00:07:26,139 --> 00:07:28,459
that you can consider is one where you're using

208
00:07:29,278 --> 00:07:31,278
you leverage managed AI services, for

209
00:07:31,278 --> 00:07:33,678
example, Bedrock for Foundation model inference or Sagemaker

210
00:07:33,678 --> 00:07:35,379
AI for ML workflow.

211
00:07:36,319 --> 00:07:38,480
All of these scenarios, they can leverage various

212
00:07:38,480 --> 00:07:40,480
storage and database solutions

213
00:07:40,480 --> 00:07:41,920
to provide persistent storage.

214
00:07:42,319 --> 00:07:44,660
And so for each scenario we want to discuss

215
00:07:45,149 --> 00:07:47,399
controls with assurance that apply broadly

216
00:07:47,399 --> 00:07:48,559
regardless of your deployment.

217
00:07:49,699 --> 00:07:51,988
So let's move into our very first building

218
00:07:51,988 --> 00:07:54,170
block, which is none other

219
00:07:54,170 --> 00:07:55,189
than encryption.

220
00:07:57,389 --> 00:07:58,329
Alright, um,

221
00:07:58,838 --> 00:08:01,220
so AWSS key Management Service, KMS

222
00:08:01,519 --> 00:08:03,639
is your central encryption control

223
00:08:03,639 --> 00:08:05,619
plane. It handles

224
00:08:05,980 --> 00:08:08,040
authentication, authorization, and

225
00:08:08,040 --> 00:08:08,660
logging.

226
00:08:09,399 --> 00:08:11,559
Now, from an architecture point of view, the most

227
00:08:11,559 --> 00:08:13,838
important decision that you have to take is

228
00:08:14,079 --> 00:08:15,579
how do you store the keys,

229
00:08:15,920 --> 00:08:16,838
and you have options.

230
00:08:17,528 --> 00:08:20,160
Um With native KMS

231
00:08:20,160 --> 00:08:22,428
you have access to a fleet of shared

232
00:08:22,428 --> 00:08:24,678
HS that are PIPS 140-3

233
00:08:24,678 --> 00:08:25,750
Level 3 compliant.

234
00:08:26,069 --> 00:08:28,369
That's the most reasonable option for

235
00:08:28,629 --> 00:08:29,750
most of the use cases.

236
00:08:30,588 --> 00:08:32,759
The second option is using cloud HSM.

237
00:08:33,200 --> 00:08:35,639
It provides dedicated HSM

238
00:08:35,639 --> 00:08:37,840
for regulated scenarios when your regulation

239
00:08:37,840 --> 00:08:38,500
requires it.

240
00:08:39,038 --> 00:08:41,239
The third scenario that you can use is external

241
00:08:41,239 --> 00:08:43,259
key store, where the keys are being

242
00:08:43,259 --> 00:08:45,719
stored on premises at the expense

243
00:08:45,719 --> 00:08:48,119
of possibly additional latency,

244
00:08:48,529 --> 00:08:50,619
as well as a dependency to your

245
00:08:50,619 --> 00:08:51,440
infrastructure.

246
00:08:52,048 --> 00:08:54,129
And finally, you can also decide to import

247
00:08:54,129 --> 00:08:55,710
external key material

248
00:08:56,038 --> 00:08:57,969
so that you have cryptographic proof of origin.

249
00:09:00,190 --> 00:09:02,190
So there's a spectrum again. As you move

250
00:09:02,190 --> 00:09:04,428
up, you have greater control, but this

251
00:09:04,428 --> 00:09:06,649
comes at the expense of possibly

252
00:09:06,649 --> 00:09:08,989
latency and higher operational overhead.

253
00:09:09,690 --> 00:09:11,729
And basically as you move down you have access to a

254
00:09:11,729 --> 00:09:13,349
managed service that gives you the best.

255
00:09:14,139 --> 00:09:15,529
The best performance

256
00:09:16,149 --> 00:09:17,090
and availability

257
00:09:18,029 --> 00:09:20,119
now. You

258
00:09:20,119 --> 00:09:21,599
can I mean,

259
00:09:22,950 --> 00:09:23,479
Um

260
00:09:24,639 --> 00:09:27,080
And what I wanted to say was that the scenario

261
00:09:27,080 --> 00:09:29,119
that you decide to use pretty much

262
00:09:29,119 --> 00:09:31,158
depends on your compliance and security

263
00:09:31,158 --> 00:09:33,239
requirements, right? You can mix and match. You can

264
00:09:33,239 --> 00:09:35,759
use one or multiple scenarios depending on the workload.

265
00:09:38,950 --> 00:09:40,950
Now the most important thing about KMS in

266
00:09:40,950 --> 00:09:43,070
that context is that keys

267
00:09:43,080 --> 00:09:45,219
never leave KMS unencrypted,

268
00:09:45,759 --> 00:09:48,918
and KMS provides four core cryptographic

269
00:09:48,918 --> 00:09:51,000
operations. The one I want to call out here because we're going to

270
00:09:51,000 --> 00:09:53,090
talk about it later in this presentation,

271
00:09:53,678 --> 00:09:55,840
is the generation and export of

272
00:09:55,840 --> 00:09:56,558
data keys.

273
00:09:57,558 --> 00:09:59,969
KMS integrates with more than 100

274
00:09:59,969 --> 00:10:00,719
services.

275
00:10:01,158 --> 00:10:03,330
And for services like Amazon

276
00:10:03,330 --> 00:10:05,759
S3 or DynamoDB, it's using envelope encryption,

277
00:10:05,808 --> 00:10:07,808
and we'll talk about this later. That's a pattern

278
00:10:07,808 --> 00:10:09,889
we're going to use and reuse throughout the

279
00:10:09,889 --> 00:10:10,599
presentation,

280
00:10:10,889 --> 00:10:13,229
and everything is monitored through CloudWatch

281
00:10:13,639 --> 00:10:14,168
and Cloud 3.

282
00:10:17,058 --> 00:10:19,389
Now let's recap encryption

283
00:10:19,389 --> 00:10:20,090
at rest.

284
00:10:21,048 --> 00:10:23,029
At AWS we provide

285
00:10:23,369 --> 00:10:26,129
3 approaches that allow you to balance

286
00:10:26,129 --> 00:10:28,308
control with operational simplicity.

287
00:10:28,849 --> 00:10:31,619
With client-side encryption, you encrypt

288
00:10:31,849 --> 00:10:32,629
your data

289
00:10:33,009 --> 00:10:35,119
before it reaches AWS, and for this,

290
00:10:35,330 --> 00:10:37,408
you can use SDKs or client-specific

291
00:10:37,408 --> 00:10:38,048
services.

292
00:10:39,149 --> 00:10:41,200
The second option is using customer

293
00:10:41,200 --> 00:10:42,340
manage key in Abase.

294
00:10:43,558 --> 00:10:45,960
This gives you control over the key policy.

295
00:10:46,889 --> 00:10:49,168
As well as the entire life cycle

296
00:10:49,168 --> 00:10:51,229
of the key and in particular in regulated

297
00:10:51,229 --> 00:10:53,210
environments you control the rotation.

298
00:10:54,058 --> 00:10:56,139
This can be mandatory depending on your

299
00:10:56,139 --> 00:10:57,259
compliance requirements.

300
00:10:58,269 --> 00:10:59,869
And the last option is

301
00:11:00,149 --> 00:11:02,149
the use of AWS own keys to provide

302
00:11:02,149 --> 00:11:04,349
transparent encryption for many AWS

303
00:11:04,349 --> 00:11:05,000
services,

304
00:11:05,739 --> 00:11:07,889
automatic rotation, and no charges for storage and

305
00:11:07,889 --> 00:11:08,808
users. And again,

306
00:11:09,229 --> 00:11:11,418
the choice pretty much depends on your

307
00:11:11,418 --> 00:11:12,700
compliance requirements, OK?

308
00:11:13,308 --> 00:11:15,570
And you can use a customer managed key to

309
00:11:15,570 --> 00:11:18,009
provide to protect many machine learning assets

310
00:11:18,229 --> 00:11:20,330
with with these keys. It can be

311
00:11:20,340 --> 00:11:22,340
bedrock custom models. It can be

312
00:11:22,340 --> 00:11:23,200
an agent session,

313
00:11:23,950 --> 00:11:26,658
data or model artifacts

314
00:11:26,658 --> 00:11:27,389
in S3.

315
00:11:28,599 --> 00:11:30,428
Now let's recap encryption in transit

316
00:11:30,769 --> 00:11:32,479
again. We have multiple options,

317
00:11:32,808 --> 00:11:35,029
so you can also use client-side encryption.

318
00:11:35,590 --> 00:11:37,960
Now of course, here you have to decrypt the data

319
00:11:37,960 --> 00:11:40,048
before you can process it. The interesting thing

320
00:11:40,048 --> 00:11:42,649
is that you can use the isolation properties of

321
00:11:42,649 --> 00:11:44,649
EC2 instances or lambda in order

322
00:11:44,649 --> 00:11:45,349
to do this.

323
00:11:46,308 --> 00:11:48,509
Um At the

324
00:11:48,509 --> 00:11:49,109
application layer,

325
00:11:49,399 --> 00:11:51,538
we provide you with TLS 1.2,

326
00:11:52,330 --> 00:11:54,359
NO 1.3 with perfect forward

327
00:11:54,359 --> 00:11:55,139
secrecy.

328
00:11:55,928 --> 00:11:57,639
Uh, this is protecting um

329
00:11:57,918 --> 00:12:00,119
services, for example, for Bedrock or Sedgem

330
00:12:00,119 --> 00:12:01,918
AI and all control plane API.

331
00:12:03,719 --> 00:12:04,808
At the VPC layer.

332
00:12:05,808 --> 00:12:08,090
Between compatible instances

333
00:12:08,090 --> 00:12:10,109
you benefit from automatic encryption

334
00:12:10,109 --> 00:12:12,259
that is taken taken care of by the

335
00:12:12,259 --> 00:12:12,940
Nitro system.

336
00:12:13,590 --> 00:12:16,029
And in addition, in regulated context,

337
00:12:16,190 --> 00:12:18,428
we recently released VPC encryption

338
00:12:18,428 --> 00:12:20,928
control that provides centralized

339
00:12:21,548 --> 00:12:23,808
encryption visibility and enforcement

340
00:12:24,349 --> 00:12:26,389
for all traffic within and across

341
00:12:26,389 --> 00:12:27,129
the VPC.

342
00:12:27,389 --> 00:12:29,548
And again, this is useful

343
00:12:29,548 --> 00:12:31,629
in regulatory context because that might be a

344
00:12:31,629 --> 00:12:32,149
requirement.

345
00:12:32,509 --> 00:12:34,408
Finally, at the physical layer,

346
00:12:35,149 --> 00:12:37,349
we encrypt all traffic at

347
00:12:37,349 --> 00:12:38,369
region boundaries

348
00:12:38,710 --> 00:12:39,788
over our backbone.

349
00:12:40,308 --> 00:12:42,349
As well as between availability

350
00:12:42,349 --> 00:12:44,349
zones and over peering connection, either with

351
00:12:44,349 --> 00:12:46,288
VPC peering or transit gateway.

352
00:12:47,029 --> 00:12:47,729
So together,

353
00:12:48,229 --> 00:12:50,570
all these layers, they create really defense

354
00:12:50,570 --> 00:12:52,710
in depth protection for all of your AIMI

355
00:12:52,710 --> 00:12:53,269
workloads.

356
00:12:55,940 --> 00:12:58,178
One thing I want to call out is a specific use

357
00:12:58,178 --> 00:13:00,418
case, which is for distributed

358
00:13:00,418 --> 00:13:01,489
AI training.

359
00:13:02,538 --> 00:13:04,979
I want to call out Elastic Fabric Adapter, EFA

360
00:13:04,979 --> 00:13:05,700
very briefly.

361
00:13:06,349 --> 00:13:08,580
EFA delivers always encrypted

362
00:13:08,580 --> 00:13:10,019
high performance networking.

363
00:13:10,969 --> 00:13:13,099
It provides hardware accelerated encryption. It takes

364
00:13:13,099 --> 00:13:14,509
advantage of the natural system again.

365
00:13:16,099 --> 00:13:18,139
With no performance penalty, and basically it

366
00:13:18,139 --> 00:13:20,298
gives you GPU direct RDMA

367
00:13:20,298 --> 00:13:22,379
access and up to 3 or 2 terabits per

368
00:13:22,379 --> 00:13:23,359
second of throughput,

369
00:13:23,658 --> 00:13:25,940
and it's really here to enable distributed

370
00:13:25,940 --> 00:13:28,019
AI training at scale without compromising

371
00:13:28,019 --> 00:13:30,129
security. Now

372
00:13:30,129 --> 00:13:32,288
let's try to put that together on a high level

373
00:13:32,288 --> 00:13:33,269
architecture slide.

374
00:13:34,849 --> 00:13:37,379
So at Tres we really want you to use encryption.

375
00:13:38,590 --> 00:13:39,369
We provide

376
00:13:39,629 --> 00:13:41,629
all these options to protect data

377
00:13:41,629 --> 00:13:43,710
across the cloud and on premises

378
00:13:43,710 --> 00:13:44,969
in both directions.

379
00:13:45,658 --> 00:13:46,570
So for example,

380
00:13:46,899 --> 00:13:49,298
here, TLS is going to safeguard

381
00:13:49,298 --> 00:13:51,298
data flowing both ways, training data

382
00:13:51,298 --> 00:13:53,080
imported from your premises,

383
00:13:53,349 --> 00:13:55,269
or from Adores storage services,

384
00:13:55,859 --> 00:13:57,859
all the way into ADres compute services.

385
00:13:57,940 --> 00:13:59,219
This can be EC2

386
00:14:00,190 --> 00:14:00,739
or Lambda.

387
00:14:01,788 --> 00:14:03,820
And it also controls all

388
00:14:03,820 --> 00:14:04,940
control plane API.

389
00:14:05,908 --> 00:14:07,779
I also want to mention Direct Connect

390
00:14:08,200 --> 00:14:10,509
because it uses Maxse at interconnect point,

391
00:14:10,960 --> 00:14:11,950
and you can use

392
00:14:12,519 --> 00:14:14,558
S2S VPN as well on top if you want

393
00:14:14,558 --> 00:14:16,599
to. Within the VPC, we

394
00:14:16,599 --> 00:14:18,840
talked about the nitro system that provides encryption

395
00:14:18,840 --> 00:14:20,928
for training workloads between compatibility EC2

396
00:14:20,928 --> 00:14:21,479
instances.

397
00:14:22,200 --> 00:14:24,399
And of course each storage services

398
00:14:24,399 --> 00:14:25,519
is using encryption at rest,

399
00:14:26,599 --> 00:14:28,639
using envelope encryption with

400
00:14:28,639 --> 00:14:30,058
KMS managed keys that

401
00:14:30,389 --> 00:14:31,899
you can control.

402
00:14:32,239 --> 00:14:34,298
So essentially you maintain control

403
00:14:34,298 --> 00:14:35,219
through your customer

404
00:14:35,798 --> 00:14:37,808
managed keys while we handle

405
00:14:38,190 --> 00:14:39,080
the actual encryption.

406
00:14:42,109 --> 00:14:44,279
Now I want to talk briefly about

407
00:14:44,279 --> 00:14:46,399
envelope encryption because then I want to talk about

408
00:14:46,399 --> 00:14:47,460
client-side encryption.

409
00:14:48,918 --> 00:14:51,009
So envelope encryption implements a

410
00:14:51,009 --> 00:14:53,928
two-tier cryptographic hierarchy where

411
00:14:53,928 --> 00:14:55,969
AWSKMS manages the

412
00:14:55,969 --> 00:14:58,090
master key, while so-called data

413
00:14:58,090 --> 00:15:00,168
keys that you get through generate

414
00:15:00,168 --> 00:15:02,489
data key handle the actual

415
00:15:02,489 --> 00:15:03,489
encryption operation.

416
00:15:04,250 --> 00:15:05,830
So when you call generate data key,

417
00:15:06,149 --> 00:15:08,349
AWSKMS generates a plain text

418
00:15:08,349 --> 00:15:10,408
data key and an encrypted key. You use the

419
00:15:10,408 --> 00:15:12,538
plain text data key to encrypt your data,

420
00:15:12,750 --> 00:15:14,788
and you throw it away. You discard it immediately.

421
00:15:15,489 --> 00:15:17,558
And you store the encrypted version with the

422
00:15:17,558 --> 00:15:19,349
encrypted data that you have.

423
00:15:20,308 --> 00:15:22,548
For decryption, you do the reverse process.

424
00:15:22,788 --> 00:15:24,869
You call in order to decrypt.

425
00:15:25,629 --> 00:15:27,750
The encryption key and then you can decrypt your

426
00:15:27,750 --> 00:15:30,129
data. And this is a stateless architecture.

427
00:15:30,190 --> 00:15:32,190
You don't need to keep state anywhere because you have the

428
00:15:32,190 --> 00:15:34,450
data, you have, you have the encryption key with the data

429
00:15:34,908 --> 00:15:35,590
and

430
00:15:36,070 --> 00:15:38,070
it allows for the encryption of large

431
00:15:38,070 --> 00:15:40,269
data sets, for instance, that

432
00:15:40,269 --> 00:15:42,548
exceed the 4 kilobyte KMS direct encryption

433
00:15:42,548 --> 00:15:43,090
limit,

434
00:15:43,590 --> 00:15:45,590
and it also enables data key

435
00:15:45,590 --> 00:15:48,090
caching to minimize API calls and latency.

436
00:15:48,349 --> 00:15:49,570
That's super important

437
00:15:50,369 --> 00:15:52,710
for large scale AI training and

438
00:15:52,710 --> 00:15:53,590
model artifacts.

439
00:15:55,969 --> 00:15:58,619
So how do you use that in the context of

440
00:15:58,619 --> 00:15:59,739
client-side encryption?

441
00:16:01,399 --> 00:16:03,590
In the context of AIML workloads, well,

442
00:16:04,239 --> 00:16:06,210
a producer can encrypt

443
00:16:06,529 --> 00:16:07,750
training data sets,

444
00:16:08,609 --> 00:16:11,109
model artifacts or inference payloads

445
00:16:11,109 --> 00:16:13,200
on premises or in the cloud using envelope

446
00:16:13,200 --> 00:16:15,288
encryption. Then

447
00:16:15,288 --> 00:16:16,928
it either persists

448
00:16:17,259 --> 00:16:19,969
that ciphertext to S3 or maybe DynamoDB

449
00:16:19,969 --> 00:16:22,408
or can pass it directly to the consumer.

450
00:16:24,960 --> 00:16:26,259
All of the processing,

451
00:16:26,719 --> 00:16:28,759
either the processing of the data or the

452
00:16:28,759 --> 00:16:30,918
encryption or the decryption data, they can

453
00:16:30,918 --> 00:16:33,418
take place across lambda, across EC2,

454
00:16:33,788 --> 00:16:34,979
across on-premises,

455
00:16:35,519 --> 00:16:37,820
and you can even use nitro Enclave in the case of EC2.

456
00:16:38,629 --> 00:16:41,298
Consumers will then retrieve or receive ciphertext,

457
00:16:41,399 --> 00:16:43,529
decrypt with identity and access management

458
00:16:43,529 --> 00:16:45,798
scope permissions, and process the data. That's

459
00:16:45,798 --> 00:16:46,820
an important point, right?

460
00:16:47,239 --> 00:16:49,379
Because you're using key policies, you can precisely

461
00:16:49,379 --> 00:16:51,538
control who is allowed to decrypt the data.

462
00:16:52,509 --> 00:16:53,408
So training data,

463
00:16:53,710 --> 00:16:55,820
model weights, hyperparameters, gradient

464
00:16:55,820 --> 00:16:56,609
checkpoints, whatever,

465
00:16:57,190 --> 00:16:59,389
they can all remain encrypted throughout the

466
00:16:59,389 --> 00:17:00,629
machine learning life cycle.

467
00:17:02,389 --> 00:17:04,420
Now I said we really want you to use

468
00:17:04,420 --> 00:17:06,630
encryption. So we

469
00:17:06,630 --> 00:17:08,670
provide you here 3 options for

470
00:17:08,670 --> 00:17:09,709
client-side encryption.

471
00:17:10,029 --> 00:17:12,068
The first one is the AOS encryption SDK.

472
00:17:12,750 --> 00:17:13,828
This is a

473
00:17:14,469 --> 00:17:16,890
multi, uh, this is a cross-platform

474
00:17:16,890 --> 00:17:17,709
um SDK.

475
00:17:18,680 --> 00:17:21,348
That enables general purpose cryptographic

476
00:17:21,348 --> 00:17:23,410
operation. I often use it in Python or Rust.

477
00:17:24,250 --> 00:17:26,368
Another option is the AWS database

478
00:17:26,368 --> 00:17:27,338
encryption SDK.

479
00:17:28,529 --> 00:17:30,608
It delivers record level encryption

480
00:17:30,608 --> 00:17:32,608
as well as field level signatures that you can

481
00:17:32,608 --> 00:17:34,170
use for data authenticity.

482
00:17:34,959 --> 00:17:35,509
Um

483
00:17:36,358 --> 00:17:38,469
And the last option is the Amazon S3

484
00:17:38,469 --> 00:17:39,578
encryption client.

485
00:17:40,239 --> 00:17:42,939
What's cool about it is that it can automatically

486
00:17:43,160 --> 00:17:45,199
encrypt and decrypt your objects by

487
00:17:45,199 --> 00:17:47,279
intercepting code to put objects

488
00:17:47,279 --> 00:17:49,539
or get objects, so it's completely transparent.

489
00:17:50,750 --> 00:17:52,469
Each of these solutions,

490
00:17:52,759 --> 00:17:55,180
they implement the same envelope encryption primitives

491
00:17:55,479 --> 00:17:58,160
and they optimize for specific use cases

492
00:17:58,160 --> 00:17:58,959
and data schema.

493
00:18:01,559 --> 00:18:03,979
So, let's look at an example.

494
00:18:06,289 --> 00:18:07,949
This Python example

495
00:18:08,250 --> 00:18:10,439
creates first an encryption SDK

496
00:18:10,439 --> 00:18:12,479
client, that's the encryption client on the

497
00:18:12,479 --> 00:18:14,818
slide. Then moves on

498
00:18:14,818 --> 00:18:16,868
to getting a client. That's

499
00:18:16,868 --> 00:18:17,469
what you need.

500
00:18:18,180 --> 00:18:19,900
And basically create a key ring.

501
00:18:20,459 --> 00:18:22,578
Uh, in the context of the query ring, uh, in

502
00:18:22,578 --> 00:18:24,939
the, in the context of the key ring creation.

503
00:18:26,578 --> 00:18:29,170
You can set encryption context metadata

504
00:18:29,588 --> 00:18:30,660
that can be

505
00:18:31,108 --> 00:18:33,390
these are optional non-secret

506
00:18:33,390 --> 00:18:34,368
key value pair

507
00:18:35,150 --> 00:18:36,250
that provides

508
00:18:36,868 --> 00:18:39,140
additional authenticated data for KMS

509
00:18:39,140 --> 00:18:40,750
encryption operation.

510
00:18:41,660 --> 00:18:43,729
And they are bound to the ciphertext, that's

511
00:18:43,729 --> 00:18:46,858
to, for example, prevent ciphertext substitution

512
00:18:46,858 --> 00:18:49,009
attacks. So you can bind

513
00:18:49,009 --> 00:18:51,088
model version or training job ID to

514
00:18:51,088 --> 00:18:53,650
encrypt the training data sets and model artifacts.

515
00:18:54,469 --> 00:18:56,949
Um The encrypt

516
00:18:56,949 --> 00:18:59,000
operation generates unique data keys

517
00:18:59,000 --> 00:19:01,068
per object, and the

518
00:19:01,068 --> 00:19:03,059
decrypt operation is fairly straightforward.

519
00:19:03,479 --> 00:19:04,739
What I'm not showing here

520
00:19:05,078 --> 00:19:07,118
is the use of, for example, data key

521
00:19:07,118 --> 00:19:07,858
caching

522
00:19:08,880 --> 00:19:10,959
that you can control either via amount of

523
00:19:10,959 --> 00:19:13,140
messages, number of bits encrypted, or

524
00:19:13,140 --> 00:19:14,059
age of the key,

525
00:19:14,358 --> 00:19:17,680
and we provide also other options, for example, hierarchical

526
00:19:17,680 --> 00:19:19,799
key rings that can use branch

527
00:19:19,799 --> 00:19:20,759
keys with Dynamo DB.

528
00:19:22,338 --> 00:19:23,328
Sometimes you can't.

529
00:19:24,799 --> 00:19:26,959
Use the encryption SDK, but

530
00:19:26,959 --> 00:19:29,078
nothing prevents you from combining those

531
00:19:29,078 --> 00:19:31,078
best patterns with open source libraries and.

532
00:19:32,759 --> 00:19:34,838
So if we now revisit again our

533
00:19:34,838 --> 00:19:35,598
examples,

534
00:19:36,039 --> 00:19:38,199
client-side encryption provides you another layer

535
00:19:38,199 --> 00:19:40,239
of encryption. So everything you've learned

536
00:19:40,239 --> 00:19:41,670
on the slide before still applies,

537
00:19:41,959 --> 00:19:44,000
encryption and transit and arrest, but you can use

538
00:19:44,000 --> 00:19:45,380
client-side encryption

539
00:19:45,979 --> 00:19:47,729
for additional assurance.

540
00:19:48,920 --> 00:19:50,519
So in the EC2 example,

541
00:19:51,039 --> 00:19:53,390
you can protect data coming in from on-premises

542
00:19:53,390 --> 00:19:55,838
or from storage services, and

543
00:19:55,838 --> 00:19:57,868
again, the advantage here, or one of the

544
00:19:57,868 --> 00:19:59,880
benefits here is that the KMS

545
00:19:59,880 --> 00:20:02,299
key policy gives you gives you precise

546
00:20:02,299 --> 00:20:04,640
control about who is authorized to do the decryption.

547
00:20:07,180 --> 00:20:07,709
All right,

548
00:20:09,358 --> 00:20:09,959
Um,

549
00:20:10,400 --> 00:20:12,489
so, AWS, um.

550
00:20:13,299 --> 00:20:15,539
So database encryption protects data

551
00:20:15,539 --> 00:20:17,559
broadly to secure data,

552
00:20:17,939 --> 00:20:20,039
to secure training data sets, inference data,

553
00:20:20,098 --> 00:20:21,309
and model artifacts.

554
00:20:22,259 --> 00:20:24,539
And the bottom line is that with customer managed keys

555
00:20:24,539 --> 00:20:25,618
you have control.

556
00:20:26,920 --> 00:20:29,209
Our fundamental security principles

557
00:20:29,209 --> 00:20:31,729
are really about making sure that there is no human interactions

558
00:20:31,729 --> 00:20:34,209
with plain text cryptographic key material

559
00:20:34,209 --> 00:20:35,568
across all our services.

560
00:20:38,858 --> 00:20:41,390
I want to now, I want to briefly

561
00:20:41,390 --> 00:20:43,410
discuss a second

562
00:20:44,759 --> 00:20:45,568
short building block.

563
00:20:47,019 --> 00:20:48,328
Which is tokenization.

564
00:20:48,779 --> 00:20:51,299
Tokenization can complement encryption.

565
00:20:51,640 --> 00:20:53,959
Basically what tokenization allows you to do

566
00:20:54,338 --> 00:20:56,199
is to reduce compliance scope

567
00:20:56,608 --> 00:20:57,598
by simply

568
00:20:58,219 --> 00:21:00,939
removing or replacing sensitive

569
00:21:00,939 --> 00:21:02,180
data from your data set.

570
00:21:04,348 --> 00:21:05,660
In the example here,

571
00:21:06,279 --> 00:21:07,410
we have, for example,

572
00:21:07,838 --> 00:21:09,019
credit card numbers

573
00:21:09,439 --> 00:21:11,479
or an email address, and these are

574
00:21:11,479 --> 00:21:12,848
being replaced by tokens.

575
00:21:13,189 --> 00:21:15,358
Tokens can be randomly or pseudo

576
00:21:15,358 --> 00:21:16,479
randomly generated.

577
00:21:18,430 --> 00:21:19,809
The tokens

578
00:21:20,130 --> 00:21:22,250
or the key value pair, the token as

579
00:21:22,250 --> 00:21:24,689
well as the original mapping, are being stored

580
00:21:24,689 --> 00:21:26,189
in what's called a token vault.

581
00:21:26,959 --> 00:21:29,088
The point here of having a token vote is

582
00:21:29,088 --> 00:21:31,348
that it's also a central point of control

583
00:21:31,689 --> 00:21:33,828
for who has the authorization.

584
00:21:34,640 --> 00:21:36,650
To recover the original mapping

585
00:21:36,650 --> 00:21:38,449
between sensitive data and the actual token.

586
00:21:43,299 --> 00:21:45,949
All right, so let us look at the high-level architecture.

587
00:21:46,299 --> 00:21:48,338
This diagram shows you one

588
00:21:48,338 --> 00:21:49,598
potential implementation,

589
00:21:49,868 --> 00:21:51,959
um, using a server-less approach

590
00:21:52,739 --> 00:21:53,880
with AWS lambda.

591
00:21:54,299 --> 00:21:56,380
So you see here, one lambda function

592
00:21:56,380 --> 00:21:58,459
that takes care of the tokenization

593
00:21:58,459 --> 00:21:59,500
process, right?

594
00:22:00,229 --> 00:22:02,439
And you see another lambda function that is

595
00:22:02,439 --> 00:22:03,739
implementing

596
00:22:04,479 --> 00:22:06,799
the business logic for the actual tokenization

597
00:22:06,799 --> 00:22:08,559
via some cryptographic operation.

598
00:22:09,500 --> 00:22:11,239
You can also see that we're using

599
00:22:11,719 --> 00:22:13,858
the pattern, the client-side encryption pattern, so

600
00:22:13,858 --> 00:22:16,019
on top of encryption address and in transit

601
00:22:16,019 --> 00:22:16,890
we're adding another.

602
00:22:18,368 --> 00:22:20,400
A layer of protection with client-side

603
00:22:20,400 --> 00:22:22,588
encryption using the Edobase

604
00:22:22,588 --> 00:22:23,489
database encryption.

605
00:22:26,180 --> 00:22:26,739
Again,

606
00:22:27,059 --> 00:22:29,140
keep in mind that tokenization will reduce

607
00:22:29,140 --> 00:22:31,140
compliance scope by removing sensitive

608
00:22:31,140 --> 00:22:33,219
data from your system. With that,

609
00:22:33,299 --> 00:22:35,539
we're moving to our 3rd building blocks, and I will let

610
00:22:35,539 --> 00:22:36,559
JD come on stage.

611
00:22:40,199 --> 00:22:42,598
Thanks Reuben. So

612
00:22:43,140 --> 00:22:45,259
we've talked a little bit about encryption in

613
00:22:45,259 --> 00:22:47,338
transit, we've spoken a little bit about

614
00:22:47,338 --> 00:22:49,299
encryption at rest,

615
00:22:49,699 --> 00:22:51,279
and now we move on to

616
00:22:51,900 --> 00:22:53,939
perhaps an area that is a little bit

617
00:22:53,939 --> 00:22:56,420
more on the frontiers, a little bit more

618
00:22:56,420 --> 00:22:58,420
present in the dialogue

619
00:22:58,420 --> 00:23:00,420
of the last say 5

620
00:23:00,420 --> 00:23:02,420
years or so than it was previous to

621
00:23:02,420 --> 00:23:04,459
that, which is the concept of protecting

622
00:23:04,459 --> 00:23:05,039
data

623
00:23:05,818 --> 00:23:08,000
while it is in use.

624
00:23:09,939 --> 00:23:10,858
Before I move forward,

625
00:23:11,269 --> 00:23:13,509
we'll, we'll speak about a few ways of

626
00:23:13,509 --> 00:23:15,209
approaching this problem.

627
00:23:15,509 --> 00:23:17,709
The area that I'm going to focus on is

628
00:23:17,709 --> 00:23:19,739
called confidential computing. Can I

629
00:23:19,739 --> 00:23:21,750
see a quick show of hands about who may have heard

630
00:23:21,750 --> 00:23:23,170
of that concept before?

631
00:23:24,068 --> 00:23:25,078
OK, we have a few,

632
00:23:25,578 --> 00:23:27,640
so I'll define it briefly for you now, which is

633
00:23:27,640 --> 00:23:29,759
we really define confidential computing as

634
00:23:29,759 --> 00:23:32,279
the act of trying to uh

635
00:23:32,279 --> 00:23:34,618
protect sensitive uh data

636
00:23:34,618 --> 00:23:36,880
or code from any external

637
00:23:36,880 --> 00:23:39,118
unauthorized access through the use of special

638
00:23:39,118 --> 00:23:40,239
purpose hardware,

639
00:23:40,598 --> 00:23:42,699
firmware, and associated software.

640
00:23:45,250 --> 00:23:47,608
At AWS, the primary confidential

641
00:23:47,608 --> 00:23:49,229
computing technology we offer

642
00:23:49,650 --> 00:23:51,500
is known as the AWS Nitro System.

643
00:23:52,549 --> 00:23:54,900
Uh, the Abus nitro system is,

644
00:23:55,019 --> 00:23:57,299
uh, really fundamentally the underlying,

645
00:23:57,430 --> 00:23:59,979
uh, technology that powers, uh, every

646
00:23:59,979 --> 00:24:02,150
single virtualized EC2

647
00:24:02,150 --> 00:24:03,410
instance that we have released

648
00:24:03,670 --> 00:24:05,660
since 2018 and on.

649
00:24:06,068 --> 00:24:08,309
Uh, this was the process of many, many years of

650
00:24:08,309 --> 00:24:10,390
development beginning in 2012 and

651
00:24:10,390 --> 00:24:12,539
culminating in the official unveiling

652
00:24:12,539 --> 00:24:14,568
and release to, to the world of

653
00:24:14,699 --> 00:24:17,269
the nitro system in November of 2017

654
00:24:17,509 --> 00:24:18,259
here at RIM.

655
00:24:19,489 --> 00:24:21,000
Uh, it consists of

656
00:24:21,578 --> 00:24:23,779
a collection of special purpose hardware devices

657
00:24:23,779 --> 00:24:25,559
as well as a custom hypervisor

658
00:24:25,818 --> 00:24:27,039
built for AWS

659
00:24:27,338 --> 00:24:29,410
and now 6 generations, uh, we're now

660
00:24:29,410 --> 00:24:31,420
on our 6th generation of custom chips

661
00:24:31,420 --> 00:24:32,400
that powers the system.

662
00:24:34,568 --> 00:24:36,880
What this enables us to offer to our customers

663
00:24:37,009 --> 00:24:39,049
is something that is pretty much

664
00:24:39,049 --> 00:24:40,309
unheard of in the industry.

665
00:24:40,689 --> 00:24:42,509
We offer always on

666
00:24:42,769 --> 00:24:45,410
confidential computing to each and every

667
00:24:45,410 --> 00:24:47,489
user of any EC2 instance that's

668
00:24:47,489 --> 00:24:48,568
based on the nitro system,

669
00:24:48,848 --> 00:24:50,969
i.e., any modern instance released

670
00:24:50,969 --> 00:24:53,049
since 2018 and onwards. This

671
00:24:53,049 --> 00:24:55,269
is free of cost. It's free of

672
00:24:55,269 --> 00:24:55,930
performance impact.

673
00:24:56,279 --> 00:24:58,348
It is simply the default offering

674
00:24:58,348 --> 00:25:00,118
of every single EC-2 instance.

675
00:25:00,719 --> 00:25:01,618
There is no

676
00:25:02,279 --> 00:25:04,309
technical mechanism for anyone at

677
00:25:04,309 --> 00:25:06,358
AWS to access the

678
00:25:06,358 --> 00:25:08,479
contents of a customer's nitro-based

679
00:25:08,479 --> 00:25:10,500
EC-2 instance or

680
00:25:10,500 --> 00:25:12,789
encrypted storage or encrypted transit

681
00:25:12,789 --> 00:25:14,838
traffic moving in and out of

682
00:25:14,838 --> 00:25:17,160
the physical underlying virtualization

683
00:25:17,160 --> 00:25:19,189
server. Customers don't need to change

684
00:25:19,189 --> 00:25:21,309
their code to enable this. It is simply

685
00:25:21,309 --> 00:25:23,390
there and always on, and that's

686
00:25:23,390 --> 00:25:25,670
really the beauty of confidential computing compared

687
00:25:25,670 --> 00:25:27,380
to some of the techniques we'll talk about

688
00:25:27,828 --> 00:25:30,338
later, which is that it enables you to, to,

689
00:25:30,348 --> 00:25:32,430
um, isolate sensitive data

690
00:25:32,430 --> 00:25:34,430
without substantially modifying your

691
00:25:34,430 --> 00:25:35,568
general purpose

692
00:25:35,949 --> 00:25:36,549
uh code.

693
00:25:38,390 --> 00:25:38,930
So

694
00:25:39,269 --> 00:25:41,420
I'm not gonna get too into exactly how

695
00:25:41,420 --> 00:25:43,828
we manage this. It's a great story. Uh, I

696
00:25:43,838 --> 00:25:46,059
I've made a habit of telling it on quite a few stages,

697
00:25:46,469 --> 00:25:48,549
uh, but we've gone to great lengths to provide assurance

698
00:25:48,549 --> 00:25:50,750
for our customers about this claim.

699
00:25:51,029 --> 00:25:53,229
One of the first things we did was to publish a deep dive

700
00:25:53,229 --> 00:25:55,420
white paper that provides a uh um

701
00:25:55,420 --> 00:25:57,449
an overview, uh, and kind of

702
00:25:57,709 --> 00:25:59,828
deep understanding of how the different components

703
00:25:59,828 --> 00:26:01,868
of the nitro system work together to create this

704
00:26:01,868 --> 00:26:04,059
outcome. We've also provided a third

705
00:26:04,059 --> 00:26:06,098
party validation from an outside security

706
00:26:06,098 --> 00:26:07,338
firm, the NCC Group,

707
00:26:07,618 --> 00:26:09,809
which came in and affirmed our security

708
00:26:09,809 --> 00:26:12,059
claims about zero operator access.

709
00:26:12,459 --> 00:26:13,088
Lastly,

710
00:26:13,410 --> 00:26:15,729
we provided a very clear and simple

711
00:26:15,729 --> 00:26:18,410
statement in our service terms, Section 96,

712
00:26:18,818 --> 00:26:21,078
which has been updated to reflect a commitment to each

713
00:26:21,078 --> 00:26:23,259
and every AWS customer about

714
00:26:23,259 --> 00:26:25,259
this zero operator access

715
00:26:25,259 --> 00:26:25,779
posture.

716
00:26:27,130 --> 00:26:29,439
Now it's important to note in this context

717
00:26:29,608 --> 00:26:31,769
that the protection of EC2 instances covers

718
00:26:31,769 --> 00:26:33,430
not only the CPU

719
00:26:33,750 --> 00:26:35,838
resources or the VCPU of a of a customer's

720
00:26:35,838 --> 00:26:36,689
instance or the memory.

721
00:26:37,059 --> 00:26:39,219
That they use but also the contents of

722
00:26:39,219 --> 00:26:41,539
any associated accelerator devices

723
00:26:41,818 --> 00:26:44,259
whether that's uh AWS's ranium chips

724
00:26:44,259 --> 00:26:46,719
or uh Nvidium Qualcomm,

725
00:26:46,900 --> 00:26:49,219
uh AMB or Intel accelerators

726
00:26:49,219 --> 00:26:51,969
we've listed some uh of the accelerators

727
00:26:51,969 --> 00:26:54,039
uh and and uh and GPU

728
00:26:54,039 --> 00:26:56,068
powered instances here that this covers but of

729
00:26:56,068 --> 00:26:58,259
course this also applies to some of the instances that we've

730
00:26:58,259 --> 00:26:59,598
released just this week

731
00:26:59,939 --> 00:27:01,250
here uh at RIM.

732
00:27:03,969 --> 00:27:04,549
Now

733
00:27:05,250 --> 00:27:07,410
as we began to interact more and more with our customers

734
00:27:07,410 --> 00:27:09,719
and to tell them about this uh

735
00:27:10,130 --> 00:27:12,289
this this property that we had baked into

736
00:27:12,289 --> 00:27:13,269
the nitro system,

737
00:27:13,809 --> 00:27:16,049
we heard more from our customers about them asking

738
00:27:16,049 --> 00:27:16,949
whether or not they

739
00:27:17,328 --> 00:27:19,660
could be enabled to build systems that similarly

740
00:27:19,660 --> 00:27:21,348
excluded any possibility

741
00:27:21,809 --> 00:27:23,828
of external unauthorized access

742
00:27:23,969 --> 00:27:25,588
at a deep and technical level.

743
00:27:25,969 --> 00:27:27,170
Now I wanna be clear here.

744
00:27:28,410 --> 00:27:29,930
Not every workload

745
00:27:30,489 --> 00:27:32,739
requires this type of mechanism.

746
00:27:34,118 --> 00:27:36,549
Furthermore, not every regulated workload

747
00:27:36,549 --> 00:27:38,059
requires this type of mechanism.

748
00:27:38,390 --> 00:27:40,469
That said, there are, uh, we, we do speak

749
00:27:40,469 --> 00:27:42,588
regularly with customers who are looking

750
00:27:42,588 --> 00:27:44,630
for these capabilities and who feel that they will

751
00:27:44,630 --> 00:27:45,848
help them to achieve

752
00:27:46,108 --> 00:27:47,769
their, their compliance

753
00:27:48,578 --> 00:27:50,660
requirements, their security requirements,

754
00:27:50,868 --> 00:27:53,250
or even just to help them to build

755
00:27:53,828 --> 00:27:56,189
trust with prospective customers.

756
00:27:56,989 --> 00:27:58,299
So ultimately

757
00:27:58,750 --> 00:27:59,420
when we

758
00:27:59,910 --> 00:28:02,009
speak with our customers about how they can design a system

759
00:28:02,009 --> 00:28:04,269
like this, the first questions we ask them are

760
00:28:04,269 --> 00:28:06,380
what are you looking to protect, i.e.,

761
00:28:06,390 --> 00:28:08,809
what is the sensitive confidential data,

762
00:28:08,949 --> 00:28:10,910
and who are you looking to protect that from.

763
00:28:11,670 --> 00:28:12,328
If

764
00:28:13,098 --> 00:28:15,309
Uh, the folks that you were trying to protect that from

765
00:28:15,309 --> 00:28:16,828
are AWS operators.

766
00:28:17,150 --> 00:28:19,189
There is no need to change the way you

767
00:28:19,189 --> 00:28:21,509
design your code running in EC-2, uh,

768
00:28:21,630 --> 00:28:23,709
in a nitro-based EC-2 instance, right? As

769
00:28:23,709 --> 00:28:24,410
I mentioned earlier,

770
00:28:24,910 --> 00:28:27,410
you already have that protection on by default.

771
00:28:27,858 --> 00:28:29,969
Now, if what you're concerned about is something like

772
00:28:30,509 --> 00:28:32,949
perhaps like your own operators or administrators

773
00:28:32,949 --> 00:28:35,049
or, uh, supply chain issues,

774
00:28:35,430 --> 00:28:37,578
uh, that's where we have a couple of, uh,

775
00:28:37,588 --> 00:28:39,410
other technologies I wanna share with you today.

776
00:28:40,439 --> 00:28:42,799
So the, the first offering that we, we released

777
00:28:42,799 --> 00:28:44,900
to our customers was called AWS Nitro

778
00:28:44,900 --> 00:28:45,789
Enclaves.

779
00:28:46,118 --> 00:28:48,439
What this enables you to do is to take an EC2

780
00:28:48,439 --> 00:28:48,969
instance

781
00:28:49,500 --> 00:28:52,180
that would otherwise have have contained, you know, potentially,

782
00:28:52,199 --> 00:28:53,699
uh, administrative access,

783
00:28:54,289 --> 00:28:55,000
uh,

784
00:28:55,400 --> 00:28:57,559
large kind of stacks of third

785
00:28:57,559 --> 00:28:59,559
party applications and

786
00:28:59,559 --> 00:29:01,709
code. That would previously have

787
00:29:01,709 --> 00:29:03,750
had to bring in data that was either

788
00:29:03,750 --> 00:29:06,068
encrypted at rest or in transit and then decrypt

789
00:29:06,068 --> 00:29:08,078
it for processing in plain text.

790
00:29:08,269 --> 00:29:10,588
You can actually take that instance now and divide

791
00:29:10,588 --> 00:29:11,449
it into two

792
00:29:12,029 --> 00:29:14,289
strongly isolated compute domains.

793
00:29:14,630 --> 00:29:16,699
Um, technically these are basically

794
00:29:16,699 --> 00:29:18,789
two pure VMs that operate

795
00:29:18,789 --> 00:29:20,969
within what is logically your EC2 instance.

796
00:29:21,680 --> 00:29:23,880
And the second virtual machine we call a nitro

797
00:29:24,118 --> 00:29:26,358
enclave. Now nitro enclave in many

798
00:29:26,358 --> 00:29:28,358
respects is like another EC2 instance

799
00:29:28,358 --> 00:29:30,598
running alongside your EC2 instance, but

800
00:29:30,598 --> 00:29:31,910
it has a few differences.

801
00:29:32,199 --> 00:29:34,338
It doesn't have, uh, local storage,

802
00:29:34,828 --> 00:29:37,318
doesn't have, uh, a TCIP-based

803
00:29:37,318 --> 00:29:38,779
IP networking connection.

804
00:29:39,239 --> 00:29:41,358
By default, there's no SSH

805
00:29:41,358 --> 00:29:43,368
or remote interactive access into the nitro

806
00:29:43,368 --> 00:29:44,150
enclave,

807
00:29:44,439 --> 00:29:47,108
and all of this creates a constrained,

808
00:29:47,318 --> 00:29:49,640
uh, and lowered surface area of

809
00:29:49,640 --> 00:29:50,160
attack.

810
00:29:54,608 --> 00:29:57,130
Critically, it's also very useful that a nitro enclave

811
00:29:57,130 --> 00:29:59,410
can be launched using a file

812
00:29:59,809 --> 00:30:01,959
that can be hashed up to ultimately

813
00:30:01,959 --> 00:30:04,088
represent a single cryptographic

814
00:30:04,088 --> 00:30:06,199
value that contains the entire

815
00:30:06,199 --> 00:30:08,199
execution context, i.e.,

816
00:30:08,838 --> 00:30:10,890
everything inside the enclave that can

817
00:30:10,890 --> 00:30:12,969
run, that can do anything, is

818
00:30:12,969 --> 00:30:15,049
ultimately represented and traceable back to

819
00:30:15,049 --> 00:30:16,049
this hash value.

820
00:30:16,410 --> 00:30:19,029
Keep that in mind as we'll return to it in just a few slides.

821
00:30:20,170 --> 00:30:22,890
So as we spoke more and more with our customers

822
00:30:22,890 --> 00:30:25,229
who were really enjoying nitro enclaves, what we found was

823
00:30:25,568 --> 00:30:26,108
that

824
00:30:26,529 --> 00:30:29,189
customers wanted to take their own EC2

825
00:30:29,189 --> 00:30:32,068
instance. They didn't really feel the need to divide

826
00:30:32,068 --> 00:30:34,130
into two different parts, but what they wanted

827
00:30:34,130 --> 00:30:36,229
to do was make their own EC2 instance

828
00:30:37,170 --> 00:30:39,469
isolated and hardened in a way that was very similar

829
00:30:39,469 --> 00:30:40,650
to a nitro enclave.

830
00:30:40,969 --> 00:30:43,229
So we recently, just a few months ago, released

831
00:30:43,229 --> 00:30:45,269
a new offering to help our customers

832
00:30:45,529 --> 00:30:48,108
apply a zero operator access configuration

833
00:30:48,108 --> 00:30:49,689
to their own EC-2 instance.

834
00:30:51,049 --> 00:30:53,209
What this ultimately looks like is provide

835
00:30:53,209 --> 00:30:54,309
uh kind of

836
00:30:54,650 --> 00:30:56,848
uh taking a copy of Amazon Linux,

837
00:30:57,009 --> 00:30:59,400
uh, a few recipes that AWS provides,

838
00:30:59,410 --> 00:31:01,689
as well as the trusted and uh trusted

839
00:31:01,689 --> 00:31:03,439
code and apps provided by the customer,

840
00:31:03,729 --> 00:31:05,729
combining them together using a

841
00:31:05,729 --> 00:31:07,739
tool called uh Kiwi Next Generation

842
00:31:07,930 --> 00:31:10,029
and ultimately, uh, creating.

843
00:31:10,144 --> 00:31:12,223
An AMI or AMIN, a machine image

844
00:31:12,223 --> 00:31:14,255
for an EC2 instance that

845
00:31:14,265 --> 00:31:17,104
doesn't contain things like SSH

846
00:31:17,104 --> 00:31:18,934
or serial console access,

847
00:31:19,344 --> 00:31:21,664
uh, that that has a read-only file system

848
00:31:21,884 --> 00:31:23,963
to create an immutable image

849
00:31:24,223 --> 00:31:25,765
that can boot up and similarly

850
00:31:26,035 --> 00:31:27,005
be captured

851
00:31:27,434 --> 00:31:29,693
uh from beginning to end

852
00:31:29,693 --> 00:31:32,064
with a single cryptographic hash.

853
00:31:34,578 --> 00:31:35,420
Now I mentioned

854
00:31:35,699 --> 00:31:37,818
I would speak more about this idea of a cryptographic

855
00:31:37,818 --> 00:31:38,420
hash

856
00:31:38,699 --> 00:31:39,259
in a second.

857
00:31:39,969 --> 00:31:40,750
And here we are.

858
00:31:41,049 --> 00:31:43,088
So, uh, we now have

859
00:31:43,088 --> 00:31:45,088
these two capabilities, uh, both

860
00:31:45,088 --> 00:31:47,269
the nitro TPM, which powers,

861
00:31:47,289 --> 00:31:49,318
uh, this attestable AMI flow I

862
00:31:49,318 --> 00:31:51,529
mentioned earlier, and nitro enclaves

863
00:31:51,689 --> 00:31:52,630
that are both able

864
00:31:53,088 --> 00:31:53,670
to provide

865
00:31:53,969 --> 00:31:55,769
a cryptographic attestation.

866
00:31:56,078 --> 00:31:57,699
Of the code that runs inside them

867
00:31:57,959 --> 00:31:59,959
to a third party system, so what they're able to do is

868
00:31:59,959 --> 00:32:01,118
to obtain a document

869
00:32:01,439 --> 00:32:02,880
from the nitro hypervisor

870
00:32:03,279 --> 00:32:05,559
that uh that attests to the

871
00:32:05,559 --> 00:32:07,719
specific measurements of those

872
00:32:07,719 --> 00:32:10,039
environments so that external systems

873
00:32:10,039 --> 00:32:10,759
can validate.

874
00:32:11,469 --> 00:32:13,509
That the code running inside is in

875
00:32:13,509 --> 00:32:15,769
fact the code that is authorized

876
00:32:16,430 --> 00:32:17,259
to uh

877
00:32:17,549 --> 00:32:19,029
for for various interactions.

878
00:32:20,588 --> 00:32:22,588
Now, a particularly useful flow

879
00:32:22,588 --> 00:32:25,608
there is our interaction with those two cryptographic

880
00:32:26,068 --> 00:32:28,568
attestation mechanisms, and AWSKMS.

881
00:32:28,989 --> 00:32:31,130
So what we do with Nitro TPM or nitro

882
00:32:31,130 --> 00:32:33,689
enclaves is to take a measurement, generate

883
00:32:33,689 --> 00:32:34,949
that attestation document,

884
00:32:35,309 --> 00:32:36,979
sign it with a nitro hypervisor,

885
00:32:37,348 --> 00:32:39,549
and allow these environments to pass a

886
00:32:39,549 --> 00:32:41,430
request to AWS KMS

887
00:32:41,949 --> 00:32:43,989
to say, for example, decrypt

888
00:32:44,189 --> 00:32:46,358
a secret value or

889
00:32:46,358 --> 00:32:48,189
uh or cryptographic credential.

890
00:32:49,068 --> 00:32:51,108
Uh, the AWS KMS can then

891
00:32:51,108 --> 00:32:53,160
validate the attestation document,

892
00:32:53,430 --> 00:32:55,509
uh, and make an authorization decision

893
00:32:55,509 --> 00:32:57,729
based upon the contents of it before either

894
00:32:58,150 --> 00:32:59,650
choosing to deny the request

895
00:32:59,949 --> 00:33:02,049
or returning back the secret value

896
00:33:02,229 --> 00:33:03,529
to the, uh, the calling

897
00:33:03,920 --> 00:33:05,269
trusted execution environment.

898
00:33:07,348 --> 00:33:07,969
Now

899
00:33:08,568 --> 00:33:10,059
this is a bit uh a a

900
00:33:10,469 --> 00:33:11,650
a bit of a noisy screen,

901
00:33:12,049 --> 00:33:14,189
uh, but I've I've highlighted two particular

902
00:33:14,189 --> 00:33:16,049
values here in blue and purple.

903
00:33:16,509 --> 00:33:18,549
So one is uh PCR 4 in a

904
00:33:18,549 --> 00:33:20,390
nitro TPM attestation document.

905
00:33:20,709 --> 00:33:22,868
This value corresponds to the to this

906
00:33:22,868 --> 00:33:25,009
measurement I was talking about earlier, right? This is

907
00:33:25,189 --> 00:33:27,368
basically a chained, uh, value.

908
00:33:27,939 --> 00:33:29,989
Uh, that corresponds to the entire

909
00:33:29,989 --> 00:33:32,108
boot context of

910
00:33:32,108 --> 00:33:34,430
this EC2 instance. So it includes the

911
00:33:34,430 --> 00:33:35,009
kernel,

912
00:33:35,549 --> 00:33:36,529
the boot code,

913
00:33:36,789 --> 00:33:39,209
uh, and also the root file system.

914
00:33:39,709 --> 00:33:42,088
So this basically measures the entire, uh,

915
00:33:42,108 --> 00:33:44,150
instance. It basically is at a very, very low,

916
00:33:44,269 --> 00:33:47,029
like from a technical level, a cryptographic

917
00:33:47,029 --> 00:33:48,650
version of execution identity.

918
00:33:49,189 --> 00:33:50,150
PCR 7.

919
00:33:50,479 --> 00:33:52,130
Is something somewhat different.

920
00:33:52,400 --> 00:33:54,509
It's actually chained to the uh UEFI

921
00:33:54,509 --> 00:33:56,920
secure boot policy of the

922
00:33:56,920 --> 00:33:58,989
instance. Now there's a lot of details

923
00:33:58,989 --> 00:34:01,420
in there that probably aren't worth going into here,

924
00:34:01,959 --> 00:34:04,039
so I'm gonna take a step back and basically tell you how you can

925
00:34:04,039 --> 00:34:05,130
think of that value.

926
00:34:05,439 --> 00:34:07,699
It effectively corresponds

927
00:34:07,838 --> 00:34:09,340
to the ability to say

928
00:34:09,840 --> 00:34:11,679
has this instance been signed

929
00:34:12,039 --> 00:34:14,559
or has this, uh, this set of code been signed

930
00:34:15,000 --> 00:34:17,079
by a particular, uh, cryptographic

931
00:34:17,079 --> 00:34:19,148
token. So generally, right, what this looks

932
00:34:19,148 --> 00:34:21,269
like is effectively that you have a CICD

933
00:34:21,269 --> 00:34:21,929
pipeline

934
00:34:22,309 --> 00:34:24,309
and you're able to sign things that come out of that

935
00:34:24,309 --> 00:34:27,168
pipeline and bless them as being appropriate

936
00:34:27,309 --> 00:34:28,929
to handle sensitive data.

937
00:34:29,429 --> 00:34:31,590
Um, usually the, the the

938
00:34:31,590 --> 00:34:33,539
bar for that sensitive data, uh,

939
00:34:34,228 --> 00:34:36,590
access is going to be something like zero

940
00:34:36,590 --> 00:34:37,489
operator access.

941
00:34:38,840 --> 00:34:40,949
Now, you take one of these two measurements,

942
00:34:40,958 --> 00:34:43,269
or perhaps both, uh, of course PCR

943
00:34:43,269 --> 00:34:45,320
4 is a very, very specific measurement

944
00:34:45,320 --> 00:34:47,478
and is, uh, you know, perhaps a bit brittle, whereas

945
00:34:47,478 --> 00:34:49,599
PCR 7 is a little bit more scalable but

946
00:34:49,599 --> 00:34:51,260
slightly lower assurance,

947
00:34:51,800 --> 00:34:53,610
and you could take these values

948
00:34:53,918 --> 00:34:56,239
and actually plug them in directly to the KMS

949
00:34:56,239 --> 00:34:58,050
key policy that you set in KMS,

950
00:34:58,469 --> 00:35:00,519
right? So here you have, um, a principal

951
00:35:00,519 --> 00:35:02,099
being allowed to decrypt a value

952
00:35:02,679 --> 00:35:04,280
and you see under the conditions section.

953
00:35:04,668 --> 00:35:06,719
That we're looking for particular values

954
00:35:06,719 --> 00:35:08,760
in the recipient attestation nitro

955
00:35:08,760 --> 00:35:11,179
TP TPM PCR

956
00:35:11,708 --> 00:35:13,958
uh insert number here, so 4

957
00:35:13,958 --> 00:35:14,699
or 7.

958
00:35:15,000 --> 00:35:17,250
And what we do here is include the two values

959
00:35:17,250 --> 00:35:18,559
from our attestation document.

960
00:35:19,360 --> 00:35:21,389
OK. We've laid a little

961
00:35:21,389 --> 00:35:23,438
bit of groundwork. What does that actually look like? How

962
00:35:23,438 --> 00:35:25,800
can I use that to achieve a valuable

963
00:35:25,800 --> 00:35:27,820
outcome? So here's

964
00:35:27,820 --> 00:35:30,349
a very, very simple architectural diagram

965
00:35:30,579 --> 00:35:32,829
um of what this looks like.

966
00:35:33,139 --> 00:35:35,438
You have, for example, an end user device

967
00:35:35,619 --> 00:35:38,059
that will encrypt data using an AWS

968
00:35:38,059 --> 00:35:39,340
KMS key

969
00:35:39,599 --> 00:35:40,719
that only

970
00:35:41,300 --> 00:35:43,449
permits decryption of that data

971
00:35:43,860 --> 00:35:46,500
when the request comes along with an attestation

972
00:35:46,500 --> 00:35:47,139
document

973
00:35:47,409 --> 00:35:49,820
bearing a trusted measurement PCR

974
00:35:49,820 --> 00:35:52,039
value. So the encrypted user data

975
00:35:52,039 --> 00:35:52,938
is then sent

976
00:35:53,199 --> 00:35:55,250
into a nitro-based EC-2 instance

977
00:35:55,250 --> 00:35:57,438
that has full access to one of these powerful

978
00:35:57,438 --> 00:35:58,309
accelerators,

979
00:35:58,639 --> 00:36:00,958
as I mentioned at the outset of

980
00:36:00,958 --> 00:36:02,070
my talk today,

981
00:36:02,398 --> 00:36:04,469
right, uh, we already know that AWS

982
00:36:04,469 --> 00:36:06,478
operators do not have access to

983
00:36:06,478 --> 00:36:07,599
this EC2 instance.

984
00:36:08,000 --> 00:36:10,159
We also know because of the measurements and

985
00:36:10,159 --> 00:36:12,519
because of the pre-validation that we performed.

986
00:36:13,320 --> 00:36:15,628
That also no operators or staff

987
00:36:15,889 --> 00:36:18,090
from the underlying uh from the customer that operates

988
00:36:18,090 --> 00:36:20,148
the EC-2 instance can also

989
00:36:20,728 --> 00:36:23,070
access the contents of that sensitive data

990
00:36:23,329 --> 00:36:23,909
or

991
00:36:24,409 --> 00:36:26,668
modify the uh the

992
00:36:26,679 --> 00:36:28,929
the the systems that run inside the EC2

993
00:36:28,929 --> 00:36:30,929
instance. So once this data comes in,

994
00:36:31,039 --> 00:36:33,090
a call is made to KMS. KMS then

995
00:36:33,090 --> 00:36:34,878
validates the attestation document,

996
00:36:35,168 --> 00:36:37,228
decrypts the data, sends it back using

997
00:36:37,228 --> 00:36:37,949
TLS.

998
00:36:39,889 --> 00:36:42,168
And an inference request is able to be

999
00:36:42,168 --> 00:36:46,280
performed. So

1000
00:36:46,280 --> 00:36:48,320
let's take a look at ways in which these types

1001
00:36:48,320 --> 00:36:50,449
of technologies as base primitives

1002
00:36:50,599 --> 00:36:53,070
can be integrated into some of the uh

1003
00:36:53,360 --> 00:36:55,219
workflows that we've spoken about so far

1004
00:36:55,550 --> 00:36:57,750
so I actually wanna go back to tokenization

1005
00:36:58,000 --> 00:36:59,860
which Ruben was speaking about briefly

1006
00:37:00,360 --> 00:37:01,079
so here.

1007
00:37:01,583 --> 00:37:03,625
One of the things about tokenization is of course that at

1008
00:37:03,625 --> 00:37:05,864
some point the sensitive data needs

1009
00:37:05,864 --> 00:37:08,293
to be tokenized. It needs to be transformed,

1010
00:37:08,664 --> 00:37:10,784
and what better type of environment to

1011
00:37:10,784 --> 00:37:12,784
handle that sensitive data and perform

1012
00:37:12,784 --> 00:37:14,945
that sensitive tokenization

1013
00:37:14,945 --> 00:37:16,224
process than.

1014
00:37:16,719 --> 00:37:17,938
A nitro enclave or

1015
00:37:18,679 --> 00:37:20,760
an attestable EC2 instance.

1016
00:37:21,119 --> 00:37:23,179
Right there you have zero operator access, you have

1017
00:37:23,179 --> 00:37:25,909
a strong isolation boundary, and

1018
00:37:25,918 --> 00:37:28,199
inside you can then safely handle this sensitive

1019
00:37:28,199 --> 00:37:30,360
data and transform it into

1020
00:37:30,360 --> 00:37:31,639
less sensitive data.

1021
00:37:32,438 --> 00:37:34,599
Uh, thanks to attestation, you can also

1022
00:37:34,599 --> 00:37:36,800
be confident that the attestation service

1023
00:37:36,800 --> 00:37:38,599
you are providing that sensitive data to,

1024
00:37:38,878 --> 00:37:41,039
uh, is, uh, the attested service, is

1025
00:37:41,039 --> 00:37:43,398
in fact the an appropriate tokenization

1026
00:37:43,398 --> 00:37:44,878
system, and then it will handle it

1027
00:37:45,239 --> 00:37:47,280
as its code has instructed it to.

1028
00:37:49,918 --> 00:37:52,039
Now here's a bit of a more complex

1029
00:37:52,039 --> 00:37:54,168
view uh that is directly

1030
00:37:54,168 --> 00:37:56,280
tied with uh an

1031
00:37:56,280 --> 00:37:58,260
inference uh request.

1032
00:37:58,590 --> 00:38:01,119
So in this case this could be an agent executing

1033
00:38:01,119 --> 00:38:03,219
a local model or

1034
00:38:03,219 --> 00:38:05,360
even just a, you know, a a broader direct

1035
00:38:05,360 --> 00:38:07,519
more simple kind of prompt

1036
00:38:07,519 --> 00:38:08,878
response inference flow,

1037
00:38:09,239 --> 00:38:11,579
but you have basically a client device

1038
00:38:11,579 --> 00:38:13,639
that encrypts the prompt data using a KMS

1039
00:38:13,639 --> 00:38:15,719
key that has been similarly configured

1040
00:38:15,719 --> 00:38:17,978
to only allow decryption by a trusted environment.

1041
00:38:18,409 --> 00:38:20,409
That data is then sent in, encrypted

1042
00:38:20,409 --> 00:38:21,269
client side,

1043
00:38:21,688 --> 00:38:22,429
um,

1044
00:38:23,019 --> 00:38:25,168
through to an EC2 instance, which

1045
00:38:25,168 --> 00:38:26,159
has the ability,

1046
00:38:26,500 --> 00:38:28,530
thanks to cryptographic attestation, to prove that it is

1047
00:38:28,530 --> 00:38:29,929
a trusted environment to KMS.

1048
00:38:31,159 --> 00:38:33,208
To then decrypt the prompt, to

1049
00:38:33,208 --> 00:38:35,289
perform an inference uh function and

1050
00:38:35,289 --> 00:38:36,739
potentially additional processing on it,

1051
00:38:37,128 --> 00:38:39,449
and then to return uh to re-encrypt

1052
00:38:39,449 --> 00:38:41,489
that data and return it back to the client,

1053
00:38:41,769 --> 00:38:43,449
all without any system.

1054
00:38:44,188 --> 00:38:46,340
Uh That has any

1055
00:38:46,340 --> 00:38:48,728
potential for unauthorized access ever

1056
00:38:48,728 --> 00:38:51,000
having been able to access that customer data

1057
00:38:51,378 --> 00:38:52,340
in plain text.

1058
00:38:55,269 --> 00:38:57,550
Now, similarly, you could perform uh uh

1059
00:38:57,550 --> 00:39:00,030
something relatively relatively equivalent

1060
00:39:00,030 --> 00:39:02,260
with a nitro enclave. The only difference

1061
00:39:02,260 --> 00:39:04,708
is nitro enclaves do not have direct

1062
00:39:04,708 --> 00:39:06,829
access to accelerator hardware. So

1063
00:39:06,829 --> 00:39:09,289
typically here you'd be thinking about a smaller model

1064
00:39:09,429 --> 00:39:11,550
that would still operate performantly

1065
00:39:11,550 --> 00:39:13,809
with CPU based inference.

1066
00:39:14,269 --> 00:39:16,688
Um, that said, because of the nitro enclave's ability

1067
00:39:16,688 --> 00:39:18,909
to run as effectively a sidecar to another

1068
00:39:18,909 --> 00:39:19,648
compute environment.

1069
00:39:20,079 --> 00:39:22,978
It opens the possibility for more distributed

1070
00:39:24,478 --> 00:39:26,159
uh inference uh workloads and opportunities there.

1071
00:39:28,119 --> 00:39:30,320
And with that said, I'm gonna hand things back to Ruben

1072
00:39:30,320 --> 00:39:31,179
to close things out.

1073
00:39:32,500 --> 00:39:36,559
Thank you. Thank

1074
00:39:36,559 --> 00:39:38,599
you. We're now going to move

1075
00:39:38,599 --> 00:39:40,719
on to building blocks that are more on

1076
00:39:40,719 --> 00:39:42,800
your side of the shared responsibility model.

1077
00:39:43,969 --> 00:39:46,019
The first one we want to talk about is federated

1078
00:39:46,019 --> 00:39:46,530
learning.

1079
00:39:46,840 --> 00:39:48,438
It addresses cases where

1080
00:39:49,958 --> 00:39:52,119
your data might be constrained to specific

1081
00:39:52,119 --> 00:39:54,300
boundaries. This can be because of regulatory

1082
00:39:54,300 --> 00:39:54,969
constraints,

1083
00:39:55,809 --> 00:39:57,800
organizational boundaries, or security boundaries.

1084
00:39:58,219 --> 00:39:58,938
In this context,

1085
00:39:59,510 --> 00:40:02,090
further learning in, inverts the centralized

1086
00:40:02,090 --> 00:40:02,878
training model.

1087
00:40:03,139 --> 00:40:05,340
You have nodes that collaboratively

1088
00:40:05,340 --> 00:40:08,059
work together across across

1089
00:40:08,059 --> 00:40:09,559
a distributed data set,

1090
00:40:09,978 --> 00:40:12,099
and each node keeps data locally.

1091
00:40:12,510 --> 00:40:14,958
And only shares model updates

1092
00:40:14,958 --> 00:40:17,000
with a centralized aggregation server.

1093
00:40:17,958 --> 00:40:19,958
So raw data never leaves the

1094
00:40:19,958 --> 00:40:21,500
node, essentially the boundary.

1095
00:40:22,280 --> 00:40:25,179
We can highlight two options for production

1096
00:40:25,179 --> 00:40:26,590
for production implementations.

1097
00:40:26,878 --> 00:40:28,989
One of them is the flow is the open source

1098
00:40:28,989 --> 00:40:29,898
flower framework,

1099
00:40:30,878 --> 00:40:32,878
which provides flexibility with support, for example,

1100
00:40:33,000 --> 00:40:34,860
for Pytorch or Tensorflow

1101
00:40:36,079 --> 00:40:37,938
and provides enterprise scale deployment.

1102
00:40:38,228 --> 00:40:40,519
And the other one is Nvidia Flair that delivers

1103
00:40:40,519 --> 00:40:41,300
GPU support.

1104
00:40:41,918 --> 00:40:44,179
And on AWS you can deploy federated learning

1105
00:40:45,139 --> 00:40:46,619
via via SageMaker containers

1106
00:40:46,878 --> 00:40:49,389
on EC2, on EKS, on ECS, or

1107
00:40:49,389 --> 00:40:51,519
even some other options.

1108
00:40:53,708 --> 00:40:55,708
This diagram highlights ferreted

1109
00:40:55,708 --> 00:40:57,800
learning on EWS with security and

1110
00:40:57,800 --> 00:40:59,800
force at multiple layers, so we keep the

1111
00:40:59,800 --> 00:41:02,039
same principles of having multiple layers

1112
00:41:02,039 --> 00:41:02,750
of security.

1113
00:41:03,110 --> 00:41:05,708
So the central orchestrator distributes the

1114
00:41:05,708 --> 00:41:07,949
global model. To nodes

1115
00:41:07,949 --> 00:41:10,139
on AWS or external premises,

1116
00:41:10,510 --> 00:41:12,668
the attestable AI here, for example, provides

1117
00:41:12,668 --> 00:41:14,969
cryptographic proof that instances

1118
00:41:15,309 --> 00:41:17,349
run trusted software, and now

1119
00:41:17,349 --> 00:41:18,168
each node

1120
00:41:18,510 --> 00:41:20,628
trains locally on private data and returns

1121
00:41:20,628 --> 00:41:22,750
only encrypted model parameters,

1122
00:41:22,938 --> 00:41:23,840
never raw data,

1123
00:41:24,188 --> 00:41:27,179
and the aggregator combines

1124
00:41:27,309 --> 00:41:29,409
updates using secure aggregation protocols.

1125
00:41:29,909 --> 00:41:32,070
So security operates at multiple levels.

1126
00:41:32,269 --> 00:41:34,269
You have the Nitro TPM to help for

1127
00:41:34,269 --> 00:41:35,550
cryptographic attestation.

1128
00:41:35,938 --> 00:41:38,019
You have client-side encryption to

1129
00:41:38,019 --> 00:41:39,789
provide additional protection for encryption.

1130
00:41:40,059 --> 00:41:42,260
You have identity and access management to control

1131
00:41:42,260 --> 00:41:44,918
who can, for example, proceed to decryption

1132
00:41:44,918 --> 00:41:47,110
operation or communicate with the central

1133
00:41:47,110 --> 00:41:48,050
aggregation server,

1134
00:41:48,378 --> 00:41:49,039
and you can use,

1135
00:41:49,539 --> 00:41:50,478
for example, IM

1136
00:41:51,260 --> 00:41:53,260
anywhere to make sure that

1137
00:41:53,260 --> 00:41:55,300
only authorized nodes can participate in

1138
00:41:55,300 --> 00:41:56,019
the protocol.

1139
00:41:57,809 --> 00:41:59,898
To dive deeper, you can find

1140
00:41:59,898 --> 00:42:01,978
here selected articles from the

1141
00:42:01,978 --> 00:42:03,978
ERs and Amazon science blogs.

1142
00:42:05,809 --> 00:42:07,989
The The second building

1143
00:42:07,989 --> 00:42:10,228
block that we want to talk about is

1144
00:42:10,228 --> 00:42:12,628
one that addresses a fundamental challenge

1145
00:42:12,628 --> 00:42:14,349
when tied to privacy protection.

1146
00:42:15,949 --> 00:42:18,309
Um, We want to talk about

1147
00:42:18,309 --> 00:42:20,309
differential privacy, or I will use

1148
00:42:20,309 --> 00:42:22,530
the word DP in short, and

1149
00:42:22,530 --> 00:42:24,628
it addresses the challenge that it addresses is

1150
00:42:24,628 --> 00:42:25,409
the erosion

1151
00:42:25,750 --> 00:42:27,949
of privacy through repeated queries

1152
00:42:27,949 --> 00:42:30,389
or analysis or the availability of side

1153
00:42:30,389 --> 00:42:32,809
information, and I think the best is to give you an example.

1154
00:42:34,110 --> 00:42:36,228
So let's consider queries on the

1155
00:42:36,228 --> 00:42:37,809
student earnings data sets,

1156
00:42:38,110 --> 00:42:40,148
and our study run 2 queries

1157
00:42:40,148 --> 00:42:42,599
across a semester, one at the beginning of the semester

1158
00:42:42,599 --> 00:42:44,168
and the second one at the end of the semester.

1159
00:42:44,938 --> 00:42:46,978
And the first query is returns that

1160
00:42:46,978 --> 00:42:49,010
out of 3,005 students,

1161
00:42:49,418 --> 00:42:50,679
202

1162
00:42:51,139 --> 00:42:52,458
earn over 400.

1163
00:42:53,429 --> 00:42:54,559
The second query

1164
00:42:55,110 --> 00:42:58,110
returns later in time that out of 3,0004

1165
00:42:58,110 --> 00:43:00,148
students, 201 earn over

1166
00:43:00,148 --> 00:43:01,570
400 in the second.

1167
00:43:02,110 --> 00:43:04,728
This one student difference can prove critical

1168
00:43:05,269 --> 00:43:07,369
because it provides precise information about

1169
00:43:07,369 --> 00:43:08,929
a specific individual.

1170
00:43:09,429 --> 00:43:11,478
And now let's say that someone has

1171
00:43:11,478 --> 00:43:12,750
access to side information.

1172
00:43:13,070 --> 00:43:15,188
They know that they know the specific

1173
00:43:15,188 --> 00:43:17,369
student who left the school during the semester.

1174
00:43:17,469 --> 00:43:19,510
They are able to recover the identity

1175
00:43:19,510 --> 00:43:20,309
of that student.

1176
00:43:21,300 --> 00:43:23,139
They can identify the individual.

1177
00:43:24,599 --> 00:43:26,610
So differential privacy is a

1178
00:43:26,610 --> 00:43:29,389
mathematical framework to provide mathematical

1179
00:43:29,389 --> 00:43:31,250
guarantees on protecting

1180
00:43:31,570 --> 00:43:32,289
individual data.

1181
00:43:33,090 --> 00:43:34,909
The fundamental intuition

1182
00:43:35,168 --> 00:43:36,269
is that DP

1183
00:43:37,250 --> 00:43:39,289
injects carefully calibrated

1184
00:43:39,289 --> 00:43:41,889
statistical noise into either calibration

1185
00:43:41,889 --> 00:43:42,610
or queries.

1186
00:43:44,889 --> 00:43:47,168
And that noise has to be tuned

1187
00:43:47,168 --> 00:43:49,168
in order to obscure specific data

1188
00:43:49,168 --> 00:43:51,389
points, but at the same time to make sure

1189
00:43:51,530 --> 00:43:53,559
that the model remains reasonably accurate.

1190
00:43:53,889 --> 00:43:56,128
And in practice you have to involve two considerations.

1191
00:43:56,409 --> 00:43:58,769
One of them is you have to manage the so-called privacy

1192
00:43:58,769 --> 00:44:00,349
budget. So you need to make sure

1193
00:44:00,688 --> 00:44:02,878
there's a parameter that's called epsilon that can be used

1194
00:44:02,878 --> 00:44:05,309
for that, that quantifies how much additional.

1195
00:44:08,030 --> 00:44:09,769
How much privacy

1196
00:44:10,269 --> 00:44:12,590
you lose at every query and the other parameter

1197
00:44:12,590 --> 00:44:13,449
is called delta.

1198
00:44:13,829 --> 00:44:16,409
It's to prevent catastrophic privacy failure

1199
00:44:16,789 --> 00:44:18,829
where the model suddenly breaks down and reveals

1200
00:44:18,829 --> 00:44:20,989
all private information, and there are trade-offs

1201
00:44:20,989 --> 00:44:24,050
here that essentially balance accuracy

1202
00:44:24,389 --> 00:44:26,590
along with how much you can protect

1203
00:44:26,590 --> 00:44:28,708
individual information and computational

1204
00:44:28,708 --> 00:44:30,719
complexity. So,

1205
00:44:31,500 --> 00:44:33,978
if you want to implement differential privacy

1206
00:44:33,978 --> 00:44:35,978
into your algorithm, there are plenty of

1207
00:44:35,978 --> 00:44:37,978
open source frameworks

1208
00:44:37,978 --> 00:44:38,648
that exist.

1209
00:44:38,938 --> 00:44:40,719
It really depends on your use cases,

1210
00:44:41,139 --> 00:44:43,260
and at AWS we provide

1211
00:44:43,260 --> 00:44:43,918
one option

1212
00:44:44,780 --> 00:44:47,099
that we'll discuss afterwards with AWS Cleanroom.

1213
00:44:48,579 --> 00:44:50,579
Um Now I want to finish

1214
00:44:50,579 --> 00:44:51,659
giving you the intuition

1215
00:44:52,530 --> 00:44:54,260
of of how DP works.

1216
00:44:54,989 --> 00:44:57,159
So now let's say that the analysts were using

1217
00:44:57,159 --> 00:44:59,179
a DP-based system that

1218
00:44:59,179 --> 00:45:00,878
is adding control randomness.

1219
00:45:01,449 --> 00:45:03,500
Now the first query would simply return

1220
00:45:03,500 --> 00:45:05,820
a noisy count of 204 students

1221
00:45:05,820 --> 00:45:07,820
that earn over 400, and the second

1222
00:45:07,820 --> 00:45:10,199
query would return a noisy count

1223
00:45:11,099 --> 00:45:13,579
of 199 that

1224
00:45:13,579 --> 00:45:15,300
returned over 40k.

1225
00:45:15,699 --> 00:45:17,820
And that randomness is what prevents

1226
00:45:17,820 --> 00:45:19,699
identifying a specific individual.

1227
00:45:21,260 --> 00:45:23,360
Differential privacy is a tool

1228
00:45:24,260 --> 00:45:26,239
that adds formal privacy guarantee

1229
00:45:26,820 --> 00:45:29,378
that remains robust, and it's one complementary

1230
00:45:29,378 --> 00:45:30,769
approach. You can, for example,

1231
00:45:31,059 --> 00:45:33,128
often use it with ferreted learning in

1232
00:45:33,128 --> 00:45:35,539
order to prevent privacy erosion

1233
00:45:35,539 --> 00:45:36,458
across many turns.

1234
00:45:38,289 --> 00:45:39,639
Now, um.

1235
00:45:40,300 --> 00:45:43,039
Implementing different differential privacy

1236
00:45:43,500 --> 00:45:45,610
is complex. You have to manage privacy

1237
00:45:45,610 --> 00:45:47,699
budget. You have to manage, you have to tune the

1238
00:45:47,699 --> 00:45:48,458
parameters.

1239
00:45:49,019 --> 00:45:50,139
You have to know how

1240
00:45:50,458 --> 00:45:52,398
to take care of it over multiple queries,

1241
00:45:52,659 --> 00:45:54,739
and AWS Cleanroom is a service

1242
00:45:54,739 --> 00:45:55,619
for secure

1243
00:45:55,938 --> 00:45:58,219
multi-party data collaborations, and

1244
00:45:58,219 --> 00:46:00,438
it, it essentially implements managed

1245
00:46:00,619 --> 00:46:02,699
differential privacy control. So in this

1246
00:46:02,699 --> 00:46:04,360
context you can have a so-called

1247
00:46:04,659 --> 00:46:05,878
clean room operator

1248
00:46:06,378 --> 00:46:08,398
that can set the total privacy budget.

1249
00:46:09,378 --> 00:46:10,489
And for example, here

1250
00:46:10,958 --> 00:46:11,610
we have

1251
00:46:12,110 --> 00:46:14,309
3 queries that consume a certain

1252
00:46:14,309 --> 00:46:16,418
amount of that budget, and the 4th query.

1253
00:46:17,639 --> 00:46:19,679
Goes over the budget and in that case

1254
00:46:19,679 --> 00:46:21,708
the query is basically prevented,

1255
00:46:21,789 --> 00:46:24,039
which prevents the leaking

1256
00:46:24,039 --> 00:46:25,199
of individual information.

1257
00:46:27,829 --> 00:46:28,340
Um,

1258
00:46:28,898 --> 00:46:31,280
Again, if you want to dive deeper, we

1259
00:46:31,280 --> 00:46:33,320
really encourage you to explore selected

1260
00:46:33,320 --> 00:46:35,469
articles from our Amazon science colleagues.

1261
00:46:35,969 --> 00:46:38,039
You can find one early reference that dates back

1262
00:46:38,039 --> 00:46:40,079
to 2008. So this is something we've been working

1263
00:46:40,079 --> 00:46:40,898
on for a long time.

1264
00:46:41,909 --> 00:46:43,300
The last building block that

1265
00:46:43,869 --> 00:46:46,208
I want to tell you about is my favorite one.

1266
00:46:48,050 --> 00:46:49,909
So what if you never had

1267
00:46:50,168 --> 00:46:51,188
to disclose data?

1268
00:46:51,688 --> 00:46:54,050
This is cryptographic computing. With cryptographic

1269
00:46:54,050 --> 00:46:56,289
computing, you can perform computation

1270
00:46:56,289 --> 00:46:57,389
on encrypted data

1271
00:46:57,889 --> 00:46:59,409
without ever decrypting it.

1272
00:47:00,269 --> 00:47:02,550
And this comprises multiple

1273
00:47:02,550 --> 00:47:04,000
forms with different trade-offs.

1274
00:47:04,260 --> 00:47:06,309
So for example, with open source

1275
00:47:06,309 --> 00:47:08,349
frameworks such as Xama or

1276
00:47:08,349 --> 00:47:10,469
Open, you

1277
00:47:10,469 --> 00:47:12,789
can perform computation on arbitrary

1278
00:47:12,789 --> 00:47:14,869
functions. Now this comes with the

1279
00:47:14,869 --> 00:47:17,070
trade-off at the expense of performance.

1280
00:47:18,639 --> 00:47:20,688
On AWS we provide two

1281
00:47:20,688 --> 00:47:21,228
options

1282
00:47:21,530 --> 00:47:22,679
for production deployment.

1283
00:47:23,039 --> 00:47:24,728
One of them is integrated into Cleanroom.

1284
00:47:25,369 --> 00:47:26,648
I'll tell you about it afterwards.

1285
00:47:26,969 --> 00:47:29,269
And the other one is integrated into the

1286
00:47:29,269 --> 00:47:30,860
AWS database encryption SDK.

1287
00:47:31,179 --> 00:47:32,829
It provides encrypted search.

1288
00:47:33,199 --> 00:47:35,360
So again, if we come back to our tokenization

1289
00:47:35,360 --> 00:47:37,750
example, that's a pretty cool

1290
00:47:37,840 --> 00:47:39,878
application because now let's say that you have to

1291
00:47:39,878 --> 00:47:40,648
figure out

1292
00:47:40,929 --> 00:47:42,929
a specific mapping between an

1293
00:47:42,929 --> 00:47:44,789
original token and its encrypted mapping.

1294
00:47:45,090 --> 00:47:47,168
Without encrypted search, you have to go through all of the

1295
00:47:47,168 --> 00:47:48,929
mapping and encrypt each one of them.

1296
00:47:49,250 --> 00:47:51,409
Thanks to encrypted search, you can do that

1297
00:47:51,409 --> 00:47:53,489
search without ever decrypting

1298
00:47:53,489 --> 00:47:56,070
the data. In

1299
00:47:56,070 --> 00:47:57,750
the context of clean rooms,

1300
00:47:58,309 --> 00:48:00,309
the use case that it addresses are

1301
00:48:00,309 --> 00:48:02,389
regulatory scenarios where you cannot

1302
00:48:02,389 --> 00:48:03,378
put the data,

1303
00:48:03,949 --> 00:48:06,489
the data has to remain encrypted

1304
00:48:06,489 --> 00:48:07,269
on the cloud.

1305
00:48:08,809 --> 00:48:10,849
One thing to always be aware with cryptographic

1306
00:48:10,849 --> 00:48:12,889
computing, it comes with trade-off. In the context

1307
00:48:12,889 --> 00:48:15,010
of Cleanroom. These trade-offs are the following. One

1308
00:48:15,010 --> 00:48:17,128
of them is that the participants must

1309
00:48:17,128 --> 00:48:18,909
agree on a shared secret key.

1310
00:48:19,739 --> 00:48:21,760
Um The

1311
00:48:21,949 --> 00:48:22,679
other one

1312
00:48:23,619 --> 00:48:24,860
is that

1313
00:48:25,139 --> 00:48:27,739
it restricts the use of cryptographic

1314
00:48:27,739 --> 00:48:29,869
encryption with clean rooms reduces

1315
00:48:29,869 --> 00:48:31,978
the amount, reduces the type of

1316
00:48:31,978 --> 00:48:32,898
operations that you can do.

1317
00:48:33,659 --> 00:48:35,829
On your collaboration room, so you can't use all

1318
00:48:35,829 --> 00:48:37,909
the operations that you could use without cryptographic

1319
00:48:37,909 --> 00:48:38,469
computing.

1320
00:48:38,949 --> 00:48:40,949
And the third, um, the 3rd aspect that

1321
00:48:40,949 --> 00:48:43,219
you have to pay attention to is uh overhead

1322
00:48:43,219 --> 00:48:44,110
in terms of storage.

1323
00:48:46,648 --> 00:48:47,438
Now I want to talk,

1324
00:48:47,860 --> 00:48:49,860
I want to talk about fully homomorphic encryption.

1325
00:48:51,309 --> 00:48:53,708
Which enables computing arbitrary

1326
00:48:53,708 --> 00:48:55,869
functions on encrypted data without

1327
00:48:55,869 --> 00:48:57,389
ever decrypting them, and

1328
00:48:57,789 --> 00:48:59,250
the example that you show here

1329
00:48:59,789 --> 00:49:02,128
is a high level example to give you the intuition.

1330
00:49:02,469 --> 00:49:04,510
Essentially you have a plain text X that is

1331
00:49:04,510 --> 00:49:05,269
encrypted.

1332
00:49:05,958 --> 00:49:06,639
And then

1333
00:49:06,918 --> 00:49:07,949
the function F,

1334
00:49:08,559 --> 00:49:10,599
which is a mapping of the computation that you

1335
00:49:10,599 --> 00:49:11,260
want to do

1336
00:49:11,708 --> 00:49:14,360
but that can work over encrypted function, operates

1337
00:49:14,360 --> 00:49:16,878
directly on the ciphertext to produce an encrypted

1338
00:49:16,878 --> 00:49:19,179
result that can then be decrypted.

1339
00:49:20,219 --> 00:49:22,530
If you're familiar with these type of approaches,

1340
00:49:22,938 --> 00:49:25,280
you might have heard that they've been traditionally

1341
00:49:25,840 --> 00:49:28,039
super computationally expensive.

1342
00:49:28,929 --> 00:49:30,989
Now in the recent years, there has been a lot of progress,

1343
00:49:31,090 --> 00:49:33,530
either in terms of accelerated acceleration

1344
00:49:33,530 --> 00:49:35,550
options by using ASIC or GPU

1345
00:49:35,550 --> 00:49:36,929
which you find on the cloud,

1346
00:49:37,409 --> 00:49:37,949
or

1347
00:49:38,250 --> 00:49:39,829
by finding specific

1348
00:49:40,739 --> 00:49:43,090
specific optimization for use cases.

1349
00:49:44,059 --> 00:49:46,110
And today, the bottom line

1350
00:49:46,110 --> 00:49:48,648
is that you can apply this type of techniques

1351
00:49:48,869 --> 00:49:51,030
for AI workloads with

1352
00:49:51,030 --> 00:49:52,030
acceptable trade-offs.

1353
00:49:53,719 --> 00:49:55,760
One of the things that I find the most impressive is

1354
00:49:55,760 --> 00:49:57,889
that today modern approaches can even

1355
00:49:57,889 --> 00:50:00,360
give you a compiler that can automatically

1356
00:50:00,360 --> 00:50:02,590
take the small FOfix and transform

1357
00:50:02,590 --> 00:50:04,039
it into a capital FOIX,

1358
00:50:04,309 --> 00:50:05,860
so it makes the usability

1359
00:50:06,360 --> 00:50:08,478
much, much, much better than something

1360
00:50:08,478 --> 00:50:09,239
like 10 years ago.

1361
00:50:10,929 --> 00:50:12,469
So let me show you that in action.

1362
00:50:12,849 --> 00:50:14,849
I'm here giving you an example with Open

1363
00:50:14,849 --> 00:50:16,889
FHE. It's one of the open source libraries that

1364
00:50:16,889 --> 00:50:19,010
you can use. It has Python bindings which

1365
00:50:19,010 --> 00:50:21,369
make it very approachable

1366
00:50:21,369 --> 00:50:22,469
if you want to get started.

1367
00:50:22,849 --> 00:50:25,010
That example shows you vector multiplication.

1368
00:50:25,708 --> 00:50:27,918
And so what you see is that in step one

1369
00:50:27,918 --> 00:50:29,918
we have to set up a cryptographic context and we

1370
00:50:29,918 --> 00:50:31,320
have to select a specific scheme.

1371
00:50:32,228 --> 00:50:32,800
In step two,

1372
00:50:33,119 --> 00:50:34,820
we have to generate encryption keys.

1373
00:50:35,809 --> 00:50:37,820
In step 3, we encrypt, no

1374
00:50:37,820 --> 00:50:39,469
surprise, and

1375
00:50:40,280 --> 00:50:42,360
The most important step is step

1376
00:50:42,360 --> 00:50:44,438
4, where we do operation on encrypted

1377
00:50:44,438 --> 00:50:46,739
data. Here in that specific scenario,

1378
00:50:46,840 --> 00:50:47,349
we're doing,

1379
00:50:47,719 --> 00:50:49,280
we're doing a vector multiplication,

1380
00:50:49,559 --> 00:50:51,000
and step 5 is the decryption.

1381
00:50:52,500 --> 00:50:54,659
And this is something that you can run on your own

1382
00:50:54,659 --> 00:50:56,159
laptop or machine if you want.

1383
00:50:56,869 --> 00:50:57,760
Now let me give you,

1384
00:50:58,168 --> 00:51:00,269
if you can do this, that means that you

1385
00:51:00,269 --> 00:51:02,309
can do machine learning. You can, for example, apply it

1386
00:51:02,309 --> 00:51:03,030
for inference.

1387
00:51:03,750 --> 00:51:05,929
Let me here show you another example

1388
00:51:05,929 --> 00:51:08,639
that has been adapted from an open source repository.

1389
00:51:09,469 --> 00:51:11,648
This is this is a linear support

1390
00:51:11,648 --> 00:51:13,148
vector machine in France.

1391
00:51:14,260 --> 00:51:16,148
The structure is very much the same.

1392
00:51:16,909 --> 00:51:19,030
The only difference are the operations that we're

1393
00:51:19,030 --> 00:51:19,889
using, OK?

1394
00:51:20,559 --> 00:51:22,750
And for example, in that example, we're

1395
00:51:22,750 --> 00:51:23,769
taking a trade-off

1396
00:51:24,829 --> 00:51:27,148
between performance and data protection.

1397
00:51:27,550 --> 00:51:29,668
So what here in that example remains

1398
00:51:29,668 --> 00:51:30,570
encrypted

1399
00:51:32,168 --> 00:51:34,309
are the values are the inference values, but

1400
00:51:34,309 --> 00:51:36,309
the model weights remain in plain text. But

1401
00:51:36,309 --> 00:51:38,349
you don't have to do that, right? There's a trade-off that you can

1402
00:51:38,349 --> 00:51:41,579
choose. That

1403
00:51:41,579 --> 00:51:43,579
example, if you run it on a

1404
00:51:43,699 --> 00:51:44,918
reasonably sized

1405
00:51:45,458 --> 00:51:46,260
CPU machines,

1406
00:51:46,610 --> 00:51:48,039
runs in under a few

1407
00:51:49,159 --> 00:51:50,958
in under tens of milliseconds

1408
00:51:51,260 --> 00:51:53,500
and provides close to 95%

1409
00:51:53,500 --> 00:51:55,840
accuracy compared to a plain text approach.

1410
00:51:56,989 --> 00:51:58,978
So that means that you can actually

1411
00:52:00,079 --> 00:52:02,409
Deploy these approaches in the clouds

1412
00:52:02,409 --> 00:52:04,429
on a lambda function in a surveillance approach.

1413
00:52:06,168 --> 00:52:09,000
That last high level architecture

1414
00:52:09,340 --> 00:52:11,860
shows you 3 different implementation

1415
00:52:11,860 --> 00:52:12,679
deployments

1416
00:52:13,090 --> 00:52:14,708
that very much depend

1417
00:52:15,369 --> 00:52:17,500
on your model type

1418
00:52:17,500 --> 00:52:19,340
and on the performance requirement that you have.

1419
00:52:20,188 --> 00:52:22,239
This is a client-server architecture

1420
00:52:22,519 --> 00:52:24,559
where the client is responsible for

1421
00:52:24,559 --> 00:52:26,619
setting up a public-private key

1422
00:52:26,619 --> 00:52:27,699
and to handle

1423
00:52:28,148 --> 00:52:30,188
a communication protocol with a model serving

1424
00:52:30,188 --> 00:52:31,809
API. So,

1425
00:52:33,329 --> 00:52:35,340
For a lightweight FHE model,

1426
00:52:35,849 --> 00:52:37,889
you can use the synchronous lambda path,

1427
00:52:37,989 --> 00:52:39,228
that's the one on the top

1428
00:52:39,889 --> 00:52:40,708
that basically

1429
00:52:40,969 --> 00:52:43,250
processes requests directly in the lambda function

1430
00:52:43,250 --> 00:52:44,269
and returns the result.

1431
00:52:46,280 --> 00:52:48,458
If you have more computationally

1432
00:52:48,958 --> 00:52:51,079
intensive models, for example, you're using

1433
00:52:51,079 --> 00:52:53,628
this type of techniques on a reasonably sized,

1434
00:52:54,269 --> 00:52:56,418
reasonably sized neural networks,

1435
00:52:57,119 --> 00:52:59,478
you can either use a surveillance approach with GPUs,

1436
00:52:59,559 --> 00:53:00,579
for example, with ECS.

1437
00:53:01,469 --> 00:53:03,719
Or you can you can use asynchronous

1438
00:53:03,719 --> 00:53:04,320
processing

1439
00:53:04,599 --> 00:53:06,958
where you're going to first put the result into a queue, it

1440
00:53:06,958 --> 00:53:09,099
gets acted on later,

1441
00:53:09,639 --> 00:53:11,260
and you recover the result later.

1442
00:53:12,239 --> 00:53:14,369
And the third option,

1443
00:53:15,010 --> 00:53:17,039
um, well, actually the 3rd, that was the 3rd option that

1444
00:53:17,039 --> 00:53:18,820
I described where you don't have GPU support.

1445
00:53:19,820 --> 00:53:21,659
You also need an S3 bucket

1446
00:53:22,019 --> 00:53:24,300
because you need to be able to store what's called an evaluation

1447
00:53:24,300 --> 00:53:26,458
key, which is specific cryptographic

1448
00:53:26,458 --> 00:53:28,840
material that you use in those cases, and that's generally

1449
00:53:29,139 --> 00:53:31,340
too large in order to be passed

1450
00:53:31,340 --> 00:53:32,659
directly via API calls.

1451
00:53:33,829 --> 00:53:35,909
And what we really want to show you here

1452
00:53:35,909 --> 00:53:37,969
with this slide is that there's a perfect

1453
00:53:37,969 --> 00:53:39,829
match between the clouds

1454
00:53:40,590 --> 00:53:41,820
and cryptographic computing, right,

1455
00:53:42,148 --> 00:53:44,519
because you have access to surveillance resources

1456
00:53:44,519 --> 00:53:46,550
and to GPUs and your data

1457
00:53:46,550 --> 00:53:48,188
can remain encrypted at all times.

1458
00:53:50,699 --> 00:53:53,418
Again, this was our last building block, and

1459
00:53:53,789 --> 00:53:55,869
that's one with great potential, and we'd love

1460
00:53:55,869 --> 00:53:57,909
to hear how we

1461
00:53:57,909 --> 00:53:58,820
can help you

1462
00:53:59,228 --> 00:54:01,389
here. And to dive deeper, here is

1463
00:54:01,389 --> 00:54:03,708
another selection of resources and articles

1464
00:54:03,708 --> 00:54:05,289
from our Amazon science colleagues.

1465
00:54:05,869 --> 00:54:07,168
All right, let's wrap up.

1466
00:54:08,619 --> 00:54:10,829
We've shown you multiple building blocks, and our

1467
00:54:10,829 --> 00:54:12,869
key message here is privacy in depth.

1468
00:54:14,570 --> 00:54:16,610
You can use them together. You can combine

1469
00:54:16,610 --> 00:54:19,168
them to meet your specific compliance

1470
00:54:19,168 --> 00:54:21,289
and protection requirement. There is not a

1471
00:54:21,289 --> 00:54:22,750
one size fits all, right?

1472
00:54:23,449 --> 00:54:25,478
It's all about visibility,

1473
00:54:25,719 --> 00:54:27,849
secure access, and control over

1474
00:54:27,849 --> 00:54:29,849
data. At the end of the day, what

1475
00:54:29,849 --> 00:54:31,728
we want you is to be able to meet.

1476
00:54:32,349 --> 00:54:34,628
Your compliance requirements and to benefit

1477
00:54:34,628 --> 00:54:36,829
from the agility and innovation

1478
00:54:36,829 --> 00:54:38,429
benefits of the cloud.

1479
00:54:40,239 --> 00:54:42,329
The other thing that we really want to call out

1480
00:54:42,329 --> 00:54:44,610
here is that data

1481
00:54:44,610 --> 00:54:45,750
protection and privacy

1482
00:54:46,208 --> 00:54:48,099
is something fundamental at AWS,

1483
00:54:48,489 --> 00:54:50,769
and many of these naming blocks, they are used

1484
00:54:50,769 --> 00:54:52,340
under the hood with managed

1485
00:54:52,909 --> 00:54:53,829
AWS services.

1486
00:54:54,289 --> 00:54:55,840
For example, with Amazon Bedrock,

1487
00:54:56,168 --> 00:54:58,369
we ensure that your data is never shared with foundation

1488
00:54:58,369 --> 00:54:59,239
model providers,

1489
00:54:59,610 --> 00:55:01,030
prompt data is not stored.

1490
00:55:01,329 --> 00:55:03,409
All API calls remain within your AWS

1491
00:55:03,409 --> 00:55:05,489
regions. We're using encryption

1492
00:55:05,489 --> 00:55:07,688
in transit and encryption at rest with

1493
00:55:07,688 --> 00:55:08,728
customer managed keys.

1494
00:55:09,449 --> 00:55:11,579
CloudWatch and Coltrail, they provide

1495
00:55:11,579 --> 00:55:14,519
monitoring and auditability

1496
00:55:14,949 --> 00:55:17,059
backed by over 20 compliance standards, and

1497
00:55:17,059 --> 00:55:19,059
the same set of principles and

1498
00:55:19,059 --> 00:55:19,679
approaches

1499
00:55:19,938 --> 00:55:21,699
are being applied to Sagemaker AI.

1500
00:55:23,360 --> 00:55:23,958
Um,

1501
00:55:24,438 --> 00:55:26,530
finally. This presentation

1502
00:55:26,530 --> 00:55:29,099
is about building blocks with assurance.

1503
00:55:29,208 --> 00:55:31,869
OK? At AWS,

1504
00:55:32,360 --> 00:55:33,478
uh, security,

1505
00:55:33,760 --> 00:55:34,438
data protection,

1506
00:55:34,849 --> 00:55:37,039
and privacy are foundational to

1507
00:55:37,039 --> 00:55:38,829
everything that we do and build.

1508
00:55:39,809 --> 00:55:42,208
And as for you, builder of regulated industries,

1509
00:55:42,289 --> 00:55:43,719
I said that several times.

1510
00:55:44,050 --> 00:55:45,909
We really want you to use encryption

1511
00:55:46,688 --> 00:55:48,688
and have control of your keys backed

1512
00:55:48,688 --> 00:55:49,340
by KMS.

1513
00:55:49,849 --> 00:55:52,000
Encryption is easy on AWS, so

1514
00:55:52,000 --> 00:55:52,849
just use it.

1515
00:55:53,780 --> 00:55:56,269
The nitro system is always is

1516
00:55:56,269 --> 00:55:58,300
always on. It provides strong physical

1517
00:55:58,300 --> 00:55:59,699
and logical isolation

1518
00:56:00,139 --> 00:56:02,128
together with attestation capabilities,

1519
00:56:02,458 --> 00:56:04,780
and that gives you control over how

1520
00:56:04,780 --> 00:56:06,260
your data can be processed.

1521
00:56:07,378 --> 00:56:08,139
And finally,

1522
00:56:08,590 --> 00:56:10,659
on your side of the shared responsibility model, take

1523
00:56:10,659 --> 00:56:13,219
advantage of furthered learning, differential

1524
00:56:13,219 --> 00:56:15,378
privacy, cryptographic computing.

1525
00:56:15,719 --> 00:56:18,139
They are here today. You can use them, right?

1526
00:56:18,539 --> 00:56:20,550
And again, we'd love to hear

1527
00:56:20,550 --> 00:56:21,958
how we can help you there

1528
00:56:22,938 --> 00:56:24,659
and how to deploy them in production.

1529
00:56:25,829 --> 00:56:27,840
These building blocks give you the

1530
00:56:27,840 --> 00:56:29,958
confidence and assurance to innovate while

1531
00:56:29,958 --> 00:56:30,820
you comply

1532
00:56:31,320 --> 00:56:33,260
with an evolving regulatory landscape.

1533
00:56:33,840 --> 00:56:35,918
Thank you very much for listening, and we'll be

1534
00:56:35,918 --> 00:56:37,219
available to take your questions.

1535
00:56:38,519 --> 00:56:40,168
Just after outside this room.

