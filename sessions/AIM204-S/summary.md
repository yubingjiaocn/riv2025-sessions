# AWS re:Invent 2025 会议总结：生产级 AI 工作负载

## 会议概述

本次会议由 Cybage 公司的 Muhammad Zaman (Mo) 和 Anish 主讲，重点探讨了如何构建生产级的 AI 工作负载。会议深入分析了企业在将 AI 集成到现有技术栈时面临的实际挑战，以及如何利用 AWS 服务来解决这些问题。演讲者强调了原型开发与生产环境实施之间的关键区别，指出不应过度设计原型系统，而应该使用 AWS 提供的低代码服务（如 Bedrock Knowledge Bases 和 Kendra）来快速验证概念。

会议涵盖了多个核心主题，包括 AI 代理架构设计、API 现代化改造、安全治理以及商业化定价策略。演讲者特别强调了在构建企业级 AI 应用时，需要将传统的三层架构进行重新思考——API 层变得更加轻量化，而 AI 代理承担了更多的业务逻辑和编排工作。此外，会议还讨论了如何通过可观测性工具、AI 网关和动态工具绑定等技术手段，确保 AI 系统在生产环境中的稳定性、安全性和可扩展性。

演讲者分享了 Cybage 在实际项目中积累的经验，包括如何处理遗留 API 的代理化改造、如何设计符合企业权限体系的工具访问控制，以及如何通过基于输出而非基于 token 的定价模式来提高用户采用率。整个会议为与会者提供了从概念验证到生产部署的完整实践指南。

## 详细时间线

开场介绍
- 演讲者介绍：Muhammad Zaman (Mo) 负责 Cybage 的 AWS 战略合作伙伴关系，Anish 领导云数据和 AI 实践团队
- 会后可访问展位 1231 进行深入交流

AI 在企业技术栈中的应用方式
- 讨论了三种主要的 AI 集成方式：数据层准备、AI 辅助开发、应用层 AI 代理
- 应用架构的转变：API 层变得更轻量，AI 代理承担更多业务逻辑和编排工作
- AWS 服务的演进：从 Bedrock 基础模型发展到 Agent Core 等完整服务体系

原型与生产环境的区别
- 核心原则：不要过度设计原型系统
- 原型阶段：使用 AWS 低代码服务（Bedrock Knowledge Bases、Kendra）在沙箱环境中快速验证概念
- 生产环境：需要更复杂的数据摄取工作流、实时数据连接器和自定义构建的解决方案

生产级架构设计要点
- MCP 服务器与代理的分离：同一个 MCP 服务器（如网页浏览、上下文检索）可被多个代理使用
- 工具与代理工作流的分离是设计重点
- Agent Core 支持跨不同 MCP 服务器的代理协作

AI 网关和可观测性
- AI 网关工具：Lite LLM 和 AWS 原生服务
- 集中化的日志记录、监控和观察对生产环境至关重要
- AWS CloudWatch 现支持 GenAI 日志摄取，实现端到端的会话和追踪可追溯性
- 可观测性帮助识别问题发生的阶段：检索阶段、生成阶段或用户使用阶段

遗留 API 的 AI 层构建
- 挑战：现有 API 并非为代理消费而设计，而是为传统用户界面设计
- API 响应问题：许多产品 API 返回 100+ 条结果，响应过于冗余，包含大量无用的 JSON 数据
- 代理无法有效处理大规模 API 响应，基于聊天的交互需要更小的工作负载和结果集

API 就绪性改造
- API 依赖性问题：LLM 需要多次往返调用（先获取认证 token，再调用 API，然后调用下游 API）
- 解决方案：采用"代理优先"的思维重新设计 API schema
- 根据用户与代理的交互方式、工作流类型和提示类型来优化 API 设计
- 这是逻辑设计问题，与 LLM 或生成技术无关

工具调用的可观测性优势
- 工具调用和函数调用的可观测性更具确定性
- 与开放式聊天响应相比，可以创建更准确的评估指标
- 可以获得代理成功调用所需 API 的准确率分数
- 这种确定性在基础聊天或自由形式聊天中无法实现，后者需要使用自定义评估指标

安全与治理
- 引入工具后，安全问题呈指数级增长
- 主要关注点：不同权限级别工具之间的上下文混合
- PII（个人身份信息）保护：使用 AWS Macie 进行 PII 检测和掩码
- 护栏机制：使用开源框架或自定义护栏，在生成前和生成后阶段保护应用

权限管理
- 将用户组绑定到其有权访问的工具
- 企业访问权限级别需要与代理权限相匹配
- 内部用户和最终客户用户都有分层权限，需要反映在工具访问中
- Agent Core 的动态工具绑定功能：可以为用户动态绑定工具，在管道中构建尊重用户权限级别的绑定

采用与商业化策略
- 基于 token 的定价模式对 AI 产品功能效果不佳
- 用户不愿意为后端使用 LLM 的功能支付基于 token 的费用
- 替代方案：将 AI 成本纳入订阅定价，或创建需要更高 AI 工作负载的新订阅层级

创新定价模式
- 建议：基于输出而非 token 来定价 AI 功能
- 示例：如果代理运行特定工作负载（内容生成、报告生成、研究报告等），按输出定价
- 实施要求：需要 API 和 AI 网关层来支持不同用户组之间的差异化 AI 工作负载限流
- 网关层负责根据 AI 使用情况对正确的用户组进行限流

总结与行动号召
- Cybage 正在与 AWS 合作构建这些生产级解决方案
- 邀请与会者访问展位 1231 进行更深入的技术讨论
- 希望参会者能够带走切实可行的学习成果