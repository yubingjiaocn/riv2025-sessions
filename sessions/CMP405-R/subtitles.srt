1
00:00:00,000 --> 00:00:01,110
- [Seth] All right, welcome everybody.

2
00:00:01,110 --> 00:00:02,070
Can everyone hear me okay?

3
00:00:02,070 --> 00:00:03,630
- Yeah.
- Awesome. That's great.

4
00:00:03,630 --> 00:00:05,400
So this is a code talk.

5
00:00:05,400 --> 00:00:06,750
So I just wanna make
sure everyone realizes,

6
00:00:06,750 --> 00:00:09,090
this is not a dark room to
hide and just look at slides.

7
00:00:09,090 --> 00:00:10,740
This is interactive.

8
00:00:10,740 --> 00:00:11,970
We're gonna start off with some questions

9
00:00:11,970 --> 00:00:13,920
that we're gonna ask,
and we have a few slides

10
00:00:13,920 --> 00:00:16,860
to go through for sure, but
the more questions you ask us,

11
00:00:16,860 --> 00:00:17,700
the more we'll get out of it.

12
00:00:17,700 --> 00:00:19,140
And I have a way to encourage that.

13
00:00:19,140 --> 00:00:22,530
I've got stickers, so ask
a question, get a sticker.

14
00:00:22,530 --> 00:00:24,780
That's the way this is gonna go today.

15
00:00:24,780 --> 00:00:27,090
So we wanna get through,
we'll get through a little bit

16
00:00:27,090 --> 00:00:28,590
of a setup here to set
up the conversation.

17
00:00:28,590 --> 00:00:30,870
We're gonna talk about
performance obviously,

18
00:00:30,870 --> 00:00:32,520
but after that, I really,

19
00:00:32,520 --> 00:00:34,650
we want you to ask us questions, right?

20
00:00:34,650 --> 00:00:35,670
That's the idea behind today.

21
00:00:35,670 --> 00:00:37,260
- [Arthur] That's gonna
be more of a console talk

22
00:00:37,260 --> 00:00:38,723
than a code talk, but.
- There you go.

23
00:00:38,723 --> 00:00:40,530
- Rename it.
- We'll get there.

24
00:00:40,530 --> 00:00:43,440
So, but before we dive into
it, I just want to get a sense

25
00:00:43,440 --> 00:00:45,240
of who's in the room today.

26
00:00:45,240 --> 00:00:46,650
Show of hands, if you ever looked

27
00:00:46,650 --> 00:00:49,680
at your application's
performance, the metrics

28
00:00:49,680 --> 00:00:50,790
around your application performance

29
00:00:50,790 --> 00:00:53,880
and thought you're not really
sure why it's running as fast,

30
00:00:53,880 --> 00:00:56,490
it should be running faster than it is.

31
00:00:56,490 --> 00:00:58,470
All right, I see a few hands up.

32
00:00:58,470 --> 00:01:00,060
For those of you that
didn't raise your hands,

33
00:01:00,060 --> 00:01:02,760
I'm gonna say you're either
incredibly lucky or optimistic,

34
00:01:02,760 --> 00:01:04,410
but we're gonna figure
out which one today.

35
00:01:04,410 --> 00:01:06,450
So, okay, hands up again.

36
00:01:06,450 --> 00:01:08,670
If you ever tried to optimize performance

37
00:01:08,670 --> 00:01:10,140
by throwing more compute at the problem,

38
00:01:10,140 --> 00:01:12,030
maybe a bigger instance, more cores,

39
00:01:12,030 --> 00:01:13,890
more memory, lots of hands up for that.

40
00:01:13,890 --> 00:01:16,592
- [Arthur] Thank you. That's
why the stock is so high.

41
00:01:16,592 --> 00:01:18,092
(audience laughs)

42
00:01:18,092 --> 00:01:21,146
- And then last question.
- Can you not record that one?

43
00:01:21,146 --> 00:01:22,020
(all laughing)

44
00:01:22,020 --> 00:01:22,853
- [Seth] Last question.

45
00:01:22,853 --> 00:01:25,410
How many of you have heard
of terms like NUMA nodes,

46
00:01:25,410 --> 00:01:27,630
cache lines, CPU affinity,

47
00:01:27,630 --> 00:01:29,700
but honestly weren't quite
sure exactly how that

48
00:01:29,700 --> 00:01:31,550
impacts your application performance?

49
00:01:32,400 --> 00:01:33,540
Right? See a few hands for that.

50
00:01:33,540 --> 00:01:35,490
Okay, I think you have all
come to the right place.

51
00:01:35,490 --> 00:01:36,510
I think based on the show of hands,

52
00:01:36,510 --> 00:01:37,343
you're in the right place here.

53
00:01:37,343 --> 00:01:40,590
But there's a persistent
myth in our industry

54
00:01:40,590 --> 00:01:43,980
that modern compilers and
cloud infrastructure have

55
00:01:43,980 --> 00:01:47,070
abstracted away the need to
really understand hardware.

56
00:01:47,070 --> 00:01:49,590
We can just write clean
code, deploy it to the cloud,

57
00:01:49,590 --> 00:01:50,643
and magic happens.

58
00:01:52,140 --> 00:01:53,760
But here's the thing,

59
00:01:53,760 --> 00:01:56,010
and this is what we're
gonna explore today.

60
00:01:56,010 --> 00:01:57,630
The difference between code that runs

61
00:01:57,630 --> 00:02:00,000
and code that flies often comes down

62
00:02:00,000 --> 00:02:03,063
to understanding the hardware
beneath these abstractions.

63
00:02:04,080 --> 00:02:05,190
So let me paint you a picture.

64
00:02:05,190 --> 00:02:07,290
Imagine you have two identical servers

65
00:02:07,290 --> 00:02:11,130
running identical code,
processing identical workloads,

66
00:02:11,130 --> 00:02:14,400
but one consistently performs
40% better than the other one.

67
00:02:14,400 --> 00:02:15,540
No visible errors,

68
00:02:15,540 --> 00:02:19,410
no obvious bottlenecks in
your tools, what's going on?

69
00:02:19,410 --> 00:02:20,400
The answer might be as simple

70
00:02:20,400 --> 00:02:22,560
as which CPU cores your threads landed on,

71
00:02:22,560 --> 00:02:26,400
or how your data structures
align with cache lines.

72
00:02:26,400 --> 00:02:28,860
So when you're pushing the
limit of what's possible,

73
00:02:28,860 --> 00:02:31,320
when every millisecond of latency matters,

74
00:02:31,320 --> 00:02:33,530
when you're trying to squeeze
every drop of performance out

75
00:02:33,530 --> 00:02:35,460
of your infrastructure budget,

76
00:02:35,460 --> 00:02:38,010
that's when understanding
these low level details

77
00:02:38,010 --> 00:02:42,210
transforms from interesting
trivia into critical knowledge.

78
00:02:42,210 --> 00:02:44,040
Today we're gonna pull back the curtain

79
00:02:44,040 --> 00:02:45,900
and explore memory topology,

80
00:02:45,900 --> 00:02:48,810
and explain why your RAM
isn't just one big pool.

81
00:02:48,810 --> 00:02:50,910
We'll examine the art of hyperthreading,

82
00:02:50,910 --> 00:02:53,910
and why sometimes using fewer cores

83
00:02:53,910 --> 00:02:55,413
gives you better performance.

84
00:02:56,430 --> 00:02:57,690
And more importantly, we'll talk about how

85
00:02:57,690 --> 00:02:59,430
to actually measure performance

86
00:02:59,430 --> 00:03:02,180
in a way that gives you more
than just pretty pictures.

87
00:03:03,300 --> 00:03:04,230
And most importantly,

88
00:03:04,230 --> 00:03:06,420
we're gonna learn how to
make informed decisions

89
00:03:06,420 --> 00:03:09,690
on when these optimizations
matter and when they don't.

90
00:03:09,690 --> 00:03:10,770
My name is Seth Fox.

91
00:03:10,770 --> 00:03:14,310
I'm joined by Arthur
Petitpierre, let's dive in.

92
00:03:14,310 --> 00:03:16,320
So I wanna talk for a second about how

93
00:03:16,320 --> 00:03:17,880
to read the EC2 instance portfolio.

94
00:03:17,880 --> 00:03:20,280
Over the years, we have lots of instances,

95
00:03:20,280 --> 00:03:22,830
lots of instance families
to sort of dive into,

96
00:03:22,830 --> 00:03:24,300
but there is kind of a decoder ring,

97
00:03:24,300 --> 00:03:25,830
and that's the sticker you'll get.

98
00:03:25,830 --> 00:03:27,990
It's gonna look a lot like this,

99
00:03:27,990 --> 00:03:30,030
but sort of break this down for folks

100
00:03:30,030 --> 00:03:32,040
so that we understand
what we're looking at.

101
00:03:32,040 --> 00:03:34,980
So we have, you know, I've
highlighted three of our,

102
00:03:34,980 --> 00:03:37,290
I call our workhorse, the C, Ms and Rs.

103
00:03:37,290 --> 00:03:38,970
Those are compute optimized,

104
00:03:38,970 --> 00:03:41,910
memory optimized, and
general purpose instances.

105
00:03:41,910 --> 00:03:43,510
And what does that mean exactly?

106
00:03:44,520 --> 00:03:47,550
It's basically a vCPU to RAM ratio.

107
00:03:47,550 --> 00:03:48,960
And you can see the ratios up there,

108
00:03:48,960 --> 00:03:50,487
and as you sort of move through those,

109
00:03:50,487 --> 00:03:53,430
the vCPU to RAM ratio doubles
as you go up that stack.

110
00:03:53,430 --> 00:03:54,690
Now this decoder,

111
00:03:54,690 --> 00:03:57,030
we're gonna decode a
compute-based instance here,

112
00:03:57,030 --> 00:04:00,210
but it'll work across
our instance families.

113
00:04:00,210 --> 00:04:04,470
So if we look at this, we've
got a c8gn two extra large.

114
00:04:04,470 --> 00:04:05,670
So what does that mean?

115
00:04:05,670 --> 00:04:07,401
I've got a compute-based instance, right?

116
00:04:07,401 --> 00:04:09,690
'Cause I know that, I see the c.

117
00:04:09,690 --> 00:04:12,300
It's eighth generation, so
you can see where it fits

118
00:04:12,300 --> 00:04:15,000
in the lineage of compute-based instances.

119
00:04:15,000 --> 00:04:16,230
And then there's a couple of options

120
00:04:16,230 --> 00:04:18,450
for this instance, g and n.

121
00:04:18,450 --> 00:04:20,520
The g tells us this is
a Graviton instance,

122
00:04:20,520 --> 00:04:23,340
so it's got a Graviton processor in it.

123
00:04:23,340 --> 00:04:27,390
And n tells me this
instance has some difference

124
00:04:27,390 --> 00:04:29,970
in networking, some
specialized networking.

125
00:04:29,970 --> 00:04:31,410
So now we get into the number,

126
00:04:31,410 --> 00:04:34,530
the 2xlarge is gonna tell
us how many vCPUs there are.

127
00:04:34,530 --> 00:04:36,330
So everything doubles.

128
00:04:36,330 --> 00:04:39,600
We start with 1 is medium, 2 is large,

129
00:04:39,600 --> 00:04:42,990
4 is extra large, two
extra, yeah, four, yeah.

130
00:04:42,990 --> 00:04:44,610
And then two extra large becomes eight.

131
00:04:44,610 --> 00:04:45,987
So now I know I've got eight CPUs,

132
00:04:45,987 --> 00:04:48,630
and because of that,
I've got 16 gigs of RAM,

133
00:04:48,630 --> 00:04:50,190
because I know the ratio for those things.

134
00:04:50,190 --> 00:04:51,600
So when I break this down,

135
00:04:51,600 --> 00:04:54,900
this is an eighth generation
compute-based instance

136
00:04:54,900 --> 00:04:57,000
with eight vCPUs, 16 gigs of RAM,

137
00:04:57,000 --> 00:04:58,320
and the specialized networking is up

138
00:04:58,320 --> 00:04:59,970
to 50 gigs of networking.

139
00:04:59,970 --> 00:05:02,610
So while this is decoding at
one compute-based instance,

140
00:05:02,610 --> 00:05:05,370
like I said, this will cover
our entire instance portfolio

141
00:05:05,370 --> 00:05:06,570
as you're looking across that,

142
00:05:06,570 --> 00:05:09,600
and you can use that to
break down different pieces

143
00:05:09,600 --> 00:05:11,670
as you're making those instance choices.

144
00:05:11,670 --> 00:05:14,453
- [Arthur] One last comment
before you go to the next one.

145
00:05:15,600 --> 00:05:20,600
We mentioned in the table at
the top left, that C, M, and R,

146
00:05:22,410 --> 00:05:26,998
or the, with the different
amount of memory, there's a myth

147
00:05:26,998 --> 00:05:30,480
that we encounter extremely often

148
00:05:30,480 --> 00:05:33,270
that dates back to fifth gen, which is

149
00:05:33,270 --> 00:05:36,390
that the processors on the Cs might be

150
00:05:36,390 --> 00:05:38,130
faster than the other ones.

151
00:05:38,130 --> 00:05:40,230
The last time it was true was

152
00:05:40,230 --> 00:05:44,610
for Intel fifth gen AWS instances.

153
00:05:44,610 --> 00:05:46,620
Starting from gen six,

154
00:05:46,620 --> 00:05:51,270
we have the exact same
processor on C, M, and Rs.

155
00:05:51,270 --> 00:05:53,820
So if you're using an M6i,

156
00:05:53,820 --> 00:05:56,730
you have the exact same
processor on a C6i,

157
00:05:56,730 --> 00:06:00,540
and the exact same processor on an R6i.

158
00:06:00,540 --> 00:06:03,780
Makes your life, as someone

159
00:06:03,780 --> 00:06:06,630
analyzing performance, much, much easier.

160
00:06:06,630 --> 00:06:09,180
It's also much, much easier
when you're using things

161
00:06:09,180 --> 00:06:12,420
like Spot and you wanna diversify.

162
00:06:12,420 --> 00:06:14,520
That's still the same processor.

163
00:06:14,520 --> 00:06:16,320
And as much as possible we will try

164
00:06:16,320 --> 00:06:20,790
to keep that a real thing
for the next generation.

165
00:06:20,790 --> 00:06:22,200
So that's definitely true

166
00:06:22,200 --> 00:06:25,710
for the seventh gen across the board.

167
00:06:25,710 --> 00:06:27,343
So on the Graviton side,

168
00:06:27,343 --> 00:06:31,920
a seven gen Graviton-based
instance, that's a Graviton3,

169
00:06:31,920 --> 00:06:33,480
and that's the same one

170
00:06:33,480 --> 00:06:37,800
for C7g, M7g, and R7g.

171
00:06:37,800 --> 00:06:40,860
That's the exact same
thing on the AMD side.

172
00:06:40,860 --> 00:06:45,860
That's the same Genoa-based
processor on AMD seventh gen.

173
00:06:46,560 --> 00:06:50,130
And we've done that again with gen eight,

174
00:06:50,130 --> 00:06:52,980
and we will do that again with gen nine.

175
00:06:52,980 --> 00:06:56,250
I cannot promise that it's
gonna be the same for gen 15,

176
00:06:56,250 --> 00:07:00,240
but for as long as we can do
that, we will try to do it.

177
00:07:00,240 --> 00:07:03,540
And we tend also to make that broader.

178
00:07:03,540 --> 00:07:06,600
So with the i instances, for example,

179
00:07:06,600 --> 00:07:10,563
we've been using the same
processors as in C, M, and R.

180
00:07:11,730 --> 00:07:12,563
Yes.

181
00:07:14,940 --> 00:07:17,700
I'm not sure whether that
thing is on. Give it a try.

182
00:07:17,700 --> 00:07:18,533
Yes, it's on.

183
00:07:18,533 --> 00:07:19,830
- [Participant 1] Cool.

184
00:07:19,830 --> 00:07:23,100
So you have AMD, Intel, and Graviton,

185
00:07:23,100 --> 00:07:26,340
and even within Intel and AMD,
you have multiple families

186
00:07:26,340 --> 00:07:28,540
and multiple, you know,
as I said, lineages.

187
00:07:30,630 --> 00:07:35,630
So even within different CPU brands,

188
00:07:37,260 --> 00:07:40,262
they are still the same performance?

189
00:07:40,262 --> 00:07:43,200
- [Arthur] No, no. That
would be too simple.

190
00:07:43,200 --> 00:07:45,300
- [Participant 1] Yeah,
that'll be too simple.

191
00:07:45,300 --> 00:07:48,480
- [Arthur] So the processor
is exactly the same

192
00:07:48,480 --> 00:07:52,260
within the same brand of processor.

193
00:07:52,260 --> 00:07:55,110
So C8i, C,

194
00:07:55,110 --> 00:07:59,310
sorry C8i, M8i, and R8i,

195
00:07:59,310 --> 00:08:01,778
that's the same processor in
the same performance profile.

196
00:08:01,778 --> 00:08:04,350
- Within the generation.
- Within the generation.

197
00:08:04,350 --> 00:08:07,890
Now if you move from an Intel to an AMD,

198
00:08:07,890 --> 00:08:09,420
they're gonna be super different.

199
00:08:09,420 --> 00:08:12,150
If you move from an AMD to a Graviton,

200
00:08:12,150 --> 00:08:13,600
they will be super different.

201
00:08:14,732 --> 00:08:16,980
And I cannot tell you there's one

202
00:08:16,980 --> 00:08:20,313
that's gonna be better at
everything compared to the other.

203
00:08:21,870 --> 00:08:25,740
I can give you guidance, I
can tell you that, in general,

204
00:08:25,740 --> 00:08:29,850
a Graviton processor will
be more cost effective,

205
00:08:29,850 --> 00:08:34,380
but in some cases an AMD
processor will be more expensive

206
00:08:34,380 --> 00:08:36,120
but will be faster,

207
00:08:36,120 --> 00:08:38,550
and there will be other
combination with intel.

208
00:08:38,550 --> 00:08:41,280
And there's never going,
well, it's gonna be hard

209
00:08:41,280 --> 00:08:44,340
to have an easy answer to that question,

210
00:08:44,340 --> 00:08:48,090
'cause they are optimized
for different things,

211
00:08:48,090 --> 00:08:50,700
and so they behave differently.

212
00:08:50,700 --> 00:08:53,580
And you will have, and
we will see that later,

213
00:08:53,580 --> 00:08:56,910
you will have cases where,
oh, you will have plenty

214
00:08:56,910 --> 00:08:59,400
of cores in the same memory domain

215
00:08:59,400 --> 00:09:01,350
on a Graviton-based instance.

216
00:09:01,350 --> 00:09:03,600
Whereas, AMD has done a
totally different type

217
00:09:03,600 --> 00:09:07,050
of optimization, and you
have clusters of eight cores,

218
00:09:07,050 --> 00:09:09,060
it will have a different
performance profile

219
00:09:09,060 --> 00:09:11,310
when you access the
memory, will have an impact

220
00:09:11,310 --> 00:09:12,693
on your applications.

221
00:09:20,220 --> 00:09:24,000
- [Participant 2] So I
know within like vendors,

222
00:09:24,000 --> 00:09:26,280
server chips, they have different SKUs,

223
00:09:26,280 --> 00:09:29,190
and they have different
TDP and clock speeds,

224
00:09:29,190 --> 00:09:32,970
but you're saying that these EC2 VMs,

225
00:09:32,970 --> 00:09:36,060
like, the underlying hardware
is just a uniform SKU

226
00:09:36,060 --> 00:09:36,893
across the board.

227
00:09:36,893 --> 00:09:40,560
So there's no, like, I know
the lower core count tends

228
00:09:40,560 --> 00:09:43,890
to have like higher boost
frequency, and that sort of thing.

229
00:09:43,890 --> 00:09:47,340
But like, going lower core
count on these instance types

230
00:09:47,340 --> 00:09:49,380
will never yield a higher performance

231
00:09:49,380 --> 00:09:51,870
in like single-threaded
applications versus higher,

232
00:09:51,870 --> 00:09:54,153
'cause the underlying hardware's uniform.

233
00:09:55,740 --> 00:09:57,690
- [Arthur] Ah, as usual,

234
00:09:57,690 --> 00:10:02,100
it won't be a straightforward answer,

235
00:10:02,100 --> 00:10:07,050
but yes, a VM is a slice of a big server.

236
00:10:07,050 --> 00:10:11,640
So when you run on an EC2 instance,

237
00:10:11,640 --> 00:10:14,610
what you get is a slice of the big server.

238
00:10:14,610 --> 00:10:18,240
Internally, by the way, we call
those big servers droplets,

239
00:10:18,240 --> 00:10:20,763
because the cloud is made out of droplets.

240
00:10:21,780 --> 00:10:25,830
And so that big droplet is gonna have

241
00:10:25,830 --> 00:10:30,510
as many cores as the
biggest sizes in the family.

242
00:10:30,510 --> 00:10:33,483
So if I take the example of a C8g 48xl,

243
00:10:37,170 --> 00:10:39,180
that's gonna be a two socket server

244
00:10:39,180 --> 00:10:44,180
with two Graviton4 processors,
each having 96 cores.

245
00:10:44,760 --> 00:10:49,560
Now if you take a C8g.large,

246
00:10:49,560 --> 00:10:53,160
that's a two vCPU
instance, that's one slice

247
00:10:53,160 --> 00:10:58,083
of that two socket 192-core server.

248
00:11:00,510 --> 00:11:03,660
So in a sense, no, it's not,

249
00:11:03,660 --> 00:11:05,820
because you select small VMs

250
00:11:05,820 --> 00:11:09,000
that you will get a higher frequency,

251
00:11:09,000 --> 00:11:13,530
because they're taken as
slices of a bigger one.

252
00:11:13,530 --> 00:11:14,550
And those bigger ones,

253
00:11:14,550 --> 00:11:19,080
they have all the exact
same underlying processor.

254
00:11:19,080 --> 00:11:20,730
- [Participant 2] And within a generation

255
00:11:20,730 --> 00:11:22,560
and for a specific vendor,

256
00:11:22,560 --> 00:11:26,640
those droplets are
homogenous across the entire.

257
00:11:26,640 --> 00:11:28,193
- Yes.
- Okay.

258
00:11:30,450 --> 00:11:32,400
- [Arthur] Now that being said,

259
00:11:32,400 --> 00:11:37,400
we do have, if you really care
about super high frequency,

260
00:11:37,920 --> 00:11:41,820
we do have special instance
types like the R7iz.

261
00:11:44,310 --> 00:11:46,950
They're usually post fixed by Z,

262
00:11:46,950 --> 00:11:50,223
and those have been
designed for high frequency.

263
00:11:51,060 --> 00:11:54,033
So usually above four gigahertz.

264
00:11:55,320 --> 00:11:59,010
We used to have M5zn,

265
00:11:59,010 --> 00:12:02,460
that was one such instance, we had Z1d.

266
00:12:02,460 --> 00:12:03,780
They tend to be instances

267
00:12:03,780 --> 00:12:06,640
that we designed for things like EDA

268
00:12:07,620 --> 00:12:11,850
where getting the highest
possible single thread performance

269
00:12:11,850 --> 00:12:13,053
is very beneficial.

270
00:12:15,660 --> 00:12:17,110
- [Seth] Cool. Go next slide.

271
00:12:20,820 --> 00:12:22,260
- [Arthur] Yeah.

272
00:12:22,260 --> 00:12:25,710
So talking about type,
families, and processors.

273
00:12:25,710 --> 00:12:27,750
So we started talking a
little bit about that,

274
00:12:27,750 --> 00:12:31,270
but basically the, what we
call the general purpose

275
00:12:32,250 --> 00:12:34,950
regroups three different types.

276
00:12:34,950 --> 00:12:37,980
The T, so the T, they are
the burstable instances.

277
00:12:37,980 --> 00:12:42,150
So they are the only
type with the flex type

278
00:12:42,150 --> 00:12:45,090
of instances in AWS to be over committed.

279
00:12:45,090 --> 00:12:48,870
Meaning that on those
ones, we run more VMs

280
00:12:48,870 --> 00:12:53,193
and we sell more vCPUs than
there are actual physical cores.

281
00:12:54,900 --> 00:12:58,170
Great for costs, great when
you have an application

282
00:12:58,170 --> 00:13:02,700
that has a limited
performance requirement,

283
00:13:02,700 --> 00:13:04,530
but probably not good for anything

284
00:13:04,530 --> 00:13:07,020
where you really care about performance.

285
00:13:07,020 --> 00:13:08,280
M, we mentioned it.

286
00:13:08,280 --> 00:13:11,010
So those ones are not over committed.

287
00:13:11,010 --> 00:13:13,140
When I mean not over committed, it means

288
00:13:13,140 --> 00:13:15,450
that every time you get,

289
00:13:15,450 --> 00:13:19,440
let's say a two vCPU-based
instance, we've carved

290
00:13:19,440 --> 00:13:22,323
for you two vCPU on that instance.

291
00:13:23,573 --> 00:13:25,290
And we do it the right way, meaning

292
00:13:25,290 --> 00:13:29,100
that those allocations are static.

293
00:13:29,100 --> 00:13:31,470
The VMs, they are not floating around.

294
00:13:31,470 --> 00:13:35,490
When you get allocated two cores,

295
00:13:35,490 --> 00:13:37,260
you stay on those two cores.

296
00:13:37,260 --> 00:13:40,683
So when the cache is warm,
it's gonna stay warm for you.

297
00:13:41,610 --> 00:13:44,250
We never allocate anything
across the boundaries

298
00:13:44,250 --> 00:13:45,480
of a NUMA node.

299
00:13:45,480 --> 00:13:48,900
So you will never end
up on an AMD instance

300
00:13:48,900 --> 00:13:52,710
with four cores on one
CCX, four cores on another.

301
00:13:52,710 --> 00:13:55,770
It's always across the boundaries.

302
00:13:55,770 --> 00:14:00,770
So if you have a VM with 16
cores in seventh gen AMD,

303
00:14:02,190 --> 00:14:05,850
that's gonna span over two CCX,

304
00:14:05,850 --> 00:14:10,470
and we'll dig that a little bit later.

305
00:14:10,470 --> 00:14:14,173
Compute optimized, again, don't think

306
00:14:15,990 --> 00:14:18,270
that, because the name
says compute optimized,

307
00:14:18,270 --> 00:14:19,740
those processors are faster.

308
00:14:19,740 --> 00:14:23,370
It just means that, if what
you care the most about is

309
00:14:23,370 --> 00:14:26,790
having compute power,
and you don't care much

310
00:14:26,790 --> 00:14:29,520
about having a lot of
memory, that's what you need.

311
00:14:29,520 --> 00:14:33,420
Two gigabyte of memory per vCPU.

312
00:14:33,420 --> 00:14:35,730
Memory optimized, again, doesn't mean

313
00:14:35,730 --> 00:14:39,210
that the memory is faster, it
just means that you get more.

314
00:14:39,210 --> 00:14:43,500
So on an R instance type,
you get eight gigabytes

315
00:14:43,500 --> 00:14:47,400
of memory per core, that
can be much more than that.

316
00:14:47,400 --> 00:14:49,200
Peaks at 16.

317
00:14:49,200 --> 00:14:52,380
Z, well, there are few Z instances,

318
00:14:52,380 --> 00:14:56,643
but it happens that, that Z
at eight gigabyte of memory.

319
00:14:57,810 --> 00:15:02,220
Accelerated compute, that's
where you will get GPUs, FPGAs,

320
00:15:02,220 --> 00:15:04,590
and various other types of accelerators

321
00:15:04,590 --> 00:15:06,210
that we have introduced.

322
00:15:06,210 --> 00:15:10,380
Storage optimized means
that you get local disks

323
00:15:10,380 --> 00:15:12,420
that are physically inside the server

324
00:15:12,420 --> 00:15:14,550
and not the virtual disks that you have.

325
00:15:14,550 --> 00:15:16,380
Things like, like EBS.

326
00:15:16,380 --> 00:15:20,580
And HPC optimized, those are
very special instance types

327
00:15:20,580 --> 00:15:22,800
that are made out of the same hardware

328
00:15:22,800 --> 00:15:27,800
but have a special ring fencing mechanism

329
00:15:27,960 --> 00:15:29,433
for HPC application.

330
00:15:30,780 --> 00:15:33,000
Flex instances, you will see

331
00:15:33,000 --> 00:15:37,770
that some of the M and
the R instances exist

332
00:15:37,770 --> 00:15:42,770
as a flex version, that's
exactly the same hardware

333
00:15:42,840 --> 00:15:46,680
as the normal class
except we overcommit them,

334
00:15:46,680 --> 00:15:50,010
and we load balance them
so that most of the time,

335
00:15:50,010 --> 00:15:52,950
you will get 100% of the performance,

336
00:15:52,950 --> 00:15:56,520
but you can go down to
80% of the performance

337
00:15:56,520 --> 00:15:57,870
of the underlying hardware.

338
00:15:58,920 --> 00:16:03,180
Super convenient when you
are not super, super critical

339
00:16:03,180 --> 00:16:05,910
on the performance side, they're cheaper.

340
00:16:05,910 --> 00:16:08,130
But if you want perfect reproducibility

341
00:16:08,130 --> 00:16:11,080
on the performance side, then
probably they're not for you.

342
00:16:12,780 --> 00:16:16,080
- [Seth] Any questions on
this? And there's a lot here.

343
00:16:16,080 --> 00:16:17,550
- [Participant 3] Are they
similar to the T instances,

344
00:16:17,550 --> 00:16:19,063
the way you used to use?

345
00:16:20,153 --> 00:16:22,020
- [Arthur] They're better than the Ts

346
00:16:22,020 --> 00:16:24,300
in the sense that you
don't have that mechanism

347
00:16:24,300 --> 00:16:28,020
where you credit CPU cycles
and then you consume it,

348
00:16:28,020 --> 00:16:32,100
and then you reach a stage
where you are out of credits,

349
00:16:32,100 --> 00:16:35,220
and then we have that unlimited mode.

350
00:16:35,220 --> 00:16:40,220
It's a more steady type of utilization.

351
00:16:41,640 --> 00:16:44,370
So it's more predictable let's say.

352
00:16:44,370 --> 00:16:45,203
- [Participant 3] Because
I've been thinking

353
00:16:45,203 --> 00:16:47,730
about using the flex instances for things

354
00:16:47,730 --> 00:16:50,430
like the staging environment
and the development environment

355
00:16:50,430 --> 00:16:52,849
where, like, there's not a huge load.

356
00:16:52,849 --> 00:16:54,843
- Hm, yep.
- Totally makes sense.

357
00:16:55,890 --> 00:16:57,210
- Staging is a great,
- Yeah, yeah.

358
00:16:57,210 --> 00:16:58,660
- [Seth] Staging is a
great place for that.

359
00:16:58,660 --> 00:16:59,567
- [Participant 3] Okay, cool.

360
00:16:59,567 --> 00:17:01,260
- [Arthur] Now if you really wanna

361
00:17:01,260 --> 00:17:05,220
evaluate the maximum throughput
that you can get from an M,

362
00:17:05,220 --> 00:17:06,870
don't take the M flex.

363
00:17:06,870 --> 00:17:08,580
Sometimes you will get 100%,

364
00:17:08,580 --> 00:17:10,843
sometimes you will get only 80%.

365
00:17:10,843 --> 00:17:14,943
- I'll take %80.
- But for staging environment,

366
00:17:15,900 --> 00:17:17,730
when it's mostly functional tests

367
00:17:17,730 --> 00:17:20,733
that you're gonna do on them,
doesn't change anything.

368
00:17:24,109 --> 00:17:27,750
And when you know that only getting 80%

369
00:17:27,750 --> 00:17:31,290
of the max is sufficient for
you, that's also a great fit.

370
00:17:31,290 --> 00:17:32,790
- [Participant 3] Yeah, okay, cool.

371
00:17:32,790 --> 00:17:35,460
- [Arthur] And most of the time,
you will get more than 80%.

372
00:17:35,460 --> 00:17:37,020
- [Participant 3] And did
it work the same interface

373
00:17:37,020 --> 00:17:39,420
as like normal on demand?

374
00:17:39,420 --> 00:17:40,370
- Exactly
- Right.

375
00:17:41,520 --> 00:17:42,570
- [Arthur] Nothing changes, it's just

376
00:17:42,570 --> 00:17:45,600
like, you name it whatever-flex.

377
00:17:45,600 --> 00:17:48,420
And the biggest sizes are
not available as flex.

378
00:17:48,420 --> 00:17:49,313
- [Participant 3] Exactly.

379
00:17:50,520 --> 00:17:52,170
- Arthur, back here.
- Yep.

380
00:17:52,170 --> 00:17:54,416
- [Participant 4] So on a T instance

381
00:17:54,416 --> 00:17:59,416
with unlimited credit, do I
know when I'm being throttled

382
00:18:00,360 --> 00:18:02,610
and I'm not getting the full 100%,

383
00:18:02,610 --> 00:18:04,172
is that visible in any way?

384
00:18:04,172 --> 00:18:09,124
- [Arthur] Ah, yes it is,
but to be honest nowadays,

385
00:18:09,124 --> 00:18:12,030
don't use the T classes anymore.

386
00:18:12,030 --> 00:18:15,603
Like, unless you really do
things that are noncritical.

387
00:18:16,593 --> 00:18:19,893
Use the flex, they're a much,
much better proposition.

388
00:18:21,000 --> 00:18:22,283
- [Participant 4] Got it. Thank you.

389
00:18:27,540 --> 00:18:30,750
I guess kind of a similar
question for the flex instances,

390
00:18:30,750 --> 00:18:33,120
is there a way to know kind of where

391
00:18:33,120 --> 00:18:35,697
in that 80 to %100 your
workloads are getting?

392
00:18:35,697 --> 00:18:36,530
- No.
- Okay.

393
00:18:36,530 --> 00:18:37,969
So if you're being throttled-

394
00:18:37,969 --> 00:18:39,992
- [Arthur] You have to
trust us. (chuckles)

395
00:18:39,992 --> 00:18:41,040
- [Seth] There's a bottom though, right?

396
00:18:41,040 --> 00:18:42,200
- Yeah.
- There is a bottom though.

397
00:18:42,200 --> 00:18:43,893
- [Arthur] So what happens
behind the scene is

398
00:18:43,893 --> 00:18:46,890
that we are load balancing those instances

399
00:18:46,890 --> 00:18:48,750
with transparent migration.

400
00:18:48,750 --> 00:18:50,790
So we have a pretty
efficient mechanism to ensure

401
00:18:50,790 --> 00:18:55,320
that you're not all of a sudden
in a droplet that is so hot

402
00:18:55,320 --> 00:18:58,380
that you're down to 60%.

403
00:18:58,380 --> 00:19:00,783
We just transparently migrate things.

404
00:19:02,280 --> 00:19:06,060
- [Participant 4] Gotcha, cool.

405
00:19:06,060 --> 00:19:08,700
- [Arthur] And transparent
migration has been something

406
00:19:08,700 --> 00:19:12,060
that AWS has been shy to talk about.

407
00:19:12,060 --> 00:19:15,270
So we've been doing it
since quite a long time,

408
00:19:15,270 --> 00:19:18,600
mostly for reliability purposes.

409
00:19:18,600 --> 00:19:20,460
It's now in the EC2 FAQ,

410
00:19:20,460 --> 00:19:22,770
but we were doing it long time

411
00:19:22,770 --> 00:19:25,860
before it was in the FAQ.

412
00:19:25,860 --> 00:19:28,893
We don't expose it to
customers in the sense

413
00:19:28,893 --> 00:19:31,230
that you can't schedule the migration

414
00:19:31,230 --> 00:19:33,060
of one of your instances.

415
00:19:33,060 --> 00:19:34,830
But we use it a lot behind the scene,

416
00:19:34,830 --> 00:19:38,190
and it's a really reliable mechanism.

417
00:19:38,190 --> 00:19:39,120
- [Seth] I mean the way
to think about it is,

418
00:19:39,120 --> 00:19:42,540
an instance is a completely
virtual construct, right?

419
00:19:42,540 --> 00:19:45,040
It doesn't live in a place,
it lives in the cloud.

420
00:19:49,920 --> 00:19:52,770
- [Arthur] Okay, let's talk a little bit

421
00:19:52,770 --> 00:19:55,680
about what are the actual processors

422
00:19:55,680 --> 00:19:57,750
that are on those different instance type,

423
00:19:57,750 --> 00:20:01,560
and here I'm gonna mostly
focus on C, M, and R,

424
00:20:01,560 --> 00:20:04,743
and anyway, that's probably
90% of what you're using.

425
00:20:07,050 --> 00:20:09,720
So for those of you who are more familiar

426
00:20:09,720 --> 00:20:12,483
with the code names of
the different vendors,

427
00:20:13,410 --> 00:20:15,480
we often get the question
of, okay, what is

428
00:20:15,480 --> 00:20:18,693
behind your fifth gen,
sixth gen, whatever?

429
00:20:19,920 --> 00:20:24,660
So gen five, and another important thing

430
00:20:24,660 --> 00:20:27,120
when you're doing performance comparison,

431
00:20:27,120 --> 00:20:30,240
even though I would tell
you, like, use the latest,

432
00:20:30,240 --> 00:20:33,600
'cause that would probably
be the right thing to do.

433
00:20:33,600 --> 00:20:37,667
If you do comparison with
different processor types,

434
00:20:41,790 --> 00:20:46,743
there's kind of a generation gap.

435
00:20:48,665 --> 00:20:51,600
A Graviton gen six for
example would be comparable

436
00:20:51,600 --> 00:20:56,400
to an Intel or AMD gen five,
and it's true across the board.

437
00:20:56,400 --> 00:21:01,350
So gen six, that's comparable
to a Graviton gen seven.

438
00:21:01,350 --> 00:21:04,290
Gen seven Intel and AMD, that's comparable

439
00:21:04,290 --> 00:21:06,900
to a Graviton gen eight.

440
00:21:06,900 --> 00:21:09,270
And well, for the rest of the gen nine,

441
00:21:09,270 --> 00:21:10,770
Graviton is not yet there,

442
00:21:10,770 --> 00:21:12,420
but that will come at some point.

443
00:21:14,130 --> 00:21:17,040
So gen five on Intel and AMD.

444
00:21:17,040 --> 00:21:20,013
Intel, we had Sky Lake and Cascade Lake.

445
00:21:20,013 --> 00:21:24,150
That was a weird thing that
hopefully we won't do anymore.

446
00:21:24,150 --> 00:21:26,280
We introduced it with Sky Lake,

447
00:21:26,280 --> 00:21:29,850
and then we did a silent
refresh with Cascade Lake,

448
00:21:29,850 --> 00:21:32,550
and it had almost the
same performance profile,

449
00:21:32,550 --> 00:21:35,940
but in some cases the Cascade
Lake was a little faster.

450
00:21:35,940 --> 00:21:39,300
So that was a little weird for customers.

451
00:21:39,300 --> 00:21:41,100
We've not done it again.

452
00:21:41,100 --> 00:21:43,953
Customer complained, and we listened.

453
00:21:44,910 --> 00:21:47,043
AMD gen five was Rome,

454
00:21:48,480 --> 00:21:53,343
and on the Graviton side,
gen six was Graviton2.

455
00:21:54,630 --> 00:21:56,910
One recommendation I would have,

456
00:21:56,910 --> 00:21:59,100
don't use those any longer

457
00:21:59,100 --> 00:22:02,160
unless you're using them through Spot.

458
00:22:02,160 --> 00:22:03,900
The price performance ratio

459
00:22:03,900 --> 00:22:07,020
of those instances is no longer worth it.

460
00:22:07,020 --> 00:22:09,540
So switch to things that
are more recent than that,

461
00:22:09,540 --> 00:22:11,880
and you will get better performance.

462
00:22:11,880 --> 00:22:15,720
Gen six Intel and AMD is
priced exactly the same way

463
00:22:15,720 --> 00:22:18,030
as gen five, and it's faster.

464
00:22:18,030 --> 00:22:20,190
Not extremely faster but it's faster.

465
00:22:20,190 --> 00:22:22,320
So there's absolutely no good reason

466
00:22:22,320 --> 00:22:24,120
unless there's no capacity available

467
00:22:24,120 --> 00:22:27,690
to use gen five on Intel or AMD,

468
00:22:27,690 --> 00:22:31,413
or to use a Graviton2
on the Graviton side.

469
00:22:33,840 --> 00:22:37,710
Even gen six compared to what
we have released recently,

470
00:22:37,710 --> 00:22:40,470
I would say, they start to be old.

471
00:22:40,470 --> 00:22:42,690
Okay, we're cheaper than gen seven,

472
00:22:42,690 --> 00:22:45,420
but in terms of price performance ratio,

473
00:22:45,420 --> 00:22:49,500
you would be better off using
a gen seven or gen eight.

474
00:22:49,500 --> 00:22:52,200
So on the Intel side, that's an Ice Lake.

475
00:22:52,200 --> 00:22:54,840
On the AMD side, that's a Milan.

476
00:22:54,840 --> 00:22:58,743
And on the Graviton side,
seven gen is Graviton3.

477
00:23:01,200 --> 00:23:06,200
Now more recent, gen seven on
Intel is a Sapphire Rapids.

478
00:23:06,960 --> 00:23:11,250
Gen seven on AMD is a
Genoa, great processor.

479
00:23:11,250 --> 00:23:14,997
And on Graviton, that's a Graviton4.

480
00:23:15,870 --> 00:23:17,100
And then the latest

481
00:23:17,100 --> 00:23:19,410
that we have released
a couple of months ago,

482
00:23:19,410 --> 00:23:22,080
we have a Granite Rapids on the Intel side

483
00:23:22,080 --> 00:23:24,840
and we have a Turin on the AMD side.

484
00:23:24,840 --> 00:23:28,503
And Graviton, well, it's easy
to guess, and that will come.

485
00:23:29,820 --> 00:23:34,410
Couple of trends that we have
seen over the last years.

486
00:23:34,410 --> 00:23:37,863
The number of cores
per socket is going up.

487
00:23:38,700 --> 00:23:40,350
And that's true across the board.

488
00:23:40,350 --> 00:23:43,500
You've seen that on Intel,
you've seen that on AMD,

489
00:23:43,500 --> 00:23:47,190
you've seen that on Graviton,
and that won't stop.

490
00:23:47,190 --> 00:23:49,380
That's gonna be true
for the next generation

491
00:23:49,380 --> 00:23:52,890
of the various instance type.

492
00:23:52,890 --> 00:23:56,133
The dollar per vCPU is also increasing.

493
00:23:57,570 --> 00:24:01,080
The manufacturing technology,
the memory technology,

494
00:24:01,080 --> 00:24:03,090
all of that is more expensive.

495
00:24:03,090 --> 00:24:06,153
So the price on a per
vCPU basis has gone up.

496
00:24:07,140 --> 00:24:10,140
That being said, the dollar per amount

497
00:24:10,140 --> 00:24:12,630
of performance has decreased,

498
00:24:12,630 --> 00:24:15,540
because the performance has increased.

499
00:24:15,540 --> 00:24:20,160
So even though on a per vCPU
basis it's more expensive,

500
00:24:20,160 --> 00:24:23,610
if your application actually
benefits from the performance

501
00:24:23,610 --> 00:24:26,043
of the processor, you
get a better value prop.

502
00:24:27,630 --> 00:24:32,220
The power consumption per unit
of work has also decreased.

503
00:24:32,220 --> 00:24:36,090
So if you wanna be a
little bit less intensive

504
00:24:36,090 --> 00:24:38,130
from a power consumption standpoint

505
00:24:38,130 --> 00:24:40,920
and be a better planet citizen,

506
00:24:40,920 --> 00:24:43,860
you'd better use the latest
generation of instances.

507
00:24:43,860 --> 00:24:45,450
They're a little bit better in-

508
00:24:45,450 --> 00:24:46,980
- [Seth] Does anybody
have sustainability goals

509
00:24:46,980 --> 00:24:47,910
in an organization?

510
00:24:47,910 --> 00:24:49,530
Show of hands.

511
00:24:49,530 --> 00:24:52,320
Yeah, the Graviton and taking advantage

512
00:24:52,320 --> 00:24:54,820
of latest processors will
help with a lot of that.

513
00:24:57,330 --> 00:24:59,460
- [Arthur] Another trend that we've seen,

514
00:24:59,460 --> 00:25:03,030
and we'll see how that will evolve, is

515
00:25:03,030 --> 00:25:05,580
that some of our processors were

516
00:25:05,580 --> 00:25:08,430
using simultaneous multithreading.

517
00:25:08,430 --> 00:25:13,350
So the ability to use two
or more thread of execution

518
00:25:13,350 --> 00:25:16,860
per physical core, some of ours do not.

519
00:25:16,860 --> 00:25:18,840
And that has an impact on the performance

520
00:25:18,840 --> 00:25:20,550
and how you measure the performance.

521
00:25:20,550 --> 00:25:25,200
And we'll see that a little bit deeper

522
00:25:25,200 --> 00:25:26,500
later in the presentation.

523
00:25:29,400 --> 00:25:30,723
So couple of things.

524
00:25:31,590 --> 00:25:33,390
Oh well, can we get that?
- Let me pause for questions.

525
00:25:33,390 --> 00:25:35,283
What questions, where can we go next?

526
00:25:38,880 --> 00:25:42,030
Everyone's gonna be quiet
today. It's the first day.

527
00:25:42,030 --> 00:25:44,553
Everyone should be
excited and not tired yet.

528
00:25:45,918 --> 00:25:47,658
Here we go, down in front.
- Okay, so a couple of things

529
00:25:47,658 --> 00:25:48,491
about the virtualization stack.

530
00:25:48,491 --> 00:25:50,243
- [Seth] Hang on, Arthur, we
got a question right here.

531
00:25:52,710 --> 00:25:55,290
- [Participant 5] Are all of the families

532
00:25:55,290 --> 00:25:57,927
that we've been discussing
available in Spot instances,

533
00:25:57,927 --> 00:26:02,010
and where does the Sapphire
Rapids name come from?

534
00:26:02,010 --> 00:26:06,600
- [Arthur] Ah, so they
were all available as Spot

535
00:26:06,600 --> 00:26:08,940
right from the beginning.

536
00:26:08,940 --> 00:26:12,690
So when we released Spot,
the Spot market is enabled,

537
00:26:12,690 --> 00:26:17,690
but the question is not so
much, are they technically

538
00:26:19,770 --> 00:26:24,570
available as Spot, as much
as, is the capacity sufficient

539
00:26:24,570 --> 00:26:27,270
for a healthy Spot market?

540
00:26:27,270 --> 00:26:28,650
'Cause when we release

541
00:26:28,650 --> 00:26:32,820
and some of those things
are very successful,

542
00:26:32,820 --> 00:26:34,680
start from the release,

543
00:26:34,680 --> 00:26:36,720
and customers are massively moving

544
00:26:36,720 --> 00:26:38,670
over to the new generations,

545
00:26:38,670 --> 00:26:41,550
there might be very
little capacity for Spots.

546
00:26:41,550 --> 00:26:45,780
So before you get a healthy Spot market,

547
00:26:45,780 --> 00:26:48,150
usually it takes a couple of weeks.

548
00:26:48,150 --> 00:26:50,553
More realistically a couple of month.

549
00:26:51,480 --> 00:26:53,730
Though, I would say that in general,

550
00:26:53,730 --> 00:26:56,430
the very early adopters of new generations

551
00:26:56,430 --> 00:27:00,900
or the Spot customers who have core,

552
00:27:00,900 --> 00:27:03,417
usually the Spot customers using Karpenter

553
00:27:03,417 --> 00:27:06,030
are the very early adopters,

554
00:27:06,030 --> 00:27:09,450
because when you use
an allocation mechanism

555
00:27:09,450 --> 00:27:12,720
with Karpenter saying I
want everything starting

556
00:27:12,720 --> 00:27:16,080
from generation X, the day we release

557
00:27:16,080 --> 00:27:18,540
before any on demand customer has started

558
00:27:18,540 --> 00:27:22,530
to use those instances,
boom, you're using it.

559
00:27:22,530 --> 00:27:25,320
And the price is low and
the performance is great.

560
00:27:25,320 --> 00:27:28,410
And then the on demand
customers started to switch,

561
00:27:28,410 --> 00:27:31,200
and then the Spot market
kind of disappears

562
00:27:31,200 --> 00:27:34,590
for a couple of weeks until
we launch enough capacity

563
00:27:34,590 --> 00:27:37,623
that you start to have
a healthy Spot market.

564
00:27:38,700 --> 00:27:42,183
Now about your second question,
the code names from Intel.

565
00:27:43,590 --> 00:27:46,560
I think that most of the
code names are coming

566
00:27:46,560 --> 00:27:51,270
from rivers and lakes
in the Washington state.

567
00:27:51,270 --> 00:27:52,920
That used to be true for sure.

568
00:27:52,920 --> 00:27:55,470
Nowadays, I don't know,
'cause I don't remember

569
00:27:55,470 --> 00:27:58,980
whether there's a Sapphire
Rapids anywhere in Washington.

570
00:27:58,980 --> 00:28:03,980
I moved like, I was in
Seattle until six months ago,

571
00:28:04,650 --> 00:28:07,890
and I've never seen
any Sapphire Rapids so.

572
00:28:07,890 --> 00:28:08,730
- [Seth] Our processor names,

573
00:28:08,730 --> 00:28:11,420
a little bit more straightforward,
Graviton 1, 2, 3, 4.

574
00:28:11,420 --> 00:28:14,670
Pretty easy to track and
you know where it came from.

575
00:28:14,670 --> 00:28:16,133
You got another question here.

576
00:28:17,700 --> 00:28:19,320
- [Participant 6] Real quick,
a reply to what you just said,

577
00:28:19,320 --> 00:28:22,260
but why is Graviton2 generation five?

578
00:28:22,260 --> 00:28:24,480
- [Seth] Ah, gosh.
(all laughing)

579
00:28:24,480 --> 00:28:25,313
Great question.

580
00:28:25,313 --> 00:28:26,250
- [Arthur] Because there was no Graviton

581
00:28:26,250 --> 00:28:28,260
when we released the first generation

582
00:28:28,260 --> 00:28:30,300
of EC2-based instances.

583
00:28:30,300 --> 00:28:32,850
And don't ask me why the first generation

584
00:28:32,850 --> 00:28:35,943
of Graviton-based instances was called A1,

585
00:28:37,440 --> 00:28:40,890
because that was our first Arm processor.

586
00:28:40,890 --> 00:28:43,020
And maybe at that time, we had the idea

587
00:28:43,020 --> 00:28:45,900
that we would call the next one A2,

588
00:28:45,900 --> 00:28:47,160
but we never did that.

589
00:28:47,160 --> 00:28:50,460
And we had A1, which was
a porting the I call,

590
00:28:50,460 --> 00:28:53,880
and then the next gen, we had C, M, and R,

591
00:28:53,880 --> 00:28:58,880
that were C6g, and M6g and R6g.

592
00:28:59,580 --> 00:29:02,280
Like honestly, I would not want

593
00:29:02,280 --> 00:29:06,420
to be the one within the
EC2 product management team

594
00:29:06,420 --> 00:29:09,750
having the responsibility
to name the instances,

595
00:29:09,750 --> 00:29:12,480
'cause however you choose to do it,

596
00:29:12,480 --> 00:29:14,013
you'll screw up at some point.

597
00:29:16,200 --> 00:29:18,510
- [Participant 6] And then
my other question was,

598
00:29:18,510 --> 00:29:21,810
so you said that as generations increase,

599
00:29:21,810 --> 00:29:23,367
the price per vCPU goes up,

600
00:29:23,367 --> 00:29:27,360
but the price per performance goes down.

601
00:29:27,360 --> 00:29:30,030
How do you, is there any methodology

602
00:29:30,030 --> 00:29:35,030
for like, evaluating
whether you'll save money

603
00:29:35,370 --> 00:29:36,900
going to a new generation?

604
00:29:36,900 --> 00:29:39,120
Like, if you're on a eight core workload,

605
00:29:39,120 --> 00:29:41,100
you have to go down to four cores

606
00:29:41,100 --> 00:29:45,030
in order to decrease your price, right?

607
00:29:45,030 --> 00:29:46,440
- [Arthur] Hm, it depends.

608
00:29:46,440 --> 00:29:50,760
If your application is really
running on a single instance,

609
00:29:50,760 --> 00:29:52,500
yes, that would be a problem.

610
00:29:52,500 --> 00:29:56,280
And there's the trick where
if the performance goes up,

611
00:29:56,280 --> 00:30:00,270
'cause usually, you have
multiple parameters.

612
00:30:00,270 --> 00:30:02,010
It's not only the performance of the CPU,

613
00:30:02,010 --> 00:30:05,280
but it's also okay, I might
really need that amount

614
00:30:05,280 --> 00:30:08,340
of memory for my workload,
and I also need that amount

615
00:30:08,340 --> 00:30:10,710
of network for my workload.

616
00:30:10,710 --> 00:30:13,590
So if network is really
not the bottleneck,

617
00:30:13,590 --> 00:30:16,380
potentially you can go to, you are on a C,

618
00:30:16,380 --> 00:30:20,760
you can go to an M with
half the number of cores,

619
00:30:20,760 --> 00:30:24,090
and maybe that's a sweet
spot for your application.

620
00:30:24,090 --> 00:30:28,590
But more often than that, you
might have a pool of servers,

621
00:30:28,590 --> 00:30:31,890
a pool of web servers that
are serving a given workload,

622
00:30:31,890 --> 00:30:36,810
and you are using, you
have a certain number

623
00:30:37,650 --> 00:30:39,240
of requests that you have to serve

624
00:30:39,240 --> 00:30:41,640
coming from your customers
and it's fluctuating.

625
00:30:41,640 --> 00:30:44,640
And let's say that, on
average, you're using a hundred

626
00:30:44,640 --> 00:30:45,990
of the servers.

627
00:30:45,990 --> 00:30:48,450
Well if you have one that is faster,

628
00:30:48,450 --> 00:30:51,870
now maybe, on average, you
will be using 80 of them.

629
00:30:51,870 --> 00:30:55,500
So they are more expensive
on a per instance basis,

630
00:30:55,500 --> 00:30:59,220
but you're using less of them,
and it doesn't need to be,

631
00:30:59,220 --> 00:31:02,550
I need to be able to use half the size.

632
00:31:02,550 --> 00:31:04,230
- [Seth] And don't worry, the idea is not

633
00:31:04,230 --> 00:31:07,320
to necessarily worry about
the CPU load on your machines.

634
00:31:07,320 --> 00:31:10,530
Worry about how much, what is
the API request per second?

635
00:31:10,530 --> 00:31:13,740
What is the business measurement
of that instance, right?

636
00:31:13,740 --> 00:31:15,600
The throughput of the instance.

637
00:31:15,600 --> 00:31:17,630
And if that increase,
and you test it, right?

638
00:31:17,630 --> 00:31:18,600
If that goes up,

639
00:31:18,600 --> 00:31:20,100
then you're getting that
price performance metric.

640
00:31:20,100 --> 00:31:25,100
- [Arthur] Now if you have
that single server, only one,

641
00:31:25,110 --> 00:31:28,050
and there's no way you
can distribute that,

642
00:31:28,050 --> 00:31:30,660
then you're right, you
get better performance,

643
00:31:30,660 --> 00:31:31,680
but you pay more.

644
00:31:32,790 --> 00:31:34,770
- [Participant 7] So I've got
a question about Spot markets

645
00:31:34,770 --> 00:31:35,940
and like the health of them.

646
00:31:35,940 --> 00:31:37,470
At what point do you guys start

647
00:31:37,470 --> 00:31:38,850
tearing old server racks out?

648
00:31:38,850 --> 00:31:40,200
I run a lot of bioinformatics workloads.

649
00:31:40,200 --> 00:31:41,937
They need boxes and memory,

650
00:31:41,937 --> 00:31:43,860
but they don't really care about speed.

651
00:31:43,860 --> 00:31:46,590
I've got everything
going back to like M4s.

652
00:31:46,590 --> 00:31:48,270
Is there a point where
like there's a deprecation,

653
00:31:48,270 --> 00:31:49,770
stop using these, we're
gonna start tearing 'em out.

654
00:31:49,770 --> 00:31:51,240
- [Arthur] So if you're running,

655
00:31:51,240 --> 00:31:53,490
if you have things running on an M4,

656
00:31:53,490 --> 00:31:57,690
it's probably no longer
running on M4 hardware.

657
00:31:57,690 --> 00:31:59,770
It's now running on Xenon Nitro

658
00:32:00,660 --> 00:32:03,300
where we emulate our previous generation

659
00:32:03,300 --> 00:32:07,140
of virtualization system,
and we make you believe

660
00:32:07,140 --> 00:32:08,995
that you're still running on an M4.

661
00:32:08,995 --> 00:32:10,618
(audience laughs)
And it-

662
00:32:10,618 --> 00:32:12,210
- It works.
- It works.

663
00:32:12,210 --> 00:32:14,520
And if you're in a company

664
00:32:14,520 --> 00:32:16,770
where you had to validate that software

665
00:32:16,770 --> 00:32:18,390
with that specific piece of hardware,

666
00:32:18,390 --> 00:32:20,610
it still worked the same way.

667
00:32:20,610 --> 00:32:22,993
But on our side, it's
probably no longer an M4.

668
00:32:23,857 --> 00:32:28,050
So we try as much as possible
not to retire instances

669
00:32:28,050 --> 00:32:29,850
for customers who need them.

670
00:32:29,850 --> 00:32:34,500
So there are accounts where
you can still launch an M2,

671
00:32:34,500 --> 00:32:37,170
but that's no longer a real M2.

672
00:32:37,170 --> 00:32:39,210
Now from a price performance standpoint,

673
00:32:39,210 --> 00:32:41,760
don't run on anything that old,

674
00:32:41,760 --> 00:32:43,690
'cause it makes absolutely no sense

675
00:32:44,790 --> 00:32:46,260
from a price performance standpoint.

676
00:32:46,260 --> 00:32:50,853
There are other reasons to
do it, but otherwise, yeah,

677
00:32:52,530 --> 00:32:54,900
I don't think we ever, well, we did,

678
00:32:54,900 --> 00:32:59,190
but for some specific instances
like old GPU instances

679
00:32:59,190 --> 00:33:01,920
where we can't emulate that,

680
00:33:01,920 --> 00:33:05,100
and we could no longer
maintain the hardware,

681
00:33:05,100 --> 00:33:07,320
and then we have retired those instances.

682
00:33:07,320 --> 00:33:09,420
But in general, we do our best

683
00:33:09,420 --> 00:33:13,263
to make them available
for as long as we can.

684
00:33:15,090 --> 00:33:17,970
- Question back here.
- One question.

685
00:33:17,970 --> 00:33:22,050
You mentioned about the price
for the latest instance type,

686
00:33:22,050 --> 00:33:23,910
the price would be lower, right?

687
00:33:23,910 --> 00:33:26,370
But one observation I made is,

688
00:33:26,370 --> 00:33:28,500
when you're going with
the reserved instances,

689
00:33:28,500 --> 00:33:32,373
I saw the older generation
are much cheaper.

690
00:33:34,882 --> 00:33:36,540
- [Arthur] So I think what you mentioned

691
00:33:36,540 --> 00:33:39,960
is very, very true for RDS

692
00:33:39,960 --> 00:33:42,460
where they change their
pricing model for the RIs.

693
00:33:44,323 --> 00:33:46,644
I don't think I've seen that for EC2.

694
00:33:46,644 --> 00:33:49,020
- [Participant 8] My
experience, EC2 instance,

695
00:33:49,020 --> 00:33:51,120
also I observed that.
- Okay, it's possible.

696
00:33:51,120 --> 00:33:52,950
And we've been trying also

697
00:33:52,950 --> 00:33:57,120
to shift customers away from
RIs, and to saving plans.

698
00:33:57,120 --> 00:33:59,250
So what I mentioned in terms

699
00:33:59,250 --> 00:34:03,000
of pricing was applying
specifically to on demand,

700
00:34:03,000 --> 00:34:04,080
the way we've chosen

701
00:34:04,080 --> 00:34:06,510
to price those long-term commitment

702
00:34:06,510 --> 00:34:08,400
can be a little different.

703
00:34:08,400 --> 00:34:10,373
- [Participant 8] So the second question,

704
00:34:11,250 --> 00:34:13,290
all the instance types are like, one CPU,

705
00:34:13,290 --> 00:34:16,803
like, memory and CPU are
strictly restricted, right?

706
00:34:17,670 --> 00:34:20,880
Is there any plan for
AWS to, you know, change?

707
00:34:20,880 --> 00:34:23,880
I can select the memory, CPU will be like,

708
00:34:23,880 --> 00:34:26,190
let's say two memory,
could be four or eight.

709
00:34:26,190 --> 00:34:28,088
- [Arthur] The same way as GCP does it.

710
00:34:28,088 --> 00:34:30,491
Not that I would be aware.

711
00:34:30,491 --> 00:34:31,770
- [Participant 8] Okay, thank you.

712
00:34:31,770 --> 00:34:33,780
- [Arthur] But we offer
more diversity also.

713
00:34:33,780 --> 00:34:36,840
It's like, it's the two
ways to handle that problem.

714
00:34:36,840 --> 00:34:39,840
It's either you have a very small number,

715
00:34:39,840 --> 00:34:43,740
and then you make that, you can go custom,

716
00:34:43,740 --> 00:34:46,890
or you offer a lot of
different combinations.

717
00:34:46,890 --> 00:34:51,390
And I believe that we
cover a very broad number

718
00:34:51,390 --> 00:34:53,160
of possible combination.

719
00:34:53,160 --> 00:34:55,770
If there's something that
is really, really missing,

720
00:34:55,770 --> 00:34:57,660
please let your account team know.

721
00:34:57,660 --> 00:34:59,730
We have a mechanism called PFRs

722
00:34:59,730 --> 00:35:03,690
where we signal our teams that, well,

723
00:35:03,690 --> 00:35:05,700
there might be that thing that is missing.

724
00:35:05,700 --> 00:35:07,650
And if we feel like the demand

725
00:35:07,650 --> 00:35:10,140
for that is big enough,
we might just do it.

726
00:35:10,140 --> 00:35:11,340
- [Seth] My understanding is they may be

727
00:35:11,340 --> 00:35:12,570
moving away from that, by the way.

728
00:35:12,570 --> 00:35:15,690
So keep that in mind.
I can't confirm this.

729
00:35:15,690 --> 00:35:17,160
They may be moving away from that,

730
00:35:17,160 --> 00:35:20,760
that choose your own
instance configuration.

731
00:35:20,760 --> 00:35:23,010
It's a challenge to
maintain for sure, right?

732
00:35:23,010 --> 00:35:26,910
But with over 950 instances,
my hunch is you can

733
00:35:26,910 --> 00:35:29,570
find something that meets your needs

734
00:35:29,570 --> 00:35:31,080
within our existing portfolio.

735
00:35:31,080 --> 00:35:33,000
- [Arthur] At the end of the
day, it's where we choose

736
00:35:33,000 --> 00:35:34,380
to expose the complexity.

737
00:35:34,380 --> 00:35:38,310
If we decide to expose
that level of flexibility,

738
00:35:38,310 --> 00:35:40,290
it means that we add some complexity

739
00:35:40,290 --> 00:35:43,890
in the way we carve the instances
on the physical hardware,

740
00:35:43,890 --> 00:35:46,890
'cause the physical
hardware, well, is fixed.

741
00:35:46,890 --> 00:35:50,130
So it's really where
we put the complexity.

742
00:35:50,130 --> 00:35:52,330
So far we have chosen
to put the complexity

743
00:35:54,073 --> 00:35:57,810
on you in some way where
we offer fixed sizes,

744
00:35:57,810 --> 00:35:59,070
we offer plenty of them.

745
00:35:59,070 --> 00:36:01,233
And you choose among those.

746
00:36:04,440 --> 00:36:06,270
- I have two questions.
- Sure.

747
00:36:06,270 --> 00:36:07,950
- [Participant 9] First
one, you mentioned,

748
00:36:07,950 --> 00:36:12,030
socket count is to the maximum?

749
00:36:12,030 --> 00:36:17,030
- [Arthur] No, on Intel-based
X class instances,

750
00:36:17,490 --> 00:36:19,110
you have four sockets

751
00:36:19,110 --> 00:36:23,010
and on U class that are very specific,

752
00:36:23,010 --> 00:36:24,870
you can't get them on demand,

753
00:36:24,870 --> 00:36:27,810
and they're mainly targeted for SAP,

754
00:36:27,810 --> 00:36:29,703
you can get up to eight sockets.

755
00:36:31,071 --> 00:36:32,100
- [Participant 9] The other question is

756
00:36:32,100 --> 00:36:35,250
around hyperthreading, and if
you're gonna talk about it,

757
00:36:35,250 --> 00:36:37,440
you can wait when you get there.

758
00:36:37,440 --> 00:36:39,790
But I've always wondered about Intel

759
00:36:40,844 --> 00:36:43,140
with hyperthreading
turned on, for example,

760
00:36:43,140 --> 00:36:46,260
a simple example, two vCPU

761
00:36:46,260 --> 00:36:48,630
with Intel hyperthreading turned on

762
00:36:48,630 --> 00:36:51,450
and AMD which doesn't have
hyperthreading turned on.

763
00:36:51,450 --> 00:36:54,180
- [Arthur] So I'm gonna talk
specifically about that,

764
00:36:54,180 --> 00:36:55,803
and I will show you how to know.

765
00:36:57,240 --> 00:37:00,903
- Thanks.
- Down here.

766
00:37:08,130 --> 00:37:12,180
- [Participant 10] Hi,
without increasing the vCPUs

767
00:37:12,180 --> 00:37:14,670
and moving on from the previous generation

768
00:37:14,670 --> 00:37:16,260
to the new generation,

769
00:37:16,260 --> 00:37:18,410
how come the performance
is getting better?

770
00:37:20,340 --> 00:37:22,260
- [Arthur] How is the performance better

771
00:37:22,260 --> 00:37:24,300
going from one gen to the next one?

772
00:37:24,300 --> 00:37:25,133
- [Participant 10] Yeah.

773
00:37:25,133 --> 00:37:28,650
- [Arthur] Oh that's, because
for all those vendors,

774
00:37:28,650 --> 00:37:32,280
we're improving the way
those CPUs are designed.

775
00:37:32,280 --> 00:37:34,860
So there are plenty of
ways you can do that.

776
00:37:34,860 --> 00:37:38,550
Gen over gen, there's
usually bigger caches,

777
00:37:38,550 --> 00:37:43,500
and that's true at, L1
has been pretty much fixed

778
00:37:43,500 --> 00:37:45,120
on the latest generations,

779
00:37:45,120 --> 00:37:47,850
but L2 has grown, L3 has grown.

780
00:37:47,850 --> 00:37:51,960
You have massive L3 cache
on the latest generation

781
00:37:51,960 --> 00:37:53,370
of Intel and AMD.

782
00:37:53,370 --> 00:37:56,610
So that helps a lot when
dealing with memory accesses

783
00:37:56,610 --> 00:37:59,790
and making your workloads usually faster.

784
00:37:59,790 --> 00:38:02,890
And other area that can be improved is

785
00:38:05,760 --> 00:38:08,760
changing the way the branch
predictor is working.

786
00:38:08,760 --> 00:38:12,720
Same thing, plenty of applications
that are super sensitive

787
00:38:12,720 --> 00:38:16,920
to how the CPU is able to
predict what is the next set

788
00:38:16,920 --> 00:38:20,400
of branches that your
code is gonna go through.

789
00:38:20,400 --> 00:38:21,813
So it's a combination.

790
00:38:23,701 --> 00:38:26,190
The memory network has also improved,

791
00:38:26,190 --> 00:38:29,040
becoming more scalable.

792
00:38:29,040 --> 00:38:33,990
The memory latency has stayed
pretty much at the same level,

793
00:38:33,990 --> 00:38:37,053
but the memory bandwidth
has increased massively.

794
00:38:38,220 --> 00:38:41,130
On gen five intel,

795
00:38:41,130 --> 00:38:44,730
if I remember well you
had four memory channels.

796
00:38:44,730 --> 00:38:47,463
Latest generation has
eight memory channel.

797
00:38:48,630 --> 00:38:51,477
Latest generation of AMD-based instances

798
00:38:51,477 --> 00:38:53,223
has 12 memory channels.

799
00:38:55,650 --> 00:38:58,500
By improving those different
areas in the processor,

800
00:38:58,500 --> 00:39:01,050
you make them better and faster.

801
00:39:01,050 --> 00:39:02,880
- [Participant 10] Okay,
let's say if I have,

802
00:39:02,880 --> 00:39:06,240
if my application has any
performance issues instead

803
00:39:06,240 --> 00:39:09,857
of just throwing more CPU
into there, you want me to,

804
00:39:11,139 --> 00:39:12,813
it always helps or not?

805
00:39:14,160 --> 00:39:17,340
- [Arthur] Giving more CPU to
an application is not always

806
00:39:17,340 --> 00:39:19,050
going to make it faster.

807
00:39:19,050 --> 00:39:21,960
'cause to benefit from
more vCPUs, you need

808
00:39:21,960 --> 00:39:24,933
to have an application that
has some level of parallelism.

809
00:39:26,070 --> 00:39:29,490
So if it is able to use multiple CPU,

810
00:39:29,490 --> 00:39:32,130
that's gonna potentially make it faster,

811
00:39:32,130 --> 00:39:33,840
up to a certain level,

812
00:39:33,840 --> 00:39:38,520
'cause you never or almost never have 100%

813
00:39:38,520 --> 00:39:41,040
of your application that
can be parallelized.

814
00:39:41,040 --> 00:39:43,620
So there's probably
part of that application

815
00:39:43,620 --> 00:39:45,870
that is still sequential,
and you won't be able

816
00:39:45,870 --> 00:39:48,600
to accelerate that to the infinite.

817
00:39:48,600 --> 00:39:51,120
One other thing that
I've forgot to mention

818
00:39:51,120 --> 00:39:53,400
about how processors have improved,

819
00:39:53,400 --> 00:39:56,460
they've also improved
in the way that we're,

820
00:39:56,460 --> 00:39:59,223
in how many instructions
they can execute in parallel.

821
00:40:00,240 --> 00:40:02,550
Many people have a mental
model of a processor

822
00:40:02,550 --> 00:40:05,610
of at every cycle you do one thing.

823
00:40:05,610 --> 00:40:08,820
But modern CPU, they do plenty
of things at every cycle.

824
00:40:08,820 --> 00:40:11,640
They do memory loads and
stores, they do addition,

825
00:40:11,640 --> 00:40:15,570
they do multiplication, and
you can, on some processor,

826
00:40:15,570 --> 00:40:17,883
do up to six instructions per cycle.

827
00:40:18,750 --> 00:40:22,590
And some applications are
built and optimized in a way

828
00:40:22,590 --> 00:40:26,760
where they can only extract a
couple instructions per cycle

829
00:40:26,760 --> 00:40:28,080
from a given processor.

830
00:40:28,080 --> 00:40:32,670
And unless you
significantly optimize them,

831
00:40:32,670 --> 00:40:36,300
they're actually under utilizing the CPU.

832
00:40:36,300 --> 00:40:41,300
So there's not a straightforward
answer to your question.

833
00:40:41,820 --> 00:40:46,203
It requires more analysis
and lower level optimization.

834
00:40:47,070 --> 00:40:50,223
- Thank you.
- Okay, let's move on.

835
00:40:52,710 --> 00:40:57,710
So one thing that, well, now most

836
00:40:58,440 --> 00:41:00,810
of our instances are using
the latest generation

837
00:41:00,810 --> 00:41:02,910
of our virtualization stack,

838
00:41:02,910 --> 00:41:06,690
but when we moved from
fourth to fifth gen,

839
00:41:06,690 --> 00:41:09,060
we've changed the way
we do virtualization.

840
00:41:09,060 --> 00:41:10,893
We moved from Xen to Nitro.

841
00:41:12,270 --> 00:41:14,550
This definitely has an
impact on the performance,

842
00:41:14,550 --> 00:41:16,380
'cause we've uploaded a bunch

843
00:41:16,380 --> 00:41:21,270
of the virtualization primitives
to dedicated hardware.

844
00:41:21,270 --> 00:41:25,290
So it has lowered the noise
of the virtualization system.

845
00:41:25,290 --> 00:41:28,230
So even, you could not
really do the comparison,

846
00:41:28,230 --> 00:41:32,700
because we never exposed the
two virtualization system

847
00:41:32,700 --> 00:41:34,530
on top of the same processor.

848
00:41:34,530 --> 00:41:36,660
But there was a significant gain

849
00:41:36,660 --> 00:41:40,113
when moving to the Nitro
virtualization stack.

850
00:41:41,010 --> 00:41:44,460
It also reduced the
noisy neighborhood effect

851
00:41:44,460 --> 00:41:46,410
that you could get from
the previous system

852
00:41:46,410 --> 00:41:51,410
with almost no noisy
neighborhood problems with Nitro,

853
00:41:51,900 --> 00:41:53,853
except at the memory bandwidth level.

854
00:41:55,680 --> 00:41:58,200
There's another thing
that Nitro made possible,

855
00:41:58,200 --> 00:42:00,630
which is bare metal instances,

856
00:42:00,630 --> 00:42:03,900
because we've moved all the
virtualization primitives

857
00:42:03,900 --> 00:42:05,070
outside of the instance.

858
00:42:05,070 --> 00:42:10,070
So everything with regards
to network access to EBS,

859
00:42:11,427 --> 00:42:13,200
and all of that, is uploaded.

860
00:42:13,200 --> 00:42:15,920
So there's nothing that
we really need to do

861
00:42:15,920 --> 00:42:19,080
at the hypervisor level
from a security standpoint.

862
00:42:19,080 --> 00:42:21,990
So we can offer instances
as a metal option

863
00:42:21,990 --> 00:42:24,060
where we remove the hypervisor

864
00:42:24,060 --> 00:42:26,910
and you get full control over the CPU.

865
00:42:26,910 --> 00:42:29,650
The drawback of that is we only offer them

866
00:42:30,870 --> 00:42:35,310
as full instances, so they
do not come in small chunks.

867
00:42:35,310 --> 00:42:37,500
But in some cases, if you need

868
00:42:37,500 --> 00:42:40,170
to get full control over
the processor, it's possible

869
00:42:40,170 --> 00:42:41,820
with the metal instances.

870
00:42:41,820 --> 00:42:43,260
From a performance standpoint,

871
00:42:43,260 --> 00:42:46,590
don't expect the metal
instances for normal workloads

872
00:42:46,590 --> 00:42:47,733
to be faster.

873
00:42:49,628 --> 00:42:52,410
The level of performance
penalty introduced

874
00:42:52,410 --> 00:42:57,410
by the Nitro hypervisor
is extremely limited.

875
00:42:57,540 --> 00:43:00,030
There's a little bit of an impact

876
00:43:00,030 --> 00:43:03,630
for people having very,
very strong requirement

877
00:43:03,630 --> 00:43:05,250
at the network level.

878
00:43:05,250 --> 00:43:08,940
So people doing high
frequency trading for example,

879
00:43:08,940 --> 00:43:10,860
you'll see a difference.

880
00:43:10,860 --> 00:43:14,700
But for normal people doing
normal web application,

881
00:43:14,700 --> 00:43:18,330
databases, there's absolutely
no point in going to metal

882
00:43:18,330 --> 00:43:20,040
unless you need for other reasons

883
00:43:20,040 --> 00:43:22,890
to run your own virtualization system.

884
00:43:22,890 --> 00:43:26,070
But that becomes more of
a functional requirement

885
00:43:26,070 --> 00:43:28,170
and not so much a performance requirement.

886
00:43:34,350 --> 00:43:35,220
- [Seth] The hyperthreading
question came up,

887
00:43:35,220 --> 00:43:36,620
maybe we talk about it here.

888
00:43:38,430 --> 00:43:39,750
- There was a question?
- The question before

889
00:43:39,750 --> 00:43:41,093
about hyperthreading,
you were gonna answer it?

890
00:43:41,093 --> 00:43:42,840
This is the slide to talk about it.

891
00:43:42,840 --> 00:43:44,820
- [Arthur] Yeah, yeah. Oh.

892
00:43:44,820 --> 00:43:47,320
Well, the title of the
slides by the way is wrong.

893
00:43:48,390 --> 00:43:51,330
So you had a question about
hyperthreading, I think.

894
00:43:51,330 --> 00:43:52,713
I forgot, who asked? Yeah.

895
00:43:54,030 --> 00:43:56,793
So that thing has changed quite a lot.

896
00:43:57,780 --> 00:44:00,600
So before we introduced Graviton,

897
00:44:00,600 --> 00:44:03,960
all our instances had
hyperthreading enabled.

898
00:44:03,960 --> 00:44:08,960
So for each physical
core, you had two threads

899
00:44:09,420 --> 00:44:11,043
mapped to a physical core.

900
00:44:11,940 --> 00:44:14,700
Starting with Graviton,
we introduced instances

901
00:44:14,700 --> 00:44:17,100
that were single threaded.

902
00:44:17,100 --> 00:44:22,100
So each vCPU is mapped to a physical core.

903
00:44:24,330 --> 00:44:29,330
Starting with AMD gen 7, AMD
is also without hyperthreading,

904
00:44:29,970 --> 00:44:31,950
and that has a bunch of consequences

905
00:44:31,950 --> 00:44:33,750
on the performance side.

906
00:44:33,750 --> 00:44:38,750
So I can show you a quick demo on that.

907
00:44:41,580 --> 00:44:44,073
Okay, so what I'm gonna do is,

908
00:44:46,500 --> 00:44:50,400
here, I'm connected on a C7i,

909
00:44:50,400 --> 00:44:53,193
so seventh gen Intel-based instances.

910
00:44:54,030 --> 00:44:58,200
If we look at what we
have in /proc/cpuinfo,

911
00:44:58,200 --> 00:45:00,360
that's a C7i large.

912
00:45:00,360 --> 00:45:03,573
So that one exposes two vCPUs,

913
00:45:05,040 --> 00:45:09,300
and those vCPUs are actually threads

914
00:45:09,300 --> 00:45:12,000
of the same physical core.

915
00:45:12,000 --> 00:45:16,953
So I'm gonna launch a
quick OpenSSL speed test,

916
00:45:20,430 --> 00:45:22,743
actually I must have it here,

917
00:45:25,590 --> 00:45:27,420
and I'm gonna do exactly the same

918
00:45:27,420 --> 00:45:30,150
on a Graviton-based instance.

919
00:45:30,150 --> 00:45:34,080
And that one also, same size,
so that's a large again,

920
00:45:34,080 --> 00:45:37,200
but this time, we still have two vCPUs,

921
00:45:37,200 --> 00:45:41,913
but each of those vCPUs
is a physical core.

922
00:45:49,350 --> 00:45:54,350
So we got a certain level of
performance with that one.

923
00:45:54,630 --> 00:45:56,880
So if we look at what we were able to do

924
00:45:56,880 --> 00:45:58,680
in terms of signature per second,

925
00:45:58,680 --> 00:46:03,150
we are roughly 39,000.

926
00:46:03,150 --> 00:46:08,150
Now I'm gonna do a second
thing where I will do that,

927
00:46:08,520 --> 00:46:10,980
but this time with two execution thread,

928
00:46:10,980 --> 00:46:15,980
so OpenSSL has the ability to
parallelize what it is doing.

929
00:46:16,740 --> 00:46:21,740
So it's actually using two
processes to do that now,

930
00:46:22,740 --> 00:46:24,840
and we'll see what we will get from there.

931
00:46:39,665 --> 00:46:43,110
And so we get a slightly
higher performance

932
00:46:43,110 --> 00:46:46,680
at 42,000 signature per second.

933
00:46:46,680 --> 00:46:50,070
But we don't double what we had.

934
00:46:50,070 --> 00:46:54,630
On the Graviton side, where
we have one vCPU mapped

935
00:46:54,630 --> 00:46:58,203
to one physical core, if
we do exactly the same.

936
00:47:03,690 --> 00:47:06,465
So first what we can
observe is that in terms

937
00:47:06,465 --> 00:47:09,390
of signature per second,
we were slightly slower

938
00:47:09,390 --> 00:47:12,120
with a single thread of execution.

939
00:47:12,120 --> 00:47:15,513
And now if we do it on
two thread of execution,

940
00:47:32,730 --> 00:47:35,703
we have almost doubled,
not quite, but almost.

941
00:47:37,843 --> 00:47:40,890
And I don't wanna use that
test to say Graviton4 is better

942
00:47:40,890 --> 00:47:45,720
than Intel in that case, what
I wanna illustrate here is

943
00:47:45,720 --> 00:47:50,720
that the SMT versus no SMT as
an influence on performance.

944
00:47:52,830 --> 00:47:56,793
If you test your application
at low levels of loads,

945
00:47:58,380 --> 00:48:02,250
what you'll see is actually
two different types of design.

946
00:48:02,250 --> 00:48:04,950
Intel has big beefy cores,

947
00:48:04,950 --> 00:48:08,640
and potentially they will give
you extremely good latency

948
00:48:08,640 --> 00:48:11,220
at low levels of utilization.

949
00:48:11,220 --> 00:48:14,400
On the Graviton side,
we have smaller cores,

950
00:48:14,400 --> 00:48:17,600
but we have more of them
allowing us to map one vCPU

951
00:48:17,600 --> 00:48:19,740
to one physical core.

952
00:48:19,740 --> 00:48:22,080
At low levels of loads,

953
00:48:22,080 --> 00:48:26,700
potentially we are not as
fast, however we scale higher.

954
00:48:26,700 --> 00:48:28,860
So two different designs leading

955
00:48:28,860 --> 00:48:32,850
to two different performance profile.

956
00:48:32,850 --> 00:48:34,740
I'm not saying use one versus the other,

957
00:48:34,740 --> 00:48:36,990
that's not the point, there
are plenty of other metrics.

958
00:48:36,990 --> 00:48:38,190
And there are cases

959
00:48:38,190 --> 00:48:39,990
where the Intel processors will be faster,

960
00:48:39,990 --> 00:48:41,220
and there are cases

961
00:48:41,220 --> 00:48:43,560
where the Graviton
processors will be faster.

962
00:48:43,560 --> 00:48:46,080
But keep that in mind when
you're evaluating the performance

963
00:48:46,080 --> 00:48:47,550
of those instances.

964
00:48:47,550 --> 00:48:50,280
And the same would be
true with AMD processors.

965
00:48:50,280 --> 00:48:51,990
AMD processors, it's a little different.

966
00:48:51,990 --> 00:48:52,860
We have chosen,

967
00:48:52,860 --> 00:48:57,030
because AMD had very high
core count processor,

968
00:48:57,030 --> 00:48:58,530
we have chosen to expose them

969
00:48:58,530 --> 00:49:01,743
as non SMT starting from gen seven.

970
00:49:02,970 --> 00:49:05,730
They're more expensive
on a per vCPU basis.

971
00:49:05,730 --> 00:49:07,380
But the performance you will extract,

972
00:49:07,380 --> 00:49:11,310
if you are parallel enough,
and if you run them hot enough,

973
00:49:11,310 --> 00:49:13,470
is gonna be extremely good.

974
00:49:13,470 --> 00:49:14,340
- [Seth] And I think that's a key point

975
00:49:14,340 --> 00:49:16,422
for this demo is this
was parallelized, right?

976
00:49:16,422 --> 00:49:17,853
Like if the application
can't be parallelized,

977
00:49:17,853 --> 00:49:19,650
it's not gonna be able to take advantage.

978
00:49:19,650 --> 00:49:22,140
And that to going back to
Arthur's point earlier,

979
00:49:22,140 --> 00:49:23,850
if that's a key distinction,

980
00:49:23,850 --> 00:49:25,650
if the application could take advantage

981
00:49:25,650 --> 00:49:28,980
of having those bigger,
larger cores is important.

982
00:49:28,980 --> 00:49:29,910
- Yes.
- Question.

983
00:49:29,910 --> 00:49:34,230
So this information about
hyperthreading, is that?

984
00:49:34,230 --> 00:49:35,460
I'm pretty sure if I-

985
00:49:35,460 --> 00:49:36,300
- [Seth] This will help
everyone else hear you.

986
00:49:36,300 --> 00:49:39,090
- [Participant 11] Yeah,
so my question was,

987
00:49:39,090 --> 00:49:41,490
so this information about
hyperthreading for example,

988
00:49:41,490 --> 00:49:44,760
and probably CPU instructions
and other things,

989
00:49:44,760 --> 00:49:46,800
I can probably find it on the internet,

990
00:49:46,800 --> 00:49:49,740
probably there's a blog
post from AWS saying this,

991
00:49:49,740 --> 00:49:52,170
is that exposed on any APIs that could-

992
00:49:52,170 --> 00:49:54,120
- [Arthur] It's not exposed in APIs,

993
00:49:54,120 --> 00:49:56,880
but the processor tells you.
- But then I'll have

994
00:49:56,880 --> 00:49:59,700
to launch an EC2 to check it.
- Yes.

995
00:49:59,700 --> 00:50:02,310
- If I have a-
- There are plenty

996
00:50:02,310 --> 00:50:04,860
of things that the APIs are not exposing.

997
00:50:04,860 --> 00:50:08,910
The API is not exposing the
amount of L1 and L2 and L3 cache

998
00:50:08,910 --> 00:50:10,193
that you get on any instance.

999
00:50:10,193 --> 00:50:13,320
The API is not exposing the NUMA topology.

1000
00:50:13,320 --> 00:50:17,280
The API is not giving you, I
don't know, the memory latency

1001
00:50:17,280 --> 00:50:19,710
or the theoretical memory bandwidth.

1002
00:50:19,710 --> 00:50:22,140
There's plenty of
characteristic of a processor

1003
00:50:22,140 --> 00:50:24,330
that the API is not giving you.

1004
00:50:24,330 --> 00:50:29,330
Or other examples, each of
those processors have options

1005
00:50:30,600 --> 00:50:32,190
in their instruction set.

1006
00:50:32,190 --> 00:50:36,240
So some generation of Intel
processors have the ability

1007
00:50:36,240 --> 00:50:40,800
to expose a 57-bit virtual address space.

1008
00:50:40,800 --> 00:50:42,300
Not all of them, some of them.

1009
00:50:43,620 --> 00:50:47,850
It's not in the EC2 API, if
you launch an EC2 instance,

1010
00:50:47,850 --> 00:50:50,880
you can check whether the
operating system has been able

1011
00:50:50,880 --> 00:50:53,010
to detect that specific feature.

1012
00:50:53,010 --> 00:50:55,380
But there's way more to a processor

1013
00:50:55,380 --> 00:51:00,300
than what we can really
realistically expose in the API.

1014
00:51:00,300 --> 00:51:02,280
- [Participant 11] Because
one of the possible use cases

1015
00:51:02,280 --> 00:51:07,280
would be, so I have quite a
few EKS clusters for example.

1016
00:51:07,680 --> 00:51:10,770
So if I could expose, I mean
I could create my own catalog,

1017
00:51:10,770 --> 00:51:12,330
I could, you know, do the homework

1018
00:51:12,330 --> 00:51:13,853
and get exactly the
instructions I care about

1019
00:51:13,853 --> 00:51:15,570
and all that kind of stuff.

1020
00:51:15,570 --> 00:51:17,490
But it could create no pulls

1021
00:51:17,490 --> 00:51:20,820
that would expose those
instructions as labels.

1022
00:51:20,820 --> 00:51:23,070
So I could schedule specific workloads

1023
00:51:23,070 --> 00:51:24,210
onto a specific set of-

1024
00:51:24,210 --> 00:51:25,980
- Yeah.
- You have to run this once

1025
00:51:25,980 --> 00:51:27,019
per processor, right?

1026
00:51:27,019 --> 00:51:29,843
It's not like you're
doing this indefinitely.

1027
00:51:29,843 --> 00:51:32,190
- [Participant 11] Per
processor, per family.

1028
00:51:32,190 --> 00:51:35,550
- [Seth] Well remember,
if it's a C8, M8, R8,

1029
00:51:35,550 --> 00:51:37,290
they're gonna have the same
processor in them, right?

1030
00:51:37,290 --> 00:51:39,178
So it's not that-
- Sure, but a 9 to 10,

1031
00:51:39,178 --> 00:51:41,010
I have to just do-
- Well, and when we refresh,

1032
00:51:41,010 --> 00:51:42,157
absolutely, you did.

1033
00:51:42,157 --> 00:51:43,260
Like, I'm not sure of any time yet,

1034
00:51:43,260 --> 00:51:44,640
if we've launched something new,

1035
00:51:44,640 --> 00:51:46,470
always test before you-
- Yeah, yeah.

1036
00:51:46,470 --> 00:51:48,450
- [Arthur] Well, I understand the request,

1037
00:51:48,450 --> 00:51:51,390
and I get it, but there's a question of,

1038
00:51:51,390 --> 00:51:53,973
to which depth do we wanna go there.

1039
00:51:54,930 --> 00:51:58,200
So far we have chosen to limit ourselves

1040
00:51:58,200 --> 00:52:01,770
to exposing the frequency,
exposing the CPU type,

1041
00:52:01,770 --> 00:52:05,130
and once you launch the instances,

1042
00:52:05,130 --> 00:52:06,930
you can get all those information,

1043
00:52:06,930 --> 00:52:09,390
because they are exposed
to the operating system.

1044
00:52:09,390 --> 00:52:12,494
But we don't make them
available as an API.

1045
00:52:12,494 --> 00:52:13,327
- [Participant 11] If it's a
non API, will it be on a blog?

1046
00:52:17,833 --> 00:52:21,090
We do have an internal discussion
on whether we wanna make,

1047
00:52:21,090 --> 00:52:23,160
we make it part of the documentation,

1048
00:52:23,160 --> 00:52:24,630
which could be a way to do it.

1049
00:52:24,630 --> 00:52:26,490
- [Seth] This came up
yesterday I think, right?

1050
00:52:26,490 --> 00:52:28,620
- [Arthur] The reality is that we have,

1051
00:52:28,620 --> 00:52:31,950
our team has that
documentation for ourselves.

1052
00:52:31,950 --> 00:52:33,630
- Correct.
- 'Cause we find it useful.

1053
00:52:33,630 --> 00:52:35,283
So yes, we could expose that.

1054
00:52:36,330 --> 00:52:38,430
- [Seth] What else? What else's questions?

1055
00:52:41,630 --> 00:52:42,810
Here we go.
- Can we go back

1056
00:52:42,810 --> 00:52:43,643
to the presentation please?

1057
00:52:43,643 --> 00:52:46,653
- Okay, right here, Arthur.
- Oh, sorry.

1058
00:52:47,520 --> 00:52:48,660
- [Participant 12] With
your demonstration,

1059
00:52:48,660 --> 00:52:51,270
it was a benchmarking on OpenSSL,

1060
00:52:51,270 --> 00:52:54,403
and you compared a-
- It's a terrible one.

1061
00:52:54,403 --> 00:52:56,733
Why have any conclusions from that?

1062
00:52:57,780 --> 00:52:59,550
- [Participant 12] You're
comparing a seventh generation

1063
00:52:59,550 --> 00:53:01,950
to an eighth generation Graviton.

1064
00:53:01,950 --> 00:53:03,630
- That was on purpose.
- Well, if you

1065
00:53:03,630 --> 00:53:06,030
tried the seventh generation Graviton,

1066
00:53:06,030 --> 00:53:08,380
I think you'd have probably
lost significantly.

1067
00:53:10,885 --> 00:53:13,316
- [Arthur] The two vCPU one, I would not.

1068
00:53:13,316 --> 00:53:15,840
The one vCPU, that would be even slower.

1069
00:53:15,840 --> 00:53:18,360
- Yes.
- But the two vCPU, no,

1070
00:53:18,360 --> 00:53:20,760
I would still win that with Graviton3.

1071
00:53:20,760 --> 00:53:21,900
- [Participant 12] Once
upon a time I tried

1072
00:53:21,900 --> 00:53:24,363
to migrate a load balancer to-

1073
00:53:26,250 --> 00:53:27,570
- [Arthur] But that was another problem.

1074
00:53:27,570 --> 00:53:28,403
- [Participant 12] Yes, it was.

1075
00:53:28,403 --> 00:53:30,780
- [Arthur] I know which one
you'll be talking about.

1076
00:53:30,780 --> 00:53:32,850
So the problem you probably have seen

1077
00:53:32,850 --> 00:53:36,600
with an SSL load balancer
was a Graviton2 problem.

1078
00:53:36,600 --> 00:53:40,953
Where on Graviton2 we made a mistake,

1079
00:53:42,210 --> 00:53:43,740
and we did not anticipate

1080
00:53:43,740 --> 00:53:46,500
that it would have that
kind of consequences.

1081
00:53:46,500 --> 00:53:50,220
And the problem was that
we did not anticipate

1082
00:53:50,220 --> 00:53:55,220
that RSA would be that
much slower on Graviton2

1083
00:53:56,970 --> 00:53:58,800
compared to intel-based instances.

1084
00:53:58,800 --> 00:54:03,390
The reason behind that
was that RSA uses a lot

1085
00:54:03,390 --> 00:54:06,750
of 64-bit integer multiplications,

1086
00:54:06,750 --> 00:54:11,190
and we had a single
64-bit integer multiplier

1087
00:54:11,190 --> 00:54:13,740
on the Graviton2 core.

1088
00:54:13,740 --> 00:54:18,740
And when running a SSL
connection, a TLS connection,

1089
00:54:20,640 --> 00:54:25,050
at the session establishment,
Graviton2 was much slower.

1090
00:54:25,050 --> 00:54:29,420
The AES part of an SSL
session was much faster

1091
00:54:29,420 --> 00:54:33,150
on Graviton2 compared to
Intel-based instances.

1092
00:54:33,150 --> 00:54:37,080
So if you had long connections,
nothing was visible,

1093
00:54:37,080 --> 00:54:38,850
and Graviton was doing great.

1094
00:54:38,850 --> 00:54:43,473
If you had short
connections, like let's say,

1095
00:54:44,310 --> 00:54:47,400
a gateway for a bunch of IoT devices,

1096
00:54:47,400 --> 00:54:50,220
or a gateway for an observability system

1097
00:54:50,220 --> 00:54:52,440
where you reestablish an SSL connection,

1098
00:54:52,440 --> 00:54:56,280
every time you send metrics,
Graviton2 was terrible.

1099
00:54:56,280 --> 00:55:01,200
We fixed that with Graviton3,
adding one multiplication unit

1100
00:55:01,200 --> 00:55:04,560
on the core, making Graviton3 much faster.

1101
00:55:04,560 --> 00:55:06,930
And then we also fixed partially,

1102
00:55:06,930 --> 00:55:10,290
we mitigated that on Graviton2

1103
00:55:10,290 --> 00:55:13,350
by optimizing RSA for Graviton2.

1104
00:55:13,350 --> 00:55:18,350
So within AWS LC, which is
a crypto library from AWS,

1105
00:55:19,380 --> 00:55:24,380
we have a much, much faster RSA
implementation on Graviton2.

1106
00:55:25,320 --> 00:55:27,570
- Excellent answer.
- That thing no longer exists,

1107
00:55:27,570 --> 00:55:29,973
and Graviton4 is doing great on crypto.

1108
00:55:31,830 --> 00:55:33,362
So we've closed that gap,

1109
00:55:33,362 --> 00:55:35,430
but that gap definitely
existed at the beginning

1110
00:55:35,430 --> 00:55:37,080
of the life of Graviton2.

1111
00:55:37,080 --> 00:55:41,370
- [Seth] Great question. Who
else, where should we go next?

1112
00:55:41,370 --> 00:55:43,263
We've got just under five minutes.

1113
00:55:49,200 --> 00:55:50,970
- [Arthur] Okay, well we have five minutes

1114
00:55:50,970 --> 00:55:52,803
to talk about memory topology then.

1115
00:55:55,710 --> 00:55:57,453
So earth isn't flat,

1116
00:55:58,590 --> 00:56:02,253
and it's very visible
on some AWS instances.

1117
00:56:03,330 --> 00:56:06,063
So you know what that thing is?

1118
00:56:09,480 --> 00:56:12,390
Well, actually that's mentioned. (laughs)

1119
00:56:12,390 --> 00:56:17,390
And so that's the memory
topology on a C7a,

1120
00:56:18,060 --> 00:56:22,860
and what it exposes is that
that processor is structured

1121
00:56:22,860 --> 00:56:25,710
with groups of eight cores.

1122
00:56:25,710 --> 00:56:30,123
They were called CCX,
compute core complex.

1123
00:56:31,230 --> 00:56:35,490
And those eight cores are
sharing a slice of L3 cache

1124
00:56:35,490 --> 00:56:40,490
and a connection to the memory die.

1125
00:56:40,620 --> 00:56:44,040
So when you run on an AMD-based instance

1126
00:56:44,040 --> 00:56:45,900
of that generation,

1127
00:56:45,900 --> 00:56:50,400
your application won't
see a flat topology.

1128
00:56:50,400 --> 00:56:53,430
If you have an application
thread that runs

1129
00:56:53,430 --> 00:56:57,870
on that first block and
accesses something in memory,

1130
00:56:57,870 --> 00:57:01,140
and that part of the memory
will stay warm in the cache,

1131
00:57:01,140 --> 00:57:03,600
if you try to access the same part

1132
00:57:03,600 --> 00:57:06,240
of the memory from the next CCX,

1133
00:57:06,240 --> 00:57:08,140
the information won't be on the cache.

1134
00:57:09,330 --> 00:57:10,590
And I've seen cases

1135
00:57:10,590 --> 00:57:14,640
of customers moving from four XLs.

1136
00:57:14,640 --> 00:57:16,950
So that would be, oh sorry, two XLs.

1137
00:57:16,950 --> 00:57:20,610
So that would be one
single slice to four XLs,

1138
00:57:20,610 --> 00:57:23,430
now you are spanning across two slices,

1139
00:57:23,430 --> 00:57:26,010
and seeing their application being slower,

1140
00:57:26,010 --> 00:57:30,150
because now, they were
across two memory domains

1141
00:57:30,150 --> 00:57:31,170
and if they were trying

1142
00:57:31,170 --> 00:57:33,930
to access the memory from one domain

1143
00:57:33,930 --> 00:57:36,450
where things have already been warmed up

1144
00:57:36,450 --> 00:57:40,020
from the other domain,
well, they had a cache miss,

1145
00:57:40,020 --> 00:57:42,240
had to replenish the cache first,

1146
00:57:42,240 --> 00:57:45,813
and that wasn't as fast
as what they expected.

1147
00:57:46,830 --> 00:57:50,670
And that one is on a 24 XL, on a 48 XL,

1148
00:57:50,670 --> 00:57:55,670
you would have another
level of non-uniformity,

1149
00:57:56,730 --> 00:57:58,740
because you would've a second socket,

1150
00:57:58,740 --> 00:58:01,650
and you would have an
even greater distance

1151
00:58:01,650 --> 00:58:03,510
between the cores on the first socket,

1152
00:58:03,510 --> 00:58:05,400
and the cores on the first socket,

1153
00:58:05,400 --> 00:58:08,013
and the memory associated
to those two sockets.

1154
00:58:09,180 --> 00:58:14,180
So when you deploy things on
AWS, pay attention to that.

1155
00:58:14,220 --> 00:58:19,220
The maximum sizes of our
instances tend to be two sockets.

1156
00:58:19,500 --> 00:58:22,710
So when going from, let's
say, in that generation

1157
00:58:22,710 --> 00:58:27,000
of instances, from 24
to 48, there are cases,

1158
00:58:27,000 --> 00:58:29,700
that may not be faster,
you will get more core,

1159
00:58:29,700 --> 00:58:31,083
you will get more memory.

1160
00:58:32,070 --> 00:58:35,880
But if your application doesn't
take into account the fact

1161
00:58:35,880 --> 00:58:39,630
that the memory is no
longer flat and uniform,

1162
00:58:39,630 --> 00:58:42,630
you might have weird surprises.

1163
00:58:42,630 --> 00:58:44,880
I had a customer a couple of weeks ago

1164
00:58:44,880 --> 00:58:49,590
who moved his database
from a 24 XL to a 48 XL

1165
00:58:49,590 --> 00:58:54,243
and the P 50 latency of
his database doubled,

1166
00:58:55,110 --> 00:58:58,490
because now memory was spread
across the two sockets, okay?

1167
00:58:58,490 --> 00:59:01,140
It had more memory, more vCPU,

1168
00:59:01,140 --> 00:59:03,750
but the database on average was slower.

1169
00:59:03,750 --> 00:59:06,960
Some requests were just the same speed,

1170
00:59:06,960 --> 00:59:09,270
the overall throughput was higher,

1171
00:59:09,270 --> 00:59:11,490
but the latency was definitely higher.

1172
00:59:11,490 --> 00:59:12,973
- [Seth] And this can also
be an issue with Kubernetes

1173
00:59:12,973 --> 00:59:15,300
as someone was talking about
using that before, right?

1174
00:59:15,300 --> 00:59:18,690
If your containers land on
different domains, right?

1175
00:59:18,690 --> 00:59:20,310
Now, all of a sudden,
on different sockets,

1176
00:59:20,310 --> 00:59:21,600
now the connectivity

1177
00:59:21,600 --> 00:59:24,570
between them is slower than
you might expect, right?

1178
00:59:24,570 --> 00:59:26,070
I see nodding heads, so that's something

1179
00:59:26,070 --> 00:59:28,140
to definitely be aware
of as you're looking at.

1180
00:59:28,140 --> 00:59:30,060
I know Kubernetes has got new features

1181
00:59:30,060 --> 00:59:31,740
becoming NUMA aware, right?

1182
00:59:31,740 --> 00:59:33,630
Something to look at as you're doing that.

1183
00:59:33,630 --> 00:59:35,940
So just something that can
become super important.

1184
00:59:35,940 --> 00:59:38,010
These are some of those
low level differences

1185
00:59:38,010 --> 00:59:39,070
that start to make a big
difference in your app.

1186
00:59:39,070 --> 00:59:40,500
- [Arthur] Yeah, my recommendation,

1187
00:59:40,500 --> 00:59:42,360
unless you know exactly what you're doing,

1188
00:59:42,360 --> 00:59:45,270
would be avoid the two socket sizes

1189
00:59:45,270 --> 00:59:48,150
on your Kubernetes cluster.

1190
00:59:48,150 --> 00:59:51,720
Well, if you know what
you're doing, then go do it.

1191
00:59:51,720 --> 00:59:54,030
But otherwise, stay
with the single socket.

1192
00:59:54,030 --> 00:59:56,740
Again well, we don't
expose that in the API.

1193
00:59:58,228 --> 01:00:00,390
- [Participant 13] But you
can do multiple sockets

1194
01:00:00,390 --> 01:00:03,450
if you were going in on
an old T socket host,

1195
01:00:03,450 --> 01:00:08,073
but you have a short,
like, a small on demand.

1196
01:00:10,830 --> 01:00:14,910
- Yes.
- All right, so I-

1197
01:00:14,910 --> 01:00:17,490
- [Participant 14] Does that
advice apply as strongly

1198
01:00:17,490 --> 01:00:22,020
to trying to keep it to
a single complex size?

1199
01:00:22,020 --> 01:00:22,890
- [Arthur] A lot less,

1200
01:00:22,890 --> 01:00:25,110
'cause the difference in terms of latency

1201
01:00:25,110 --> 01:00:29,490
and memory bandwidth between
two CCX is much, much lower

1202
01:00:29,490 --> 01:00:32,112
compared to between two sockets.

1203
01:00:32,112 --> 01:00:33,750
- [Seth] All right, and
we'll thank you, everybody.

1204
01:00:33,750 --> 01:00:36,360
We are out of time. Please
fill out your surveys.

1205
01:00:36,360 --> 01:00:38,130
And for those of you that want a sticker,

1206
01:00:38,130 --> 01:00:39,810
but didn't ask a question, come see me.

1207
01:00:39,810 --> 01:00:41,311
Happy to give 'em out.

1208
01:00:41,311 --> 01:00:42,983
(audience applauding)
- Thank you.

