# AWS re:Invent 2025 会议总结：FIS 与 AWS 构建高性能支付解决方案

## 会议概述

本次会议由 AWS 首席技术专家 Samir Sharma、FIS 资金转移副总裁 Aid Sterling 以及 AWS 高级交付顾问 Elilango Sunundar Rajan 共同主讲，深入介绍了 FIS 如何与 AWS 合作，从零开始重新构建了一个高性能、大规模可扩展的支付处理解决方案——Money Movement Hub（资金转移中心）。

FIS 作为全球金融服务领域的关键技术提供商，每年处理 160 亿笔交易，管理着 8 万亿美元的资产，为全球 95% 以上的大型金融机构提供服务。面对即时支付、全天候服务、多支付渠道等新需求，传统的批处理支付系统已无法满足现代用户对速度和体验的期望。FIS 决定利用 AWS 云服务从根本上重新思考支付解决方案的架构，构建了一个云原生、多租户、支持多支付渠道的统一支付编排平台。

该解决方案的核心特点包括：在 5 秒内完成支付执行和结算、每秒处理超过 1000 笔支付、实现 99.995% 的可用性（全年停机时间少于 30 分钟）。通过采用事件驱动的微服务架构、容器化部署（EKS）、高性能数据库（Aurora PostgreSQL）、内存缓存（ElastiCache）以及智能扩展机制（KEDA、Karpenter），该系统成功实现了大规模实时支付处理，同时保持了高可靠性和端到端可观测性。

## 详细时间线与关键要点

### 开场与背景介绍
[00:00 - 02:30] - 会议开场
- 主持人通过现场调查引入话题：几乎所有人在过去一周都使用手机进行过支付
- 介绍演讲嘉宾：Samir Sharma（AWS 首席技术专家）、Aid Sterling（FIS 资金转移副总裁）、Elilango Sunundar Rajan（AWS 高级交付顾问）
- 会议目标：分享 FIS 与 AWS 合作构建关键任务支付应用的经验和技术洞察

[02:30 - 04:00] - 会议议程概览
- 介绍 FIS 及其在全球金融服务中的关键角色
- 解释 FIS 为何决定从零开始重新思考支付解决方案
- 即时支付处理演示
- 技术要求与挑战
- 解决方案架构深度剖析
- 关键经验与教训分享

### FIS 公司介绍与行业挑战
[04:00 - 07:30] - FIS 在金融服务领域的地位
- FIS 将资金分为三个阶段：静态资金（核心银行存储）、流动资金（支付处理）、工作资金（交易、借贷、财富管理）
- FIS 处理美国 58% 的大型和零售金融机构的核心银行和支付业务
- 每年处理 160 亿笔交易，转移超过 16 万亿美元
- 为全球 95% 以上的大型金融机构提供服务
- FIS 拥有 60 年的支付处理经验

[07:30 - 12:00] - 支付行业面临的变革
- 用户期望发生根本性变化：希望随时随地快速完成支付
- Aid Sterling 分享个人经历：传统银行退款流程（邮寄支票）已无法满足现代用户需求
- 支付渠道不断增加：从传统 ACH、电汇扩展到 FedNow、RTP、Venmo、Zelle 等即时支付方式
- 服务模式从"朝九晚五"转变为"全天候 24/7"
- 传统系统呈现"意大利面条式"的复杂集成，难以扩展
- 用户体验开始超越利率成为银行竞争的关键因素

[12:00 - 15:30] - FIS 的战略决策
- 尽管 FIS 已拥有多个支付系统（电汇、实时支付、账单支付、Zelle 等），但这些系统相互孤立
- 支付渠道本身已成为"基础设施"，真正的价值在于编排和执行能力
- 需要智能化的支付路由：自动选择最快、最安全、最经济的支付方式
- 2024 年初，FIS 与 AWS 合作达成"顿悟时刻"，决定构建 Money Movement Hub
- 设计目标：云原生、多租户、多渠道、支持多种数字环境和核心银行系统集成

### 即时支付处理演示
[15:30 - 22:00] - 支付处理演示
- 展示统一 API 设计：基于 ISO 20022 pain.001 标准消息格式，适用于所有支付类型
- 演示场景：用户通过标准 UI 发起转账（向 Jane 支付 re:Invent 门票费用）
- 实时展示 API 动态更新：金额从 $150 改为 $100，备注信息实时反映在 API 中
- 强调 SDK 设计：为数字服务提供商提供便捷的集成方式

[22:00 - 26:30] - 支付处理的复杂性
- 即时支付要求在 5 秒内完成与支付渠道的双向通信
- 发送方处理流程：
  - 验证核心银行系统：账户有效性、余额充足性、账户状态
  - 实时欺诈检测：交易筛查、反洗钱（AML）检查、交易监控
  - 向核心系统记账：借记发送方账户
- 接收方处理流程：
  - 验证接收账户的有效性和状态
  - 对入账交易进行欺诈检测（发送方和受益方双重检查）
  - 贷记接收方账户
- 所有这些复杂操作必须在 5 秒内完成，并符合多个支付渠道的监管要求

### 技术要求与挑战
[26:30 - 30:00] - 核心技术要求
- **性能要求**：每笔支付在 5 秒内完成执行和结算
- **可扩展性要求**：多租户架构，支持每秒处理超过 1000 笔支付，能够根据支付量动态快速扩缩容
- **可用性要求**：99.995% 的可用性，意味着全年停机时间少于 30 分钟
- **集成挑战**：必须与本地数据中心的传统银行系统无缝集成
- **可扩展性挑战**：新支付渠道（如数字货币、稳定币）应能轻松集成，无需完全重写系统
- **可观测性挑战**：实现端到端监控，跨多个子系统追踪每笔支付的完整生命周期

### 解决方案架构概览
[30:00 - 35:00] - 功能架构
- 核心是支付处理管道（Payment Processing Pipeline）
- 主要子系统：支付验证、支付编排、支付执行
- 支持多种支付渠道：FedNow、RTP、电汇、SWIFT、数字货币
- 实时集成：本地核心银行系统、实时欺诈和风险管理系统
- 与传统批处理不同，所有欺诈检测必须在支付执行前的 5 秒内完成

[35:00 - 42:00] - AWS 解决方案架构
- **外部连接**：
  - 金融机构通过 HTTPS API 或 AWS 私有网络访问
  - 本地银行系统通过 AWS Direct Connect 实现低延迟高吞吐连接
- **多账户策略**：
  - 将不同子系统隔离到独立的 AWS 账户中
  - 提供合规边界、故障边界和安全边界
  - 支持不同团队采用不同的运营模式（如支付渠道团队采用全栈模式，支付处理团队分离基础设施和应用团队）
  - 账户间通过 AWS PrivateLink 连接，保持私有网络通信

[42:00 - 48:00] - 计算层设计
- **架构模式**：事件驱动设计 + 微服务 + 解耦异步处理
- **容器编排**：使用 Amazon EKS（Elastic Kubernetes Service）
- **微服务示例**：支付验证服务、支付编排服务、支付执行服务（实际有数十个微服务）
- **开源工具集成**：
  - KEDA：用于 Pod 自动扩展
  - Karpenter：用于节点自动扩展
  - Conductor：用于工作流管理
- **优势**：独立扩展各个微服务，实现大规模水平扩展；单个服务故障不影响其他服务，提高整体弹性

[48:00 - 52:00] - 数据层设计
- **事务数据库**：Amazon Aurora PostgreSQL
  - 云原生设计，支持高可用、高扩展、高性能
  - 支持同区域内最多 15 个读副本
  - 极高的 I/O 吞吐量，I/O 延迟低至个位数毫秒
- **缓存层**：Amazon ElastiCache
  - 提供微秒级（而非毫秒级）I/O 延迟
  - 用于支付编排工作流的实时状态管理
  - 支持每秒数千笔支付的实时扩展
- **数据湖**：基于 Amazon S3
  - 存储系统生成的海量数据，用于合规和 AI 分析
  - 使用 AWS Glue 进行非实时数据处理

[52:00 - 55:00] - 事件流与可观测性
- **事件流处理**：Amazon MSK（Managed Streaming for Kafka）
  - 处理事件驱动架构中的大量事件
  - 实现生产者和消费者之间的事件传递
- **可观测性**：Amazon CloudWatch + Application Signals
  - Application Signals：应用级监控（而非仅基础设施级）
  - 支持服务级别目标（SLO）监控
- **安全服务**：AWS KMS、Secrets Manager、HSM

### 可扩展性深度剖析
[55:00 - 62:00] - 自动扩展机制
- **应用技术栈**：Java 21（后端）+ Angular（前端）
- **Pod 自动扩展（KEDA）**：
  - 监控两个关键指标：HTTP 请求数量、ElastiCache 队列深度
  - HTTP 请求数直接对应支付 API 数量
  - Conductor 将复杂编排转换为工作流，工作流分解为多个任务（Task），任务放入 ElastiCache 队列
  - 队列深度反映完成支付所需的待处理任务数
  - KEDA 根据这两个指标动态扩展 Pod 数量

- **Warm Pool 策略**：
  - 预先运行低优先级 Pod 占用节点资源
  - Money Movement Hub 的 Pod 设置为高优先级
  - Kubernetes 根据优先级类抢占低优先级 Pod，立即调度高优先级 Pod
  - 实现 Pod 的即时调度和启动

- **节点自动扩展（Karpenter）**：
  - 当 Warm Pool 不足时，Karpenter 快速添加新的工作节点
  - 新节点快速加入 EKS 集群

[62:00 - 65:00] - IP 地址管理
- **挑战**：大规模扩展需要足够的 IP 地址
- **解决方案**：自定义 VPC CNI 插件
  - 为 Pod 使用辅助的不可路由 IP 范围
  - 工作节点运行在可路由 IP 空间
  - 为不可路由 Pod 使用 /20 CIDR 块，提供充足的 IP 地址

[65:00 - 68:00] - 应用架构设计
- **设计原则**：开闭原则（Open-Close Principle）
  - 对扩展开放，对修改关闭
  - 业务需求频繁变化，架构必须灵活应对
- **工作流管理（Conductor）**：
  - 支持复杂的并行任务和多决策点
  - 支持多版本工作流，可随时回滚到旧版本
  - 提供友好的运维 UI，运维团队可监控、重新运行工作流

### 性能优化
[68:00 - 73:00] - 性能优化策略
- **Pod 启动时间优化**：
  - 使用 Bottlerocket（专为容器设计的操作系统）
  - 保持 Docker 镜像精简：
    - 使用多阶段 Docker 构建
    - 仅添加运行时必需的库
    - 仔细评估 Java 库，只包含必要依赖
  - 使用 Spring 懒加载（Lazy Bean Loading），仅加载启动所需的 Bean
  - **结果**：Pod 启动时间控制在 4 秒以内

- **数据访问优化**：
  - 创建自定义 Spring 注解，将所有读 SQL 路由到 Aurora 读副本
  - 使用 2-3 个读副本，提供充足的读性能
  - 快速写入使用 Write-Through Cache：
    - 先写入 ElastiCache
    - 异步更新 Aurora 主节点

- **未来优化方向**：
  - 评估 Spring AOT（Ahead-of-Time）编译
  - 评估 GraalVM 创建原生镜像
  - 评估 Bottlerocket 的 Seekable OCI 功能（并行按需拉取 Docker 镜像）

### 多区域弹性
[73:00 - 76:00] - 跨区域复制策略
- **服务选择原则**：优先选择提供原生跨区域复制的 AWS 服务
- **具体实现**：
  - Amazon Aurora：使用全球数据库（Global Database）
  - ElastiCache：使用全球数据存储（Global Data Store）
  - S3：使用原生 S3 跨区域复制
  - Kafka：使用 MSK Replicator
    - 不仅复制消息，还复制消费者偏移量（Consumer Offset）
    - 确保应用在另一区域运行时能从正确位置继续消费

### 会议结尾
[76:00 - 结束] - 总结与展望
- 演讲者总结了构建高性能、大规模可扩展支付解决方案的关键技术决策
- 强调了云原生架构、事件驱动设计、容器化部署的重要性
- 展示了 FIS 与 AWS 深度合作如何实现传统金融服务的现代化转型
- 为与会者提供了构建关键任务应用的实践经验和技术洞察

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


关键技术总结：
- **核心架构**：事件驱动 + 微服务 + 异步处理
- **容器编排**：EKS + KEDA + Karpenter + Warm Pool
- **数据层**：Aurora PostgreSQL + ElastiCache + S3 数据湖
- **事件流**：Amazon MSK（Kafka）
- **工作流**：Conductor 开源编排引擎
- **性能指标**：5 秒内完成支付、每秒 1000+ 笔、99.995% 可用性、Pod 4 秒启动