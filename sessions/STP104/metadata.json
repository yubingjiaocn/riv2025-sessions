{
  "title": "AWS re:Invent 2025 - Own Your AI – Blazing Fast OSS AI on AWS (STP104)",
  "title_cn": "AWS re:Invent 2025 - 拥有您的AI – AWS上的超快开源AI (STP104)",
  "abstract": "Companies like Notion, GitLab, and DoorDash run their AI inference on Fireworks because they want to own their models without sacrificing performance. We'll show you how or stack optimizations – custom CUDA kernels, speculative decoding, disaggregated serving – enabling blazing fast inference at scale. Then we'll walk through real AWS deployment patterns: fully managed multi-region or in-VPC deployment on SageMaker/EKS/ECS, or locked down in your VPC. Plus, see how to build production agents using Fireworks with AWS AgentCore.",
  "abstract_cn": "像 Notion、GitLab 和 DoorDash 这样的公司在 Fireworks 上运行他们的 AI 推理，因为他们希望拥有自己的模型而不牺牲性能。我们将向您展示我们的堆栈优化 - 自定义 CUDA 内核、推测解码、分解服务 - 实现大规模的超快推理。然后我们将介绍真实的 AWS 部署模式：在 SageMaker/EKS/ECS 上完全托管的多区域或 VPC 内部署，或在您的 VPC 中锁定部署。此外，了解如何使用 Fireworks 和 AWS AgentCore 构建生产代理。",
  "presenter": [
    {
      "name": "Roberto Barroso-Luque",
      "title": "Applied AI",
      "company": "FireworksAI"
    }
  ],
  "attributes": {
    "topic": "",
    "area_of_interest": [],
    "services": [],
    "type": "Lightning talk"
  },
  "video_url": "https://www.youtube.com/watch?v=2vPqiKVh8yI",
  "session_code": "STP104",
  "duration_seconds": 1040,
  "duration_minutes": 17.3
}