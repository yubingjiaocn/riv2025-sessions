# AWS re:Invent 2025 - DAT313 会议总结

## 会议概述

本次会议主题为"使用生成式AI增强Amazon DocumentDB的应用智能"(DAT313)。会议由两位Amazon DocumentDB首席解决方案架构师Cody Allen和Doug Bonser主讲。

会议重点探讨了如何将生成式AI技术与Amazon DocumentDB结合,帮助企业构建智能化应用。演讲者强调,数据是生成式AI应用的核心差异化因素,而不是模型本身。企业无需为AI应用构建全新的数据架构,而应该利用现有的数据基础设施。通过在DocumentDB中集成向量搜索功能,企业可以避免引入新的数据库组件,同时利用团队已有的技能和知识,降低学习成本和系统复杂度。

会议通过三个主要访问模式展示了实际应用场景:首先是TSQL到MQL的转换工具,帮助关系型数据库背景的开发者快速上手DocumentDB;其次是RAG(检索增强生成)架构,展示如何利用企业自有数据构建智能问答系统;最后介绍了模型上下文协议(MCP)服务器,提供标准化的方式访问AI能力。整个会议强调了实用性和可操作性,通过多个现场演示展示了这些技术如何简化开发流程并提升生产力。

## 详细时间线

### 开场介绍 (00:00:00 - 00:03:30)
- **00:00:00** - 会议开始,确认会场为DAT313会议室
- **00:00:15** - 介绍会议主题:使用生成式AI增强DocumentDB应用智能
- **00:00:45** - 演讲者幽默提问:今天有谁没参加过17场关于生成式AI的会议?
- **00:01:15** - 介绍演讲者:Cody Allen(首席解决方案架构师)和Doug Bonser(高级解决方案架构师)
- **00:02:00** - 说明演讲者日常工作:与客户讨论DocumentDB和生成式AI应用
- **00:02:45** - 概述会议内容:访问模式、工具演示、最佳实践

### 生成式AI背景与数据重要性 (00:03:30 - 00:08:00)
- **00:03:30** - 引用麦肯锡研究:生成式AI将为全球经济每年增加2.6-4.4万亿美元
- **00:04:15** - 强调生成式AI已成为企业级战略举措
- **00:04:45** - 提问观众:谁的公司没在讨论生成式AI?(无人举手)
- **00:05:30** - 核心观点:数据是生成式AI应用的命脉,特别是安全、丰富的企业数据
- **00:06:15** - 重申去年的观点:数据是差异化因素,这一点至今未变
- **00:07:00** - 说明生成式AI应用是建立在现有数据基础之上的新应用类型
- **00:07:45** - 客户反馈:不希望为新应用创建全新的数据架构

### 向量嵌入与数据库集成 (00:08:00 - 00:12:00)
- **00:08:00** - 强调将向量存储与底层数据存储靠近的优势
- **00:08:30** - 好处包括:简化架构、减少数据移动、提升性能、降低许可成本
- **00:09:15** - 避免学习新的API和SDK,利用现有知识
- **00:09:45** - 举例:如果熟悉Redis,可使用MemoryDB的向量功能
- **00:10:30** - 列举AWS支持向量搜索的服务:Aurora、RDS、OpenSearch、Neptune Analytics、DocumentDB
- **00:11:15** - 强调利用已在生产环境验证的现有数据结构
- **00:11:45** - 现有架构已满足安全性、可用性、存储和计算需求

### 向量嵌入基础 (00:12:00 - 00:14:30)
- **00:12:00** - 介绍向量嵌入:文本、视频、图片的数值表示
- **00:12:30** - 解释为什么需要向量:计算机理解数字,不理解文字
- **00:13:00** - 向量嵌入使机器能够理解上下文,类似人类理解方式
- **00:13:45** - 说明词语在不同上下文中有不同含义
- **00:14:15** - 区别于二进制搜索,向量搜索关注上下文和自然语言查询

### 客户应用场景 (00:14:30 - 00:16:00)
- **00:14:30** - 客户构建生成式AI应用的四大目标
- **00:14:45** - 目标1:改善客户体验
- **00:15:00** - 目标2:提高员工生产力(AWS内部也大量使用)
- **00:15:15** - 目标3:创建全新内容
- **00:15:30** - 目标4:改进业务运营
- **00:15:45** - 应用领域:金融、工程、客户支持、销售、营销等各行业

### 访问模式1:TSQL到MQL转换插件 (00:16:00 - 00:28:00)
- **00:16:00** - 介绍第一个访问模式:DocumentDB TSQL插件
- **00:16:30** - Cody自述:关系型数据库背景(SQL Server、Oracle、MySQL、PostgreSQL)
- **00:17:00** - 展示SQL查询示例:SELECT  FROM table - 感觉像"家"一样熟悉
- *00:17:30** - 对比MongoDB查询语言(MQL):充满$lookup、$project等操作符,令人困惑
- **00:18:15** - 展示UPDATE语句的对比:SQL简单直观,MQL复杂难懂
- **00:19:00** - 介绍解决方案:在MongoShell中将TSQL命令转换为DocumentDB命令
- **00:19:45** - 提供两个版本:连接Bedrock的版本和使用本地LLM的版本
- **00:20:15** - 演示开始:展示GitHub仓库中的两个包

#### TSQL插件演示 - Ollama本地版本 (00:20:30 - 00:24:30)
- **00:20:30** - 运行安装脚本,安装依赖项
- **00:21:00** - 下载Ollama LLM模型:Code Llama 7B(3.8GB)
- **00:21:30** - 说明使用兼容性工具确保使用支持的API
- **00:22:00** - 启动MongoShell,加载TSQL插件
- **00:22:30** - 演示数据:customers、orders、products集合,约100个文档
- **00:23:00** - 执行第一个查询:SELECT  FROM table WHERE field = value(autoExecute=false)
- *00:23:30** - 显示转换后的MQL,复制并成功执行
- **00:23:45** - Cody幽默评论:"就像插USB接口,我总是第三次才插对"
- **00:24:00** - 更复杂查询:SELECT多个字段,多个WHERE条件
- **00:24:30** - 演示SELECT COUNT查询,生成聚合管道($match和$count)

#### TSQL插件演示 - 自定义LLM (00:24:30 - 00:26:00)
- **00:24:30** - 切换到更大的模型:Code Llama 13B(7.4GB)
- **00:25:00** - 修改JS配置文件,无需重新编译
- **00:25:30** - 重新启动shell,使用新模型
- **00:25:45** - 执行相同查询,得到略有不同但结果相同的MQL(75条记录)

#### TSQL插件演示 - Bedrock版本 (00:26:00 - 00:28:00)
- **00:26:00** - 切换到Bedrock版本,运行安装脚本
- **00:26:30** - 需要配置AWS凭证(aws configure)
- **00:26:45** - 说明模型访问权限已简化(2-3周前更新)
- **00:27:00** - 使用Claude 3模型
- **00:27:30** - 演示相同查询,生成countDocuments方法(与Ollama版本略有不同)
- **00:27:45** - 展示复杂查询:多个WHERE、AND条件、ORDER BY
- **00:28:00** - 总结:提升开发者体验和生产力的工具

### 访问模式2:RAG架构 (00:28:00 - 00:42:00)
- **00:28:00** - Cody停顿:"戏剧性暂停,因为我快失声了"
- **00:28:30** - 重申核心观点:数据是生成式AI应用的关键差异化因素
- **00:29:00** - 所有人都能访问相同的基础模型,但只有使用自有数据才能创造独特价值
- **00:29:45** - 好消息:无需构建自己的模型
- **00:30:15** - 介绍RAG(检索增强生成):获取相关信息、添加到上下文、生成响应
- **00:30:45** - Cody幽默:"这是400级别的技术内容,我会尽量简化"

#### RAG应用场景示例 (00:31:00 - 00:33:00)
- **00:31:00** - 场景:在线鞋店的交互式客服代理
- **00:31:30** - 客户问题:"我能退货并获得退款吗?"
- **00:32:00** - 系统操作:查询运营数据库获取库存和订单信息
- **00:32:30** - 执行向量相似性搜索,查询政策文档集合
- **00:32:45** - 示例政策:30天后收费,7天内免费升级等
- **00:33:00** - 利用知识库做出决策

#### RAG架构详解 (00:33:00 - 00:35:00)
- **00:33:00** - 步骤1:用户提问,通过提示词处理
- **00:33:30** - 步骤2:存储对话历史(考虑到用户可能中断后继续对话)
- **00:34:00** - 步骤3:查询情境数据(库存、订单状态等)
- **00:34:15** - 步骤4:使用LLM对问题进行标记化,生成问题嵌入
- **00:34:30** - 步骤5:在向量数据存储中执行相似性搜索(使用近似最近邻算法)
- **00:34:45** - 步骤6:将所有信息合成为工程化提示词发送给LLM
- **00:35:00** - 步骤7:更新对话历史并返回响应

#### DocumentDB在RAG中的角色 (00:35:00 - 00:36:00)
- **00:35:00** - DocumentDB支持向量搜索和向量索引
- **00:35:30** - 向量搜索和数据源搜索在同一存储库中运行
- **00:35:45** - DocumentDB既是运营数据存储,也可存储对话历史
- **00:36:00** - 大幅降低架构复杂度

### RAG演示:DocumentDB聊天机器人 (00:36:00 - 00:42:00)
- **00:36:00** - 演示开始:创建DocumentDB聊天机器人
- **00:36:30** - 安装库:Gradio(用户界面)和LangChain(创建向量)
- **00:37:00** - 设置向量参数:嵌入维度、索引参数
- **00:37:30** - 创建HNSW索引,使用余弦相似度
- **00:38:00** - 建立DocumentDB客户端连接,设置连接池和超时
- **00:38:30** - 数据分块:1000字符块,200字符重叠(保持语义连贯)
- **00:39:00** - 数据源:DocumentDB完整开发者指南(1500页)、数据建模指南PDF
- **00:39:30** - 额外数据:所有DocumentDB博客文章、定价页面、FAQ、功能页面
- **00:40:00** - 使用Titan Embedding Text v2模型创建嵌入
- **00:40:30** - 存储内容:原始文本(1000字符)、向量内容、元数据(来源、页码等)
- **00:41:00** - 查看DocumentDB中的文档:约5400个文档
- **00:41:30** - 展示文档结构:文本内容、元数据(来源、标题、链接)
- **00:42:00** - 展示完整文档:包含向量数组(对人类无意义的数字)

#### 聊天机器人提示词和配置 (00:42:00 - 00:44:00)
- **00:42:00** - 设置提示词:"你是DocumentDB问答助手"
- **00:42:30** - 规则:识别技术细节、确保答案准确、清晰简洁
- **00:43:00** - Cody幽默评论:"要友好和有帮助 - 我想看看如果设置为不友好和无用会怎样"
- **00:43:30** - 提供响应示例模板
- **00:43:45** - 设置阈值:score_threshold=0.8(至少80%准确)
- **00:44:00** - 对话历史:记住过去6轮对话

#### 聊天机器人查询演示 (00:44:00 - 00:48:00)
- **00:44:00** - 查询1:"DocumentDB提供无服务器实例吗?"- 简单问题
- **00:44:30** - 查询2:"如何审计集群登录?"- 需要用户、时间、日期信息
- **00:45:00** - 回答包括:如何启用、日志发送到CloudWatch、可用字段、CloudWatch查询示例
- **00:45:30** - Cody评论:"CloudWatch过滤比MQL更难写"
- **00:46:00** - 查询3:关于部分索引 - "需要在customer集合上创建部分索引,过滤德克萨斯州地址"
- **00:46:15** - Cody:"有德克萨斯人吗?Yeehaw!"
- **00:46:45** - 回答提供:部分过滤表达式、关键要点、额外信息
- **00:47:15** - 查询4:"需要连接orders和customers集合,获取前三名客户"
- **00:47:45** - 回答逐步解释聚合管道:$lookup、$unwind、$group等
- **00:48:00** - Cody:"让我的关系型数据库大脑能理解它在做什么"

#### 复杂场景演示 (00:48:00 - 00:51:00)
- **00:48:00** - 复杂查询1:电商平台从PostgreSQL迁移
- **00:48:30** - 场景描述:多个独立表(产品、库存、订单、配送、客户评论)、多个变体、分类、10万SKU
- **00:49:00** - 提示:"在YouTube上暂停视频阅读完整问题"
- **00:49:30** - 回答提供:产品集合模式、产品评论集合、库存文档、订单集合的完整模式设计
- **00:50:00** - 强调:将此工具交给开发者,简化与DocumentDB的交互
- **00:50:30** - 复杂查询2:游戏平台场景
- **00:50:45** - 描述:15个规范化表、每日100万玩家、需要实时排行榜、跨游戏成就追踪、游戏内购买历史
- **00:51:00** - Cody幽默:"这就是为什么我是个好程序员 - 因为有这些工具"
- **00:51:30** - 回答提供:完整模式、数据交互方式、存储位置建议

#### 多语言支持演示 (00:51:30 - 00:53:00)
- **00:51:30** - 强调多语言支持的重要性
- **00:52:00** - 举例:内布拉斯加总部,西班牙和伦敦开发者;智利总部,阿根廷和巴西开发者
- **00:52:30** - 演示:用葡萄牙语提问"DocumentDB在圣保罗区域支持吗?"
- **00:52:45** - 观众识别:葡萄牙语
- **00:53:00** - 系统自动翻译并用葡萄牙语回答:"是的,DocumentDB在圣保罗区域支持"
- **00:53:30** - 总结:全球开发者可用母语交互,获得一致答案

### 访问模式3:模型上下文协议(MCP)服务器 (00:53:00 - 00:58:00)
- **00:53:00** - Doug接手演讲
- **00:53:15** - 提问观众:"有多少人没听说过MCP?"(少数人举手)
- **00:53:45** - MCP介绍:提供AI代理组件与现有工具/系统之间的无缝集成
- **00:54:15** - 简化定义:访问能力的标准化方式
- **00:54:45** - 与前两个访问模式的对比:当你知道如何访问数据,但需要深入挖掘时
- **00:55:15** - MCP服务器的价值:避免编写大量查询,提供标准化访问方式

#### MCP详细说明 (00:55:30 - 00:58:00)
- **00:55:30** - MCP是开放协议,标准化应用程序向LLM提供上下文的方式
- **00:56:00** - 实现本地运行的MCP服务器与系统之间的通信
- **00:56:30** - 用户可以向Kiro CLI添加MCP服务器
- **00:57:00** - MCP服务器提供额外工具和资源,扩展能力
- **00:57:30** - 如果与用户请求相关,可以调用这些工具
- **00:58:00** - [演示部分在字幕中被截断]

### 总结与最佳实践 (字幕未完整覆盖)
- 会议强调了三种主要访问模式的实用性
- 重点是利用现有数据基础设施,避免增加复杂性
- 所有演示都展示了如何简化开发流程并提高生产力
- 强调数据作为生成式AI应用差异化因素的核心地位