# AMD Epic CPU在通用计算和AI工作负载中的应用

## 会议概述

本次AWS re:Invent 2025分会场由AMD服务器产品团队负责人Madhu Rangarajan、AMD公有云产品负责人Mike Thompson以及CVS Health FinOps实践负责人Kyle McLaughlin共同主讲。会议重点探讨了AMD Epic CPU如何在通用计算和AI工作负载中提供卓越性能，以及如何通过明智的处理器选择实现显著的成本优化。

演讲涵盖了AMD作为端到端解决方案提供商的战略定位，从硬件到软件的完整生态系统，以及在AI推理、机器学习和企业级工作负载中的实际应用案例。特别强调了在当前AI快速发展的背景下，CPU在整个AI管道中的重要作用，以及如何通过性能驱动的成本优化策略实现高达45%的运营成本节省。

## 详细时间线与关键要点

### 0:00-5:00 开场介绍与AMD公司战略
- 演讲者自我介绍：Madhu Rangarajan（AMD服务器产品团队负责人）、Mike Thompson（AMD公有云产品负责人）、Kyle McLaughlin（CVS Health FinOps实践负责人）
- AMD公司定位：从单纯硅片供应商转向端到端解决方案提供商
- 产品组合包括CPU、GPU、网络设备以及通过收购ZT Systems获得的集群级设计能力
- 强调软件层在整合各组件中的重要性

### 5:00-10:00 AI工作负载谱系与推理成本趋势
- CPU适用场景：通用计算、小型AI工作负载、AI管道处理、经典机器学习
- GPU适用场景：大规模AI、实时推理、大型生成式AI模型
- 推理成本急剧下降：18个月内下降280倍，从2022年每百万token 20美元降至2024年0.07美元
- Jevons悖论效应：成本降低导致需求激增，推动硅片增长和数据中心建设

### 10:00-15:00 代理AI与Epic CPU性能优势
- 代理AI的复杂性：用户部署的代理永不休眠，访问计算资源频率比人类高数千倍
- Epic CPU市场份额增长：从2017年Zen一代的个位数百分比增长到当前Zen五代的41%
- Turin（第五代Epic）性能表现：在企业工作负载中比竞争对手高2-4倍性能
- Epic 9575F高频处理器：专为GPU服务器优化，可提升GPU性能20%

### 15:00-20:00 AI推理在CPU上的优势与软件生态
- CPU推理适用场景：机器学习决策树、小型语言模型、推荐系统、混合AI应用
- 软件支持：原生支持PyTorch、TensorFlow、ONNX框架
- ZenDNN插件：可进一步提升性能，正在向上游框架集成
- CPU优势：可访问性强、利用率优化机会、可扩展性、运营简化

### 20:00-25:00 性能驱动的成本优化策略
- Mike Thompson接手演讲，重点讲解成本效率
- 性能对比：AMD Epic CPU相比Intel Ice Lake可提供高达2倍性能提升
- 成本节省：通过性能提升可实现45%的成本降低
- 四步优化法：停止实例→选择AMD实例（带"A"标识）→启动实例→实现成本节省

### 25:00-30:00 能耗效率与AI挑战应对
- 能效表现：AMD实例提供高达2.2倍的性能功耗比
- 预算灵活性：通过基础设施优化释放27-45%成本节省，用于AI创新投资
- 软件许可成本优化：2倍性能提升可将实例规模减半，显著降低按核心许可的软件成本
- CPU利用率优化：利用非峰值时段进行AI批处理，最大化预留实例价值

### 30:00-35:00 CVS Health FinOps实践案例
- Kyle McLaughlin分享CVS Health经验
- 公司规模：财富五强企业，年收入4000亿美元，每日服务1亿客户
- FinOps三阶段框架：告知（Inform）→优化（Optimize）→运营（Operate）
- 关键策略：标准化SKU、透明化成本可见性、与大型应用团队建立合作关系

### 35:00-38:30 总结与未来展望
- Madhu总结Epic CPU平台优势：高性能、易用性、兼容性
- X86-64架构优势：应用程序无需移植即可运行
- 提升和优化策略：先迁移获得性能提升，再进行进一步调优
- 会议结束，开放20分钟问答时间