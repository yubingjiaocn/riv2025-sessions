# AWS re:Invent 2025 - 最大化 EC2 性能

## 会议概述

本次技术分享会由 AWS EC2 团队的专家解决方案架构师 Toby Buckley 和 Annapurna Labs 的首席工程师 Jeff Blake 主讲,主题聚焦于如何最大化 Amazon EC2 实例的性能表现。会议采用代码演示(Code Talk)的形式,在 Mandalay Bay 会场举行。

两位讲师深入探讨了性能工程的方法论,特别强调了"先广后深"(wide before deep)的性能优化策略。他们介绍了 AWS 开发的开源工具 Aperf(版本 1.0,上周刚发布到 GitHub),这是一个专门用于系统级性能分析的工具。与传统的深度分析工具不同,Aperf 采用全系统视角,能够收集数百个系统级统计指标,从高层的 CPU 和内存利用率到底层的 CPU 性能计数器,帮助工程师快速定位性能瓶颈。

会议通过两个实际案例演示了性能优化过程:一个基于 Groovy 的 Web 应用程序(使用面向切面编程 AOP),另一个是 MongoDB 数据库优化。讲师们展示了如何使用 Aperf 识别性能问题,如何解读火焰图(Flame Graph)和 CPU 性能指标,以及如何通过 JVM 参数调优和实例升级(从 M7G 到 M8G Graviton 实例)来提升应用性能。整个演示强调了在性能工程中避免依赖直觉,而是基于数据驱动的决策方法。

## 详细时间线

### 开场与介绍
- **00:00:00 - 00:02:30** - 开场致谢,感谢观众来到 Mandalay Bay 会场;介绍会议主题"最大化 EC2 性能";说明这是一场代码演示形式的技术分享会

- **00:02:30 - 00:03:45** - 讲师自我介绍:Toby Buckley(EC2 团队专家解决方案架构师,专注 EC2 性能优化)和 Jeff Blake(Annapurna Labs 首席工程师,负责 Graviton 实例性能优化)

- **00:03:45 - 00:05:00** - 会议议程概览:性能工程高层视角、Aperf 工具介绍、Groovy 演示案例、MongoDB 案例、行动号召

### 性能工程基础
- **00:05:00 - 00:07:30** - 性能工程定义:在系统中寻找优化机会,无论是效率提升还是性价比优化;讨论性能工程的挑战,包括抽象泄漏问题

- **00:07:30 - 00:09:00** - 分享客户案例:需要深入到抽象层下方进行优化;强调"一切皆有成本"的理念;说明性能瓶颈可能会隐藏其他问题

- **00:09:00 - 00:11:00** - 介绍理想的性能工程流程:定义测量目标 → 测量 → 理解 → 调优 → 循环迭代;对比现实中的复杂情况:多种工具(strace, iotop, eBPF, perf 等)导致路径曲折

- **00:11:00 - 00:13:30** - 提出"先广后深"方法论:优先查看全系统信号,避免直觉误导;分享案例:客户认为需要优化压缩库,实际问题是内存不足导致磁盘交换,修复后性能提升 50%

### Aperf 工具介绍
- **00:13:30 - 00:15:30** - 正式介绍 Aperf 工具:上周发布 1.0 版本到 GitHub;设计理念是"先广后深";Toby 分享作为解决方案架构师如何使用 Aperf 与客户和团队建立共同语言

- **00:15:30 - 00:17:00** - Aperf 特性说明:不是唯一工具,而是工具箱中的一个;测量数百个系统级统计数据;简单易用的独立二进制文件;生成静态网页报告;低开销(单个 CPU 使用率低于 5%)

- **00:17:00 - 00:18:30** - 部署方式:可通过 SCP 部署到虚拟机或裸机;支持容器化部署到 Kubernetes Pod(特权容器模式);这是最近一个月开发的新功能

### Groovy 演示案例介绍
- **00:18:30 - 00:20:30** - 介绍演示场景:使用 Groovy 和面向切面编程(AOP);询问观众对 AOP 的了解程度;解释 AOP 概念:跨切面关注点,可应用于多个方法(如日志记录)

- **00:20:30 - 00:22:00** - 强调 AOP 的优势(可维护性、可测试性、可读性)和成本;演示目标:帮助理解这些成本以便做出权衡决策

- **00:22:00 - 00:24:00** - 测试拓扑结构:三个节点组的 Kubernetes 集群;使用 WRK2 负载生成器;测试实例包括 M7G(未优化和优化版本)和 M8G;进行性价比分析

### 代码演示开始
- **00:24:00 - 00:25:30** - Jeff 切换到 VS Code 窗口;确认后排观众能否看清屏幕;展示 Dockerfile:基于 Amazon Linux 2023,安装 Corretto 21 JDK

- **00:25:30 - 00:27:00** - 展示容器配置:使用 Gradle 构建 Groovy 应用;部署到 Tomcat 服务器;JVM 基础配置:8GB 堆内存,G1GC 垃圾收集器

- **00:27:00 - 00:30:00** - 展示 Groovy 代码结构:简单的 Web 应用端点(hello、process、message、setup、health check、metrics);强调关注点分离:端点处理 HTTP 请求,业务逻辑在独立包中

- **00:30:00 - 00:32:30** - 展示 AOP 实现:aspects 目录包含授权等横切关注点代码;可通过注解或 Spring Boot 切点过滤器应用;代码清晰但性能可能受影响

### SLO 概念讲解
- **00:32:30 - 00:34:30** - Toby 询问观众对服务级别目标(SLO)的了解;解释 SLO 与 SLA 的区别:SLO 是业务视角的性能目标,SLA 是面向最终用户的承诺

- **00:34:30 - 00:36:00** - 示例 SLO:P99 延迟 100 毫秒,吞吐量 5000 RPS;SLO 作为性能优化的锚点;本演示的突破延迟点:4000 RPS 时 P99 约 50 毫秒,超过后延迟急剧上升

- **00:36:00 - 00:37:30** - 解释突破延迟曲线:性能随负载增加先上升后平稳再下降,拐点即为突破延迟;演示目标:从 4000 RPS 提升到 10000 RPS(超过两倍性能)

### 启动优化测试
- **00:37:30 - 00:39:00** - Jeff 说明代码本身优化空间有限:业务逻辑不复杂,但仍无法达到高吞吐量;准备查看已收集的 Aperf 报告

- **00:39:00 - 00:40:30** - 启动优化版本测试:通过脚本 patch Kubernetes Pod,添加多个 Java 优化参数;测试将在后台运行 3-4 分钟;稍后会解释这些优化参数的原因

### Aperf 报告分析
- **00:40:30 - 00:42:00** - Toby 补充说明:演示使用脚本自动化部署、启动、记录和停止过程;欢迎会后交流脚本细节

- **00:42:00 - 00:43:30** - 询问观众 Graviton 使用情况:约 60-70% 听说过,部分正在使用;邀请未使用者会后交流;Jeff 强调演示内容大部分也适用于 x86 实例

- **00:43:30 - 00:45:30** - 打开 Aperf 报告首页:显示基本统计信息(ARM ID、实例类型 M7G.xlarge 4 CPU、内核版本);强调验证测试环境配置的重要性,分享错误案例(24xlarge 与 8xlarge 对比)

- **00:45:30 - 00:47:00** - 左侧菜单展示数百个统计指标分组:CPU 利用率、内存利用率等;点击 CPU 利用率查看时间序列图:60-75% 利用率,接近 3 CPU 限制(4 CPU 节点)

- **00:47:00 - 00:48:30** - 检查内存利用率:保持稳定,堆内存表现符合预期;介绍其他可用指标:虚拟内存统计、中断、磁盘统计、内核配置、sysctl 配置(可调优 TCP 网络栈或调度器)

### 火焰图分析
- **00:48:30 - 00:50:30** - 展示代码性能分析:系统火焰图(Perf)和 Java 专用的 Async Profiler;询问观众对火焰图的了解;解释火焰图:X 轴表示函数调用分布,Y 轴表示栈深度,宽度表示调用次数而非时间

- **00:50:30 - 00:52:30** - 火焰图颜色说明:亮绿色表示 JIT 编译代码,浅青色表示内联,深蓝色表示匹配项;关键发现:栈跟踪包含大量非用户编写的函数(如 internal_doFilter、invoke_exact_mt)

- **00:52:30 - 00:54:00** - 栈深度超过 100 帧,都是 AOP 和 JVM 语言实现的框架代码;搜索用户代码"AOP heavy code"只找到少量;结论:直接优化代码空间有限,需要寻找其他优化机会

### CPU 性能指标深入分析
- **00:54:00 - 00:56:00** - 询问观众微架构背景:一人有相关经验(来自 ARM,曾与 Jeff 同事);Jeff 决定讲解 CPU 工作原理以便理解后续 PMU(性能监控单元)指标

- **00:56:00 - 00:58:00** - CPU 基础:最简单的状态机循环 - 获取指令 → 执行数学运算 → 返回步骤 1;现代 CPU 每秒执行数十亿次循环(Graviton 接近 3GHz,高端桌面可达 6GHz)

- **00:58:00 - 01:00:30** - CPU 微架构详解:分为前端和后端两部分;前端从内存获取指令并放入队列;后端从队列执行指令;类似微服务的关注点分离

- **01:00:30 - 01:02:30** - 分支预测机制:前端无法等待后端反馈,必须预测下一步(循环、条件分支);基于历史行为预测未来;预测错误时需要刷新整个流水线,代价高昂;目标是让前后端始终全速运行

### PMU 指标分析
- **01:02:30 - 01:04:00** - 查看 IPC(每周期指令数)指标:点击可查看帮助说明;IPC 表示 CPU 处理速度,理想值应大于 1;当前平均值低于 1,说明大量时间未做有效工作

- **01:04:00 - 01:05:30** - 现代 CPU 理论上可达 8-12 IPC(所有条件对齐时);Aperf 将 PMU 统计数据按前端/后端分组便于理解

- **01:05:30 - 01:07:00** - 前端停顿分析:每千个周期中停顿次数;当前约 600/1000(60%),前端无法向后端提供指令;这是主要瓶颈

- **01:07:00 - 01:08:00** - 后端停顿分析:仅 200/1000(20%),后端处理速度较快;确认优化重点应在前端

- **01:08:00 - 01:09:30** - 分支预测失误率:每千条指令约 10 次失误,表现不佳;CPU 频繁停顿和刷新流水线

- **01:09:30 - 01:11:00** - 指令缓存未命中率:每千条指令约 60 次未命中;CPU 缓存层级:希望指令存储在最近的缓存中以快速获取;当前缓存利用率不佳

- **01:11:00 - 01:12:00** - TLB(地址转换缓冲)未命中率:每千条指令约 4 次;虚拟地址到物理地址转换效率较低;总结:所有这些指标都应尽可能接近零

### JVM 优化参数讲解
- **01:12:00 - 01:14:00** - 回顾之前启动的优化测试中添加的 JVM 参数;优化策略:针对前端瓶颈,需要将指令尽可能紧密排列,压缩指令间距离

注:字幕在此处截断,后续内容未提供

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


总结要点:
- 会议时长约 74 分钟(基于提供的字幕)
- 核心工具:Aperf 1.0(开源,GitHub 可获取)
- 核心方法论:先广后深,避免直觉驱动,基于数据决策
- 主要演示:Groovy/AOP 应用性能优化,从 4000 RPS 提升至 10000+ RPS
- 关键技术:火焰图分析、CPU 微架构理解、PMU 性能计数器、JVM 调优