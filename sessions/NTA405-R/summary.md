# AWS re:Invent 2025 技术分享会总结

## 会议概述

本次技术分享会重点介绍了如何使用无服务器架构（Serverless）、Strands Agent 和模型上下文协议（MCP）构建 AI 代理系统。演讲者通过现场编码演示，展示了如何将这三个核心技术组件整合在一起，创建一个功能完整的智能代理应用。

会议的核心理念是将 AI 代理比作自动驾驶汽车，而传统的大语言模型（LLM）则像是车载 GPS 导航系统。GPS 只能告诉你路线，而自动驾驶汽车能够连接各种传感器、天气数据、交通信息等工具，并根据实时信息做出动态决策。这正是代理式 AI（Agentic AI）的核心价值——通过连接多种工具和数据源，使 AI 能够执行复杂的多步骤推理和决策。

演示项目构建了一个实用的通勤建议代理，该代理能够：1）查询天气信息；2）根据天气条件提供通勤方式建议；3）调用远程 MCP 服务器掷骰子。这个示例完美展示了如何整合内置工具、自定义工具和远程 MCP 工具，体现了系统的可扩展性和灵活性。整个架构采用 AWS Lambda 无服务器方式部署，实现了按需付费、自动扩展和零运维的优势。

## 详细时间线与关键要点

### 开场与背景介绍（00:00 - 05:30）

00:00 - 会议开始，演讲者通过现场调查了解听众对 MCP、无服务器和 Lambda 的熟悉程度

01:15 - 介绍会议三大核心主题：无服务器架构、MCP 服务器和 Strands Agent

02:00 - 说明演示计划：MCP 服务器已预先部署（需要约 15 分钟部署时间），Strands Agent 将现场编码和部署

02:45 - 概述议程：什么是代理式 AI、为什么需要它、三大核心组件（MCP、Strands、Serverless）以及如何实现即插即用的架构

### 代理式 AI 核心概念（05:30 - 12:00）

05:30 - 提出核心问题：为什么需要代理式 AI 而不是传统 AI？

06:15 - 使用自动驾驶汽车类比解释代理式 AI：传统 LLM 像 GPS 提供方向，代理式 AI 像自动驾驶汽车能连接传感器、天气数据、交通信息并做出动态决策

07:30 - 强调代理式 AI 的三大能力：调用任意模型、连接多种工具、根据实时信息动态调整响应

08:45 - 介绍代理循环（Agent Loop）的核心作用：这是所有代理式 AI 框架的心脏，负责管理 LLM、工具和代理之间的交互

10:00 - 解释代理循环的递归特性：当条件变化时（如天气变化），循环会重新运行以提供新的决策

11:15 - 说明用户提示（Prompt）是触发代理循环的关键，就像启动汽车会启动自动驾驶系统

11:45 - 补充说明：代理不仅可以调用工具，还支持 A2A（Agent-to-Agent）协议，实现代理间通信

### Strands Agent 介绍（12:00 - 18:30）

12:00 - 介绍 Strands Agent：开源代理框架，支持与多种工具通信，内置 20 多个实用工具

12:45 - 强调 Strands Agent 的优势：Python SDK、简单易用、原生集成 MCP

13:30 - 现场互动：询问构建代理的三大核心组件（名称、LLM、提示词）

14:15 - 展示最简单的三行代码创建代理示例：导入 Agent、创建带系统提示的代理、调用代理

15:00 - 展示如何配置模型：使用 AWS Nova 模型替代默认的 Anthropic Claude 4 模型

16:00 - 说明超参数配置：温度（temperature）、最大令牌数（max tokens）、top-P、top-K 等参数可根据用例调整

16:45 - 展示如何使用 OpenAI 模型：Strands 支持多种模型提供商，体现开源框架的灵活性

### 工具（Tools）概念与实现（18:30 - 25:00）

18:30 - 提出问题：什么是工具？工具的主要功能是什么？

19:15 - 解释工具本质：让 LLM 能够理解和调用的普通函数，是业务逻辑的 AI 可访问接口

20:00 - 强调工具的作用：扩展代理能力，代理循环负责工具选择和执行过程

20:45 - 展示 Strands 内置工具：计算器工具等 20 多个开箱即用的工具

21:30 - 演示自定义工具：使用 @tool 装饰器将天气 API 函数转换为代理可用的工具

22:30 - 解释装饰器的重要性：防止无限循环、提供安全性、可观测性和防护栏

23:45 - 说明装饰器如何记录对话状态：确保代理不会在同一对话中重复调用相同工具

24:30 - 展示如何将工具传递给代理：通过工具数组初始化代理，代理根据问题动态选择工具调用顺序

### MCP（模型上下文协议）详解（25:00 - 32:00）

25:00 - 引入 MCP 之前的问题：如果没有 MCP，5 个模型 × 5 个工具 = 25 个集成点，扩展性差

26:15 - 介绍 MCP 解决方案：开放标准协议，将 M×N 问题转化为 M+N 问题

27:00 - 类比 REST API：MCP 是 AI 应用的 API 标准，简化工具集成

28:00 - 强调 MCP 的三大优势：开发者快速构建、标准化连接、支持代理-工具模式

29:00 - 说明 Strands Agent 原生集成 MCP 客户端，无需额外开发工作

30:00 - 展示 MCP 架构图：左侧是 AI 应用，右侧是三类工具（数据源、Python 代码、自定义功能）

31:00 - 总结 MCP 价值：为开发者、AI 应用和终端用户都节省了大量时间和精力

### MCP 工具集成实现（32:00 - 35:30）

32:00 - 展示 MCP 工具集成代码：使用 Streamable HTTP 客户端连接远程 MCP 服务器

32:45 - 说明 Strands 支持三种 MCP 客户端类型：STDIO、SSE 和 Streamable HTTP

33:30 - 解释为何使用 Streamable HTTP：因为 MCP 服务器部署在 Lambda 上，属于远程服务器

34:15 - 演示示例：MCP 服务器提供掷骰子工具，代理可以像使用其他工具一样调用它

35:00 - 幽默提醒：不要用演示中的随机数字去赌场下注

### 无服务器架构优势（35:30 - 38:00）

35:30 - 解释选择无服务器的原因：代理不工作时不付费、自动扩展、零基础设施管理

36:15 - 举例说明：黑色星期五购物助手代理可以自动扩展以应对流量高峰

37:00 - 强调安全性和可观测性：无服务器架构开箱即用提供这些特性

37:45 - 说明推广目的：虽然很少有人这样做，但实际上非常简单易用

### 整体架构演示（38:00 - 43:00）

38:00 - 展示高层架构图：两个蓝色框分别代表 MCP 服务器和 Strands Agent

38:45 - 说明小蓝框（MCP 服务器）：已部署的掷骰子工具，不会现场编码

39:30 - 说明大蓝框（Strands Agent）：将现场构建的代理，提供三个功能

40:15 - 列举代理功能：1）预测天气；2）根据天气建议通勤方式；3）掷骰子（展示 MCP 集成）

41:00 - 强调演示目的：展示三种工具集成方式（内置工具、自定义工具、MCP 工具）

42:00 - 详细说明三个工具：HTTP 请求（内置）、通勤建议（自定义业务逻辑）、掷骰子（MCP 服务器）

### 工作流程示例（43:00 - 47:00）

43:00 - 展示完整工作流程：用户提问"我今天应该如何通勤？"

43:45 - 解释代理推理过程：虽然用户没有明确询问天气，但代理知道需要先查询天气

44:30 - 说明系统提示的作用：定义代理角色为"通勤顾问"，指导其推理逻辑

45:15 - 详细步骤 1：代理调用 LLM 制定计划，决定先调用 HTTP 工具查询天气

45:45 - 详细步骤 2：获取天气信息后，调用通勤建议工具，判断适合步行

46:15 - 详细步骤 3：调用掷骰子 MCP 工具，获取幸运数字

46:45 - 最终响应：代理汇总所有信息，给出连贯的回答（天气好、建议骑车、幸运数字 10）

### MCP 服务器代码演示（47:00 - 53:00）

47:00 - 开始展示 MCP 服务器代码（小蓝框），强调这部分已部署完成

47:45 - 展示系统提示处理：接受多种表达方式（"roll one dice"、"roll a dice"、"roll two dice"）

48:30 - 说明 LLM 的作用：解析用户输入，提取骰子数量，避免字符串解析

49:15 - 展示 Bedrock LLM 调用：使用 Anthropic 模型将提示转换为数字

50:00 - 强调实用性：展示如何从 Lambda 调用 Bedrock

50:45 - 展示 @mcp 装饰器：将普通 Python 函数转换为 MCP 服务器

51:30 - 展示核心逻辑：生成随机数、求和、返回结果

52:00 - 说明 DynamoDB 集成：由于 Lambda 无状态，使用 DynamoDB 存储骰子结果

52:45 - 介绍 Lambda Web Adapter：在 Lambda 上运行 Web 服务器，处理 HTTP API 事件

### 安全性考虑（53:00 - 55:00）

53:00 - 强调安全性重要性：是部署代理式 AI 的主要障碍之一

53:45 - 展示 Lambda 授权器实现：简单的令牌验证机制

54:30 - 说明授权逻辑：有效令牌允许执行，无效令牌拒绝访问

54:45 - 总结 MCP 服务器代码：装饰器 + 函数逻辑 + 授权器

### Agent Core 与 MCP Inspector（55:00 - 58:30）

55:00 - 回答观众问题：讨论 AWS Agent Core Gateway 的作用

55:45 - 说明 Agent Core 优势：管理多个 MCP 服务器、IDP 身份验证、端到端授权

56:30 - 对比纯代码方式：适合开发者快速原型开发，无需额外成本

57:15 - 介绍 MCP Inspector：Anthropic 提供的本地测试工具

57:45 - 强调测试最佳实践：在暴露给其他代理之前，先本地测试 MCP 服务器

### Lambda 限制与替代方案讨论（58:30 - 62:00）

58:30 - 回答观众关于 Lambda 15 分钟限制的问题

59:00 - 说明适用场景：Web 应用（用户不会等待 3 分钟或 30 秒）非常适合无服务器

59:45 - 讨论长时间运行场景：研究型 AI 代理可能需要选择其他计算选项（如 EC2）

60:30 - 提及最新公告：Lambda 可以在 EC2 上运行，可能支持更长运行时间

61:15 - 回答 Lambda Layer 问题：适合共享公共依赖库，可用于多个代理共享 MCP 代码

61:45 - 建议优先使用无服务器：减少基础设施管理负担

### 现场编码准备（62:00 - 结束）

62:00 - 开始准备现场编码演示

62:30 - 展示 MCP Inspector 界面：用于测试 MCP 服务器的工具

63:00 - 说明测试流程：确保 MCP 服务器正常工作后再集成到代理中

63:30 - 准备连接到已部署的 MCP 服务器进行演示

64:00 - 开始进入实际编码环节（字幕在此处结束）

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


核心技术要点总结：
- **代理循环**：管理 LLM、工具和代理交互的核心机制
- **工具装饰器**：防止无限循环、提供安全性和状态管理
- **MCP 标准**：将 M×N 集成问题简化为 M+N
- **无服务器优势**：按需付费、自动扩展、零运维
- **Strands Agent**：开源、简单、原生支持 MCP