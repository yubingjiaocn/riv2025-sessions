# AWS re:Invent 会议总结：金融系统的下一个前沿 - 基于Transformer的基础模型

## 会议概述

本次AWS re:Invent会议探讨了基于Transformer的基础模型如何变革金融支付行业。演讲者Sudit Kalindi（AWS首席解决方案架构师）和Pahal Patangia（NVIDIA全球支付行业业务负责人）共同介绍了如何利用最新的AI技术来处理海量金融交易数据，提升欺诈检测准确率，并实现个性化服务。

会议开场通过一个互动问题引入主题：有多少人经历过信用卡被拒或收到银行的欺诈警告？这些警告正是来自理解信用卡历史的AI模型。随着数字交易在数量和复杂性上的爆炸式增长，传统的基于规则或简单机器学习的模型已经难以应对。欺诈手段也在不断演进，欺诈者甚至使用聊天机器人和生成式AI来模拟合成身份。因此，支付行业需要新一代的AI解决方案。

演讲重点介绍了Transformer架构如何捕捉客户行为的静态特征和动态趋势，通过将交易序列转化为嵌入向量（embeddings），这些嵌入可以增强传统机器学习模型（如XGBoost）的预测能力。同时保持模型的可解释性以满足金融监管要求。NVIDIA提供了加速计算能力和工具库（如RAPIDS、Nemo Framework），而AWS则提供了完整的MLOps平台（SageMaker、Hyperpod等），使企业能够大规模训练和部署这些模型。

## 详细时间线与关键要点

00:00 - 开场与背景介绍
- 演讲者自我介绍：Sudit Kalindi（AWS）和Pahal Patangia（NVIDIA）
- 互动环节：询问观众是否经历过信用卡被拒或欺诈警告
- 说明这些警告来自理解信用卡历史的AI模型

02:30 - 会议议程
- 为什么需要变革支付系统
- 基础模型如何使用交易数据识别大规模模式
- 如何实现个性化和模式挖掘
- 如何在AWS上使用NVIDIA加速开发和部署
- 关键要点和行动呼吁

03:45 - 为什么支付需要新一代AI
- 数字交易在数量和复杂性上爆炸式增长
- 每天有数十亿笔交易流经系统（信用卡、二维码、非接触式、跨境支付）
- 生成海量多样化数据集
- 传统基于规则或AI的模型难以应对
- 欺诈手段日益复杂，使用聊天机器人和生成式AI模拟合成身份

06:20 - Transformer在金融服务中的价值
- 金融服务行业主要依赖结构化数据和表格数据
- 传统方法结合统计或机器学习算法提取洞察
- Transformer能够捕捉客户的静态特征和动态趋势
- 可以同时理解长期历史和近期兴趣
- 帮助构建个性化客户画像和预测下一笔交易

09:15 - 传统机器学习管道 vs 序列模型
- 传统管道：表格数据 → 机器学习算法 → 预测概率
- XGBoost和LightGBM在准确性和效率方面表现出色
- 序列模型（RNN、LSTM）在2017年前主导金融服务
- 但存在梯度消失问题，无法捕捉长窗口上下文

12:40 - 嵌入向量（Embeddings）的作用
- 金融服务需要模型的可解释性和透明度
- 不能直接使用黑盒前沿模型
- 解决方案：使用基于树的模型进行决策，同时用Transformer生成的嵌入增强特征
- 嵌入向量帮助理解实体连接、聚类交易、识别模式
- 这是传统机器学习工作流的附加步骤

16:30 - GPU加速的必要性
- Transformer模型需要处理大量数据和多种数据模态
- 包括商户数据、银行数据、点击日志等
- 这是大规模计算问题，需要并行化
- GPU在训练嵌入和微调模型时非常有效
- NVIDIA提供开源库和工具包，可在AWS SageMaker和Marketplace上使用

19:45 - 行业演进：从规则到深度学习
- 早期：启发式规则（静态、被动响应）
- 中期：机器学习算法
- 现在：使用Transformer和图神经网络（GNN）生成嵌入
- 嵌入成为新模型的基础层

23:10 - 表格数据的Transformer训练方法
- 传统方法：使用语言模型（如Llama、Qwen）在表格数据上微调
- 这些模型原本为文本设计，需要学习结构化数据的语言
- 关键步骤：编写自定义分词器（tokenizer）
- 简单方法：将交易转换为句子（"Pahal在某日某时在In-N-Out消费5美元"）
- 更复杂方法：为特定单元格分配特定token，对商户类别进行独热编码

27:35 - 预训练策略
- 方法一：从头开始在表格数据上预训练整个模型（较少采用）
- 方法二：使用开源语言模型，然后在特定领域数据上微调（更常见）
- 需要正确表示分词器和单元格数据
- 处理重要字段（金额、日期、商户名称等）
- 使用NVIDIA RAPIDS库在SageMaker上大规模构建分词器

31:20 - 微调过程
- 使用NVIDIA Nemo Framework进行端到端定制和微调
- 确保模型有效收敛
- 支持分布式训练
- 可使用强化学习人类反馈（RLHF）或监督微调技术

34:50 - 交易序列作为客户故事
- 每次客户互动（刷卡、点击、转账）形成序列
- 序列讲述客户行为、习惯、意图和购买模式
- 金融数据包括：交易、账户信息、数字行为、银行活动
- 基础模型建立数据间的关系，理解上下文和支付标准

37:40 - 支付交易的分词化
- 类似于Transformer理解英语句子和单词token
- 支付历史作为序列，每笔交易作为token
- 在数百万笔交易上训练
- 可用于欺诈检测、产品推荐、交易监控等下游任务

40:15 - 基础模型扩展到欺诈检测之外
- 数据管道：原始数据 → 结构化（交易、用户档案、商户档案）
- 数据丰富：使用NVIDIA RAPIDS在Spark上进行特征工程
- 传统方法需要专家直觉
- RNN难以处理长历史和最近行为模式
- Transformer学习支付历史，GNN理解用户、商户、交易间的关系

44:30 - AWS部署架构
- 使用NVIDIA Nemo、PyTorch和DJL（用于GNN）
- 生成嵌入向量，捕捉密集的客户行为
- 嵌入输入到下游模型（如XGBoost，使用NVIDIA RAPIDS加速）
- 使用NVIDIA Triton进行实时推理，处理数百万到数十亿事件
- 应用场景：个性化、授权路由、争议保护
- 持续学习：欺诈向量反馈到训练中

48:50 - AWS实施架构详解
- 数据摄取：AppFlow、Kinesis Data Firehose、Lambda、Athena
- 数据结构化：NVIDIA RAPIDS、AWS Batch Transform、FSx for Lustre
- 分词化：NVIDIA Nemo Framework
- 训练：SageMaker Hyperpod上的PyTorch + Nemo
- 图关系：使用PyG和DJL构建GNN嵌入
- 向量存储：Amazon向量数据库用于相似性搜索
- MLflow识别最佳模型
- 推理：NVIDIA Triton处理数十亿交易

53:40 - ML工作流操作化
- SageMaker Data Wrangler和Processing Job进行数据清洗和转换
- Feature Store提供训练和推理特征
- SageMaker AI实验进行多次实验
- 最佳模型推送到Model Registry
- 数据科学家批准后部署
- SageMaker Deployment进行A/B测试
- 持续反馈和重新训练

57:20 - CI/CD管道
- 数据科学家构建SageMaker实验、笔记本、训练脚本
- 构建SageMaker Pipeline（模型评估、转换、注册、部署）
- 代码提交到代码仓库
- 触发CodePipeline生成SageMaker Pipeline
- 模型部署到Model Registry
- 首席数据科学家批准后推送到预生产环境
- 最终批准后部署到生产环境

01:00:45 - 安全架构
- AWS托管服务：Inspector（漏洞扫描）、Config（配置治理）、CloudTrail（活动日志）
- AI服务：SageMaker AI、Bedrock、ECR
- 自管理服务：KMS（密钥管理）、IAM（身份控制）、VPC（网络隔离）、WAF（威胁隔离）
- 第三方解决方案：Palo Alto、CrowdStrike Falcon、Prisma Cloud、Okta

01:03:30 - 早期成功案例
- 支付金融科技公司：卡测试攻击检测准确率从58%提升到97%
- 拉美新银行：构建"一刀切"模型，应用于欺诈、个性化、争议预测等，AUC提升2%
- 大型支付网络：发布Transaction GPT论文
- 大型银行：在NVIDIA GTC展示基于Transformer的推荐系统，使用Transformers4Rec库，参与度提升10-12%

01:06:50 - 关键要点
- NVIDIA和AWS不是自己构建基础模型，而是赋能开发者和企业
- 提供工具和库帮助解决模型收敛、准确率、机器利用率、成本等问题
- 提供参考蓝图和配方消除障碍
- AWS和NVIDIA在性能、可扩展性和信任方面深度合作
- 未来趋势：结合交易表格数据和非结构化数据
- 预计出现更多"一刀切"模型，然后细化为特定领域模型
- 全局嵌入帮助构建客户、产品、实体的更大上下文

01:09:30 - 行动呼吁
- 如果正在实验和构建，请联系AWS和NVIDIA团队
- 解决方案架构师、工程师和合作伙伴生态系统可提供帮助
- 最佳实践正在融入更广泛的生态系统
- 如果正在从传统机器学习迁移到GNN和Transformer，这是合作的机会
- 演讲者可通过LinkedIn联系
- 欢迎会后提问