1
00:00:02,140 --> 00:00:03,000
Good morning everyone.

2
00:00:04,099 --> 00:00:06,280
Welcome to our session here. We're here to talk

3
00:00:06,280 --> 00:00:08,439
about, uh, how you can protect your data

4
00:00:08,858 --> 00:00:11,118
and secure your data for AI workloads in particular

5
00:00:11,220 --> 00:00:12,339
using tokenization.

6
00:00:12,739 --> 00:00:14,880
In the next 45 minutes or so,

7
00:00:15,179 --> 00:00:17,339
uh, we're gonna talk about one of the biggest

8
00:00:17,339 --> 00:00:19,449
fiction points facing enterprises today,

9
00:00:19,699 --> 00:00:21,239
which is around how to secure

10
00:00:21,658 --> 00:00:23,120
your data and at the same time make

11
00:00:23,420 --> 00:00:25,579
it useful for your AI workloads

12
00:00:25,579 --> 00:00:26,879
and analytic workloads.

13
00:00:27,298 --> 00:00:29,699
Um, we will also talk through how

14
00:00:29,699 --> 00:00:31,719
we navigated this journey at Capital One

15
00:00:31,899 --> 00:00:33,819
and share some of these learnings, um.

16
00:00:34,359 --> 00:00:36,679
And uh talk through some of your key takeaways

17
00:00:36,679 --> 00:00:37,298
from those.

18
00:00:38,189 --> 00:00:40,579
Um By

19
00:00:40,579 --> 00:00:42,618
way of um introduction here, so my name

20
00:00:42,618 --> 00:00:44,679
is Sukan Bankat. I'm part of the uh

21
00:00:44,679 --> 00:00:46,779
product team here at Capital One Software,

22
00:00:46,859 --> 00:00:48,529
and with me is my partner in Crime Binayak.

23
00:00:49,649 --> 00:00:51,168
So we both will

24
00:00:51,529 --> 00:00:53,689
talk through different parts of this. um, I will cover

25
00:00:53,689 --> 00:00:56,090
some of the initial portion around motivation

26
00:00:56,090 --> 00:00:58,109
for this as well as, um,

27
00:00:58,209 --> 00:00:59,029
some of our

28
00:00:59,450 --> 00:01:01,630
key learnings and then hand it off to and I

29
00:01:01,630 --> 00:01:03,069
to wrap up the,

30
00:01:03,408 --> 00:01:05,198
the blueprints and other parts of the presentation.

31
00:01:05,528 --> 00:01:07,730
So here's a road map. Our agenda, so we'll

32
00:01:07,730 --> 00:01:09,349
start with what we call the

33
00:01:09,650 --> 00:01:10,159
um

34
00:01:10,489 --> 00:01:12,638
AI data dilemma. Essentially we'll start

35
00:01:12,638 --> 00:01:13,689
by defining what

36
00:01:14,010 --> 00:01:15,909
the industry-wide challenge we face today

37
00:01:16,250 --> 00:01:17,168
around fueling AI

38
00:01:17,730 --> 00:01:19,730
uh with sensitive data without compromising

39
00:01:19,730 --> 00:01:20,709
the utility of the data

40
00:01:21,010 --> 00:01:22,849
and compromising the security of the data.

41
00:01:23,540 --> 00:01:25,799
Um, in the second part we'll cover

42
00:01:26,069 --> 00:01:28,290
what is tokenization, how that can help with,

43
00:01:28,299 --> 00:01:30,299
uh, maybe handling this

44
00:01:30,299 --> 00:01:32,329
dilemma and, um, you know,

45
00:01:32,579 --> 00:01:34,838
handling this sort of bottleneck that exists between the two.

46
00:01:35,370 --> 00:01:37,379
Specifically, we'll talk about, uh, the format

47
00:01:37,379 --> 00:01:39,198
preserving nature of, uh, tokenization,

48
00:01:39,659 --> 00:01:41,730
uh, as one of the superior methods to encryption

49
00:01:41,730 --> 00:01:43,900
or masking or other techniques for data protection.

50
00:01:44,680 --> 00:01:46,959
Um, we'll round this out with the

51
00:01:46,959 --> 00:01:49,260
Capital One case study where we'll talk about,

52
00:01:49,519 --> 00:01:51,620
um, we'll sort of peel back the curtain

53
00:01:51,620 --> 00:01:53,760
on how Capital One went through this journey, how

54
00:01:53,760 --> 00:01:55,219
we, uh, built up our

55
00:01:55,799 --> 00:01:56,388
product stack,

56
00:01:56,680 --> 00:01:58,719
and, uh, how did we enforce this at,

57
00:01:58,730 --> 00:02:00,109
uh, scale, um,

58
00:02:00,439 --> 00:02:02,900
for that is, uh, demanded by our large

59
00:02:02,959 --> 00:02:03,469
footprint.

60
00:02:04,069 --> 00:02:06,069
Um, at the end of this, we'll also

61
00:02:06,069 --> 00:02:08,110
share some learnings from this, some actionable

62
00:02:08,110 --> 00:02:10,169
patterns that you can take and use today

63
00:02:10,429 --> 00:02:12,699
for, uh, training LLMs or other models

64
00:02:12,699 --> 00:02:14,710
and building AI guardrails, uh, with

65
00:02:14,710 --> 00:02:15,800
this approach.

66
00:02:17,050 --> 00:02:19,169
So with that let's uh kind

67
00:02:19,169 --> 00:02:21,368
of talk through what what is this data

68
00:02:21,368 --> 00:02:23,508
dilemma or data bottleneck that we see today.

69
00:02:23,960 --> 00:02:26,069
uh, essentially what this is

70
00:02:26,270 --> 00:02:26,909
is, uh,

71
00:02:27,330 --> 00:02:29,710
the reality that a lot of us face today

72
00:02:29,969 --> 00:02:32,288
with enterprise data. He is a top priority.

73
00:02:32,330 --> 00:02:34,558
Over 70% of, uh, enterprises

74
00:02:34,558 --> 00:02:36,508
today, um, have,

75
00:02:37,330 --> 00:02:38,368
have the, uh.

76
00:02:39,639 --> 00:02:41,819
Have projects that are centered around AI.

77
00:02:42,099 --> 00:02:44,020
Almost everyone here in the room has

78
00:02:44,300 --> 00:02:46,538
some AI project, uh, within your enterprise

79
00:02:46,538 --> 00:02:48,159
that you're probably, uh,

80
00:02:48,740 --> 00:02:50,909
looking to leverage data for.

81
00:02:51,250 --> 00:02:53,258
Businesses are aggressively pursuing this AI

82
00:02:53,258 --> 00:02:55,179
with 70% of this organizations listing,

83
00:02:55,500 --> 00:02:57,618
uh, AI as the top, uh, one

84
00:02:57,618 --> 00:02:59,189
of the top 5 investment areas

85
00:02:59,460 --> 00:03:01,639
for accelerating, um, these coding

86
00:03:01,639 --> 00:03:03,409
tasks, for example, um,

87
00:03:03,740 --> 00:03:06,338
with your AI assistance or evolutionizing

88
00:03:06,338 --> 00:03:07,960
your customer experience. Uh,

89
00:03:08,868 --> 00:03:10,868
the potential for AI is huge, we

90
00:03:10,868 --> 00:03:11,379
understand that,

91
00:03:11,710 --> 00:03:13,949
but the value that you can get out of those AI

92
00:03:13,949 --> 00:03:14,649
investments

93
00:03:15,069 --> 00:03:16,069
depends on,

94
00:03:16,349 --> 00:03:17,849
um, the value of the

95
00:03:18,189 --> 00:03:20,050
quality and value and quality of the data

96
00:03:20,508 --> 00:03:22,508
and completeness of the data that is used to train

97
00:03:22,508 --> 00:03:24,629
these models and is used at inference time.

98
00:03:25,149 --> 00:03:27,189
So as these AI models, uh,

99
00:03:27,270 --> 00:03:29,508
we all know is data, they are all data hungry,

100
00:03:29,909 --> 00:03:32,199
they need vast amounts of high quality

101
00:03:32,199 --> 00:03:32,770
data

102
00:03:33,099 --> 00:03:35,379
and high quality information to learn these patterns

103
00:03:35,379 --> 00:03:36,528
and make predictions.

104
00:03:36,788 --> 00:03:39,028
Um, significant portion of that is,

105
00:03:39,149 --> 00:03:41,520
uh, includes sensitive data. So this could be your,

106
00:03:41,830 --> 00:03:44,028
you know, uh, PII information, financial

107
00:03:44,028 --> 00:03:45,050
records, health data.

108
00:03:45,750 --> 00:03:47,788
And this creates a sort of a deadlock that

109
00:03:47,788 --> 00:03:49,149
uh we want to kind of explore.

110
00:03:49,469 --> 00:03:51,750
So you need this data to innovate,

111
00:03:52,028 --> 00:03:53,050
but using that data

112
00:03:53,528 --> 00:03:55,710
uh in the raw form creates massive risks, whether it's

113
00:03:55,710 --> 00:03:56,490
from a compliance

114
00:03:56,750 --> 00:03:57,929
or regulatory perspective.

115
00:03:58,500 --> 00:04:00,550
Uh, the most predictive data that you might have

116
00:04:00,550 --> 00:04:02,788
in your enterprise could, this could be transactions,

117
00:04:02,868 --> 00:04:04,949
these could be health records, this could be personal

118
00:04:04,949 --> 00:04:05,889
identifiers,

119
00:04:06,270 --> 00:04:08,649
is also the most regulated and the most risky.

120
00:04:08,868 --> 00:04:10,929
So for businesses this data is an asset

121
00:04:11,189 --> 00:04:13,429
and it represents the insight, but for the

122
00:04:13,429 --> 00:04:15,508
security teams it poses a problem. How

123
00:04:15,508 --> 00:04:17,778
do we enable the secure, uh,

124
00:04:18,588 --> 00:04:20,588
secure usage of this data, especially for AI

125
00:04:20,588 --> 00:04:21,160
workloads,

126
00:04:21,470 --> 00:04:23,730
and you can see here some more, uh, statistics around.

127
00:04:24,100 --> 00:04:26,379
Uh, the prevalence of privacy regulations

128
00:04:26,379 --> 00:04:28,459
that is, you know, uh, kind of exploded over the

129
00:04:28,459 --> 00:04:30,540
past several years, and

130
00:04:30,540 --> 00:04:32,699
then the number of data breaches. So these are stats

131
00:04:32,699 --> 00:04:33,920
that, you know, I'm sure you've seen,

132
00:04:34,209 --> 00:04:35,319
uh, across the industry.

133
00:04:35,619 --> 00:04:37,619
The, the key part here is that this is

134
00:04:37,619 --> 00:04:39,778
also linked to almost the, uh, tripling

135
00:04:39,778 --> 00:04:40,399
of this data.

136
00:04:40,754 --> 00:04:42,875
Over the past several years, uh, this is all

137
00:04:42,875 --> 00:04:44,875
net new data that's been generated and how

138
00:04:44,875 --> 00:04:46,994
do we now use this all responsibly

139
00:04:46,994 --> 00:04:49,074
in, in our AI workloads for training

140
00:04:49,074 --> 00:04:50,334
and inferncing purposes.

141
00:04:50,713 --> 00:04:52,875
So that's, that's what we'll talk about through the

142
00:04:52,875 --> 00:04:53,553
rest of this talk.

143
00:04:53,954 --> 00:04:56,303
So our approach centers around, uh,

144
00:04:56,314 --> 00:04:57,454
separating the,

145
00:04:57,915 --> 00:04:58,535
uh,

146
00:04:59,113 --> 00:05:01,153
this value from risk. So the idea here

147
00:05:01,153 --> 00:05:03,233
being that we break the deadlock we're

148
00:05:03,233 --> 00:05:04,553
changing how we view the data.

149
00:05:04,980 --> 00:05:07,028
Uh, we need to support, uh, separate

150
00:05:07,028 --> 00:05:08,970
the informational value of the data

151
00:05:09,230 --> 00:05:11,488
from the risk that it poses and during use.

152
00:05:11,910 --> 00:05:14,149
Uh, we, we sort of have this framework called

153
00:05:14,149 --> 00:05:15,088
de-identify,

154
00:05:15,350 --> 00:05:17,579
analyze, and unlock that, um,

155
00:05:17,778 --> 00:05:20,309
you know, we found, uh, useful and, uh,

156
00:05:20,319 --> 00:05:21,730
uh, when we talk about this at Capital One.

157
00:05:22,170 --> 00:05:24,608
The first pillar of this is the de-identified

158
00:05:24,608 --> 00:05:26,670
part. So we replace the sensitive data

159
00:05:26,889 --> 00:05:27,428
with

160
00:05:27,889 --> 00:05:29,250
with non-sensitive tokens

161
00:05:29,528 --> 00:05:31,569
which ends up reducing the risk

162
00:05:31,569 --> 00:05:33,769
and sometimes even neutralizing this risk.

163
00:05:34,129 --> 00:05:36,129
So if the data gets compromised, the hackers steal

164
00:05:36,129 --> 00:05:38,170
the data, you still are protected because

165
00:05:38,170 --> 00:05:40,389
they've gained nothing of value. All of the data

166
00:05:40,389 --> 00:05:42,608
still is non-sensitive and

167
00:05:42,608 --> 00:05:44,720
can be safely used in in these

168
00:05:44,720 --> 00:05:45,290
contexts.

169
00:05:45,649 --> 00:05:47,988
The second part of this which is critical

170
00:05:47,988 --> 00:05:50,149
is that. It needs to enable

171
00:05:50,149 --> 00:05:52,428
your analytic use cases and your AI

172
00:05:52,428 --> 00:05:54,809
training and other uh AI enabled workflows,

173
00:05:55,069 --> 00:05:56,170
uh, for that

174
00:05:56,629 --> 00:05:58,629
we need to preserve the format, we need to preserve

175
00:05:58,629 --> 00:06:00,670
the statistical properties and other desirable

176
00:06:00,670 --> 00:06:02,670
characteristics of the data and not lose

177
00:06:02,670 --> 00:06:04,329
them as you desensitize this data

178
00:06:04,790 --> 00:06:06,809
and this allows uh all of these

179
00:06:06,988 --> 00:06:08,988
AI workloads and analytic engines

180
00:06:08,988 --> 00:06:11,750
to run with very minor modifications

181
00:06:11,750 --> 00:06:12,588
and uh

182
00:06:13,028 --> 00:06:15,149
not use that utility of the data that we

183
00:06:15,149 --> 00:06:15,750
had talked about.

184
00:06:16,500 --> 00:06:19,088
Uh, through these, uh, techniques,

185
00:06:19,350 --> 00:06:21,428
if the risk is virtually eliminated now

186
00:06:21,428 --> 00:06:23,608
you can open the floodgates, you can freely use this,

187
00:06:23,959 --> 00:06:26,149
uh, to train, use this data to, through your

188
00:06:26,149 --> 00:06:27,980
AI data pipelines for model training,

189
00:06:28,259 --> 00:06:29,108
decision making, etc.

190
00:06:29,459 --> 00:06:31,879
So that's, that's the approach that we are advocating

191
00:06:31,879 --> 00:06:32,970
for and then we'll see how

192
00:06:33,798 --> 00:06:36,108
Keplerman worked through this journey and, um, talk

193
00:06:36,108 --> 00:06:36,928
through some of our

194
00:06:37,230 --> 00:06:37,988
learnings from there.

195
00:06:39,910 --> 00:06:40,928
So, uh,

196
00:06:41,309 --> 00:06:43,309
I wanna kind of take a step back and when we talk

197
00:06:43,309 --> 00:06:44,528
about protecting data,

198
00:06:44,988 --> 00:06:47,309
um, there is a spectrum, um,

199
00:06:47,350 --> 00:06:49,689
of of of this landscape of data protection,

200
00:06:49,988 --> 00:06:51,009
uh, that you see out here.

201
00:06:51,298 --> 00:06:53,588
So on the left you have methods like your deletion,

202
00:06:53,709 --> 00:06:56,149
masking, reduction. These are typically

203
00:06:56,149 --> 00:06:58,009
non-reversible. There are some cases where,

204
00:06:58,509 --> 00:07:00,750
uh, there's some reversible masking that has been

205
00:07:00,750 --> 00:07:01,278
attempted

206
00:07:01,548 --> 00:07:03,709
and they are the key part here is that they are

207
00:07:03,709 --> 00:07:05,889
somewhat destructive to the utility of the data.

208
00:07:06,290 --> 00:07:07,920
So they're great for reducing the risk,

209
00:07:08,250 --> 00:07:10,319
but they also compromise the,

210
00:07:10,399 --> 00:07:12,528
the utility of your data. So as an

211
00:07:12,528 --> 00:07:14,809
example, you can't train your models, AI models

212
00:07:14,809 --> 00:07:16,809
on deleted data. You, you can't train them

213
00:07:16,809 --> 00:07:18,069
on partially massed data

214
00:07:18,449 --> 00:07:20,488
where only let's say, uh, part of

215
00:07:20,488 --> 00:07:22,750
your strings are available, part of your numbers are available,

216
00:07:23,129 --> 00:07:25,389
um, in, in, in, in the form that

217
00:07:25,449 --> 00:07:26,428
is desensitized.

218
00:07:26,850 --> 00:07:29,209
So let's, uh, kind of look at this landscape,

219
00:07:29,278 --> 00:07:31,238
uh, through this lens. So say I mask a

220
00:07:31,608 --> 00:07:34,009
credit card number to reveal only the last four digits.

221
00:07:34,559 --> 00:07:36,720
I've secured the data, but at the same time I've now

222
00:07:36,720 --> 00:07:38,798
compromised the utility of the data, so I can't

223
00:07:38,798 --> 00:07:39,778
train a fraud model,

224
00:07:40,278 --> 00:07:42,319
uh, where I only know the last four digits and I

225
00:07:42,319 --> 00:07:44,559
can't analyze those spending patterns. It's

226
00:07:44,559 --> 00:07:46,319
safe, but it's not useful. So

227
00:07:46,600 --> 00:07:48,798
how do we sort of, you know, overcome this is

228
00:07:48,798 --> 00:07:51,000
through the other two methods that you see on the right here. So

229
00:07:51,000 --> 00:07:52,769
on the right we have those reversible methods

230
00:07:53,079 --> 00:07:55,600
where, uh, with encryption or tokenization

231
00:07:55,838 --> 00:07:56,759
we can, um,

232
00:07:57,028 --> 00:07:57,939
reverse the process

233
00:07:58,238 --> 00:08:00,519
and at the same time be able to preserve all of that analytic

234
00:08:00,519 --> 00:08:01,238
value, um,

235
00:08:01,759 --> 00:08:03,639
you know, is not lost in in the transformation.

236
00:08:04,358 --> 00:08:06,298
Both allow you to get the original data back

237
00:08:06,720 --> 00:08:08,798
if you, if, uh, the user and in

238
00:08:08,798 --> 00:08:11,259
the context in which they're using it, it's authorized

239
00:08:11,439 --> 00:08:13,798
and you also have access to other, you know, key

240
00:08:13,798 --> 00:08:16,178
material and other things that we need to reverse the transformation

241
00:08:16,639 --> 00:08:18,920
but there are critical differences between the two so

242
00:08:18,920 --> 00:08:21,199
I wanna touch upon a couple of those and

243
00:08:21,199 --> 00:08:23,319
then talk about why, uh, we went

244
00:08:23,319 --> 00:08:25,910
down the tokenization path and,

245
00:08:25,920 --> 00:08:27,920
um, how we sort of affected

246
00:08:27,920 --> 00:08:28,720
that at Capital One.

247
00:08:30,540 --> 00:08:31,809
So if you look at the.

248
00:08:32,739 --> 00:08:35,070
Um, the key differences here,

249
00:08:35,808 --> 00:08:37,879
traditional encryption deals with data

250
00:08:37,879 --> 00:08:39,889
addressed, so it takes your, let's say your nine

251
00:08:39,889 --> 00:08:42,009
digit social number, turns it into a string

252
00:08:42,009 --> 00:08:44,080
of, um, alphanumeric or numeric

253
00:08:44,080 --> 00:08:44,629
characters.

254
00:08:44,928 --> 00:08:46,090
The problem is that.

255
00:08:46,989 --> 00:08:49,379
Unless you're using a format preserving encryption,

256
00:08:49,820 --> 00:08:51,950
um, it breaks your database schemas,

257
00:08:52,460 --> 00:08:54,168
um, it breaks any validation logic,

258
00:08:54,440 --> 00:08:56,558
and most importantly, your AI models

259
00:08:56,558 --> 00:08:58,558
tend to be confused because they can no longer

260
00:08:58,558 --> 00:09:00,558
see the shape and the characteristics of

261
00:09:00,558 --> 00:09:01,129
the data.

262
00:09:01,558 --> 00:09:02,918
Tokenization is

263
00:09:03,288 --> 00:09:05,639
slightly different from this approach. So what

264
00:09:05,639 --> 00:09:07,840
we do there is we replace this with

265
00:09:07,840 --> 00:09:10,149
another similar

266
00:09:10,149 --> 00:09:11,599
formatted string.

267
00:09:12,139 --> 00:09:14,418
And it looks like a credit card number. It

268
00:09:14,418 --> 00:09:16,119
passes the validation checks, etc.

269
00:09:16,379 --> 00:09:18,379
It fits in, you know, with whatever the referential

270
00:09:18,379 --> 00:09:20,500
integrity constraints you might have on your database

271
00:09:20,500 --> 00:09:21,119
columns,

272
00:09:21,489 --> 00:09:22,798
um, so.

273
00:09:23,950 --> 00:09:26,190
To your applications, uh, whether

274
00:09:26,190 --> 00:09:28,330
to be analytic applications or AI

275
00:09:28,330 --> 00:09:30,629
models or pipelines, they did look, looks

276
00:09:30,629 --> 00:09:31,649
real, but

277
00:09:31,908 --> 00:09:34,408
to a bad actor it's meaningless. So even if it's compromised,

278
00:09:34,779 --> 00:09:36,788
it is just a, uh, you know, bunch of

279
00:09:36,788 --> 00:09:39,548
tokens that don't have any value or correlation

280
00:09:39,788 --> 00:09:41,308
to the sensitive information.

281
00:09:41,719 --> 00:09:43,840
So this format preservation length preservation,

282
00:09:43,879 --> 00:09:45,139
all of these characteristics

283
00:09:45,399 --> 00:09:47,440
allows us to secure the data in

284
00:09:47,440 --> 00:09:49,820
use, not just at rest so you can

285
00:09:50,158 --> 00:09:52,200
now do joints across columns and

286
00:09:52,440 --> 00:09:54,519
and the magic key here for AI is that all of

287
00:09:54,519 --> 00:09:55,599
these downstream applications

288
00:09:56,418 --> 00:09:57,460
uh can now

289
00:09:57,989 --> 00:10:00,038
literally consume this data and be able

290
00:10:00,038 --> 00:10:01,158
to, you know,

291
00:10:01,440 --> 00:10:03,599
provide the same level of accuracy and fidelity and we

292
00:10:03,609 --> 00:10:05,678
we'll share some results around this, um, as

293
00:10:05,678 --> 00:10:06,719
we talk this process.

294
00:10:07,288 --> 00:10:09,369
So the, the concept is summarized

295
00:10:09,369 --> 00:10:11,219
at the, uh, in the graphic below.

296
00:10:11,570 --> 00:10:13,590
So you see, uh, uh, the

297
00:10:13,889 --> 00:10:15,308
original Social Security number

298
00:10:15,580 --> 00:10:17,690
is put through a tokenization engine

299
00:10:17,690 --> 00:10:18,849
through APIs, etc.

300
00:10:19,200 --> 00:10:21,769
and then out comes this string that is formatted

301
00:10:21,769 --> 00:10:23,820
exactly like the original Social Security number with the

302
00:10:24,168 --> 00:10:26,450
324 with dashes and we ran

303
00:10:26,450 --> 00:10:28,700
them then that is how it's stored,

304
00:10:28,928 --> 00:10:30,529
so it's stored as modified.

305
00:10:30,950 --> 00:10:33,090
And um that makes it easier

306
00:10:33,090 --> 00:10:35,369
for these uh business tools and others that are

307
00:10:35,710 --> 00:10:37,989
using this to be able to utilize

308
00:10:37,989 --> 00:10:40,029
that uh in the same fashion as they

309
00:10:40,029 --> 00:10:42,029
were with the original data and then you can

310
00:10:42,029 --> 00:10:44,178
now safely do your joints and preserve the analytic

311
00:10:44,178 --> 00:10:45,599
values because uh

312
00:10:45,869 --> 00:10:48,250
there's consistency in terms of that operation. So

313
00:10:48,308 --> 00:10:50,440
if A goes to B somewhere, then A goes to B

314
00:10:50,599 --> 00:10:52,668
everywhere that you see A in your data.

315
00:10:53,889 --> 00:10:54,729
So that's the

316
00:10:55,019 --> 00:10:57,099
uh value that you see here and that's one

317
00:10:57,099 --> 00:10:59,320
of the reasons why we went with the tokenization approach

318
00:10:59,678 --> 00:11:01,700
uh which is uh which we found is far

319
00:11:01,700 --> 00:11:03,168
superior to any other uh

320
00:11:04,058 --> 00:11:05,779
data protection techniques that we talked about.

321
00:11:06,259 --> 00:11:08,830
So in particular what are the uh

322
00:11:09,139 --> 00:11:11,158
key benefits that we get with uh

323
00:11:11,700 --> 00:11:13,840
protecting your sensitive data using tokenization,

324
00:11:14,190 --> 00:11:16,820
uh, beyond just the format preservation

325
00:11:16,820 --> 00:11:18,580
of modern tokenization systems offer.

326
00:11:19,129 --> 00:11:21,489
Sort of the security hygiene for the cloud.

327
00:11:21,639 --> 00:11:23,038
So what we mean by that is,

328
00:11:23,320 --> 00:11:25,509
uh, we have simplified key management. So we are

329
00:11:25,509 --> 00:11:27,960
managing a key for every single read

330
00:11:27,960 --> 00:11:29,869
operation like you would have to do with encryption,

331
00:11:30,158 --> 00:11:32,158
and this becomes a huge bottleneck and the

332
00:11:32,158 --> 00:11:34,200
performance, um, and, and brings

333
00:11:34,200 --> 00:11:36,200
up latency and other issues that, uh, you'll

334
00:11:36,200 --> 00:11:38,649
encounter with the whole, uh, encryption

335
00:11:38,649 --> 00:11:39,178
space.

336
00:11:39,639 --> 00:11:42,000
Uh, the second piece is around the referential integrity,

337
00:11:42,119 --> 00:11:44,239
so the same input always gets the same

338
00:11:44,239 --> 00:11:46,428
token. Uh, this means you can perform your

339
00:11:46,428 --> 00:11:48,788
joints safely across different databases

340
00:11:48,788 --> 00:11:49,750
using the tokens

341
00:11:50,070 --> 00:11:52,389
without ever reversing that tokenization

342
00:11:52,389 --> 00:11:54,710
process. The third piece that is also critical

343
00:11:54,710 --> 00:11:57,029
here is that we embed

344
00:11:57,029 --> 00:11:57,690
metadata,

345
00:11:58,029 --> 00:11:59,580
um. Uh,

346
00:11:59,979 --> 00:12:00,538
such as, you know,

347
00:12:00,859 --> 00:12:02,279
versioning and other logic

348
00:12:02,779 --> 00:12:03,960
inside of the token itself,

349
00:12:04,298 --> 00:12:06,820
so this allows us to do key rotations,

350
00:12:07,019 --> 00:12:09,099
uh, for example, and then, uh, the

351
00:12:09,099 --> 00:12:11,259
system knows, uh, a priori

352
00:12:11,259 --> 00:12:13,580
how to detokenize this based on the

353
00:12:13,580 --> 00:12:15,979
token itself which allows us to do

354
00:12:15,979 --> 00:12:16,639
this, uh.

355
00:12:17,158 --> 00:12:19,239
Key rotation as well as excess any sort of,

356
00:12:19,279 --> 00:12:20,779
you know, bad or compromised data

357
00:12:21,080 --> 00:12:23,080
when that happens and then we can now

358
00:12:23,080 --> 00:12:25,320
safely rotate this without touching the raw data

359
00:12:25,558 --> 00:12:27,599
so this gives us a huge benefit in

360
00:12:27,599 --> 00:12:28,178
terms of

361
00:12:28,479 --> 00:12:30,599
management of this over time as as

362
00:12:30,599 --> 00:12:31,279
changes happen.

363
00:12:31,639 --> 00:12:32,298
The other two,

364
00:12:32,840 --> 00:12:34,580
key pieces mentioned at the bottom here

365
00:12:34,840 --> 00:12:36,960
are the preservation of the analytic value which

366
00:12:36,960 --> 00:12:39,000
we already touched upon and

367
00:12:39,239 --> 00:12:41,460
because of this, uh, the architecture of

368
00:12:41,678 --> 00:12:43,710
this tokenization. Uh, solution

369
00:12:43,710 --> 00:12:44,729
that we'll talk about,

370
00:12:44,989 --> 00:12:47,489
uh, the brute force, key compromises,

371
00:12:47,710 --> 00:12:48,229
um,

372
00:12:48,509 --> 00:12:49,729
become virtually,

373
00:12:50,129 --> 00:12:52,190
uh, infeasible. So we'll, we'll see how that

374
00:12:52,190 --> 00:12:54,009
is possible with, uh, in the next

375
00:12:54,489 --> 00:12:55,308
few slides.

376
00:12:57,048 --> 00:12:59,129
OK, the other key question that you

377
00:12:59,129 --> 00:13:00,548
might be wondering here

378
00:13:00,889 --> 00:13:01,469
is,

379
00:13:02,460 --> 00:13:03,019
Um

380
00:13:03,729 --> 00:13:06,090
Data does the tokenization actually hurt

381
00:13:06,090 --> 00:13:08,090
my model's performance? We did

382
00:13:08,090 --> 00:13:10,250
a study and we'll be releasing the results of this

383
00:13:10,250 --> 00:13:11,668
in the next couple of weeks,

384
00:13:11,969 --> 00:13:14,158
um, where we did a study comparing

385
00:13:14,158 --> 00:13:16,408
three sets of, uh, 3 data sets. So the

386
00:13:16,408 --> 00:13:17,969
original raw clear text data.

387
00:13:18,330 --> 00:13:20,440
Mass data and tokenized data and

388
00:13:20,440 --> 00:13:21,950
we use those to train models

389
00:13:22,239 --> 00:13:24,288
and then we saw a dramatic improvement

390
00:13:24,288 --> 00:13:26,330
in performance with the tokenized data

391
00:13:26,330 --> 00:13:28,668
so you see the, the red box that represents

392
00:13:28,928 --> 00:13:31,210
uh the accuracy of the massed,

393
00:13:31,250 --> 00:13:33,570
uh, the data using the mass uh the

394
00:13:33,570 --> 00:13:34,908
models using the mass data

395
00:13:35,369 --> 00:13:36,750
that drops it from

396
00:13:37,009 --> 00:13:39,548
the clear text baseline of 100% to 50%

397
00:13:39,889 --> 00:13:42,250
in the world of prediction, you know, 50%

398
00:13:42,250 --> 00:13:43,960
is obviously not the greatest slick.

399
00:13:44,408 --> 00:13:46,489
You know, just the same as a coin toss and

400
00:13:46,489 --> 00:13:47,590
practically worthless.

401
00:13:48,009 --> 00:13:50,048
On the other side, when we use tokenized data,

402
00:13:50,129 --> 00:13:51,229
we were able to preserve,

403
00:13:51,690 --> 00:13:54,219
uh, that accuracy. So 99%

404
00:13:54,219 --> 00:13:56,489
of, uh, +% of the predictive accuracy

405
00:13:56,489 --> 00:13:59,038
was, uh, retained with the clear stack

406
00:13:59,038 --> 00:13:59,769
baseline data.

407
00:14:00,590 --> 00:14:02,729
Um, so what this means is that you can now

408
00:14:02,729 --> 00:14:04,808
train your models, um, on

409
00:14:04,808 --> 00:14:06,928
safe compliant data and still

410
00:14:06,928 --> 00:14:08,190
get the same results

411
00:14:08,489 --> 00:14:10,489
that you would that are virtually identical to

412
00:14:10,489 --> 00:14:12,519
training that on the raw sensitive

413
00:14:12,519 --> 00:14:14,769
data. So you get nearly identical model

414
00:14:14,769 --> 00:14:16,808
performance with virtually zero risk with

415
00:14:16,808 --> 00:14:18,969
this. So that's why we went down this path

416
00:14:18,969 --> 00:14:19,830
of, uh,

417
00:14:20,330 --> 00:14:22,619
doing all of our data protection

418
00:14:22,690 --> 00:14:25,210
anchoring on, on, uh, tokenization.

419
00:14:26,759 --> 00:14:29,139
So, shifting gears a little bit, let's maybe

420
00:14:29,359 --> 00:14:30,759
look at the concepts here.

421
00:14:31,038 --> 00:14:33,038
So we looked at what tokenization

422
00:14:33,038 --> 00:14:33,798
offers us.

423
00:14:34,080 --> 00:14:36,119
Let's see how that is actually done in

424
00:14:36,119 --> 00:14:39,009
practice. So

425
00:14:39,009 --> 00:14:41,308
here's a little cartoon that explains this.

426
00:14:41,808 --> 00:14:43,908
Um, so you'll see on the top here,

427
00:14:44,519 --> 00:14:46,609
uh, so the sensitive data, this could be a Social Security

428
00:14:46,609 --> 00:14:48,750
number that is being fed into your

429
00:14:48,750 --> 00:14:50,769
applications, uh, the tokenization

430
00:14:50,769 --> 00:14:52,849
engine, API or whatever you're using will

431
00:14:52,849 --> 00:14:55,320
request uh token. So all of the

432
00:14:55,320 --> 00:14:57,729
crypto material and all the magic with all the algorithms

433
00:14:57,729 --> 00:15:00,048
behind the scenes will convert that, uh,

434
00:15:00,320 --> 00:15:02,570
raw sensitive data into a token that

435
00:15:02,570 --> 00:15:04,759
preserves the format and length, etc. and

436
00:15:04,759 --> 00:15:06,769
then it returns that token that you see there starting with the

437
00:15:06,769 --> 00:15:07,570
5C7.

438
00:15:08,548 --> 00:15:10,330
And that data is now uh

439
00:15:10,668 --> 00:15:12,849
stored in wherever your uh

440
00:15:13,029 --> 00:15:15,229
data, wherever the original data sources, and

441
00:15:15,229 --> 00:15:17,308
then the applications can now safely use that

442
00:15:17,548 --> 00:15:19,710
proxy or the surrogate token wherever

443
00:15:19,710 --> 00:15:21,048
the original data was needed

444
00:15:21,469 --> 00:15:23,629
and because of its uh format preserving

445
00:15:23,629 --> 00:15:25,750
link preserving all of these other characteristics we can now

446
00:15:25,750 --> 00:15:26,369
use this

447
00:15:26,788 --> 00:15:28,869
consistently across your entire landscape and you

448
00:15:28,869 --> 00:15:29,570
won't lose any

449
00:15:29,950 --> 00:15:31,349
referential integrity issues. You

450
00:15:31,750 --> 00:15:33,830
won't run into this. But how do you actually implement

451
00:15:33,830 --> 00:15:36,048
this in a modern cloud native

452
00:15:36,269 --> 00:15:36,969
sort of environment.

453
00:15:37,450 --> 00:15:38,428
And without,

454
00:15:38,928 --> 00:15:41,019
uh, you know, grinding, bringing your

455
00:15:41,019 --> 00:15:42,190
operations to a grinding halt.

456
00:15:42,808 --> 00:15:43,428
So that's how

457
00:15:44,009 --> 00:15:46,129
we want to talk about next in, in our case study

458
00:15:46,129 --> 00:15:46,928
with Capital One.

459
00:15:49,629 --> 00:15:50,288
So,

460
00:15:50,869 --> 00:15:53,349
uh, our journey with tokenization

461
00:15:53,349 --> 00:15:54,349
began, um,

462
00:15:54,629 --> 00:15:56,928
around 2016. We were a traditional bank.

463
00:15:57,029 --> 00:15:59,070
We had a lot of on-premise data centers

464
00:15:59,070 --> 00:16:00,450
and lots of data over there,

465
00:16:00,788 --> 00:16:02,830
but we made this very bold decision, um,

466
00:16:02,908 --> 00:16:05,149
in 2016 to go all in on the cloud,

467
00:16:05,428 --> 00:16:06,808
on the public cloud in particular.

468
00:16:07,190 --> 00:16:09,269
By 2020 we had completed this transformation,

469
00:16:09,308 --> 00:16:11,469
exited our data centers entirely,

470
00:16:11,750 --> 00:16:13,950
and we were the first major bank, uh, to

471
00:16:13,950 --> 00:16:14,710
do, do so.

472
00:16:15,259 --> 00:16:16,330
But that migration

473
00:16:16,710 --> 00:16:18,769
came with a sort of a little twist here,

474
00:16:18,788 --> 00:16:20,729
so we had to move these petabytes of data

475
00:16:21,190 --> 00:16:23,330
in, you know, highly sensitive financial data

476
00:16:23,330 --> 00:16:24,190
into the cloud

477
00:16:24,460 --> 00:16:26,469
and our old data security

478
00:16:26,469 --> 00:16:27,678
approaches couldn't keep up

479
00:16:27,950 --> 00:16:29,979
so they became bottlenecks for us. So how do,

480
00:16:30,139 --> 00:16:30,989
how do we kind of, you know,

481
00:16:31,349 --> 00:16:32,869
get, you know, get over this bottleneck?

482
00:16:33,489 --> 00:16:36,070
Uh, we looked at a lot of, uh, technologies

483
00:16:36,070 --> 00:16:37,690
out there, uh, did a.

484
00:16:38,038 --> 00:16:39,979
A lot of evaluations of of these

485
00:16:40,288 --> 00:16:42,538
uh and we found out that there's nothing that could

486
00:16:42,710 --> 00:16:44,918
offer the performance and scale that we needed for

487
00:16:44,918 --> 00:16:45,700
our data

488
00:16:46,000 --> 00:16:48,158
so we ended up building our own

489
00:16:48,158 --> 00:16:49,000
engine so

490
00:16:49,320 --> 00:16:50,908
we built our own token tokenization engine from the ground up

491
00:16:51,298 --> 00:16:53,320
and designed

492
00:16:53,320 --> 00:16:55,479
it specifically for the elasticity

493
00:16:55,479 --> 00:16:57,519
and other characteristics uh that

494
00:16:57,519 --> 00:16:58,879
we needed in the cloud.

495
00:16:59,229 --> 00:17:01,548
So that engine has become like the de facto standard

496
00:17:01,548 --> 00:17:03,808
and core pillar of our data security across

497
00:17:03,940 --> 00:17:06,189
Capital One today and it's like

498
00:17:06,430 --> 00:17:08,818
it kind of underpins our entire data security strategy

499
00:17:08,818 --> 00:17:09,529
at Capital One.

500
00:17:10,269 --> 00:17:12,410
So we took these learnings and then

501
00:17:12,430 --> 00:17:12,989
um

502
00:17:13,430 --> 00:17:14,009
as a

503
00:17:14,348 --> 00:17:15,328
we realized that hey.

504
00:17:16,417 --> 00:17:18,479
There is a huge amount of value here

505
00:17:18,678 --> 00:17:20,817
that can, you know, we can

506
00:17:20,817 --> 00:17:22,817
give to other enterprises outside if we

507
00:17:22,817 --> 00:17:24,898
share this technology, so we decided to productize

508
00:17:24,898 --> 00:17:26,938
this through, uh, the Capital One

509
00:17:26,938 --> 00:17:29,138
software entity that we founded

510
00:17:29,138 --> 00:17:31,239
in 2022 and then we launched this product

511
00:17:31,428 --> 00:17:33,208
as what we call, uh, as data board

512
00:17:33,659 --> 00:17:35,077
in April 2025,

513
00:17:35,347 --> 00:17:37,759
um, at the RSA conference earlier this year.

514
00:17:38,150 --> 00:17:40,150
And this is what we will talk about in

515
00:17:40,150 --> 00:17:42,170
the rest of this presentation of uh

516
00:17:42,430 --> 00:17:44,818
how what the benefits are and how we, uh,

517
00:17:44,828 --> 00:17:46,868
you know, what that has netted us and some

518
00:17:46,868 --> 00:17:48,868
patterns that we've learned in the

519
00:17:48,868 --> 00:17:50,969
usage of these kinds of technologies

520
00:17:51,108 --> 00:17:53,338
in terms of securing data at scale with cloud

521
00:17:53,338 --> 00:17:55,150
native uh environments.

522
00:17:57,689 --> 00:18:00,049
So just to kind of give you a bit of context

523
00:18:00,049 --> 00:18:02,289
on this, uh, the scale of this whole

524
00:18:02,289 --> 00:18:04,289
tokenization engine and how it's used

525
00:18:04,289 --> 00:18:05,088
at Capital One.

526
00:18:05,469 --> 00:18:05,979
Um,

527
00:18:06,279 --> 00:18:06,818
we protect

528
00:18:07,318 --> 00:18:09,358
over 29 different types of sensitive elements,

529
00:18:09,640 --> 00:18:11,719
everything from your Social Security numbers to dates

530
00:18:11,719 --> 00:18:12,519
of birth or

531
00:18:12,989 --> 00:18:15,519
custom, you know, customer account IDs, etc.

532
00:18:15,910 --> 00:18:18,118
Over 900 applications, um,

533
00:18:18,199 --> 00:18:20,519
all hitting this, you know, massive

534
00:18:20,519 --> 00:18:22,799
tokenization infrastructure internally

535
00:18:23,000 --> 00:18:24,420
and then billions of records

536
00:18:24,719 --> 00:18:27,068
where, you know, across our enterprise that are,

537
00:18:27,078 --> 00:18:29,059
um, used,

538
00:18:29,479 --> 00:18:32,098
um, and then all of this is AWS native,

539
00:18:32,199 --> 00:18:33,939
so when you operate at this scale,

540
00:18:34,439 --> 00:18:37,160
um. We, you know, latency

541
00:18:37,160 --> 00:18:39,338
is, uh, it's not just an annoyance, it

542
00:18:39,338 --> 00:18:40,078
becomes a failure

543
00:18:40,420 --> 00:18:41,739
of the design. So we've

544
00:18:42,019 --> 00:18:44,459
very carefully architect this, uh, tokenization

545
00:18:44,459 --> 00:18:45,618
engine to

546
00:18:46,019 --> 00:18:48,019
really be very highly performing

547
00:18:48,019 --> 00:18:49,318
and have very low latency.

548
00:18:49,660 --> 00:18:50,818
So what this means is that.

549
00:18:51,430 --> 00:18:52,660
As a digital bank

550
00:18:52,920 --> 00:18:55,000
we really need to have a real-time highly

551
00:18:55,000 --> 00:18:57,118
available fault tolerant service that

552
00:18:57,118 --> 00:18:58,180
we can rely upon

553
00:18:58,469 --> 00:19:00,670
to be able to do this. So that's, that's what,

554
00:19:00,689 --> 00:19:02,719
uh, we've built and we'll talk through some

555
00:19:02,719 --> 00:19:04,259
of the characteristics of this and

556
00:19:04,568 --> 00:19:06,598
then I will do a deep dive into some of our learnings from

557
00:19:06,598 --> 00:19:07,578
there and, and,

558
00:19:07,858 --> 00:19:09,309
uh, how we can kind of, you know,

559
00:19:09,598 --> 00:19:11,598
expand the footprint of these, uh, use cases

560
00:19:11,598 --> 00:19:13,939
that we can address, especially from an AI perspective,

561
00:19:14,160 --> 00:19:15,578
uh, with this

562
00:19:16,118 --> 00:19:18,529
solution. OK,

563
00:19:18,660 --> 00:19:20,818
so one of the key underpinnings of

564
00:19:20,818 --> 00:19:22,459
our tokenization solution

565
00:19:22,779 --> 00:19:24,779
um is the concept of a vaultless

566
00:19:24,779 --> 00:19:25,500
tokenization.

567
00:19:25,809 --> 00:19:28,098
Traditional tokenization approach you have relied

568
00:19:28,098 --> 00:19:30,338
on a vault, which is a massive central

569
00:19:30,338 --> 00:19:32,380
database which maps your sensitive

570
00:19:32,380 --> 00:19:34,539
data to the tokens or the

571
00:19:34,539 --> 00:19:36,009
proxies or surrogate values.

572
00:19:36,699 --> 00:19:37,479
The problem

573
00:19:37,969 --> 00:19:40,318
with this is that because it's a database,

574
00:19:40,539 --> 00:19:42,160
it quickly becomes a bottleneck.

575
00:19:42,420 --> 00:19:43,259
Every time you need,

576
00:19:43,719 --> 00:19:45,779
every, every time you need a token, you have to

577
00:19:45,779 --> 00:19:46,838
do a database lookup.

578
00:19:47,338 --> 00:19:49,390
And because of that, it adds latency and

579
00:19:49,390 --> 00:19:50,670
creates a single point of failure.

580
00:19:51,318 --> 00:19:53,519
Um, and it also becomes a massive

581
00:19:53,519 --> 00:19:54,689
attack vector for your, uh,

582
00:19:55,029 --> 00:19:57,088
hackers. In fact, your

583
00:19:57,088 --> 00:19:59,108
vault becomes a honey pot. So if a

584
00:19:59,400 --> 00:20:00,739
hacker breaches this

585
00:20:01,078 --> 00:20:03,400
database, they have keys to the entire kingdom. So

586
00:20:03,400 --> 00:20:05,640
mapping of every piece of sensitive information that you have.

587
00:20:06,239 --> 00:20:07,500
So we thought

588
00:20:07,799 --> 00:20:09,739
long and hard and came up with a

589
00:20:10,039 --> 00:20:11,259
solution for this, which is

590
00:20:11,559 --> 00:20:13,170
what we call the worldless architecture.

591
00:20:13,489 --> 00:20:15,848
So. We use a deterministic

592
00:20:15,848 --> 00:20:18,269
algorithmic approach. We generate these tokens

593
00:20:18,759 --> 00:20:20,930
cry with crypto algorithms that are

594
00:20:21,848 --> 00:20:22,519
now even call them safe

595
00:20:22,789 --> 00:20:25,019
rather than database lookups. This offers infinite

596
00:20:25,019 --> 00:20:26,088
scale for us,

597
00:20:26,719 --> 00:20:28,779
uh, because we aren't limited by the database IO

598
00:20:28,779 --> 00:20:31,068
in this case, and it gives us

599
00:20:31,068 --> 00:20:33,449
the, uh, the nice characteristics of.

600
00:20:33,769 --> 00:20:35,890
Uh, highly performing and you

601
00:20:35,890 --> 00:20:38,009
know, the tokenization operation itself

602
00:20:38,009 --> 00:20:40,088
having very, very low latency in overhead, so it

603
00:20:40,088 --> 00:20:41,318
happens in microseconds.

604
00:20:41,769 --> 00:20:44,029
So this enables real-time use cases

605
00:20:44,170 --> 00:20:46,170
such as fraud detection that were previously

606
00:20:46,170 --> 00:20:48,108
very difficult to achieve with a vaulted approach.

607
00:20:48,500 --> 00:20:50,848
So we kind of anchored our, our tokenization

608
00:20:50,848 --> 00:20:52,430
engine on this, uh,

609
00:20:52,809 --> 00:20:54,868
key, uh, sort of

610
00:20:55,170 --> 00:20:57,068
scale, uh, scaling and artifact.

611
00:20:59,098 --> 00:21:00,920
So, um, as we

612
00:21:01,259 --> 00:21:03,420
built and matured this tokenization, um,

613
00:21:03,699 --> 00:21:04,239
engine within,

614
00:21:04,500 --> 00:21:05,489
uh, Capital One,

615
00:21:05,779 --> 00:21:07,439
we saw the opportunity that,

616
00:21:08,019 --> 00:21:09,880
hey, this is a universal problem. So

617
00:21:10,259 --> 00:21:12,539
how about we think about, you know, helping

618
00:21:12,539 --> 00:21:13,400
other enterprises

619
00:21:13,739 --> 00:21:15,900
by commercializing this technology, um, outside

620
00:21:15,900 --> 00:21:16,598
of Capital One.

621
00:21:16,900 --> 00:21:19,039
So as part of Capital One software

622
00:21:19,140 --> 00:21:21,459
we launched this product called Data World back in April.

623
00:21:21,650 --> 00:21:22,469
Mentioned before

624
00:21:22,769 --> 00:21:24,809
and this is uh designed

625
00:21:24,809 --> 00:21:26,809
with all of these um elements that you

626
00:21:26,809 --> 00:21:29,009
see here so it provides you the same advanced security

627
00:21:29,009 --> 00:21:29,630
models

628
00:21:29,930 --> 00:21:32,709
um it gives you the cloud native architecture

629
00:21:32,939 --> 00:21:34,949
and it gives you lightning fast performance

630
00:21:35,180 --> 00:21:37,479
and it represents an evolution so we did a,

631
00:21:37,789 --> 00:21:39,848
uh, a few added a few bells and whistles

632
00:21:39,848 --> 00:21:42,029
on top of our tokenization engine,

633
00:21:42,289 --> 00:21:44,568
uh, for this to be consumable

634
00:21:44,568 --> 00:21:46,180
outside of Capital One as an enterprise.

635
00:21:46,568 --> 00:21:48,568
So in particular there were some architectural

636
00:21:48,568 --> 00:21:49,769
elements that, um.

637
00:21:50,239 --> 00:21:52,439
Uh, enabled us to do this. This

638
00:21:52,439 --> 00:21:54,519
is where we have a separation of,

639
00:21:54,529 --> 00:21:56,358
uh, duties. So we have a control plane

640
00:21:56,640 --> 00:21:58,719
where you manage all of the metadata, the

641
00:21:58,719 --> 00:22:00,400
policies and keys, etc.

642
00:22:00,719 --> 00:22:02,789
and these sit securely in Capital One's

643
00:22:02,789 --> 00:22:03,338
cloud.

644
00:22:03,680 --> 00:22:05,939
Then there's components that you drop into the,

645
00:22:05,959 --> 00:22:07,420
uh, the customer environments

646
00:22:07,719 --> 00:22:09,818
where the tokenization happens actually. So

647
00:22:10,170 --> 00:22:11,459
what this means is that

648
00:22:11,719 --> 00:22:13,328
it happens within your. Network,

649
00:22:13,588 --> 00:22:15,789
uh, your data never leaves that

650
00:22:15,789 --> 00:22:18,140
environment and comes into the Capital One plane. Only

651
00:22:18,140 --> 00:22:20,390
the metadata is provided there and

652
00:22:20,390 --> 00:22:22,509
then you keep custody of your data. We

653
00:22:22,509 --> 00:22:24,828
never see your sensitive information. So we

654
00:22:24,828 --> 00:22:27,328
built with all of these, uh, architectural

655
00:22:27,328 --> 00:22:28,959
and other constraints in mind,

656
00:22:29,449 --> 00:22:31,509
um, and then Vinai will walk you through the

657
00:22:31,509 --> 00:22:33,630
product and, um, you know, the

658
00:22:33,630 --> 00:22:35,670
capabilities there and also some of our learnings as

659
00:22:35,670 --> 00:22:36,969
we build this and scale this

660
00:22:37,568 --> 00:22:39,729
over to you. Thanks.

661
00:22:41,108 --> 00:22:42,189
Uh, hi, everybody.

662
00:22:42,469 --> 00:22:44,630
My name is Vinayan Kullaule. Uh, I'm the senior

663
00:22:44,630 --> 00:22:46,328
Distribution engineer at Capital One.

664
00:22:47,269 --> 00:22:49,989
I would like to take, uh, next few minutes to peel

665
00:22:49,989 --> 00:22:52,029
back the layer of this architecture at a very

666
00:22:52,029 --> 00:22:52,650
high level.

667
00:22:53,098 --> 00:22:55,309
Uh, as you can see, uh, Data Bolt

668
00:22:55,309 --> 00:22:56,189
operates,

669
00:22:56,469 --> 00:22:58,630
uh, on a hybrid deployment model, which

670
00:22:58,630 --> 00:23:00,630
is designed specifically for the

671
00:23:00,630 --> 00:23:02,328
security and resiliency.

672
00:23:03,459 --> 00:23:04,880
On the left side of your screen,

673
00:23:05,150 --> 00:23:06,410
you see a control plane.

674
00:23:06,670 --> 00:23:08,789
That control plane is deployed within

675
00:23:08,789 --> 00:23:10,509
Capital One software's cloud environment.

676
00:23:10,890 --> 00:23:13,049
It handles the management traffic. Uh,

677
00:23:13,779 --> 00:23:14,949
by management traffic, I mean,

678
00:23:15,279 --> 00:23:17,539
The configuration and the access policies,

679
00:23:17,920 --> 00:23:20,000
uh, and it also serves artifacts

680
00:23:20,000 --> 00:23:21,219
like SDKs,

681
00:23:21,479 --> 00:23:22,098
uh,

682
00:23:22,358 --> 00:23:23,900
your documentations as well.

683
00:23:24,279 --> 00:23:26,500
Uh, this is the place where you go

684
00:23:26,500 --> 00:23:27,729
and configure your SSO,

685
00:23:28,479 --> 00:23:30,598
uh, this is the place where you go and

686
00:23:30,598 --> 00:23:33,000
see your audit, uh, analytics dashboards

687
00:23:33,000 --> 00:23:33,699
as well.

688
00:23:34,209 --> 00:23:36,519
Uh, on the right, uh, you

689
00:23:36,519 --> 00:23:38,789
see a data plane. This is our, uh,

690
00:23:38,799 --> 00:23:39,479
core engine.

691
00:23:40,848 --> 00:23:42,989
This entirely runs, uh,

692
00:23:43,009 --> 00:23:45,170
within your ecosystem as

693
00:23:45,170 --> 00:23:47,140
you mentioned. So.

694
00:23:49,078 --> 00:23:51,019
Every operation is, uh,

695
00:23:51,529 --> 00:23:53,640
is within its its own memory. That

696
00:23:53,640 --> 00:23:54,858
means, uh, this

697
00:23:55,189 --> 00:23:57,630
sensitive data is not going

698
00:23:57,630 --> 00:23:59,868
outside of that process and your

699
00:23:59,868 --> 00:24:01,098
network boundary as well.

700
00:24:01,680 --> 00:24:03,680
This data never reaches our control

701
00:24:03,680 --> 00:24:05,818
plane, so you can be very sure that,

702
00:24:05,880 --> 00:24:08,059
uh, Capital One does not have access to your data.

703
00:24:09,289 --> 00:24:10,729
And this data plan can run

704
00:24:11,140 --> 00:24:13,430
in, uh, in your AWS

705
00:24:13,430 --> 00:24:14,009
VPC

706
00:24:14,299 --> 00:24:16,299
on uh the cloud or

707
00:24:16,299 --> 00:24:18,759
even on on-prem data center as well.

708
00:24:19,578 --> 00:24:21,969
Uh. The critical part,

709
00:24:22,108 --> 00:24:23,809
uh, that I talked about is

710
00:24:24,390 --> 00:24:26,750
all these tokenization detoxation operations

711
00:24:26,750 --> 00:24:27,529
are happening

712
00:24:27,789 --> 00:24:29,489
within the memory. That means

713
00:24:29,910 --> 00:24:32,108
we can do these operations very

714
00:24:32,108 --> 00:24:34,259
fast. You

715
00:24:34,259 --> 00:24:35,519
don't have to

716
00:24:35,939 --> 00:24:38,098
basically do a database lookup as uh Srikan

717
00:24:38,098 --> 00:24:38,900
mentioned earlier.

718
00:24:40,390 --> 00:24:42,549
The other thing that I would like to talk about

719
00:24:42,549 --> 00:24:43,390
is, uh,

720
00:24:43,670 --> 00:24:44,410
I get, uh,

721
00:24:44,670 --> 00:24:46,719
asked a lot, what happens if control plane

722
00:24:46,719 --> 00:24:47,489
goes down?

723
00:24:47,989 --> 00:24:48,608
Uh,

724
00:24:48,989 --> 00:24:51,489
don't worry, we built this for, uh, resiliency.

725
00:24:52,900 --> 00:24:55,098
When the data plane boots up, uh, it

726
00:24:55,098 --> 00:24:55,799
basically

727
00:24:56,098 --> 00:24:58,259
establishes a secure channel with the

728
00:24:58,259 --> 00:24:58,880
control plane

729
00:24:59,140 --> 00:25:01,500
to fetch its configuration and the cryptographic

730
00:25:01,500 --> 00:25:04,098
material, uh, and we take this communication

731
00:25:04,098 --> 00:25:05,279
path very seriously.

732
00:25:05,699 --> 00:25:07,739
Uh, we don't want anybody

733
00:25:07,739 --> 00:25:09,858
to save this traffic and decrypt

734
00:25:09,858 --> 00:25:11,858
later, so, uh, we

735
00:25:11,858 --> 00:25:12,459
use

736
00:25:12,799 --> 00:25:15,098
a NIST approved post quantum algorithm,

737
00:25:15,380 --> 00:25:17,618
uh, on top of regular TLS to secure

738
00:25:17,618 --> 00:25:18,439
this traffic.

739
00:25:19,578 --> 00:25:22,009
Once initialized, uh, this data plane,

740
00:25:22,289 --> 00:25:24,729
uh, caches this information in memory and

741
00:25:24,729 --> 00:25:26,269
continues its its operation. So,

742
00:25:26,689 --> 00:25:28,229
in the event the control plane,

743
00:25:28,568 --> 00:25:30,769
uh, is unreachable, uh, the airplane

744
00:25:30,769 --> 00:25:33,489
can continue its operations autonomously.

745
00:25:34,219 --> 00:25:36,338
Your workload will continue running

746
00:25:36,338 --> 00:25:38,838
without a hiccup even if control panel is not available.

747
00:25:39,259 --> 00:25:41,118
This share nothing runtime approach

748
00:25:41,500 --> 00:25:43,689
ensures that our availability issues, uh,

749
00:25:43,699 --> 00:25:44,519
will never become

750
00:25:44,900 --> 00:25:46,160
your availability issues.

751
00:25:48,000 --> 00:25:50,189
Uh, let's go a little deeper,

752
00:25:50,289 --> 00:25:52,358
uh, on the benefits and

753
00:25:52,358 --> 00:25:54,088
the characters of a data volt.

754
00:25:54,568 --> 00:25:56,969
Uh, Shikan already alluded to the fact

755
00:25:56,969 --> 00:25:58,828
that we use a vaultless architecture.

756
00:25:59,328 --> 00:26:02,150
Uh, in a traditional, uh, vaulted architecture,

757
00:26:02,358 --> 00:26:04,549
you have a massive, uh, central vault.

758
00:26:06,368 --> 00:26:08,759
And uh you store with mapping

759
00:26:08,759 --> 00:26:10,809
between uh your sensitive data and

760
00:26:10,809 --> 00:26:11,868
the token in that pot.

761
00:26:12,170 --> 00:26:14,170
It, it works for the small data sets,

762
00:26:14,608 --> 00:26:16,769
but, uh, when you scale it to the uh

763
00:26:16,769 --> 00:26:18,140
enterprise like bank,

764
00:26:18,449 --> 00:26:20,630
uh, it quickly becomes a bottleneck,

765
00:26:20,848 --> 00:26:22,890
uh, and a massive cost center as

766
00:26:22,890 --> 00:26:24,809
well, uh, and Shik can already

767
00:26:25,930 --> 00:26:28,469
mentioned about the security issues that it brings.

768
00:26:29,170 --> 00:26:31,180
That's why, uh, we chose Waltless

769
00:26:31,180 --> 00:26:32,709
architecture for Data bolt.

770
00:26:33,559 --> 00:26:35,818
DataW uses deterministic

771
00:26:36,000 --> 00:26:37,779
and format-preserving algorithms.

772
00:26:38,318 --> 00:26:40,519
We don't store the mapping, we compare that

773
00:26:40,519 --> 00:26:41,279
mathematically.

774
00:26:42,519 --> 00:26:45,019
And since there is no, uh,

775
00:26:45,029 --> 00:26:47,209
database look up, I've uh repeated this this

776
00:26:47,209 --> 00:26:47,769
many times,

777
00:26:48,130 --> 00:26:50,150
uh, we, we can offer

778
00:26:50,150 --> 00:26:52,318
a single load digit millisecond

779
00:26:52,318 --> 00:26:53,818
latency for this operation.

780
00:26:54,328 --> 00:26:56,588
So, uh, you can scale infinitely.

781
00:26:56,848 --> 00:26:57,828
Uh, you don't,

782
00:26:58,410 --> 00:27:00,529
if, if you need a high throughput, you just need to spin up

783
00:27:00,529 --> 00:27:02,608
more, uh, data blend parts and you

784
00:27:02,608 --> 00:27:04,390
get that, uh, for free.

785
00:27:05,390 --> 00:27:06,809
Now regarding security,

786
00:27:07,108 --> 00:27:09,309
uh, being from Capital One, we are

787
00:27:09,309 --> 00:27:10,969
very paranoid about the security,

788
00:27:11,459 --> 00:27:13,680
uh, in our inter interim implementation,

789
00:27:13,868 --> 00:27:16,108
we assume that the host is

790
00:27:16,108 --> 00:27:16,969
compromised.

791
00:27:17,269 --> 00:27:19,390
Uh, that's the reason we have employed

792
00:27:19,390 --> 00:27:21,709
advanced memory techniques to safeguard

793
00:27:21,709 --> 00:27:23,750
this cryptographic material in memory as well.

794
00:27:24,068 --> 00:27:26,140
These, uh, keys which are in memory

795
00:27:26,140 --> 00:27:27,000
are scrambled.

796
00:27:27,328 --> 00:27:29,500
In such a way that uh if the bad actor

797
00:27:29,500 --> 00:27:31,618
gets access to the host and it dumps

798
00:27:31,618 --> 00:27:34,500
the memory, they will not be able to extract

799
00:27:34,858 --> 00:27:36,900
the keys from the dump as well. It will

800
00:27:36,900 --> 00:27:38,939
be practically infeasible and

801
00:27:38,939 --> 00:27:39,719
we carried

802
00:27:39,979 --> 00:27:41,979
this, uh, these security measures to

803
00:27:41,979 --> 00:27:42,838
Datavolt as well.

804
00:27:43,568 --> 00:27:46,088
Uh, we also support, uh, tokenization

805
00:27:46,088 --> 00:27:48,269
on right, uh, via our SDKs,

806
00:27:48,568 --> 00:27:50,890
uh, which can, uh, seamlessly

807
00:27:50,890 --> 00:27:52,029
integrate with your code,

808
00:27:52,449 --> 00:27:54,519
uh, in the platform like Snowflake, Data

809
00:27:54,519 --> 00:27:55,189
bricks,

810
00:27:55,650 --> 00:27:57,799
uh, and for monitoring, uh,

811
00:27:57,930 --> 00:27:58,858
we use Otel.

812
00:27:59,449 --> 00:28:01,449
That means, uh, our customers don't

813
00:28:01,449 --> 00:28:02,299
have to use,

814
00:28:02,568 --> 00:28:04,848
they can use their, uh, existing monitoring tools,

815
00:28:04,920 --> 00:28:06,229
uh, to monitor data bolt.

816
00:28:07,420 --> 00:28:08,140
Moving on

817
00:28:09,088 --> 00:28:10,949
Uh, in our experience,

818
00:28:11,229 --> 00:28:13,328
uh, for most enterprise, uh,

819
00:28:14,118 --> 00:28:16,289
organizations, analytics is the first

820
00:28:16,289 --> 00:28:17,709
use case for tokenization.

821
00:28:18,328 --> 00:28:20,650
The data dilemma that Shikan talked about

822
00:28:20,809 --> 00:28:22,380
is the most acute here.

823
00:28:22,969 --> 00:28:25,049
Uh, you have data scientists, analysis,

824
00:28:25,189 --> 00:28:26,108
uh, analysts,

825
00:28:26,449 --> 00:28:28,479
uh, that want, uh, uh,

826
00:28:29,189 --> 00:28:30,670
those, uh, they want access,

827
00:28:31,130 --> 00:28:33,269
access to, uh, high fidelity production data

828
00:28:33,809 --> 00:28:36,130
to, um, uh, build models

829
00:28:36,130 --> 00:28:37,130
to run reports.

830
00:28:38,068 --> 00:28:40,259
But you cannot give them, uh, access to raw

831
00:28:40,259 --> 00:28:41,209
PII data.

832
00:28:41,910 --> 00:28:43,250
Uh, historically, uh,

833
00:28:43,640 --> 00:28:44,930
organizations have used masking,

834
00:28:45,509 --> 00:28:47,588
but, uh, masking is just, uh, they

835
00:28:47,588 --> 00:28:49,000
just replace the data with asterisk

836
00:28:49,699 --> 00:28:51,269
that destroys the data utility.

837
00:28:52,108 --> 00:28:54,160
You can't join table on a masked

838
00:28:54,160 --> 00:28:56,818
column. Our

839
00:28:56,818 --> 00:28:58,818
blueprint is very simple land

840
00:28:58,818 --> 00:28:59,939
your data tokenized.

841
00:29:00,680 --> 00:29:01,789
Whether it's S3,

842
00:29:02,068 --> 00:29:02,660
Redshift,

843
00:29:02,959 --> 00:29:04,430
Dabolt, or Snowflake,

844
00:29:04,799 --> 00:29:07,000
use the Dabolt SDKs in your retail

845
00:29:07,000 --> 00:29:07,699
pipeline

846
00:29:07,959 --> 00:29:10,219
to tokenize the data the moment it enters

847
00:29:10,219 --> 00:29:11,559
your analytic environment.

848
00:29:12,199 --> 00:29:14,500
This, uh, gives you two things. First,

849
00:29:14,959 --> 00:29:15,959
security at rest.

850
00:29:16,479 --> 00:29:18,618
So, uh, let's say if someone

851
00:29:19,000 --> 00:29:21,130
incorrectly configures your SD

852
00:29:21,130 --> 00:29:21,858
bucket,

853
00:29:22,118 --> 00:29:24,318
uh, that results in a data breach

854
00:29:24,318 --> 00:29:25,410
leaking your data.

855
00:29:25,719 --> 00:29:27,858
Uh, they get just the, uh,

856
00:29:27,880 --> 00:29:29,719
access to the tokens, not the actual data.

857
00:29:30,029 --> 00:29:32,699
And in fact, uh, for our internal implementation,

858
00:29:32,959 --> 00:29:33,469
uh,

859
00:29:33,838 --> 00:29:36,160
we had this issue and, uh, our

860
00:29:36,160 --> 00:29:38,318
internal recognition saved us, uh, saved our

861
00:29:38,318 --> 00:29:40,348
face because, uh, we had the data

862
00:29:40,348 --> 00:29:41,640
tokenized in that S3 bucket.

863
00:29:43,078 --> 00:29:44,890
The second is the granular access

864
00:29:45,479 --> 00:29:47,549
with uh data address being

865
00:29:47,549 --> 00:29:49,799
tokenized, you can implement

866
00:29:49,989 --> 00:29:51,699
on the fly detokenization

867
00:29:52,000 --> 00:29:54,199
for reads for the authorized users so

868
00:29:54,199 --> 00:29:56,500
that only authorized users can get access to

869
00:29:57,430 --> 00:29:59,539
your raw plane data and your data

870
00:29:59,539 --> 00:30:00,318
is secured.

871
00:30:03,390 --> 00:30:06,209
So, uh, let's look at the concrete implementation

872
00:30:06,209 --> 00:30:08,469
of this pattern using Amazon Redshift. Uh,

873
00:30:08,578 --> 00:30:10,818
this is from uh one of our earlier cust uh,

874
00:30:10,828 --> 00:30:11,769
early customers.

875
00:30:12,309 --> 00:30:14,489
They needed to expand access,

876
00:30:14,809 --> 00:30:15,709
uh, uh,

877
00:30:16,029 --> 00:30:17,489
to their data warehouses,

878
00:30:17,789 --> 00:30:19,910
uh, to all analysis,

879
00:30:20,150 --> 00:30:22,189
uh, but they wanted to

880
00:30:22,189 --> 00:30:24,348
make sure that the raw PII

881
00:30:24,348 --> 00:30:26,029
is, uh, accessed

882
00:30:26,430 --> 00:30:27,848
by a select few analyst.

883
00:30:28,309 --> 00:30:30,130
So, uh, here is how they set it up.

884
00:30:30,769 --> 00:30:32,989
They deployed the, uh, data dataplane

885
00:30:33,368 --> 00:30:35,489
in private submit of the AWS

886
00:30:35,489 --> 00:30:36,588
account, uh,

887
00:30:36,890 --> 00:30:39,150
in the existing AKS cluster.

888
00:30:39,809 --> 00:30:42,269
For the execution flow, they used,

889
00:30:43,689 --> 00:30:45,769
Red shifts, uh, masking policies

890
00:30:45,769 --> 00:30:47,890
and UDF features, uh,

891
00:30:48,289 --> 00:30:49,630
when an analyst,

892
00:30:50,009 --> 00:30:52,239
uh, tries to run a query like Flickstar

893
00:30:52,239 --> 00:30:52,858
from customer,

894
00:30:53,650 --> 00:30:56,108
uh, the red shift invokes this UDF,

895
00:30:56,608 --> 00:30:58,449
uh, for the sensitive columns.

896
00:30:59,568 --> 00:31:01,719
And this UDF triggers a data

897
00:31:01,719 --> 00:31:03,068
bolt to connect to lambda.

898
00:31:03,650 --> 00:31:05,900
This lambda act as a breach, bridge

899
00:31:05,900 --> 00:31:08,049
to the uh data bolt data plane.

900
00:31:09,618 --> 00:31:12,059
This lambda authentic authenticates

901
00:31:12,059 --> 00:31:14,549
the call using uh IM policies,

902
00:31:14,858 --> 00:31:17,160
uh, and then passes the call

903
00:31:17,259 --> 00:31:19,539
to the data plane uh to get the actual

904
00:31:19,539 --> 00:31:21,410
value for the token. Data plane

905
00:31:21,818 --> 00:31:24,180
consults its uh predefined

906
00:31:24,180 --> 00:31:26,140
access policies, and if,

907
00:31:26,420 --> 00:31:28,108
uh, the authorization is correct,

908
00:31:28,459 --> 00:31:30,699
uh, it will return the actual value, otherwise

909
00:31:30,699 --> 00:31:32,118
it will return the same token back.

910
00:31:33,568 --> 00:31:34,108
The result,

911
00:31:34,769 --> 00:31:37,108
uh, the analyst, uh, the analyst

912
00:31:37,729 --> 00:31:38,509
continue using

913
00:31:38,969 --> 00:31:40,689
their standard SQL.

914
00:31:41,618 --> 00:31:43,939
They don't have to worry about the heavy, uh,

915
00:31:43,969 --> 00:31:44,699
security,

916
00:31:45,019 --> 00:31:45,549
um,

917
00:31:46,049 --> 00:31:48,519
lifting that goes in the background.

918
00:31:49,180 --> 00:31:49,759
Uh,

919
00:31:50,390 --> 00:31:52,449
one thing I would like to also note

920
00:31:52,449 --> 00:31:54,660
here that we're also working on a lambda

921
00:31:54,660 --> 00:31:55,588
native data plan

922
00:31:56,059 --> 00:31:58,140
that will remove the need to,

923
00:31:58,160 --> 00:31:58,719
uh, run

924
00:31:59,170 --> 00:32:01,459
the Cuban Native cluster in the AWS environment

925
00:32:01,459 --> 00:32:02,759
for the use cases like this.

926
00:32:05,608 --> 00:32:06,920
OK. Uh, so

927
00:32:07,239 --> 00:32:07,880
now

928
00:32:08,299 --> 00:32:10,368
analytics is the immediate need,

929
00:32:10,709 --> 00:32:12,739
but, uh, the new frontier is obviously

930
00:32:12,739 --> 00:32:13,920
the AI workloads.

931
00:32:14,338 --> 00:32:16,890
Uh, interestingly, the architecture I just

932
00:32:16,890 --> 00:32:19,239
described, uh, applies

933
00:32:19,660 --> 00:32:21,759
almost identically to, uh,

934
00:32:22,180 --> 00:32:23,640
AI workloads as well.

935
00:32:24,519 --> 00:32:26,529
Just that the value proposition shifts

936
00:32:26,529 --> 00:32:27,189
slightly.

937
00:32:29,880 --> 00:32:31,219
In analytics

938
00:32:32,209 --> 00:32:34,219
Uh, you, you may need to see the

939
00:32:34,219 --> 00:32:35,039
real data again,

940
00:32:35,779 --> 00:32:37,779
but uh for the AI workload, you

941
00:32:37,779 --> 00:32:38,640
almost never do.

942
00:32:39,900 --> 00:32:42,118
If you train a model on mass data,

943
00:32:42,469 --> 00:32:44,469
uh, I think, uh, she can went over

944
00:32:44,469 --> 00:32:46,509
this, uh, the model

945
00:32:46,509 --> 00:32:48,890
learns nothing because it's just a string of asterisks.

946
00:32:49,660 --> 00:32:50,858
But with tokenization,

947
00:32:51,180 --> 00:32:53,328
the, uh, feature set is preserved.

948
00:32:53,890 --> 00:32:55,430
Like data world preserves

949
00:32:55,890 --> 00:32:57,858
length and format, so your SSN

950
00:32:58,410 --> 00:33:00,400
is 99 characters long.

951
00:33:00,729 --> 00:33:01,989
Your tokenized email

952
00:33:02,309 --> 00:33:04,358
has, uh, that at the rate symbol and

953
00:33:04,358 --> 00:33:06,189
domain in the token as well.

954
00:33:06,650 --> 00:33:08,809
This means, uh, you can train your small

955
00:33:08,809 --> 00:33:10,900
language model or fine tune your

956
00:33:10,900 --> 00:33:12,949
large language model on fully tokenized

957
00:33:13,338 --> 00:33:13,989
data set.

958
00:33:14,719 --> 00:33:17,189
The model can learn the patterns like, uh,

959
00:33:17,199 --> 00:33:19,500
people with, uh, X zip code

960
00:33:19,500 --> 00:33:21,449
tend to buy a product Y,

961
00:33:22,039 --> 00:33:23,719
like, uh, this use cases

962
00:33:24,358 --> 00:33:25,299
without ever

963
00:33:25,799 --> 00:33:26,779
absorbing the

964
00:33:27,318 --> 00:33:29,459
actual PII into its model weights.

965
00:33:30,618 --> 00:33:32,660
This also effectively eliminates the

966
00:33:32,660 --> 00:33:34,739
model inversion attacks. Uh, these

967
00:33:34,739 --> 00:33:37,088
attacks are basically trying to extract

968
00:33:37,088 --> 00:33:38,799
the original data, uh,

969
00:33:39,338 --> 00:33:40,098
from the model.

970
00:33:42,630 --> 00:33:44,949
This is what the pipelines look like, looks

971
00:33:44,949 --> 00:33:47,209
like in AWS. It's very straightforward.

972
00:33:47,868 --> 00:33:50,130
You have your raw data in S3.

973
00:33:50,670 --> 00:33:52,969
Uh, you can use Glue data catalog

974
00:33:53,259 --> 00:33:55,779
to tag sensitive, uh, columns.

975
00:33:56,150 --> 00:33:58,608
Uh, then Data bolt can ingest this,

976
00:33:58,618 --> 00:33:59,608
uh, metadata,

977
00:34:00,029 --> 00:34:02,130
uh, and it can create a

978
00:34:02,489 --> 00:34:04,890
tokenized replica of this data set.

979
00:34:05,439 --> 00:34:07,789
Then you can, uh, point your SageMaker

980
00:34:07,789 --> 00:34:10,269
training pipeline to this tokenized replica,

981
00:34:10,789 --> 00:34:12,898
uh. The result that

982
00:34:12,898 --> 00:34:14,079
you get is the

983
00:34:14,739 --> 00:34:16,679
high-quality model that is

984
00:34:17,739 --> 00:34:18,840
already compliant

985
00:34:19,378 --> 00:34:21,938
because it never saw the sensitive

986
00:34:21,938 --> 00:34:26,318
data. OK.

987
00:34:26,478 --> 00:34:28,518
Uh, finally, let's talk about

988
00:34:28,518 --> 00:34:30,088
the in-demand use case that is G applications.

989
00:34:33,000 --> 00:34:35,449
Gene applications requires proactive as well as reactive

990
00:34:35,449 --> 00:34:36,030
controls.

991
00:34:36,458 --> 00:34:38,938
Uh, when you deploy chatbot or chatbot-like,

992
00:34:38,989 --> 00:34:40,090
uh, application,

993
00:34:40,458 --> 00:34:42,500
you, you're opening up a new interface to

994
00:34:42,500 --> 00:34:43,320
your data.

995
00:34:44,159 --> 00:34:46,458
Uh, and users are unpredictable. They

996
00:34:46,458 --> 00:34:48,780
can always enter a sensitive

997
00:34:48,780 --> 00:34:50,320
information in, in, in their prompt.

998
00:34:52,039 --> 00:34:54,159
You cannot rely only

999
00:34:54,159 --> 00:34:56,489
on the safety training uh

1000
00:34:56,489 --> 00:34:57,918
of the model for that.

1001
00:34:58,239 --> 00:35:00,378
If you rely on that, that means you're taking a risk.

1002
00:35:02,469 --> 00:35:04,510
Also, uh, there are sometimes legitimate

1003
00:35:04,510 --> 00:35:06,989
need for the downstream application to reference

1004
00:35:06,989 --> 00:35:09,110
what user, uh, has in the

1005
00:35:09,110 --> 00:35:11,208
original prompt. So you might need

1006
00:35:11,829 --> 00:35:13,728
access to what user have entered.

1007
00:35:14,349 --> 00:35:16,500
So for use cases like this, uh,

1008
00:35:16,590 --> 00:35:18,530
we recommend sandwich approached,

1009
00:35:18,789 --> 00:35:21,070
uh, first pre-processing, uh, you

1010
00:35:21,070 --> 00:35:22,688
tokenize your sensitive data

1011
00:35:23,030 --> 00:35:24,369
before it leaves your environment,

1012
00:35:24,949 --> 00:35:27,070
then post-processing, when you get the, uh, response

1013
00:35:27,070 --> 00:35:29,159
back from the model, detokenize and

1014
00:35:29,159 --> 00:35:30,869
return it to the downstream applications.

1015
00:35:33,260 --> 00:35:34,500
Uh, this slides.

1016
00:35:35,909 --> 00:35:37,449
It illustrate that flow,

1017
00:35:37,820 --> 00:35:38,369
um.

1018
00:35:39,539 --> 00:35:41,750
If you see in the middle, there is an orchestration

1019
00:35:41,750 --> 00:35:42,329
service.

1020
00:35:43,280 --> 00:35:45,320
Uh, it acts like a traffic cop.

1021
00:35:45,409 --> 00:35:47,530
Uh, it receives the user

1022
00:35:47,530 --> 00:35:48,228
input.

1023
00:35:48,809 --> 00:35:50,969
Uh, it calls scanner to detect

1024
00:35:50,969 --> 00:35:53,128
to see if there are any sensitive elements in

1025
00:35:53,128 --> 00:35:55,090
that input. Uh, if it's found,

1026
00:35:55,449 --> 00:35:56,590
uh, it will call.

1027
00:35:57,369 --> 00:35:59,530
Data bowl to tokenize that information and

1028
00:35:59,530 --> 00:36:01,349
then uh it will replace

1029
00:36:02,128 --> 00:36:04,489
the sensory information with tokens and then construct

1030
00:36:04,489 --> 00:36:06,550
the prompt again and then that prompt

1031
00:36:06,769 --> 00:36:09,219
gets sent to uh like Bedrock

1032
00:36:09,570 --> 00:36:11,949
uh uh any LLM hosted in the bedrock

1033
00:36:12,300 --> 00:36:14,409
uh and after receiving the

1034
00:36:14,409 --> 00:36:15,969
response from the LLM

1035
00:36:16,530 --> 00:36:18,530
uh if it has sensitive

1036
00:36:18,530 --> 00:36:20,550
elements, uh, it will again, uh,

1037
00:36:20,559 --> 00:36:22,728
detokenize and then send back the

1038
00:36:22,728 --> 00:36:24,889
clear answer to the application or user.

1039
00:36:26,208 --> 00:36:28,789
This keeps PII completely invisible

1040
00:36:29,090 --> 00:36:31,449
to the model provider. Uh, this also

1041
00:36:31,449 --> 00:36:34,519
solves your data residency and privacy

1042
00:36:34,519 --> 00:36:35,728
concerns with public LLMs.

1043
00:36:37,969 --> 00:36:38,699
OK, uh,

1044
00:36:39,039 --> 00:36:41,119
to wrap up, uh, whether it's for

1045
00:36:41,119 --> 00:36:43,478
like traditional analytics or the emerging,

1046
00:36:43,519 --> 00:36:45,239
uh, AI workloads,

1047
00:36:45,849 --> 00:36:48,019
vaultless tokenization ensures you

1048
00:36:48,019 --> 00:36:49,079
stay compliant

1049
00:36:49,539 --> 00:36:51,320
without slowing down your innovation

1050
00:36:51,708 --> 00:36:53,898
velocity, and Data bolt can help

1051
00:36:53,898 --> 00:36:54,878
you in that space.

1052
00:36:55,340 --> 00:36:57,809
Uh, thank you for your time. I'll hand it back to Shrikan

1053
00:36:57,809 --> 00:36:59,159
to cover the key takeaways.

1054
00:36:59,938 --> 00:37:02,369
Right, thanks, Vinai. All right, so,

1055
00:37:02,429 --> 00:37:03,050
um,

1056
00:37:03,309 --> 00:37:03,929
we have

1057
00:37:04,188 --> 00:37:06,269
3 key takeaways here that we talked

1058
00:37:06,269 --> 00:37:08,269
about. The first part is how do you unlock

1059
00:37:08,269 --> 00:37:08,800
your data?

1060
00:37:09,110 --> 00:37:11,110
So addressing this whole

1061
00:37:11,110 --> 00:37:13,208
issue with this data dilemma that we saw

1062
00:37:13,378 --> 00:37:15,648
before where you're balancing the,

1063
00:37:15,659 --> 00:37:17,708
uh, utility value of that or

1064
00:37:17,708 --> 00:37:18,809
information value of the data

1065
00:37:19,188 --> 00:37:21,349
along with the security risk that

1066
00:37:21,349 --> 00:37:23,349
it poses. So how do we do that? And then

1067
00:37:23,349 --> 00:37:25,289
we identified and showed how

1068
00:37:25,628 --> 00:37:27,849
tokenization can help you as one of the strategies

1069
00:37:27,849 --> 00:37:29,030
to help you prepare for that.

1070
00:37:29,659 --> 00:37:31,849
Um, then the second piece that we talked about

1071
00:37:31,849 --> 00:37:33,889
is around the architectures, the cloud

1072
00:37:33,889 --> 00:37:35,079
native architectures

1073
00:37:35,500 --> 00:37:36,458
designed for the scale,

1074
00:37:36,849 --> 00:37:38,898
performance, latency needs, uh,

1075
00:37:39,019 --> 00:37:41,250
of a large enterprise with like, you know, uh,

1076
00:37:41,260 --> 00:37:43,360
petabytes of data that we have in the cloud.

1077
00:37:43,699 --> 00:37:45,780
So, uh, some of the characteristics that we

1078
00:37:45,780 --> 00:37:48,579
saw that that helped us, uh, around implementing

1079
00:37:48,579 --> 00:37:50,780
these as a vaultless federated

1080
00:37:50,780 --> 00:37:51,639
architecture

1081
00:37:51,898 --> 00:37:53,938
and then also providing, uh, you

1082
00:37:53,938 --> 00:37:56,398
know, using the native services on AWS to enhance

1083
00:37:56,539 --> 00:37:58,760
some of these for the scalability side.

1084
00:37:59,369 --> 00:38:01,378
Uh, the third key takeaway here is that we

1085
00:38:01,378 --> 00:38:03,659
always want to build this as, uh, defense

1086
00:38:03,659 --> 00:38:05,110
in depth sort of layers,

1087
00:38:05,418 --> 00:38:07,500
so tokenization can be used as one

1088
00:38:07,500 --> 00:38:09,579
of those layers, as, as, uh, when I

1089
00:38:09,579 --> 00:38:11,659
mentioned, as a data centric guardrail, for, for

1090
00:38:11,659 --> 00:38:14,329
example, that gives you these proactive and reactive

1091
00:38:14,329 --> 00:38:14,840
controls,

1092
00:38:15,139 --> 00:38:17,168
um, and then gives you the ability to,

1093
00:38:17,179 --> 00:38:17,719
um,

1094
00:38:18,269 --> 00:38:19,280
uh, use your

1095
00:38:19,659 --> 00:38:21,398
data responsibly and safely

1096
00:38:21,739 --> 00:38:23,418
without worrying about the risk that it poses.

1097
00:38:23,699 --> 00:38:24,789
So you can go from.

1098
00:38:25,610 --> 00:38:27,168
You know, blocking your AI

1099
00:38:27,929 --> 00:38:29,739
use cases due to the risk

1100
00:38:30,050 --> 00:38:32,168
to enabling those with

1101
00:38:32,168 --> 00:38:34,489
confidence with, with the data protection

1102
00:38:34,489 --> 00:38:35,929
built in through these layers.

1103
00:38:36,719 --> 00:38:38,840
So, these are the, the key sort of

1104
00:38:38,840 --> 00:38:41,179
learnings that we wanted to share with, with you,

1105
00:38:41,199 --> 00:38:42,579
um, and also kind of

1106
00:38:42,840 --> 00:38:45,099
talk you through this journey so that, um,

1107
00:38:45,280 --> 00:38:47,280
you can use this in, in your, uh, day

1108
00:38:47,280 --> 00:38:49,599
to day challenges that you see with your enterprise

1109
00:38:49,599 --> 00:38:52,030
data. So we'll,

1110
00:38:52,050 --> 00:38:52,599
uh,

1111
00:38:53,610 --> 00:38:55,688
stop here for, uh, the presentation side of

1112
00:38:55,688 --> 00:38:57,809
the house. We have a couple of, uh, call

1113
00:38:57,809 --> 00:39:00,269
to action here, so please do visit our booth,

1114
00:39:00,530 --> 00:39:02,628
um, and then you will see,

1115
00:39:02,929 --> 00:39:04,829
um, on the chairs,

1116
00:39:05,208 --> 00:39:07,628
uh, the air tag holder, so

1117
00:39:07,728 --> 00:39:10,000
you can go and, uh, collect the air tags from,

1118
00:39:10,010 --> 00:39:11,188
uh, our booth.

1119
00:39:11,449 --> 00:39:13,510
So we welcome you to come in. Uh, see us

1120
00:39:13,510 --> 00:39:14,829
there then we'll show you

1121
00:39:15,110 --> 00:39:16,628
a demo of data bolt in action.

1122
00:39:17,030 --> 00:39:19,219
Uh, we also have an upcoming webinar where we,

1123
00:39:19,269 --> 00:39:20,010
uh, uh,

1124
00:39:20,590 --> 00:39:22,849
where we talk about the study that we alluded to here,

1125
00:39:23,148 --> 00:39:25,148
uh, where we looked at training

1126
00:39:25,148 --> 00:39:27,269
the models on mass data,

1127
00:39:27,349 --> 00:39:29,139
the clear data as well as tokenized data,

1128
00:39:29,429 --> 00:39:31,429
and we'll share some of the results, uh, that's

1129
00:39:31,429 --> 00:39:33,159
upcoming, uh, with PWC

1130
00:39:33,510 --> 00:39:34,809
on the 12th,

1131
00:39:35,188 --> 00:39:36,610
um, essentially.

1132
00:39:37,489 --> 00:39:38,579
These are, uh,

1133
00:39:38,889 --> 00:39:40,929
key next steps in terms of how we

1134
00:39:40,929 --> 00:39:43,378
want to proceed with this, and we'd love to, um,

1135
00:39:43,610 --> 00:39:45,688
kind of get your feedback and questions. Uh, we

1136
00:39:45,688 --> 00:39:47,269
have a few minutes left here, so

1137
00:39:47,688 --> 00:39:49,750
we'll, we'll pause here and take questions.

1138
00:39:50,289 --> 00:39:56,918
Thank you. students.

