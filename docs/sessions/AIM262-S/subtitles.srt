1
00:00:02,490 --> 00:00:03,019
Hi everyone.

2
00:00:04,629 --> 00:00:05,429
Thank you for coming.

3
00:00:06,969 --> 00:00:09,009
I hope you've enjoyed the conference so far as

4
00:00:09,009 --> 00:00:09,788
much as I have.

5
00:00:10,169 --> 00:00:12,288
And one of the things whenever I come to a conference like

6
00:00:12,288 --> 00:00:14,409
this, is I'm just always amazed at the sheer

7
00:00:14,409 --> 00:00:16,568
amount of organization that is needed to put it

8
00:00:16,568 --> 00:00:18,649
together. If you think about even just the

9
00:00:18,649 --> 00:00:20,649
very basic things like the chairs in this

10
00:00:20,649 --> 00:00:22,888
room, or the microphone into which I'm speaking

11
00:00:22,888 --> 00:00:25,039
now, these

12
00:00:25,039 --> 00:00:27,719
things are always very complicated, both logistically

13
00:00:27,719 --> 00:00:29,068
and also technologically.

14
00:00:29,658 --> 00:00:31,708
And whenever I get thinking about this, I always think

15
00:00:31,708 --> 00:00:33,750
about how at some point there was a

16
00:00:33,750 --> 00:00:34,329
first

17
00:00:34,590 --> 00:00:35,609
of these things.

18
00:00:35,950 --> 00:00:38,490
There was a first microphone, maybe prototypically

19
00:00:38,490 --> 00:00:40,700
there was a first chair, but humans have always been sitting

20
00:00:40,700 --> 00:00:42,889
down. And at some point

21
00:00:42,990 --> 00:00:44,048
that was made

22
00:00:44,348 --> 00:00:45,048
by a person

23
00:00:45,429 --> 00:00:47,630
who sat in a room, maybe a mad scientist

24
00:00:47,630 --> 00:00:49,250
or someone with some resources,

25
00:00:49,709 --> 00:00:51,848
and they discovered something and they made it.

26
00:00:52,310 --> 00:00:54,348
And then what happened over time was we got

27
00:00:54,348 --> 00:00:56,168
very good at making those things.

28
00:00:56,709 --> 00:00:58,539
To fit particular profiles.

29
00:00:58,959 --> 00:01:00,240
These chairs here, for example,

30
00:01:00,520 --> 00:01:02,719
they're not particularly ornate, they're not necessarily

31
00:01:02,719 --> 00:01:05,198
particularly interesting even, but they're easy to stack,

32
00:01:05,519 --> 00:01:07,959
they're probably relatively comfortable, and crucially

33
00:01:07,959 --> 00:01:09,819
they match the color scheme and the price.

34
00:01:10,359 --> 00:01:12,400
This happens with all things that go from

35
00:01:12,400 --> 00:01:14,400
being artisanal, made in

36
00:01:14,400 --> 00:01:16,549
some regular way by some person

37
00:01:16,549 --> 00:01:17,418
very carefully

38
00:01:18,319 --> 00:01:20,058
to what we would now term as industrialization.

39
00:01:20,838 --> 00:01:22,909
And one of the great things about industrialization

40
00:01:22,909 --> 00:01:25,308
is that it means that you can make things

41
00:01:25,489 --> 00:01:27,888
and then map them to these criteria that I mentioned

42
00:01:27,888 --> 00:01:29,888
earlier. The

43
00:01:29,888 --> 00:01:31,939
reason why I bring this up is, I'm sure you've all

44
00:01:31,939 --> 00:01:32,569
noticed,

45
00:01:32,859 --> 00:01:36,000
that AI is really beginning to undergo an industrialization.

46
00:01:36,620 --> 00:01:38,870
For a long time, models that were made

47
00:01:38,870 --> 00:01:41,480
were really kind of made based on gut feeling

48
00:01:41,480 --> 00:01:43,620
and some clever guy that you knew who

49
00:01:43,620 --> 00:01:45,359
had an idea about how to do this.

50
00:01:45,900 --> 00:01:48,319
And the applications were also not particularly

51
00:01:48,500 --> 00:01:49,120
useful.

52
00:01:49,579 --> 00:01:51,730
I think it was Faraday who said when electricity was

53
00:01:51,730 --> 00:01:53,698
discovered, what use is a new baby?

54
00:01:54,849 --> 00:01:56,888
Sometimes when you create these things, it's not clear how

55
00:01:56,888 --> 00:01:58,888
you will use them, you just hope that there

56
00:01:58,888 --> 00:02:00,209
will be some use for them.

57
00:02:00,569 --> 00:02:02,730
And I think for a long time AI was in a similar

58
00:02:02,730 --> 00:02:04,849
place. Right, all of these things were coming

59
00:02:04,849 --> 00:02:07,028
out, but ultimately all you could really do

60
00:02:07,290 --> 00:02:08,949
was interact with a chatbot.

61
00:02:09,368 --> 00:02:11,808
And now if you look where we are in 2025

62
00:02:11,808 --> 00:02:13,258
going into 2026,

63
00:02:13,528 --> 00:02:15,610
it should be clear that there are lots of very

64
00:02:15,610 --> 00:02:17,610
useful and economically viable uses

65
00:02:17,610 --> 00:02:18,210
of AI

66
00:02:18,849 --> 00:02:20,969
that people want to deploy inside businesses

67
00:02:20,969 --> 00:02:23,169
and they want to benefit from

68
00:02:23,169 --> 00:02:24,250
what AI can give them.

69
00:02:24,909 --> 00:02:27,080
I also think very crucially, if you look at the

70
00:02:27,080 --> 00:02:29,349
language that companies are using and the

71
00:02:29,349 --> 00:02:30,580
industry is using to talk about AI

72
00:02:31,028 --> 00:02:33,229
we hear Nvidia talking about AI

73
00:02:33,229 --> 00:02:34,508
for the factory age.

74
00:02:34,830 --> 00:02:36,969
You're gonna hear me today talking about a model factory.

75
00:02:37,288 --> 00:02:39,469
All of these companies are really hinting at how

76
00:02:39,469 --> 00:02:41,469
much AI is scaling up.

77
00:02:42,479 --> 00:02:44,520
One thing we're really bad at doing as

78
00:02:44,520 --> 00:02:45,338
an industry

79
00:02:45,639 --> 00:02:48,258
is talking about how we build models.

80
00:02:49,278 --> 00:02:51,278
Occasionally a model might come out, and you'll

81
00:02:51,278 --> 00:02:53,520
get some nice new model card and maybe

82
00:02:53,520 --> 00:02:54,758
some eval scores,

83
00:02:55,240 --> 00:02:57,240
maybe if you're lucky, like with a deep seek, you'll get

84
00:02:57,240 --> 00:02:57,849
a paper,

85
00:02:58,319 --> 00:03:00,319
but that doesn't really begin to cover the

86
00:03:00,319 --> 00:03:02,479
real technicalities and difficulties

87
00:03:02,479 --> 00:03:04,639
behind actually building foundation models

88
00:03:04,639 --> 00:03:05,278
at scale.

89
00:03:06,538 --> 00:03:08,618
As an industry, we're really bad at this, and

90
00:03:08,618 --> 00:03:10,788
I think it comes from a place of fear about giving

91
00:03:10,788 --> 00:03:11,969
away some secret source.

92
00:03:12,429 --> 00:03:14,788
We don't really talk about, you know, the tricks

93
00:03:14,788 --> 00:03:16,788
or the things that we have to do, or even

94
00:03:16,788 --> 00:03:19,028
the battles that we fought to build models

95
00:03:19,028 --> 00:03:20,169
that actually matter.

96
00:03:20,588 --> 00:03:22,939
And quite frankly, I think this is quite ridiculous,

97
00:03:23,349 --> 00:03:25,629
because you could, the ideas are very cheap.

98
00:03:26,058 --> 00:03:27,649
It's execution that matters.

99
00:03:27,909 --> 00:03:30,308
And I wanna be very clear, I'm here to talk today about poolside

100
00:03:30,308 --> 00:03:32,308
and how we build models in our model factory.

101
00:03:32,729 --> 00:03:34,808
But I guarantee you that every company that

102
00:03:34,808 --> 00:03:36,889
is at the frontier has a version of

103
00:03:36,889 --> 00:03:39,110
this. I can only speak to ours,

104
00:03:39,368 --> 00:03:41,368
because I've only worked here and I only know about

105
00:03:41,368 --> 00:03:43,679
this, but I'm pretty sure that your OpenAI's,

106
00:03:43,689 --> 00:03:46,169
your anthropics, your XAIs, all of these companies

107
00:03:46,169 --> 00:03:47,129
have a similar thing.

108
00:03:47,960 --> 00:03:49,838
This is what you need to be at the frontier.

109
00:03:50,270 --> 00:03:52,278
This is what we have used to get to the frontier,

110
00:03:52,629 --> 00:03:54,629
and I want to spend some time today talking to you about how

111
00:03:54,629 --> 00:03:56,868
this works and how it will enable us to continue

112
00:03:56,868 --> 00:03:57,449
improving

113
00:03:57,788 --> 00:03:59,849
our models going forward into the future.

114
00:04:01,399 --> 00:04:03,979
Now, I think it's worth starting

115
00:04:04,118 --> 00:04:04,758
from the beginning.

116
00:04:05,729 --> 00:04:07,770
So those of you who have trained models in

117
00:04:07,770 --> 00:04:09,770
the past will be familiar with a

118
00:04:09,770 --> 00:04:11,689
workflow that looks something like this.

119
00:04:12,460 --> 00:04:14,679
So to give you an analogy, let's imagine

120
00:04:14,679 --> 00:04:16,738
that we wanted to build a model that was

121
00:04:16,738 --> 00:04:18,819
really good at imitating Shakespeare.

122
00:04:19,259 --> 00:04:21,338
And we're gonna do it in this old fashioned way.

123
00:04:22,358 --> 00:04:24,519
What we would first do is we would first decide on

124
00:04:24,519 --> 00:04:25,119
some data set.

125
00:04:25,869 --> 00:04:26,449
That might be

126
00:04:26,750 --> 00:04:29,170
Shakespeare's sonnets, that might be English language,

127
00:04:29,470 --> 00:04:31,709
that might be code even in some senses.

128
00:04:32,389 --> 00:04:34,569
But it could equally be something that I've gotten some from

129
00:04:34,569 --> 00:04:35,949
guy, some guy down the pub.

130
00:04:36,209 --> 00:04:38,428
Right, there's not really any way here to

131
00:04:38,959 --> 00:04:41,129
interrogate what our data set should be.

132
00:04:41,488 --> 00:04:43,488
We just choose one and hope that it turns out to be

133
00:04:43,488 --> 00:04:44,309
a good data set,

134
00:04:44,649 --> 00:04:46,149
again based on our intuitions.

135
00:04:47,350 --> 00:04:48,790
Once we have that data set,

136
00:04:49,220 --> 00:04:51,199
we're gonna feed it into what's called pre-training,

137
00:04:51,540 --> 00:04:53,689
which is this process of, you know, doing

138
00:04:53,689 --> 00:04:55,699
next token prediction, computing the loss.

139
00:04:55,980 --> 00:04:58,059
Believe me, I could go into that for a long time, but I won't.

140
00:04:58,699 --> 00:05:00,699
And again, there are lots of decisions that you need

141
00:05:00,699 --> 00:05:01,879
to make here,

142
00:05:02,379 --> 00:05:04,639
but in this model we simply cannot

143
00:05:04,798 --> 00:05:06,809
interrogate in any scientific way.

144
00:05:07,139 --> 00:05:09,619
Right? I might have some intuitions about the architecture

145
00:05:09,619 --> 00:05:10,889
that I need to make a good model.

146
00:05:11,220 --> 00:05:13,269
My friends might have some intuitions about what

147
00:05:13,269 --> 00:05:15,410
makes a good model from an architectural perspective.

148
00:05:15,778 --> 00:05:18,059
But there's no real way of discovering

149
00:05:18,059 --> 00:05:19,259
how we could have done better.

150
00:05:20,108 --> 00:05:22,189
And equally, once we've finally done

151
00:05:22,189 --> 00:05:24,350
this pre-training, and believe me, there's a lot that goes into

152
00:05:24,350 --> 00:05:26,470
it, we get into the stage at the end called

153
00:05:26,470 --> 00:05:27,170
fine tuning.

154
00:05:27,588 --> 00:05:29,540
And this is the bit where we take this,

155
00:05:29,858 --> 00:05:31,869
this person or this model that we've taught to write

156
00:05:31,869 --> 00:05:32,449
Shakespeare,

157
00:05:32,709 --> 00:05:34,790
and we give them detailed instructions of what

158
00:05:34,790 --> 00:05:35,889
it is they should do.

159
00:05:36,269 --> 00:05:38,298
So you can imagine, much like a child that goes through

160
00:05:38,298 --> 00:05:39,009
primary education.

161
00:05:39,639 --> 00:05:40,819
They get to the end of their life,

162
00:05:41,238 --> 00:05:43,238
and then you give them some, oh sorry, they get to the end of

163
00:05:43,238 --> 00:05:45,910
their school life, and then you give them some

164
00:05:45,920 --> 00:05:48,119
specific training. So maybe they want to be a doctor,

165
00:05:48,238 --> 00:05:50,269
maybe they want to be a computer scientist, whatever it

166
00:05:50,269 --> 00:05:52,319
is, you give them some particular training.

167
00:05:53,399 --> 00:05:55,319
And again, what's really crucial here is that

168
00:05:55,759 --> 00:05:58,079
this is just one model out of an infinite

169
00:05:58,079 --> 00:05:59,500
number that we could have trained.

170
00:05:59,838 --> 00:06:01,879
Right, at any point along here we could have

171
00:06:01,879 --> 00:06:03,298
made a different decision

172
00:06:03,619 --> 00:06:05,838
that would have led to a different and maybe

173
00:06:05,838 --> 00:06:06,738
better model.

174
00:06:07,500 --> 00:06:09,660
But with this, you have no way of

175
00:06:09,660 --> 00:06:10,238
knowing

176
00:06:10,819 --> 00:06:12,819
how your model could have been better or what

177
00:06:12,819 --> 00:06:14,639
you could have done to make it better.

178
00:06:15,019 --> 00:06:17,019
We have no insight into how good

179
00:06:17,019 --> 00:06:19,100
the data set was at actually making our

180
00:06:19,100 --> 00:06:20,100
model good at Shakespeare.

181
00:06:20,379 --> 00:06:22,540
Right, maybe the trick to getting a model that

182
00:06:22,540 --> 00:06:24,540
writes good sonnets is to expose it to

183
00:06:24,540 --> 00:06:26,160
French or German or Greek.

184
00:06:26,738 --> 00:06:28,160
We don't have any insight into that.

185
00:06:28,920 --> 00:06:30,959
Equally for the sum number of parameters

186
00:06:30,959 --> 00:06:32,619
or for some fine tuning strategy.

187
00:06:33,470 --> 00:06:35,509
We're just stuck assuming that the model that

188
00:06:35,509 --> 00:06:36,428
we have is good.

189
00:06:37,879 --> 00:06:40,119
Even if we trained multiple models, maybe

190
00:06:40,119 --> 00:06:42,178
we had multiple physical hypotheses,

191
00:06:42,278 --> 00:06:44,449
and we think, oh you know what, I'm just gonna sit there and

192
00:06:44,449 --> 00:06:46,259
repeat this process vertically many times.

193
00:06:47,639 --> 00:06:49,759
That is a really heavy engineering

194
00:06:49,759 --> 00:06:50,338
task.

195
00:06:51,278 --> 00:06:53,439
You would need a huge team to do this, because

196
00:06:53,439 --> 00:06:55,519
there's so many things that you need to get this

197
00:06:55,519 --> 00:06:58,040
right, that there's just in this

198
00:06:58,040 --> 00:07:00,480
form, there's a huge amount of manual intervention

199
00:07:00,480 --> 00:07:01,220
that is needed.

200
00:07:01,509 --> 00:07:03,600
Pre-training, for example, is a notoriously

201
00:07:03,600 --> 00:07:04,819
buggy process.

202
00:07:05,399 --> 00:07:07,559
Nodes die, you need to make sure that your training

203
00:07:07,559 --> 00:07:09,259
is stable and doesn't restart.

204
00:07:09,879 --> 00:07:11,949
And doing all of that manually is

205
00:07:11,949 --> 00:07:12,750
impossible.

206
00:07:13,019 --> 00:07:15,040
You would need a huge team to

207
00:07:15,040 --> 00:07:17,069
do this in some way that actually

208
00:07:17,069 --> 00:07:18,338
enabled you to be productive.

209
00:07:19,488 --> 00:07:21,608
And I really want to narrow in on this point, which

210
00:07:21,608 --> 00:07:23,889
is that there is a very large

211
00:07:23,889 --> 00:07:24,420
gap,

212
00:07:24,769 --> 00:07:26,899
both in terms of the headcount that you need

213
00:07:26,899 --> 00:07:29,079
and the talent of your employees and

214
00:07:29,088 --> 00:07:30,769
quite frankly the systems that you've built.

215
00:07:32,069 --> 00:07:34,149
To go between training one model to

216
00:07:34,149 --> 00:07:36,309
training many models at an industrial

217
00:07:36,309 --> 00:07:38,329
scale. And again this kind of

218
00:07:38,329 --> 00:07:40,480
comes back to what I was saying about the chair earlier on.

219
00:07:40,959 --> 00:07:43,088
It's very easy for one person to make a chair,

220
00:07:43,170 --> 00:07:45,290
one skilled carpenter can probably knock out a

221
00:07:45,290 --> 00:07:46,108
chair very quickly.

222
00:07:46,449 --> 00:07:48,528
But making the number of chairs that are in this room,

223
00:07:48,809 --> 00:07:50,389
let alone at this conference,

224
00:07:50,750 --> 00:07:52,750
is a much bigger challenge.

225
00:07:53,250 --> 00:07:55,410
And crucially, doing it in the old fashioned

226
00:07:55,410 --> 00:07:57,750
artisanal way is very slow.

227
00:07:58,290 --> 00:08:00,569
Right, you need to sit down, you need to have

228
00:08:00,569 --> 00:08:03,019
ideas, you need to run this very buggy

229
00:08:03,019 --> 00:08:03,850
training process.

230
00:08:04,358 --> 00:08:05,579
That's really tough,

231
00:08:05,959 --> 00:08:08,160
and it means that it's very easy to fall behind

232
00:08:08,160 --> 00:08:09,480
where everyone else is.

233
00:08:10,000 --> 00:08:12,119
Because there's always someone who's gonna be smarter than you,

234
00:08:12,559 --> 00:08:13,759
more resourced than you.

235
00:08:14,439 --> 00:08:16,500
And you can't scale that way if you want to compete

236
00:08:16,500 --> 00:08:18,600
with these much larger companies in the way that we

237
00:08:18,600 --> 00:08:20,689
do. So I've

238
00:08:20,689 --> 00:08:22,790
said a lot about how you can take,

239
00:08:22,809 --> 00:08:24,428
or how you want to improve

240
00:08:24,928 --> 00:08:25,970
a model that you've trained.

241
00:08:27,048 --> 00:08:29,369
But one of the good things is to have some objective

242
00:08:29,369 --> 00:08:30,350
way to do this.

243
00:08:31,088 --> 00:08:33,090
So this is quite common in the industry now, whenever a

244
00:08:33,090 --> 00:08:35,889
model card comes out, you'll see evaluation scores

245
00:08:35,889 --> 00:08:37,389
across various benchmarks.

246
00:08:38,009 --> 00:08:40,009
And actually it turns out that it's really useful

247
00:08:40,009 --> 00:08:42,219
to be able to deploy these evaluations

248
00:08:42,219 --> 00:08:43,009
almost anywhere.

249
00:08:43,529 --> 00:08:45,769
So here you'll see that we have this on

250
00:08:45,769 --> 00:08:46,710
the pre-training

251
00:08:47,210 --> 00:08:47,750
block.

252
00:08:48,369 --> 00:08:50,408
But actually, this is something that makes sense to

253
00:08:50,408 --> 00:08:51,269
have also at the end

254
00:08:51,609 --> 00:08:53,690
or at the beginning, in fact throughout training.

255
00:08:54,418 --> 00:08:56,200
One of the reasons why this is really useful

256
00:08:56,538 --> 00:08:58,580
is because as you go over your data

257
00:08:58,580 --> 00:09:00,599
set, your model could get worse.

258
00:09:01,099 --> 00:09:03,178
Right, it could be the case that your model picks up

259
00:09:03,178 --> 00:09:05,298
some bad information, right, maybe it reads some

260
00:09:05,298 --> 00:09:07,038
disinformation from Reddit or

261
00:09:07,298 --> 00:09:09,500
maybe it reads some English document from

262
00:09:09,500 --> 00:09:10,538
before modern English.

263
00:09:10,899 --> 00:09:12,639
These are all things that can make your model worse.

264
00:09:13,178 --> 00:09:15,879
And it turns out that having some way to automatically

265
00:09:15,879 --> 00:09:17,940
evaluate how your model gets

266
00:09:17,940 --> 00:09:18,960
better over time

267
00:09:19,739 --> 00:09:20,639
really is useful.

268
00:09:21,450 --> 00:09:23,519
Now I want to be really clear about this as well,

269
00:09:23,529 --> 00:09:24,489
because it's an important point.

270
00:09:25,710 --> 00:09:27,029
Evaluations are not everything.

271
00:09:28,340 --> 00:09:30,609
The way that I like to think about this is if you have a child,

272
00:09:30,940 --> 00:09:32,590
as someone who has perhaps not much intelligence,

273
00:09:33,320 --> 00:09:35,690
standardized testing actually will tell you the difference

274
00:09:35,690 --> 00:09:38,048
between what is a smart child and what is perhaps not a smart child.

275
00:09:38,489 --> 00:09:40,609
Because actually, the sum of the things that they could know

276
00:09:40,609 --> 00:09:42,469
is probably relatively small.

277
00:09:43,119 --> 00:09:45,288
By contrast, by the time you get someone who is very

278
00:09:45,288 --> 00:09:46,359
highly educated,

279
00:09:46,808 --> 00:09:48,849
the model that is good for you, or the person

280
00:09:48,849 --> 00:09:50,308
that is good for you in your business.

281
00:09:51,288 --> 00:09:53,408
Might not necessarily be separable from someone who

282
00:09:53,408 --> 00:09:55,649
isn't good for your business based on standardized

283
00:09:55,649 --> 00:09:57,769
testing, right, it's more of how friendly

284
00:09:57,769 --> 00:09:59,969
they are, how much you like to talk to them, how

285
00:09:59,969 --> 00:10:00,808
helpful they are.

286
00:10:01,168 --> 00:10:03,269
These are all very er soft

287
00:10:03,489 --> 00:10:05,690
things, they're very intuitive, I think, to people.

288
00:10:06,090 --> 00:10:08,090
And so even though we have this evaluations

289
00:10:08,090 --> 00:10:10,408
thing here, I want to stress that at Poolside

290
00:10:10,408 --> 00:10:11,950
we do a huge amount of

291
00:10:12,330 --> 00:10:13,570
manual vibe checking.

292
00:10:14,250 --> 00:10:16,288
So it's a companywide effort. If

293
00:10:16,288 --> 00:10:18,330
there are salespeople who want to try

294
00:10:18,330 --> 00:10:18,889
a new model,

295
00:10:19,168 --> 00:10:21,149
they're more than welcome to at any stage of training.

296
00:10:21,489 --> 00:10:24,009
And our engineers do the same thing, we really interrogate

297
00:10:24,009 --> 00:10:26,158
our models as often as we possibly can

298
00:10:26,489 --> 00:10:28,750
to make sure that they are going in the right direction.

299
00:10:30,000 --> 00:10:31,989
One real crucial advantage of this

300
00:10:32,250 --> 00:10:34,330
is that often your models are really

301
00:10:34,330 --> 00:10:36,710
bad at one thing in a particular area.

302
00:10:37,200 --> 00:10:39,529
So for example, me personally, I can't speak French.

303
00:10:39,769 --> 00:10:41,849
If you ask me a question in French, it would be clear that I

304
00:10:41,849 --> 00:10:43,849
don't know it. Now that might be a flaw

305
00:10:43,849 --> 00:10:45,379
of me as a person, maybe not,

306
00:10:45,700 --> 00:10:47,168
but models fail in a similar way.

307
00:10:47,500 --> 00:10:49,658
Right, often they have gaps in their knowledge that are very

308
00:10:49,658 --> 00:10:50,279
systemic.

309
00:10:50,820 --> 00:10:53,519
And it can be useful to interrogate them personally

310
00:10:53,739 --> 00:10:55,820
to see, OK, what is the gap in their knowledge,

311
00:10:55,940 --> 00:10:57,700
how can I improve this overall thing?

312
00:10:59,129 --> 00:11:01,129
Now one of the things about evaluations

313
00:11:01,129 --> 00:11:02,989
is that you need a way to actually run your model.

314
00:11:03,869 --> 00:11:06,139
So we've just added another box to our diagram,

315
00:11:06,149 --> 00:11:07,969
which is an inference service.

316
00:11:08,548 --> 00:11:10,750
Now, inference is a

317
00:11:10,750 --> 00:11:12,750
very interesting area, we could talk about it

318
00:11:12,750 --> 00:11:13,710
for a very long time.

319
00:11:14,428 --> 00:11:16,649
But something I want to point out is that it

320
00:11:16,649 --> 00:11:18,719
is not necessarily clear straight

321
00:11:18,719 --> 00:11:20,759
away how you would co-locate training

322
00:11:20,759 --> 00:11:22,840
and inference in the same

323
00:11:22,840 --> 00:11:23,678
world, right?

324
00:11:23,960 --> 00:11:26,440
And this actually is primarily a scalability

325
00:11:26,440 --> 00:11:28,570
argument. You could use the

326
00:11:28,570 --> 00:11:30,649
same nodes, the same physical nodes for

327
00:11:30,649 --> 00:11:31,668
training and inference.

328
00:11:32,210 --> 00:11:33,678
But actually in practice,

329
00:11:33,969 --> 00:11:36,239
that means you can't scale them independently. Right,

330
00:11:36,288 --> 00:11:38,408
you would have to scale up your training world to

331
00:11:38,408 --> 00:11:39,908
also scale up your inference world.

332
00:11:40,288 --> 00:11:42,320
And because we want to run this inference, right,

333
00:11:42,369 --> 00:11:44,830
we want to interact with our models during training,

334
00:11:45,288 --> 00:11:47,369
we need a quick way of transferring the

335
00:11:47,369 --> 00:11:48,668
weights that we've produced

336
00:11:49,129 --> 00:11:50,428
between training and inference

337
00:11:50,889 --> 00:11:52,090
without blocking either of them.

338
00:11:52,649 --> 00:11:54,649
Right, if we had to stop our training every time to

339
00:11:54,649 --> 00:11:57,288
offload weights and then deploy them on evaluations,

340
00:11:57,609 --> 00:11:59,548
that's going to cost us a huge amount of time.

341
00:11:59,918 --> 00:12:01,928
And the whole purpose of this is to enable us to

342
00:12:01,928 --> 00:12:03,408
build better models faster.

343
00:12:04,229 --> 00:12:06,269
And so one of the lines on this graph that's actually

344
00:12:06,269 --> 00:12:08,389
been very crucial for us is having a

345
00:12:08,389 --> 00:12:10,408
way to move weights between

346
00:12:10,408 --> 00:12:12,048
our pre-training and our inference.

347
00:12:12,658 --> 00:12:14,658
And this makes it very easy to look at how

348
00:12:14,658 --> 00:12:15,719
your model's evolving,

349
00:12:16,418 --> 00:12:18,719
how it's getting better, all of these things.

350
00:12:19,340 --> 00:12:21,460
We'll come onto this later, but I think it's an important point

351
00:12:21,460 --> 00:12:22,259
to mention here.

352
00:12:23,250 --> 00:12:24,509
One of the very

353
00:12:24,969 --> 00:12:27,619
good ways to choose between different model architectures,

354
00:12:27,729 --> 00:12:29,000
if all else is the same,

355
00:12:29,288 --> 00:12:31,288
is how capable they are at doing

356
00:12:31,288 --> 00:12:31,950
quick inference.

357
00:12:32,798 --> 00:12:34,908
So we have some models that on evals

358
00:12:34,908 --> 00:12:37,090
or when we're doing our preliminary ablations

359
00:12:37,469 --> 00:12:39,570
actually perform very similarly to each other.

360
00:12:40,109 --> 00:12:42,308
And a good way to choose between them is to see, OK,

361
00:12:42,509 --> 00:12:44,269
which one has better inference in practice.

362
00:12:44,750 --> 00:12:46,788
And of course, you know, we optimize, right, we take these

363
00:12:46,788 --> 00:12:48,830
models once we've picked one and we do

364
00:12:48,830 --> 00:12:50,750
lots of tweaks to make it as quick as it can be.

365
00:12:51,619 --> 00:12:53,700
But making sure there are no fundamental reasons

366
00:12:53,700 --> 00:12:55,000
why your model is slow

367
00:12:55,340 --> 00:12:57,340
actually is a really good thing to do before you

368
00:12:57,340 --> 00:12:58,538
invest in a huge training run.

369
00:13:00,168 --> 00:13:01,529
Now, once we have this.

370
00:13:03,558 --> 00:13:05,298
You can make decisions about trade-offs.

371
00:13:05,759 --> 00:13:08,158
So I've mentioned this already in the context of

372
00:13:08,158 --> 00:13:10,428
making sure that your model has quick inference,

373
00:13:10,759 --> 00:13:12,759
but actually there are lots of other places where

374
00:13:12,759 --> 00:13:13,739
this is useful.

375
00:13:14,320 --> 00:13:15,658
Normally when you're building a model,

376
00:13:16,119 --> 00:13:18,119
in your head you have a parameter budget

377
00:13:18,119 --> 00:13:18,710
in mind.

378
00:13:19,080 --> 00:13:21,440
Let's say, I don't know, you want to build an 80 billion

379
00:13:21,440 --> 00:13:23,519
parameter dense model or a 500

380
00:13:23,519 --> 00:13:25,139
billion MOE model.

381
00:13:25,759 --> 00:13:27,899
These are parameters that you can spend in many

382
00:13:27,899 --> 00:13:28,678
different places.

383
00:13:29,099 --> 00:13:31,250
Right, you could make your embeddings bigger, you

384
00:13:31,250 --> 00:13:33,298
could have more parameters allocated to

385
00:13:33,298 --> 00:13:35,298
your MLPs. These are all parameters

386
00:13:35,298 --> 00:13:36,080
that you can spend,

387
00:13:36,859 --> 00:13:39,009
and when you have these insights, suddenly

388
00:13:39,009 --> 00:13:41,259
you can be very informed about

389
00:13:41,259 --> 00:13:43,369
what the model actually should

390
00:13:43,369 --> 00:13:43,979
be like

391
00:13:44,298 --> 00:13:46,298
and balance it against all of your requirements as a

392
00:13:46,298 --> 00:13:48,899
business. Now,

393
00:13:49,158 --> 00:13:50,460
I want to give you an example

394
00:13:50,840 --> 00:13:52,840
of where this sort of thinking can really

395
00:13:52,840 --> 00:13:54,840
help you. So historically as a

396
00:13:54,840 --> 00:13:56,859
company, Poolside has operated under the

397
00:13:56,869 --> 00:13:57,918
thesis

398
00:13:58,320 --> 00:14:00,399
that if you make models that are good at writing

399
00:14:00,399 --> 00:14:02,479
code, they're also generally

400
00:14:02,479 --> 00:14:03,058
capable.

401
00:14:03,639 --> 00:14:05,960
Now this was a little bit of an out there thesis when we

402
00:14:05,960 --> 00:14:07,509
founded the company in 2023,

403
00:14:07,918 --> 00:14:10,000
but it's gradually become more mainstream. Right,

404
00:14:10,080 --> 00:14:12,158
companies have started releasing coding products

405
00:14:12,158 --> 00:14:12,950
for their models,

406
00:14:13,239 --> 00:14:15,320
and I think they're all seeing a similar uplift that

407
00:14:15,320 --> 00:14:15,840
we've seen.

408
00:14:16,330 --> 00:14:18,558
When you have a model that is good at writing code,

409
00:14:18,779 --> 00:14:20,779
it turns out those skills really

410
00:14:20,779 --> 00:14:22,538
transfer over to other tasks.

411
00:14:23,288 --> 00:14:25,428
Now I want to be clear here, what I'm gonna talk about in a second

412
00:14:25,808 --> 00:14:27,899
is not just limited to coding,

413
00:14:28,408 --> 00:14:29,889
but coding is a good place to start.

414
00:14:30,928 --> 00:14:33,308
So I think

415
00:14:33,308 --> 00:14:34,090
personally

416
00:14:34,548 --> 00:14:36,609
that the way that pre-training works for

417
00:14:36,989 --> 00:14:38,710
specific skill acquisition

418
00:14:38,989 --> 00:14:39,750
is nonsense.

419
00:14:40,580 --> 00:14:42,719
Think about it like this, if you wanted to learn

420
00:14:42,719 --> 00:14:43,899
to write C++,

421
00:14:44,259 --> 00:14:46,580
you would never read every single C++

422
00:14:46,580 --> 00:14:47,558
program that had ever been written.

423
00:14:48,019 --> 00:14:50,399
It would be nonsense, you would never learn to write code,

424
00:14:50,739 --> 00:14:53,058
because you never actually do it, you're just acquiring

425
00:14:53,058 --> 00:14:55,250
information. And it turns out that the same

426
00:14:55,250 --> 00:14:57,149
is really true for

427
00:14:57,408 --> 00:14:58,548
foundation model building.

428
00:14:59,418 --> 00:15:01,418
So one of the things that we do at poolside

429
00:15:01,418 --> 00:15:03,538
is we enable our model during

430
00:15:03,538 --> 00:15:05,700
training and also at various points post

431
00:15:05,700 --> 00:15:07,859
training to interact

432
00:15:07,859 --> 00:15:09,519
with a coding environment.

433
00:15:09,979 --> 00:15:12,009
So you can think of this like a docker container

434
00:15:12,009 --> 00:15:13,599
or some virtual environment of some kind.

435
00:15:14,739 --> 00:15:16,580
And you give it tasks to solve.

436
00:15:17,178 --> 00:15:19,690
Now these tasks can really vary in difficulty.

437
00:15:19,979 --> 00:15:22,009
They can go from add a doc string to

438
00:15:22,009 --> 00:15:24,379
this Python function to implement

439
00:15:24,379 --> 00:15:26,500
this entire epic in this repository.

440
00:15:27,178 --> 00:15:29,219
The whole point is that you should be able to stack

441
00:15:29,219 --> 00:15:31,440
these in a way that enables the model to learn

442
00:15:31,899 --> 00:15:33,940
better, right, you, you know, you wouldn't give a

443
00:15:33,940 --> 00:15:36,139
kid a PhD level math problem,

444
00:15:36,408 --> 00:15:38,340
you would give them a question about addition.

445
00:15:38,779 --> 00:15:40,899
The same is true of models when you're trying to get

446
00:15:40,899 --> 00:15:42,139
particular capabilities.

447
00:15:43,308 --> 00:15:45,989
Something else to note is that although this diagram

448
00:15:45,989 --> 00:15:48,090
has this going into the pre-training box,

449
00:15:48,668 --> 00:15:51,190
this whole thing can be slid along an axis,

450
00:15:51,489 --> 00:15:52,779
pretty much wherever you want.

451
00:15:53,109 --> 00:15:55,190
If you wanted to do this sort of

452
00:15:55,190 --> 00:15:57,489
learning during pre-training, you could.

453
00:15:57,908 --> 00:16:00,538
If you just want to do it in mid-training or post-training,

454
00:16:00,750 --> 00:16:01,719
you also could.

455
00:16:02,070 --> 00:16:04,109
Right, there's no reason why this has to belong

456
00:16:04,109 --> 00:16:05,288
into the pre-training box,

457
00:16:05,750 --> 00:16:07,308
it's just for the sake of this diagram.

458
00:16:08,058 --> 00:16:10,500
And very crucially, when we're talking about RL

459
00:16:10,779 --> 00:16:11,678
in particular,

460
00:16:12,259 --> 00:16:14,259
there's no reason why we need to limit ourselves

461
00:16:14,259 --> 00:16:15,080
just to code.

462
00:16:15,538 --> 00:16:17,729
Right? Anything where the model can

463
00:16:17,729 --> 00:16:19,940
learn signals from what it's doing, and there's a rich

464
00:16:19,940 --> 00:16:21,048
variety of signals

465
00:16:21,460 --> 00:16:23,369
can be modeled like this.

466
00:16:23,700 --> 00:16:25,808
It doesn't just have to be programming, right, it

467
00:16:25,808 --> 00:16:26,519
could be

468
00:16:27,058 --> 00:16:29,058
translation, it could be anything where there is

469
00:16:29,058 --> 00:16:30,918
a clear structured signal

470
00:16:31,178 --> 00:16:32,460
from which the model can learn.

471
00:16:33,349 --> 00:16:35,349
Now, something that is not strictly within

472
00:16:35,349 --> 00:16:36,590
the realms of model building

473
00:16:36,908 --> 00:16:39,190
is that finding these problems inside a business

474
00:16:39,190 --> 00:16:41,219
can be very difficult. Inside an enterprise can be

475
00:16:41,219 --> 00:16:41,750
very difficult.

476
00:16:42,668 --> 00:16:44,908
We've recently launched a forward deployed research

477
00:16:44,908 --> 00:16:45,428
engineer,

478
00:16:45,940 --> 00:16:48,070
er, essentially function as part of our company

479
00:16:48,070 --> 00:16:49,769
to help you find these problems.

480
00:16:50,149 --> 00:16:52,340
And if these problems exist and we can

481
00:16:52,340 --> 00:16:54,428
integrate them into our model pipeline like

482
00:16:54,428 --> 00:16:56,509
this, you will be able to benefit

483
00:16:56,509 --> 00:16:58,590
from an uplift in model capabilities at that

484
00:16:58,590 --> 00:16:59,168
task.

485
00:16:59,590 --> 00:17:01,668
So if there is a task that is suited to this sort

486
00:17:01,668 --> 00:17:03,869
of setup, if you imagine the code execution box

487
00:17:03,869 --> 00:17:04,689
doesn't exist.

488
00:17:05,519 --> 00:17:07,578
Then that's something where the model can learn

489
00:17:07,578 --> 00:17:09,719
and grow at that particular task.

490
00:17:11,289 --> 00:17:13,130
Now, once we have this,

491
00:17:13,769 --> 00:17:14,430
the only thing

492
00:17:14,769 --> 00:17:16,890
that's on this side of the diagram that we haven't spoken

493
00:17:16,890 --> 00:17:17,479
about yet

494
00:17:17,969 --> 00:17:20,049
is actually adjusting the model

495
00:17:20,049 --> 00:17:22,250
itself. Right, I mentioned earlier that you can choose

496
00:17:22,250 --> 00:17:23,519
when to spend your parameters,

497
00:17:23,880 --> 00:17:25,949
but we haven't really spoken about it so far.

498
00:17:26,608 --> 00:17:28,608
Normally what happens here is you have

499
00:17:28,608 --> 00:17:30,180
some idea that you want to try.

500
00:17:30,479 --> 00:17:32,809
Let's say you want to have more embedding parameters

501
00:17:32,809 --> 00:17:34,890
or more experts active

502
00:17:34,890 --> 00:17:36,868
in your MOE or any of these things.

503
00:17:37,828 --> 00:17:40,489
And it's useful to be able to express these very succinctly.

504
00:17:41,029 --> 00:17:43,108
So in practice, this box here on the left hand

505
00:17:43,108 --> 00:17:44,689
side, the model ablation platform,

506
00:17:45,269 --> 00:17:47,529
is essentially a collection of four loops

507
00:17:47,529 --> 00:17:49,068
inside our internal repository.

508
00:17:49,390 --> 00:17:51,509
You specify all of the parameters that you

509
00:17:51,509 --> 00:17:53,269
want, let's say the number of experts.

510
00:17:53,880 --> 00:17:56,180
And our system automatically takes those

511
00:17:56,318 --> 00:17:58,400
and launches a training run for each of

512
00:17:58,400 --> 00:18:00,618
them. Now normally it's on a

513
00:18:00,618 --> 00:18:02,779
small model, so we wouldn't train a huge model

514
00:18:02,779 --> 00:18:04,729
on this, maybe a few billion parameters.

515
00:18:05,219 --> 00:18:07,400
But normally this is enough to give you a sense

516
00:18:07,400 --> 00:18:09,578
of whether you're in the right direction

517
00:18:09,578 --> 00:18:11,118
if you're going along the right path.

518
00:18:11,539 --> 00:18:13,848
I liken this to having children at school, right,

519
00:18:14,019 --> 00:18:16,140
if the class is bad, chances are you'll

520
00:18:16,140 --> 00:18:18,299
be able to tell they aren't learning very quickly, and

521
00:18:18,299 --> 00:18:20,559
it's the same with this. And you wouldn't waste your time

522
00:18:20,559 --> 00:18:22,799
with that child in that class if it wasn't going well.

523
00:18:23,380 --> 00:18:25,618
So having the system here really helps you

524
00:18:25,618 --> 00:18:27,059
to take your model.

525
00:18:27,430 --> 00:18:29,588
And understand whether it's going to be viable for you.

526
00:18:33,239 --> 00:18:35,250
I think you already have noticed from what's been on the

527
00:18:35,250 --> 00:18:37,390
slide so far that there's a huge amount

528
00:18:37,390 --> 00:18:39,689
of coordination that's needed for this.

529
00:18:40,400 --> 00:18:42,410
If you take away nothing else from this talk,

530
00:18:42,479 --> 00:18:43,868
it has to be this slide,

531
00:18:44,209 --> 00:18:46,529
which is that a great deal of modern AI

532
00:18:46,529 --> 00:18:47,328
model building

533
00:18:47,598 --> 00:18:49,509
is essentially systems work.

534
00:18:49,890 --> 00:18:51,930
It's about making sure that your training

535
00:18:51,930 --> 00:18:54,410
proceeds reliably. It's about making

536
00:18:54,410 --> 00:18:56,719
sure that your chips are performing. It's

537
00:18:56,719 --> 00:18:58,890
making sure that you don't have any networking bugs.

538
00:18:59,209 --> 00:19:01,410
It's about making sure that all of these systems

539
00:19:01,410 --> 00:19:03,469
can talk to each other in a way that doesn't

540
00:19:03,469 --> 00:19:05,680
slow any of them down or doesn't harm the

541
00:19:05,680 --> 00:19:06,630
design of any of them.

542
00:19:07,449 --> 00:19:09,108
Now I say systems here

543
00:19:09,368 --> 00:19:10,799
and not distributed systems,

544
00:19:11,170 --> 00:19:13,368
because actually there's a lot of traditional systems

545
00:19:13,368 --> 00:19:14,199
programming as well,

546
00:19:14,489 --> 00:19:16,799
right, making sure that your kernels are very

547
00:19:16,799 --> 00:19:18,809
quick, making sure that you can read

548
00:19:18,809 --> 00:19:21,239
files without going onto an out of memory error.

549
00:19:21,680 --> 00:19:24,009
There's lots of things here that are not just

550
00:19:24,009 --> 00:19:25,229
distributed systems.

551
00:19:25,729 --> 00:19:27,809
And something as someone who is more of an engineer than

552
00:19:27,809 --> 00:19:29,209
a researcher these days,

553
00:19:29,529 --> 00:19:32,049
I find that doing this work really enables

554
00:19:32,049 --> 00:19:33,890
people who are much smarter than me

555
00:19:34,170 --> 00:19:35,809
to do their best work at poolside.

556
00:19:36,269 --> 00:19:38,630
Right, to actually be able to research and

557
00:19:38,630 --> 00:19:40,630
understand their own ideas more quickly

558
00:19:40,630 --> 00:19:42,009
than they could anywhere else.

559
00:19:42,709 --> 00:19:44,709
It really enables them to not have to think about

560
00:19:44,709 --> 00:19:47,209
the minutia of scheduling jobs

561
00:19:47,439 --> 00:19:49,390
or making sure that their nose don't crash.

562
00:19:49,670 --> 00:19:51,709
The systems that we have built handle

563
00:19:51,709 --> 00:19:52,838
all of that for them.

564
00:19:53,229 --> 00:19:55,390
And so they don't have to worry about that, they don't have to spend

565
00:19:55,390 --> 00:19:57,588
their hours debugging trivial things.

566
00:19:57,910 --> 00:20:00,328
They get to spend their hours thinking about big problems

567
00:20:00,420 --> 00:20:02,390
and coming up with solutions to those problems.

568
00:20:03,358 --> 00:20:05,479
Now I've said that a great deal of modern

569
00:20:05,479 --> 00:20:06,939
model building systems work,

570
00:20:07,509 --> 00:20:09,618
but I want to stress the rest is science.

571
00:20:10,420 --> 00:20:12,689
And when I say science, I mean a very

572
00:20:12,689 --> 00:20:14,059
traditional science.

573
00:20:14,920 --> 00:20:17,739
I mean empiricism. I mean you have a hypothesis,

574
00:20:17,989 --> 00:20:20,059
you test that hypothesis, you see how

575
00:20:20,059 --> 00:20:22,289
it went, and you repeat this process

576
00:20:22,289 --> 00:20:24,578
over and over again until you end up with something

577
00:20:24,578 --> 00:20:25,140
that is good.

578
00:20:26,068 --> 00:20:28,229
I think this is not really understood

579
00:20:28,229 --> 00:20:30,269
by the outside world because the thing that

580
00:20:30,269 --> 00:20:31,568
they see is the outer product,

581
00:20:31,868 --> 00:20:33,910
right, it's the big model release that everyone

582
00:20:33,910 --> 00:20:36,269
makes a lot of noise about, it's the deep seek moment.

583
00:20:36,630 --> 00:20:38,670
It's all of these things that are very, for want

584
00:20:38,670 --> 00:20:39,739
of a better term, hype,

585
00:20:40,108 --> 00:20:42,459
but it doesn't really reflect the hard work that

586
00:20:42,459 --> 00:20:44,289
goes into building these models in practice.

587
00:20:46,088 --> 00:20:48,250
One of the things that any of you who have done

588
00:20:48,250 --> 00:20:50,189
science in any serious way will know

589
00:20:50,809 --> 00:20:51,969
is that your data is everything.

590
00:20:52,828 --> 00:20:54,939
Keeping track of your data and being

591
00:20:54,939 --> 00:20:56,959
able to understand what it is that you have done

592
00:20:56,959 --> 00:20:58,699
to get to where that data is now

593
00:20:59,019 --> 00:21:00,390
is incredibly important.

594
00:21:00,699 --> 00:21:02,818
I mean, even those of you who plotted graphs at school

595
00:21:02,818 --> 00:21:04,618
will know that you had to be aware of outliers,

596
00:21:04,979 --> 00:21:06,239
and AI is no different.

597
00:21:06,779 --> 00:21:08,910
So one of the key pieces of this model factory

598
00:21:08,910 --> 00:21:10,180
that we're discussing today

599
00:21:10,459 --> 00:21:12,660
is having the ability to transform our

600
00:21:12,660 --> 00:21:14,019
data at scale.

601
00:21:14,818 --> 00:21:16,818
Now this can be as simple as

602
00:21:16,818 --> 00:21:19,059
getting rid of non-permissive licenses

603
00:21:19,059 --> 00:21:20,140
from your training data set,

604
00:21:20,420 --> 00:21:22,140
making sure you aren't training on anything illegal,

605
00:21:22,539 --> 00:21:25,439
but it can also be as large as doing deduplication,

606
00:21:25,618 --> 00:21:27,719
right, making sure that the model doesn't see

607
00:21:28,380 --> 00:21:30,380
too much of one particular data and so it doesn't

608
00:21:30,380 --> 00:21:30,939
overfit.

609
00:21:31,969 --> 00:21:34,130
Being able to track all of that and

610
00:21:34,130 --> 00:21:36,489
being able to make sure that you have a very

611
00:21:36,489 --> 00:21:38,809
consistent lineage, like a chain of custody

612
00:21:38,809 --> 00:21:40,630
for everything that you've done along the way,

613
00:21:41,170 --> 00:21:43,250
is a really important way of making

614
00:21:43,250 --> 00:21:45,568
sure that you understand, OK, I fed

615
00:21:45,568 --> 00:21:47,608
this into my model, and this is

616
00:21:47,608 --> 00:21:48,289
what happened.

617
00:21:48,809 --> 00:21:50,848
This is why the loss went down or this

618
00:21:50,848 --> 00:21:52,269
is why the loss went up.

619
00:21:52,689 --> 00:21:54,848
And there's lots of really clever tricks that you can

620
00:21:54,848 --> 00:21:56,930
play to incorporate this whole system

621
00:21:56,930 --> 00:21:58,959
together. So for example, one thing

622
00:21:58,959 --> 00:21:59,868
that you can do

623
00:22:00,170 --> 00:22:02,170
is during your training, if you build

624
00:22:02,170 --> 00:22:02,848
such a thing,

625
00:22:03,209 --> 00:22:05,789
you can uniquely link loss spikes

626
00:22:06,088 --> 00:22:08,588
back to the data sample that caused those loss spikes.

627
00:22:09,539 --> 00:22:11,689
And that information enables you later

628
00:22:12,189 --> 00:22:14,309
to look at your data and go actually, you

629
00:22:14,309 --> 00:22:16,848
know what, that sample was out of distribution, or

630
00:22:16,989 --> 00:22:19,049
actually we really want this in our training data

631
00:22:19,049 --> 00:22:20,809
set, let's try and get more of it.

632
00:22:21,259 --> 00:22:23,348
There's lots of clever tricks you can play when

633
00:22:23,348 --> 00:22:25,469
you have this sort of systems view of

634
00:22:25,469 --> 00:22:25,989
your training.

635
00:22:28,799 --> 00:22:31,189
Now, One of the things

636
00:22:31,848 --> 00:22:33,949
that the AI industry doesn't tell you very often

637
00:22:33,949 --> 00:22:34,779
is that

638
00:22:35,049 --> 00:22:36,650
we all train on

639
00:22:37,088 --> 00:22:39,289
various rephrased forms of web data.

640
00:22:40,029 --> 00:22:42,269
Now everyone tells you that they train on the web, that's

641
00:22:42,269 --> 00:22:43,000
no secret,

642
00:22:43,509 --> 00:22:45,449
but training on

643
00:22:46,029 --> 00:22:48,029
web data as it is just, you know, purely

644
00:22:48,029 --> 00:22:48,650
scraped

645
00:22:48,949 --> 00:22:50,939
often is not what is best for your model.

646
00:22:51,469 --> 00:22:53,509
What is good for your model is to have data that is

647
00:22:53,509 --> 00:22:55,029
expressed in a particular form.

648
00:22:55,430 --> 00:22:57,549
Right? I don't think anyone here in this room has learned anything

649
00:22:57,549 --> 00:22:59,588
difficult by reading, you know, raw text

650
00:22:59,588 --> 00:23:00,608
snippets from the internet.

651
00:23:00,949 --> 00:23:03,029
Chances are you learned from a lecturer or from a

652
00:23:03,029 --> 00:23:04,209
book that you studied yourself

653
00:23:04,630 --> 00:23:06,670
that had already been organized in a way that made

654
00:23:06,670 --> 00:23:08,529
it easy for you to learn things.

655
00:23:09,098 --> 00:23:11,180
And one of the great things is that you

656
00:23:11,180 --> 00:23:13,180
can do this very similarly with

657
00:23:13,180 --> 00:23:14,500
synthetic data generation.

658
00:23:15,459 --> 00:23:17,578
Now to be clear, this requires you to have access

659
00:23:17,578 --> 00:23:18,358
to inference again,

660
00:23:18,618 --> 00:23:20,618
right, because you need to query some

661
00:23:20,618 --> 00:23:22,189
model that does the work for you.

662
00:23:22,739 --> 00:23:24,979
But you can already see how this diagram really

663
00:23:24,979 --> 00:23:27,098
stacks on top of itself, how all

664
00:23:27,098 --> 00:23:29,338
of these boxes are beginning to interact

665
00:23:29,338 --> 00:23:30,140
with each other

666
00:23:30,479 --> 00:23:32,500
in a way that enables them to be more than the

667
00:23:32,500 --> 00:23:33,618
sum of their parts.

668
00:23:34,059 --> 00:23:36,180
Right, inference by itself is very useful,

669
00:23:36,539 --> 00:23:38,019
but when you can use it to generate more data.

670
00:23:39,719 --> 00:23:41,640
Suddenly that means you can make better models,

671
00:23:41,969 --> 00:23:44,049
which also means that they can be more useful

672
00:23:44,049 --> 00:23:45,150
for synthetic data generation.

673
00:23:46,009 --> 00:23:48,049
So the whole thing really builds on itself

674
00:23:48,049 --> 00:23:49,989
when you have a diagram like this.

675
00:23:50,939 --> 00:23:53,259
Another thing that you can see as highlighted on this slide

676
00:23:53,259 --> 00:23:54,920
is this blender box.

677
00:23:55,500 --> 00:23:57,529
Now, historically, when you've trained

678
00:23:57,529 --> 00:23:58,239
a model,

679
00:23:58,779 --> 00:24:00,900
what you have done is you have chosen the number of

680
00:24:00,900 --> 00:24:02,199
nodes you want ahead of time,

681
00:24:02,578 --> 00:24:04,818
you've distributed the data set to those nodes,

682
00:24:05,170 --> 00:24:06,900
and then they have run off and done the training.

683
00:24:08,039 --> 00:24:10,390
This is fine and it kind of works,

684
00:24:10,759 --> 00:24:12,750
but actually there's a lot of limitations to it.

685
00:24:13,239 --> 00:24:14,838
So one of the limitations to it

686
00:24:15,118 --> 00:24:15,900
is that

687
00:24:16,279 --> 00:24:18,338
you have to have your data ready ahead of time,

688
00:24:18,719 --> 00:24:20,880
right? You can't stream data

689
00:24:20,880 --> 00:24:23,088
to these nodes, as the way I've described,

690
00:24:23,479 --> 00:24:25,640
because you have to predistribute your data set.

691
00:24:26,199 --> 00:24:28,239
Equally, it makes it really hard to scale

692
00:24:28,239 --> 00:24:30,519
up your training in any meaningful way.

693
00:24:30,959 --> 00:24:33,078
It's quite easy to scale down because, you know, you just

694
00:24:33,078 --> 00:24:34,739
take some pool of nodes and you shrink them.

695
00:24:35,299 --> 00:24:37,328
But if you want to scale up, you've got to redistribute

696
00:24:37,328 --> 00:24:37,890
your dataset.

697
00:24:39,318 --> 00:24:41,400
That also can be a real pain if you've got to replace

698
00:24:41,400 --> 00:24:42,279
a faulty node,

699
00:24:42,719 --> 00:24:44,920
right? Let's say you've got 8000 GPUs

700
00:24:44,920 --> 00:24:46,750
that are being used and one of them dies.

701
00:24:47,078 --> 00:24:49,199
Well, suddenly you have to add a new machine in and

702
00:24:49,199 --> 00:24:51,459
you have to preload the data set onto that node.

703
00:24:51,838 --> 00:24:53,078
And that's really tough,

704
00:24:53,358 --> 00:24:55,410
right? It makes your training much more difficult than it

705
00:24:55,410 --> 00:24:55,959
needs to be.

706
00:24:56,719 --> 00:24:59,000
So one of the things that we do at Poolside is

707
00:24:59,000 --> 00:25:01,078
we stream data directly into

708
00:25:01,078 --> 00:25:02,140
our training nodes

709
00:25:02,400 --> 00:25:04,279
via this service that we have called Blender.

710
00:25:05,000 --> 00:25:07,318
Now as the name suggests, Blender also

711
00:25:07,318 --> 00:25:08,769
produces data, blends.

712
00:25:09,199 --> 00:25:11,390
So you'll mix multiple different data sources,

713
00:25:11,479 --> 00:25:13,519
you know, Shakespeare, code, all of

714
00:25:13,519 --> 00:25:14,259
these things.

715
00:25:15,160 --> 00:25:17,199
Because it turns out that much like a kid at

716
00:25:17,199 --> 00:25:19,309
school, you don't want to expose your model to

717
00:25:19,309 --> 00:25:20,719
just one thing at once.

718
00:25:21,039 --> 00:25:23,279
Right? If you, if you only read Shakespeare

719
00:25:23,279 --> 00:25:25,479
and then suddenly you learned C programming,

720
00:25:25,959 --> 00:25:27,160
that would probably be quite confusing.

721
00:25:27,670 --> 00:25:29,920
And the same thing is true of models, right, they like

722
00:25:29,920 --> 00:25:31,920
to be taught multiple things at

723
00:25:31,920 --> 00:25:33,939
once, admittedly in a structured way

724
00:25:34,318 --> 00:25:36,318
so that they can keep things in their head

725
00:25:36,318 --> 00:25:37,239
whilst they're learning.

726
00:25:38,750 --> 00:25:40,709
One of the other great things about streaming

727
00:25:41,029 --> 00:25:42,108
data into your training

728
00:25:42,469 --> 00:25:44,588
is that filtering and producing

729
00:25:44,588 --> 00:25:46,868
data is incredibly time consuming

730
00:25:46,868 --> 00:25:47,769
and expensive.

731
00:25:48,348 --> 00:25:50,559
I probably estimate that on any

732
00:25:50,559 --> 00:25:52,630
given day, admittedly when we're not doing

733
00:25:52,630 --> 00:25:54,868
anything else, the vast majority of our GPUs

734
00:25:54,868 --> 00:25:56,939
are used for synthetic data generation at any given

735
00:25:56,939 --> 00:25:59,380
time. If

736
00:25:59,380 --> 00:26:01,078
you had to wait for those to be done,

737
00:26:01,500 --> 00:26:03,858
that streaming process into, oh sorry, that

738
00:26:03,858 --> 00:26:05,140
preloading into training

739
00:26:05,420 --> 00:26:06,729
would set you back by weeks.

740
00:26:07,059 --> 00:26:09,180
You can't afford this if you want to be at the frontier, you've

741
00:26:09,180 --> 00:26:11,199
got to be able to continuously improve.

742
00:26:11,618 --> 00:26:13,660
And so one of the great things that Blender allows

743
00:26:13,660 --> 00:26:15,739
you to do is to stream your data

744
00:26:15,739 --> 00:26:16,939
into your training nodes.

745
00:26:17,729 --> 00:26:19,890
It turns out that this has other advantages

746
00:26:19,890 --> 00:26:20,420
as well,

747
00:26:20,809 --> 00:26:22,689
because you can adjust things on the fly.

748
00:26:23,009 --> 00:26:25,489
Right, if you suddenly decide that you need a new blend

749
00:26:25,729 --> 00:26:27,809
or a new er data mixture or you want

750
00:26:27,809 --> 00:26:29,150
to add another data source,

751
00:26:29,848 --> 00:26:32,229
streaming enables you to do that very easily.

752
00:26:33,130 --> 00:26:35,209
And so all of a sudden you have many advanced

753
00:26:35,209 --> 00:26:37,250
techniques that you can play with when you

754
00:26:37,250 --> 00:26:38,189
come to train your model.

755
00:26:38,568 --> 00:26:40,930
Right, maybe you see your loss curve going up halfway

756
00:26:40,930 --> 00:26:41,630
through and you think

757
00:26:41,930 --> 00:26:43,769
I need to add more Fortran code to this.

758
00:26:44,250 --> 00:26:46,068
OK, that's very easy to do.

759
00:26:46,568 --> 00:26:48,729
If you redistribute everything, that's way, way

760
00:26:48,729 --> 00:26:49,309
harder.

761
00:26:49,689 --> 00:26:52,009
And even things as simple as like tokenizing

762
00:26:52,009 --> 00:26:52,630
your data

763
00:26:53,049 --> 00:26:55,170
or packing your documents into one

764
00:26:55,170 --> 00:26:57,880
big form. Is not

765
00:26:57,880 --> 00:26:59,670
necessarily theoretically very difficult,

766
00:27:00,250 --> 00:27:02,769
but the practicalities of it kind of get quite thorny

767
00:27:02,769 --> 00:27:03,390
quite quickly.

768
00:27:03,930 --> 00:27:06,078
And having a service like this that handles it all

769
00:27:06,078 --> 00:27:06,588
for you,

770
00:27:06,930 --> 00:27:09,009
really enables you to move quickly and have

771
00:27:09,009 --> 00:27:10,769
new ideas that you can actually act on.

772
00:27:13,209 --> 00:27:15,250
Now I mentioned earlier that we do a

773
00:27:15,250 --> 00:27:17,219
great deal of vibe checking at poolside,

774
00:27:17,489 --> 00:27:19,519
and so it's only right that we have this

775
00:27:19,519 --> 00:27:21,900
box right at the end of pre-training and also

776
00:27:21,900 --> 00:27:22,410
post-training.

777
00:27:23,390 --> 00:27:25,549
This, it turns out, is actually very

778
00:27:25,549 --> 00:27:27,588
useful even on partially trained

779
00:27:27,588 --> 00:27:29,828
models. So I mentioned earlier, maybe

780
00:27:29,828 --> 00:27:31,989
your model has got some common failure case, right,

781
00:27:32,068 --> 00:27:33,689
maybe you can interrogate this early.

782
00:27:34,400 --> 00:27:36,598
But actually one of the things that we have found

783
00:27:36,598 --> 00:27:37,479
this enables

784
00:27:37,759 --> 00:27:40,000
is for members of the poolside

785
00:27:40,000 --> 00:27:42,140
GTM team that are in customers,

786
00:27:42,479 --> 00:27:44,500
to give us feedback about what doesn't work.

787
00:27:45,578 --> 00:27:47,858
Oftentimes it's really difficult to get

788
00:27:48,108 --> 00:27:49,380
in-field information

789
00:27:49,900 --> 00:27:51,939
because, you know, there's a huge number of

790
00:27:51,939 --> 00:27:54,019
people that are between any given person.

791
00:27:54,680 --> 00:27:57,140
But when you have an introspection platform like this,

792
00:27:57,439 --> 00:27:59,989
it becomes really easy to drop bad samples

793
00:28:00,318 --> 00:28:02,618
into this, and for people to go, oh hey,

794
00:28:03,000 --> 00:28:04,199
this thing doesn't work very well.

795
00:28:04,858 --> 00:28:07,019
And it really enables everyone at Poolside to be

796
00:28:07,019 --> 00:28:08,568
part of actually building the models.

797
00:28:08,900 --> 00:28:10,939
It's not just the domain of the researchers that

798
00:28:10,939 --> 00:28:13,209
actually, you know, do the nitty gritty hands-on

799
00:28:13,209 --> 00:28:15,618
work. Everyone from our head of HR

800
00:28:15,618 --> 00:28:17,779
to our communications director to

801
00:28:17,779 --> 00:28:18,588
everyone in between,

802
00:28:18,900 --> 00:28:20,039
plays with our models

803
00:28:20,380 --> 00:28:22,660
and uses them to get a good understanding of

804
00:28:22,660 --> 00:28:23,809
what's actually going wrong.

805
00:28:24,098 --> 00:28:26,269
And even, I mean, some people in the company very

806
00:28:26,269 --> 00:28:28,338
recently have picked up vibe coding as well, which has been

807
00:28:28,338 --> 00:28:30,489
quite fun when they haven't had any coding background

808
00:28:30,489 --> 00:28:32,709
before. And that is a really

809
00:28:32,709 --> 00:28:34,868
good testament to how effective this

810
00:28:34,868 --> 00:28:37,049
is. Giving everyone the ability

811
00:28:37,049 --> 00:28:39,219
to actually play and interact with the model

812
00:28:39,549 --> 00:28:41,789
suddenly makes it much more of a community thing

813
00:28:42,108 --> 00:28:44,588
rather than just some people who work on pre-training

814
00:28:44,588 --> 00:28:47,449
thing. Now,

815
00:28:47,769 --> 00:28:48,890
I'm sure you've all

816
00:28:49,170 --> 00:28:51,250
noticed by this point that this box originally

817
00:28:51,250 --> 00:28:53,289
only pointed to the pre-training step.

818
00:28:54,299 --> 00:28:56,309
But it should be clear, right, that actually, you

819
00:28:56,309 --> 00:28:58,140
want to be able to ablate everything.

820
00:28:58,709 --> 00:29:00,769
There's nothing here that shouldn't be subject

821
00:29:00,769 --> 00:29:02,108
to some fixing.

822
00:29:03,108 --> 00:29:04,630
So to be frank about what I mean,

823
00:29:05,108 --> 00:29:07,250
normally what we do is we fix

824
00:29:07,588 --> 00:29:09,789
some particular piece of

825
00:29:09,789 --> 00:29:11,828
the architecture, so let's say the

826
00:29:11,828 --> 00:29:13,989
model architecture or the fine tuning

827
00:29:13,989 --> 00:29:15,509
that we're going to use or whatever,

828
00:29:15,989 --> 00:29:18,229
and then we alter any of these pieces

829
00:29:18,229 --> 00:29:20,088
independently to see what happens.

830
00:29:20,900 --> 00:29:22,930
This in general is just good science hygiene, right,

831
00:29:23,009 --> 00:29:25,160
you try not to move too many variables at once because

832
00:29:25,160 --> 00:29:26,430
you can have confounding effects.

833
00:29:27,358 --> 00:29:29,479
But in terms of model building, it actually

834
00:29:29,479 --> 00:29:30,279
really matters.

835
00:29:31,130 --> 00:29:33,130
And again, this is really a limitation of 2D

836
00:29:33,130 --> 00:29:35,130
space. Every diagram or every

837
00:29:35,130 --> 00:29:37,189
box on this diagram should really talk

838
00:29:37,189 --> 00:29:38,150
to every other box,

839
00:29:38,608 --> 00:29:40,689
right? Our model ablations actually also

840
00:29:40,689 --> 00:29:41,900
happen in code execution.

841
00:29:42,250 --> 00:29:44,250
We don't use every code execution task

842
00:29:44,250 --> 00:29:45,019
for every model.

843
00:29:45,368 --> 00:29:47,368
We don't use every reinforcement learning algorithm

844
00:29:47,368 --> 00:29:48,689
that we've got for every model.

845
00:29:49,009 --> 00:29:51,049
We don't even run the same evaluations

846
00:29:51,049 --> 00:29:53,469
necessarily on every model because they might not be relevant.

847
00:29:53,930 --> 00:29:56,209
And so having the ability to

848
00:29:56,410 --> 00:29:58,789
adjust any piece of this really

849
00:29:58,789 --> 00:30:00,848
easily and quite frankly seamlessly.

850
00:30:01,539 --> 00:30:03,318
Really enables you as a company

851
00:30:04,479 --> 00:30:06,500
to move much faster than you otherwise would be able

852
00:30:06,500 --> 00:30:08,608
to. This diagram

853
00:30:08,608 --> 00:30:10,739
is also horribly incomplete and out of date.

854
00:30:10,930 --> 00:30:12,439
Um, I apologize for

855
00:30:12,699 --> 00:30:14,170
fitting on such a small slide.

856
00:30:14,739 --> 00:30:17,098
There are probably somewhere between 50 and 100

857
00:30:17,098 --> 00:30:19,299
such boxes like this in our model

858
00:30:19,299 --> 00:30:21,420
factory at any given time, and probably

859
00:30:21,420 --> 00:30:23,250
every week we end up with a new one.

860
00:30:25,449 --> 00:30:27,368
This system really ever evolves.

861
00:30:28,130 --> 00:30:30,289
When we first built it, it was much like

862
00:30:30,289 --> 00:30:32,160
the system that I described to you earlier on,

863
00:30:32,459 --> 00:30:34,729
right, it was, we had these 3 boxes, then

864
00:30:34,729 --> 00:30:37,078
we added evaluation, then we added inference.

865
00:30:37,529 --> 00:30:39,729
But actually it continues to evolve as our

866
00:30:39,729 --> 00:30:41,729
needs as a business change, our needs as

867
00:30:41,729 --> 00:30:43,469
a frontier company change.

868
00:30:44,170 --> 00:30:46,328
For example, one of the boxes that was not on this previous

869
00:30:46,328 --> 00:30:47,608
slide was quantization.

870
00:30:48,348 --> 00:30:50,430
So the ability to take your model and shrink down

871
00:30:50,430 --> 00:30:52,509
the size of the weights or the activations

872
00:30:52,509 --> 00:30:53,489
or any of these things.

873
00:30:54,250 --> 00:30:56,410
It turns out that that is also something that you

874
00:30:56,410 --> 00:30:58,180
really want to be able to play around with,

875
00:30:58,769 --> 00:30:59,509
because maybe.

876
00:31:00,309 --> 00:31:01,608
A quantized model

877
00:31:01,868 --> 00:31:02,930
in one place

878
00:31:03,209 --> 00:31:05,509
might be substantially worse than the

879
00:31:05,509 --> 00:31:06,209
original model.

880
00:31:06,949 --> 00:31:08,989
But maybe certain architectures, when you

881
00:31:08,989 --> 00:31:10,989
tweak them, are more, let's

882
00:31:10,989 --> 00:31:11,729
say, resilient

883
00:31:12,390 --> 00:31:13,009
to quantization.

884
00:31:14,219 --> 00:31:15,930
Knowing that is really important

885
00:31:16,390 --> 00:31:18,469
because it means that you can make informed decisions

886
00:31:18,469 --> 00:31:20,848
about the models that you're actually building and training.

887
00:31:21,269 --> 00:31:23,568
And so having some er

888
00:31:23,949 --> 00:31:26,108
capacity or some ability to

889
00:31:26,108 --> 00:31:28,130
accurately look at these things

890
00:31:28,509 --> 00:31:30,630
really matters, and having the ability to adapt

891
00:31:30,630 --> 00:31:31,209
this system

892
00:31:31,750 --> 00:31:32,479
really matters.

893
00:31:34,259 --> 00:31:36,390
Another thing that's really important about the Model factory

894
00:31:36,390 --> 00:31:38,588
is that it serves as a basis of

895
00:31:38,588 --> 00:31:39,789
everything that we do in the company.

896
00:31:40,660 --> 00:31:42,380
Whenever a new joiner joins the company,

897
00:31:42,789 --> 00:31:44,858
normally there's some time that it takes them to get

898
00:31:44,858 --> 00:31:45,598
up to speed.

899
00:31:45,910 --> 00:31:48,189
And invariably there's some moment of,

900
00:31:48,380 --> 00:31:50,539
have you tried this? Have you thought about

901
00:31:50,539 --> 00:31:52,680
that? Having a system like

902
00:31:52,680 --> 00:31:54,680
this enables you to point new

903
00:31:54,680 --> 00:31:56,439
people to the things that you've already done,

904
00:31:56,920 --> 00:31:58,979
or the data sources that you're already using

905
00:31:59,118 --> 00:32:01,239
or the RL algorithms that you've implemented.

906
00:32:01,719 --> 00:32:03,759
All of these things together are important

907
00:32:03,759 --> 00:32:05,118
to get people to be efficient.

908
00:32:05,799 --> 00:32:08,098
And I mean, even me, I've been at the company since

909
00:32:08,098 --> 00:32:09,160
nearly since founding,

910
00:32:09,439 --> 00:32:11,459
and there are things that I think about every day

911
00:32:11,559 --> 00:32:13,630
that people have thought about months ago, and I've just not

912
00:32:13,630 --> 00:32:14,299
asked them yet.

913
00:32:14,719 --> 00:32:16,719
And being able to go and check and go, oh, OK, they

914
00:32:16,719 --> 00:32:18,838
had this idea, great, it worked, or great it

915
00:32:18,838 --> 00:32:20,880
didn't, is really very useful.

916
00:32:20,959 --> 00:32:23,039
It decouples the work from the

917
00:32:23,039 --> 00:32:23,618
workers.

918
00:32:24,000 --> 00:32:26,250
It means that people can have insights

919
00:32:26,250 --> 00:32:26,979
independently.

920
00:32:27,400 --> 00:32:29,400
And actually it's one of the real strengths of this sort

921
00:32:29,400 --> 00:32:30,519
of way of engineering

922
00:32:30,838 --> 00:32:31,380
is that

923
00:32:31,838 --> 00:32:33,838
other than like scheduling constraints or

924
00:32:33,838 --> 00:32:35,459
just team and company missions.

925
00:32:35,910 --> 00:32:38,348
You're able to be much more effective individually

926
00:32:38,789 --> 00:32:41,068
than you would be if you were doing everything in the old fashioned

927
00:32:41,068 --> 00:32:43,130
way, right? I can sit at my computer,

928
00:32:43,588 --> 00:32:45,588
I can launch a training run, assuming I've got enough

929
00:32:45,588 --> 00:32:46,108
compute,

930
00:32:46,670 --> 00:32:48,150
and then I can have an answer very quickly.

931
00:32:48,959 --> 00:32:51,118
And providing there's enough compute in my compute queue

932
00:32:51,118 --> 00:32:53,199
and I don't have to, you know, do something that's more

933
00:32:53,199 --> 00:32:55,229
pressing. I I, we

934
00:32:55,229 --> 00:32:56,368
can have these insights,

935
00:32:56,709 --> 00:32:59,130
and it enables us all to move much faster.

936
00:32:59,348 --> 00:33:01,759
It enables us to be much closer to the frontier

937
00:33:02,068 --> 00:33:04,269
and crucially to continue being at the frontier

938
00:33:04,269 --> 00:33:05,108
as time goes on.

939
00:33:07,239 --> 00:33:09,318
It also acts as a real ultimate source

940
00:33:09,318 --> 00:33:10,019
of truth.

941
00:33:10,439 --> 00:33:12,479
I think AI as an industry is

942
00:33:12,479 --> 00:33:14,608
one that is very full of opinions. I

943
00:33:14,608 --> 00:33:16,680
think if you asked anyone here about their opinions

944
00:33:16,680 --> 00:33:18,699
on Transformers versus linear attention.

945
00:33:19,449 --> 00:33:21,150
AMD versus Nvidia,

946
00:33:21,769 --> 00:33:22,828
which company is going to win,

947
00:33:23,328 --> 00:33:25,130
all of these things are ultimately opinions.

948
00:33:25,719 --> 00:33:27,959
And it turns out that having an ultimate

949
00:33:27,959 --> 00:33:29,259
source of truth of

950
00:33:29,519 --> 00:33:31,640
no we tried that, it didn't work, or

951
00:33:31,640 --> 00:33:33,400
no we tried that, it looks promising,

952
00:33:33,759 --> 00:33:35,799
or even just having the ability to experiment

953
00:33:35,799 --> 00:33:37,598
over a conceptual disagreement.

954
00:33:38,509 --> 00:33:40,588
Really helps you to understand what it is that

955
00:33:40,588 --> 00:33:41,269
you're doing,

956
00:33:41,549 --> 00:33:43,130
and it removes a lot of the noise,

957
00:33:43,588 --> 00:33:45,750
right? I personally don't ever look at Twitter,

958
00:33:45,828 --> 00:33:47,949
I don't ever see what anyone is posting about the models

959
00:33:47,949 --> 00:33:48,489
that they're building,

960
00:33:49,068 --> 00:33:51,410
because I know that if I'm interested and I find an idea,

961
00:33:51,709 --> 00:33:52,608
I can try it,

962
00:33:53,068 --> 00:33:53,779
and if it works,

963
00:33:54,108 --> 00:33:54,949
great, perfect.

964
00:33:55,799 --> 00:33:57,880
This enables you to really decouple

965
00:33:57,880 --> 00:33:59,880
yourself from everything else that is going on

966
00:33:59,880 --> 00:34:00,939
in the outside world,

967
00:34:01,199 --> 00:34:03,459
and it enables you to focus on your mission

968
00:34:03,680 --> 00:34:04,500
and what's happening.

969
00:34:04,858 --> 00:34:06,880
You don't have to think about what anyone else thinks is the

970
00:34:06,880 --> 00:34:08,320
latest and greatest idea,

971
00:34:08,599 --> 00:34:09,800
you yourself can try it.

972
00:34:10,648 --> 00:34:12,688
And having a system like this really, I must

973
00:34:12,688 --> 00:34:15,108
stress, does enable you to experiment with things

974
00:34:15,447 --> 00:34:16,349
very easily.

975
00:34:16,849 --> 00:34:18,849
If there is a new attention variant or

976
00:34:18,849 --> 00:34:20,829
some new post-training algorithm or

977
00:34:21,298 --> 00:34:23,329
QK norms versus layer norms versus RMS

978
00:34:23,329 --> 00:34:24,907
norms or any of these things,

979
00:34:25,367 --> 00:34:27,467
you can adjust just that piece

980
00:34:28,088 --> 00:34:29,329
and leave everything else the same.

981
00:34:30,458 --> 00:34:32,539
And it means that you really don't have to deal with all of

982
00:34:32,539 --> 00:34:35,119
the amount of minutia that you would otherwise have to handle

983
00:34:35,418 --> 00:34:37,500
when it comes to evaluating these ideas and

984
00:34:37,500 --> 00:34:38,800
seeing how they actually work.

985
00:34:41,298 --> 00:34:43,309
Something to point out, I know I've already mentioned this briefly,

986
00:34:43,387 --> 00:34:45,447
is that the factory really grows from

987
00:34:45,447 --> 00:34:47,867
itself. So one of the good examples

988
00:34:47,867 --> 00:34:49,447
is that in our code execution

989
00:34:49,947 --> 00:34:51,128
environment that I mentioned before,

990
00:34:51,867 --> 00:34:53,489
for a long time we had very static

991
00:34:53,809 --> 00:34:55,829
rules, right, this is a C project,

992
00:34:55,907 --> 00:34:57,509
OK, run make or run GCC.

993
00:34:57,867 --> 00:34:59,009
This is a Python project,

994
00:34:59,309 --> 00:35:00,467
OK, run Pip install.

995
00:35:01,340 --> 00:35:03,349
But actually that's very far from how

996
00:35:03,349 --> 00:35:04,739
a human does this,

997
00:35:05,070 --> 00:35:07,228
right? What a human does is they look at the

998
00:35:07,228 --> 00:35:09,579
read me, they look at the installation instructions,

999
00:35:09,869 --> 00:35:11,059
they follow the steps.

1000
00:35:11,389 --> 00:35:13,628
If it's a C++ project, it's probably missing some

1001
00:35:13,628 --> 00:35:15,188
dependencies, and so you've install those,

1002
00:35:15,668 --> 00:35:17,168
and then you get something that works.

1003
00:35:18,050 --> 00:35:20,208
It turns out that agents are also really

1004
00:35:20,208 --> 00:35:22,289
good at this. And so what

1005
00:35:22,289 --> 00:35:24,530
we did was we built an agent that would build

1006
00:35:24,530 --> 00:35:26,769
these environments for us, that would build these containers

1007
00:35:26,769 --> 00:35:29,070
for us. And when you have that,

1008
00:35:29,360 --> 00:35:31,320
that enables you to build better models,

1009
00:35:31,719 --> 00:35:33,780
which in turn means you can build better agents.

1010
00:35:34,199 --> 00:35:36,478
And you just can see how this process really

1011
00:35:36,478 --> 00:35:38,679
builds on itself to keep you moving very

1012
00:35:38,679 --> 00:35:40,719
quickly and enabling you to do things

1013
00:35:40,719 --> 00:35:42,340
that you couldn't do otherwise.

1014
00:35:42,719 --> 00:35:44,840
It means that you are, you can really

1015
00:35:44,840 --> 00:35:46,958
benefit from your own good work

1016
00:35:46,958 --> 00:35:47,840
almost immediately.

1017
00:35:48,530 --> 00:35:50,530
Synthetic data generation, as I mentioned earlier,

1018
00:35:50,550 --> 00:35:51,780
is another example, right?

1019
00:35:52,128 --> 00:35:53,429
As your models get better,

1020
00:35:54,050 --> 00:35:56,090
they're much more capable of rephrasing,

1021
00:35:56,168 --> 00:35:57,969
annotating, synthesizing,

1022
00:35:58,329 --> 00:36:00,329
which enables you to train better models

1023
00:36:00,329 --> 00:36:02,418
later on. This whole thing

1024
00:36:02,418 --> 00:36:04,418
really builds on itself and enables you

1025
00:36:04,418 --> 00:36:04,958
to compound.

1026
00:36:05,978 --> 00:36:08,219
I think as engineers we all know that good abstractions

1027
00:36:08,219 --> 00:36:08,739
compound,

1028
00:36:09,059 --> 00:36:11,059
right, this is one of those classic things that you're taught as

1029
00:36:11,059 --> 00:36:11,800
an undergrad,

1030
00:36:12,219 --> 00:36:14,099
but it's also very true in AI.

1031
00:36:14,820 --> 00:36:16,619
When you get that architecture right,

1032
00:36:16,898 --> 00:36:18,938
or when you have built something that you know, you can

1033
00:36:18,938 --> 00:36:20,039
stack on top of itself,

1034
00:36:21,059 --> 00:36:23,320
suddenly you see benefits immediately,

1035
00:36:23,329 --> 00:36:25,418
both from a model perspective and from a

1036
00:36:25,418 --> 00:36:26,378
systems perspective.

1037
00:36:28,329 --> 00:36:30,369
Now I've spoken a lot about the theory so

1038
00:36:30,369 --> 00:36:32,449
far, but I wanna give you a sense of what

1039
00:36:32,449 --> 00:36:34,449
this actually looks like practically and what

1040
00:36:34,449 --> 00:36:36,570
this looks like on a day to day basis for someone like

1041
00:36:36,570 --> 00:36:37,398
me who works on it.

1042
00:36:38,409 --> 00:36:40,610
So one of the key aspects

1043
00:36:40,610 --> 00:36:43,050
of all of this is what we term an asset.

1044
00:36:43,780 --> 00:36:46,019
Now an asset is essentially a versioned

1045
00:36:46,019 --> 00:36:47,599
piece of code and data

1046
00:36:47,978 --> 00:36:50,159
in some directed acyclic graph.

1047
00:36:50,909 --> 00:36:52,949
And the crucial aspect of any asset

1048
00:36:52,949 --> 00:36:53,750
that we have

1049
00:36:54,079 --> 00:36:56,188
is that you can regenerate it from

1050
00:36:56,188 --> 00:36:57,610
scratch on demand.

1051
00:36:58,579 --> 00:37:00,739
Every asset is linked to the exact git

1052
00:37:00,739 --> 00:37:02,978
commit of the code that used that

1053
00:37:02,978 --> 00:37:04,659
was er was used to produce it.

1054
00:37:04,978 --> 00:37:07,139
The exact data sets and the lineage

1055
00:37:07,139 --> 00:37:08,360
that were used to produce it.

1056
00:37:08,739 --> 00:37:10,458
And what that enables you to do is,

1057
00:37:10,739 --> 00:37:12,378
let's say later on you think to yourself,

1058
00:37:12,739 --> 00:37:14,978
you know, I had a bug in my data processing pipeline,

1059
00:37:15,019 --> 00:37:16,760
or I really just wanna see, you know,

1060
00:37:17,260 --> 00:37:19,309
if I do this again, will I get the same result?

1061
00:37:19,898 --> 00:37:21,938
Suddenly you have the ultimate ability to reproduce

1062
00:37:21,938 --> 00:37:24,090
things. And I want to be clear, even

1063
00:37:24,090 --> 00:37:26,000
though you might have the same code and same data,

1064
00:37:26,289 --> 00:37:28,329
you might get a different response or a different

1065
00:37:28,329 --> 00:37:30,409
result. And this is because obviously

1066
00:37:30,409 --> 00:37:32,728
you're dealing with systems, right, chaotic systems.

1067
00:37:33,110 --> 00:37:35,349
Maybe your node died,

1068
00:37:35,409 --> 00:37:37,610
but died silently, and so that affected

1069
00:37:37,610 --> 00:37:39,840
the computation of some activation or something

1070
00:37:39,840 --> 00:37:40,469
like that.

1071
00:37:40,969 --> 00:37:43,360
Having the ability to reproduce things on

1072
00:37:43,360 --> 00:37:45,510
demand really matters.

1073
00:37:45,929 --> 00:37:48,050
And crucially, when you have everything structured

1074
00:37:48,050 --> 00:37:48,820
in this way.

1075
00:37:49,800 --> 00:37:52,019
Running new experiments based on old stuff

1076
00:37:52,199 --> 00:37:53,378
is really easy,

1077
00:37:53,840 --> 00:37:55,929
because what you can do is you can take the asset

1078
00:37:55,929 --> 00:37:57,539
configuration that you had before.

1079
00:37:57,958 --> 00:38:00,119
You can fork it, much like you would fork

1080
00:38:00,119 --> 00:38:00,878
something on Git.

1081
00:38:02,059 --> 00:38:03,809
Make an adjustment and then run it,

1082
00:38:04,320 --> 00:38:05,889
and all of the previous lineage,

1083
00:38:06,289 --> 00:38:08,628
everything you've done, all of the code that you've had before,

1084
00:38:09,050 --> 00:38:10,349
stacks on top of itself.

1085
00:38:10,728 --> 00:38:12,849
And suddenly you're able to experiment in new and

1086
00:38:12,849 --> 00:38:15,110
very exciting ways that you just couldn't do before.

1087
00:38:16,579 --> 00:38:18,099
This is an example of what I mean.

1088
00:38:18,958 --> 00:38:21,119
So you can see these, uh, our actual

1089
00:38:21,119 --> 00:38:23,119
graph is much, much larger than this, and

1090
00:38:23,119 --> 00:38:24,688
this is just an artist's rendition.

1091
00:38:25,159 --> 00:38:27,320
But you can see what happens here, right, we have all of these

1092
00:38:27,320 --> 00:38:28,059
different boxes

1093
00:38:28,489 --> 00:38:29,780
that feed into each other.

1094
00:38:30,398 --> 00:38:32,398
Now that vertical stack that's

1095
00:38:32,398 --> 00:38:34,070
uh 2 from the right,

1096
00:38:34,360 --> 00:38:36,958
you can see is a deduplication stack,

1097
00:38:37,360 --> 00:38:39,559
and you can see that each of them end with a different

1098
00:38:39,559 --> 00:38:41,559
number. This, it turns out is

1099
00:38:41,559 --> 00:38:43,760
the percentage similarity uh parameter

1100
00:38:43,760 --> 00:38:45,559
that we used when we were doing deduplication.

1101
00:38:46,398 --> 00:38:48,519
And you can see here how all of these boxes

1102
00:38:48,519 --> 00:38:50,179
feed into these other boxes.

1103
00:38:51,128 --> 00:38:53,530
And enable you to experiment more than you otherwise

1104
00:38:53,530 --> 00:38:56,010
could, right? If I wanted to add a

1105
00:38:56,010 --> 00:38:57,800
code 0 DU 40 box,

1106
00:38:58,128 --> 00:38:59,099
I could also do that,

1107
00:38:59,489 --> 00:39:01,530
right? There's no reason why this needs to

1108
00:39:01,530 --> 00:39:03,610
be the way that it is. I can play

1109
00:39:03,610 --> 00:39:05,688
to my heart's content with these different parameters.

1110
00:39:06,199 --> 00:39:07,889
And then when you have these,

1111
00:39:08,199 --> 00:39:10,239
you can feed them into the next thing and the next thing

1112
00:39:10,239 --> 00:39:11,159
and the next thing, right?

1113
00:39:11,539 --> 00:39:13,599
Deduplication doesn't have to be the last thing on your

1114
00:39:13,599 --> 00:39:15,599
pipeline, it can be the first or the

1115
00:39:15,599 --> 00:39:17,599
last or somewhere in the middle. Maybe

1116
00:39:17,599 --> 00:39:19,469
you run it twice, who knows?

1117
00:39:19,760 --> 00:39:21,878
There's lots of things that you can do when you have a

1118
00:39:21,878 --> 00:39:23,978
system that is structured and built like this.

1119
00:39:25,829 --> 00:39:27,869
Another thing that you really need is

1120
00:39:27,869 --> 00:39:29,909
the ability to schedule jobs on

1121
00:39:29,909 --> 00:39:30,648
your cluster.

1122
00:39:31,110 --> 00:39:33,708
So at the moment we have something like 10,000 H200s

1123
00:39:33,708 --> 00:39:35,489
that we use. We have more coming soon.

1124
00:39:36,469 --> 00:39:39,000
But having all of that compute only means something

1125
00:39:39,000 --> 00:39:40,599
if you can effectively utilize it.

1126
00:39:41,280 --> 00:39:43,398
And it would be really silly to just say, right, we're

1127
00:39:43,398 --> 00:39:45,559
gonna use all of these GPUs for training

1128
00:39:45,559 --> 00:39:46,300
all of the time.

1129
00:39:47,039 --> 00:39:49,119
Because actually sometimes you, you're just doing

1130
00:39:49,119 --> 00:39:51,320
something else, right? You don't want to do a big pre-training

1131
00:39:51,320 --> 00:39:53,438
run. You want to do data generation or you wanna

1132
00:39:53,438 --> 00:39:55,708
do fine tuning or you want to do reinforcement learning.

1133
00:39:56,119 --> 00:39:58,199
And sometimes you don't even need a whole node

1134
00:39:58,199 --> 00:39:59,260
for the job that you're doing.

1135
00:39:59,599 --> 00:40:01,389
Right, if you have a really small model,

1136
00:40:01,679 --> 00:40:03,378
you probably don't need a whole,

1137
00:40:03,840 --> 00:40:05,840
you know, 8 H200s to run that. You could

1138
00:40:05,840 --> 00:40:07,039
probably run it on just one.

1139
00:40:08,010 --> 00:40:10,438
Having the ability to schedule jobs

1140
00:40:10,590 --> 00:40:11,599
on machines

1141
00:40:11,958 --> 00:40:14,320
in arbitrary ways and ways that actually

1142
00:40:14,320 --> 00:40:16,360
grow and shrink depending on the work that you're

1143
00:40:16,360 --> 00:40:18,360
doing is really key to

1144
00:40:18,360 --> 00:40:19,780
having a system like this.

1145
00:40:20,188 --> 00:40:21,878
If you don't have something like this,

1146
00:40:22,159 --> 00:40:24,478
you're always gonna have ways to compute. You're

1147
00:40:24,478 --> 00:40:26,800
always gonna move more slowly than you otherwise

1148
00:40:26,800 --> 00:40:28,800
could. And ultimately you're never

1149
00:40:28,800 --> 00:40:30,269
gonna get to the frontier of things,

1150
00:40:30,679 --> 00:40:32,860
because someone else will have that advantage.

1151
00:40:33,438 --> 00:40:35,719
So having the ability to schedule jobs

1152
00:40:35,719 --> 00:40:36,840
essentially arbitrarily.

1153
00:40:37,179 --> 00:40:39,179
And crucially, not having to worry about that

1154
00:40:39,179 --> 00:40:40,139
as a researcher

1155
00:40:40,699 --> 00:40:42,860
really is one of those things that enables you to move

1156
00:40:42,860 --> 00:40:45,050
quickly. One of the other good things

1157
00:40:45,050 --> 00:40:47,128
about having a really robust scheduler

1158
00:40:47,128 --> 00:40:49,369
is that you don't need to worry about failed

1159
00:40:49,369 --> 00:40:51,429
nodes. Because every job is

1160
00:40:51,429 --> 00:40:53,590
a configuration, right, I mentioned before that

1161
00:40:53,590 --> 00:40:54,530
everything was an asset.

1162
00:40:55,070 --> 00:40:57,110
So if I detect that a node has failed

1163
00:40:57,110 --> 00:40:59,349
during some pre pre-flight check or

1164
00:40:59,349 --> 00:41:00,570
during the actual job itself,

1165
00:41:01,228 --> 00:41:03,449
I can just switch that node out with another one,

1166
00:41:03,869 --> 00:41:04,860
and everything is good,

1167
00:41:05,188 --> 00:41:07,289
right? I don't need to worry about having to

1168
00:41:07,289 --> 00:41:09,389
do systems configuration myself or setting

1169
00:41:09,389 --> 00:41:10,708
up the networking or anything.

1170
00:41:11,030 --> 00:41:12,128
It all just works.

1171
00:41:13,849 --> 00:41:16,289
It also as a as a system

1172
00:41:16,289 --> 00:41:18,369
has a distributed logbook associated

1173
00:41:18,369 --> 00:41:20,409
with it. So I mentioned before that

1174
00:41:20,409 --> 00:41:22,389
we have this directed acyclic graph,

1175
00:41:22,760 --> 00:41:24,969
but actually each of those also link out

1176
00:41:24,969 --> 00:41:27,409
to various er metric platforms

1177
00:41:27,409 --> 00:41:27,949
as well.

1178
00:41:28,438 --> 00:41:30,530
And we collect all number of metrics, right, we

1179
00:41:30,530 --> 00:41:32,250
have our traditional training metrics,

1180
00:41:32,530 --> 00:41:34,849
but we also record a huge amount about the efficiency

1181
00:41:34,849 --> 00:41:35,969
of various jobs,

1182
00:41:36,329 --> 00:41:38,369
a number of GPUs that they use, when they were

1183
00:41:38,369 --> 00:41:39,750
busy, when they were idle,

1184
00:41:40,168 --> 00:41:41,418
their power draw.

1185
00:41:41,878 --> 00:41:44,079
Collecting all of those things really enables you

1186
00:41:44,079 --> 00:41:45,559
to do a lot of things.

1187
00:41:45,969 --> 00:41:48,449
So for one, it enables you to look at

1188
00:41:48,449 --> 00:41:50,090
certain workloads and go,

1189
00:41:50,449 --> 00:41:51,648
do we need to make this faster?

1190
00:41:52,280 --> 00:41:54,610
Or actually, can we scale it down, right, maybe it's

1191
00:41:54,610 --> 00:41:56,769
mostly waiting for network most of the time, well,

1192
00:41:56,929 --> 00:41:58,469
perhaps we don't need as many GPUs then.

1193
00:41:59,280 --> 00:42:01,539
It also crucially enables you to

1194
00:42:01,878 --> 00:42:03,418
get more insights about reliability.

1195
00:42:04,309 --> 00:42:06,309
One of the things that we've seen is that nodes

1196
00:42:06,309 --> 00:42:08,769
tend to fail under certain workloads.

1197
00:42:09,228 --> 00:42:11,429
So if you're running, you know, mini matrix multiplications

1198
00:42:11,429 --> 00:42:12,398
back to back to back,

1199
00:42:12,789 --> 00:42:14,590
chances are that's going to overheat your GPU.

1200
00:42:15,519 --> 00:42:17,530
If we detect that that workload is there

1201
00:42:17,530 --> 00:42:19,570
and that workload is actually crashing nodes in

1202
00:42:19,570 --> 00:42:20,119
practice,

1203
00:42:20,489 --> 00:42:22,489
there are more precautions that we can take to

1204
00:42:22,489 --> 00:42:23,989
make sure that that doesn't happen.

1205
00:42:24,449 --> 00:42:26,570
And again, sometimes you're, you know, you're just unlucky,

1206
00:42:26,820 --> 00:42:27,648
sometimes things happen,

1207
00:42:28,090 --> 00:42:30,250
but having a log of every single thing that you

1208
00:42:30,250 --> 00:42:32,329
did, and every single thing that has happened

1209
00:42:32,329 --> 00:42:33,309
and will happen

1210
00:42:33,668 --> 00:42:35,849
is a really good way to make sure that you're

1211
00:42:35,849 --> 00:42:38,340
not. Missing out on insights

1212
00:42:38,340 --> 00:42:40,378
that would enable you to get closer to the frontier.

1213
00:42:42,489 --> 00:42:44,809
I want to talk briefly about how all of this feeds

1214
00:42:44,809 --> 00:42:46,958
into large scale training runs.

1215
00:42:47,329 --> 00:42:49,570
I think large scale training runs are kind of the big headline

1216
00:42:49,570 --> 00:42:51,280
number that everyone gets excited about.

1217
00:42:51,610 --> 00:42:53,728
Right, when you saw last year that Deep Sek released

1218
00:42:53,728 --> 00:42:56,570
a model that was trained on only a few 1000 H200s,

1219
00:42:56,889 --> 00:42:59,050
or, or when Mr. Ow yesterday announced that they

1220
00:42:59,050 --> 00:43:01,570
trained their large model on only 2000 H200s.

1221
00:43:02,260 --> 00:43:04,260
Everyone always talks about the large scale training

1222
00:43:04,260 --> 00:43:06,500
runs. And it makes sense, right? It's

1223
00:43:06,500 --> 00:43:08,599
the thing that gives you the most eyeballs, it's

1224
00:43:08,599 --> 00:43:10,289
the thing that talks about the most money.

1225
00:43:10,579 --> 00:43:12,219
It's clear to see why we like this.

1226
00:43:12,898 --> 00:43:15,019
But what I want to point out to you is that there's

1227
00:43:15,019 --> 00:43:17,110
actually not that much difference between the large

1228
00:43:17,110 --> 00:43:18,269
scale training runs

1229
00:43:18,550 --> 00:43:20,550
and the small ones when you have a system

1230
00:43:20,550 --> 00:43:21,070
like this.

1231
00:43:22,000 --> 00:43:24,079
So this diagram that I showed

1232
00:43:24,079 --> 00:43:24,739
you before

1233
00:43:25,199 --> 00:43:26,559
of the asset flow

1234
00:43:26,918 --> 00:43:28,458
is exactly the same

1235
00:43:28,800 --> 00:43:30,878
no matter whether the model that you're training is

1236
00:43:30,878 --> 00:43:33,199
big or small. All

1237
00:43:33,199 --> 00:43:35,579
you do is you tack another box on the end,

1238
00:43:37,179 --> 00:43:39,320
you specify more GPUs or a different configuration

1239
00:43:39,320 --> 00:43:40,079
in some way,

1240
00:43:40,478 --> 00:43:41,099
and that's it.

1241
00:43:42,099 --> 00:43:44,119
There's no distinction in our system between

1242
00:43:44,739 --> 00:43:46,739
small models, a 7 billion parameter model,

1243
00:43:46,978 --> 00:43:48,530
or a 5 trillion parameter model.

1244
00:43:48,938 --> 00:43:50,938
You just adjust what it is that you have in

1245
00:43:50,938 --> 00:43:53,099
your configuration in some way, perhaps

1246
00:43:53,099 --> 00:43:54,478
some way that's determined by research,

1247
00:43:55,179 --> 00:43:55,739
and that's it.

1248
00:43:56,659 --> 00:43:59,019
And everything I've said to you so far is also

1249
00:43:59,019 --> 00:44:00,139
true for those big runs,

1250
00:44:00,458 --> 00:44:03,010
right, you can interrogate what's happening with your workflow,

1251
00:44:03,250 --> 00:44:05,458
you can see where the network is slow, you can

1252
00:44:05,458 --> 00:44:07,739
see, oh hey, actually maybe we need more GPUs

1253
00:44:07,739 --> 00:44:09,389
or maybe we can get away with fewer.

1254
00:44:09,898 --> 00:44:11,800
All of the insights that I've mentioned so far

1255
00:44:12,378 --> 00:44:14,418
also hold for big models as well as

1256
00:44:14,418 --> 00:44:15,119
small models.

1257
00:44:15,699 --> 00:44:17,769
So you don't have to worry about whether your big

1258
00:44:17,769 --> 00:44:20,219
model is training well or whether your loss spikes,

1259
00:44:20,340 --> 00:44:22,219
because you'll know if it happens.

1260
00:44:22,539 --> 00:44:23,619
You can sleep soundly.

1261
00:44:24,179 --> 00:44:26,179
And on a personal note, one of the things

1262
00:44:26,179 --> 00:44:27,639
I love about this system

1263
00:44:27,978 --> 00:44:29,199
is we all sleep soundly.

1264
00:44:29,969 --> 00:44:31,869
Because actually it's really reliable.

1265
00:44:32,369 --> 00:44:33,550
In times gone by,

1266
00:44:33,889 --> 00:44:35,889
engineers would stay up all night to make sure that

1267
00:44:35,889 --> 00:44:37,989
their training didn't crash, or if it did crash, it

1268
00:44:37,989 --> 00:44:39,219
would be all hands on deck.

1269
00:44:40,070 --> 00:44:42,469
Now we mostly have automated systems that recover

1270
00:44:42,469 --> 00:44:43,418
these things for us.

1271
00:44:43,989 --> 00:44:46,389
Sometimes, granted, there is a need for manual intervention,

1272
00:44:46,789 --> 00:44:48,829
but that is way less common than it is almost

1273
00:44:48,829 --> 00:44:50,949
anywhere else. And it's way less common than it used to be

1274
00:44:50,949 --> 00:44:51,949
even for us.

1275
00:44:52,590 --> 00:44:54,789
Most other companies have whole teams

1276
00:44:54,789 --> 00:44:56,869
that are just dedicated for babysitting a

1277
00:44:56,869 --> 00:44:58,148
training run. We do not.

1278
00:44:59,429 --> 00:45:01,860
And that is a crucial thing about moving quickly,

1279
00:45:02,469 --> 00:45:04,500
because let's face it, your headcount is an

1280
00:45:04,500 --> 00:45:05,168
expense.

1281
00:45:05,559 --> 00:45:07,809
Hiring more engineers in AI is a very expensive

1282
00:45:07,809 --> 00:45:10,309
thing. And if you can scale

1283
00:45:10,309 --> 00:45:12,309
and compete with people without having to

1284
00:45:12,309 --> 00:45:13,530
hire ever more people.

1285
00:45:14,340 --> 00:45:16,860
There's a lot more you can do, right? You can have more GPUs

1286
00:45:16,860 --> 00:45:19,239
or you can afford to get better people.

1287
00:45:19,619 --> 00:45:21,699
Or alternatively, you can enable the

1288
00:45:21,699 --> 00:45:23,199
brilliant people that you've hired

1289
00:45:23,579 --> 00:45:25,760
just to do the work that they actually care about.

1290
00:45:26,099 --> 00:45:28,099
I don't think anyone goes into AI because they want

1291
00:45:28,099 --> 00:45:30,739
to wait all night to fix some scheduling

1292
00:45:30,739 --> 00:45:32,739
issue, right? They want to build AGI, they want to

1293
00:45:32,739 --> 00:45:33,958
solve hard problems.

1294
00:45:35,208 --> 00:45:37,530
Having a system like this enables that. It

1295
00:45:37,530 --> 00:45:39,728
enables you to get people who

1296
00:45:39,728 --> 00:45:40,909
want to move quickly

1297
00:45:41,208 --> 00:45:43,110
and to enable them to move quickly.

1298
00:45:43,449 --> 00:45:45,449
They don't have to deal with internal politics, they don't have to

1299
00:45:45,449 --> 00:45:47,489
deal with systems that are flaky and don't work.

1300
00:45:47,809 --> 00:45:50,148
You have this whole system and it just works for them.

1301
00:45:50,648 --> 00:45:52,969
And it enables us to move so much faster,

1302
00:45:53,320 --> 00:45:55,539
it enables us to punch well above our weight,

1303
00:45:55,769 --> 00:45:58,208
and it enables us to stay ever closer to the frontier.

1304
00:46:02,260 --> 00:46:04,269
Before I wrap up, I just want to point out that

1305
00:46:04,889 --> 00:46:07,090
actually comparatively few GPU

1306
00:46:07,090 --> 00:46:09,090
hours are actually spent on the big

1307
00:46:09,090 --> 00:46:11,090
training run. It's a real misconception in

1308
00:46:11,090 --> 00:46:11,909
the industry.

1309
00:46:12,409 --> 00:46:14,570
Everything I've spoken about so far

1310
00:46:14,889 --> 00:46:16,329
has been based around.

1311
00:46:17,449 --> 00:46:20,039
You know, doing ablations on small models

1312
00:46:20,039 --> 00:46:22,228
or playing with different parameter mixtures

1313
00:46:22,228 --> 00:46:24,500
or playing with new RL

1314
00:46:24,500 --> 00:46:26,389
algorithms or things like that.

1315
00:46:27,208 --> 00:46:29,429
This is very much the case,

1316
00:46:29,628 --> 00:46:31,769
right, we spend our GPUs on those

1317
00:46:31,769 --> 00:46:33,889
things, on making sure that our

1318
00:46:33,889 --> 00:46:36,239
model can scale when it does scale,

1319
00:46:36,570 --> 00:46:38,610
making sure that the new algorithms that we've trialed

1320
00:46:38,610 --> 00:46:40,119
play out on a small scale.

1321
00:46:40,489 --> 00:46:43,010
Making sure that our data mixture isn't just horrendously

1322
00:46:43,010 --> 00:46:43,519
awful.

1323
00:46:43,889 --> 00:46:45,869
Right, we stack all of these things together

1324
00:46:46,128 --> 00:46:47,128
at a small scale.

1325
00:46:47,878 --> 00:46:50,148
And I promise you, every other foundation

1326
00:46:50,148 --> 00:46:52,389
lab in the world that makes models

1327
00:46:52,398 --> 00:46:53,309
does the same thing.

1328
00:46:54,260 --> 00:46:56,378
The reason why Deepeek were able to produce such

1329
00:46:56,378 --> 00:46:58,039
a good model nearly a year ago

1330
00:46:58,378 --> 00:47:00,648
was because they had tried many

1331
00:47:00,648 --> 00:47:02,699
small optimisations and tweaks

1332
00:47:02,699 --> 00:47:03,639
and ideas

1333
00:47:03,978 --> 00:47:06,019
and then combined them together to make a model that

1334
00:47:06,019 --> 00:47:08,219
was good. And all of those

1335
00:47:08,219 --> 00:47:10,289
ideas probably had to be trained in or had to be

1336
00:47:10,289 --> 00:47:12,469
tried independently, right? I don't know I wasn't there.

1337
00:47:12,769 --> 00:47:15,449
But I can't imagine that you would make all of those tweaks

1338
00:47:15,458 --> 00:47:16,320
just on a whim.

1339
00:47:16,728 --> 00:47:18,809
Right? Chances are you're at least going to look at it first and

1340
00:47:18,809 --> 00:47:21,000
go, oh actually that means something,

1341
00:47:21,050 --> 00:47:21,809
that's important.

1342
00:47:22,489 --> 00:47:24,750
And it turns out the same is true for us, right,

1343
00:47:24,809 --> 00:47:26,688
we spend comparatively few

1344
00:47:27,010 --> 00:47:29,128
of our GPU hours on a

1345
00:47:29,128 --> 00:47:30,128
huge training run.

1346
00:47:30,610 --> 00:47:32,849
It's more the ta da at the end of the year

1347
00:47:33,050 --> 00:47:35,329
or during, you know, some point, right, we go, oh,

1348
00:47:35,530 --> 00:47:37,389
actually we're ready, let's train a big model.

1349
00:47:37,688 --> 00:47:39,570
And then it can, you know, it proceeds for some weeks,

1350
00:47:40,050 --> 00:47:42,090
but actually ultimately that's not where we spend most of

1351
00:47:42,090 --> 00:47:44,168
our time, that's not where we spend our thinking time.

1352
00:47:45,409 --> 00:47:47,590
One of the things about having such a system though is it

1353
00:47:47,590 --> 00:47:49,809
gives you the confidence that if tomorrow you

1354
00:47:49,809 --> 00:47:52,010
needed to train a new big model, you could.

1355
00:47:52,530 --> 00:47:54,570
Right? If someone came down to me

1356
00:47:54,570 --> 00:47:56,570
and said, Joe, we need to train a new state

1357
00:47:56,570 --> 00:47:58,360
of the art model tomorrow, can you do it?

1358
00:47:58,849 --> 00:48:01,050
This system gives me the confidence

1359
00:48:01,050 --> 00:48:01,648
to say yes.

1360
00:48:02,510 --> 00:48:04,628
I don't have to worry about how we're going to get there because the

1361
00:48:04,628 --> 00:48:06,708
system enables you to already have those insights in

1362
00:48:06,708 --> 00:48:08,860
place. We have many buns in the oven,

1363
00:48:08,869 --> 00:48:11,030
as it were, right, we're constantly iterating over

1364
00:48:11,030 --> 00:48:11,688
these things,

1365
00:48:11,949 --> 00:48:13,989
and at any given point we know what we need to

1366
00:48:13,989 --> 00:48:15,208
do to improve our model.

1367
00:48:16,378 --> 00:48:18,619
Having a system like this really enables

1368
00:48:18,619 --> 00:48:20,699
you to have such confidence in

1369
00:48:20,699 --> 00:48:21,918
what it is that you're doing.

1370
00:48:22,418 --> 00:48:24,619
And actually, as someone who works there, that

1371
00:48:24,619 --> 00:48:25,409
really matters,

1372
00:48:25,760 --> 00:48:27,780
right, knowing that we can keep up

1373
00:48:27,780 --> 00:48:29,978
with everyone else, despite having a much smaller

1374
00:48:29,978 --> 00:48:32,119
team is perfect, that's what I want.

1375
00:48:32,300 --> 00:48:34,418
I want to have that confidence. And having a system

1376
00:48:34,418 --> 00:48:36,139
like this gives that to you in spades.

1377
00:48:37,148 --> 00:48:38,090
With that being said,

1378
00:48:39,539 --> 00:48:41,719
If you're interested in going from

1379
00:48:41,820 --> 00:48:44,079
being artisanal to being industrial, we are hiring.

1380
00:48:44,179 --> 00:48:45,679
All of our open roles are on our website.

1381
00:48:46,019 --> 00:48:48,128
And if you're interested in what I've spoken about, we're at booth

1382
00:48:48,128 --> 00:48:48,849
802.

1383
00:48:49,179 --> 00:48:51,219
So please feel free to head down and come and say

1384
00:48:51,219 --> 00:48:53,340
hello. And with that, I'd like to thank you all for listening.

1385
00:48:53,500 --> 00:48:55,019
If you've got any questions, I'd be happy to answer them.

