# AWS re:invent 2025 - 在 AWS 上使用 SageMaker 训练高性能 AI 模型

## 会议概述

本次技术会议由 AWS SageMaker 团队的 Michael Aguik（高级产品经理）和 Tomori Shimomura（首席解决方案架构师）主讲，并邀请了 Roblox 的首席机器学习科学家 Denny Gupil 分享实际应用案例。会议重点介绍了如何使用 Amazon SageMaker 训练大规模 AI 模型，特别是 SageMaker Training Jobs 和 SageMaker HyperPod 两大核心能力。

随着 AI 模型规模的不断扩大，训练这些模型需要越来越多的计算资源。会议深入探讨了训练大型 AI 模型时面临的六个关键维度：计算可用性、性能、弹性、可观测性、易用性以及成本。每个维度都直接影响训练成本和效率。SageMaker 提供了全面的解决方案来应对这些挑战，从自动化的集群管理到高级的故障恢复机制，帮助客户更高效地训练大规模模型。

Roblox 的案例展示了如何使用 SageMaker HyperPod 训练 4D 基础模型（3D 对象加功能性），该模型用于为创作者生成可交互的游戏资产。通过 HyperPod 与 EKS 的集成，Roblox 能够灵活使用现有的 AI 平台工具，同时获得企业级的稳定性和弹性能力。

## 详细时间轴与关键要点

### 开场介绍 (00:00 - 04:00)
- **00:00:00** - 会议开始，欢迎参加 re:invent 第一天的技术会议
- **00:00:17** - Michael Aguik 自我介绍，担任 SageMaker 高级产品经理，专注于帮助客户训练高性能模型
- **00:00:32** - 介绍 Tomori Shimomura，首席解决方案架构师
- **00:00:44** - 介绍 Roblox 的 Denny Gupil，将分享实际使用案例
- **00:00:55** - 会议议程：讨论训练大型 AI 模型的需求、挑战以及 SageMaker 的解决方案
- **01:30** - 现场调查：多少人训练或定制过大型模型
- **01:43** - 现场调查：多少人使用过 SageMaker

### AI 模型训练的趋势与挑战 (04:00 - 10:00)
- **01:53** - 观察到 AI 图标（sparkle icon）在各处出现的趋势
- **02:26** - 每个 AI 图标背后都是一个训练好的模型
- **02:45** - 客户需要为其用户体验添加更强大的模型
- **02:52** - McKinsey 研究显示 47% 使用生成式 AI 的公司也在训练或定制模型
- **03:04** - SageMaker 的构建目标：帮助客户构建更强大的模型
- **03:23** - 2017 年推出 SageMaker Training Jobs
- **03:28** - Training Jobs 提供完全托管的 API，自动创建和删除集群
- **04:02** - 客户需求：更精细的控制、可观测性和持久化集群
- **04:29** - 推出 SageMaker HyperPod 满足这些需求

### SageMaker 训练能力介绍 (10:00 - 20:00)
- **04:33** - 两大核心能力：Training Jobs（临时计算）和 HyperPod（持久化）
- **05:03** - 训练大型 AI 模型的六个关键维度
- **05:20** - 每个维度都直接影响成本
- **05:43** - 深入探讨计算可用性
- **05:52** - 过去几年需要更多计算来训练更强大的模型
- **06:00** - 更多训练数据和更多参数使模型更强大
- **06:30** - 现在使用 10^24 flops（yottaflop）的计算能力
- **06:40** - 1 yottaflop 的具体含义
- **06:55** - 5 yottaflops = 1000 个 P5 GPU 持续运行一个月
- **07:06** - 优化 GPU 利用率至关重要
- **07:17** - SageMaker 提供多种 GPU 和加速器选择
- **07:31** - 从 H100 单 GPU 到 GB200 ultra 服务器
- **07:47** - 多种容量获取选项：按需、预留、Spot 实例
- **08:06** - 上周在 HyperPod 上推出 Spot 实例支持

### 性能优化 (20:00 - 30:00)
- **08:30** - 讨论性能维度
- **10:05** - 演示参数数量与 GPU 内存的关系
- **10:29** - 模型参数增长快于 GPU 内存增长
- **11:08** - Llama 3 70B 模型需要约 1.4TB GPU 内存
- **11:46** - H100 只有 80GB 内存，无法容纳整个模型
- **11:56** - 需要分布式训练来克服扩展挑战
- **12:17** - 模型并行：分片模型，复制数据
- **12:54** - 数据并行：分片数据，复制模型
- **13:33** - 网络成为关键瓶颈
- **14:08** - 需要高带宽、低延迟的通信
- **14:16** - SageMaker 提供多种性能优化能力
- **14:34** - 自动化设置，支持 PyTorch、TensorFlow、Ray
- **14:43** - 通信库：Nvidia NCCL 和 Neuron Collective
- **14:57** - 高速网络：NVLink 和 EFA（最高 3200 Gbps）

### 弹性与故障恢复 (30:00 - 40:00)
- **15:33** - 讨论弹性维度
- **15:59** - Meta 研究显示：1024 节点平均 8 小时故障一次
- **16:36** - 每天三次故障（早餐、午餐、凌晨 2 点）
- **16:46** - HyperPod 的四步弹性策略
- **17:01** - 缓解：鼓励检查点
- **17:19** - 推出托管分层检查点，减少开销
- **17:42** - 预防：标准和深度健康检查
- **18:07** - 检测：自动健康监控代理
- **18:16** - 恢复：自动重启节点或替换节点
- **18:33** - 节省高达 40% 的训练时间

### 实际演示 - SageMaker Training Jobs (40:00 - 50:00)
- **18:57** - Tomori 开始演示部分
- **19:13** - 介绍 SageMaker 的两种训练能力
- **19:37** - Training Jobs 示例代码片段
- **20:23** - 演示创建训练作业对象
- **21:23** - HyperPod 介绍：持久化集群
- **22:05** - HyperPod 支持 Slurm 和 EKS 两种编排器
- **23:19** - Slurm：三种节点类型（控制器、计算、登录）
- **23:55** - EKS/Kubernetes：仅包含计算节点
- **24:54** - 选择建议：根据团队偏好和用例

### HyperPod 演示 (50:00 - 60:00)
- **25:34** - HyperPod 弹性能力回顾
- **26:22** - 演示创建 HyperPod 集群
- **26:46** - 快速设置：选择实例类型和数量
- **27:09** - 安装可观测性插件（一键安装）
- **27:31** - 启用任务治理功能
- **28:30** - 配置训练作业
- **29:11** - 安装额外软件
- **29:41** - 修改检查点代码以启用托管分层检查点
- **30:33** - 监控三个信息：节点状态、Pod 状态、训练日志
- **31:19** - 注入人工 GPU 故障以模拟硬件错误
- **32:00** - 演示节点变为 NotReady 状态
- **32:23** - 实例自动替换
- **32:40** - 作业自动恢复

### 可观测性仪表板 (60:00 - 70:00)
- **34:10** - 展示可观测性仪表板
- **34:26** - 基于 Prometheus 和 Amazon Managed Grafana
- **34:40** - 集群仪表板：显示硬件资源信息
- **35:28** - 任务仪表板：显示 CPU、GPU、内存利用率
- **36:10** - 任务级别而非实例级别的指标
- **36:22** - 新功能亮点
- **36:38** - 增强的集群创建体验
- **37:17** - 一键可观测性
- **38:22** - HyperPod 训练操作器
- **39:30** - 托管分层检查点
- **40:18** - 在 HyperPod 上运行 IDE 和 Jupyter Notebook
- **40:43** - SageMaker AI 的 MCP 服务器

### Roblox 案例研究 (70:00 - 80:00)
- **41:19** - Denny Gupil 介绍 Roblox AI 应用
- **41:40** - Roblox 平台概述：创建、游戏和互动
- **41:52** - 1.5 亿日活跃用户，4500 万峰值并发
- **42:00** - AI 基础设施：每秒 100 万次以上查询，350+ 模型
- **42:23** - AI 在安全方面的应用
- **42:40** - 实时语音和文本审核
- **43:05** - 为玩家提供推荐和搜索
- **43:30** - 为创作者提供生成式 AI 工具
- **43:40** - 创作者助手演示
- **44:11** - 4D 模型介绍：3D 对象 + 功能性
- **44:40** - 示例：西瓜枪和魔毯

### Roblox 训练基础设施 (80:00 - 90:00)
- **45:17** - AI 平台架构概览
- **45:40** - 数据组件：数据湖、特征存储、嵌入
- **45:52** - 训练组件：数据处理和训练
- **46:11** - 服务组件：模型注册表和服务
- **46:40** - 可观测性、成本跟踪和实验平台
- **46:51** - 重点关注分布式训练组件
- **47:17** - 4D 模型的扩展因素
- **47:30** - 数据规模：1 亿个 3D 资产，6.5PB 数据
- **47:59** - 模型大小：10 亿到 700 亿参数
- **48:28** - 硬件需求：大量 GPU 内存，选择 H200
- **48:41** - 训练技术要求：高性能、稳定、易用
- **48:59** - 最重要：能够运行多个并行作业

### Roblox 面临的挑战与解决方案 (90:00 - 结束)
- **50:10** - 三大挑战
- **50:38** - 挑战 1：如何获取容量
- **51:09** - 挑战 2：如何确保弹性
- **51:42** - 挑战 3：成本效率和 GPU 利用率
- **52:08** - HyperPod 如何帮助解决这些挑战
- **52:14** - 易于设置：从原型到生产仅需一个月
- **52:40** - 最近创建新集群不到一小时
- **52:56** - GPU 容量：多种选项（预留、Spot、灵活训练计划）
- **53:10** - 稳定性：内置弹性功能
- **53:30** - 三个月内未发现单个节点故障
- **53:50** - 缺失功能：节点恢复检测的可见性
- **54:04** - 灵活性：与 EKS 集成
- **54:51** - HyperPod 节点像普通 EKS 节点一样工作
- **55:17** - 框架无关：可使用 Kubeflow 和 Ray
- **55:52** - 未来计划：去中心化计算
- **56:16** - 跨区域、跨集群动态调度工作负载
- **56:56** - 对用户透明的统一体验
- **57:16** - 希望与 SageMaker 团队合作实现多区域、多集群支持

### 总结与资源 (结束部分)
- **57:38** - Michael 总结会议
- **57:53** - 回顾六个关键维度
- **58:14** - 灵活选择的重要性
- **58:30** - 从硬件到编排层的多种选项
- **59:17** - 预构建镜像、驱动程序和工具包
- **59:33** - 多种训练库和 MLOps 集成
- **59:59** - 支持 Ray、Kubectl、Prometheus、Grafana
- **1:00:15** - 可使用 SageMaker Studio 或直接从本地机器提交作业
- **1:00:35** - HyperPod 支持 Kubernetes 和 Slurm
- **1:00:50** - 博客链接和 GitHub 示例
- **1:01:13** - 感谢参与，欢迎会后交流