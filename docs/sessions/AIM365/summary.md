# AWS re:Invent 2025 - 使用SageMaker训练高性能AI模型

## 会议概述

本次会议由AWS SageMaker团队的高级产品经理Michael Oguike和首席解决方案架构师Tomonori Shimomura主讲，并邀请了Roblox的首席机器学习科学家Denis Goupil分享实际应用案例。会议重点讨论了在AWS上使用SageMaker训练大型AI模型的挑战和解决方案，特别是SageMaker Training Jobs和HyperPod两个核心服务的能力。

会议涵盖了训练大型AI模型的六个关键维度：计算可用性、性能、弹性、可观测性、易用性和成本。通过技术演示和Roblox的4D基础模型训练实例，展示了SageMaker如何帮助客户解决分布式训练中的复杂挑战，包括GPU集群管理、故障恢复、检查点管理等关键功能。

## 详细时间线与关键要点

### 0:00-10:00 会议开场与背景介绍
- 介绍演讲嘉宾和会议议程
- 通过举手调查了解观众对大模型训练和SageMaker的使用经验
- 展示AI应用的普及趋势，McKinsey研究显示47%使用生成式AI的公司正在训练或定制AI模型
- 介绍SageMaker的发展历程：从2017年的Training Jobs到后来的HyperPod

### 10:00-20:00 计算可用性挑战
- 分析训练大模型所需的计算资源增长趋势，达到10^24 FLOPs（yottaFLOP）
- 解释yottaFLOP的概念：相当于1000个P5 GPU持续运行一个月
- 介绍SageMaker提供的多种GPU选择：从H100单GPU到GP200 ultra服务器
- 讲解不同的容量获取方式：按需、Spot实例（最高节省90%）、预留容量、灵活训练计划

### 20:00-30:00 性能优化与分布式训练
- 对比模型参数增长与GPU内存增长的趋势差异
- 以Llama 3-70B为例说明内存需求：1.4TB vs H100的80GB
- 详细解释分布式训练策略：
  - 模型并行：分片模型，复制数据
  - 数据并行：分片数据，复制模型
  - 混合并行：同时使用两种策略
- 强调高速网络的重要性：NVLink技术和Elastic Fabric Adapter

### 30:00-40:00 弹性与故障恢复
- 引用Meta研究：1024节点集群平均故障间隔仅8小时
- 介绍四层弹性策略：缓解、预防、检测、恢复
- 详细说明各层功能：
  - 检查点管理和分层检查点
  - 深度健康检查和节点隔离
  - 自动健康监控
  - 自动节点重启和替换
- 展示可节省高达40%的训练时间

### 40:00-50:00 技术演示
- Tomonori演示SageMaker Training Jobs的完整流程
- 展示代码编辑器、数据预处理、训练任务配置
- 演示MLflow集成和训练指标监控
- HyperPod集群创建和配置演示
- 实际演示故障注入和自动恢复过程
- 展示Grafana和Prometheus集成的可观测性仪表板

### 50:00-56:30 Roblox案例分享与总结
- Denis介绍Roblox平台：1.5亿日活用户，4500万峰值并发
- 分享AI在Roblox的应用：安全审核、推荐系统、创作者工具
- 详细介绍4D基础模型项目：100万个3D资产，6.5PB数据
- 讲解HyperPod在实际项目中的三大优势：
  - 容量获取的灵活性
  - 内置的稳定性和故障恢复
  - 与EKS的无缝集成
- Michael总结SageMaker的技术栈灵活性和资源推荐