1
00:00:00,450 --> 00:00:02,280
- My name is Abhijit Bose.

2
00:00:02,280 --> 00:00:06,420
I head the Enterprise AI/ML
Platforms and Engineering

3
00:00:06,420 --> 00:00:07,623
for Capital One.

4
00:00:08,940 --> 00:00:11,853
We have a few Capital
One folks here as well.

5
00:00:13,290 --> 00:00:17,820
We are responsible for strategy
development and execution

6
00:00:17,820 --> 00:00:21,240
of our enterprise AI/ML infrastructure,

7
00:00:21,240 --> 00:00:26,240
which powers most of the AI/ML
applications at the company.

8
00:00:34,380 --> 00:00:37,800
Here is a quick look at the agenda.

9
00:00:37,800 --> 00:00:42,800
I will start with a few
slides on AI at Capital One.

10
00:00:45,030 --> 00:00:47,670
It's actually a 10-year journey for us.

11
00:00:47,670 --> 00:00:50,940
It's been, you know, a
series of innovations

12
00:00:50,940 --> 00:00:53,520
we have done over the years,

13
00:00:53,520 --> 00:00:56,730
I would say transformations,
that led to this moment,

14
00:00:56,730 --> 00:00:58,980
you know, where we are
at the frontier of AI.

15
00:00:59,820 --> 00:01:04,820
And then core to our strategy,
there are two things.

16
00:01:06,750 --> 00:01:09,060
The first one is the custom AI.

17
00:01:09,060 --> 00:01:12,810
A lot of folks, a lot of
companies are using AI.

18
00:01:12,810 --> 00:01:16,980
But core to our strategy is
how do we build custom AI

19
00:01:16,980 --> 00:01:20,160
that run in tune with our infrastructure,

20
00:01:20,160 --> 00:01:23,433
that run using our own customized models.

21
00:01:24,930 --> 00:01:28,623
And then the second part of our
strategy is the AI platform.

22
00:01:30,000 --> 00:01:31,410
And in this presentation,

23
00:01:31,410 --> 00:01:33,603
I'll focus more on the AI platform.

24
00:01:35,520 --> 00:01:37,770
There is another big
conference going on this week,

25
00:01:37,770 --> 00:01:39,480
which is NeurIPS.

26
00:01:39,480 --> 00:01:40,560
If you follow NeurIPS,

27
00:01:40,560 --> 00:01:43,410
you can follow some of
the Capital One talks

28
00:01:43,410 --> 00:01:45,690
by my colleagues there.

29
00:01:45,690 --> 00:01:50,550
There you will find out more
about our customized model

30
00:01:50,550 --> 00:01:52,920
and that custom AI strategy.

31
00:01:52,920 --> 00:01:54,420
But in this talk,

32
00:01:54,420 --> 00:01:57,663
it'll be more about the
platform and infrastructure.

33
00:01:59,970 --> 00:02:04,970
I will also go over a
particular case study

34
00:02:05,370 --> 00:02:07,520
that's, I think, on a
lot of people's mind.

35
00:02:08,790 --> 00:02:11,820
How do we deploy agentic coding tools?

36
00:02:11,820 --> 00:02:14,340
But the way we are deploying it is

37
00:02:14,340 --> 00:02:17,880
actually using our own
platform to deploy that

38
00:02:17,880 --> 00:02:19,500
with the right set of guardrails,

39
00:02:19,500 --> 00:02:21,723
with the right set of, you know, gateway,

40
00:02:22,770 --> 00:02:26,460
that actually makes it
much more well-managed

41
00:02:26,460 --> 00:02:28,260
and scalable throughout the company.

42
00:02:29,820 --> 00:02:31,020
And, of course, you know,

43
00:02:31,020 --> 00:02:34,410
none of this would be possible
without having great talent.

44
00:02:34,410 --> 00:02:37,440
I'm really fortunate
to have such wonderful,

45
00:02:37,440 --> 00:02:41,160
extremely exceptional, you
know, talent at the company.

46
00:02:41,160 --> 00:02:44,920
So I'm gonna focus on a
couple of things we are doing

47
00:02:45,900 --> 00:02:50,460
to really be at the forefront of AI

48
00:02:50,460 --> 00:02:52,470
so that we build a brand name

49
00:02:52,470 --> 00:02:55,860
so that we can attract the
best talent in the world

50
00:02:55,860 --> 00:02:56,973
to work with us.

51
00:03:04,380 --> 00:03:07,020
But first I want to share

52
00:03:07,020 --> 00:03:09,183
some quick context about Capital One.

53
00:03:10,050 --> 00:03:14,493
We are a 30-year-old,
founder-led Fortune 100 company.

54
00:03:15,450 --> 00:03:20,450
The founder-led is really, you
know, kind of important for,

55
00:03:20,790 --> 00:03:22,743
for me, having come from Facebook.

56
00:03:24,900 --> 00:03:27,300
Our founder, Rich Fairbank,

57
00:03:27,300 --> 00:03:32,300
works very actively hands-on
with us on our AI strategy.

58
00:03:32,520 --> 00:03:35,910
And that actually has
made my life much easier.

59
00:03:35,910 --> 00:03:39,120
And, you know, a lot of other
AI leaders at the company,

60
00:03:39,120 --> 00:03:41,733
we are just fortunate to
have such a, you know,

61
00:03:43,230 --> 00:03:46,560
forward-leaning and very innovative CEO

62
00:03:46,560 --> 00:03:48,843
at the helm of the company.

63
00:03:50,310 --> 00:03:53,103
We are also the nation's
largest direct bank.

64
00:03:54,300 --> 00:03:55,133
And along the way,

65
00:03:55,133 --> 00:04:00,133
we have been recognized as one
of the best places to work.

66
00:04:00,300 --> 00:04:04,653
But I will focus on, I'll just
draw your attention to two.

67
00:04:06,150 --> 00:04:07,620
In the last three years,

68
00:04:07,620 --> 00:04:12,620
we have been number one in
talent in the Evident AI index,

69
00:04:13,830 --> 00:04:17,520
that actually takes in, I
think, 50 or 60 global banks

70
00:04:17,520 --> 00:04:22,293
and then rates them on their
AI maturity, you know, talent,

71
00:04:23,190 --> 00:04:25,680
how responsible they have been

72
00:04:25,680 --> 00:04:30,030
in deploying AI at the company, et cetera.

73
00:04:30,030 --> 00:04:32,280
And then the second one is that,

74
00:04:32,280 --> 00:04:34,590
this just came out recently,

75
00:04:34,590 --> 00:04:38,760
we are now top 10 companies in the world

76
00:04:38,760 --> 00:04:43,760
along with Google, Microsoft,
you know, Nvidia, Samsung,

77
00:04:45,780 --> 00:04:50,433
in terms of the generative
and agentic AI patents.

78
00:04:53,070 --> 00:04:55,320
You know, all of this is to say

79
00:04:55,320 --> 00:05:00,320
that just to highlight
the focus on innovation

80
00:05:00,990 --> 00:05:03,720
and the relentless focus on developing

81
00:05:03,720 --> 00:05:05,973
and attracting talent at the company.

82
00:05:15,930 --> 00:05:20,930
So, you know, it's not a surprise
that we are at this moment

83
00:05:24,150 --> 00:05:29,150
of AI transforming so
many, you know, businesses,

84
00:05:29,700 --> 00:05:31,920
so much of society.

85
00:05:31,920 --> 00:05:35,700
But our history as a technology innovator

86
00:05:35,700 --> 00:05:38,493
actually positions us really well.

87
00:05:41,970 --> 00:05:43,620
Before I go to the next slide,

88
00:05:43,620 --> 00:05:48,620
but the foundations of
our company is build,

89
00:05:48,840 --> 00:05:53,163
are built on our heritage of
data-driven decision making,

90
00:05:54,570 --> 00:05:56,670
modern-tech stack.

91
00:05:56,670 --> 00:06:00,633
We have our in-house data
science and engineering talent.

92
00:06:01,710 --> 00:06:03,123
We are all in the cloud.

93
00:06:04,980 --> 00:06:08,100
I joined the company in late 2020,

94
00:06:08,100 --> 00:06:11,400
and that was the year we got
out of our last data center.

95
00:06:11,400 --> 00:06:13,323
I still remember we celebrated that.

96
00:06:14,400 --> 00:06:17,793
We have been in, you know,
AWS primarily since then.

97
00:06:19,950 --> 00:06:21,660
We have done a lot of work

98
00:06:21,660 --> 00:06:25,080
in transforming our data
ecosystem at the company.

99
00:06:25,080 --> 00:06:27,330
And as you know, your data advantage

100
00:06:27,330 --> 00:06:29,673
is really your AI advantage these days.

101
00:06:31,110 --> 00:06:33,570
And then we have a
history, very rich history.

102
00:06:33,570 --> 00:06:38,340
We have a DNA of enterprise platforms.

103
00:06:38,340 --> 00:06:42,573
We don't do bespoke application
development at the company.

104
00:06:43,530 --> 00:06:45,750
From data to AI to cloud,

105
00:06:45,750 --> 00:06:48,930
wherever we see a common pattern,

106
00:06:48,930 --> 00:06:52,860
we build platforms that
everybody in the company uses.

107
00:06:52,860 --> 00:06:56,523
And AI is no exception to that.

108
00:06:57,750 --> 00:06:59,760
And then, of course, you know,

109
00:06:59,760 --> 00:07:04,760
we are exceptional at risk management.

110
00:07:07,050 --> 00:07:11,430
But this does not happen overnight.

111
00:07:11,430 --> 00:07:13,533
This takes, you know, many years.

112
00:07:14,370 --> 00:07:19,370
As our senior leaders say, you
know, it's a lonely journey

113
00:07:22,620 --> 00:07:24,123
with a lot of hard work.

114
00:07:25,890 --> 00:07:30,003
And for us, it started
almost 10 years ago.

115
00:07:31,371 --> 00:07:33,120
And I'm not gonna go
through the timelines,

116
00:07:33,120 --> 00:07:37,590
but you can see those
like from open source

117
00:07:37,590 --> 00:07:40,050
to declaring we were all in the cloud,

118
00:07:40,050 --> 00:07:43,113
to getting out of our
last data center in 2020,

119
00:07:44,850 --> 00:07:47,310
launching Capital One software,

120
00:07:47,310 --> 00:07:50,280
where we took some of the capabilities.

121
00:07:50,280 --> 00:07:53,400
We were building in-house for ourselves.

122
00:07:53,400 --> 00:07:57,480
We saw an opportunity to
actually take those to the market

123
00:07:57,480 --> 00:08:01,020
for other businesses, other companies.

124
00:08:01,020 --> 00:08:03,720
And that actually brought a
very different perspective

125
00:08:04,767 --> 00:08:07,590
to our software engineers
and product managers,

126
00:08:07,590 --> 00:08:11,070
because now we are not just the customer,

127
00:08:11,070 --> 00:08:13,800
but we are more service providers.

128
00:08:13,800 --> 00:08:16,830
So things like multi-tenancy
became very important

129
00:08:16,830 --> 00:08:18,660
for all of us.

130
00:08:18,660 --> 00:08:20,670
Even in the AI platform,

131
00:08:20,670 --> 00:08:23,850
I remember the first kind of the impetus

132
00:08:23,850 --> 00:08:26,010
for multi-tenancy started, you know,

133
00:08:26,010 --> 00:08:29,550
when Capital One software
started working with us,

134
00:08:29,550 --> 00:08:31,830
and we realized that
not all of our platforms

135
00:08:31,830 --> 00:08:34,860
and capabilities were
built for multi-tenancy.

136
00:08:34,860 --> 00:08:37,380
And now every capability that we build,

137
00:08:37,380 --> 00:08:38,940
it has to be multi-tenant

138
00:08:38,940 --> 00:08:42,360
because someday we might
actually externalize that service

139
00:08:42,360 --> 00:08:43,953
to other customers.

140
00:08:49,920 --> 00:08:54,920
In late 2024, we started
kind of the groundwork

141
00:08:55,230 --> 00:08:59,373
for building our first agentic
application at the company.

142
00:09:00,930 --> 00:09:03,570
And then in January of this year,

143
00:09:03,570 --> 00:09:06,030
we launched our first customer-facing,

144
00:09:06,030 --> 00:09:10,620
multi-agentic application
called Chat Concierge.

145
00:09:10,620 --> 00:09:13,353
I'm gonna briefly talk about that.

146
00:09:15,840 --> 00:09:19,110
And that again was a
pivotal moment for us.

147
00:09:19,110 --> 00:09:21,600
You know, this is the first time

148
00:09:21,600 --> 00:09:26,363
a bank really exposed
a multi-agentic system

149
00:09:27,210 --> 00:09:30,783
in front of live customers
live in the market.

150
00:09:31,740 --> 00:09:33,630
We learned a ton from that.

151
00:09:33,630 --> 00:09:38,630
And we are, and as I'll
show you, we learned,

152
00:09:39,630 --> 00:09:41,820
that we took all the lessons learned,

153
00:09:41,820 --> 00:09:46,820
and then we kind of like
reformulated our platform plans.

154
00:09:47,370 --> 00:09:49,440
And now we are all in agents

155
00:09:49,440 --> 00:09:52,293
and how we scale agents at the company.

156
00:09:57,150 --> 00:10:01,710
We are also using AI
extensively at the company

157
00:10:01,710 --> 00:10:04,950
for all kinds of applications.

158
00:10:04,950 --> 00:10:07,650
Here are some examples.

159
00:10:07,650 --> 00:10:12,650
I already talked about the
multi-agentic AI workflow

160
00:10:12,870 --> 00:10:14,283
called Chat Concierge.

161
00:10:15,990 --> 00:10:20,313
We also use AI for real-time
fraud detection and mitigation.

162
00:10:21,300 --> 00:10:24,180
Many of you are familiar with
Transformer architecture.

163
00:10:24,180 --> 00:10:26,340
We use Transformers these days

164
00:10:26,340 --> 00:10:31,340
to personalize user experiences
on our mobile and webpages.

165
00:10:35,100 --> 00:10:39,600
If you use our Capital
One Shopping plugin,

166
00:10:39,600 --> 00:10:44,280
it uses AI to find the right
offer for you from the right,

167
00:10:44,280 --> 00:10:47,910
you know, merchant as you are checking in,

168
00:10:47,910 --> 00:10:52,473
checking out, you know, your SKU.

169
00:10:54,000 --> 00:10:57,630
And then if you use our
Capital One Auto Navigator app,

170
00:10:57,630 --> 00:11:02,400
it uses image recognition
to find you the right card

171
00:11:02,400 --> 00:11:03,663
that you are looking for.

172
00:11:04,770 --> 00:11:08,850
Again, those are, by AI,
I mean not generative AI.

173
00:11:08,850 --> 00:11:11,073
A lot of these are, you know, neural nets.

174
00:11:12,570 --> 00:11:17,570
But, you know, more and more
we are also using LLM-driven

175
00:11:18,390 --> 00:11:20,913
and agentic AI systems.

176
00:11:24,510 --> 00:11:29,510
Now, let's talk about
where we are going with AI

177
00:11:29,880 --> 00:11:31,113
at the enterprise.

178
00:11:33,750 --> 00:11:38,750
Now, we all realize that AI
is not just a new technology.

179
00:11:39,930 --> 00:11:43,050
It is going to fundamentally
change our business,

180
00:11:43,050 --> 00:11:45,210
fundamentally change our processes

181
00:11:45,210 --> 00:11:47,193
that we use at the company.

182
00:11:48,120 --> 00:11:53,120
Now, when it comes to
scaling AI at any large,

183
00:11:53,850 --> 00:11:57,540
you know, regulated industry like ours,

184
00:11:57,540 --> 00:12:00,870
I think all of us have
to deal with two things.

185
00:12:00,870 --> 00:12:03,030
One is the need for speed.

186
00:12:03,030 --> 00:12:04,800
You know, every other day,

187
00:12:04,800 --> 00:12:06,750
there is a new something happening,

188
00:12:06,750 --> 00:12:08,760
you know, new model coming up,

189
00:12:08,760 --> 00:12:11,820
or some inferencing, you know,

190
00:12:11,820 --> 00:12:14,403
algorithm optimization comes up.

191
00:12:15,390 --> 00:12:19,560
Lot of work is happening
in agentic coding tools.

192
00:12:19,560 --> 00:12:21,720
We are seeing real benefits.

193
00:12:21,720 --> 00:12:25,380
So there is a lot of pressure on all of us

194
00:12:25,380 --> 00:12:28,770
to actually come bring
these tools into the company

195
00:12:28,770 --> 00:12:29,733
and deploy them.

196
00:12:30,990 --> 00:12:34,770
But we also have to make sure

197
00:12:34,770 --> 00:12:38,040
that all these tools are well-managed.

198
00:12:38,040 --> 00:12:43,040
You know, we have zero tolerance
for cyber or risk failures

199
00:12:44,100 --> 00:12:47,460
and we have an exceptionally
high bar on those.

200
00:12:47,460 --> 00:12:51,220
So how do you build at the frontier of AI

201
00:12:53,640 --> 00:12:56,400
at the speed of well-managed?

202
00:12:56,400 --> 00:13:00,300
That is the core problem
statement, I think, for all of us.

203
00:13:00,300 --> 00:13:02,340
Those who work in, you
know, large companies

204
00:13:02,340 --> 00:13:05,040
and regulated industries,

205
00:13:05,040 --> 00:13:06,720
we have to deal with.

206
00:13:06,720 --> 00:13:11,520
Now, before I go to the next page,

207
00:13:11,520 --> 00:13:15,570
I want to define the
speed of well-managed,

208
00:13:15,570 --> 00:13:17,460
because that's also something we learned.

209
00:13:17,460 --> 00:13:22,460
You know, it's not the
speed that we were used to

210
00:13:24,240 --> 00:13:26,430
maybe even three years ago.

211
00:13:26,430 --> 00:13:31,430
With AI, we also have
to lift our risk, cyber,

212
00:13:32,760 --> 00:13:36,180
you know, governance, all of
the controls that we deploy,

213
00:13:36,180 --> 00:13:38,643
all of the audit functions in the company.

214
00:13:39,780 --> 00:13:43,203
So the speed here is also increasing.

215
00:13:44,100 --> 00:13:47,220
It's not just, you
know, AI is moving fast,

216
00:13:47,220 --> 00:13:50,370
but my processes are still slow.

217
00:13:50,370 --> 00:13:51,600
That's not gonna work.

218
00:13:51,600 --> 00:13:53,823
So how do we lift all boats?

219
00:13:55,410 --> 00:13:58,010
That's the core, you know,
of the problem statement.

220
00:14:00,510 --> 00:14:05,103
Now, to us,

221
00:14:06,840 --> 00:14:09,840
to build that company

222
00:14:09,840 --> 00:14:12,480
that innovates at the speed of AI,

223
00:14:12,480 --> 00:14:14,760
but also at the speed of well-managed,

224
00:14:14,760 --> 00:14:17,343
it comes down to this building blocks,

225
00:14:18,660 --> 00:14:22,590
proprietary data, cloud and serverless,

226
00:14:22,590 --> 00:14:27,123
GPUs or, you know, compute infrastructure,

227
00:14:28,290 --> 00:14:32,220
modern-tech stack, enterprise platforms,

228
00:14:32,220 --> 00:14:33,780
I'll mention about that,

229
00:14:33,780 --> 00:14:36,330
in-house talent, risk, governance,

230
00:14:36,330 --> 00:14:40,173
and then the last one
is model customization.

231
00:14:41,490 --> 00:14:44,280
It's not just using the, you know,

232
00:14:44,280 --> 00:14:49,280
third-party frontier models
that are available at an API.

233
00:14:49,410 --> 00:14:52,020
But the companies that are gonna be

234
00:14:52,020 --> 00:14:53,280
at the forefront of this,

235
00:14:53,280 --> 00:14:58,280
they will leverage their own
data to build LLMs from scratch

236
00:14:58,590 --> 00:15:01,200
and customized for various, you know,

237
00:15:01,200 --> 00:15:02,820
specialized tasks at the company.

238
00:15:02,820 --> 00:15:05,700
And they need to have the
infrastructure and talent

239
00:15:05,700 --> 00:15:08,160
to then deploy them at scale,

240
00:15:08,160 --> 00:15:11,220
at the, you know, same
level of sophistication

241
00:15:11,220 --> 00:15:15,033
as some of the frontier model
companies have been doing.

242
00:15:19,320 --> 00:15:24,320
Now, as I said, you know, we
set out to do all of those

243
00:15:26,070 --> 00:15:28,410
through two things, you
know, customized models,

244
00:15:28,410 --> 00:15:29,280
and now I'm gonna come

245
00:15:29,280 --> 00:15:32,013
to the enterprise AI platform part of it.

246
00:15:33,690 --> 00:15:38,690
Now, we have been
building this AI platform

247
00:15:40,230 --> 00:15:43,230
for last four years, and
we have learned a lot.

248
00:15:43,230 --> 00:15:45,873
We have redesigned a few
things over the years.

249
00:15:48,000 --> 00:15:51,633
But couple of basic principles
have stayed the same.

250
00:15:52,740 --> 00:15:57,740
For example, for the best AWS services,

251
00:15:57,750 --> 00:16:00,360
we take them, we build
on the shoulders of them.

252
00:16:00,360 --> 00:16:05,360
So, for example, EKS, ECS,
SageMaker, Bedrock, OpenSearch,

253
00:16:08,310 --> 00:16:10,950
you know, EFS, S3,

254
00:16:10,950 --> 00:16:15,270
FSX for last year, for high
performance file system

255
00:16:15,270 --> 00:16:16,833
for GPU cluster.

256
00:16:18,510 --> 00:16:20,130
We have taken them,

257
00:16:20,130 --> 00:16:22,110
but we have also built

258
00:16:22,110 --> 00:16:25,710
a lot of other capabilities on our own.

259
00:16:25,710 --> 00:16:27,870
And then we have also incorporated

260
00:16:27,870 --> 00:16:31,560
a lot of open source
projects into our platform.

261
00:16:31,560 --> 00:16:36,560
So this particular combination
of AWS services, open source,

262
00:16:39,090 --> 00:16:42,150
and our custom proprietary capabilities

263
00:16:42,150 --> 00:16:46,110
that actually has helped us
to be at the forefront of AI.

264
00:16:46,110 --> 00:16:50,910
And we are at a stage now
where we can mix third party

265
00:16:50,910 --> 00:16:52,860
and first party capabilities

266
00:16:52,860 --> 00:16:57,860
almost interchangeably
into our stack to be,

267
00:16:58,590 --> 00:17:01,170
you know, very quick and fast

268
00:17:01,170 --> 00:17:04,173
in deploying a lot of capabilities
at the company at scale.

269
00:17:05,430 --> 00:17:09,273
If there is one kind of like, you know,

270
00:17:10,890 --> 00:17:13,320
nugget of information I can give you is

271
00:17:13,320 --> 00:17:17,160
that being able to design a control plane,

272
00:17:17,160 --> 00:17:18,870
being able to design a stack

273
00:17:18,870 --> 00:17:21,280
where you can bring in these three things

274
00:17:22,260 --> 00:17:24,873
easily in a well-managed way,

275
00:17:26,340 --> 00:17:29,910
that is something, you
know, people should take on

276
00:17:29,910 --> 00:17:31,590
because it's not just about depending

277
00:17:31,590 --> 00:17:34,170
on a vendor for everything.

278
00:17:34,170 --> 00:17:37,290
It's not about building
everything on your own.

279
00:17:37,290 --> 00:17:39,930
Then you will miss out on
a lot of the innovation.

280
00:17:39,930 --> 00:17:41,160
And then it's also not,

281
00:17:41,160 --> 00:17:44,673
open source is not enough in many cases.

282
00:17:47,940 --> 00:17:51,993
So in the next few slides, I'm
gonna talk about two things.

283
00:17:53,490 --> 00:17:54,930
Two parts of the platform.

284
00:17:54,930 --> 00:17:59,430
One is the model training or
our training infrastructure,

285
00:17:59,430 --> 00:18:01,953
how we build using,
again, three different,

286
00:18:03,090 --> 00:18:06,360
you know, pieces of capabilities.

287
00:18:06,360 --> 00:18:10,837
And then very importantly,
the inferencing capabilities.

288
00:18:11,730 --> 00:18:14,820
So if you think of like
the modern GenAI stack,

289
00:18:14,820 --> 00:18:15,720
you have to have

290
00:18:15,720 --> 00:18:20,720
a really well-designed
training infrastructure,

291
00:18:21,750 --> 00:18:24,390
and you need to have very well-designed,

292
00:18:24,390 --> 00:18:27,150
high-performance inference infrastructure.

293
00:18:27,150 --> 00:18:30,330
Of course, traditional, you
know, core ML had that too,

294
00:18:30,330 --> 00:18:32,040
model training and model inference.

295
00:18:32,040 --> 00:18:36,723
But in case of LMS and generative
AI, it is really complex,

296
00:18:38,220 --> 00:18:42,270
much more complex than what
we have dealt in the past

297
00:18:42,270 --> 00:18:43,713
for core machine learning.

298
00:18:45,330 --> 00:18:48,210
So I'm gonna talk about our HPC clusters.

299
00:18:48,210 --> 00:18:51,540
It's been about, I would
say, maybe two years.

300
00:18:51,540 --> 00:18:52,743
And we learned a lot.

301
00:18:53,910 --> 00:18:57,180
You know, at the basic level,

302
00:18:57,180 --> 00:19:01,140
it's basically compute,
network, and storage.

303
00:19:01,140 --> 00:19:03,060
And you could say, how difficult is it?

304
00:19:03,060 --> 00:19:06,720
Like you get your compute from AWS.

305
00:19:06,720 --> 00:19:07,890
You get your storage.

306
00:19:07,890 --> 00:19:12,890
You know, you get your network
like EFA, storage like FSX.

307
00:19:13,110 --> 00:19:16,740
But we find that you need to build

308
00:19:16,740 --> 00:19:19,680
a lot of additional
capabilities on top of that

309
00:19:19,680 --> 00:19:21,600
to be really at the tipping,

310
00:19:21,600 --> 00:19:24,300
the kind of like at the bleeding age

311
00:19:24,300 --> 00:19:28,420
of, you know, building very large models

312
00:19:29,670 --> 00:19:34,200
that, you know, where
nodes fail all the time,

313
00:19:34,200 --> 00:19:37,020
you don't want to waste these,
you know, GPU resources,

314
00:19:37,020 --> 00:19:38,463
which are very expensive.

315
00:19:40,500 --> 00:19:43,803
And you also have to invest
in your training pipelines,

316
00:19:44,760 --> 00:19:49,760
you know, so that those, you
know, are also very efficient.

317
00:19:51,960 --> 00:19:54,543
So this is what we did.

318
00:19:55,710 --> 00:19:58,683
We took the infrastructure,

319
00:19:59,550 --> 00:20:04,550
a lot of it from AWS Native,
you know, capabilities.

320
00:20:06,450 --> 00:20:10,953
That's the left hand side of the slide.

321
00:20:11,850 --> 00:20:15,900
Things like high-speed networking,
scheduling and queuing,

322
00:20:15,900 --> 00:20:20,900
high performance file system,
GPU nodes recovery, et cetera.

323
00:20:20,970 --> 00:20:23,970
The software stack, the heart
of the training pipeline,

324
00:20:23,970 --> 00:20:26,940
and these are training
pipelines that need to run,

325
00:20:26,940 --> 00:20:31,500
you know, jobs across many
GPUs, hundreds of GPUs,

326
00:20:31,500 --> 00:20:35,913
or sometimes thousands of
GPUs in a distributed way.

327
00:20:36,780 --> 00:20:41,220
That was mostly open source
and our own custom pipelines,

328
00:20:41,220 --> 00:20:43,683
and we tuned that to the hardware.

329
00:20:45,210 --> 00:20:47,280
And then the third one,

330
00:20:47,280 --> 00:20:51,510
the thing on the right, user experience,

331
00:20:51,510 --> 00:20:54,543
a lot of that, we had to
build all by ourselves.

332
00:20:56,190 --> 00:20:59,850
So this is a perfect
example of you can build,

333
00:20:59,850 --> 00:21:02,700
you know, world-class infrastructure

334
00:21:02,700 --> 00:21:07,700
with combination of AWS open
source and your own stack.

335
00:21:10,710 --> 00:21:12,990
And all of this has been built

336
00:21:12,990 --> 00:21:17,823
by our own in-house AI
researchers and engineering team.

337
00:21:19,500 --> 00:21:23,610
But we didn't do this, you know, in a day.

338
00:21:23,610 --> 00:21:26,910
It was really a learning
experience for us.

339
00:21:26,910 --> 00:21:28,530
We did it in three phases.

340
00:21:28,530 --> 00:21:29,550
In the first phase,

341
00:21:29,550 --> 00:21:31,710
we got a lot of the
infrastructure procured

342
00:21:31,710 --> 00:21:32,917
and provisioned by AWS.

343
00:21:34,110 --> 00:21:37,260
In phase two, we focused
on our training pipeline

344
00:21:37,260 --> 00:21:38,250
and really building

345
00:21:38,250 --> 00:21:41,673
that in-house knowledge of
how could the kernels work.

346
00:21:42,690 --> 00:21:46,923
You know, even even debugging GPU,

347
00:21:47,850 --> 00:21:51,600
like training code that
runs on GPU is very complex.

348
00:21:51,600 --> 00:21:54,693
So we had to build a lot
of that expertise in-house.

349
00:21:55,860 --> 00:21:57,630
And then in phase three,

350
00:21:57,630 --> 00:22:00,180
we started to become more
and more sophisticated.

351
00:22:00,180 --> 00:22:03,570
We focused on minimizing downtime.

352
00:22:03,570 --> 00:22:07,470
How quickly can you
checkpoint restart a job,

353
00:22:07,470 --> 00:22:09,483
you know, that has filled on one GPU.

354
00:22:10,830 --> 00:22:13,320
And so you can think of this as a journey

355
00:22:13,320 --> 00:22:14,763
that you have to go through.

356
00:22:16,200 --> 00:22:18,720
And it took us probably about a,

357
00:22:18,720 --> 00:22:20,970
you know, year or so to get really,

358
00:22:20,970 --> 00:22:24,243
you know, to the point where we are now.

359
00:22:27,450 --> 00:22:30,600
And this is kind of the
training infrastructure

360
00:22:30,600 --> 00:22:32,043
that looks today.

361
00:22:34,650 --> 00:22:37,140
You know, I will tell
you a few things that,

362
00:22:37,140 --> 00:22:41,130
at the top you see the
diversity of the users

363
00:22:41,130 --> 00:22:44,940
we support on this training
infrastructure today.

364
00:22:44,940 --> 00:22:47,970
And this is not just one cluster

365
00:22:47,970 --> 00:22:50,580
that we maintain a few different clusters,

366
00:22:50,580 --> 00:22:53,850
you know, for custom build,
for certain kind of jobs

367
00:22:53,850 --> 00:22:57,420
like RL, you know, versus
like post-training RL,

368
00:22:57,420 --> 00:22:58,770
versus like pre-training

369
00:22:58,770 --> 00:23:03,003
or specialized transformer
for certain applications.

370
00:23:04,740 --> 00:23:08,670
But there are whole range of users

371
00:23:08,670 --> 00:23:11,190
with varying knowledge of infrastructure,

372
00:23:11,190 --> 00:23:13,860
but they don't have to deal
with much of the complexity

373
00:23:13,860 --> 00:23:15,693
of a GPU cluster today.

374
00:23:17,880 --> 00:23:19,530
Thanks to a lot of the, you know,

375
00:23:19,530 --> 00:23:23,850
abstractions we have built
in how you submit a job,

376
00:23:23,850 --> 00:23:26,223
how you debug, et cetera.

377
00:23:27,630 --> 00:23:29,763
It's also built for multi-tenancy.

378
00:23:31,260 --> 00:23:33,840
We can stand up a cluster
for certain application,

379
00:23:33,840 --> 00:23:35,970
certain division within the company

380
00:23:35,970 --> 00:23:40,773
where there may be strict
data, you know, restrictions.

381
00:23:42,720 --> 00:23:46,320
And again, you know,
as I mentioned earlier,

382
00:23:46,320 --> 00:23:48,930
multi-tenancy is kind of in our DNA now

383
00:23:48,930 --> 00:23:51,153
after, you know, Capital One software.

384
00:23:54,990 --> 00:23:59,220
Yeah, and then at the bottom-most layer,

385
00:23:59,220 --> 00:24:02,400
you know, we have the data layer

386
00:24:02,400 --> 00:24:06,330
where we can bring in data from Snowflake.

387
00:24:06,330 --> 00:24:10,293
We have a pretty large
Snowflake footprint.

388
00:24:11,370 --> 00:24:14,400
We have S3. We have other data lake.

389
00:24:14,400 --> 00:24:18,010
And then of course a lot of
the data need to come into FSX

390
00:24:18,960 --> 00:24:20,313
to feed the GPUs.

391
00:24:24,480 --> 00:24:29,220
I'm gonna talk about, next, our
model hosting and inference.

392
00:24:29,220 --> 00:24:31,440
And this is something, you know,

393
00:24:31,440 --> 00:24:33,330
again, a lot of you have realized this,

394
00:24:33,330 --> 00:24:36,270
is that training cost
is kind of like fixed

395
00:24:36,270 --> 00:24:39,243
or, you know, once you
have trained the model,

396
00:24:40,707 --> 00:24:43,980
you know, you have incurred
a certain kind of cost,

397
00:24:43,980 --> 00:24:46,500
but your inference cost is just starting

398
00:24:46,500 --> 00:24:48,180
at that point, right?

399
00:24:48,180 --> 00:24:53,180
And if you are not careful
with your inference platform,

400
00:24:53,820 --> 00:24:56,973
that itself can be a huge expense.

401
00:24:58,140 --> 00:25:01,410
You know, you are not gonna
get the kind of the economics

402
00:25:01,410 --> 00:25:04,680
of these token or per query right.

403
00:25:04,680 --> 00:25:06,330
And as a result,

404
00:25:06,330 --> 00:25:09,603
you know, what worked for
100 users as a prototype,

405
00:25:10,530 --> 00:25:12,060
you will find that that doesn't work

406
00:25:12,060 --> 00:25:14,950
when you have to support
100 million customers

407
00:25:15,900 --> 00:25:17,370
with that GenAI applications.

408
00:25:17,370 --> 00:25:19,747
And when you hear, you know, like,

409
00:25:19,747 --> 00:25:22,950
"Oh, a lot of GenAI applications are dying

410
00:25:22,950 --> 00:25:24,780
at the POC level,"

411
00:25:24,780 --> 00:25:27,270
one of the reasons it dies, you know,

412
00:25:27,270 --> 00:25:30,120
is that people haven't thought through

413
00:25:30,120 --> 00:25:33,420
how to really develop the infrastructure

414
00:25:33,420 --> 00:25:37,440
and how to really create
the cost structure

415
00:25:37,440 --> 00:25:40,800
to scale it to millions
and millions of customers,

416
00:25:40,800 --> 00:25:45,333
you know, millions of tokens
per minute, for example.

417
00:25:46,440 --> 00:25:49,320
So we took this very seriously.

418
00:25:49,320 --> 00:25:51,213
You know, in our first iteration,

419
00:25:52,800 --> 00:25:55,533
we put together a system that worked.

420
00:25:56,520 --> 00:26:00,870
It supported a smaller number
of, you know, users internally

421
00:26:00,870 --> 00:26:02,850
for an internal application.

422
00:26:02,850 --> 00:26:05,010
But for us it was existential

423
00:26:05,010 --> 00:26:08,190
that we have to get really world-class

424
00:26:08,190 --> 00:26:11,253
in our inference platform capability.

425
00:26:12,900 --> 00:26:17,900
So there are three things here.

426
00:26:20,490 --> 00:26:25,263
First is the cost per token
or cost per query at scale,

427
00:26:26,430 --> 00:26:27,693
unit economics,

428
00:26:29,460 --> 00:26:33,180
then the user experience,
latency and throughput.

429
00:26:33,180 --> 00:26:36,780
You know, when we first
deployed the Chat Concierge,

430
00:26:36,780 --> 00:26:40,473
and I'll get to that
in a couple of slides,

431
00:26:41,610 --> 00:26:43,110
Chat Concierge, we had,

432
00:26:43,110 --> 00:26:46,620
because it's multiple
agents, multiple LLM calls,

433
00:26:46,620 --> 00:26:50,250
I remember we were getting
something around 40 seconds

434
00:26:50,250 --> 00:26:52,830
from the point you ping the,

435
00:26:52,830 --> 00:26:54,690
you know, you put your query

436
00:26:54,690 --> 00:26:56,370
and then the system will come back

437
00:26:56,370 --> 00:26:58,113
and, you know, answer,

438
00:26:59,490 --> 00:27:01,950
give you the answer back in 40 seconds.

439
00:27:01,950 --> 00:27:03,873
Now it's about one second.

440
00:27:05,100 --> 00:27:09,390
So that did not happen,

441
00:27:09,390 --> 00:27:12,240
you know, without a lot
of the optimizations

442
00:27:12,240 --> 00:27:15,753
in our inference stack, on
our model customization stack.

443
00:27:16,650 --> 00:27:19,560
This is why, you know, this,

444
00:27:19,560 --> 00:27:21,240
it's not just about AI,

445
00:27:21,240 --> 00:27:23,760
but it's custom AI that
you have to figure out

446
00:27:23,760 --> 00:27:27,000
what works for your own enterprise.

447
00:27:27,000 --> 00:27:28,650
That's where the leverage is.

448
00:27:28,650 --> 00:27:30,850
And that's where I think
things are heading.

449
00:27:32,250 --> 00:27:35,460
And, of course, reliability.

450
00:27:35,460 --> 00:27:38,610
If you're gonna maintain
a large fleet of GPUs

451
00:27:38,610 --> 00:27:43,610
for inference, you know,
uptime dependencies

452
00:27:44,220 --> 00:27:47,070
and how much you can pack within each GPU,

453
00:27:47,070 --> 00:27:50,403
how many inference calls,
those things start to matter.

454
00:27:52,590 --> 00:27:54,870
Now, we faced a dilemma.

455
00:27:54,870 --> 00:27:59,640
And I think it's very common
for a lot of companies

456
00:27:59,640 --> 00:28:02,430
who are experimenting or deploying GenAI,

457
00:28:02,430 --> 00:28:05,550
and I'm sure some of you
are familiar with this,

458
00:28:05,550 --> 00:28:09,420
that, should I go to a
managed, you know, provider,

459
00:28:09,420 --> 00:28:10,620
I get an API,

460
00:28:10,620 --> 00:28:14,520
I get, you know, a Llama,
or, you know, Claude,

461
00:28:14,520 --> 00:28:18,420
or, you know, a lot of
different models behind an API,

462
00:28:18,420 --> 00:28:20,820
and I get started right away?

463
00:28:20,820 --> 00:28:25,320
So I have huge velocity, you know?

464
00:28:25,320 --> 00:28:27,450
And I pay by tokens, right?

465
00:28:27,450 --> 00:28:31,773
And so if my usage pattern
is variable, it makes sense.

466
00:28:32,670 --> 00:28:34,233
You can pay by usage.

467
00:28:35,730 --> 00:28:38,250
And then of course,

468
00:28:38,250 --> 00:28:43,230
you'll be trading off on,
you know, data privacy.

469
00:28:43,230 --> 00:28:44,550
You have to audit them.

470
00:28:44,550 --> 00:28:45,540
You have to make sure

471
00:28:45,540 --> 00:28:49,680
that they are not using
your data for training

472
00:28:49,680 --> 00:28:53,310
or there is, you know,
leakage going on somewhere,

473
00:28:53,310 --> 00:28:56,283
you know, exposing user-level
information outside.

474
00:28:57,660 --> 00:29:02,660
And then even when you
go to a managed provider,

475
00:29:02,670 --> 00:29:04,830
depending on your scale,

476
00:29:04,830 --> 00:29:08,220
as you are going from
like 30 users dock footing

477
00:29:08,220 --> 00:29:12,300
to 1,000 users to 1 million
to 10 million to 100 million,

478
00:29:12,300 --> 00:29:13,897
at some point you'll find that,

479
00:29:13,897 --> 00:29:17,830
"Okay, this economics probably
does not work for me anymore

480
00:29:18,780 --> 00:29:20,700
because I'm paying so much, you know,

481
00:29:20,700 --> 00:29:23,457
for my tokens all the time."

482
00:29:24,480 --> 00:29:28,500
So then the other side of
that is the self-hosted option

483
00:29:28,500 --> 00:29:31,710
where you have to have
now your own DevOps team,

484
00:29:31,710 --> 00:29:33,630
your own AI engineers.

485
00:29:33,630 --> 00:29:36,750
You know, you have to
get GPUs provisioned.

486
00:29:36,750 --> 00:29:38,763
There is a fixed cost to all of that.

487
00:29:39,930 --> 00:29:43,410
And the answer for us was that, you know,

488
00:29:43,410 --> 00:29:46,680
like many other choices in
life, it's actually both.

489
00:29:46,680 --> 00:29:49,810
So we have been able to
design a control plane

490
00:29:50,850 --> 00:29:55,850
where we actually host a
third-party, you know, platform

491
00:29:56,190 --> 00:29:58,743
for certain types of use cases.

492
00:29:59,910 --> 00:30:03,810
And then we also host our own
platform inference platform

493
00:30:03,810 --> 00:30:07,350
where we can really optimize end to end

494
00:30:07,350 --> 00:30:10,860
like our own custom models,
our own inference stack,

495
00:30:10,860 --> 00:30:13,893
our own hardware provision,

496
00:30:14,910 --> 00:30:19,910
to really optimize the
latency, throughput, and cost.

497
00:30:23,640 --> 00:30:27,030
And these are some
examples of optimizations

498
00:30:27,030 --> 00:30:27,863
that we have done

499
00:30:27,863 --> 00:30:32,163
in our in-house self-hosted
inference platform.

500
00:30:33,360 --> 00:30:36,120
I talked about model-level optimizations.

501
00:30:36,120 --> 00:30:37,110
But we have also done

502
00:30:37,110 --> 00:30:41,790
a lot of infrastructure
stack optimization,

503
00:30:41,790 --> 00:30:46,790
which is basically how do
you maximize the GPU usage

504
00:30:46,950 --> 00:30:49,770
by bin packing, you know,

505
00:30:49,770 --> 00:30:53,340
by putting multiple
tenants on the same GPU,

506
00:30:53,340 --> 00:30:57,360
but then you have to worry
about, you know, data separation,

507
00:30:57,360 --> 00:30:59,223
query separation, and all of that.

508
00:31:01,440 --> 00:31:03,300
It's, you know, you have
to build those systems.

509
00:31:03,300 --> 00:31:08,300
But we have been able to get
orders of magnitude lower

510
00:31:09,960 --> 00:31:12,960
from where we started,
you know, about a year ago

511
00:31:12,960 --> 00:31:16,950
on this optimization
work to now where we are,

512
00:31:16,950 --> 00:31:20,340
to the point that we
feel that we will reach

513
00:31:20,340 --> 00:31:24,480
a level that's comparable to
any other provider outside.

514
00:31:24,480 --> 00:31:26,040
And in fact, that's our benchmark.

515
00:31:26,040 --> 00:31:29,700
Like if we can get as
competitive as any other,

516
00:31:29,700 --> 00:31:33,150
like OpenAI, Anthropic, you know, GCP,

517
00:31:33,150 --> 00:31:36,780
or, you know, Bedrock,

518
00:31:36,780 --> 00:31:40,533
we need to be in the same league there.

519
00:31:44,340 --> 00:31:49,143
Now I'm gonna talk a little
bit about Chat Concierge.

520
00:31:50,940 --> 00:31:55,940
So I talked about the LLM
training, LLM inferencing.

521
00:31:56,550 --> 00:31:58,800
You know, as we are building those things,

522
00:31:58,800 --> 00:32:01,950
there are also agents story happening

523
00:32:01,950 --> 00:32:05,850
in the broader GenAI ecosystem.

524
00:32:05,850 --> 00:32:08,580
So in 2024, we started working on,

525
00:32:08,580 --> 00:32:13,580
is our first kind of use
case, it's for consumers.

526
00:32:15,630 --> 00:32:18,480
When you go look for a car,

527
00:32:18,480 --> 00:32:22,072
a lot of dealerships offer you a chatbot

528
00:32:22,072 --> 00:32:23,520
and you can interact with the chatbot.

529
00:32:23,520 --> 00:32:27,270
You can say, "I'm looking for
a, you know, whatever car,

530
00:32:27,270 --> 00:32:30,330
you know, this color,
this model, you know?

531
00:32:30,330 --> 00:32:32,187
Do you have it in your inventory?"

532
00:32:34,170 --> 00:32:39,170
So we have a very, you know,
well-established auto business,

533
00:32:39,780 --> 00:32:41,700
a very forward-thinking auto business.

534
00:32:41,700 --> 00:32:44,460
It's not the traditional auto lending.

535
00:32:44,460 --> 00:32:46,950
We also work with a lot of dealers

536
00:32:46,950 --> 00:32:50,850
to build a lot of the dealer
backend software platforms

537
00:32:50,850 --> 00:32:52,893
that go into lending,

538
00:32:53,790 --> 00:32:56,460
maintaining the dealer websites,

539
00:32:56,460 --> 00:32:58,830
you know, a lot of the
capabilities that dealer need

540
00:32:58,830 --> 00:33:01,140
to interact with customers.

541
00:33:01,140 --> 00:33:04,710
So one of the ideas was
that can we build a chat bot

542
00:33:04,710 --> 00:33:07,080
on top of our AI platform

543
00:33:07,080 --> 00:33:11,640
that will be hosted on our platform,

544
00:33:11,640 --> 00:33:16,200
but there'll be a little chat
window on dealer websites.

545
00:33:16,200 --> 00:33:21,200
And then prospective customers
will be interacting with it.

546
00:33:21,420 --> 00:33:24,600
But then our agentic framework,
on the Capital One side,

547
00:33:24,600 --> 00:33:27,990
will actually do the actual conversation.

548
00:33:27,990 --> 00:33:32,460
So that's the product.
It's called Chat Concierge.

549
00:33:32,460 --> 00:33:34,263
Now, to build a product,

550
00:33:35,250 --> 00:33:39,240
we, you know, did a few
iterations initially.

551
00:33:39,240 --> 00:33:42,640
But then we landed on a
multi-agentic framework called MACAW

552
00:33:43,770 --> 00:33:44,603
to build this,

553
00:33:44,603 --> 00:33:47,493
and I'll show you a little
slide on MACAW next.

554
00:33:48,960 --> 00:33:51,753
But then we also had
to build a lot of the,

555
00:33:53,310 --> 00:33:57,750
you know, a lot of the
kind of vertical stack

556
00:33:57,750 --> 00:34:01,800
to support this agentic application.

557
00:34:01,800 --> 00:34:04,533
For example, we used TensorRT,

558
00:34:07,320 --> 00:34:10,320
you know, for LLM hosting for that.

559
00:34:10,320 --> 00:34:14,710
We used Llama and then, you
know, fine tune Llama models

560
00:34:16,170 --> 00:34:17,253
for the task.

561
00:34:18,240 --> 00:34:20,673
We had to build some custom guardrails.

562
00:34:21,810 --> 00:34:24,750
Chat Concierge today is
on many dealer websites.

563
00:34:24,750 --> 00:34:27,630
And we have very aggressive ramp-up plans

564
00:34:27,630 --> 00:34:31,170
to many hundreds and thousands of dealers.

565
00:34:31,170 --> 00:34:35,133
If you get a chance, you
can play with it on the web.

566
00:34:37,470 --> 00:34:42,450
But this particular agentic framework

567
00:34:42,450 --> 00:34:46,470
turned out to be a very
general-purpose framework

568
00:34:46,470 --> 00:34:50,040
where we start with an understanding agent

569
00:34:50,040 --> 00:34:53,190
that starts interacting with the customer

570
00:34:53,190 --> 00:34:55,440
to understand the intent.

571
00:34:55,440 --> 00:34:59,280
So, for example, if I say
I'm looking for a blue BMW,

572
00:34:59,280 --> 00:35:02,520
to figure out that I'm
looking for a car called BMW

573
00:35:02,520 --> 00:35:03,723
with color blue,

574
00:35:04,620 --> 00:35:06,573
that's the understanding agent.

575
00:35:07,440 --> 00:35:12,060
Then it passes off that
information to a planner agent,

576
00:35:12,060 --> 00:35:14,370
which does some planning.

577
00:35:14,370 --> 00:35:17,370
And then that planner agent hands it off

578
00:35:17,370 --> 00:35:20,370
to an evaluator agent that
has access to a sandbox

579
00:35:20,370 --> 00:35:22,200
with a bunch of APIs,

580
00:35:22,200 --> 00:35:27,200
with some synthetic data to
do a simulation essentially,

581
00:35:27,270 --> 00:35:32,100
to figure out, "Is my answer
or reply gonna be correct?"

582
00:35:32,100 --> 00:35:37,100
And then once, you know, it's satisfied,

583
00:35:37,500 --> 00:35:39,690
it hands it off to the explainer agent,

584
00:35:39,690 --> 00:35:44,690
which then re, kind of like,
frames, you know, the code

585
00:35:46,440 --> 00:35:51,220
and the output of the evaluator
agent in human language

586
00:35:53,160 --> 00:35:55,023
so that the customer, you know,

587
00:35:56,430 --> 00:35:57,263
for the customer,

588
00:35:57,263 --> 00:36:01,413
it's a natural-language-conversation-based
interaction.

589
00:36:03,115 --> 00:36:04,950
And this is multi-turn, multi-pass.

590
00:36:04,950 --> 00:36:08,760
So anytime, you know, for
example, planner agent can go back

591
00:36:08,760 --> 00:36:10,203
to the understanding agent,

592
00:36:12,360 --> 00:36:15,810
basically asking for more
information for the customer

593
00:36:15,810 --> 00:36:17,913
so that it can plan, you know, better.

594
00:36:19,470 --> 00:36:24,110
And of course we supply
it with memory, knowledge,

595
00:36:25,350 --> 00:36:26,183
tools and APIs.

596
00:36:26,183 --> 00:36:28,770
You know, for example,
these tools would be calling

597
00:36:28,770 --> 00:36:33,770
dealer inventory in real time
or scheduling, you know, API

598
00:36:36,570 --> 00:36:39,150
so that the dealer can actually,

599
00:36:39,150 --> 00:36:41,760
the customer can set up a
time to come to the dealership

600
00:36:41,760 --> 00:36:42,993
to test drive a car.

601
00:36:45,060 --> 00:36:47,250
Even to do the tool calling.

602
00:36:47,250 --> 00:36:49,410
you know, we had to do a bunch of work

603
00:36:49,410 --> 00:36:51,850
to make sure the LLM is
calling the right tool

604
00:36:52,860 --> 00:36:56,193
in the evaluator agent part of it.

605
00:36:57,360 --> 00:37:02,360
Now, it turned out that this
particular goal-oriented,

606
00:37:02,700 --> 00:37:07,700
you know, planning and
evaluation and explainer is

607
00:37:08,790 --> 00:37:12,480
actually very general-purpose
agentic framework.

608
00:37:12,480 --> 00:37:15,030
So now we are in the
process of generalizing it

609
00:37:15,030 --> 00:37:18,753
and deploying it for many
use cases at the company.

610
00:37:21,750 --> 00:37:26,750
Now, the first version of
Chat Concierge was more of a,

611
00:37:27,960 --> 00:37:29,880
you know, custom built.

612
00:37:29,880 --> 00:37:31,620
We had a very limited time window.

613
00:37:31,620 --> 00:37:35,763
And we didn't feel like we have
to build a whole ecosystem.

614
00:37:37,170 --> 00:37:38,850
We were not sure what
the outcome would be.

615
00:37:38,850 --> 00:37:43,850
It was more of an, you
know, exploratory work.

616
00:37:44,250 --> 00:37:48,960
Once we validated the idea,
and once we started seeing,

617
00:37:48,960 --> 00:37:52,950
you know, good usage of it
and ramping up, you know,

618
00:37:52,950 --> 00:37:56,760
in dealerships across the country,

619
00:37:56,760 --> 00:38:00,930
then we started to put
together a plan for,

620
00:38:00,930 --> 00:38:02,880
how do we now generalize it?

621
00:38:02,880 --> 00:38:05,250
How do we now build an agentic ecosystem

622
00:38:05,250 --> 00:38:06,900
and agentic platform,

623
00:38:06,900 --> 00:38:11,900
again, sitting on top of our
AI platform core capabilities

624
00:38:13,140 --> 00:38:15,870
so that we can really scale decisions

625
00:38:15,870 --> 00:38:17,170
everywhere in the company.

626
00:38:18,600 --> 00:38:23,343
That took us in the path,
you know, that you see here.

627
00:38:24,720 --> 00:38:27,450
The last two ones, the GenAI core services

628
00:38:27,450 --> 00:38:30,450
and GenAI foundation services
were already kind of in place

629
00:38:30,450 --> 00:38:33,510
because of where AI work, like GenAI work.

630
00:38:33,510 --> 00:38:36,660
But a lot of the agent
orchestrator, agent runtime,

631
00:38:36,660 --> 00:38:41,660
you know, agent development
kit, agent marketplace,

632
00:38:41,760 --> 00:38:44,820
application lifecycle
management, part of it,

633
00:38:44,820 --> 00:38:47,880
those are new things that
we are continuing to build

634
00:38:47,880 --> 00:38:50,733
and we have, you know, work to do here.

635
00:38:52,410 --> 00:38:57,183
But once we have that
infrastructure in place,

636
00:38:58,290 --> 00:39:00,480
anybody in the company
would be able to create

637
00:39:00,480 --> 00:39:02,310
their own agent,

638
00:39:02,310 --> 00:39:04,590
you know, put it on our platform,

639
00:39:04,590 --> 00:39:06,390
and, from that point on,

640
00:39:06,390 --> 00:39:09,660
using our SDK agent development kit.

641
00:39:09,660 --> 00:39:10,710
And then at that point,

642
00:39:10,710 --> 00:39:14,460
the platform will manage that
agent on behalf of the user.

643
00:39:14,460 --> 00:39:16,110
And to us, again, it goes back

644
00:39:16,110 --> 00:39:18,390
to the enterprise platform idea

645
00:39:18,390 --> 00:39:21,510
that we don't want these
things to, you know,

646
00:39:21,510 --> 00:39:24,600
to be bespoke capabilities
across the company.

647
00:39:24,600 --> 00:39:26,790
We want everybody to use the platform

648
00:39:26,790 --> 00:39:31,173
and scale agentic AI for
all kinds of applications.

649
00:39:34,710 --> 00:39:39,710
So with that, I'm gonna
talk about a case study

650
00:39:39,900 --> 00:39:41,673
on agentic coding tools.

651
00:39:42,720 --> 00:39:44,940
I think everywhere everyone
in this room has heard

652
00:39:44,940 --> 00:39:48,120
about like Cursor, Windsurf, Claude Code,

653
00:39:48,120 --> 00:39:52,023
you know, Antigravity,
and so on, so forth.

654
00:39:54,369 --> 00:39:55,830
The example that I'm gonna show you,

655
00:39:55,830 --> 00:39:57,150
it'll talk about Claude Code,

656
00:39:57,150 --> 00:39:59,820
but it's actually a general blueprint.

657
00:39:59,820 --> 00:40:02,441
And at Capital One, we
have been deploying,

658
00:40:02,441 --> 00:40:03,420
you know, a lot of these tools

659
00:40:03,420 --> 00:40:05,583
and we are experimenting early days.

660
00:40:06,690 --> 00:40:08,040
You know, we are learning a lot

661
00:40:08,040 --> 00:40:11,040
how to really embed these tools

662
00:40:11,040 --> 00:40:14,583
into our software development life cycle.

663
00:40:16,410 --> 00:40:18,810
But all the things that
I talked about being,

664
00:40:18,810 --> 00:40:23,100
you know, enterprise
platforms, data maturity,

665
00:40:23,100 --> 00:40:25,530
our focus on, you know, risk management,

666
00:40:25,530 --> 00:40:29,460
automating a lot of our
risk and cyber controls,

667
00:40:29,460 --> 00:40:31,860
all of these, we see the same parallel

668
00:40:31,860 --> 00:40:34,830
as we deploy agentic coding
tools at the company,

669
00:40:34,830 --> 00:40:38,130
that they're actually
supercharging our ability

670
00:40:38,130 --> 00:40:41,850
to deploy these tools to our,

671
00:40:41,850 --> 00:40:45,393
you know, 14,000
developers at the company.

672
00:40:48,030 --> 00:40:52,950
So the challenge is that bringing LLMs

673
00:40:52,950 --> 00:40:56,100
into any regulated enterprise
environment creates

674
00:40:56,100 --> 00:40:57,570
a lot of inherent risks.

675
00:40:57,570 --> 00:41:02,570
And, you know, if you don't
address the inherent risks,

676
00:41:03,240 --> 00:41:05,820
like you will spend a lot
of time creating, you know,

677
00:41:05,820 --> 00:41:10,560
a lot of like meetings,
documents, documenting risk,

678
00:41:10,560 --> 00:41:13,020
or you may have to accept certain risk,

679
00:41:13,020 --> 00:41:14,613
which are not always ideal.

680
00:41:15,990 --> 00:41:17,040
At the same time,

681
00:41:17,040 --> 00:41:18,960
when you look at how fast

682
00:41:18,960 --> 00:41:21,120
these agentic coding tools are moving,

683
00:41:21,120 --> 00:41:23,250
you know, how quickly
they're getting better

684
00:41:23,250 --> 00:41:25,740
at a lot of software engineering tasks,

685
00:41:25,740 --> 00:41:28,113
you don't have a lot of time to actually,

686
00:41:29,340 --> 00:41:33,160
you know, get all of these things in shape

687
00:41:34,650 --> 00:41:37,653
to be able to bring these
tools inside the company.

688
00:41:38,790 --> 00:41:41,680
So what we did is that we created

689
00:41:44,040 --> 00:41:46,500
kind of an architecture pattern

690
00:41:46,500 --> 00:41:50,190
that will be a zero trust AI environment

691
00:41:50,190 --> 00:41:52,833
for one of these tools, Claude Code,

692
00:41:54,720 --> 00:41:59,720
but using some of the native
security of AWS Bedrock.

693
00:41:59,910 --> 00:42:03,600
And again, you know, if
you see a common theme

694
00:42:03,600 --> 00:42:05,760
in this whole talk,

695
00:42:05,760 --> 00:42:10,760
is our ability to commingle first party,

696
00:42:11,520 --> 00:42:12,540
you know, third party,

697
00:42:12,540 --> 00:42:17,540
and AWS together to
build a solution quickly.

698
00:42:17,550 --> 00:42:20,070
And I'm gonna skip this slide,

699
00:42:20,070 --> 00:42:22,113
but I'll come directly to this.

700
00:42:23,460 --> 00:42:25,233
And this is an example.

701
00:42:27,300 --> 00:42:29,550
Claude Code is a CLI.

702
00:42:29,550 --> 00:42:33,633
It's a little tool that you
download on your laptop.

703
00:42:34,890 --> 00:42:36,960
And then it needs to have access

704
00:42:36,960 --> 00:42:40,350
to either Anthropic Claude.ai,

705
00:42:40,350 --> 00:42:42,450
you know, they are hosting platform,

706
00:42:42,450 --> 00:42:47,100
or access to Claude through
Bedrock or some other provider.

707
00:42:47,100 --> 00:42:50,220
For us, the Bedrock choice was ideal

708
00:42:50,220 --> 00:42:53,410
because we are using the
account-level permissions

709
00:42:54,450 --> 00:42:56,520
and the Bedrock gateway

710
00:42:56,520 --> 00:42:59,790
as a, you know, enhanced security for us.

711
00:42:59,790 --> 00:43:02,310
We don't have to worry about, for example,

712
00:43:02,310 --> 00:43:03,810
whether, you know, the data

713
00:43:03,810 --> 00:43:07,290
that we are sending there would
be used for training or not.

714
00:43:07,290 --> 00:43:11,400
There are a lot of reasons
why you want to, you know,

715
00:43:11,400 --> 00:43:13,083
use something like Bedrock.

716
00:43:14,370 --> 00:43:18,840
For us, it's the time to market,

717
00:43:18,840 --> 00:43:21,270
the security implications,

718
00:43:21,270 --> 00:43:25,530
and the scale of bedrock and accessing,

719
00:43:25,530 --> 00:43:28,473
you know, Claude Sonnet
and Opus, et cetera,

720
00:43:30,480 --> 00:43:31,980
through the Bedrock ecosystem.

721
00:43:32,880 --> 00:43:37,383
Now, what we have to build
ourselves is the AI gateway.

722
00:43:38,520 --> 00:43:41,760
That's where we focused on,

723
00:43:41,760 --> 00:43:44,460
because that's where we put our controls.

724
00:43:44,460 --> 00:43:47,040
We put, for example, token rate limiting.

725
00:43:47,040 --> 00:43:49,050
You know, you don't want somebody to go in

726
00:43:49,050 --> 00:43:53,520
and, you know, kind of like
spend $1 million worth of tokens

727
00:43:53,520 --> 00:43:56,410
in a single, you know, offline task

728
00:43:57,390 --> 00:44:00,360
because, you know, Claude Code is not same

729
00:44:00,360 --> 00:44:02,343
as like Cursor or Windsurf,

730
00:44:03,420 --> 00:44:06,330
where, it doesn't need an ID, right?

731
00:44:06,330 --> 00:44:08,827
You can write a bad job
and you can say like,

732
00:44:08,827 --> 00:44:12,330
"Go through these 20 depos
and then do some tasks,

733
00:44:12,330 --> 00:44:15,000
you know, do a code review
or fix a bunch of things

734
00:44:15,000 --> 00:44:16,440
and come back,"

735
00:44:16,440 --> 00:44:20,970
and you accidentally give it
like a huge amount of context,

736
00:44:20,970 --> 00:44:25,970
and then, you know, you
get a large token usage.

737
00:44:26,220 --> 00:44:29,490
So we have implemented a
bunch of things, controls,

738
00:44:29,490 --> 00:44:31,233
on our AI gateway.

739
00:44:32,462 --> 00:44:35,400
And we also built in a
lot of like observability

740
00:44:35,400 --> 00:44:36,300
into the gateway

741
00:44:36,300 --> 00:44:40,350
so that we are doing a
lot of detective control

742
00:44:40,350 --> 00:44:42,003
on the traffic itself.

743
00:44:44,070 --> 00:44:49,023
The other thing we have,
we are still learning.

744
00:44:50,160 --> 00:44:53,820
When you let an agent sit on your desktop,

745
00:44:53,820 --> 00:44:55,680
like developer desktop,

746
00:44:55,680 --> 00:44:57,600
it has access to a lot of your files

747
00:44:57,600 --> 00:44:59,130
and a lot of other information.

748
00:44:59,130 --> 00:45:02,193
So you have to create the
right sandbox around it.

749
00:45:04,020 --> 00:45:07,530
But we don't want users
to disable those settings.

750
00:45:07,530 --> 00:45:10,260
So we have a combination
of like managed settings

751
00:45:10,260 --> 00:45:13,080
that we fix from the enterprise side.

752
00:45:13,080 --> 00:45:15,510
And then it also allows, you know,

753
00:45:15,510 --> 00:45:20,073
the developer to set certain
settings on their own.

754
00:45:21,060 --> 00:45:23,010
Again, a lot of that infrastructure,

755
00:45:23,010 --> 00:45:24,963
we had to build ourselves.

756
00:45:26,340 --> 00:45:31,340
But overall, you know, we were
able to bring this to market

757
00:45:31,560 --> 00:45:36,560
to live very quickly in
matter of weeks actually.

758
00:45:44,280 --> 00:45:47,973
So where does it lead us?

759
00:45:49,770 --> 00:45:52,083
This is kind of like forward-looking.

760
00:45:53,100 --> 00:45:57,090
I think our focus on vertically
integrated end-to-end stack

761
00:45:57,090 --> 00:46:00,870
will position us really well
as new technologies come,

762
00:46:00,870 --> 00:46:01,890
new models come,

763
00:46:01,890 --> 00:46:06,753
new architectures come up
in the research community.

764
00:46:08,460 --> 00:46:11,310
Our conscious decision

765
00:46:11,310 --> 00:46:16,310
of intentionally choosing a
combination of open source, AWS,

766
00:46:17,400 --> 00:46:19,743
and third-party solutions,

767
00:46:21,000 --> 00:46:23,280
that has, you know,
worked out really well.

768
00:46:23,280 --> 00:46:28,280
And we think that it'll also
continue to work well for us.

769
00:46:28,530 --> 00:46:32,640
But we are here today because
we spent a lot of time

770
00:46:32,640 --> 00:46:35,640
on designing our infrastructure in a way,

771
00:46:35,640 --> 00:46:39,000
our control plane in a way
that allows us to be able

772
00:46:39,000 --> 00:46:40,890
to get these things from different places

773
00:46:40,890 --> 00:46:43,113
and to build kind of a hybrid platform.

774
00:46:44,670 --> 00:46:47,880
We have full control
over our infrastructure.

775
00:46:47,880 --> 00:46:51,600
We don't depend on any particular,

776
00:46:51,600 --> 00:46:53,943
you know, vendor, et cetera.

777
00:46:54,810 --> 00:46:58,890
We can tune our stack
very well at every level.

778
00:46:58,890 --> 00:47:02,580
And this idea of, you
know, having custom models,

779
00:47:02,580 --> 00:47:06,360
to custom hardware, to custom pipeline,

780
00:47:06,360 --> 00:47:08,580
to custom inferencing stack,

781
00:47:08,580 --> 00:47:10,923
or even if you take it
to the agentic layer,

782
00:47:12,210 --> 00:47:14,970
that is, you know, where I think

783
00:47:14,970 --> 00:47:17,283
a lot of the leverage will come from.

784
00:47:19,260 --> 00:47:23,040
And then the way we are
approaching our risk

785
00:47:23,040 --> 00:47:25,380
and cyber controls by automating them,

786
00:47:25,380 --> 00:47:27,960
by creating, you know,
specialized environments

787
00:47:27,960 --> 00:47:32,823
where these agents can play, so to speak.

788
00:47:34,050 --> 00:47:35,920
And then we are extending these

789
00:47:37,149 --> 00:47:41,610
to all of the other capabilities,
you know, that need AI,

790
00:47:41,610 --> 00:47:42,600
some kind of agent.

791
00:47:42,600 --> 00:47:44,763
For example, in our data platforms,

792
00:47:45,750 --> 00:47:49,083
when our data platforms build data agents,

793
00:47:51,316 --> 00:47:52,770
they're not gonna build a custom,

794
00:47:52,770 --> 00:47:56,040
you know, data agentic platform.

795
00:47:56,040 --> 00:47:57,450
They will start to leverage

796
00:47:57,450 --> 00:48:00,450
our own agent platform, for example.

797
00:48:00,450 --> 00:48:05,040
So we are extending the same
control, same infrastructure.

798
00:48:05,040 --> 00:48:07,620
Everywhere, there is,
you know, a need for AI

799
00:48:07,620 --> 00:48:10,803
or infusing AI into that
particular platform.

800
00:48:12,900 --> 00:48:17,900
Now, key to this is our
ability to attract talent

801
00:48:19,080 --> 00:48:20,283
and develop them.

802
00:48:21,480 --> 00:48:23,613
I think if there is a single,

803
00:48:25,980 --> 00:48:30,900
you know, a differentiator
among companies going forward,

804
00:48:30,900 --> 00:48:32,733
it's really gonna be the talent.

805
00:48:34,920 --> 00:48:37,200
We have been really lucky,

806
00:48:37,200 --> 00:48:40,110
fortunate enough to have
the kind of the ecosystem

807
00:48:40,110 --> 00:48:41,943
and the environment and the culture,

808
00:48:43,650 --> 00:48:47,220
to be able, to be in a position
where we can, you know,

809
00:48:47,220 --> 00:48:49,500
attract a lot of great talent.

810
00:48:49,500 --> 00:48:54,500
And one of the, kind of like
the validations of that,

811
00:48:57,270 --> 00:48:59,580
I mentioned in Evident AI,

812
00:48:59,580 --> 00:49:03,033
three years in a row, we have
been number one in AI Talent,

813
00:49:06,390 --> 00:49:08,223
but we are not stopping there.

814
00:49:10,410 --> 00:49:13,320
In the last couple of years,

815
00:49:13,320 --> 00:49:15,990
we have really started to look across

816
00:49:15,990 --> 00:49:17,530
and forming partnerships

817
00:49:18,570 --> 00:49:21,960
with some of the most
forward-thinking leading universities

818
00:49:21,960 --> 00:49:23,103
in the US.

819
00:49:24,526 --> 00:49:28,677
We have established research
centers at USC, Columbia,

820
00:49:30,030 --> 00:49:32,160
University of Illinois,
University of Maryland,

821
00:49:32,160 --> 00:49:36,090
and more recently, maybe around summer,

822
00:49:36,090 --> 00:49:41,030
we were the only bank and one
of the two companies in the US

823
00:49:42,510 --> 00:49:45,960
that became partner to NSF AI Institutes.

824
00:49:45,960 --> 00:49:50,960
NSF is awarding, I think,
five academic groups,

825
00:49:53,730 --> 00:49:57,870
five national, you know, science
foundation AI institutes.

826
00:49:57,870 --> 00:49:59,820
We partnered with one of them.

827
00:49:59,820 --> 00:50:02,370
And we are the only bank there.

828
00:50:02,370 --> 00:50:06,480
And I personally see some
of the benefits we have had.

829
00:50:06,480 --> 00:50:09,780
You know, we have brought
in a lot of faculty,

830
00:50:09,780 --> 00:50:12,180
a lot of summer interns.

831
00:50:12,180 --> 00:50:14,880
We just started a AI
engineering internship program

832
00:50:14,880 --> 00:50:17,370
starting, you know, from next summer.

833
00:50:17,370 --> 00:50:19,470
These are our pipelines.

834
00:50:19,470 --> 00:50:20,730
And they come in.

835
00:50:20,730 --> 00:50:24,330
They get to work on
world-class infrastructure.

836
00:50:24,330 --> 00:50:27,603
They get to work with world-class
scientists and engineers.

837
00:50:28,980 --> 00:50:31,890
And then, you know, they
are able to actually deploy

838
00:50:31,890 --> 00:50:34,170
something that has tangible value

839
00:50:34,170 --> 00:50:36,900
that actually goes in
front of our customers.

840
00:50:36,900 --> 00:50:38,850
So it's a great flywheel

841
00:50:38,850 --> 00:50:40,893
that we are creating in terms of talent.

842
00:50:42,330 --> 00:50:46,530
So I will end here saying it's
an incredibly exciting time

843
00:50:46,530 --> 00:50:50,313
for us in the AI community and
particularly at Capital One.

844
00:50:51,870 --> 00:50:55,050
You know, as I said, I have worked at,

845
00:50:55,050 --> 00:50:56,760
you know, tech companies.

846
00:50:56,760 --> 00:51:01,630
But I just find Capital One
to be such a amazing place

847
00:51:03,150 --> 00:51:06,960
to allow us to think big
and then to be able to build

848
00:51:06,960 --> 00:51:09,660
this kind of infrastructure at scale.

849
00:51:09,660 --> 00:51:10,963
Thank you.

850
00:51:10,963 --> 00:51:12,878
(audience applauding)

