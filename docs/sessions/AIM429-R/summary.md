# AWS re:Invent 2025 - Amazon Nova 2 Light 编码代理实战工作坊总结

## 会议概述

本次工作坊由AWS解决方案架构师Pat和Amazon AGI团队的Jean主讲，重点介绍了如何使用刚刚发布的Amazon Nova 2 Light模型构建全自动编码代理（coding agent）。这是一场高度互动的代码实战（code talk）会议，讲师们通过实际代码演示，展示了如何利用Nova 2 Light的推理能力、大上下文窗口（100万token）和工具调用功能来解决真实的GitHub代码库问题。

会议以LangChain AWS代码库的实际GitHub issue为例，演示了从简单提示到复杂多代理架构的完整演进过程。讲师们强调了在构建生产级编码代理时需要考虑的关键因素：上下文管理、工具选择、提示工程最佳实践、成本优化以及多代理架构设计。整个会议采用边讲边做的方式，鼓励观众随时提问，营造了非常活跃的学习氛围。

Nova 2 Light作为AWS最新发布的推理模型，专门针对代理工作流进行了优化，支持64,000 token输出、内置系统工具支持，并且在代码生成任务中表现出色。工作坊通过实际案例展示了该模型在处理复杂编码任务时的能力和局限性。

## 详细时间线与关键要点

00:00:00 - 开场介绍
- Pat和Jean介绍自己的背景和团队
- 询问现场有多少人已经试用了不到7小时前发布的Nova 2 Light
- 说明这是一场代码实战工作坊（code talk），会有大量实时编码演示

00:01:30 - 会议目标设定
- 强调会议将涵盖大量内容，可能无法完成所有计划
- 核心目标：展示如何提示Nova 2 Light、构建规模化编码代理的主要考虑因素
- 鼓励观众随时提问，保持互动

00:02:15 - 观众背景调查
- 询问有多少人做过code talk
- 了解观众对Strands框架的熟悉程度
- 调查对MCP（Model Context Protocol）的了解情况
- 询问是否有人使用MCP服务器构建过代理

00:03:00 - 问题场景介绍
- 使用LangChain AWS代码库的真实GitHub issue作为演示案例
- 问题：新模型发布后需要集成支持新功能
- 强调这是在真实代码库中工作，而非简单的一次性应用演示

00:04:00 - Strands框架介绍
- Strands是AWS版本的类似LangChain的框架
- 与AWS服务和工具有很好的集成
- 可以用几行代码快速启动代理

00:05:00 - 第一次演示：基础提示
- 使用极其简单的提示："查看这个issue并评论你的实现计划"
- 仅提供GitHub MCP客户端工具
- 没有系统提示，没有上下文

00:06:30 - MCP（Model Context Protocol）详解
- MCP提供标准化的方式与任意服务器交互
- GitHub的MCP服务器提供约40个工具
- 无需自己实现每个GitHub API，可直接使用标准化接口
- 示例工具：获取issue、修改文件、创建分支、添加评论等

00:08:00 - 工具数量的挑战
- 40个工具意味着模型需要从大量选项中选择
- 这会占用大量上下文窗口（超过8,000 tokens仅用于工具配置）
- 强调需要谨慎选择工具，通常建议不超过20个工具
- 超过20个工具时建议考虑多代理架构

00:09:30 - 第一次运行结果分析
- 模型成功读取issue并添加了评论
- 创建了合理的实现计划
- 但计划过于笼统，没有实际查看代码文件
- 没有探索代码库结构

00:11:00 - 改进的系统提示
- 介绍Nova 2 Light的提示工程最佳实践
- 使用特定的结构化部分：
  - **核心要求（Core Mandates）**：关键业务规则
  - **工作流程（Workflow）**：期望模型遵循的步骤
  - **工具使用（Tool Usage）**：如何调用工具的业务规则
  - **错误处理（Error Handling）**：如何应对失败情况
  - **输出格式（Output Formatting）**：放在提示末尾效果最好

00:13:00 - 工具使用指导
- 在提示中明确提及工具名称可以引导模型注意力
- 鼓励并行工具调用以提高效率
- 并行工具调用：模型在一次响应中调用多个工具

00:14:30 - 第二次运行：使用改进的系统提示
- 模型开始实际查看文件内容
- 进行了8次工具调用
- 生成了更具体的实现计划，包含实际代码更改建议
- 但速度较慢，因为需要探索代码库

00:16:00 - 上下文管理挑战
- 提出问题：为什么不直接将整个代码库放入100万token上下文？
- 演示将整个代码库（约50万tokens）放入上下文的效果

00:17:30 - 长上下文的局限性
- 所有模型在上下文增加时性能都会下降
- 长上下文适合"大海捞针"式的精确搜索
- 但对于代码理解，需要的是语义连接和关系理解
- 将所有内容放入上下文反而降低了代理性能

00:18:30 - 长上下文运行结果
- 工具调用次数减少
- 但模型未能按要求添加评论（违反了指令）
- 代码质量仍然不错，但代理工作流性能下降
- 成本显著增加

00:20:00 - 优化方案：提供文件路径结构
- 不提供完整代码内容，而是提供代码库的文件路径列表
- 利用人类设计的直观文件结构
- 文件路径本身就包含语义信息（如"bedrock_converse.py"）
- 这给模型提供了探索的起点

00:22:00 - 文件路径方案运行结果
- 速度明显加快
- 工具调用次数合理
- 输出质量保持高水平
- 上下文使用更加高效

00:23:00 - 进一步优化建议
- 可以对文件路径进行排序
- 可以在agent.md文件中提供额外的代码库导航信息
- 许多代码库开始为代理提供专门的文档

00:24:00 - 成本考虑
- 代理是"token消耗大户"
- 代码库会极快地消耗token
- 工具选择和上下文管理直接影响成本
- 需要在性能和成本之间找到平衡

00:25:30 - 从单代理到多代理架构
- 单代理架构的问题：规划阶段的所有上下文都会被保留
- 实际上只需要规划的输出结果
- 引入多代理架构：规划代理 + 执行代理

00:27:00 - 多代理架构设计
- 使用Strands的图（graph）方法
- 规划代理：查看文件，确定需要做什么
- 执行代理：接收实现计划，实际编写代码
- 代理之间传递状态，但不共享完整上下文

00:28:30 - 代理编排模式介绍
- **管理者-子代理模式**：管理者代理决定调用哪个子代理以及何时完成
- **图模式**：代理从左到右依次执行，不回退
- 类似Cursor等工具的工作方式：需求 → 设计 → 实现

00:30:00 - GitHub MCP的性能问题
- 每次获取文件内容都要调用完整的API
- 创建/更新文件时也要输出完整文件内容
- 这个过程非常慢
- 暗示后续会展示更实用的方法

00:31:00 - Strands图构建器演示
- 创建图构建器
- 添加节点（代理）
- 定义节点之间的连接
- 代码实现非常简洁

00:32:00 - 工具作为安全边界
- 不给代理某个工具，它就无法执行相关操作
- 这是一个隐式的安全边界
- 在迭代开发时可以快速发现问题

00:33:00 - 代码助手使用调查
- 询问有多少人在IDE中使用代码助手
- 提到Cursor、Continue等工具
- 这些工具都非常精确地管理上下文
- 它们会提取特定行号的代码片段而非整个文件

00:34:00 - 上下文管理最佳实践
- 使用代码库结构而非完整内容
- 利用文件路径的语义信息
- 让模型有探索的起点
- 避免一开始就消耗大量上下文

00:35:00 - 实际编码代理的考虑因素总结
- 提示工程：结构化的系统提示
- 工具选择：精心挑选相关工具
- 上下文管理：战略性地提供信息
- 架构设计：单代理 vs 多代理
- 成本优化：token使用效率
- 安全性：工具权限控制

00:36:00 - 互动问答环节
- 讨论MCP服务器的部署（自托管 vs 托管API）
- GitHub token权限的安全考虑
- 分享了一些实验中的"惨痛教训"
- 强调保护主分支的重要性

00:38:00 - 会议总结与展望
- Nova 2 Light专为代理工作流优化
- 构建生产级编码代理需要多方面考虑
- 鼓励观众尝试并从错误中学习
- 强调安全和成本管理的重要性