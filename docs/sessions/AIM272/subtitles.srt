1
00:00:02,939 --> 00:00:05,150
All right. Welcome everyone, and uh

2
00:00:05,150 --> 00:00:05,750
good afternoon.

3
00:00:06,459 --> 00:00:08,148
Uh, my name is Ankur,

4
00:00:08,460 --> 00:00:11,019
and uh, I'm joined by my colleague

5
00:00:11,019 --> 00:00:12,538
here today, Mark Andrews,

6
00:00:12,858 --> 00:00:14,489
and we're gonna be talking to you

7
00:00:14,858 --> 00:00:16,958
about AI model development

8
00:00:16,958 --> 00:00:17,859
with SageMaker.

9
00:00:20,219 --> 00:00:22,219
So, let's dive in with the

10
00:00:22,219 --> 00:00:23,039
key challenge.

11
00:00:23,579 --> 00:00:25,809
These days, when I talk to customers,

12
00:00:26,219 --> 00:00:27,039
they often tell me

13
00:00:27,579 --> 00:00:29,440
that how easy it has become

14
00:00:30,019 --> 00:00:31,478
for them to access

15
00:00:31,818 --> 00:00:33,740
generative AI models and start using them.

16
00:00:34,490 --> 00:00:37,000
But they also tell me that because of the same fact,

17
00:00:37,408 --> 00:00:38,439
now they feel that

18
00:00:38,929 --> 00:00:41,590
everybody has access to access to the same models.

19
00:00:41,969 --> 00:00:44,130
In fact, their competitors have access

20
00:00:44,130 --> 00:00:45,789
to the same models as I do.

21
00:00:46,250 --> 00:00:48,668
So they ask me, well, how do we build differentiation?

22
00:00:50,149 --> 00:00:52,228
Now we think that differentiation is

23
00:00:52,228 --> 00:00:53,798
a key component of innovation,

24
00:00:54,189 --> 00:00:56,649
as is creating value for customers.

25
00:00:57,719 --> 00:00:59,889
But how do you create differentiation?

26
00:01:01,168 --> 00:01:03,168
The models that you work with are

27
00:01:03,168 --> 00:01:04,400
genetic, you know,

28
00:01:04,730 --> 00:01:06,430
so we don't think that

29
00:01:06,689 --> 00:01:09,010
creating differentiation will happen

30
00:01:09,010 --> 00:01:11,329
through building better AI with the same commodity

31
00:01:11,329 --> 00:01:12,040
foundation.

32
00:01:12,528 --> 00:01:13,290
We think what

33
00:01:13,769 --> 00:01:16,010
to create differentiation, what you need

34
00:01:16,010 --> 00:01:18,409
is our models who deeply

35
00:01:18,409 --> 00:01:19,870
understand you and your business.

36
00:01:21,138 --> 00:01:23,439
But how do you get that competitive advantage?

37
00:01:23,859 --> 00:01:26,000
Well, first, let's acknowledge

38
00:01:26,299 --> 00:01:28,299
that the generative AI models that are out

39
00:01:28,299 --> 00:01:28,900
there today,

40
00:01:29,299 --> 00:01:30,088
they're amazing.

41
00:01:30,599 --> 00:01:31,319
You know, they can,

42
00:01:31,778 --> 00:01:33,079
uh, they can create,

43
00:01:33,588 --> 00:01:34,138
write,

44
00:01:34,418 --> 00:01:36,730
summarize, reason, you name it.

45
00:01:37,138 --> 00:01:39,049
They're genuinely intelligent and they,

46
00:01:39,379 --> 00:01:41,500
you know, hold a vast amount of information.

47
00:01:42,370 --> 00:01:44,418
But They don't know

48
00:01:44,418 --> 00:01:46,189
about your business, your domain.

49
00:01:47,250 --> 00:01:49,448
They don't know about your data. They don't

50
00:01:49,448 --> 00:01:51,469
understand the hidden patterns in

51
00:01:51,469 --> 00:01:52,750
your transactional history

52
00:01:53,129 --> 00:01:55,250
or your support tickets or

53
00:01:55,250 --> 00:01:57,049
the domain expertise that you have

54
00:01:58,409 --> 00:01:59,308
over the years.

55
00:01:59,888 --> 00:02:01,888
They also don't know about your

56
00:02:01,888 --> 00:02:03,549
constraints in your business.

57
00:02:04,609 --> 00:02:06,808
Whether what's considered safe and compliant

58
00:02:06,808 --> 00:02:08,868
in your business and what's considered

59
00:02:09,250 --> 00:02:09,909
high quality.

60
00:02:11,399 --> 00:02:12,538
So ultimately,

61
00:02:13,118 --> 00:02:15,270
building models that can deeply understand

62
00:02:15,270 --> 00:02:17,278
you is really about

63
00:02:17,278 --> 00:02:19,360
boils down to how you make the model

64
00:02:19,360 --> 00:02:21,080
learn what you want to learn.

65
00:02:22,689 --> 00:02:25,020
So it's important to understand how a model learns.

66
00:02:25,939 --> 00:02:27,800
Well, uh, it turns out,

67
00:02:28,300 --> 00:02:30,659
models learn in a step by step

68
00:02:30,659 --> 00:02:32,740
process. In the first stages

69
00:02:32,740 --> 00:02:34,788
of modern learning, they learn the

70
00:02:34,979 --> 00:02:36,379
generalized world knowledge.

71
00:02:37,199 --> 00:02:39,419
Then they start learning more specialized

72
00:02:39,550 --> 00:02:40,270
knowledge,

73
00:02:40,558 --> 00:02:42,258
and then finally, they get better

74
00:02:42,558 --> 00:02:43,960
at executing tasks.

75
00:02:44,849 --> 00:02:46,949
This is actually not much different than

76
00:02:46,949 --> 00:02:47,808
how models learn.

77
00:02:48,618 --> 00:02:50,419
So let's actually take a look at

78
00:02:50,899 --> 00:02:53,080
uh the human model, uh, the human

79
00:02:53,860 --> 00:02:56,139
learning journey and how it compares

80
00:02:56,139 --> 00:02:57,899
to uh how models learn.

81
00:02:59,439 --> 00:03:01,558
So let's start with pre-training, which is the first

82
00:03:01,558 --> 00:03:02,679
stage of model learning.

83
00:03:03,550 --> 00:03:05,490
At this stage, the model

84
00:03:06,028 --> 00:03:08,028
basically mimics a child who

85
00:03:08,028 --> 00:03:09,659
is learning language by immersion.

86
00:03:10,368 --> 00:03:12,710
It consumes a vast amount of text,

87
00:03:12,969 --> 00:03:15,429
images, and other data,

88
00:03:15,808 --> 00:03:17,808
and it learns how to predict the next token.

89
00:03:21,360 --> 00:03:23,360
At this stage, the model is not

90
00:03:23,360 --> 00:03:25,699
learning any specific tasks,

91
00:03:26,000 --> 00:03:28,038
but it is the foundation that

92
00:03:28,038 --> 00:03:30,159
is created at this stage that it draws

93
00:03:30,159 --> 00:03:32,038
upon later during inferences,

94
00:03:32,399 --> 00:03:34,538
much like how humans recall

95
00:03:34,879 --> 00:03:37,038
early language skills in daily

96
00:03:37,038 --> 00:03:39,099
conversations. Now, after

97
00:03:39,278 --> 00:03:40,419
having mastered

98
00:03:40,800 --> 00:03:42,469
basic language skills,

99
00:03:42,758 --> 00:03:44,379
now the model is ready to learn

100
00:03:44,758 --> 00:03:46,118
how to follow instructions.

101
00:03:46,520 --> 00:03:47,979
So it is exposed to

102
00:03:48,240 --> 00:03:50,169
uh pairs of input and output.

103
00:03:50,909 --> 00:03:52,569
Questions with good answers,

104
00:03:53,110 --> 00:03:55,189
and through that, it learns how to

105
00:03:55,189 --> 00:03:56,028
stay on topic,

106
00:03:56,479 --> 00:03:58,629
provide structured explanations and

107
00:03:58,629 --> 00:03:59,689
be generally helpful.

108
00:04:01,020 --> 00:04:03,258
This is much like middle school students

109
00:04:03,258 --> 00:04:03,838
learning

110
00:04:04,139 --> 00:04:06,118
how to write essays and follow directions.

111
00:04:07,588 --> 00:04:08,689
Now the next stage

112
00:04:08,990 --> 00:04:10,479
is preference optimization.

113
00:04:10,849 --> 00:04:12,649
At this stage, the model

114
00:04:13,069 --> 00:04:15,069
learns how to not just be correct, but

115
00:04:15,069 --> 00:04:15,710
how to be good.

116
00:04:16,689 --> 00:04:18,689
So it's exposed to ranked and

117
00:04:18,689 --> 00:04:20,350
rated examples

118
00:04:20,850 --> 00:04:23,209
of um of responses

119
00:04:23,209 --> 00:04:24,709
that it learns from and it

120
00:04:25,250 --> 00:04:25,838
understands

121
00:04:26,209 --> 00:04:27,369
what humans think

122
00:04:27,649 --> 00:04:28,569
is concise,

123
00:04:28,850 --> 00:04:29,428
clear,

124
00:04:29,809 --> 00:04:31,350
and aligned with social norms.

125
00:04:32,480 --> 00:04:33,619
This is similar to how

126
00:04:34,319 --> 00:04:36,399
high school students refine their

127
00:04:36,399 --> 00:04:38,600
communication and tone through

128
00:04:38,600 --> 00:04:40,259
feedback from teachers.

129
00:04:41,298 --> 00:04:43,579
And in our model's case, the model

130
00:04:43,579 --> 00:04:45,738
is learning, judgment, and empathy.

131
00:04:47,358 --> 00:04:48,379
Now college

132
00:04:49,040 --> 00:04:50,259
represents a shift

133
00:04:50,639 --> 00:04:53,040
from memorization to reasoning.

134
00:04:54,209 --> 00:04:55,399
So this is where

135
00:04:56,399 --> 00:04:58,559
the model practices multi-step thought,

136
00:04:58,778 --> 00:04:59,939
problem decomposition.

137
00:05:01,048 --> 00:05:01,600
And

138
00:05:01,889 --> 00:05:03,730
thinking through and providing structured

139
00:05:04,730 --> 00:05:05,290
answers.

140
00:05:07,500 --> 00:05:09,579
This is commonly done through techniques

141
00:05:09,579 --> 00:05:10,980
such as reinforcement learning.

142
00:05:11,850 --> 00:05:13,939
And this is quite similar to how

143
00:05:13,939 --> 00:05:16,420
college students are able to synthesize

144
00:05:16,420 --> 00:05:18,439
ideas across multiple disciplines.

145
00:05:19,759 --> 00:05:21,259
Now after graduation.

146
00:05:22,119 --> 00:05:23,199
In the workforce,

147
00:05:23,559 --> 00:05:25,678
the model has to switch from

148
00:05:25,678 --> 00:05:26,519
learning to doing.

149
00:05:27,519 --> 00:05:29,639
At this point, the model has to apply

150
00:05:29,639 --> 00:05:30,910
whatever it has learned

151
00:05:31,290 --> 00:05:32,988
to real world tasks.

152
00:05:33,980 --> 00:05:36,338
Now, much like many of us

153
00:05:36,338 --> 00:05:38,399
professionals who like to continue taking,

154
00:05:38,858 --> 00:05:39,540
uh,

155
00:05:40,619 --> 00:05:41,519
you know, educational courses

156
00:05:41,819 --> 00:05:42,959
while we are working,

157
00:05:43,338 --> 00:05:45,019
models can still continue to learn.

158
00:05:45,899 --> 00:05:47,230
Through techniques such as LA

159
00:05:47,660 --> 00:05:49,720
and parameter efficient fine tuning,

160
00:05:50,059 --> 00:05:52,259
models can continue to learn even when they're

161
00:05:52,259 --> 00:05:54,220
out there deployed in production.

162
00:05:54,939 --> 00:05:57,100
Without having to retrain the base model.

163
00:06:02,149 --> 00:06:04,309
OK. So let's talk about uh

164
00:06:04,309 --> 00:06:04,970
pre-training

165
00:06:05,269 --> 00:06:07,069
in more detail, which is the first stage.

166
00:06:07,759 --> 00:06:09,600
Of the model's learning journey.

167
00:06:09,959 --> 00:06:12,040
So during pre-training, the model

168
00:06:12,040 --> 00:06:14,298
is trained on a massive amount

169
00:06:14,298 --> 00:06:16,459
of tokens from diverse

170
00:06:16,879 --> 00:06:17,858
data sources,

171
00:06:18,160 --> 00:06:20,178
and through this it learns

172
00:06:20,319 --> 00:06:21,420
patterns in the data.

173
00:06:21,798 --> 00:06:23,579
It learns how to predict the next token,

174
00:06:24,079 --> 00:06:25,980
uh, based on a sequence of tokens,

175
00:06:26,319 --> 00:06:28,439
and it also discovers grammar and

176
00:06:28,439 --> 00:06:30,559
syntax and facts and it

177
00:06:30,559 --> 00:06:32,040
builds internal representation.

178
00:06:34,259 --> 00:06:34,858
Also,

179
00:06:35,178 --> 00:06:37,278
while there are different scaling laws today,

180
00:06:37,670 --> 00:06:38,559
generally speaking,

181
00:06:38,899 --> 00:06:41,178
with larger models with more training

182
00:06:41,178 --> 00:06:42,920
steps, more compute and more data.

183
00:06:44,028 --> 00:06:45,048
Uh, models

184
00:06:45,660 --> 00:06:48,170
achieve stronger generalization and capabilities.

185
00:06:48,629 --> 00:06:51,009
Now, note that at the pre-training stage,

186
00:06:51,509 --> 00:06:53,939
the model is not learning how to execute

187
00:06:53,939 --> 00:06:56,069
a particular task or how to become an

188
00:06:56,069 --> 00:06:57,829
expert in any one topic.

189
00:06:59,730 --> 00:07:01,079
Well, this sounds simple, right?

190
00:07:01,369 --> 00:07:02,509
But in reality,

191
00:07:03,088 --> 00:07:04,709
the pre-training um

192
00:07:05,048 --> 00:07:07,389
stage uh is quite complicated

193
00:07:07,528 --> 00:07:08,410
to execute through.

194
00:07:09,269 --> 00:07:11,649
The multiple challenges that you face

195
00:07:11,869 --> 00:07:13,350
when you're pre-training a model.

196
00:07:14,100 --> 00:07:15,548
The first one is efficient scaling.

197
00:07:16,309 --> 00:07:18,488
Well, these models are large

198
00:07:18,488 --> 00:07:20,629
and there's a lot of data being used to train

199
00:07:20,629 --> 00:07:23,028
them, so they often don't fit onto

200
00:07:23,028 --> 00:07:25,319
a single AI accelerator.

201
00:07:25,709 --> 00:07:26,769
So you have to

202
00:07:27,040 --> 00:07:29,170
uh pre-train over a large

203
00:07:29,170 --> 00:07:31,670
cluster of AI accelerators such as GPUs

204
00:07:31,670 --> 00:07:34,108
or AWS training instances.

205
00:07:35,559 --> 00:07:36,509
And

206
00:07:36,769 --> 00:07:38,970
so you need solutions to be able to efficiently

207
00:07:38,970 --> 00:07:40,970
scale across a large number of

208
00:07:40,970 --> 00:07:41,689
accelerators.

209
00:07:42,660 --> 00:07:45,040
The next challenge you run into is resiliency.

210
00:07:45,379 --> 00:07:47,660
Well, unlike uh distributed

211
00:07:47,660 --> 00:07:49,899
data computing workloads where

212
00:07:49,899 --> 00:07:52,100
every work is kind of doing its own thing,

213
00:07:52,379 --> 00:07:53,540
in distributed training.

214
00:07:54,379 --> 00:07:56,459
Every process, every training

215
00:07:56,459 --> 00:07:58,500
process across all your GPUs in a cluster,

216
00:07:58,939 --> 00:08:01,100
uh, is collaboratively training one model.

217
00:08:02,178 --> 00:08:04,238
So whenever there is a failure

218
00:08:04,238 --> 00:08:05,059
in the system,

219
00:08:05,338 --> 00:08:07,379
either even a single GPU fails, the

220
00:08:07,379 --> 00:08:08,670
entire training process stops.

221
00:08:09,019 --> 00:08:11,559
So resiliency of your infrastructure

222
00:08:11,559 --> 00:08:12,540
is extremely important.

223
00:08:14,379 --> 00:08:16,540
Next comes utilization. Well, let's

224
00:08:16,540 --> 00:08:19,500
face it, these AI accelerator-based

225
00:08:19,500 --> 00:08:21,079
clusters are expensive.

226
00:08:21,459 --> 00:08:23,250
So if they're not fully utilized,

227
00:08:23,660 --> 00:08:26,238
it can lead to wastage and cost overruns.

228
00:08:26,588 --> 00:08:28,619
So maintaining high utilization is

229
00:08:28,619 --> 00:08:29,259
extremely important.

230
00:08:30,619 --> 00:08:32,619
You also want to make sure that the engineers and data

231
00:08:32,619 --> 00:08:34,899
scientists who are working on your pre-training

232
00:08:34,899 --> 00:08:37,000
projects, they're able to focus

233
00:08:37,298 --> 00:08:39,460
on value-added work rather

234
00:08:39,460 --> 00:08:41,279
than dealing with infrastructure.

235
00:08:41,609 --> 00:08:43,479
So having the right tools to ensure

236
00:08:43,820 --> 00:08:46,139
that they are able to be highly productive is

237
00:08:46,139 --> 00:08:48,200
important. And while

238
00:08:48,200 --> 00:08:50,239
your training is running, it's also important

239
00:08:50,239 --> 00:08:51,239
for you to have

240
00:08:51,690 --> 00:08:53,019
a good amount of insight,

241
00:08:53,519 --> 00:08:55,558
uh, insight into what's happening within your

242
00:08:55,558 --> 00:08:58,119
training job and have observability

243
00:08:58,119 --> 00:08:59,119
across your training staff.

244
00:08:59,899 --> 00:09:00,788
And lastly,

245
00:09:01,109 --> 00:09:03,109
there are new open source tools

246
00:09:03,308 --> 00:09:04,070
that are

247
00:09:04,349 --> 00:09:06,330
becoming available and popular

248
00:09:07,349 --> 00:09:09,548
very quickly these days. So you want to make

249
00:09:09,548 --> 00:09:11,090
sure that your infrastructure

250
00:09:11,389 --> 00:09:13,389
gives you the ability to be able

251
00:09:13,389 --> 00:09:15,590
to use new tools as

252
00:09:15,590 --> 00:09:16,989
they become available.

253
00:09:17,779 --> 00:09:20,019
So the composability of your AI stack is

254
00:09:20,019 --> 00:09:22,229
important. Well,

255
00:09:22,519 --> 00:09:23,298
before we move forward,

256
00:09:23,678 --> 00:09:25,719
uh, I wanna talk to you about how

257
00:09:26,080 --> 00:09:27,779
the, the overall,

258
00:09:28,080 --> 00:09:30,558
the two big areas, the two big ways

259
00:09:30,558 --> 00:09:32,460
you can train models on SageMaker.

260
00:09:32,960 --> 00:09:35,239
The first one is SageMaker training jobs.

261
00:09:35,558 --> 00:09:37,019
So this is an ephemeral

262
00:09:37,279 --> 00:09:38,678
training job capability

263
00:09:38,960 --> 00:09:41,119
where you submit, you, you

264
00:09:41,119 --> 00:09:42,178
have your training code

265
00:09:42,519 --> 00:09:44,460
and you submit a training job.

266
00:09:44,849 --> 00:09:47,190
And it goes and spins up the infrastructure

267
00:09:47,190 --> 00:09:49,960
to train your model, does the training, monitors

268
00:09:50,099 --> 00:09:52,158
the model, and then spins down the infrastructure.

269
00:09:52,580 --> 00:09:54,820
The second option is SageMaker Hyperpod.

270
00:09:55,940 --> 00:09:58,369
Hyper Hyperpod provides a persistent cluster

271
00:09:58,369 --> 00:10:00,418
of AI accelerators for you to train

272
00:10:00,418 --> 00:10:01,119
your models.

273
00:10:02,229 --> 00:10:04,269
And hyperpod automatically offers

274
00:10:04,269 --> 00:10:05,729
uh handles

275
00:10:06,139 --> 00:10:08,178
uh downtime failover and

276
00:10:08,178 --> 00:10:10,769
also provides you full control and flexibility

277
00:10:11,070 --> 00:10:11,950
in your infrastructure.

278
00:10:14,918 --> 00:10:16,989
We're talking a little bit more about Hyperpod.

279
00:10:17,399 --> 00:10:19,000
So, in Hyperpod,

280
00:10:19,288 --> 00:10:19,879
you can

281
00:10:20,239 --> 00:10:22,308
spin up a cluster of AI accelerators

282
00:10:22,308 --> 00:10:22,820
quickly,

283
00:10:23,200 --> 00:10:25,099
you can orchestrate your workloads

284
00:10:25,359 --> 00:10:26,739
using either Qubinities

285
00:10:27,599 --> 00:10:30,038
or using SLERM. Many of our customers

286
00:10:30,038 --> 00:10:32,158
who have run HVC workloads before

287
00:10:32,479 --> 00:10:34,509
prefer to use SLERM as a, as an interface, and

288
00:10:34,509 --> 00:10:36,058
which is why we provide that choice.

289
00:10:36,710 --> 00:10:39,048
In addition, Hyperpod is integrated

290
00:10:39,229 --> 00:10:41,590
with uh tools such as StageMaker Tensor

291
00:10:41,590 --> 00:10:44,090
support, as well as provides capabilities

292
00:10:44,389 --> 00:10:46,529
for real-time scheduling and prioritization

293
00:10:46,529 --> 00:10:47,609
of your training jobs.

294
00:10:49,210 --> 00:10:51,808
Also, it has built in fault tolerance,

295
00:10:51,889 --> 00:10:52,950
so it's able to recover

296
00:10:53,210 --> 00:10:54,279
from failures

297
00:10:54,570 --> 00:10:55,590
quickly, which we'll

298
00:10:55,928 --> 00:10:57,969
talk a little bit more about in the

299
00:10:58,450 --> 00:10:59,389
in the next few minutes.

300
00:11:00,658 --> 00:11:02,719
It's also highly customizable.

301
00:11:03,479 --> 00:11:05,558
So it's at the top layer, as I

302
00:11:05,558 --> 00:11:08,239
mentioned, it supports different orchestration

303
00:11:08,239 --> 00:11:09,139
options through

304
00:11:09,960 --> 00:11:11,759
Amazon EKS as well as SLUM

305
00:11:12,359 --> 00:11:13,509
for job submission,

306
00:11:13,798 --> 00:11:16,000
you can use the Hyperpot CLI

307
00:11:16,000 --> 00:11:18,070
or you could also directly use Cube

308
00:11:18,070 --> 00:11:18,700
CTL,

309
00:11:19,000 --> 00:11:21,168
Ray, um, the SLUM client

310
00:11:21,168 --> 00:11:21,899
or Composer.

311
00:11:22,479 --> 00:11:24,700
It's has out of the box support

312
00:11:24,700 --> 00:11:26,879
for observability through integrations

313
00:11:26,879 --> 00:11:29,418
with uh Prometheus, Graffaa, and CloudWatch.

314
00:11:30,129 --> 00:11:32,359
In addition, it supports all popular

315
00:11:32,500 --> 00:11:35,019
AI frameworks such as Pytorch, Tensorflow,

316
00:11:35,178 --> 00:11:36,080
Nemo, and JAX.

317
00:11:37,479 --> 00:11:39,609
And lastly, it also supports

318
00:11:39,609 --> 00:11:41,849
all the latest AI accelerated

319
00:11:41,849 --> 00:11:43,308
instances on AWS,

320
00:11:43,649 --> 00:11:45,210
both GPUs and ranium,

321
00:11:45,609 --> 00:11:46,590
and a variety of

322
00:11:46,849 --> 00:11:49,158
different storage options that you can use in your pre-training

323
00:11:49,158 --> 00:11:52,229
workload. Now

324
00:11:52,229 --> 00:11:54,250
one challenge that we've seen is with

325
00:11:54,250 --> 00:11:56,509
pre-training as we talked about resiliency earlier.

326
00:11:57,359 --> 00:11:58,119
Is that

327
00:11:58,440 --> 00:12:00,479
as your cluster size grows.

328
00:12:01,200 --> 00:12:03,918
The frequency of failures

329
00:12:03,918 --> 00:12:04,479
increases.

330
00:12:05,479 --> 00:12:07,590
Because, and why, why is that relevant? It's

331
00:12:07,590 --> 00:12:08,639
relevant because,

332
00:12:09,190 --> 00:12:11,469
you know, as I mentioned earlier, in

333
00:12:11,469 --> 00:12:12,710
distributed training,

334
00:12:13,119 --> 00:12:15,519
you know, even if a single GPU fails,

335
00:12:15,879 --> 00:12:18,000
your entire training process across

336
00:12:18,000 --> 00:12:19,759
the cluster comes to a halt.

337
00:12:20,969 --> 00:12:23,320
So, and as the cluster size grows,

338
00:12:23,639 --> 00:12:25,960
the probability of a failure increases

339
00:12:25,960 --> 00:12:27,599
because you have more GPUs in the cluster.

340
00:12:28,408 --> 00:12:28,960
And

341
00:12:29,259 --> 00:12:31,529
so as the frequency of failures increases,

342
00:12:31,779 --> 00:12:33,820
you're spending more and more time in

343
00:12:33,820 --> 00:12:35,899
dealing with those failures than actually making training

344
00:12:35,899 --> 00:12:38,928
progress. And

345
00:12:38,928 --> 00:12:41,349
why does this lead to, why is this a problem?

346
00:12:41,889 --> 00:12:43,908
Because when a failure occurs,

347
00:12:44,750 --> 00:12:46,038
And you have to spend time

348
00:12:46,308 --> 00:12:48,399
in finding the root cause.

349
00:12:48,759 --> 00:12:51,158
Then you have to spend time in taking remediation

350
00:12:51,158 --> 00:12:53,700
actions such as restarting or even replacing

351
00:12:53,700 --> 00:12:55,960
the failed node with a healthy node, and

352
00:12:55,960 --> 00:12:58,379
then restarting the entire training cluster.

353
00:12:59,000 --> 00:13:01,599
Then you have to restore from the previous checkpoints,

354
00:13:01,759 --> 00:13:02,739
from durable storage,

355
00:13:03,080 --> 00:13:05,080
and then restart all the training frameworks

356
00:13:05,080 --> 00:13:06,918
and processes on every GPU

357
00:13:07,320 --> 00:13:08,038
in the cluster.

358
00:13:08,668 --> 00:13:10,849
And this process can actually take hours.

359
00:13:12,190 --> 00:13:13,229
So in hyperpod,

360
00:13:13,570 --> 00:13:15,379
we've created a self-healing.

361
00:13:16,859 --> 00:13:19,009
Capability to handle such faults. So when your

362
00:13:19,009 --> 00:13:21,710
training is running and a node fails, Hyperpod

363
00:13:21,710 --> 00:13:23,940
automatically detects and diagnoses the

364
00:13:23,940 --> 00:13:26,330
issue. If a node needs to be replaced,

365
00:13:26,609 --> 00:13:28,969
then it, it does that automatically, and

366
00:13:28,969 --> 00:13:31,009
then it automatically restores your

367
00:13:31,009 --> 00:13:32,869
training from the last safe checkpoint,

368
00:13:33,210 --> 00:13:35,048
and then it automatically resumes training.

369
00:13:37,070 --> 00:13:38,700
But there's still a key challenge.

370
00:13:40,259 --> 00:13:42,369
The first one is that there is an all

371
00:13:42,369 --> 00:13:44,178
or nothing cascade problem here.

372
00:13:45,479 --> 00:13:47,570
When the training is stopping

373
00:13:47,570 --> 00:13:49,619
because of a of a fault, then it's

374
00:13:49,619 --> 00:13:51,729
stopping on all GPUs on your cluster.

375
00:13:51,969 --> 00:13:54,129
Your cluster is completely stopped. It's not doing any

376
00:13:54,129 --> 00:13:56,570
work, so that leads to a lot of wastage.

377
00:13:57,038 --> 00:13:59,048
2, all the recovery steps

378
00:13:59,048 --> 00:14:00,029
are sequential.

379
00:14:00,769 --> 00:14:02,889
First, you're replacing a failed

380
00:14:02,889 --> 00:14:04,009
node with a healthy node.

381
00:14:04,399 --> 00:14:05,418
Then you are,

382
00:14:05,678 --> 00:14:07,859
uh, you know, restoring, uh,

383
00:14:07,869 --> 00:14:09,918
uh, from the last safe checkpoint and then

384
00:14:09,918 --> 00:14:11,710
you're restarting all the training processes.

385
00:14:12,080 --> 00:14:14,479
All of that is sequential in nature and blocks

386
00:14:14,479 --> 00:14:15,460
the,

387
00:14:15,719 --> 00:14:17,080
every step of the way.

388
00:14:18,979 --> 00:14:20,119
The second thing is

389
00:14:20,538 --> 00:14:22,918
the checkpoint-based recovery is expensive

390
00:14:22,918 --> 00:14:25,109
because you're loading the checkpoints from persistent

391
00:14:25,109 --> 00:14:26,639
storage onto compute nodes.

392
00:14:27,450 --> 00:14:28,349
And that can take

393
00:14:28,769 --> 00:14:30,769
tens of minutes based on the size

394
00:14:30,769 --> 00:14:31,529
of your checkpoint.

395
00:14:32,548 --> 00:14:33,739
And at scale,

396
00:14:34,320 --> 00:14:36,719
this has a big impact because overall

397
00:14:36,719 --> 00:14:38,759
recovery from faults can take

398
00:14:38,759 --> 00:14:39,479
up to an hour.

399
00:14:42,489 --> 00:14:44,830
So, yesterday in the keynote,

400
00:14:44,918 --> 00:14:46,269
uh, we announced

401
00:14:46,570 --> 00:14:48,229
checkpointless training on hyperpod.

402
00:14:48,889 --> 00:14:51,000
So this capability completely changes

403
00:14:51,000 --> 00:14:53,330
the paradigm for distributed training at scale.

404
00:14:54,779 --> 00:14:56,038
The way it works is

405
00:14:56,500 --> 00:14:58,239
when a failure occurs during

406
00:14:58,779 --> 00:15:00,259
a distributed training job.

407
00:15:01,759 --> 00:15:03,580
Uh, checkpointless training

408
00:15:03,840 --> 00:15:05,000
is able to

409
00:15:05,279 --> 00:15:07,279
not rather than stopping all

410
00:15:07,279 --> 00:15:09,359
the training processes, it keeps the

411
00:15:09,359 --> 00:15:11,359
training processes alive and it's

412
00:15:11,359 --> 00:15:12,418
able to restore

413
00:15:12,950 --> 00:15:13,798
model state

414
00:15:14,239 --> 00:15:17,168
through a peer to peer mechanism from nearby

415
00:15:17,168 --> 00:15:18,399
nodes that have model state.

416
00:15:19,940 --> 00:15:22,479
And that way it's able to recover

417
00:15:22,700 --> 00:15:25,099
from failures without having to restart

418
00:15:25,099 --> 00:15:27,359
any infrastructure or training processes

419
00:15:27,580 --> 00:15:29,899
or and without relying on

420
00:15:29,899 --> 00:15:31,899
any checkpoint in durable storage.

421
00:15:32,840 --> 00:15:35,000
So essentially you get a restart

422
00:15:35,000 --> 00:15:36,580
list and a checkpoint list system.

423
00:15:37,570 --> 00:15:38,099
And

424
00:15:38,979 --> 00:15:41,019
with that, what that means is that you're able to

425
00:15:41,019 --> 00:15:43,440
recover from faults in mere seconds.

426
00:15:47,000 --> 00:15:49,000
So Let's

427
00:15:49,000 --> 00:15:51,479
take an example of how this works.

428
00:15:52,379 --> 00:15:54,899
When a failure occurs in a traditional checkpoint-based

429
00:15:54,899 --> 00:15:55,529
recovery,

430
00:15:55,859 --> 00:15:58,399
you're diagnosing and triggering a recovery,

431
00:15:58,820 --> 00:16:01,038
and then you're reinitializing your cluster.

432
00:16:02,009 --> 00:16:04,288
And that happens on all GPUs in the cluster.

433
00:16:05,168 --> 00:16:07,750
And then you're downloading your checkpoint

434
00:16:08,129 --> 00:16:08,889
from S3.

435
00:16:09,759 --> 00:16:12,080
And finally, you're also then resuming

436
00:16:12,080 --> 00:16:14,200
training. So there's

437
00:16:14,200 --> 00:16:15,859
a big difference between

438
00:16:16,119 --> 00:16:18,460
the steps that a traditional process follows

439
00:16:18,759 --> 00:16:20,798
and how quickly checkpointless training

440
00:16:20,798 --> 00:16:21,739
is able to

441
00:16:22,739 --> 00:16:23,479
recover from the fault.

442
00:16:26,158 --> 00:16:28,418
Now, all the latest NA models

443
00:16:28,629 --> 00:16:29,859
that we announced this week

444
00:16:30,200 --> 00:16:32,619
were all trained using this capability,

445
00:16:32,918 --> 00:16:33,940
and what we found

446
00:16:34,599 --> 00:16:36,139
uh in those during

447
00:16:37,200 --> 00:16:38,519
those training, um,

448
00:16:39,570 --> 00:16:41,788
training projects was that, uh,

449
00:16:41,798 --> 00:16:44,168
using this capability we were able to recover

450
00:16:44,168 --> 00:16:46,820
from faults in many cases in seconds

451
00:16:47,158 --> 00:16:48,418
and at larger scale

452
00:16:48,759 --> 00:16:50,359
within 1 to 2 minutes.

453
00:16:51,418 --> 00:16:53,229
And it also helped us achieve

454
00:16:53,619 --> 00:16:55,668
consistently achieve 95%

455
00:16:55,668 --> 00:16:57,158
good on our training cluster.

456
00:17:00,250 --> 00:17:02,250
So, checkpointless training

457
00:17:02,250 --> 00:17:04,608
under the hood is underpinned by

458
00:17:04,608 --> 00:17:05,269
4

459
00:17:05,809 --> 00:17:06,809
important innovations.

460
00:17:08,848 --> 00:17:11,328
The first one is optimize collective communication

461
00:17:11,328 --> 00:17:12,430
initialization.

462
00:17:12,930 --> 00:17:15,170
So when a distributor training job

463
00:17:15,170 --> 00:17:17,868
is initializing, it has to establish

464
00:17:18,039 --> 00:17:20,368
uh communication channels. Every

465
00:17:20,368 --> 00:17:21,469
node has to do that.

466
00:17:21,809 --> 00:17:24,170
And traditionally the way it happens is, is

467
00:17:24,170 --> 00:17:26,328
that there's a central root server that

468
00:17:26,328 --> 00:17:27,108
coordinates

469
00:17:27,529 --> 00:17:29,809
establishing all, all those communication

470
00:17:29,809 --> 00:17:30,430
channels,

471
00:17:30,848 --> 00:17:32,489
and that creates a big bottleneck.

472
00:17:33,098 --> 00:17:35,420
So with this capability we've

473
00:17:35,420 --> 00:17:36,848
gotten rid of that

474
00:17:37,299 --> 00:17:39,578
centralized root server and we've

475
00:17:39,578 --> 00:17:41,759
developed a new peer to peer mechanism

476
00:17:42,189 --> 00:17:43,439
of nodes to discover

477
00:17:43,769 --> 00:17:45,949
each other and establish communication channels.

478
00:17:46,180 --> 00:17:47,598
So that reduces the

479
00:17:48,568 --> 00:17:50,660
communication initialization from minutes

480
00:17:50,660 --> 00:17:51,259
to seconds.

481
00:17:52,380 --> 00:17:53,559
The second is

482
00:17:54,019 --> 00:17:55,140
memory map data loading.

483
00:17:56,630 --> 00:17:58,930
So when you're resuming training,

484
00:17:59,660 --> 00:18:01,779
You need your training process needs

485
00:18:01,779 --> 00:18:03,039
access to training data,

486
00:18:03,500 --> 00:18:05,699
and many times you have

487
00:18:05,699 --> 00:18:08,519
data pipelines that require pre-processing

488
00:18:08,618 --> 00:18:09,598
and it can take

489
00:18:10,219 --> 00:18:11,160
several minutes

490
00:18:11,549 --> 00:18:13,660
for you to pre-process that data and actually

491
00:18:13,660 --> 00:18:15,338
make it available to your training process.

492
00:18:16,729 --> 00:18:18,509
So this new innovation

493
00:18:18,779 --> 00:18:21,039
caches the training data in shared

494
00:18:21,039 --> 00:18:21,630
memory

495
00:18:22,400 --> 00:18:24,489
through memory mapped files that persist

496
00:18:24,489 --> 00:18:27,078
across training failures. So when your training resumes,

497
00:18:27,289 --> 00:18:29,430
it has instant access to training data

498
00:18:29,848 --> 00:18:32,009
while your data pipeline is initializing.

499
00:18:33,818 --> 00:18:35,920
The 3rd is in process recovery.

500
00:18:36,459 --> 00:18:37,519
This means that

501
00:18:37,779 --> 00:18:39,098
when a failure occurs.

502
00:18:40,309 --> 00:18:41,449
This capability

503
00:18:41,769 --> 00:18:43,989
does not have to stop the training processes,

504
00:18:44,068 --> 00:18:45,890
it keeps the training processes running,

505
00:18:46,390 --> 00:18:47,088
and then,

506
00:18:47,469 --> 00:18:49,549
uh, so your training basically just

507
00:18:49,549 --> 00:18:50,680
pauses and resumes.

508
00:18:51,759 --> 00:18:53,539
And last is checkpointless recovery

509
00:18:54,279 --> 00:18:56,500
where. Hyperpod

510
00:18:56,500 --> 00:18:58,640
is able to swap failed components

511
00:18:58,640 --> 00:19:00,680
with healthy ones through a peer to peer

512
00:19:00,680 --> 00:19:02,799
recovery of model and optimizer

513
00:19:02,799 --> 00:19:04,920
state from healthy AI accelerators

514
00:19:04,920 --> 00:19:07,118
rather than relying on an explicit

515
00:19:07,118 --> 00:19:07,640
checkpoint.

516
00:19:09,920 --> 00:19:11,380
Now let's talk about another

517
00:19:12,500 --> 00:19:14,559
problem or challenge we face in

518
00:19:14,559 --> 00:19:16,759
during pre-training, which is of infrastructure

519
00:19:16,759 --> 00:19:17,640
underutilization.

520
00:19:19,380 --> 00:19:20,529
Now, uh

521
00:19:21,160 --> 00:19:22,299
Idle compute

522
00:19:22,880 --> 00:19:24,920
happens to be a key challenge here because if

523
00:19:24,920 --> 00:19:26,959
your jobs, the way your jobs

524
00:19:26,959 --> 00:19:28,618
are running, if they are not,

525
00:19:28,920 --> 00:19:31,719
uh, if they're not utilizing your infrastructure

526
00:19:32,479 --> 00:19:34,598
fully, then it leads to compute

527
00:19:34,598 --> 00:19:36,818
being wasted and that leads to cost overruns.

528
00:19:37,439 --> 00:19:39,880
It also leads to suboptimal prioritization.

529
00:19:41,140 --> 00:19:43,279
Because if you have high priority

530
00:19:43,279 --> 00:19:45,400
jobs run uh waiting in the queue

531
00:19:45,400 --> 00:19:47,078
because your low priority jobs are running,

532
00:19:47,479 --> 00:19:48,779
then obviously you're not

533
00:19:49,078 --> 00:19:50,640
working on the most important things.

534
00:19:51,930 --> 00:19:54,269
This wastage also increases your cost

535
00:19:54,269 --> 00:19:56,400
and reduces productivity for

536
00:19:56,400 --> 00:19:58,410
your developers because oftentimes they're

537
00:19:58,410 --> 00:20:00,509
waiting for infrastructure availability

538
00:20:01,009 --> 00:20:01,750
rather than

539
00:20:02,009 --> 00:20:03,170
being able to make progress.

540
00:20:05,439 --> 00:20:06,650
So we've solved this

541
00:20:06,920 --> 00:20:07,818
in StageMaker

542
00:20:08,130 --> 00:20:10,358
through uh uh hyperpo task

543
00:20:10,358 --> 00:20:11,019
governance,

544
00:20:11,449 --> 00:20:13,779
which automatically runs your jobs according

545
00:20:13,779 --> 00:20:14,880
to their priority.

546
00:20:15,640 --> 00:20:17,660
And you can also adjust these priorities

547
00:20:17,660 --> 00:20:18,439
in real time.

548
00:20:19,108 --> 00:20:21,529
It also offers you real-time observability.

549
00:20:22,368 --> 00:20:24,588
So you can monitor your overall cluster

550
00:20:24,588 --> 00:20:25,420
utilization.

551
00:20:26,420 --> 00:20:28,459
Both at the cluster level as

552
00:20:28,459 --> 00:20:30,618
well as at job and and team level.

553
00:20:31,449 --> 00:20:33,410
This helps you reduce idle compute.

554
00:20:34,318 --> 00:20:36,239
And minimize task wait time.

555
00:20:37,039 --> 00:20:38,269
And it helps you

556
00:20:38,729 --> 00:20:41,049
increase and maximize your overall compute

557
00:20:41,289 --> 00:20:42,568
utilization in your cluster.

558
00:20:44,140 --> 00:20:45,229
So the way it works is

559
00:20:46,630 --> 00:20:49,088
With this capability, you can go into hyperpod

560
00:20:49,088 --> 00:20:51,150
and you can set up different types of

561
00:20:51,150 --> 00:20:53,509
tasks, such as training, fine tuning,

562
00:20:53,789 --> 00:20:55,809
experimentation, or even infants,

563
00:20:56,150 --> 00:20:57,390
and you can give them weights.

564
00:20:58,568 --> 00:21:00,719
Then you can set up compute allocations.

565
00:21:00,769 --> 00:21:03,130
You can define your teams or projects.

566
00:21:03,719 --> 00:21:05,719
And allocate compute limits to them.

567
00:21:06,739 --> 00:21:09,368
And finally, you can also specify

568
00:21:09,630 --> 00:21:11,709
how idle compute is allocated

569
00:21:11,709 --> 00:21:13,809
whenever there is free compute capacity

570
00:21:14,108 --> 00:21:15,509
available within the cluster,

571
00:21:15,868 --> 00:21:17,250
you can control whether it

572
00:21:17,618 --> 00:21:19,670
becomes it's distributed to different

573
00:21:19,670 --> 00:21:21,828
teams of projects or jobs in a first

574
00:21:21,828 --> 00:21:24,239
come first serve basis or using a fair

575
00:21:24,489 --> 00:21:26,670
fair share way which uses the weights

576
00:21:26,670 --> 00:21:28,828
that you define for different tasks to allocate

577
00:21:28,828 --> 00:21:29,449
capacity.

578
00:21:31,598 --> 00:21:33,699
In addition, you can set up lend

579
00:21:33,699 --> 00:21:36,049
and borrow rules. So there, here you

580
00:21:36,049 --> 00:21:38,189
can define whether a team

581
00:21:38,729 --> 00:21:40,969
can automatically borrow compute

582
00:21:40,969 --> 00:21:42,969
capacity from another team when it

583
00:21:42,969 --> 00:21:43,709
is available,

584
00:21:44,068 --> 00:21:46,250
or can a team lend its compute

585
00:21:46,250 --> 00:21:48,338
capacity to another team when it's available,

586
00:21:48,608 --> 00:21:50,848
and all of this happens automatically.

587
00:21:51,049 --> 00:21:51,989
You can also control

588
00:21:52,489 --> 00:21:54,689
whether higher priority tasks can

589
00:21:54,689 --> 00:21:56,368
preempt lower priority tasks.

590
00:21:57,199 --> 00:21:59,449
So you're always working on the most important

591
00:21:59,449 --> 00:22:04,598
things. So

592
00:22:04,598 --> 00:22:07,088
let's talk about another challenge related to infrastructure

593
00:22:07,088 --> 00:22:08,729
underutilization during pre-training.

594
00:22:09,549 --> 00:22:11,670
Now, distributed training jobs

595
00:22:11,930 --> 00:22:13,209
are quite inflexible.

596
00:22:13,750 --> 00:22:15,868
What I mean is that once you've started the

597
00:22:15,868 --> 00:22:18,150
job with a set of nodes, let's

598
00:22:18,150 --> 00:22:20,660
say you're running a job with 8 nodes,

599
00:22:21,108 --> 00:22:23,430
then until your job has completed.

600
00:22:24,380 --> 00:22:26,769
You have to continue with the same node

601
00:22:26,769 --> 00:22:27,420
configuration.

602
00:22:28,799 --> 00:22:31,068
But oftentimes the compute availability

603
00:22:31,068 --> 00:22:33,420
changes. Sometimes more compute may

604
00:22:33,420 --> 00:22:35,588
become available and you may want to use it in your

605
00:22:35,588 --> 00:22:38,088
existing training job to make it go faster.

606
00:22:38,509 --> 00:22:39,689
Or other times

607
00:22:40,108 --> 00:22:42,180
there might be another high priority job that may

608
00:22:42,180 --> 00:22:43,088
need some compute,

609
00:22:43,439 --> 00:22:45,509
and you may want to take some compute out

610
00:22:45,509 --> 00:22:47,568
of the training job that you're running to make

611
00:22:47,750 --> 00:22:49,049
that job go faster.

612
00:22:49,630 --> 00:22:50,259
However,

613
00:22:50,630 --> 00:22:52,709
today, if you need to do that, you need to completely

614
00:22:52,709 --> 00:22:53,969
stop the training

615
00:22:54,229 --> 00:22:56,309
workload that you're running, need to completely

616
00:22:56,309 --> 00:22:57,368
reconfigure it.

617
00:22:58,029 --> 00:23:00,348
With the new uh node configuration

618
00:23:00,750 --> 00:23:02,838
and then completely restart and rerun it. So

619
00:23:02,838 --> 00:23:04,529
that obviously leads to

620
00:23:05,098 --> 00:23:07,368
a lot of wastage and um

621
00:23:07,789 --> 00:23:08,910
and, and, and delay.

622
00:23:10,489 --> 00:23:12,699
So to solve this yesterday we also

623
00:23:12,699 --> 00:23:14,979
announced elastic training on

624
00:23:14,979 --> 00:23:15,618
hyperpod.

625
00:23:16,920 --> 00:23:18,000
What this does is,

626
00:23:18,479 --> 00:23:20,078
when your training job is running.

627
00:23:20,858 --> 00:23:22,920
It helps you define uh

628
00:23:23,009 --> 00:23:25,000
scaling rules for your training job,

629
00:23:25,459 --> 00:23:26,000
and when

630
00:23:26,420 --> 00:23:28,578
you need, uh, when there is

631
00:23:28,578 --> 00:23:30,160
extra capacity available,

632
00:23:30,578 --> 00:23:32,779
it helps your training job automatically scale

633
00:23:32,779 --> 00:23:34,979
up, and when you need more

634
00:23:34,979 --> 00:23:37,259
capacity out of this training job, it can also scale

635
00:23:37,259 --> 00:23:39,539
down and give you capacity back while continuing

636
00:23:39,539 --> 00:23:40,180
to execute.

637
00:23:41,380 --> 00:23:43,449
This is also done in a way that does

638
00:23:43,449 --> 00:23:44,959
not impact model convergence

639
00:23:45,219 --> 00:23:47,259
because it shrinks and grows in terms

640
00:23:47,259 --> 00:23:48,779
of data parallel replicas.

641
00:23:51,789 --> 00:23:53,868
So let's see how it works. So

642
00:23:53,868 --> 00:23:55,229
you've got a training job running.

643
00:23:56,098 --> 00:23:58,459
You have 4 nodes become available and

644
00:23:58,459 --> 00:24:00,900
so your training job automatically scales up

645
00:24:01,180 --> 00:24:02,479
and then further scales up.

646
00:24:03,170 --> 00:24:03,949
And then,

647
00:24:04,368 --> 00:24:06,529
when you need capacity

648
00:24:06,529 --> 00:24:08,750
out of this training job, because let's say your

649
00:24:08,750 --> 00:24:10,890
infants is scaling up and you need capacity

650
00:24:10,890 --> 00:24:12,269
to scale infants up,

651
00:24:12,769 --> 00:24:14,390
it can also easily scale down

652
00:24:14,858 --> 00:24:17,009
and uh and the training

653
00:24:17,009 --> 00:24:18,969
continues to make progress throughout this process.

654
00:24:23,309 --> 00:24:25,828
Let's talk about another key challenge

655
00:24:25,828 --> 00:24:26,949
of observability.

656
00:24:27,838 --> 00:24:29,098
So, uh,

657
00:24:29,400 --> 00:24:29,939
you know,

658
00:24:30,519 --> 00:24:31,979
when you're running your training,

659
00:24:32,279 --> 00:24:34,318
uh, training job, it's very important for

660
00:24:34,318 --> 00:24:36,279
you to have a very deep understanding

661
00:24:36,559 --> 00:24:38,199
of what's going on in your cluster,

662
00:24:38,519 --> 00:24:39,868
right? So, I'll tell you,

663
00:24:40,239 --> 00:24:41,858
I'll give you one example. So,

664
00:24:42,358 --> 00:24:44,939
um, some time ago, before this capability

665
00:24:44,939 --> 00:24:45,479
existed,

666
00:24:45,880 --> 00:24:48,078
our science team at AWS they were working

667
00:24:48,078 --> 00:24:50,068
on, uh, some training projects.

668
00:24:50,750 --> 00:24:52,959
And they saw a dip

669
00:24:52,959 --> 00:24:54,699
in the model training performance.

670
00:24:55,709 --> 00:24:57,509
And they were wondering why that's happening,

671
00:24:57,868 --> 00:25:00,049
and it took us days to figure out that

672
00:25:00,059 --> 00:25:01,689
that was happening because of certain

673
00:25:02,059 --> 00:25:04,029
temperature fluctuations at the GPU level.

674
00:25:04,809 --> 00:25:06,890
Right? And there wasn't good tooling

675
00:25:06,890 --> 00:25:08,689
to actually root cause that quickly.

676
00:25:09,670 --> 00:25:11,799
Your training stack is like a layered cake. It

677
00:25:11,799 --> 00:25:14,059
has so many different layers from your training code

678
00:25:14,059 --> 00:25:16,400
to, you know, your training

679
00:25:16,400 --> 00:25:17,858
frameworks to compute,

680
00:25:18,239 --> 00:25:19,719
networking and the actual hardware.

681
00:25:21,009 --> 00:25:23,170
So, it's very important that you have,

682
00:25:23,479 --> 00:25:25,910
um, you know, high quality observability

683
00:25:26,088 --> 00:25:27,588
in your training solution.

684
00:25:28,130 --> 00:25:30,269
So that's why we build hyperpod observability.

685
00:25:30,650 --> 00:25:32,680
This gives you one click and out

686
00:25:32,680 --> 00:25:34,769
of the box support for Amazon

687
00:25:34,769 --> 00:25:36,368
managed Prometheus and Gfana.

688
00:25:37,068 --> 00:25:39,420
Uh, it offers preconfigured metrics

689
00:25:39,739 --> 00:25:42,279
across all layers of the stack from your

690
00:25:42,279 --> 00:25:44,358
job level metrics to

691
00:25:44,358 --> 00:25:46,578
compute layer to our networking layer

692
00:25:46,719 --> 00:25:47,400
and hardware.

693
00:25:48,259 --> 00:25:50,729
And also this scales automatically

694
00:25:50,949 --> 00:25:52,588
with Azure cluster scales.

695
00:25:55,779 --> 00:25:57,930
OK. So we've talked about

696
00:25:58,309 --> 00:25:59,449
how our model

697
00:25:59,910 --> 00:26:02,039
learns more general information through

698
00:26:02,039 --> 00:26:02,719
pre-training.

699
00:26:03,068 --> 00:26:05,529
Let's not talk about post-training or model customization.

700
00:26:06,618 --> 00:26:08,739
Because that's where we create real value and

701
00:26:08,739 --> 00:26:09,618
real differentiation.

702
00:26:11,449 --> 00:26:12,509
So at a high level,

703
00:26:13,709 --> 00:26:14,289
There are

704
00:26:14,630 --> 00:26:17,130
many different fine tuning or model customization

705
00:26:17,130 --> 00:26:18,309
techniques available today.

706
00:26:19,289 --> 00:26:21,358
Let's talk about each of them and see where they

707
00:26:21,358 --> 00:26:21,949
are relevant.

708
00:26:23,838 --> 00:26:24,858
So the first one

709
00:26:25,279 --> 00:26:26,759
is supervised fine tuning.

710
00:26:27,598 --> 00:26:29,680
So with supervised fine tuning, the

711
00:26:29,680 --> 00:26:31,939
model directly learns from labeled

712
00:26:32,078 --> 00:26:33,199
input output data.

713
00:26:34,348 --> 00:26:36,439
And it can use this to improve

714
00:26:36,439 --> 00:26:38,680
overall task performance and

715
00:26:38,680 --> 00:26:39,318
understand your domain.

716
00:26:40,489 --> 00:26:42,500
And this is actually quite

717
00:26:42,500 --> 00:26:44,618
useful when you have a have

718
00:26:44,618 --> 00:26:46,358
clear ground truth available with you.

719
00:26:47,910 --> 00:26:49,309
So, commonly used,

720
00:26:50,430 --> 00:26:53,068
common use cases for fine tuning

721
00:26:53,068 --> 00:26:55,189
include customer support Q&As and

722
00:26:55,189 --> 00:26:57,449
summarization tasks where you have

723
00:26:57,739 --> 00:26:59,029
gold standard references

724
00:26:59,309 --> 00:27:01,430
or even domain adaptation when you

725
00:27:01,430 --> 00:27:02,430
need to adapt your

726
00:27:03,000 --> 00:27:05,289
model to, let's say jargon

727
00:27:05,430 --> 00:27:07,828
from me or terms from

728
00:27:07,828 --> 00:27:09,549
medical field or legal or finance.

729
00:27:12,009 --> 00:27:14,140
Next, let's talk about reinforcement

730
00:27:14,140 --> 00:27:16,568
learning. Reinforcement

731
00:27:16,568 --> 00:27:17,809
learning is interesting.

732
00:27:18,098 --> 00:27:19,279
The way it works is.

733
00:27:20,598 --> 00:27:23,299
The model generates multiple outputs

734
00:27:23,479 --> 00:27:25,519
and then it reserve and it receives

735
00:27:25,519 --> 00:27:27,739
a reward or a penalty,

736
00:27:28,000 --> 00:27:29,660
and based on that it knows whether,

737
00:27:30,078 --> 00:27:32,239
you know, what to do and what not to do.

738
00:27:33,368 --> 00:27:35,380
And so it's extremely

739
00:27:35,380 --> 00:27:36,000
useful

740
00:27:36,358 --> 00:27:38,539
for long form reasoning and adherence

741
00:27:38,539 --> 00:27:39,779
to multi-rule policies.

742
00:27:41,858 --> 00:27:44,088
Now, The way RL

743
00:27:44,088 --> 00:27:44,890
works is

744
00:27:45,328 --> 00:27:46,098
there's a

745
00:27:46,368 --> 00:27:48,539
policy model in the system, in the RL

746
00:27:48,539 --> 00:27:50,890
system, which is basically the model that you're

747
00:27:51,250 --> 00:27:51,890
fine tuning.

748
00:27:52,868 --> 00:27:55,289
It generates rollouts, which is basically

749
00:27:55,989 --> 00:27:57,709
different outputs for a given prompt.

750
00:27:58,979 --> 00:28:01,098
Then, uh, a component

751
00:28:01,098 --> 00:28:03,338
computes rewards using a reward function

752
00:28:03,338 --> 00:28:04,108
or a model,

753
00:28:04,459 --> 00:28:06,539
and then an optimization algorithm

754
00:28:07,140 --> 00:28:08,199
updates the model

755
00:28:08,500 --> 00:28:09,598
based on those rewards.

756
00:28:10,588 --> 00:28:12,650
And there are a few different variations

757
00:28:12,650 --> 00:28:13,348
of this.

758
00:28:14,559 --> 00:28:15,578
When the reward

759
00:28:16,039 --> 00:28:18,199
is computed based on labeled

760
00:28:18,199 --> 00:28:18,858
human data.

761
00:28:19,799 --> 00:28:20,779
This is known as

762
00:28:21,160 --> 00:28:23,459
RLHF or RL from human feedback.

763
00:28:24,439 --> 00:28:26,519
When an AI judge or AI model

764
00:28:26,519 --> 00:28:29,380
acts as a judge and computes these rewards,

765
00:28:29,920 --> 00:28:31,959
then it is known as RL from

766
00:28:31,959 --> 00:28:34,239
AI feedback, and this is quite useful

767
00:28:34,239 --> 00:28:36,519
when there's a large

768
00:28:36,519 --> 00:28:38,680
amount of reward computation that needs to

769
00:28:38,680 --> 00:28:40,140
happen and you don't have enough

770
00:28:40,519 --> 00:28:42,529
uh human resources to label that

771
00:28:42,529 --> 00:28:45,059
data. And lastly,

772
00:28:45,969 --> 00:28:48,390
For cases where you can programmatically

773
00:28:48,390 --> 00:28:50,588
verify the accuracy

774
00:28:51,059 --> 00:28:53,130
of model output, you can

775
00:28:53,130 --> 00:28:54,769
also write a reward function.

776
00:28:55,858 --> 00:28:58,269
To do RL and this is known as RL

777
00:28:58,269 --> 00:28:59,529
from verifiable rewards.

778
00:29:00,608 --> 00:29:02,650
And this is easy because it's, uh, you know,

779
00:29:02,689 --> 00:29:04,469
it's, it's, it's scalable

780
00:29:04,848 --> 00:29:07,078
and it's, it has, it doesn't, it's objective,

781
00:29:07,088 --> 00:29:08,410
it has less bias

782
00:29:08,769 --> 00:29:11,108
and it's for specific tasks such as,

783
00:29:11,209 --> 00:29:11,969
um, you know,

784
00:29:12,328 --> 00:29:14,568
coding and uh tasks with

785
00:29:14,568 --> 00:29:16,699
clear correctness signals. This is quite

786
00:29:16,699 --> 00:29:17,529
a popular technique.

787
00:29:20,430 --> 00:29:21,449
And the last one

788
00:29:21,789 --> 00:29:23,269
is direct preference optimization.

789
00:29:24,078 --> 00:29:26,189
So, DPO is a close cousin of

790
00:29:26,189 --> 00:29:27,709
RL but not quite RL?

791
00:29:28,500 --> 00:29:29,500
In the sense that

792
00:29:29,779 --> 00:29:31,900
with DPO you're telling the model,

793
00:29:31,979 --> 00:29:33,459
you show the model that hey,

794
00:29:33,739 --> 00:29:35,900
I prefer this response for a given

795
00:29:35,900 --> 00:29:37,318
prompt I prefer this response

796
00:29:37,739 --> 00:29:39,779
over the other and through that the model

797
00:29:39,779 --> 00:29:41,160
learns your preferences

798
00:29:41,618 --> 00:29:44,239
and so this technique is quite useful

799
00:29:44,588 --> 00:29:46,858
for subjective or style driven

800
00:29:46,858 --> 00:29:48,858
learning. So let's say you want to make your model

801
00:29:48,858 --> 00:29:49,618
learn about,

802
00:29:49,900 --> 00:29:52,160
uh, you know, um, learn your brand

803
00:29:52,160 --> 00:29:54,318
voice or or values or

804
00:29:54,699 --> 00:29:56,219
how um the tone.

805
00:29:56,598 --> 00:29:58,739
Uh, that you want in your chatbot.

806
00:30:00,078 --> 00:30:02,170
And it's also easy to implement

807
00:30:02,170 --> 00:30:02,989
because it doesn't

808
00:30:03,568 --> 00:30:05,719
require um the full RL

809
00:30:05,719 --> 00:30:08,880
setup. Well,

810
00:30:09,160 --> 00:30:10,660
but here's the reality,

811
00:30:11,118 --> 00:30:13,459
like, these techniques are great,

812
00:30:13,799 --> 00:30:15,880
but then to implement them, I actually

813
00:30:15,880 --> 00:30:16,979
put them to use.

814
00:30:17,769 --> 00:30:19,930
You know, you have to wrestle with a lot of different

815
00:30:19,930 --> 00:30:21,189
things. First,

816
00:30:21,759 --> 00:30:24,170
you have to deal with a lot of infrastructure

817
00:30:24,170 --> 00:30:26,689
set up because there are different components

818
00:30:26,689 --> 00:30:27,549
involved from,

819
00:30:27,848 --> 00:30:28,809
you know, uh

820
00:30:29,328 --> 00:30:31,368
accumulating data to running

821
00:30:31,368 --> 00:30:33,650
these different techniques, and the setup

822
00:30:33,650 --> 00:30:36,009
for all these different techniques is actually

823
00:30:36,009 --> 00:30:36,608
quite different.

824
00:30:36,979 --> 00:30:39,078
And then you have to evaluate models and then

825
00:30:39,219 --> 00:30:41,259
if you're doing this at this at enterprise

826
00:30:41,259 --> 00:30:43,338
scale, then you also have to worry about

827
00:30:43,338 --> 00:30:45,479
governance and who has access to what

828
00:30:45,779 --> 00:30:47,868
and whether you have full lineage

829
00:30:47,868 --> 00:30:48,910
tracking in place.

830
00:30:49,259 --> 00:30:51,338
So all in all you're spending more time

831
00:30:51,338 --> 00:30:53,598
plumbing than actually doing value added work.

832
00:30:55,719 --> 00:30:56,858
So this is

833
00:30:57,118 --> 00:30:59,519
where SageMaker comes in. So SageMaker

834
00:30:59,519 --> 00:31:00,539
acts as

835
00:31:00,799 --> 00:31:02,180
a unified runway

836
00:31:02,680 --> 00:31:04,539
for a model customization.

837
00:31:05,160 --> 00:31:07,500
First, it offers a broad choice

838
00:31:07,630 --> 00:31:09,989
of models that you can customize out of the box,

839
00:31:10,439 --> 00:31:12,799
including the Amazon Nova models and

840
00:31:12,799 --> 00:31:14,838
other open weights models such as GPT

841
00:31:14,838 --> 00:31:15,549
OSS,

842
00:31:15,959 --> 00:31:17,078
Lama models, Queen,

843
00:31:17,358 --> 00:31:18,318
Deep Seek, and more.

844
00:31:20,078 --> 00:31:21,180
And it supports

845
00:31:21,559 --> 00:31:22,660
all the popular

846
00:31:23,039 --> 00:31:25,430
different fine tuning techniques from reinforcement

847
00:31:25,430 --> 00:31:27,838
learning to supervised fine tuning and

848
00:31:27,838 --> 00:31:28,920
direct preference optimization.

849
00:31:29,989 --> 00:31:32,068
And the entire process for

850
00:31:32,068 --> 00:31:34,108
model customization in StageMaker is

851
00:31:34,108 --> 00:31:34,959
fully managed.

852
00:31:35,420 --> 00:31:37,568
And so you don't have to deal with any

853
00:31:38,029 --> 00:31:39,890
infrastructure uh management.

854
00:31:42,719 --> 00:31:45,239
So yesterday, we also announced

855
00:31:45,239 --> 00:31:46,660
serverless training jobs

856
00:31:47,078 --> 00:31:49,719
on SageMaker, which can help you customize

857
00:31:49,719 --> 00:31:50,858
these models

858
00:31:51,559 --> 00:31:52,660
without having to deal

859
00:31:53,000 --> 00:31:54,598
with any compute capacity.

860
00:31:55,459 --> 00:31:57,400
It's very simple, you basically

861
00:31:57,939 --> 00:31:59,939
pick your data and pick the model that you

862
00:31:59,939 --> 00:32:00,680
wanna customize,

863
00:32:01,380 --> 00:32:03,420
and you can either use an API

864
00:32:03,420 --> 00:32:04,338
or the UI

865
00:32:04,618 --> 00:32:06,660
to kick off a completely serverless training

866
00:32:06,660 --> 00:32:09,630
job. Now,

867
00:32:09,769 --> 00:32:11,789
once you've customized your model, you

868
00:32:11,789 --> 00:32:13,809
also want to make sure that it's actually

869
00:32:13,809 --> 00:32:15,789
better than the model that you started with.

870
00:32:16,410 --> 00:32:18,608
Now, to do that, evaluation of

871
00:32:18,608 --> 00:32:20,719
the model that you've customized is

872
00:32:20,719 --> 00:32:21,368
extremely important.

873
00:32:22,088 --> 00:32:22,920
So for that

874
00:32:23,328 --> 00:32:25,608
we've also launched a new model

875
00:32:25,608 --> 00:32:26,848
evaluation capability.

876
00:32:27,719 --> 00:32:29,789
Again, this is available both through the

877
00:32:29,789 --> 00:32:31,880
API as well as our UI, which

878
00:32:31,880 --> 00:32:33,000
is Sage Maker Studio.

879
00:32:33,799 --> 00:32:36,390
And it supports multiple modes of evaluation

880
00:32:37,130 --> 00:32:38,189
from, uh,

881
00:32:38,459 --> 00:32:40,680
you can evaluate a model using standard

882
00:32:40,680 --> 00:32:42,630
industry benchmarks or you can use

883
00:32:42,969 --> 00:32:44,309
an LLM as a judge

884
00:32:44,608 --> 00:32:46,650
to which can uh where an AI model

885
00:32:46,650 --> 00:32:48,670
acts as a critic for

886
00:32:48,670 --> 00:32:51,229
the. Model you're evaluating,

887
00:32:51,729 --> 00:32:54,250
and you can also define your own custom metrics

888
00:32:54,250 --> 00:32:55,088
for evaluation.

889
00:32:58,380 --> 00:33:00,420
And then when you're running your training, you also

890
00:33:00,420 --> 00:33:02,880
want to make sure that you're able to capture

891
00:33:03,259 --> 00:33:04,779
and look at different metrics

892
00:33:05,068 --> 00:33:07,160
such as training loss or your reward

893
00:33:07,420 --> 00:33:08,439
uh metrics

894
00:33:08,779 --> 00:33:09,818
and um

895
00:33:10,140 --> 00:33:12,500
ML flow has emerged as a popular

896
00:33:12,500 --> 00:33:13,039
tool

897
00:33:13,299 --> 00:33:15,098
for doing such experiment tracking.

898
00:33:16,009 --> 00:33:17,358
And looking at different metrics.

899
00:33:17,769 --> 00:33:19,930
So, uh, this week we also announced

900
00:33:19,930 --> 00:33:21,500
a serverless ML flow

901
00:33:21,880 --> 00:33:22,828
in SageMaker,

902
00:33:23,368 --> 00:33:25,519
and so you can use serverless ML

903
00:33:25,519 --> 00:33:27,890
flow to start logging

904
00:33:27,890 --> 00:33:30,049
metrics from your training experiments

905
00:33:30,049 --> 00:33:32,140
and, and review them easily.

906
00:33:32,529 --> 00:33:34,969
Um, and also when you customize a model

907
00:33:34,969 --> 00:33:37,160
using our serverless training jobs in SageMaker

908
00:33:37,160 --> 00:33:39,170
now, your uh your metrics

909
00:33:39,170 --> 00:33:41,250
from your training job automatically show up in

910
00:33:41,250 --> 00:33:41,769
ML flow.

911
00:33:45,219 --> 00:33:47,709
OK, so we talked about the tools and techniques,

912
00:33:47,828 --> 00:33:49,130
but how do you use them,

913
00:33:49,549 --> 00:33:51,608
right? Well, there are 3 ways.

914
00:33:52,318 --> 00:33:53,160
In Sagemaker.

915
00:33:54,108 --> 00:33:56,269
One is the code-based path where you

916
00:33:56,269 --> 00:33:58,630
have access to an SDK to easily

917
00:33:58,630 --> 00:33:59,650
customize a model.

918
00:34:00,150 --> 00:34:02,189
The second is a UI path

919
00:34:02,189 --> 00:34:04,769
where you can use an easy to use UI

920
00:34:05,390 --> 00:34:07,670
in a point and click fashion to customize

921
00:34:07,670 --> 00:34:08,688
a model in twin.

922
00:34:09,148 --> 00:34:11,188
And the third one is an agent

923
00:34:11,188 --> 00:34:12,099
guided path.

924
00:34:13,059 --> 00:34:15,217
So this is where an agent can

925
00:34:15,217 --> 00:34:17,248
work with you and collaborate with you

926
00:34:17,579 --> 00:34:19,778
to design a customization task and

927
00:34:19,778 --> 00:34:20,838
actually execute on it.

928
00:34:22,978 --> 00:34:25,039
So, this is an example of the,

929
00:34:25,418 --> 00:34:27,329
of the code base path. So,

930
00:34:27,619 --> 00:34:29,469
using the SageMaker AI SDK

931
00:34:29,878 --> 00:34:31,199
you can start customizing

932
00:34:31,579 --> 00:34:33,820
uh models uh in a few minutes, in

933
00:34:33,820 --> 00:34:35,398
a, in a few lines of code.

934
00:34:36,059 --> 00:34:38,418
Also, you can write these codes in whatever

935
00:34:38,418 --> 00:34:40,500
ID you want, but you can also

936
00:34:40,500 --> 00:34:41,039
use

937
00:34:41,340 --> 00:34:43,539
built-in Jupiter Lab and open source

938
00:34:43,539 --> 00:34:45,699
VS code um IDEs

939
00:34:45,699 --> 00:34:46,599
within SageMaker.

940
00:34:47,927 --> 00:34:50,108
And also you can start with

941
00:34:50,367 --> 00:34:51,989
code and then jump to UI

942
00:34:52,447 --> 00:34:53,367
or vice versa.

943
00:34:55,849 --> 00:34:57,889
So next is the UI guided fine

944
00:34:57,889 --> 00:34:58,550
tuning.

945
00:34:59,128 --> 00:35:00,208
So, uh,

946
00:35:01,349 --> 00:35:03,369
The way this works is

947
00:35:04,280 --> 00:35:06,898
That you can go to models,

948
00:35:07,478 --> 00:35:09,820
you can select a model and say you want to customize

949
00:35:09,820 --> 00:35:10,398
with UI.

950
00:35:12,099 --> 00:35:13,530
And let's say you give it a name,

951
00:35:13,829 --> 00:35:15,949
select your fine tuning technique. In this

952
00:35:15,949 --> 00:35:17,469
case, we are using RLVR.

953
00:35:18,269 --> 00:35:18,909
And then

954
00:35:19,188 --> 00:35:21,260
you can select a reward function that

955
00:35:21,260 --> 00:35:22,389
you previously created.

956
00:35:23,878 --> 00:35:25,099
You select your data

957
00:35:28,719 --> 00:35:30,918
And then you can simply just submit

958
00:35:30,918 --> 00:35:31,780
the training job

959
00:35:32,119 --> 00:35:34,159
and off it goes and executes.

960
00:35:38,840 --> 00:35:41,000
Now, once your training job is running,

961
00:35:41,039 --> 00:35:41,739
you can

962
00:35:42,039 --> 00:35:43,539
monitor its performance.

963
00:35:44,889 --> 00:35:46,500
And once the model is done,

964
00:35:46,780 --> 00:35:48,059
you can also evaluate.

965
00:35:48,699 --> 00:35:49,398
The model.

966
00:35:51,369 --> 00:35:53,369
Uh, you can create a new evaluation job. You can

967
00:35:53,369 --> 00:35:55,849
select, uh, let's say in this case, if you're selecting

968
00:35:55,849 --> 00:35:57,320
an LLM as a judge approach,

969
00:35:57,610 --> 00:35:59,800
you can select the, uh, the, the judge model.

970
00:35:59,969 --> 00:36:01,869
You can also select the metrics that you

971
00:36:02,250 --> 00:36:03,570
want to evaluate the model on.

972
00:36:04,708 --> 00:36:07,050
You can also provide your own custom data sets

973
00:36:07,269 --> 00:36:08,590
and prompts for evaluation.

974
00:36:10,679 --> 00:36:13,039
And then when you kick off the evaluation job, it's

975
00:36:13,039 --> 00:36:14,099
completely serverless

976
00:36:14,639 --> 00:36:16,708
and uh it just executes

977
00:36:16,708 --> 00:36:17,219
in the background.

978
00:36:19,679 --> 00:36:21,719
Now going back to the custom

979
00:36:21,719 --> 00:36:23,099
model that we've created here.

980
00:36:24,878 --> 00:36:26,958
You can monitor different metrics as the job is

981
00:36:26,958 --> 00:36:29,289
running. You

982
00:36:29,289 --> 00:36:31,289
can also go back to your evaluation job

983
00:36:31,289 --> 00:36:33,570
and look at different evaluation steps and

984
00:36:33,570 --> 00:36:34,409
their progress.

985
00:36:44,340 --> 00:36:46,449
And then once the evaluation is, uh,

986
00:36:46,458 --> 00:36:47,449
job has completed,

987
00:36:47,739 --> 00:36:48,760
you can look at

988
00:36:49,159 --> 00:36:50,398
evaluation results.

989
00:36:51,309 --> 00:36:53,458
On the UI or you can also download

990
00:36:53,458 --> 00:36:54,898
the results via 3.

991
00:36:57,918 --> 00:36:58,719
In addition,

992
00:36:59,570 --> 00:37:01,579
When you've evaluated the job and now you want to

993
00:37:01,579 --> 00:37:03,860
deploy it, you can easily just click the deploy

994
00:37:03,860 --> 00:37:06,239
button. And deployed

995
00:37:06,239 --> 00:37:08,659
either on a SageMaker infants endpoint

996
00:37:09,039 --> 00:37:11,418
or um imported into bedrock.

997
00:37:13,119 --> 00:37:13,860
So here,

998
00:37:14,398 --> 00:37:16,179
we're choosing a StageMaker endpoint

999
00:37:16,679 --> 00:37:18,039
to deploy this model to.

1000
00:37:21,228 --> 00:37:23,610
So in this case, right now it's deploying,

1001
00:37:24,148 --> 00:37:24,849
now it's done,

1002
00:37:25,280 --> 00:37:27,349
and you can, once the model is deployed, you can

1003
00:37:27,349 --> 00:37:28,570
open the playground

1004
00:37:28,989 --> 00:37:31,179
and you can actually start chatting with the model

1005
00:37:31,179 --> 00:37:31,849
to test

1006
00:37:32,188 --> 00:37:32,918
the output.

1007
00:37:37,789 --> 00:37:39,809
Here we're just going to put some sample text.

1008
00:37:40,519 --> 00:37:42,519
And see that the model actually responds,

1009
00:37:42,809 --> 00:37:43,389
which is great.

1010
00:37:47,800 --> 00:37:48,969
Now we can.

1011
00:37:50,030 --> 00:37:51,889
Go back to our model page.

1012
00:37:52,869 --> 00:37:54,378
And in addition

1013
00:37:54,878 --> 00:37:56,300
to the metrics,

1014
00:37:56,639 --> 00:37:57,978
what we also have

1015
00:37:58,280 --> 00:38:00,500
um is other information

1016
00:38:00,500 --> 00:38:02,639
um such as a lineage.

1017
00:38:02,840 --> 00:38:04,958
So with the our lineage tool, you can see

1018
00:38:04,958 --> 00:38:07,260
all the changes that the model has gone through,

1019
00:38:07,918 --> 00:38:09,958
what data was used, what job was

1020
00:38:09,958 --> 00:38:12,039
run, what approvals were used to run

1021
00:38:12,039 --> 00:38:12,780
those jobs,

1022
00:38:13,239 --> 00:38:15,639
and what evaluations were done, etc.

1023
00:38:15,878 --> 00:38:17,918
You can also see all the training logs, and

1024
00:38:17,918 --> 00:38:20,159
this is available as the training job is executing.

1025
00:38:24,489 --> 00:38:25,110
All right.

1026
00:38:25,688 --> 00:38:27,809
So now let's move uh

1027
00:38:27,809 --> 00:38:29,849
and move to the agent guided

1028
00:38:30,168 --> 00:38:31,889
path and see how that works.

1029
00:38:33,000 --> 00:38:34,860
So again, you can choose

1030
00:38:35,679 --> 00:38:37,760
the option to customize a model with an

1031
00:38:37,760 --> 00:38:38,519
AI agent.

1032
00:38:39,179 --> 00:38:40,750
You can give your conversation a name.

1033
00:38:41,489 --> 00:38:42,478
And then you can

1034
00:38:43,539 --> 00:38:45,780
In simple language, you can describe your use

1035
00:38:45,780 --> 00:38:47,958
case. And then the agent

1036
00:38:47,958 --> 00:38:50,300
asks you questions to clarify your use case.

1037
00:38:51,168 --> 00:38:53,369
It asks you to select a

1038
00:38:53,369 --> 00:38:54,188
base model.

1039
00:38:57,219 --> 00:38:59,878
And then it generates a use case specification,

1040
00:39:00,539 --> 00:39:02,559
which describes the use case

1041
00:39:02,559 --> 00:39:04,590
and success tenets, which will

1042
00:39:04,590 --> 00:39:06,378
later be used to evaluate the model.

1043
00:39:08,030 --> 00:39:10,228
Finally, it also generates some,

1044
00:39:10,349 --> 00:39:12,628
based on your use case, it also generates some data

1045
00:39:12,628 --> 00:39:15,369
examples which you can edit or

1046
00:39:15,369 --> 00:39:17,329
uh or uh improve.

1047
00:39:18,139 --> 00:39:20,969
And then it generates a data generation specification,

1048
00:39:21,340 --> 00:39:22,599
which determines how

1049
00:39:22,938 --> 00:39:23,478
your data

1050
00:39:23,898 --> 00:39:26,099
for this model customization will be generated.

1051
00:39:27,070 --> 00:39:29,070
It also then goes ahead and generates

1052
00:39:29,070 --> 00:39:30,289
synthetic data for you,

1053
00:39:30,550 --> 00:39:33,050
uh, using the examples or using

1054
00:39:33,050 --> 00:39:35,228
uh contextual data that you provide.

1055
00:39:36,340 --> 00:39:37,418
And once that's done,

1056
00:39:37,699 --> 00:39:38,599
you can look at.

1057
00:39:39,329 --> 00:39:41,679
The samples of the synthetic data generated

1058
00:39:41,849 --> 00:39:44,110
and you can also get data quality

1059
00:39:44,530 --> 00:39:46,889
metrics such as data diversity and

1060
00:39:46,889 --> 00:39:49,369
other statistics as well as responsible AI metrics.

1061
00:39:50,389 --> 00:39:51,079
Once that's done,

1062
00:39:51,969 --> 00:39:54,340
Because we're, the, the agent recommended

1063
00:39:54,340 --> 00:39:55,239
RLVR,

1064
00:39:55,599 --> 00:39:58,019
uh, it also gives you a starting,

1065
00:39:58,199 --> 00:40:00,199
uh, reward function template based

1066
00:40:00,199 --> 00:40:02,300
on your use case which you can further edit

1067
00:40:02,719 --> 00:40:03,958
and, and approve.

1068
00:40:10,760 --> 00:40:12,789
Once you've done that, now you're ready to

1069
00:40:12,789 --> 00:40:14,010
kick off your training job.

1070
00:40:15,659 --> 00:40:16,360
You can start

1071
00:40:16,619 --> 00:40:17,280
the job

1072
00:40:17,539 --> 00:40:19,539
just by talking to the agent and then you can

1073
00:40:19,539 --> 00:40:20,360
also review

1074
00:40:20,938 --> 00:40:23,079
and monitor the training progress

1075
00:40:23,579 --> 00:40:24,559
within the same screen.

1076
00:40:25,030 --> 00:40:26,139
Once your training is done,

1077
00:40:26,500 --> 00:40:28,610
you can also review the evaluation

1078
00:40:28,610 --> 00:40:30,739
criteria in tenets and make any revisions

1079
00:40:30,739 --> 00:40:32,769
to it. Once you approve it,

1080
00:40:32,929 --> 00:40:35,329
the agent goes and runs the evaluation.

1081
00:40:36,639 --> 00:40:37,760
Once that's done,

1082
00:40:38,239 --> 00:40:39,659
you can easily see

1083
00:40:40,599 --> 00:40:41,840
the evaluation results.

1084
00:40:45,378 --> 00:40:47,659
So here you see that the fine-tuned

1085
00:40:47,659 --> 00:40:49,739
model actually performed much better

1086
00:40:49,739 --> 00:40:52,300
than the base model on a number of different metrics.

1087
00:40:53,409 --> 00:40:55,539
And after that, you can also go and

1088
00:40:55,539 --> 00:40:57,039
deploy the model,

1089
00:40:57,500 --> 00:41:00,099
um, from the models page to StageMaker

1090
00:41:00,099 --> 00:41:00,780
or Bedrock.

1091
00:41:02,289 --> 00:41:04,909
So to summarize, there are 3 important pillars

1092
00:41:04,909 --> 00:41:07,329
when it comes to model development on Sagemaker AI.

1093
00:41:07,760 --> 00:41:09,070
The first is of choice,

1094
00:41:09,409 --> 00:41:11,449
and we use this as a core design tenet in

1095
00:41:11,449 --> 00:41:12,409
all our capabilities.

1096
00:41:13,389 --> 00:41:15,469
Where we offer choice of different models that

1097
00:41:15,469 --> 00:41:16,878
you can use and customize,

1098
00:41:17,309 --> 00:41:19,659
choice of different customization techniques,

1099
00:41:19,989 --> 00:41:21,989
and also choice of different interfaces from

1100
00:41:21,989 --> 00:41:23,590
UI to SDK2 agent.

1101
00:41:24,659 --> 00:41:26,079
We also focus on efficiency,

1102
00:41:26,458 --> 00:41:28,500
so with the new server-less experience, you don't

1103
00:41:28,500 --> 00:41:30,478
have to worry about infrastructure management,

1104
00:41:30,820 --> 00:41:32,820
and it reduces the time for

1105
00:41:32,820 --> 00:41:35,139
customizing your models from months to days.

1106
00:41:36,610 --> 00:41:37,889
When you're doing AI at scale,

1107
00:41:38,289 --> 00:41:40,329
doing it safely and securely is,

1108
00:41:40,409 --> 00:41:41,579
uh, is really important.

1109
00:41:42,010 --> 00:41:42,909
So with built-in

1110
00:41:43,570 --> 00:41:45,489
governance and lineage capabilities,

1111
00:41:45,769 --> 00:41:47,280
you don't have to worry about,

1112
00:41:47,639 --> 00:41:49,668
you know, how your models are being

1113
00:41:49,668 --> 00:41:51,728
used and who has access to what, and

1114
00:41:51,728 --> 00:41:53,728
you have full visibility into the changes

1115
00:41:53,728 --> 00:41:55,728
that have gone into the model. Plus also you can

1116
00:41:55,728 --> 00:41:56,809
securely, you know,

1117
00:41:57,079 --> 00:41:58,750
control access with IM

1118
00:41:59,119 --> 00:42:01,168
and run these jobs in your VPC.

1119
00:42:02,639 --> 00:42:04,679
All right. So now, let's move on to

1120
00:42:04,679 --> 00:42:06,679
talk about how you can build with Amazon

1121
00:42:06,679 --> 00:42:08,820
Nova on StageMaker, and for that, I'll call upon

1122
00:42:09,199 --> 00:42:10,438
my colleague Mark Andrews.

1123
00:42:11,168 --> 00:42:12,599
Awesome. Thank you, Ankar.

1124
00:42:15,300 --> 00:42:16,449
Alright, hey folks,

1125
00:42:16,829 --> 00:42:18,989
um, hopefully, or you may have seen the

1126
00:42:18,989 --> 00:42:21,148
announcement on Tuesday about Amazon

1127
00:42:21,148 --> 00:42:24,349
Nova, and we had a talk yesterday, uh, 33:25

1128
00:42:24,349 --> 00:42:26,030
if I'm remembering, uh, correctly,

1129
00:42:26,389 --> 00:42:28,469
um, so we're excited to go into this in

1130
00:42:28,469 --> 00:42:30,010
a little detail here again too.

1131
00:42:30,309 --> 00:42:32,769
This is a bit of a refresh if any of you were in that session

1132
00:42:32,769 --> 00:42:34,869
yesterday, but, uh, we'll blast through it. There is

1133
00:42:34,869 --> 00:42:36,090
a little bit of new content.

1134
00:42:36,510 --> 00:42:37,668
OK, so roughly.

1135
00:42:38,500 --> 00:42:39,159
Um,

1136
00:42:39,550 --> 00:42:41,550
you all operate in an environment

1137
00:42:41,550 --> 00:42:43,228
where you have lots of intellectual property,

1138
00:42:43,510 --> 00:42:45,628
your own proprietary data, which is unique

1139
00:42:45,628 --> 00:42:47,969
to your company. So this is the whole concept

1140
00:42:47,969 --> 00:42:49,989
of Nova Forge. Essentially we're

1141
00:42:49,989 --> 00:42:51,969
allowing you to bridge this gap here between

1142
00:42:52,898 --> 00:42:55,090
foundation model knowledge on the left

1143
00:42:55,099 --> 00:42:57,389
and organizational knowledge, which is

1144
00:42:57,389 --> 00:42:59,699
essentially central to your company. So

1145
00:42:59,699 --> 00:43:00,570
we want to

1146
00:43:00,869 --> 00:43:03,869
essentially bridge that divide through the

1147
00:43:03,869 --> 00:43:05,688
program we're calling NovaForge.

1148
00:43:07,239 --> 00:43:08,610
Just to kind of recap, like,

1149
00:43:09,010 --> 00:43:11,239
uh, to help you kind of level set on, you know, why is

1150
00:43:11,239 --> 00:43:12,659
Forge useful, um,

1151
00:43:13,000 --> 00:43:15,179
there are many different techniques you can use from,

1152
00:43:15,239 --> 00:43:17,829
uh, on the top left here. This is like the rag-based

1153
00:43:17,829 --> 00:43:19,958
approach where you're essentially bringing

1154
00:43:19,958 --> 00:43:21,958
knowledge context from an external source into the

1155
00:43:21,958 --> 00:43:24,039
model. Um, on the top right,

1156
00:43:24,110 --> 00:43:25,340
we have adaptations,

1157
00:43:25,760 --> 00:43:26,438
which is

1158
00:43:27,519 --> 00:43:29,760
Laura-based fine tuning is the example here where

1159
00:43:29,760 --> 00:43:31,840
you're you're essentially enhancing, you

1160
00:43:31,840 --> 00:43:34,059
know, the foundation model a small bit

1161
00:43:34,059 --> 00:43:35,579
in, in various dimensions.

1162
00:43:36,320 --> 00:43:38,369
On the bottom left we have expansion. This is

1163
00:43:38,369 --> 00:43:40,449
essentially where CPT with open weights

1164
00:43:40,449 --> 00:43:42,809
models might come in, but as you can see from the graphic

1165
00:43:42,809 --> 00:43:44,889
here, the risk there is it catastrophically

1166
00:43:44,889 --> 00:43:45,688
forgets

1167
00:43:46,208 --> 00:43:48,728
basic things that the model needs to be

1168
00:43:48,728 --> 00:43:50,789
pretty proficient in like instruction following.

1169
00:43:51,090 --> 00:43:52,789
And then on the bottom right hand side,

1170
00:43:53,208 --> 00:43:55,610
building your own model from scratch. However, building

1171
00:43:55,610 --> 00:43:57,610
your own model from scratch is enormously expensive

1172
00:43:57,610 --> 00:43:58,449
and time consuming.

1173
00:44:00,010 --> 00:44:02,039
So that's why we are excited to

1174
00:44:02,039 --> 00:44:03,059
announce Nova Forge.

1175
00:44:03,840 --> 00:44:05,869
This bridges that gap. It essentially

1176
00:44:06,429 --> 00:44:08,728
allows you to accelerate building your own foundation

1177
00:44:08,728 --> 00:44:10,809
model, leveraging all of the benefits

1178
00:44:10,809 --> 00:44:12,958
of the Sagemaker platform that Ankara

1179
00:44:12,958 --> 00:44:14,949
went into. Sagemaker is the

1180
00:44:15,289 --> 00:44:17,929
best infrastructure platform in the world to

1181
00:44:17,929 --> 00:44:20,128
build your own foundation model, and that's why NovaForge

1182
00:44:20,128 --> 00:44:20,969
is built on top of it.

1183
00:44:22,250 --> 00:44:24,510
So just as a quick recap, like, uh,

1184
00:44:24,530 --> 00:44:26,050
on Tuesday,

1185
00:44:26,519 --> 00:44:28,610
Matt Garman basically announced the

1186
00:44:28,610 --> 00:44:30,688
newer generation models, so the second generation

1187
00:44:30,688 --> 00:44:32,840
models that are here on the slide, that's Nova 2 Lite,

1188
00:44:32,969 --> 00:44:34,030
um, and on the bottom,

1189
00:44:34,510 --> 00:44:36,829
we have the early access models, Nova 2 Pro

1190
00:44:36,829 --> 00:44:38,530
and uh Nova 2 Omni.

1191
00:44:39,179 --> 00:44:41,179
Um, as you, if you have

1192
00:44:41,179 --> 00:44:43,280
seen it, you, you will also see that the

1193
00:44:43,280 --> 00:44:45,340
performance of these models on the, uh, third

1194
00:44:45,340 --> 00:44:47,000
party validated benchmarks

1195
00:44:47,300 --> 00:44:49,320
are very equivalent to

1196
00:44:49,320 --> 00:44:51,239
the leading models from, um,

1197
00:44:51,539 --> 00:44:53,619
uh, all of the other leading model providers.

1198
00:44:53,739 --> 00:44:55,860
So if you start with Nova Forge,

1199
00:44:56,139 --> 00:44:58,329
especially our Nova 2 family, you're starting from a

1200
00:44:58,329 --> 00:45:00,820
great baseline. OK,

1201
00:45:00,949 --> 00:45:03,099
so roughly Ankara went into this in detail, so

1202
00:45:03,099 --> 00:45:04,599
I'll breeze through some of this,

1203
00:45:04,898 --> 00:45:05,699
essentially.

1204
00:45:07,208 --> 00:45:09,188
You start with an empty model. Um,

1205
00:45:09,489 --> 00:45:11,530
this is where this is ultimately giving

1206
00:45:11,530 --> 00:45:13,570
you a precursor with respect to how you, how you build

1207
00:45:13,570 --> 00:45:15,570
this, uh, how you build a model from scratch.

1208
00:45:15,750 --> 00:45:17,929
Uh, you start with the scaffolding, essentially the

1209
00:45:17,929 --> 00:45:19,039
foundation model scaffolding.

1210
00:45:19,800 --> 00:45:22,188
The base model is built by through the pre-training,

1211
00:45:22,250 --> 00:45:24,320
um, uh, which Anchor explained

1212
00:45:24,320 --> 00:45:26,489
earlier, and then mid-training where you kind of refine

1213
00:45:26,489 --> 00:45:27,550
the context. Uh,

1214
00:45:27,809 --> 00:45:28,708
Think of it like a,

1215
00:45:29,050 --> 00:45:31,050
a pre-training being like the Grey's

1216
00:45:31,050 --> 00:45:32,668
Anatomy medical text,

1217
00:45:33,010 --> 00:45:35,530
and mid-training might be, I want to specialize in dermatology.

1218
00:45:36,260 --> 00:45:38,739
And then on the right hand side is your fully fine-tuned

1219
00:45:38,739 --> 00:45:40,780
model where you might er tweak like various

1220
00:45:40,780 --> 00:45:43,239
clinical practices and so on, based on your business.

1221
00:45:45,969 --> 00:45:48,039
These are, this, this is kind of the same thing again.

1222
00:45:48,090 --> 00:45:50,250
It's essentially taking your um er

1223
00:45:50,250 --> 00:45:52,349
on on on the previous slide, taking your,

1224
00:45:52,449 --> 00:45:53,510
uh, if we could go back.

1225
00:45:54,260 --> 00:45:56,300
Uh, it's, it's taking your long form context,

1226
00:45:56,429 --> 00:45:58,789
text, essentially like the Gray's, uh, medical

1227
00:45:58,789 --> 00:45:59,628
anatomy, uh,

1228
00:46:00,469 --> 00:46:02,070
anatomy, um, plus, um,

1229
00:46:02,590 --> 00:46:04,849
the second is, uh, you know, your focus into,

1230
00:46:04,989 --> 00:46:07,378
uh, dermatology, and the third is,

1231
00:46:07,469 --> 00:46:08,469
uh,

1232
00:46:08,929 --> 00:46:11,110
uh, post-training like fine tuning, and as anchor

1233
00:46:11,110 --> 00:46:11,909
also explained.

1234
00:46:12,489 --> 00:46:14,550
You have SFT and RL. Like SFT.

1235
00:46:15,128 --> 00:46:17,329
One example I like to think of just to keep it simple is like

1236
00:46:17,329 --> 00:46:19,570
dog training, right? SFT is like your obedience

1237
00:46:19,570 --> 00:46:21,590
school training. There's this is teaching the dog the basic

1238
00:46:21,590 --> 00:46:23,708
concepts like sit, uh, roll,

1239
00:46:23,829 --> 00:46:25,728
um, er, etc.

1240
00:46:26,208 --> 00:46:28,289
Um, RL is essentially you take the dog to the park.

1241
00:46:28,530 --> 00:46:30,849
Now there's lots of different distractions. There's a,

1242
00:46:31,168 --> 00:46:33,398
um, maybe you want to teach the dog new techniques.

1243
00:46:33,478 --> 00:46:35,570
This is where you essentially provide reward functions,

1244
00:46:35,610 --> 00:46:37,728
like in this case, if the dog does something good, you give it a treat.

1245
00:46:37,878 --> 00:46:39,929
If it doesn't do something that you want, you

1246
00:46:39,929 --> 00:46:40,728
say no. Um,

1247
00:46:41,360 --> 00:46:43,360
and essentially ultimately the end result is you

1248
00:46:43,360 --> 00:46:45,429
have a very aligned post-trained

1249
00:46:45,429 --> 00:46:47,840
model that behaves exactly how you want it to behave.

1250
00:46:49,869 --> 00:46:51,030
So building with Nova Forge,

1251
00:46:51,869 --> 00:46:53,489
the exciting part here, there are

1252
00:46:53,829 --> 00:46:55,909
5 key things that we've done here, um,

1253
00:46:56,030 --> 00:46:58,148
access to model checkpoints across all phases

1254
00:46:58,148 --> 00:47:00,469
of model development. I'll show that briefly on the

1255
00:47:00,469 --> 00:47:01,849
second slide after this.

1256
00:47:02,539 --> 00:47:04,668
Um, the ability to blend your proprietary

1257
00:47:04,668 --> 00:47:06,889
data with Amazon Nova curated training data.

1258
00:47:07,610 --> 00:47:09,889
Um, uh, performing reinforcement

1259
00:47:09,889 --> 00:47:11,929
learning with reward functions in your environment. This

1260
00:47:11,929 --> 00:47:13,590
is actually a key one which we will also go through,

1261
00:47:13,969 --> 00:47:16,128
um, using push button recipes. So this is

1262
00:47:16,128 --> 00:47:18,250
accelerating the modeled development cycle

1263
00:47:18,250 --> 00:47:20,628
itself and then using our responsible,

1264
00:47:20,769 --> 00:47:22,590
uh, AI toolkit if you wish.

1265
00:47:22,860 --> 00:47:24,449
Um, as we announced, uh,

1266
00:47:24,969 --> 00:47:27,409
yesterday, uh, Reddit was a key development partner

1267
00:47:27,409 --> 00:47:28,349
for us, and they built.

1268
00:47:29,489 --> 00:47:31,728
One of the world's leading moderation solutions

1269
00:47:31,728 --> 00:47:33,769
using NovaForge. Um, they couldn't do this with

1270
00:47:33,769 --> 00:47:35,789
any other model off the shelf. They used NovaForge

1271
00:47:35,789 --> 00:47:37,889
because it gave them the flexibility to create the

1272
00:47:37,889 --> 00:47:39,329
most, um, uh,

1273
00:47:39,809 --> 00:47:42,110
highly accurate profision model for their use case.

1274
00:47:45,289 --> 00:47:47,820
So building a model with Forge, essentially

1275
00:47:47,820 --> 00:47:49,929
this is exactly as we described earlier.

1276
00:47:50,010 --> 00:47:52,398
You have large volumes of unstructured

1277
00:47:52,398 --> 00:47:54,530
data. This is like the Grey's Anatomy text

1278
00:47:54,530 --> 00:47:56,030
example in the in the pre-training.

1279
00:47:56,769 --> 00:47:58,139
You have your specialist domain knowledge like the uh

1280
00:47:59,449 --> 00:48:01,489
uh dermatology in

1281
00:48:01,489 --> 00:48:03,889
your mid-training and then you have um instruction

1282
00:48:03,889 --> 00:48:06,010
following um to essentially have a

1283
00:48:06,010 --> 00:48:06,929
highly performant uh

1284
00:48:07,409 --> 00:48:09,228
uh post-train model. So in

1285
00:48:09,820 --> 00:48:11,510
looking at this, like the reason why

1286
00:48:12,250 --> 00:48:14,250
we we see a lot of advantage

1287
00:48:14,250 --> 00:48:16,329
to your businesses being able to

1288
00:48:16,329 --> 00:48:18,530
bring in your intellectual property, your i.e.

1289
00:48:18,530 --> 00:48:20,530
your, your, your assets in terms of what your company

1290
00:48:20,530 --> 00:48:21,510
is proficient in

1291
00:48:21,929 --> 00:48:22,510
is.

1292
00:48:23,179 --> 00:48:25,340
Most of the learning model, i.e., most

1293
00:48:25,340 --> 00:48:27,418
of the, again using the brain analogy from

1294
00:48:27,418 --> 00:48:29,780
earlier, neuroplasticity is highest

1295
00:48:29,780 --> 00:48:32,119
earlier in the process. This is where

1296
00:48:32,119 --> 00:48:34,320
much more data is coming into it. I think Matt

1297
00:48:34,320 --> 00:48:36,340
Garman used on Tuesday the analogy of a

1298
00:48:36,340 --> 00:48:38,199
of of a child learning a new language.

1299
00:48:38,610 --> 00:48:40,659
It's much easier for a child to learn a new language than

1300
00:48:40,659 --> 00:48:42,239
it is for an adult to use a new language.

1301
00:48:42,849 --> 00:48:44,918
Um, and as a result, like,

1302
00:48:45,019 --> 00:48:46,668
uh, before we get to the post-training phase,

1303
00:48:47,059 --> 00:48:49,349
there's much more neuroplasticity earlier

1304
00:48:49,349 --> 00:48:50,619
in the process of training,

1305
00:48:50,938 --> 00:48:52,438
which is why we believe

1306
00:48:52,699 --> 00:48:54,780
bringing your data in at that point is actually

1307
00:48:54,780 --> 00:48:56,780
much more proficient, i.e., it imbues

1308
00:48:56,780 --> 00:48:59,010
the model with the competence of your,

1309
00:48:59,099 --> 00:48:59,719
uh,

1310
00:49:00,099 --> 00:49:01,659
of your domain, uh, data.

1311
00:49:02,219 --> 00:49:04,300
And then post-training is still a very useful function.

1312
00:49:04,389 --> 00:49:06,539
This is where you refine the model and tweak it for

1313
00:49:06,539 --> 00:49:09,099
your specific, uh, uh, performance reasons.

1314
00:49:12,090 --> 00:49:14,510
So one of the key points here is

1315
00:49:14,769 --> 00:49:16,769
I mentioned earlier, catastrophic forgetting

1316
00:49:16,769 --> 00:49:18,929
is a big risk with respect to open

1317
00:49:18,929 --> 00:49:19,728
weights models.

1318
00:49:21,119 --> 00:49:23,250
The way we've helped prevent that

1319
00:49:23,250 --> 00:49:25,728
is through our proprietary

1320
00:49:25,728 --> 00:49:27,769
data mixing technique which

1321
00:49:27,769 --> 00:49:29,228
essentially allows you to blend

1322
00:49:29,849 --> 00:49:31,949
your proprietary data with Amazon's

1323
00:49:32,079 --> 00:49:33,938
Amazon Nova curated data.

1324
00:49:34,889 --> 00:49:36,938
And we'll, we'll, we'll show a slide in

1325
00:49:36,938 --> 00:49:39,099
a moment where it it essentially indicates

1326
00:49:39,099 --> 00:49:41,219
that you can blend across different domains

1327
00:49:41,219 --> 00:49:41,800
like math,

1328
00:49:42,300 --> 00:49:43,639
science, etc. etc.

1329
00:49:44,260 --> 00:49:46,260
um, and you can dial up or dial

1330
00:49:46,260 --> 00:49:48,079
down the data that you

1331
00:49:48,378 --> 00:49:50,519
want to reinforce or wanted to forget.

1332
00:49:51,168 --> 00:49:53,179
Um, but the important part is this data mixing

1333
00:49:53,179 --> 00:49:54,639
is actually critical to

1334
00:49:54,898 --> 00:49:57,070
helping prevent catastrophic forgetting. Like without

1335
00:49:57,070 --> 00:49:59,099
it, what can easily happen is if you bring in

1336
00:49:59,099 --> 00:50:00,378
too much data, the model will,

1337
00:50:00,659 --> 00:50:03,489
as I said earlier, basically forget very fundamental

1338
00:50:03,489 --> 00:50:05,579
tasks with respect to instruction following and

1339
00:50:05,579 --> 00:50:08,409
others. And

1340
00:50:08,409 --> 00:50:10,550
uh you know this is not just a hypothetical,

1341
00:50:10,989 --> 00:50:12,969
just take an example of um

1342
00:50:13,550 --> 00:50:14,090
Amazon

1343
00:50:14,559 --> 00:50:15,128
stores,

1344
00:50:15,789 --> 00:50:17,929
they improved their shopping

1345
00:50:18,668 --> 00:50:20,829
MMLU, the massive multi-site language

1346
00:50:20,829 --> 00:50:23,079
understanding, by 9.8% and

1347
00:50:23,099 --> 00:50:25,148
and indeed actually it improved by

1348
00:50:25,148 --> 00:50:27,909
2.7% on standard MMLU

1349
00:50:27,909 --> 00:50:28,429
tasks.

1350
00:50:30,500 --> 00:50:32,500
So building our model at NovaForge, there

1351
00:50:32,500 --> 00:50:34,559
are Uh, two

1352
00:50:34,559 --> 00:50:36,978
things here that, uh, that are worth mentioning,

1353
00:50:37,039 --> 00:50:39,260
um, with respect to reinforcement learning, you can,

1354
00:50:39,639 --> 00:50:41,800
um, essentially bring your reward functions into

1355
00:50:41,800 --> 00:50:44,099
the AWS environment yourself, but the,

1356
00:50:44,320 --> 00:50:46,699
the key interesting part here is that you can actually,

1357
00:50:46,719 --> 00:50:48,860
uh, incorporate your own reward functions

1358
00:50:48,860 --> 00:50:50,250
in your very own environment,

1359
00:50:50,679 --> 00:50:52,840
um, essentially, but, uh, through an API

1360
00:50:52,840 --> 00:50:53,539
that we provide.

1361
00:50:53,918 --> 00:50:56,148
This gives you much more flexibility to,

1362
00:50:56,280 --> 00:50:58,280
you know, within your own applications, essentially send

1363
00:50:58,280 --> 00:51:00,219
the signals back into um

1364
00:51:00,760 --> 00:51:03,199
the forge development environment and into SageMaker

1365
00:51:03,199 --> 00:51:05,378
um to reinforce the model

1366
00:51:05,378 --> 00:51:07,519
um live and then you can

1367
00:51:07,519 --> 00:51:09,599
essentially iterate as much as you want

1368
00:51:09,599 --> 00:51:11,918
with respect to how often you want that reinforcement

1369
00:51:11,918 --> 00:51:14,260
learning data to be incorporated into the core model.

1370
00:51:15,300 --> 00:51:17,309
And again, like, uh, you know, we've been working very

1371
00:51:17,309 --> 00:51:20,059
closely with key partners here, so cosign Cosign

1372
00:51:20,059 --> 00:51:22,188
AI, um, uh, essentially we

1373
00:51:22,188 --> 00:51:24,378
worked with them to develop this, uh,

1374
00:51:24,469 --> 00:51:26,628
API reinforcement learning solution. This

1375
00:51:26,628 --> 00:51:28,668
was one big thing that we, we, we learned from them

1376
00:51:28,668 --> 00:51:30,329
that, um, it wasn't

1377
00:51:30,628 --> 00:51:32,769
enough just simply to uh

1378
00:51:32,769 --> 00:51:34,809
incorporate their reinforcement learning data

1379
00:51:34,809 --> 00:51:36,840
into uh NovaForge to the

1380
00:51:36,840 --> 00:51:38,949
AWS environment. They wanted an API to

1381
00:51:38,949 --> 00:51:40,489
be able to uh have it, um,

1382
00:51:40,989 --> 00:51:42,590
basically push that data in real time.

1383
00:51:44,079 --> 00:51:46,199
Just talking briefly about Reddit, which I mentioned

1384
00:51:46,199 --> 00:51:47,059
as well, um,

1385
00:51:47,438 --> 00:51:49,478
they had amazing results with

1386
00:51:49,478 --> 00:51:52,019
their moderation solution. They saw a 26

1387
00:51:52,519 --> 00:51:54,750
point precision lift, which is

1388
00:51:54,750 --> 00:51:56,300
huge in, in the,

1389
00:51:56,659 --> 00:51:58,360
in the moderation use case.

1390
00:51:58,728 --> 00:52:00,780
Like they've been a key development partner here

1391
00:52:01,478 --> 00:52:03,958
again, like, like very, very successful results

1392
00:52:03,958 --> 00:52:06,019
from uh from Reddit using NovaForge.

1393
00:52:08,449 --> 00:52:10,570
So building your model with Nova Forge, like, uh, there

1394
00:52:10,570 --> 00:52:12,780
are two things here that are worth pointing out.

1395
00:52:12,929 --> 00:52:15,050
Um, we do provide push button recipes

1396
00:52:15,050 --> 00:52:16,070
so that it's easiest,

1397
00:52:16,360 --> 00:52:18,668
it's as easy as possible and fast as possible

1398
00:52:18,668 --> 00:52:20,070
for you to actually get started,

1399
00:52:20,530 --> 00:52:22,530
and then you have the maximum flexibility

1400
00:52:22,530 --> 00:52:24,090
to tweak and adjust as appropriate.

1401
00:52:26,168 --> 00:52:28,250
The other thing, you can do it all through the CLI, which

1402
00:52:28,250 --> 00:52:28,829
is on the left,

1403
00:52:29,090 --> 00:52:31,280
or you can use our UI which is on the right. The

1404
00:52:31,280 --> 00:52:33,360
other thing is you can actually interface

1405
00:52:33,360 --> 00:52:35,610
between the two. So if you want to start with the

1406
00:52:35,610 --> 00:52:37,250
UI and go to the CLI,

1407
00:52:37,648 --> 00:52:39,688
you can. You can also go back to the UI if you start with

1408
00:52:39,688 --> 00:52:41,969
the CLI later too, so they're they're, they're

1409
00:52:41,969 --> 00:52:44,329
fully reinforcing one another. So that gives you maximum

1410
00:52:44,329 --> 00:52:46,469
flexibility to. Be able to speed up or slow down

1411
00:52:46,469 --> 00:52:48,750
or leverage the more bin

1412
00:52:48,750 --> 00:52:50,789
pack techniques as appropriate and then actually on the

1413
00:52:50,789 --> 00:52:52,829
right hand side of the UI you can

1414
00:52:52,829 --> 00:52:54,929
see this is our data mixing UI so you can

1415
00:52:54,929 --> 00:52:57,030
see like for entertainment, you can dial it up to 5%

1416
00:52:57,030 --> 00:52:59,110
or whatever for factual you can have it at a higher

1417
00:52:59,110 --> 00:53:01,110
percentage for legal, you can turn it off if you wish,

1418
00:53:01,188 --> 00:53:03,228
etc. and that's a pretty long

1419
00:53:03,228 --> 00:53:04,168
list of

1420
00:53:05,590 --> 00:53:07,829
data mixing categories that you can actually dial

1421
00:53:07,829 --> 00:53:09,869
up or down, dial down as appropriate.

1422
00:53:10,719 --> 00:53:13,110
The other thing we have, uh, again, you can monitor,

1423
00:53:13,148 --> 00:53:15,309
of course, the er the training process

1424
00:53:15,309 --> 00:53:17,389
itself, and again this is reinforced by the

1425
00:53:17,389 --> 00:53:18,570
StageMaker platform.

1426
00:53:19,188 --> 00:53:20,250
So you have the full

1427
00:53:20,550 --> 00:53:22,829
um status of your

1428
00:53:22,829 --> 00:53:24,909
training jobs as they're running through the process

1429
00:53:24,909 --> 00:53:25,469
end to end.

1430
00:53:26,949 --> 00:53:28,208
So building with Nova Forge.

1431
00:53:30,059 --> 00:53:32,099
The main thing here is this is built on the same code

1432
00:53:32,099 --> 00:53:33,898
used to train Nova,

1433
00:53:34,219 --> 00:53:36,500
so essentially you're you're you're building on a very

1434
00:53:36,500 --> 00:53:38,039
powerful foundation model

1435
00:53:38,619 --> 00:53:39,559
as it stands.

1436
00:53:40,929 --> 00:53:43,019
The training code that is used if you

1437
00:53:43,019 --> 00:53:45,739
bring in your intellectual property is

1438
00:53:45,739 --> 00:53:48,438
essentially reinforcing

1439
00:53:48,909 --> 00:53:50,918
your domain knowledge into

1440
00:53:51,539 --> 00:53:53,699
the Nova model itself and then we're actually

1441
00:53:53,699 --> 00:53:55,478
kind of calling these novellas

1442
00:53:55,889 --> 00:53:58,139
um in terms of uh the uh unique models

1443
00:53:58,139 --> 00:54:00,179
that you may develop as as companies based

1444
00:54:00,179 --> 00:54:01,079
on your data.

1445
00:54:02,199 --> 00:54:04,250
And it's uh it is actually very important

1446
00:54:04,260 --> 00:54:05,179
important to point out that

1447
00:54:05,719 --> 00:54:08,119
these models that you develop are your models exclusively.

1448
00:54:08,199 --> 00:54:09,619
We do not have access to them,

1449
00:54:09,918 --> 00:54:12,519
no one else has access to them. It's completely your flexibility

1450
00:54:12,519 --> 00:54:13,659
to do with them as you wish.

1451
00:54:15,030 --> 00:54:15,789
You

1452
00:54:17,969 --> 00:54:20,010
You can, um, if you wish,

1453
00:54:20,128 --> 00:54:22,159
obviously, you know, if you have customers,

1454
00:54:22,208 --> 00:54:24,530
if you're an ISV or whatnot, actually expose

1455
00:54:24,530 --> 00:54:26,869
those to ISVs and allow them to further fine tune

1456
00:54:26,869 --> 00:54:29,208
and so on. So you know there is maximum

1457
00:54:29,208 --> 00:54:31,090
flexibility in what you do with the model,

1458
00:54:31,610 --> 00:54:33,769
but Amazon does not have access to the model

1459
00:54:33,780 --> 00:54:35,708
itself. It's completely within your control.

1460
00:54:36,090 --> 00:54:38,349
The data is also yours. We do not see the data

1461
00:54:38,349 --> 00:54:40,628
that goes into the model training itself.

1462
00:54:41,530 --> 00:54:43,530
That is yours intellectual property and that

1463
00:54:43,530 --> 00:54:44,510
is protected for you.

1464
00:54:46,409 --> 00:54:48,610
So as I mentioned before, uh, one of the other

1465
00:54:48,610 --> 00:54:50,889
component parts that you can leverage

1466
00:54:50,889 --> 00:54:53,409
if you wish is the customizable content moderation

1467
00:54:53,409 --> 00:54:54,280
settings, um,

1468
00:54:54,688 --> 00:54:57,010
you know, as I mentioned in the Reddit example, they essentially

1469
00:54:57,010 --> 00:54:57,909
are a,

1470
00:54:58,389 --> 00:54:59,590
um, uh,

1471
00:55:00,090 --> 00:55:02,208
a moderation platform, or, or at least

1472
00:55:02,208 --> 00:55:04,208
the model they developed is a moderation

1473
00:55:04,208 --> 00:55:06,280
solution. So

1474
00:55:06,398 --> 00:55:08,639
they want to dial down all of these

1475
00:55:08,639 --> 00:55:10,679
controls because essentially they're building that capability

1476
00:55:10,679 --> 00:55:11,418
from scratch.

1477
00:55:11,949 --> 00:55:14,000
Another example, just a simple example, is if you're law

1478
00:55:14,000 --> 00:55:16,239
enforcement, you know, you don't want RAI

1479
00:55:16,239 --> 00:55:18,309
controls to be on because that's the whole point of

1480
00:55:18,309 --> 00:55:20,320
what you're doing. You're trying to get the model to process,

1481
00:55:20,398 --> 00:55:22,478
you know, potentially disturbing

1482
00:55:22,478 --> 00:55:24,679
subject matter and whatnot, and that's actually part of the

1483
00:55:24,679 --> 00:55:25,679
solution that you may want to build.

1484
00:55:26,159 --> 00:55:28,260
So you have complete flexibility to turn this up,

1485
00:55:28,438 --> 00:55:30,469
uh, to turn this on or off, and dial it

1486
00:55:30,469 --> 00:55:31,559
up and down as appropriate.

1487
00:55:33,599 --> 00:55:35,719
The other thing that's worth pointing out, um, if you

1488
00:55:35,719 --> 00:55:37,099
wish to, uh,

1489
00:55:37,438 --> 00:55:39,478
you know, some assistance or whatnot to be able

1490
00:55:39,478 --> 00:55:41,519
to help identify the right data

1491
00:55:41,519 --> 00:55:43,719
and whatnot that you may want to incorporate

1492
00:55:43,719 --> 00:55:44,958
into building your own model,

1493
00:55:45,659 --> 00:55:47,840
uh, the AWS Gen AI Innovation

1494
00:55:47,840 --> 00:55:50,039
Center is there for you. Essentially this

1495
00:55:50,039 --> 00:55:52,119
allows you to, you know, work with them in

1496
00:55:52,119 --> 00:55:54,360
a professional services context to

1497
00:55:54,360 --> 00:55:56,539
integrate your business DNA into

1498
00:55:56,800 --> 00:55:58,000
your own customized model.

1499
00:55:59,079 --> 00:56:01,000
So, I think uh just from there,

1500
00:56:01,360 --> 00:56:03,438
very excited to talk about Nova Forage.

1501
00:56:03,489 --> 00:56:05,559
Again, we couldn't do without the er the benefit

1502
00:56:05,559 --> 00:56:07,559
of the SageMaker platform. So

1503
00:56:07,559 --> 00:56:09,559
thank you all for listening and if you have any questions,

1504
00:56:09,570 --> 00:56:11,019
we're happy to take them afterwards.

1505
00:56:11,519 --> 00:56:11,878
Thank you.

