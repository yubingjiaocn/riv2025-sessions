# AWS re:Invent 2025 - SageMaker AI模型开发会议总结

## 会议概述

本次会议由AWS的Ankur和Mark Andrews主讲，重点介绍了使用Amazon SageMaker进行AI模型开发的完整解决方案。会议深入探讨了从预训练到模型定制的整个模型开发生命周期，特别强调了如何通过SageMaker构建具有竞争优势的定制化AI模型。

演讲者首先阐述了当前企业面临的核心挑战：虽然访问生成式AI模型变得容易，但由于竞争对手也能使用相同的通用模型，企业需要构建深度理解自身业务的定制化模型来创造差异化优势。会议详细介绍了SageMaker平台的各项创新功能，包括Hyperpod的无检查点训练、弹性训练、任务治理等突破性技术，以及全新发布的Amazon Nova Forge程序。

## 详细时间线与关键要点

### 00:00-05:00 开场与核心挑战
- 介绍演讲者Ankur和Mark Andrews
- 阐述企业面临的差异化挑战：通用模型无法提供竞争优势
- 强调需要构建深度理解业务的定制化模型
- 解释模型学习的阶段性过程：从通用知识到专业知识再到任务执行

### 05:00-10:00 模型学习过程类比
- 详细对比人类学习与模型学习的相似性
- 预训练阶段：如儿童通过沉浸式学习语言
- 指令调优：如中学生学习写作和遵循指导
- 偏好优化：如高中生通过反馈改进沟通
- 推理训练：如大学生学习多步骤思考和问题分解

### 10:00-15:00 预训练挑战与解决方案
- 介绍预训练阶段的复杂性和多重挑战
- 高效扩展：需要在大型GPU集群上分布式训练
- 弹性恢复：单个GPU故障会导致整个训练停止
- 利用率优化：昂贵的AI加速器集群需要保持高利用率
- 介绍SageMaker的两种训练方式：训练作业和Hyperpod

### 15:00-20:00 Hyperpod平台特性
- 支持Kubernetes和SLURM两种编排选项
- 集成TensorBoard等观测工具
- 支持PyTorch、TensorFlow、Nemo、JAX等主流框架
- 提供GPU和Trainium实例支持
- 内置故障容错和自动恢复机制

### 20:00-25:00 无检查点训练技术突破
- 传统检查点恢复的问题：级联停机、顺序恢复步骤、昂贵的检查点加载
- 无检查点训练的创新：通过点对点机制从邻近节点恢复模型状态
- 实现秒级故障恢复，无需重启基础设施或训练进程
- AWS Nova模型训练中实现95%的集群利用率

### 25:00-30:00 无检查点训练技术细节
- 优化的集体通信初始化：去除中央根服务器瓶颈
- 内存映射数据加载：通过共享内存缓存训练数据
- 进程内恢复：保持训练进程运行状态
- 点对点恢复：从健康加速器恢复模型和优化器状态

### 30:00-35:00 任务治理与资源优化
- 解决基础设施利用率不足问题
- 实时优先级调整和作业调度
- 团队和项目级别的计算资源分配
- 借贷规则：团队间自动资源共享
- 高优先级任务可抢占低优先级任务

### 35:00-40:00 弹性训练与可观测性
- 弹性训练：训练作业可根据资源可用性自动扩缩容
- 通过数据并行副本实现扩缩而不影响模型收敛
- Hyperpod可观测性：一键集成Prometheus和Grafana
- 跨栈层的预配置指标：从作业级到硬件级

### 40:00-45:00 模型定制技术
- 监督微调(SFT)：从标记的输入输出数据学习
- 强化学习(RL)：通过奖励和惩罚机制学习
- RLHF、RLAIF、RLVR三种RL变体
- 直接偏好优化(DPO)：学习主观偏好和风格

### 45:00-50:00 SageMaker统一模型定制平台
- 支持Amazon Nova和开源模型的广泛选择
- 无服务器训练作业：无需管理计算容量
- 模型评估能力：标准基准、LLM评判、自定义指标
- 无服务器MLflow：自动实验跟踪和指标记录

### 50:00-56:00 Amazon Nova Forge介绍
- Mark Andrews介绍Nova Forge程序
- 桥接基础模型知识与组织专有知识
- Nova 2系列模型：Lite、Pro、Omni
- 与Reddit等合作伙伴的成功案例
- 数据混合技术防止灾难性遗忘
- 客户专有的定制模型完全归客户所有