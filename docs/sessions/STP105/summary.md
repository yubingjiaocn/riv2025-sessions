# AWS re:Invent 2025 - PolyAI 企业级语音AI代理部署案例分享

## 会议概述

本次分享由 PolyAI 战略联盟副总裁 Michael 主讲，重点介绍了企业如何部署 PolyAI 的语音 AI 代理来实现超过 75% 的处理时间缩减，相当于替代约一千名全职员工的工作量。PolyAI 成立于 2017 年，由剑桥大学的研究人员创立，专注于将大型语言模型和 Transformer 架构应用于企业客户服务场景。目前公司已为超过 100 家企业客户部署了约 2,000 个独立 AI 代理，融资超过 1.2 亿美元，团队规模达到 280-290 人。

会议以太平洋燃气电力公司（PG&E）的实际部署案例为核心，展示了如何将传统 IVR 系统迁移到生成式 AI 解决方案。该项目成功迁移了 7,000 个意图，实现了 67% 的呼叫解决率，客户努力度降低 25%，客户满意度提升 22%。在停电高峰期，系统能够在 5 分钟内扩展 50 倍容量以应对突发流量。Michael 强调，要实现企业级规模的 AI 代理部署，需要从三个维度考虑：AI 代理应用本身、平台能力以及运营模式。

## 详细时间线与关键要点

00:00 - 01:30 | 开场介绍
- Michael 自我介绍，担任 PolyAI 战略联盟副总裁
- 会议主题：企业如何部署语音 AI 代理以节省劳动力成本
- 核心目标：展示 AI 代理如何承担约一千名全职员工的工作量

01:30 - 03:45 | PolyAI 公司背景
- 2017 年成立，三位联合创始人 Sean、Eddie 和 Nicola 来自剑桥大学
- 专注于对话系统和语音识别研究，将 Transformer 模型应用于客户服务
- 目前运营超过 2,000 个 AI 代理，服务 100+ 企业客户
- 融资超过 1.2 亿美元，投资方包括 Nvidia
- 被 Gartner 魔力象限认可为对话式 AI 平台供应商
- 团队规模 280-290 人，分布在伦敦、旧金山和纽约

03:45 - 04:30 | AWS 合作关系
- 基于 AWS 构建，可通过 AWS Marketplace 获取
- 获得 AWS 生成式 AI 能力认证及其他多项能力认证
- 已与 Amazon Connect 在美国、英国、欧洲部署多个实时项目
- 同时支持其他联络中心平台，如 Zendesk

04:30 - 06:45 | PG&E 案例介绍
- 选择公用事业公司 PG&E 作为典型案例
- 停电和账单咨询是最重要的客户交互场景
- 部署前问题：等待时间超过一小时，传统 Nuance IVR 系统难以调整
- 监管要求严格，需要在敏感时期提供准确沟通

06:45 - 07:30 | 解决方案演示
- 播放客户 Kristen Punter 与虚拟助手 Peggy 的通话录音
- 演示了账单查询场景的自然对话流程
- 系统能够通过电话直接提供账户余额信息

07:30 - 09:15 | 部署成效
- 迁移了 7,000 个意图从传统 IVR 到生成式 AI 解决方案
- 实现 67% 的呼叫解决率
- 客户努力度降低 25%
- 停电期间能在 5 分钟内扩展 50 倍容量
- 客户满意度（CSAT）提升 22%
- 目前处理约 1,600 万通电话/年

09:15 - 10:30 | 部署历程
- 强调这是一个渐进式过程，不是一蹴而就
- 从停电通知开始，逐步增加用例
- 每个新用例都需要针对语音识别、意图识别、知识库等进行调优
- 这是与多家财富 500 强企业成功合作的经验

10:30 - 14:00 | 第一支柱：AI 代理应用层面

语音理解能力（10:30 - 12:15）
- 70% 的生成式 AI 解决方案体验不佳源于语音转文本错误
- 与 Nvidia 合作构建语音转文本模型集成
- 针对不同场景训练专门模型：美国口音、英国口音、美国邮编、英国邮编、克罗地亚人名等
- 支持模型切换、词汇增强、对话中任意位置设置护栏
- 机器学习驱动的语音活动检测，自动适应呼叫者
- 基于 AWS 的架构支持即时扩展

客户参与度（12:15 - 13:15）
- 智能程度不重要，关键是客户愿意参与
- 支持多模态交互，语音为主
- 可在通话中发送表单、接收照片、视频、位置信息
- 通话不中断的情况下完成表单填写

LLM 编排（13:15 - 14:00）
- 自研 Raven 模型，基于 AWS 训练
- 正在通过 SageMaker 和 Bedrock 提供模型
- 针对客户服务对话场景进行微调
- 支持对话中任意位置触发函数调用和集成（同步/异步）
- 推理使用专用实例，不共享资源
- 提供架构灵活性，满足企业数据处理和托管要求

14:00 - 18:30 | 第二支柱：平台能力

可观测性（14:00 - 15:30）
- 提供核心元数据和自定义业务指标
- 跟踪对话上下文状态和历史
- 记录每个步骤的 LLM 输入输出
- 提供完整转录和录音
- 支持查看完整 LLM 请求用于调试
- 可视化延迟分析，识别瓶颈来源（语音识别、LLM、函数调用、文本转语音）

协作体验（15:30 - 17:15）
- 成熟度阶梯模型：
  - 第一阶段：支持多用户、权限管理、多环境
  - 第二阶段：审计跟踪，记录变更历史和版本
  - 第三阶段：支持同时编辑多个草稿并合并
  - 终极目标：原生开发者副驾驶，无需编写 Python 代码即可构建语音 AI 代理

分析与洞察（17:15 - 18:30）
- 通过自然语言创建自定义分析指标
- 使用 Amazon QuickSight 作为仪表板解决方案
- 利用 Bedrock 和 Anthropic 模型提供智能分析能力
- 支持用自然语言查询数百万通电话的对话数据

18:30 - 20:00 | 第三支柱：运营模式
- 不仅需要前置部署工程师
- 提供解决方案架构顾问
- 配备产品解决方案经理，协助企业规划 AI 代理改进周期
- 提供对话设计师，将企业品牌体验融入 AI 代理
- 专业团队判断问题根源（语音识别、LLM 还是文本转语音）

20:00 - 21:00 | 总结与问答
- 重申三大支柱：AI 代理、平台、运营模式
- 强调企业级部署需要全方位能力支持
- 开放现场问答环节