1
00:00:00,008 --> 00:00:01,929
Great. Good afternoon, reinvent.

2
00:00:02,250 --> 00:00:04,250
Uh, I wanna start by

3
00:00:04,250 --> 00:00:06,230
letting you guys in on a little secret.

4
00:00:07,019 --> 00:00:09,250
This is the best one. Many of the fastest

5
00:00:09,250 --> 00:00:11,489
moving companies and engineering

6
00:00:11,489 --> 00:00:13,689
teams in the world don't use GitHub

7
00:00:13,689 --> 00:00:15,069
for code review anymore.

8
00:00:15,970 --> 00:00:17,309
Now what do I mean by that?

9
00:00:18,129 --> 00:00:20,199
What I mean is that they've realized

10
00:00:20,199 --> 00:00:22,239
that this new era of agentic software

11
00:00:22,239 --> 00:00:22,859
development

12
00:00:23,280 --> 00:00:25,359
requires a whole new platform for

13
00:00:25,359 --> 00:00:27,388
code review that can keep up with the pace

14
00:00:27,388 --> 00:00:29,559
at which software can now be written. And that's

15
00:00:29,559 --> 00:00:31,149
exactly what we've built at Graphite.

16
00:00:31,440 --> 00:00:33,899
We are building the AI powered code review platform

17
00:00:34,240 --> 00:00:36,139
for this new age of gente software development.

18
00:00:38,259 --> 00:00:40,478
Well, let's take a quick look at Graphite before we dive in.

19
00:00:40,630 --> 00:00:42,719
Uh, we have, we are privileged

20
00:00:42,719 --> 00:00:44,829
to work with some of the fastest, um,

21
00:00:44,840 --> 00:00:46,673
and largest engineering. Teams in the world,

22
00:00:46,954 --> 00:00:49,554
teams like Shopify, Snowflake, Robinhood,

23
00:00:49,755 --> 00:00:51,914
Duolingo, uh, and it's not

24
00:00:51,914 --> 00:00:54,115
just a matter of hype. We've delivered real

25
00:00:54,115 --> 00:00:55,533
enterprise value for them.

26
00:00:55,984 --> 00:00:58,194
Shopify, for instance, um, after using

27
00:00:58,194 --> 00:01:00,194
Graphite has seen 33%

28
00:01:00,194 --> 00:01:02,435
more PRs merged, uh, per

29
00:01:02,435 --> 00:01:04,305
developer after adopting Graphite.

30
00:01:04,594 --> 00:01:06,594
Asana has shipped 21% more lines

31
00:01:06,594 --> 00:01:08,674
of code per engineer, and we've done this

32
00:01:08,674 --> 00:01:10,674
time and time again with hundreds of thousands of

33
00:01:10,674 --> 00:01:12,153
engineers across the industry.

34
00:01:14,028 --> 00:01:16,269
So before we get into how we do this

35
00:01:16,269 --> 00:01:18,469
exactly, I want to talk about why code review

36
00:01:18,469 --> 00:01:20,588
is important right now and why you can't

37
00:01:20,588 --> 00:01:23,010
just do this, uh, with any AI model.

38
00:01:24,028 --> 00:01:26,230
So starting with the first one, you know, why should we even

39
00:01:26,230 --> 00:01:28,250
care about code review? You know, isn't it enough?

40
00:01:28,308 --> 00:01:30,388
Can't we just let the AI run with this and write

41
00:01:30,388 --> 00:01:31,849
all of our code for us today?

42
00:01:32,870 --> 00:01:35,109
And I, I think that the, the answer to this,

43
00:01:35,209 --> 00:01:36,629
um, if we think about it, is that,

44
00:01:36,909 --> 00:01:38,909
you know, writing code, uh, first of all, how many

45
00:01:38,909 --> 00:01:40,948
of you guys are engineers? Raise your hand if you're,

46
00:01:41,028 --> 00:01:43,168
if you're an engineer. OK, pretty much everybody here.

47
00:01:43,269 --> 00:01:45,388
So, you know, you guys all know that writing code

48
00:01:45,388 --> 00:01:47,459
is only the first part of the story.

49
00:01:47,790 --> 00:01:49,948
You know, once we've written the code, you know, we'll

50
00:01:49,948 --> 00:01:51,709
build it locally, we'll debug.

51
00:01:52,129 --> 00:01:54,189
But after that happens, we still have to

52
00:01:54,189 --> 00:01:56,540
go through the entire out of loop process of

53
00:01:56,760 --> 00:01:58,959
getting our code reviewed, testing it,

54
00:01:59,088 --> 00:02:01,198
you know, reviewing, getting it merged, deploying

55
00:02:01,198 --> 00:02:03,519
it. And oftentimes at enterprise

56
00:02:03,519 --> 00:02:05,558
scale, uh, this is actually more of the

57
00:02:05,558 --> 00:02:07,638
bottleneck than writing it in the first place.

58
00:02:07,918 --> 00:02:09,960
Uh, even before this age of AI,

59
00:02:10,110 --> 00:02:12,399
uh, my co-founders and I all came from large companies

60
00:02:12,399 --> 00:02:14,639
like Meta and Google, where we'd often

61
00:02:14,639 --> 00:02:16,740
spend more time waiting for our co-workers

62
00:02:16,740 --> 00:02:19,000
to give us code reviews than we would actually building

63
00:02:19,000 --> 00:02:20,278
the feature in the first place.

64
00:02:21,250 --> 00:02:23,770
So, Codeview's always been a bottleneck at enterprises,

65
00:02:23,808 --> 00:02:25,308
and this has always been important.

66
00:02:26,129 --> 00:02:28,210
But now, AI is making this 10 times

67
00:02:28,210 --> 00:02:30,669
worse because every engineer has these incredible

68
00:02:30,669 --> 00:02:33,278
tools like quad code, cursor,

69
00:02:33,449 --> 00:02:35,449
you know, Windsurf, that they're able to use

70
00:02:35,449 --> 00:02:37,629
to build features faster than ever.

71
00:02:38,050 --> 00:02:40,050
But again, this is just shifting

72
00:02:40,050 --> 00:02:42,159
this bottleneck over to the right here, like all

73
00:02:42,159 --> 00:02:44,229
of that. That code still needs to be

74
00:02:44,229 --> 00:02:46,229
reviewed. It still needs to be tested, merged,

75
00:02:46,240 --> 00:02:47,069
and deployed.

76
00:02:47,409 --> 00:02:49,469
Uh, and now what we're finding and hearing from many

77
00:02:49,469 --> 00:02:51,868
of our largest customers is that their engineers

78
00:02:51,868 --> 00:02:53,909
are just drowning in PRs. They can't

79
00:02:53,909 --> 00:02:55,088
find enough time in the day

80
00:02:55,349 --> 00:02:57,429
to review the PRs that their teams can

81
00:02:57,429 --> 00:02:58,508
now can now create.

82
00:03:00,409 --> 00:03:02,409
I thought that this tweet really summarized it

83
00:03:02,409 --> 00:03:02,949
well.

84
00:03:03,490 --> 00:03:05,788
The new bottleneck is no longer doing the work,

85
00:03:06,008 --> 00:03:07,349
it's reviewing the work.

86
00:03:09,058 --> 00:03:11,069
So this is our conclusion number one.

87
00:03:11,460 --> 00:03:13,740
This, in this new age of AI codegen

88
00:03:14,020 --> 00:03:16,179
needs AI code review if we're going

89
00:03:16,179 --> 00:03:18,219
to truly unlock the power of LLMs

90
00:03:18,219 --> 00:03:19,399
for generating code.

91
00:03:20,819 --> 00:03:21,740
Put another way,

92
00:03:22,020 --> 00:03:24,038
you can't just apply AI to the

93
00:03:24,038 --> 00:03:26,050
IDE. You kind of need to apply

94
00:03:26,050 --> 00:03:28,099
it to your entire toolchain if you

95
00:03:28,099 --> 00:03:30,258
want to really get the most out of what LLMs

96
00:03:30,258 --> 00:03:31,679
can do for software development.

97
00:03:33,439 --> 00:03:35,550
So, you know, that answers the first question, but,

98
00:03:35,719 --> 00:03:36,740
you know, now you're probably thinking,

99
00:03:37,008 --> 00:03:39,118
why can't we just rely on the base LLMs? Like,

100
00:03:39,360 --> 00:03:41,520
isn't, isn't loud code and GPT

101
00:03:41,520 --> 00:03:43,520
5 good enough on their own to,

102
00:03:43,679 --> 00:03:45,758
to be a reviewer? Like, can't we just hack something

103
00:03:45,758 --> 00:03:47,830
together, throw it in a GitHub action, and, and let

104
00:03:47,830 --> 00:03:48,460
it run?

105
00:03:49,719 --> 00:03:51,875
Well, this was actually the first thing. That we did when

106
00:03:51,875 --> 00:03:53,875
we tried to build this. So, in the

107
00:03:53,875 --> 00:03:56,344
beginning, uh, we started before, uh, before

108
00:03:56,344 --> 00:03:58,395
AI was, was really powerful. Uh, we

109
00:03:58,395 --> 00:04:00,514
were just building a workflow tool, and the

110
00:04:00,514 --> 00:04:02,713
first approach that we had to this when we were experimenting

111
00:04:02,713 --> 00:04:05,034
was, you know, let's just take the code diff

112
00:04:05,153 --> 00:04:07,493
and give it to Claude and see what happens. So,

113
00:04:07,594 --> 00:04:08,413
we tried that.

114
00:04:09,419 --> 00:04:11,580
And these are some of the common responses we get. Things

115
00:04:11,580 --> 00:04:13,699
like, you know, you should update the code to just do what it's

116
00:04:13,699 --> 00:04:14,599
doing already.

117
00:04:15,058 --> 00:04:17,000
You know, CSS doesn't work this way.

118
00:04:17,619 --> 00:04:19,660
You should add a comment here, this is a really common

119
00:04:19,660 --> 00:04:21,778
one, you know, or even you should just revert

120
00:04:21,778 --> 00:04:24,119
this code to do exactly what it used to do.

121
00:04:25,139 --> 00:04:27,338
You know, it's kind of like you just dropped an intern into your

122
00:04:27,338 --> 00:04:29,369
code base in their first week on the job and

123
00:04:29,369 --> 00:04:31,759
expected them to do complicated refactors.

124
00:04:33,250 --> 00:04:35,369
So, this is the second major realization that

125
00:04:35,369 --> 00:04:37,488
we had, was that the LLMs are

126
00:04:37,488 --> 00:04:39,689
trained in RL to generate code in

127
00:04:39,689 --> 00:04:40,399
seconds,

128
00:04:40,769 --> 00:04:43,009
but reviewing and understanding

129
00:04:43,009 --> 00:04:45,129
of code is a much harder problem that

130
00:04:45,129 --> 00:04:47,189
needs a lot of specialized engineering.

131
00:04:47,649 --> 00:04:50,009
Uh, it's an instance of what's called the, the generator

132
00:04:50,009 --> 00:04:52,269
validator gap in LLM research, where

133
00:04:52,449 --> 00:04:54,709
LLMs are fantastic at generating

134
00:04:54,709 --> 00:04:56,649
valid examples of something.

135
00:04:57,059 --> 00:04:59,178
But they're much worse at understanding and, and

136
00:04:59,178 --> 00:05:01,338
validating uh why something

137
00:05:01,338 --> 00:05:03,699
is valid. Like they can't exactly introspect

138
00:05:03,699 --> 00:05:05,699
and tell you, you know, why is this correct, like

139
00:05:05,699 --> 00:05:07,738
why is this matching the pattern that it, that we want it

140
00:05:07,738 --> 00:05:09,559
to. So,

141
00:05:09,889 --> 00:05:11,230
that was the second major realization,

142
00:05:11,608 --> 00:05:13,730
uh, and that really brings us to this 3rd

143
00:05:13,730 --> 00:05:15,798
point, um, and the most interesting question,

144
00:05:16,009 --> 00:05:18,048
you know, how is Graphite achieving

145
00:05:18,048 --> 00:05:20,209
this? Like, how are we helping enterprises ship

146
00:05:20,209 --> 00:05:22,369
code faster in this new era of AI?

147
00:05:23,889 --> 00:05:25,449
And it's a multi-pronged approach.

148
00:05:25,730 --> 00:05:28,048
It's not enough just to drop in an agent

149
00:05:28,048 --> 00:05:30,048
that reviews code, you really need the whole

150
00:05:30,048 --> 00:05:32,410
platform for code review and reimagining

151
00:05:32,410 --> 00:05:34,410
the pull request experience completely end to

152
00:05:34,410 --> 00:05:36,428
end. And that's exactly what we've done.

153
00:05:36,588 --> 00:05:39,048
So, first of all, we have an AI review agent,

154
00:05:39,259 --> 00:05:41,309
uh, that scans every pull request in a few

155
00:05:41,309 --> 00:05:43,389
seconds. It's able to find bugs,

156
00:05:43,629 --> 00:05:45,829
security vulnerabilities, any of the common

157
00:05:45,829 --> 00:05:47,910
issues that a developer would, would be looking for

158
00:05:47,910 --> 00:05:48,949
in a code review, but

159
00:05:49,309 --> 00:05:51,309
instead of waiting potentially hours overnight for

160
00:05:51,309 --> 00:05:53,309
a co-worker to give you a review, this will give

161
00:05:53,309 --> 00:05:55,829
you the review in a few seconds. So, you save

162
00:05:55,829 --> 00:05:58,108
hours of back and forth, what would have been like

163
00:05:58,108 --> 00:06:00,149
many, many review cycles now can

164
00:06:00,149 --> 00:06:01,509
be condensed down into one.

165
00:06:02,769 --> 00:06:04,889
We've combined that though with a best in class

166
00:06:04,889 --> 00:06:07,410
code review experience. So we have an inbox

167
00:06:07,410 --> 00:06:09,500
that unifies your workflow and shows you

168
00:06:09,500 --> 00:06:11,608
exactly what PRs are waiting on your review,

169
00:06:11,809 --> 00:06:13,850
where your changes are in progress.

170
00:06:14,209 --> 00:06:16,369
It's amazing that in, in 10 years, GitHub has

171
00:06:16,369 --> 00:06:18,410
not built a way to just organize your workflow

172
00:06:18,410 --> 00:06:19,608
and see what you need to do.

173
00:06:19,970 --> 00:06:21,949
That's the first thing you see when you log into raftite.

174
00:06:22,838 --> 00:06:25,278
We also bring you smarter self-fueling CI,

175
00:06:25,439 --> 00:06:27,559
so graphite agent will suggest if a test

176
00:06:27,559 --> 00:06:29,639
is failing, uh, it'll suggest a fix,

177
00:06:29,798 --> 00:06:31,959
uh, and, and let you just rerun it, requeue

178
00:06:31,959 --> 00:06:33,548
it, um, and get that unblocked.

179
00:06:33,838 --> 00:06:35,959
We're about to introduce merge conflict resolution

180
00:06:35,959 --> 00:06:38,000
as well. So if, if something is failing

181
00:06:38,000 --> 00:06:40,230
in merge, graphite agent will fix it for you,

182
00:06:40,439 --> 00:06:42,439
uh, get your quick sign off and be ready to

183
00:06:42,439 --> 00:06:43,079
keep going.

184
00:06:43,629 --> 00:06:45,829
Uh, we let you measure developer productivity and

185
00:06:45,829 --> 00:06:47,910
we bring it all together, um, in a

186
00:06:47,910 --> 00:06:48,528
smaller platform.

187
00:06:50,588 --> 00:06:52,790
This is quite a quick view of what, what the new PR page

188
00:06:52,790 --> 00:06:54,829
looks like. Let me see if I can get this to play. So

189
00:06:55,069 --> 00:06:57,108
we basically have, you have your PR, but you

190
00:06:57,108 --> 00:06:59,309
have, uh, a whole chat window right

191
00:06:59,309 --> 00:07:01,410
alongside it, so. In Graphite, I can

192
00:07:01,410 --> 00:07:03,579
ask it questions, I can understand this

193
00:07:03,579 --> 00:07:05,988
change. I can have it highlight a few issues,

194
00:07:06,338 --> 00:07:08,338
and then I can actually have, uh, I can actually give

195
00:07:08,338 --> 00:07:10,439
it an instruction and work with it. So,

196
00:07:10,500 --> 00:07:12,619
in this case, I'm asking graphite agent to swap out

197
00:07:12,619 --> 00:07:14,619
the model. It's gonna actually make that

198
00:07:14,619 --> 00:07:17,238
change in line, propose a code change.

199
00:07:18,040 --> 00:07:20,350
I can open up a whole editor and view the diff

200
00:07:20,350 --> 00:07:21,379
that it's generated,

201
00:07:21,720 --> 00:07:23,959
and then with one click, I can go ahead and apply that

202
00:07:23,959 --> 00:07:25,959
change. Uh, this previously would

203
00:07:25,959 --> 00:07:27,278
have, would have taken you,

204
00:07:27,790 --> 00:07:29,838
minutes or potentially hours to like go back

205
00:07:29,838 --> 00:07:31,220
to your, to your IDE,

206
00:07:31,519 --> 00:07:33,798
make this change, you know, pull the changes in, make

207
00:07:33,798 --> 00:07:35,845
the change, push it back up. Get a

208
00:07:35,845 --> 00:07:36,574
review again.

209
00:07:36,975 --> 00:07:39,244
Now this is all just happening in a matter of seconds

210
00:07:39,244 --> 00:07:41,454
uh on Graphite's new PR page. So, yeah,

211
00:07:41,574 --> 00:07:43,613
much like what Cursor did to VS code and like

212
00:07:43,613 --> 00:07:45,613
bringing AI like right into the

213
00:07:45,613 --> 00:07:46,355
IDE,

214
00:07:46,704 --> 00:07:49,134
we're doing that with pull requests with Graphite, bringing

215
00:07:49,134 --> 00:07:51,475
an agent in real time that you can collaborate with

216
00:07:51,653 --> 00:07:52,774
right into the PR page.

217
00:07:55,220 --> 00:07:57,298
So, graphite agent, yeah, it's not just,

218
00:07:57,379 --> 00:07:59,579
it's not just a matter of, of being there and working

219
00:07:59,579 --> 00:08:01,819
with you. Uh, you know, we can really validate

220
00:08:01,819 --> 00:08:03,858
the results of this, um, and looking at, at

221
00:08:03,858 --> 00:08:05,838
the rate at which it's comments are accepted. So,

222
00:08:06,189 --> 00:08:08,750
You know, less than 4% of graphite agents' comments

223
00:08:08,750 --> 00:08:11,189
are downvoted or marked as, as not accurate,

224
00:08:11,649 --> 00:08:13,709
uh, and 55% of comments actually

225
00:08:13,709 --> 00:08:15,809
then lead to an underlying code change.

226
00:08:16,149 --> 00:08:18,269
This is always how we're measuring and validating

227
00:08:18,269 --> 00:08:20,350
that every change we make to graphite agent or every

228
00:08:20,350 --> 00:08:22,509
change graphite agent suggests is, is a good

229
00:08:22,509 --> 00:08:24,569
one and that you want it to actually lead

230
00:08:24,569 --> 00:08:26,088
to that code being changed.

231
00:08:26,889 --> 00:08:29,809
For comparison, humans are about 49%

232
00:08:29,809 --> 00:08:32,168
here, so we've actually now exceeded,

233
00:08:32,210 --> 00:08:34,479
uh, like graphite agent is now better than the vast

234
00:08:34,479 --> 00:08:36,710
majority of human code reviewers in terms of

235
00:08:36,840 --> 00:08:39,210
the percentage of their comments that actually create

236
00:08:39,210 --> 00:08:40,129
code changes in the end.

237
00:08:44,548 --> 00:08:45,399
frameworks. So,

238
00:08:45,690 --> 00:08:47,918
you know, going back to, uh, going back to the Enterprise

239
00:08:47,918 --> 00:08:50,279
Impact and talking about this, uh, Shopify

240
00:08:50,279 --> 00:08:52,320
has been one of our, our larger customers and

241
00:08:52,320 --> 00:08:54,629
one that's really worked with us and pushed us to,

242
00:08:54,700 --> 00:08:57,000
you know, help their engineering team move as quickly as possible.

243
00:08:57,359 --> 00:08:59,359
Uh, you can imagine in the past month or

244
00:08:59,359 --> 00:09:01,359
two, they were in their full sprint, getting

245
00:09:01,359 --> 00:09:03,519
ready for Black Friday and Cyber Monday. It's

246
00:09:03,519 --> 00:09:05,519
a huge, huge code push for them. Uh,

247
00:09:05,759 --> 00:09:07,798
you know, they're doing, they're doing like tens of thousands

248
00:09:07,798 --> 00:09:09,649
of PRs and lead up to this, uh.

249
00:09:10,090 --> 00:09:12,099
And with Graphite, uh, we saw real

250
00:09:12,099 --> 00:09:14,168
results in terms of developer efficiency. So

251
00:09:14,399 --> 00:09:16,570
33% more PR shipped per engineer.

252
00:09:16,678 --> 00:09:18,928
Uh, we're now up to, uh, almost

253
00:09:18,928 --> 00:09:21,330
three quarters of all PRs, um, at Shopify

254
00:09:21,330 --> 00:09:23,408
are now being merged through Graphite instead

255
00:09:23,408 --> 00:09:24,048
of GitHub.

256
00:09:24,519 --> 00:09:26,639
Um, again, hundreds of thousands of PRs that this is

257
00:09:26,639 --> 00:09:28,960
covered, and, you know, if you, if you want to really

258
00:09:28,960 --> 00:09:31,340
dig into like what is the enterprise impact of this,

259
00:09:31,558 --> 00:09:33,558
uh, we get to, you know, hundreds of

260
00:09:33,558 --> 00:09:35,719
additional engineers' worth of developer time

261
00:09:35,719 --> 00:09:37,940
saved. You know, you can imagine every single PR,

262
00:09:38,200 --> 00:09:40,599
even if you're saving an hour or two off of, off

263
00:09:40,599 --> 00:09:42,879
of review time, off of time that they would have been blocked

264
00:09:42,879 --> 00:09:44,359
waiting for somebody to unblock them.

265
00:09:44,719 --> 00:09:46,879
That's a huge amount of time over an entire

266
00:09:46,879 --> 00:09:48,879
year, uh, and a huge amount of engineering

267
00:09:48,879 --> 00:09:51,029
hours that you're now giving back to the team and,

268
00:09:51,038 --> 00:09:53,038
uh, letting them spend less time in review and

269
00:09:53,038 --> 00:09:55,038
more time doing what matters and actually being able

270
00:09:55,038 --> 00:09:55,700
to build.

271
00:09:58,178 --> 00:10:00,469
We're, you know, zooming out. We're really excited,

272
00:10:00,548 --> 00:10:02,580
uh, and, and we're proud to partner with some

273
00:10:02,580 --> 00:10:04,739
of the leading companies in the industry. So, you

274
00:10:04,739 --> 00:10:06,859
know, Robinhood, we talked about Shopify, but, you

275
00:10:06,859 --> 00:10:08,408
know, Robinhood, Snowflake,

276
00:10:08,700 --> 00:10:10,779
teams like RAM, some of the AI native companies

277
00:10:10,779 --> 00:10:13,168
like Harvey and Replet and Purcell, uh,

278
00:10:13,460 --> 00:10:15,700
really seeing across the industry, uh, like

279
00:10:15,700 --> 00:10:18,139
large adoption of this and, uh, excitement

280
00:10:18,139 --> 00:10:20,219
around what AI can do again, not just

281
00:10:20,219 --> 00:10:22,259
in the IDE but in the outer loop as

282
00:10:22,259 --> 00:10:22,798
a whole.

283
00:10:24,359 --> 00:10:26,428
You know, back to the graph I did a glance, you know,

284
00:10:26,599 --> 00:10:28,779
what we've built is the best in class code review platform

285
00:10:28,779 --> 00:10:29,869
on top of GitHub.

286
00:10:30,239 --> 00:10:32,279
We're trusted by some of the very best

287
00:10:32,279 --> 00:10:34,399
developers and teams in the industry, um, and

288
00:10:34,399 --> 00:10:36,558
we're really bringing AI to, uh, to the

289
00:10:36,558 --> 00:10:38,668
pull request process and transforming what

290
00:10:38,668 --> 00:10:40,798
code review looks like now, um, in this new era

291
00:10:40,798 --> 00:10:41,859
of software development.

292
00:10:43,989 --> 00:10:46,190
So, a few key takeaways that I want to leave you with.

293
00:10:46,349 --> 00:10:48,428
Uh, number one, you know, LLMs

294
00:10:48,428 --> 00:10:50,469
are really flooding enterprise engineering teams

295
00:10:50,469 --> 00:10:52,570
with more code than they can safely review.

296
00:10:52,908 --> 00:10:55,070
We now have, you know, not only is there more

297
00:10:55,070 --> 00:10:57,109
code being generated than ever, uh, we see

298
00:10:57,109 --> 00:10:58,788
about 70% more,

299
00:10:59,109 --> 00:11:01,229
more code per engineer, uh, now

300
00:11:01,229 --> 00:11:03,418
than we saw back in 2023. Um,

301
00:11:03,428 --> 00:11:05,548
it's just a huge amount of more, more changes

302
00:11:05,548 --> 00:11:07,908
that are being created, uh, with the help of LLMs

303
00:11:07,908 --> 00:11:08,489
now. So,

304
00:11:08,788 --> 00:11:09,509
there's more code.

305
00:11:10,058 --> 00:11:12,259
It's also less, you know, potentially like

306
00:11:12,259 --> 00:11:14,259
less valid, uh, less safe code

307
00:11:14,259 --> 00:11:16,418
than ever before because, you know, let's be real, is

308
00:11:16,418 --> 00:11:18,500
every single engineer scanning every line

309
00:11:18,500 --> 00:11:19,580
that's being generated?

310
00:11:19,859 --> 00:11:21,899
Probably not. Like they're putting, they're in a rush, they're putting

311
00:11:21,899 --> 00:11:23,940
code up, you know, we almost need, you

312
00:11:23,940 --> 00:11:25,940
know, not only just to handle the volume of

313
00:11:25,940 --> 00:11:28,379
code, uh, but the nature of AI generated

314
00:11:28,379 --> 00:11:30,538
code, you know, necessitates us to have

315
00:11:30,538 --> 00:11:32,849
better tooling around making sure that it's reviewed,

316
00:11:33,058 --> 00:11:35,298
making sure that it's safe, and making sure that it's validated.

317
00:11:36,080 --> 00:11:38,399
So, there's more code than ever before. We

318
00:11:38,399 --> 00:11:40,080
need AI code review more than ever.

319
00:11:40,609 --> 00:11:42,649
You know, traditional tools and LLMs, we

320
00:11:42,649 --> 00:11:44,808
can't just take quad code or or

321
00:11:44,808 --> 00:11:46,840
GBT-5 and throw it at this and expect it to

322
00:11:46,840 --> 00:11:48,928
do well. We really need a whole

323
00:11:48,928 --> 00:11:51,298
new platform for code review for this new era.

324
00:11:51,529 --> 00:11:53,928
Um, and that's exactly what we've delivered. You know, Graphite

325
00:11:53,928 --> 00:11:56,250
has, has built that platform. We've integrated

326
00:11:56,250 --> 00:11:58,469
AI into the entire pull request life cycle

327
00:11:58,808 --> 00:12:01,279
from the moment it's created to the moment that it's merged,

328
00:12:01,629 --> 00:12:03,649
uh, and we're delivering, you know, really great

329
00:12:03,649 --> 00:12:05,849
measurable enterprise outcomes, um, by doing

330
00:12:05,849 --> 00:12:08,469
that. Uh,

331
00:12:08,590 --> 00:12:10,629
thank you guys very much. That's all I've got for you. Uh,

332
00:12:10,710 --> 00:12:12,710
you can find us. We're on graphite.com if

333
00:12:12,710 --> 00:12:14,710
you wanna check it out. Uh, you can try the platform

334
00:12:14,710 --> 00:12:16,788
out for free, uh, for 30 days.

335
00:12:17,029 --> 00:12:19,149
Um, and we're right around the corner, um, over

336
00:12:19,149 --> 00:12:21,190
at Booth 535 if you wanna come

337
00:12:21,190 --> 00:12:23,308
check us out. Uh, we got plenty of people who can tell you

338
00:12:23,308 --> 00:12:25,629
more about the platform and the details, and, uh,

339
00:12:25,739 --> 00:12:27,558
we're excited to chat with you. So thank you very much,

340
00:12:27,830 --> 00:12:28,950
everyone. Thank you.

