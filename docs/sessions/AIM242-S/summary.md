# AWS re:Invent 2025 AI 安全会议总结

## 会议概述

本次会议深入探讨了 AI 时代的安全挑战与防护策略。演讲者（参加了12次 re:Invent）强调，AI 正在成为组织创新的主要驱动力，但同时也成为攻击者的新战场。传统的安全防护方法已经无法满足 AI 应用的需求，因为 AI 不仅仅是添加护栏或模型安全那么简单，而是需要在数据、模型、AI 管道和运行时等多个层面建立全面的防护体系。

会议指出，每个新的 AI 工作负载都可能成为攻击者的新入口。现代安全策略必须在拥抱创新的同时，保持对攻击者的领先优势。AI 安全的新战场不仅包括传统的云基础设施，还涵盖了数据、模型、AI 管道等整个生态系统。如果在这些关键节点缺乏适当的保护，可能会影响整个 AI 应用的生态系统。演讲者特别强调了用户层面的重要性，包括企业内部员工使用 AI 的风险，以及外部用户与 AI 应用交互时可能带来的安全威胁。

会议基于 Trend Micro 威胁研究团队（Alfredo Olivera 和 David Fer）的研究成果，展示了攻击者如何从容器中提取模型、操纵训练数据并重新部署，从而改变应用响应结果的真实案例。这凸显了 AI 安全需要从被动防御转向主动、自适应的防护策略。

## 详细时间线与关键要点

### **开场与背景介绍** (00:00 - 05:30)
- **00:00** - 会议开始，演讲者欢迎参会者并进行互动调查
- **01:15** - 询问参会者参加 re:Invent 的次数，演讲者分享这是自己第12次参加
- **02:30** - 回顾 Trend Micro 作为首个参与 re:Invent 的网络安全厂商的历史
- **03:45** - 引入主题：AI 如何成为创新驱动力，同时也成为攻击者的新战场

### **AI 安全的核心挑战** (05:30 - 12:00)
- **05:30** - 强调 AI 安全不仅是添加护栏或模型安全，而是多层防护
- **06:45** - 介绍 AI 攻击面的扩展：每个新 AI 工作负载都是潜在攻击向量
- **08:20** - 展示 AI 安全飞轮模型：数据、模型、AI 管道、运行时
- **09:30** - 强调用户因素的重要性：企业员工和外部客户两个维度
- **10:45** - 讨论间接攻击：通过跨站脚本等方式污染 AI 应用的数据源

### **数据投毒与模型窃取** (12:00 - 18:30)
- **12:00** - 详细解释数据投毒攻击：通过注入恶意数据操纵模型行为
- **13:30** - 介绍模型窃取威胁：模型可被窃取并在黑市转售
- **15:00** - 基于 Trend Micro 研究的案例：从容器中提取、操纵并重新部署模型
- **16:45** - 强调模型是组织的新"皇冠珠宝"，包含敏感训练数据

### **AI 管道与供应链安全** (18:30 - 25:00)
- **18:30** - 讨论 AI 管道中的多个攻击点：模型构建、后门注入、供应链
- **20:00** - 提示注入和推理攻击是最常见的利用方式
- **21:30** - Shadow AI 问题：组织缺乏对所有 AI 应用的完整可见性
- **23:00** - 分享 Reddit 案例：仅依赖模型安全而非运行时护栏导致失败
- **24:15** - 强调需要自定义护栏，不能仅依赖模型自带的安全机制

### **传统防御的局限性** (25:00 - 30:00)
- **25:00** - 指出传统防御过于被动，无法应对快速演变的 AI 威胁
- **26:30** - AI 在六个月内的变化巨大：模型漂移、管道更新、代理自动化
- **28:00** - 强调需要自适应、主动和 AI 感知的防护方法
- **29:15** - 提出在投入生产前进行风险优先级排序和缓解

### **数据层防护** (30:00 - 37:00)
- **30:00** - 介绍数据安全基础：大多数 AI 风险源于数据
- **31:30** - 展示数据可见性冰山模型：已分类数据只是表面，大量未分类数据存在风险
- **33:45** - 数据泄漏可能发生在训练、推理、日志、API 通信和模型输出等环节
- **35:30** - 提出数据安全态势管理（DSPM）解决方案
- **36:20** - 强调在训练和应用使用前监控数据集，识别敏感和知识产权数据

### **微服务与供应链防护** (37:00 - 44:00)
- **37:00** - AI 组件依赖大量库、开源应用和外部服务
- **38:30** - 单个漏洞或依赖问题可能产生多米诺效应
- **40:00** - 三大攻击向量：依赖投毒、未验证镜像、管道妥协
- **41:30** - 强调容器镜像扫描的重要性：不仅查找漏洞，还要查找密钥
- **42:45** - 发现公开容器镜像中存在明文 AWS 凭证的案例
- **43:30** - 建议为每个镜像创建签名以验证供应链完整性

### **模型与 AI 代理安全** (44:00 - 52:00)
- **44:00** - 模型和代理本身可能成为攻击向量
- **45:30** - 模型可被投毒、操纵或通过对抗性输入误导
- **47:00** - AI 代理自主行动引入全新风险类别
- **48:30** - 分享客户案例：无法控制代理的范围和行为
- **50:00** - 关键攻击向量：恶意输入、流氓代理行为、操纵输出
- **51:00** - 强调模型安全的动态性：同一问题100次查询可能有不同答案，需持续测试

### **AI 扫描器与护栏技术** (52:00 - 56:00)
- **52:00** - 介绍本周发布的 AI Scanner 新工具
- **53:00** - 功能：扫描 AI 应用和 API 端点，检测敏感数据泄露、提示注入、系统提示泄漏等
- **54:15** - 基于 OWASP Top 10 for LLMs 和生成式 AI 的风险检测
- **55:00** - 后端使用 LLM Judge 自动生成护栏，类似"AI 应用的虚拟补丁"

### **基础设施防护** (56:00 - 64:00)
- **56:00** - AI 基础设施面临资源耗尽、GPU 滥用、加密挖矿等威胁
- **57:30** - 展示基础设施防护的"城堡"模型：计算、特权访问、访问覆盖
- **59:00** - 客户主要担忧：资源耗尽、GPU 成本增加、数据泄漏
- **60:30** - 攻击向量：特权升级、云错误配置、漏洞利用
- **62:00** - 提出 AI 安全态势管理（AI SPM）：监控 Bedrock、SageMaker 等服务的错误配置
- **63:00** - 结合合规要求：EU AI Act、CSA、OWASP Top 10

### **威胁情报与日志监控** (64:00 - 68:00)
- **64:00** - 介绍 AI 模型、资源和控制的监控方法
- **65:00** - 收集 VPC Flow Logs 和 CloudTrail 日志并应用威胁情报
- **66:30** - 检测到可疑活动时，通过云检测响应（CDR）立即缓解攻击
- **67:30** - 强调对 SageMaker 和 Bedrock 的实时监控

### **网络层防护** (68:00 - 76:00)
- **68:00** - 随着 AI 应用对外开放，网络成为新的操纵路径
- **69:30** - 讨论混合基础设施场景：数据中心与云环境的连接
- **71:00** - 介绍 Trend Micro Zero Day Initiative (ZDI)：最大的企业漏洞赏金计划
- **72:30** - 去年发现市场上73%的漏洞，涵盖 AI 技术栈
- **74:00** - 与 AWS Network Firewall 集成，添加 IDS/IPS 规则保护漏洞利用
- **75:00** - 网络攻击向量：API 拦截、横向移动、数据渗透

### **API 安全警示** (76:00 - 79:00)
- **76:00** - 强调流量检测的重要性，特别是 API 流量
- **77:00** - 惊人数据：40% 的 API 端点缺乏身份验证和授权
- **78:00** - 警告：未受保护的 API 如同通往关键数据的"高速公路"
- **78:45** - 建议：所有面向互联网的 API 必须至少有身份验证，并添加 IDS/IPS 保护

### **用户层防护** (79:00 - 85:00)
- **79:00** - 人为因素是自互联网诞生以来最大的安全问题
- **80:30** - 用户错误可能导致基础设施访问权限泄露
- **81:45** - 强调访问控制、权限管理和安全意识培训
- **83:00** - 钓鱼、社会工程攻击和 AI 生成的深度伪造攻击日益增多
- **84:00** - 一次点击或一个恶意库就可能为攻击者打开大门

### **错误配置与深度伪造** (85:00 - 89:00)
- **85:00** - 错误配置问题：过度暴露的访问权限
- **86:00** - 深度伪造操纵攻击大幅增加
- **87:00** - 开发者在本地桌面创建 AI 应用的监控需求
- **88:00** - 强调监控本地 AI 应用和检测深度伪造的重要性

### **统一安全策略** (89:00 - 94:00)
- **89:00** - 总结：AI 安全需要连接从数据到用户的每一层
- **90:30** - AI 安全只有在数据、模型、管道和运行时统一在单一安全视角下才有效
- **92:00** - 警告：分散的技术无法关联遥测数据和发现，影响检测响应
- **93:30** - 强调整合的重要性以实现有效的缓解和检测响应

### **威胁研究案例** (94:00 - 98:00)
- **94:00** - 介绍会议基础研究："Silent Sabotage: Weaponizing Models and Exposed Containers"
- **95:00** - 案例详情：攻击者通过暴露的容器提取模型、操纵数据并重新部署
- **96:30** - 强调容器安全和运行时监控的重要性
- **97:30** - 容器应该是不可变的，任何更改应在推送到生产前在管道中完成

### **AI 安全蓝图** (98:00 - 结束)
- **98:00** - 介绍去年 re:Invent 创建的 AI Security Blueprint
- **99:00** - 蓝图已集成到平台中，涵盖开发者、部署、运行时、AI 工作负载、应用和数据
- **100:00** - 平台可识别环境中的每个 AI 基础设施组件并映射保护层
- **101:00** - 帮助客户识别是否启用了每层防护，防止恶意行为者攻击
- **102:00** - 为每层提供安全挑战、控制措施和平台技术的详细说明

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


核心要点总结：
- AI 安全需要多层防护，从数据到用户的全生命周期保护
- 不能仅依赖模型安全，必须建立自定义运行时护栏
- 供应链、容器镜像和 API 端点是关键攻击面
- 40% 的 API 缺乏基本身份验证，存在严重风险
- 需要从被动防御转向主动、自适应的 AI 感知安全策略
- 统一的安全视角对于关联威胁和快速响应至关重要