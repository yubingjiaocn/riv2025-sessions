# AWS re:Invent 2025 Breakout Session 总结

## 会议概述

本次会议由 Zoox 公司的 Jim Robinson Bonslav(基础模型训练技术负责人)以及 AWS 的解决方案架构师团队共同呈现,重点介绍了 Zoox 如何利用构建在 AWS 上的机器学习基础设施来训练其自动驾驶基础模型。

Zoox 是一家致力于打造全自动驾驶出租车(robotaxi)的公司,目标是让个人交通变得安全、清洁且令人愉悦。他们的车辆已在拉斯维加斯投入运营,提供免费乘车服务。自动驾驶系统面临着巨大的长尾挑战——从处理消防车、行人乱穿马路,到应对坦克车队、穿着施工指挥员服装的儿童等罕见场景。为了应对这些挑战,Zoox 采用了基于大规模基础模型的方法,构建了多模态语言动作模型(Multimodal Language Action Model),能够实现零样本学习,在首次遇到罕见事件时就能准确处理。

会议详细介绍了 Zoox 如何利用 AWS SageMaker HyperPod 进行大规模分布式训练,包括其弹性集群架构、自动故障恢复、高性能网络(EFA)以及与各种机器学习框架的集成。演讲者还分享了实施过程中遇到的挑战和解决方案,展示了如何在 AWS 云平台上构建高效、可扩展的机器学习训练平台。

## 详细时间线与关键要点

### **开场与公司介绍 (00:00 - 05:30)**

00:00 - 会议开始,Jim Robinson Bonslav 介绍自己是 Zoox 基础模型训练团队的技术负责人

00:45 - 介绍会议议程:Zoox 公司简介、基础模型用例概述、AWS SageMaker HyperPod 集成

01:15 - Zoox 公司使命介绍:让个人交通对所有人都安全、清洁且令人愉悦

01:45 - 展示 Zoox 专门设计的 robotaxi:全电动、全自动驾驶、为乘客设计

02:15 - 解释为何需要改变现状:人类驾驶车辆危险(每年大量交通事故死亡)、车辆闲置时间长、污染严重

02:45 - 宣布 Zoox 已在拉斯维加斯投入运营,展示车辆在拉斯维加斯大道行驶的视频

03:15 - 鼓励观众扫描二维码下载应用,在拉斯维加斯免费乘坐

### **自动驾驶技术架构 (05:30 - 10:00)**

05:30 - 介绍 Zoox 自动驾驶系统高层架构:车辆周围配备传感器舱

06:00 - 传感器配置:激光雷达、雷达、摄像头、热成像摄像头、麦克风等,提供 360 度视野

06:30 - 传感器具有冗余设计以防硬件故障,探测距离超过 150 米

07:00 - 自动驾驶三大支柱:感知(Perception)、预测(Prediction)、规划与控制(Planning and Controls)

07:30 - 感知系统:将传感器原始数据转换为结构化的世界理解,核心是 3D 边界框检测和跟踪

08:15 - 预测系统:预测周围所有智能体的未来可能位置,采用多模态预测(预测多个可能的未来)

09:00 - 规划与控制系统:整合感知输出、预测结果、高精地图和任务目标,生成实际控制车辆的指令

### **长尾场景挑战 (10:00 - 15:30)**

10:00 - 大多数驾驶场景简单,但某些场景极其困难

10:30 - 案例 1:高速行驶时遇到消防车在车道上放置消防水带,系统成功检测并安全绕行

11:15 - 案例 2:拉斯维加斯大道上有人横穿六车道,系统必须能处理这种不良决策

12:00 - 展示各种罕见场景图片:
- 穿着施工指挥员服装的儿童
- 坦克车队在大道上行驶
- 交通锥被放置在标志牌顶部
- 着火的汽车
- 手写的施工区标志
- 半旅游巴士半购物车的"Cartzilla"

13:30 - 更多极端案例:有人爬上 robotaxi 车顶、背着狗的骑行者

14:30 - 强调长尾问题的复杂性:边缘案例不断增加,越来越难以应对

### **基础模型方法 (15:30 - 22:00)**

15:30 - 引入 Richard Sutton 的"苦涩教训"(Bitter Lesson):70 年 AI 研究的最大教训是利用计算的通用方法最终最有效

16:30 - 展示三种模型改进路径对比图:
- 短期:大量人工工程和专业知识(针对特定任务的小模型)
- 中期:更通用的模型
- 长期:使用大量计算的简单方法(Zoox 的选择)

17:30 - Zoox 的策略:在大数据上训练大模型,不加入过多人类知识或偏见

18:00 - 目标:训练模型实现零样本学习,首次遇到罕见场景(如坦克、穿施工服的儿童)就能准确处理

18:45 - 介绍多模态语言动作模型(Multimodal Language Action Model)

19:30 - 模型输出:机器人控制(加速、制动、转向)、3D 检测、问题答案、场景描述

20:30 - 模型输入:文本提示、预训练的嵌入层、摄像头/视频数据、激光雷达和雷达数据

21:30 - 强调 LLM 核心的灵活性:可以编码并传入多种数据,包括现有感知系统的输出

### **训练流程 (22:00 - 25:30)**

22:00 - 训练流程概述:从预训练模型开始(如 Qwen 2-VL)

22:45 - 第一阶段:大规模监督微调(SFT)
- 从数万小时人类驾驶中进行行为克隆
- 数百万个 3D 检测标签
- 视觉问答、空间理解等标准 LLM 技术

23:45 - 第二阶段:小规模但高质量的 SFT
- 稀有物体检测
- 困难场景驾驶
- 合成思维链推理

24:30 - 第三阶段:强化学习
- 在最困难场景上微调机器人控制
- 使用 GRPO、DAPO 等技术

25:00 - 部署阶段:离线使用 VLM,在线集成考虑使用 TensorRT-LLM

### **训练挑战 (25:30 - 27:00)**

25:30 - 挑战 1:PB 级数据(多模态传感器数据、结构化数据)

26:00 - 挑战 2:准确性和性能权衡(尽可能高精度和低延迟)

26:30 - 挑战 3:快速可扩展的迭代(研究人员需要快速启动实验、跟踪、获取指标、运行评估)

26:45 - 挑战 4:复杂的基础设施(数据集管理、计算分配、调试训练流程)

### **AWS SageMaker HyperPod 介绍 (27:00 - 35:00)**

27:00 - AWS 解决方案架构师 Avin Kuri 接手演讲

27:30 - 询问观众中有多少人在构建基础模型或进行分布式训练

28:00 - 指出常见问题:硬件故障导致大量时间用于调试,GPU 闲置造成高成本

28:30 - SageMaker HyperPod 介绍:专为分布式训练和机器学习工作负载构建的弹性集群

29:00 - HyperPod 多功能环境架构层次:
- 基础层:存储和计算
- 支持 AWS Trainium 和 Nvidia GPU(P4、P5、P6)
- 已见过超过 500 个节点的集群

30:00 - 存储选项:Amazon S3、FSx Lustre、EFS,支持 PB 级数据直接加载到 GPU

30:45 - 高性能网络:Elastic Fabric Adapter (EFA),每个节点提供 3200 Gbps 带宽

31:30 - 运行时环境:支持 Nvidia CUDA 库和 AWS Neuron 运行时

32:00 - ML 框架和工具:PyTorch、Nemo Megatron、Kubectl、Ray 等

32:45 - 可观测性:与 Amazon CloudWatch、Amazon Managed Grafana 和 Prometheus 集成

33:30 - 编排器:支持 Slurm 和 Amazon EKS

### **HyperPod 架构 (35:00 - 38:30)**

35:00 - HyperPod 示例架构展示

35:30 - 计算节点位于 SageMaker 服务账户中,映射到客户节点

36:00 - 健康检查机制:HyperPod 控制和保护节点,故障时自动替换

36:45 - 控制节点:用于编排和处理作业的头节点

37:15 - 登录节点:保护控制节点并执行管理活动

37:45 - 内置功能:生命周期脚本、检查点机制、CloudWatch 集成

### **弹性恢复机制 (38:30 - 42:00)**

38:30 - 弹性是 HyperPod 最重要的支柱之一

39:00 - 示例场景:16 节点集群运行作业 A(8 节点)、作业 B 和 C(各 4 节点)

39:45 - 软件故障(超参数配置错误、缺少分号)通常由 ML 工程师调试修复

40:30 - 硬件故障(过热等物理问题)需要替换节点,随着节点数增加(8、16、32 个),调试时间成倍增加

41:15 - HyperPod 的自动恢复功能:基于健康检查自动替换故障节点

41:45 - HyperPod 在服务账户中保留备用节点,自动检查并替换实例,无需人工干预

### **HyperPod 核心能力 (42:00 - 44:30)**

42:00 - 能力回顾:弹性(刚讨论过)

42:30 - 可扩展性:EFA 为数百个节点提供高带宽互连

43:00 - SageMaker 灵活训练计划:预留实例,确保持续运行

43:30 - 多功能环境:支持多种框架和工具,ML 工程师可专注于编码和建模

44:00 - 效率:集成深度学习 AMI 和内置脚本,快速启动集群;CloudWatch 集成提供可观测性平台

### **训练生命周期 (44:30 - 46:00)**

44:30 - 构建基础模型的典型生命周期

45:00 - 步骤 1:收集大量数据

45:15 - 步骤 2:存储数据(使用 S3)

45:30 - 步骤 3:将数据加载到 GPU

45:45 - 步骤 4:使用高效机制和分布式训练进行模型训练

46:00 - 步骤 5:部署模型

### **Zoox 的 HyperPod 实施 (46:00 - 52:00)**

46:00 - Zoox ML 平台分布式训练负责人 Anindo 接手演讲

46:30 - HyperPod 吸引 Zoox 的关键特性:
- 大规模训练支持(FSDP、HSDP、DDP)
- EFA 支持
- 检查点功能
- 训练计划(保证 P5、P6 等昂贵实例的可用性)

47:30 - 基础模型训练平台的基本要求:
1. 分布式训练作业(多 GPU 节点,64+ GPU,FSDP/HSDP/张量并行)
2. TB 级数据流(使用 Mosaic 数据流)
3. 生产级弹性(作业运行 2-3 天,自动节点恢复)
4. 统一可观测性(EFA、GPU、FSx 指标)
5. 检查点(分布式异步检查点,自动从最后检查点恢复)

49:30 - Zoox 架构展示:
- 中心:多个 P5 和 P6 节点分区(在 SageMaker 管理的 VPC 中)
- 左侧:Zoox VPC(包含 FSx 等组件)
- 右侧:SageMaker 附加组件(Comet ML 实验跟踪、CloudWatch)

### **用户工作流程 (52:00 - 56:00)**

52:00 - 用户工作流程详解

52:30 - FSx 是系统核心,挂载到所有节点(计算节点、控制节点、登录节点)

53:00 - 工作流程步骤:
1. 用户登录到登录节点
2. 创建 Python 虚拟环境(在 FSx 上,每个实验可有独立环境)
3. 检出特定分支或 SHA,可即时修改训练代码
4. 提交作业到 Slurm 控制器(使用 sbatch)
5. Slurm 调度到计算节点,分布式训练开始
6. SageMaker 健康代理监控作业,故障时替换节点并重新启动
7. 模型输出写入检查点
8. 触发评估作业

55:00 - 强调 SageMaker 和非 SageMaker 组件可在同一 VPC 中共存协作

### **扩展技术 (56:00 - 58:30)**

56:00 - 模型训练扩展技术:
- HSDP(混合分片数据并行):跨节点使用 DP,节点内使用 FSDP
- 张量并行:对于数十亿参数的大模型,分片矩阵乘法

57:00 - 训练优化:
- BF16(计算更快,内存消耗减半)
- 梯度检查点(增加批量大小)
- Torch Compile(编译 PyTorch 图)

57:45 - EFA 网络保证跨节点的高吞吐量

### **数据平面 (58:30 - 60:30)**

58:30 - 使用 Mosaic 数据流(MDS)实现高吞吐量和效率

59:00 - MDS 特性:
- 直接流式传输和本地缓存
- 拓扑感知(知道哪个分片需要下载到特定 GPU/节点)
- 确定性采样和可恢复迭代
- 中期恢复(节点故障后从中间恢复)
- 维护全局样本状态(跳过已见样本,只处理未见样本)
- 批量预取(GPU 处理当前批次时准备下一批次)

### **实施挑战与解决方案 (60:30 - 结束)**

60:30 - 实施过程中的挑战

61:00 - 挑战 1:最初使用 Docker + Pyxis + Enroot 在 Slurm 上运行容器,过于复杂,阻碍开发速度
- 解决方案:改用虚拟环境方法

61:45 - 挑战 2-4(Zoox 特定):证书启用、Git 连接、安全设置

62:15 - 挑战 5:IP 范围计算不足
- P5 和 P6 节点配备 EFA,每个 EFA 网卡额外消耗一个 IP
- 随着节点增长,子网 IP 耗尽
- 解决方案:重新设计 CIDR 和 VPC

63:00 - 生命周期脚本帮助解决证书安装等问题

63:30 - 会议结束

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


总结要点:
- Zoox 利用 AWS SageMaker HyperPod 构建了大规模机器学习训练平台
- 采用多模态语言动作模型应对自动驾驶长尾挑战
- HyperPod 的自动故障恢复、高性能网络和灵活性是关键优势
- 使用 Mosaic 数据流实现高效数据加载
- 通过虚拟环境和 FSx 共享存储实现灵活的开发工作流程