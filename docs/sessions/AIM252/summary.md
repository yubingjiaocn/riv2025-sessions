# AWS re:Invent 2025 AI基础设施扩展客户专题会议总结

## 会议概述

本次会议是AWS re:Invent 2025的一场客户专题讨论会，主题聚焦于如何使用AWS基础设施和技术栈扩展AI应用。会议由AWS GenAI加速计算团队的首席专家Aniruddha主持，邀请了三位来自不同行业的杰出演讲者：Arm工程总监Andrea Klein、Genentech高级工程总监Henri Dwyer，以及Fireworks现场CTO Shaunak Godbole。

会议围绕AI扩展的三个核心维度展开：纵向扩展（scaling up）- 提升TFLOPS、内存和内存带宽；横向扩展（scaling out）- 增加GPU数量、服务器和UltraClusters；以及跨推理栈扩展（scaling across）。每位演讲者基于各自的实际经验，分享了在大规模AI部署中的最佳实践、挑战解决方案和优化策略。会议特别强调了从小规模实验扩展到千GPU级别集群时需要注意的关键问题，以及如何构建高效的智能体AI系统。

## 详细时间线与关键要点

### 0:00-8:00 会议开场与框架介绍
- **会议背景**：呼应当天Matt Garman主题演讲中关于AI基础设施、AI工厂、Trainium 3 GA发布、UltraClusters和UltraServers的内容
- **演讲者介绍**：三位行业专家将分别从不同角度分享AI扩展经验
- **核心框架**：
  - 纵向扩展：提升单节点性能（TFLOPS、内存、带宽）
  - 横向扩展：增加GPU和服务器数量
  - 跨栈扩展：优化整个推理技术栈

### 8:00-15:00 AI工作负载特征分析
- **前沿模型需求**：千亿参数以上模型需要大量计算资源
- **推理场景多样性**：
  - 批处理推理：处理PB级数据，需要大规模并行计算
  - 实时推理：对延迟敏感，特别是视频和图像模型
- **HPC工作负载特点**：
  - 紧耦合工作负载：训练任务通常需要单AZ甚至单spine部署
  - 松耦合工作负载：推理任务可以分布式部署
- **内存和网络需求**：
  - 大模型如Llama 4和DeepSeek至少需要P5E或P5EN实例
  - 混合专家模型和多模态模型对网络带宽要求极高

### 15:00-20:00 AWS基础设施解决方案
- **UltraCluster 3.0发布**：与Trainium 3同时发布，提供16倍带宽提升
- **UltraServer架构**：单个高速域内支持144个Trainium芯片，性能功耗比提升5倍
- **GPU实例演进**：
  - 与NVIDIA 15年合作历程
  - 最新P6实例：6.4TB/s网络速度，270GB GPU内存
  - GB200基础的P6e实例
- **技术栈层次**：从硬件层到Nitro安全虚拟化，再到EFA网络和SageMaker托管服务

### 20:00-35:00 Andrea Klein：大规模GPU集群管理实践
- **目标受众**：首次管理千GPU级别集群的团队
- **关键挑战识别**：
  - 硬件故障频率随规模增加
  - 分布式工作负载的网络优化需求
  - 多租户和多工作负载的资源竞争
- **采购建议**：
  - 集中部署：所有机器部署在同一物理UltraCluster
  - 标准化选择：选择"主力机型"而非过度优化的异构配置
- **集群管理最佳实践**：
  - 使用Kubernetes和EKS进行集群管理
  - 实施节点池分离策略
  - 规划存储层次结构，充分利用NVME SSD
- **调度和编排**：
  - 批处理作业需要gang scheduling避免死锁
  - 考虑GB200等机架级容量的拓扑约束
- **可观测性要求**：
  - 实时监控容量使用率和调度效率
  - 长期跟踪工作负载效率和成本分摊

### 35:00-42:00 Henri Dwyer：药物发现中的AI扩展经验
- **应用背景**：基于机器学习的分子设计和"实验室在环"流程
- **模型规模**：700亿参数LLM训练，多节点分布式部署
- **基础设施**：Parallel Cluster调度器 + S3长期存储
- **关键挑战与解决方案**：
  - 硬件故障：实施节点测试脚本，及时发现和替换故障节点
  - 网络问题：避免跨AZ和跨spine通信，提升稳定性
  - 模型实现：仔细测试CUDA、EFA、NCCL等库的版本兼容性
  - 数据加载：优化Python多线程/多进程数据管道
  - 检查点机制：实现分布式检查点以应对故障恢复
- **性能优化成果**：GPU利用率从60%提升至90%以上
- **智能体AI应用**：构建理解药物发现领域的意图感知智能体

### 42:00-49:30 Shaunak Godbole：智能体AI的基础设施优化
- **核心理念**：
  - 模型即产品：基于企业数据构建专有模型
  - 模型即知识产权：不应将模型视为商品
- **技术选择复杂性**：
  - 模型类型：文本、图像、视频、嵌入等多模态
  - 模型提供商：Amazon、Meta、DeepSeek、Qwen等
  - 模型对齐：监督微调、DPO、强化学习微调
- **推理基础设施优化**：
  - 硬件选择：Ampere、Hopper、Blackwell系列GPU，Trainium 3
  - 推理引擎优化：模型分片、分离式服务、推测解码
  - 服务栈优化：提示缓存、会话亲和性、请求故障转移
  - 全球安全服务：跨区域调度、私有VPC、Private-Link
- **Fireworks成果**：每秒15万请求，日处理13万亿tokens