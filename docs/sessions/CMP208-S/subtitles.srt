1
00:00:01,470 --> 00:00:02,303
- Cool.

2
00:00:02,303 --> 00:00:03,540
Thanks everyone for joining.

3
00:00:03,540 --> 00:00:06,120
Today we're gonna have a good discussion

4
00:00:06,120 --> 00:00:11,120
on, you know, scaling AI
in the real world with AMD.

5
00:00:13,800 --> 00:00:16,950
So we have an incredible panel here.

6
00:00:16,950 --> 00:00:21,540
We have Arjun Raj, we
have Kasey, and Roman.

7
00:00:21,540 --> 00:00:23,851
I'm gonna let them introduce themselves

8
00:00:23,851 --> 00:00:25,920
and then we'll have a good conversation.

9
00:00:25,920 --> 00:00:26,753
Go ahead, Arjun.

10
00:00:26,753 --> 00:00:29,640
- Hi, my name is Arjun Raj.

11
00:00:29,640 --> 00:00:32,955
I'm head of computational
biology currently at Somite.

12
00:00:32,955 --> 00:00:35,760
I'm actually also professor

13
00:00:35,760 --> 00:00:37,290
of genetics and bioengineering

14
00:00:37,290 --> 00:00:39,750
at the University of Pennsylvania.

15
00:00:39,750 --> 00:00:41,301
- Kasey.

16
00:00:41,301 --> 00:00:42,134
- Hi, Kasey.

17
00:00:42,134 --> 00:00:43,833
Head of US for Upstage AI.

18
00:00:44,820 --> 00:00:49,380
- Hi, Roman Hasenback, CEO
and co-founder of Rambler AI.

19
00:00:49,380 --> 00:00:50,250
- Cool.

20
00:00:50,250 --> 00:00:52,133
Thank you guys for joining us today.

21
00:00:52,133 --> 00:00:56,820
So I think, you know, as
you are attending re:Invent,

22
00:00:56,820 --> 00:01:01,274
I think a lot of you
probably have heard AI

23
00:01:01,274 --> 00:01:03,810
enough number of times, right?

24
00:01:03,810 --> 00:01:07,320
So what we want to talk
about today is not just AI,

25
00:01:07,320 --> 00:01:09,360
but choice in AI, right?

26
00:01:09,360 --> 00:01:13,980
And how AMD's bringing
choice when you think of AI.

27
00:01:13,980 --> 00:01:18,284
I think there's been a obvious, you know,

28
00:01:18,284 --> 00:01:22,043
euphoria around AI, what
the possibilities of AI are,

29
00:01:22,043 --> 00:01:24,524
but we also want to see how it actually

30
00:01:24,524 --> 00:01:27,420
affects, you know, people,
how we actually bring it

31
00:01:27,420 --> 00:01:30,030
to touch people's lives, right?

32
00:01:30,030 --> 00:01:33,025
And so with the incredible
panel we have here,

33
00:01:33,025 --> 00:01:38,025
we'll start, you know,
unpacking what they do,

34
00:01:38,250 --> 00:01:39,960
how they're bringing AI to life,

35
00:01:39,960 --> 00:01:42,702
how they're bringing AI to touch people,

36
00:01:42,702 --> 00:01:45,270
and then we'll, you know,

37
00:01:45,270 --> 00:01:47,160
we'll have some Q&A at the end.

38
00:01:47,160 --> 00:01:48,940
So with that, Arjun, you wanna tell us

39
00:01:48,940 --> 00:01:51,720
a little bit about your work?

40
00:01:51,720 --> 00:01:54,300
AI and biology is like, you know,

41
00:01:54,300 --> 00:01:56,580
just fascinating to just imagine, right?

42
00:01:56,580 --> 00:01:58,560
It's like, it's two ends of the spectrum.

43
00:01:58,560 --> 00:02:00,900
I would be like, you either
choose one or the other.

44
00:02:00,900 --> 00:02:02,400
It's not like you choose both.

45
00:02:02,400 --> 00:02:04,080
So you've chosen both.

46
00:02:04,080 --> 00:02:06,330
So we'd love to hear,
you know, your journey

47
00:02:06,330 --> 00:02:08,580
and what you plan to do.

48
00:02:08,580 --> 00:02:10,290
- Yeah, well, you know,
like many journeys,

49
00:02:10,290 --> 00:02:12,180
I think the problem finds you

50
00:02:12,180 --> 00:02:13,530
maybe some fraction of the time.

51
00:02:13,530 --> 00:02:17,685
So, you know, I can say
how I came to Somite,

52
00:02:17,685 --> 00:02:20,040
and so I've been a
professor, as I was saying,

53
00:02:20,040 --> 00:02:21,500
of genetics and bioengineering.

54
00:02:21,500 --> 00:02:23,860
My work is really focused

55
00:02:23,860 --> 00:02:26,490
around the biology of single cells.

56
00:02:26,490 --> 00:02:28,527
So if you wanna talk about cells,

57
00:02:28,527 --> 00:02:30,240
whether cells have free will,

58
00:02:30,240 --> 00:02:32,963
just buy me a drink after and
I'm happy to talk about it.

59
00:02:34,001 --> 00:02:37,800
One of the central challenges in biology

60
00:02:37,800 --> 00:02:42,090
is for us to understand
how to control cells,

61
00:02:42,090 --> 00:02:43,569
to tell cells what to do,

62
00:02:43,569 --> 00:02:45,979
and this is one of the central missions

63
00:02:45,979 --> 00:02:50,040
that Somite therapeutics is
to understand that language.

64
00:02:50,040 --> 00:02:51,690
And right now I would say that, you know,

65
00:02:51,690 --> 00:02:55,450
through decades of hard
biological work, we've figured out

66
00:02:56,329 --> 00:03:00,120
sort of like the words, like the tokens,

67
00:03:00,120 --> 00:03:02,640
but we don't know how to
string together sentences.

68
00:03:02,640 --> 00:03:04,080
So if we wanted to tell,

69
00:03:04,080 --> 00:03:06,540
we know kind of like the elemental units,

70
00:03:06,540 --> 00:03:08,580
like the signals that
we can give to cells,

71
00:03:08,580 --> 00:03:10,828
but we don't know how to
turn them into instructions

72
00:03:10,828 --> 00:03:15,330
that could turn, say, a
stem cell into a muscle cell

73
00:03:15,330 --> 00:03:17,559
to cure like a muscle wasting disease,

74
00:03:17,559 --> 00:03:22,559
or any number of other
potential therapeutics

75
00:03:22,800 --> 00:03:25,246
that are very hard to do currently.

76
00:03:25,246 --> 00:03:27,690
What we're doing at Somite is generating

77
00:03:27,690 --> 00:03:31,596
actually in the lab huge amounts
of data, new kinds of data

78
00:03:31,596 --> 00:03:34,380
that we think will allow us

79
00:03:34,380 --> 00:03:36,454
to now actually build predictive models

80
00:03:36,454 --> 00:03:38,610
that allow us to solve that problem

81
00:03:38,610 --> 00:03:41,160
of how to control cells
with these signals.

82
00:03:41,160 --> 00:03:43,950
And we can do that, you know,

83
00:03:43,950 --> 00:03:48,950
using all these new ML techniques
and powered by AMD GPUs.

84
00:03:49,980 --> 00:03:50,997
- Nice.

85
00:03:50,997 --> 00:03:52,470
We are super excited about that.

86
00:03:52,470 --> 00:03:54,810
I mean, I personally have been working

87
00:03:54,810 --> 00:03:57,329
with, you know, Frontier
research in that area,

88
00:03:57,329 --> 00:04:00,000
especially given AMD's advantage

89
00:04:00,000 --> 00:04:03,660
with large memory and
high bandwidth memory.

90
00:04:03,660 --> 00:04:07,447
We can actually do a lot
of the, you know, discovery

91
00:04:07,447 --> 00:04:10,110
in one system or one GPU, right?

92
00:04:10,110 --> 00:04:15,110
And that helps facilitate
that progress in the field.

93
00:04:15,808 --> 00:04:16,641
Cool.

94
00:04:16,641 --> 00:04:20,130
Kasey, do you wanna give
us a little bit on Upstage?

95
00:04:20,130 --> 00:04:21,287
- Yeah, of course.

96
00:04:21,287 --> 00:04:23,617
After hearing what Arjun does.

97
00:04:23,617 --> 00:04:27,390
Okay, so I think there's a
diversity of AI here as well.

98
00:04:27,390 --> 00:04:32,390
So we're using AI to help
you, you know, help all of us,

99
00:04:32,838 --> 00:04:34,740
especially the one who, you know,

100
00:04:34,740 --> 00:04:37,980
where we work at a every
day, there's repetitive,

101
00:04:37,980 --> 00:04:40,920
very, you know, brain-numbing workflows.

102
00:04:40,920 --> 00:04:44,748
We're deploying AI to automate
all of that for enterprises

103
00:04:44,748 --> 00:04:47,250
especially in the financial
service industries,

104
00:04:47,250 --> 00:04:50,068
healthcare, public sector
where you think about

105
00:04:50,068 --> 00:04:53,160
there's a huge, lot of
regulations or the legacies

106
00:04:53,160 --> 00:04:54,491
that actually prevent you

107
00:04:54,491 --> 00:04:57,607
from deploying the newest technology.

108
00:04:57,607 --> 00:05:00,120
So the way that we describe ourself

109
00:05:00,120 --> 00:05:05,120
is we do the unsexy work
for, you know, using AI.

110
00:05:05,910 --> 00:05:06,780
So I think this is the-

111
00:05:06,780 --> 00:05:09,360
- The sexy work.
- Right. Right.

112
00:05:09,360 --> 00:05:12,510
But, you know, I think all
of us need AI to help us,

113
00:05:12,510 --> 00:05:15,060
and I think like we ChatGPT and OpenAI,

114
00:05:15,060 --> 00:05:17,550
we've all experienced what is possible

115
00:05:17,550 --> 00:05:21,398
once AI is actually understand
the context and, you know,

116
00:05:21,398 --> 00:05:25,338
actually help as a
co-pilot or as a companion

117
00:05:25,338 --> 00:05:27,690
and help you automate
some of the workflow.

118
00:05:27,690 --> 00:05:29,790
So that's where we are focused on,

119
00:05:29,790 --> 00:05:33,015
and to go one level
deeper, what we identified

120
00:05:33,015 --> 00:05:36,075
when we started the
company five years ago.

121
00:05:36,075 --> 00:05:39,011
So we started in Korea and we went around

122
00:05:39,011 --> 00:05:41,490
and met with a hundred CEOs of, you know,

123
00:05:41,490 --> 00:05:44,460
Samsung, LG, and Hyundai of the world,

124
00:05:44,460 --> 00:05:48,180
and ask what would be one AI use case

125
00:05:48,180 --> 00:05:52,530
that you're willing to
pay whatever price it is,

126
00:05:52,530 --> 00:05:54,750
if we can actually fix it for you?

127
00:05:54,750 --> 00:05:58,470
And they all came back with
the most unsexy answer.

128
00:05:58,470 --> 00:06:00,990
and that was the document extraction.

129
00:06:00,990 --> 00:06:03,750
And like OCR, the optical
character recognition,

130
00:06:03,750 --> 00:06:06,300
has been there for a while.

131
00:06:06,300 --> 00:06:08,147
It's not a surprise, it's not the newest,

132
00:06:08,147 --> 00:06:12,256
but it was very clear that
there was a huge limitation.

133
00:06:12,256 --> 00:06:16,378
So if anyone is using OCR,
have experienced the OCR,

134
00:06:16,378 --> 00:06:19,243
what happened is basically,

135
00:06:19,243 --> 00:06:21,960
it is reading the documents left and right

136
00:06:21,960 --> 00:06:23,670
without understanding the context

137
00:06:23,670 --> 00:06:25,560
or the layout of the document.

138
00:06:25,560 --> 00:06:26,730
So if you think about

139
00:06:26,730 --> 00:06:29,910
there's a little bit of
changes in the layout,

140
00:06:29,910 --> 00:06:34,650
or a little bit of handwriting
involved in documents,

141
00:06:34,650 --> 00:06:36,990
or it's a crumbled, it's,
you know, kind of tilted,

142
00:06:36,990 --> 00:06:39,240
it's kind of really throwing you off,

143
00:06:39,240 --> 00:06:42,060
and that negates the purpose of automation

144
00:06:42,060 --> 00:06:45,990
when you cannot get to
95% or above accuracy.

145
00:06:45,990 --> 00:06:50,010
So we focused on that first
very specific use case,

146
00:06:50,010 --> 00:06:54,450
and we developed our
proprietary next generation OCR,

147
00:06:54,450 --> 00:06:57,330
as well as our proprietary LLM,

148
00:06:57,330 --> 00:06:58,740
and that's where AMD comes in.

149
00:06:58,740 --> 00:07:02,053
We're training our
proprietary LLLM Cold Solar

150
00:07:02,053 --> 00:07:04,380
using AMD GPUs.

151
00:07:04,380 --> 00:07:07,920
And once we marry that OCR
and LLM, what's possible now

152
00:07:07,920 --> 00:07:11,940
is this becomes a
template-free extraction.

153
00:07:11,940 --> 00:07:15,840
So users can come and say,
hey, I want to extract,

154
00:07:15,840 --> 00:07:18,344
let's say, name, ID, address.

155
00:07:18,344 --> 00:07:19,980
That information is somewhere

156
00:07:19,980 --> 00:07:22,500
in this 500 page long document.

157
00:07:22,500 --> 00:07:23,940
Can you find that for us?

158
00:07:23,940 --> 00:07:26,970
And we can easily fetch those
information, identify it,

159
00:07:26,970 --> 00:07:29,357
validate it, and extract dynamically

160
00:07:29,357 --> 00:07:34,290
for very fast and cost-efficient manner,

161
00:07:34,290 --> 00:07:36,450
and that's what we are
focusing on right now.

162
00:07:36,450 --> 00:07:38,820
But I do believe that once we build

163
00:07:38,820 --> 00:07:41,685
that data foundation for enterprises,

164
00:07:41,685 --> 00:07:46,685
then we have so much opportunities
based on the foundations.

165
00:07:47,010 --> 00:07:48,210
So we're also looking

166
00:07:48,210 --> 00:07:51,264
into more of end-to-end
workflow automation,

167
00:07:51,264 --> 00:07:55,950
but really, you know,
fixing the most unsexy job

168
00:07:55,950 --> 00:07:59,220
that is actually comes with
a high willingness to pay.

169
00:07:59,220 --> 00:08:00,450
That's what we do at Upstage.

170
00:08:00,450 --> 00:08:01,849
- Nice.

171
00:08:01,849 --> 00:08:04,650
I think, you know, it may be unsexy,

172
00:08:04,650 --> 00:08:07,581
but I call it walking the last mile of AI.

173
00:08:07,581 --> 00:08:11,160
You know, because the hype
and all of it is good,

174
00:08:11,160 --> 00:08:13,827
but in the end, to go
touch people's lives,

175
00:08:13,827 --> 00:08:16,740
you gotta go do the grunt work, right?

176
00:08:16,740 --> 00:08:18,030
You want to automate those things,

177
00:08:18,030 --> 00:08:21,210
and I have experienced like, even like,

178
00:08:21,210 --> 00:08:22,904
rescheduling flights or something, right?

179
00:08:22,904 --> 00:08:26,760
I used to dread calling,
you know, the travel agent

180
00:08:26,760 --> 00:08:27,870
to go through the process,

181
00:08:27,870 --> 00:08:31,537
and now it's just actually
I was talking to a person

182
00:08:31,537 --> 00:08:34,115
and it got rescheduled
and then I was like, wait,

183
00:08:34,115 --> 00:08:35,550
was this just automated?

184
00:08:35,550 --> 00:08:36,990
And then yes, you know,

185
00:08:36,990 --> 00:08:39,515
it's like passing the
Turing test for grunt work,

186
00:08:39,515 --> 00:08:44,515
I think is a huge business opportunity.

187
00:08:44,580 --> 00:08:45,840
So it's great that you're doing it

188
00:08:45,840 --> 00:08:47,330
and doing it on AMD, right?

189
00:08:47,330 --> 00:08:49,486
So that's great to hear.

190
00:08:49,486 --> 00:08:52,860
Roman, you wanna introduce
yourself and Rambler?

191
00:08:52,860 --> 00:08:53,693
- Sure.

192
00:08:54,540 --> 00:08:57,660
At Rambler, we built
an end-to-end platform

193
00:08:57,660 --> 00:09:01,803
to train and deploy vision AI agents.

194
00:09:03,719 --> 00:09:06,120
Maybe to give you some background,

195
00:09:06,120 --> 00:09:09,630
so I spent my entire
career on that intersection

196
00:09:09,630 --> 00:09:12,780
between the real world and technology.

197
00:09:12,780 --> 00:09:17,130
The previous company has
now got acquired by Apple

198
00:09:17,130 --> 00:09:20,310
and is now it was kind of the
starting point for AR kid.

199
00:09:20,310 --> 00:09:21,360
Apple Vision Pro.

200
00:09:21,360 --> 00:09:25,500
I worked at Apple for six years
and then I decided to leave

201
00:09:25,500 --> 00:09:27,270
because I saw this inflection point

202
00:09:27,270 --> 00:09:30,660
where, you know, AI needs to develop

203
00:09:30,660 --> 00:09:33,390
a granular understanding
of the real world,

204
00:09:33,390 --> 00:09:36,569
what is going on around us in
order to be able to support us

205
00:09:36,569 --> 00:09:40,347
in our day-to-day life, but
also in our, you know, at work

206
00:09:40,347 --> 00:09:43,320
when you're working in
a manufacturing plant,

207
00:09:43,320 --> 00:09:45,900
or for industrial processes.

208
00:09:45,900 --> 00:09:49,170
So we started Rambler.

209
00:09:49,170 --> 00:09:51,400
You can think of it as a system

210
00:09:52,553 --> 00:09:54,210
that enables you to collect
data in the real world,

211
00:09:54,210 --> 00:09:57,330
like literally how someone
is performing a task,

212
00:09:57,330 --> 00:10:01,170
and then we can fine tune and
train a vision language model

213
00:10:01,170 --> 00:10:05,430
on understanding how a task
is supposed to be performed,

214
00:10:05,430 --> 00:10:07,560
and then we can deploy
it into the real world

215
00:10:07,560 --> 00:10:12,288
and, you know, confirm
if tasks were performed

216
00:10:12,288 --> 00:10:15,240
according to the standard
operating procedure

217
00:10:15,240 --> 00:10:19,053
or if anyone deviated from that.

218
00:10:20,340 --> 00:10:21,210
As part of that,

219
00:10:21,210 --> 00:10:22,710
like the fundamental technologies,

220
00:10:22,710 --> 00:10:25,440
essentially video understanding
on a granular level,

221
00:10:25,440 --> 00:10:28,677
and we built kind of the
end-to-end system for that

222
00:10:28,677 --> 00:10:31,503
and agnostic with regards to the hardware.

223
00:10:32,387 --> 00:10:33,660
- Fascinating.

224
00:10:33,660 --> 00:10:36,030
I mean, it's great to see that, you know,

225
00:10:36,030 --> 00:10:39,180
we're talking about like physical AI

226
00:10:39,180 --> 00:10:42,870
and vision language models,
document extraction,

227
00:10:42,870 --> 00:10:46,784
and like biology and AI
all like in one, you know,

228
00:10:46,784 --> 00:10:49,620
in one timeframe, right?

229
00:10:49,620 --> 00:10:51,774
Like, each one of these can be, you know,

230
00:10:51,774 --> 00:10:55,950
like life changing and altering

231
00:10:55,950 --> 00:10:59,382
for entire generations of people.

232
00:10:59,382 --> 00:11:01,890
So this is great.

233
00:11:01,890 --> 00:11:06,890
So let's start with I know, Roman,

234
00:11:08,652 --> 00:11:12,510
you'll have to scoot for
a flight at some point,

235
00:11:12,510 --> 00:11:14,280
so whenever you want to
leave, just raise your hand.

236
00:11:14,280 --> 00:11:15,113
Like, you can.

237
00:11:16,200 --> 00:11:18,390
- Well, it depends on
the questions you ask me.

238
00:11:18,390 --> 00:11:19,830
- Yeah, if you have any questions for him,

239
00:11:19,830 --> 00:11:21,080
catch him on the way out.

240
00:11:21,917 --> 00:11:23,886
But, you know, it'll be great.

241
00:11:23,886 --> 00:11:28,650
You know, let's just
start with Kasey maybe.

242
00:11:28,650 --> 00:11:30,300
You know, enterprise AI, right?

243
00:11:30,300 --> 00:11:31,882
Like, enterprise is just huge.

244
00:11:31,882 --> 00:11:34,740
What are trends that you're seeing

245
00:11:34,740 --> 00:11:39,003
in terms of AI
infrastructure and, you know,

246
00:11:40,555 --> 00:11:43,320
people always think that GPU poor, right?

247
00:11:43,320 --> 00:11:45,592
Or you always need more GPUs or compute,

248
00:11:45,592 --> 00:11:47,670
and given that you have

249
00:11:47,670 --> 00:11:50,877
like that touch point with enterprises,

250
00:11:50,877 --> 00:11:52,290
how do you see the world

251
00:11:52,290 --> 00:11:56,070
and what do you see, you
know, from your customers?

252
00:11:56,070 --> 00:11:57,605
- Yeah, love this question.

253
00:11:57,605 --> 00:12:02,605
I think it actually, I wanna
fast forward to actually like,

254
00:12:02,880 --> 00:12:06,600
look back when this whole generative AI

255
00:12:06,600 --> 00:12:10,453
was the big shock like last year.

256
00:12:10,453 --> 00:12:13,290
:Lot of enterprise's customer came to us

257
00:12:13,290 --> 00:12:14,600
and say, hey, what is...

258
00:12:15,710 --> 00:12:16,543
Like, this is two years ago,

259
00:12:16,543 --> 00:12:17,376
and then they started doing POC

260
00:12:17,376 --> 00:12:19,440
and they're was like, what
is this enterprise AI?

261
00:12:19,440 --> 00:12:20,850
Sorry, generative AI.

262
00:12:20,850 --> 00:12:22,380
How do I get started?

263
00:12:22,380 --> 00:12:24,960
And back then the answer was

264
00:12:24,960 --> 00:12:27,998
okay, there is an OpenAI,
there is an anthropic.

265
00:12:27,998 --> 00:12:30,600
Huge, massive model.

266
00:12:30,600 --> 00:12:32,940
You can't really take
it onto your own premise

267
00:12:32,940 --> 00:12:34,740
or your own cloud environment.

268
00:12:34,740 --> 00:12:39,740
So the only way to tap
into this new technology

269
00:12:40,333 --> 00:12:45,333
was actually leveraging
really high compute GPU

270
00:12:45,423 --> 00:12:49,298
in a major cloud provider like AWS.

271
00:12:49,298 --> 00:12:54,279
And it was amazing how
some of the POC went well,

272
00:12:54,279 --> 00:12:57,750
but I think there were
various reports that came out,

273
00:12:57,750 --> 00:12:59,850
like, namely the MIT report that came out

274
00:12:59,850 --> 00:13:01,074
like, you know, summer this year

275
00:13:01,074 --> 00:13:04,615
that like 90 something percent
of the POC for enterprise

276
00:13:04,615 --> 00:13:06,900
didn't get to the production.

277
00:13:06,900 --> 00:13:09,390
And I think we've seen

278
00:13:09,390 --> 00:13:11,580
the fair amount of those cases as well,

279
00:13:11,580 --> 00:13:14,130
and really that came down to ROI.

280
00:13:14,130 --> 00:13:18,088
Like, okay, this is great, it works great.

281
00:13:18,088 --> 00:13:20,340
How much is it again?

282
00:13:20,340 --> 00:13:23,425
Then that's where like the
conversation gets stuck,

283
00:13:23,425 --> 00:13:26,130
and that's where,

284
00:13:26,130 --> 00:13:28,335
going back to your
question on infrastructure,

285
00:13:28,335 --> 00:13:32,104
and the software, the AI, the model side

286
00:13:32,104 --> 00:13:35,744
are so, you know, all in
the same time in parallel

287
00:13:35,744 --> 00:13:40,123
improved a lot to the point
that for the tedious workflow

288
00:13:40,123 --> 00:13:44,070
that enterprise are trying
to achieve using AI,

289
00:13:44,070 --> 00:13:46,680
you don't need this
massive frontier model.

290
00:13:46,680 --> 00:13:49,903
You can actually achieve this
using much, much smaller model

291
00:13:49,903 --> 00:13:53,880
that can actually feed
on CPU, not even GPU.

292
00:13:53,880 --> 00:13:55,380
And that's where the conversation

293
00:13:55,380 --> 00:13:57,570
kind of turned with our customers

294
00:13:57,570 --> 00:14:00,405
that, like, for us, for
document extraction,

295
00:14:00,405 --> 00:14:03,270
we have an OCR model that is like

296
00:14:03,270 --> 00:14:06,270
not even a billion in the parameter size,

297
00:14:06,270 --> 00:14:10,260
and then our model LLM is
like 17 billion parameter.

298
00:14:10,260 --> 00:14:12,120
It's nicely built on a single GPU,

299
00:14:12,120 --> 00:14:15,210
and then you can achieve
the same level of accuracy,

300
00:14:15,210 --> 00:14:17,708
same level of performance,

301
00:14:17,708 --> 00:14:21,313
and with the hardware cost that is 1/10th,

302
00:14:21,313 --> 00:14:24,450
this is a no brainer, and this is a case

303
00:14:24,450 --> 00:14:26,940
where you can actually productize.

304
00:14:26,940 --> 00:14:29,609
So I think fast, you
know, like within a year,

305
00:14:29,609 --> 00:14:32,070
we've noticed that this conversation

306
00:14:32,070 --> 00:14:36,780
just rapidly changed from
POC to actual production ROI,

307
00:14:36,780 --> 00:14:41,280
and now a lot of enterprises do the POC,

308
00:14:41,280 --> 00:14:44,235
understand the use case,
test the capability,

309
00:14:44,235 --> 00:14:45,954
look for a smaller model

310
00:14:45,954 --> 00:14:48,540
that they can deploy
a lot more efficiently

311
00:14:48,540 --> 00:14:53,280
on a smaller set of GPU, or
even CPU, and then deploy it,

312
00:14:53,280 --> 00:14:57,030
and then actually get onto
multiple use cases like this,

313
00:14:57,030 --> 00:14:59,433
and that way they can
achieve a lot more efficiency

314
00:14:59,433 --> 00:15:01,352
in terms of the hardware cost

315
00:15:01,352 --> 00:15:04,680
as well as the software cost as well.

316
00:15:04,680 --> 00:15:06,750
- Yeah, I think that's a good point,

317
00:15:06,750 --> 00:15:10,470
and also the hardware
evolution, like for example,

318
00:15:10,470 --> 00:15:11,370
what we see with AMD, right?

319
00:15:11,370 --> 00:15:13,830
Like, we have a pervasive
AI hardware story.

320
00:15:13,830 --> 00:15:16,830
So even on our laptops, like
the laptop I carry around

321
00:15:16,830 --> 00:15:18,840
is a RYZEN Max 395.

322
00:15:18,840 --> 00:15:20,310
It's like 128 gigs of HBM.

323
00:15:20,310 --> 00:15:24,718
Not HBM. 128 gigs of RAM.

324
00:15:24,718 --> 00:15:29,337
Can run like a GPT OSS 120B,
you know, fully, right?

325
00:15:29,337 --> 00:15:30,420
And that's on a laptop.

326
00:15:30,420 --> 00:15:32,197
So it'll be interesting
to see as, you know,

327
00:15:32,197 --> 00:15:34,191
your models kind of get to the edge,

328
00:15:34,191 --> 00:15:37,552
how it enables that
intelligence at the edge,

329
00:15:37,552 --> 00:15:40,290
but even though it starts from, you know,

330
00:15:40,290 --> 00:15:42,843
infrastructure that's
built on MI 300, et cetera.

331
00:15:44,040 --> 00:15:48,010
Arjun, on the biology
plus AI front, right?

332
00:15:48,010 --> 00:15:50,639
Like, I'm fascinated as
to like, when did you,

333
00:15:50,639 --> 00:15:54,510
like, you know, it's like,
because you're coming

334
00:15:54,510 --> 00:15:56,309
from the biology side of things,

335
00:15:56,309 --> 00:15:58,920
you're like, suddenly you find a tool.

336
00:15:58,920 --> 00:16:01,680
It's like you found a hammer
and you've had all these nails

337
00:16:01,680 --> 00:16:03,759
and now you're like, oh
great, I can actually do this.

338
00:16:03,759 --> 00:16:05,999
Like, can you walk us through,

339
00:16:05,999 --> 00:16:08,430
when did you like become a believer

340
00:16:08,430 --> 00:16:09,638
in like, okay, this is a hammer

341
00:16:09,638 --> 00:16:14,130
and here are the nails that
I gotta go, you know, hit on.

342
00:16:14,130 --> 00:16:17,070
- Yeah, I mean, I think, well for me,

343
00:16:17,070 --> 00:16:20,100
I had to sort of personally
like a Chat GPT moment

344
00:16:20,100 --> 00:16:22,560
where I was like, wow, this
is really changing things.

345
00:16:22,560 --> 00:16:24,124
So that was obviously

346
00:16:24,124 --> 00:16:28,350
one major inflection
point for me personally,

347
00:16:28,350 --> 00:16:32,070
but then just in the field
in general of biology,

348
00:16:32,070 --> 00:16:36,090
I would say for the last
honestly, 20, 30 years,

349
00:16:36,090 --> 00:16:38,430
a lot of it has gotten stuck.

350
00:16:38,430 --> 00:16:40,020
It's hit a complexity barrier

351
00:16:40,020 --> 00:16:43,268
where I think human understanding,

352
00:16:43,268 --> 00:16:45,420
you know, there's massive investment

353
00:16:45,420 --> 00:16:49,464
in trying to understand how biology works,

354
00:16:49,464 --> 00:16:52,815
and there are a lot of
sort of very linear stories

355
00:16:52,815 --> 00:16:55,050
that people had developed in science.

356
00:16:55,050 --> 00:16:57,600
Like, you know, this
causes this, causes this,

357
00:16:57,600 --> 00:17:01,410
and basically around sort of, you know,

358
00:17:01,410 --> 00:17:04,517
the year 2000 or a little before that,

359
00:17:04,517 --> 00:17:06,426
maybe even starting before that,

360
00:17:06,426 --> 00:17:09,081
we just started to hit
this complexity wall

361
00:17:09,081 --> 00:17:13,331
where it was like, you know,
A depends on, you know,

362
00:17:13,331 --> 00:17:18,090
A1 through A200 depends
on B1 through B2000.

363
00:17:18,090 --> 00:17:19,460
Like, that kind of thing.

364
00:17:19,460 --> 00:17:23,430
So, you know, there were so many problems

365
00:17:23,430 --> 00:17:25,650
that we've been sort of
mired and stuck with,

366
00:17:25,650 --> 00:17:30,650
and now those are starting to
be solved by machine learning,

367
00:17:30,977 --> 00:17:33,330
which is really remarkable.

368
00:17:33,330 --> 00:17:37,170
I mean, we can now build predictive models

369
00:17:37,170 --> 00:17:40,200
that could tell us how a
particular sequence of DNA

370
00:17:40,200 --> 00:17:44,160
might affect how some biomolecule
worked, and in principle,

371
00:17:44,160 --> 00:17:45,900
all of this was all there,

372
00:17:45,900 --> 00:17:48,570
but we just couldn't pull
out the meaning from it

373
00:17:48,570 --> 00:17:49,920
or pull out the predictive power

374
00:17:49,920 --> 00:17:51,220
at least let's say, right?

375
00:17:52,350 --> 00:17:54,870
And, you know, AlphaFold
was one huge moment

376
00:17:54,870 --> 00:17:56,170
for, you know, where basically

377
00:17:56,170 --> 00:18:00,240
where do atoms line up to form molecules?

378
00:18:00,240 --> 00:18:02,639
I think that's just
the tip of the iceberg,

379
00:18:02,639 --> 00:18:04,217
and I think, you know,

380
00:18:04,217 --> 00:18:07,110
Somite is supposed to
do interesting things.

381
00:18:07,110 --> 00:18:09,823
I think that'll be just
one of many, you know,

382
00:18:09,823 --> 00:18:11,850
huge changes that we're gonna see

383
00:18:11,850 --> 00:18:13,920
in the coming decade, let's say.

384
00:18:13,920 --> 00:18:15,150
- Nice. Nice.

385
00:18:15,150 --> 00:18:16,530
That's exciting.

386
00:18:16,530 --> 00:18:20,700
And Roman, on the vision
language models, right?

387
00:18:20,700 --> 00:18:25,700
Vision is just, I mean, it's
the amount of data is infinite.

388
00:18:26,160 --> 00:18:29,463
Like, I can look at this
room in 10 different ways

389
00:18:29,463 --> 00:18:32,310
and I can process, you know,

390
00:18:32,310 --> 00:18:35,070
audio visual signals in different ways

391
00:18:35,070 --> 00:18:36,090
like how the brain does it,

392
00:18:36,090 --> 00:18:38,040
and you're trying to make sense of that

393
00:18:39,498 --> 00:18:41,760
and make it accessible to
machine learning models

394
00:18:41,760 --> 00:18:44,275
and also reason with that, right?

395
00:18:44,275 --> 00:18:46,980
That's just, you know,
that's another step function.

396
00:18:46,980 --> 00:18:48,480
Just like on the biology side,

397
00:18:48,480 --> 00:18:50,310
you're just taking the physical world

398
00:18:50,310 --> 00:18:52,380
into a consumable form.

399
00:18:52,380 --> 00:18:56,790
So when did that click
for you and how? (laughs)

400
00:18:56,790 --> 00:19:01,140
You're like, ah, okay, you
know, this is the way forward.

401
00:19:01,140 --> 00:19:03,090
- Yeah, it's a good question

402
00:19:03,090 --> 00:19:06,510
because, you know, when we
started Rambler in 2021,

403
00:19:06,510 --> 00:19:09,930
like, you know, there were
no vision language models.

404
00:19:09,930 --> 00:19:13,080
Like, we've been going through, you know,

405
00:19:13,080 --> 00:19:15,000
development cycles and research cycles.

406
00:19:15,000 --> 00:19:18,485
I've never experienced anything
even remotely like that,

407
00:19:18,485 --> 00:19:20,250
and now we are at a stage

408
00:19:20,250 --> 00:19:23,280
where literally with a
relatively small model,

409
00:19:23,280 --> 00:19:26,583
7 billion parameters that you
can run on an edge device,

410
00:19:28,530 --> 00:19:31,800
you know, you can actually
extract granular details

411
00:19:31,800 --> 00:19:34,650
from, you know, how humans
interact with the world,

412
00:19:34,650 --> 00:19:36,663
how robots interact with the world.

413
00:19:37,680 --> 00:19:40,470
It's, you know, I can't really pinpoint

414
00:19:40,470 --> 00:19:44,010
what that like wow moment was
where I was like, oh my God,

415
00:19:44,010 --> 00:19:47,640
this is like we are heading into a future

416
00:19:47,640 --> 00:19:49,470
that we don't really understand

417
00:19:49,470 --> 00:19:52,200
how systems that understand our world

418
00:19:52,200 --> 00:19:54,474
can actually start
supporting us, helping us,

419
00:19:54,474 --> 00:19:57,480
and not just during work hours,

420
00:19:57,480 --> 00:19:59,940
but also throughout our
day-to-day lives, right?

421
00:19:59,940 --> 00:20:03,180
Like, if you think of the next
generation consumer devices,

422
00:20:03,180 --> 00:20:05,880
we see kind of the first adoption

423
00:20:05,880 --> 00:20:09,393
with the Meta Ray-Ban 3
and Meta Ray-Ban 3 display,

424
00:20:10,603 --> 00:20:11,808
and now they're, you know,

425
00:20:11,808 --> 00:20:13,938
pretty much every consumer
electronics provider

426
00:20:13,938 --> 00:20:16,470
is coming out with a new device.

427
00:20:16,470 --> 00:20:18,240
We're also seeing a lot more cameras

428
00:20:18,240 --> 00:20:20,220
deployed out there, right?

429
00:20:20,220 --> 00:20:23,847
But like these systems,

430
00:20:23,847 --> 00:20:26,610
they need to be able to support you

431
00:20:26,610 --> 00:20:27,480
throughout your day to day,

432
00:20:27,480 --> 00:20:30,420
which means it's a very heavy workload

433
00:20:30,420 --> 00:20:32,250
like processing frames.

434
00:20:32,250 --> 00:20:35,725
Unfortunately, we can't
fit it on just CPU.

435
00:20:35,725 --> 00:20:40,380
That requires, you know,
pretty powerful GPUs out there,

436
00:20:40,380 --> 00:20:42,900
and I'm really excited

437
00:20:42,900 --> 00:20:45,420
about the future and what it's bringing,

438
00:20:45,420 --> 00:20:47,250
and, you know, companies like AMD

439
00:20:47,250 --> 00:20:49,140
have really unlocked that space.

440
00:20:49,140 --> 00:20:51,822
Also, you know, bringing physical AI

441
00:20:51,822 --> 00:20:54,681
really into the real
world where it matters,

442
00:20:54,681 --> 00:20:57,600
and yeah, I'm very excited about that.

443
00:20:57,600 --> 00:20:58,860
- I think that that is one of the reasons

444
00:20:58,860 --> 00:21:02,513
why, like, when AMD was
designing the hardware, you know,

445
00:21:02,513 --> 00:21:05,178
specifications for like what to go after,

446
00:21:05,178 --> 00:21:08,430
capacity and bandwidth are huge, right?

447
00:21:08,430 --> 00:21:10,562
Obviously computational
flops are important,

448
00:21:10,562 --> 00:21:15,030
but we need to be able to
consume like data at the scale.

449
00:21:15,030 --> 00:21:17,700
So if you look at, you know,
generation over generation,

450
00:21:17,700 --> 00:21:21,237
we've consistently had leadership

451
00:21:21,237 --> 00:21:24,450
in terms of, you know, 288 gigs of HBM,

452
00:21:24,450 --> 00:21:27,310
like a year or two before
competition shows up, right?

453
00:21:27,310 --> 00:21:31,060
So if you have those ideas
on like what to build,

454
00:21:31,060 --> 00:21:35,000
you know, AMD definitely has
a good hardware footprint,

455
00:21:35,000 --> 00:21:37,110
and on the software side
too, we are, you know,

456
00:21:37,110 --> 00:21:38,310
we wanna make it very seamless.

457
00:21:38,310 --> 00:21:41,527
So, you know, we understand
the incumbent ecosystem

458
00:21:41,527 --> 00:21:44,520
so if you've played with
it, we wanna make sure

459
00:21:44,520 --> 00:21:49,263
that the transition to
evaluating AMD is zero friction.

460
00:21:49,263 --> 00:21:51,031
Just like we've done on the CPUs,

461
00:21:51,031 --> 00:21:53,910
on the GPUs to like, no code changes,

462
00:21:53,910 --> 00:21:57,396
you should be able to run on AMD hardware.

463
00:21:57,396 --> 00:22:00,450
So I think this is good.

464
00:22:00,450 --> 00:22:02,370
So, you know, I wanna
switch it up a little bit

465
00:22:02,370 --> 00:22:07,350
and let's just see because we
have vision language models,

466
00:22:07,350 --> 00:22:11,417
we have enterprise AI,
we have biology and AI.

467
00:22:11,417 --> 00:22:16,417
Like hypothetically, if
we were all brainstorming

468
00:22:17,021 --> 00:22:21,240
to start a company, what would we build,

469
00:22:21,240 --> 00:22:22,140
like the four of us?

470
00:22:22,140 --> 00:22:25,440
Like, I mean, let's say I'm
the guy who's gonna go sell it.

471
00:22:25,440 --> 00:22:27,120
So let's leave me out of the way.

472
00:22:27,120 --> 00:22:29,100
I'll give you the compute.

473
00:22:29,100 --> 00:22:30,810
What will the three of you want to build

474
00:22:30,810 --> 00:22:34,519
given, you know, biology, enterprise,

475
00:22:34,519 --> 00:22:36,750
vision language models?

476
00:22:36,750 --> 00:22:41,750
I know it's a idea generation question.

477
00:22:41,970 --> 00:22:42,803
- I can start.

478
00:22:42,803 --> 00:22:44,190
- Yeah.

479
00:22:44,190 --> 00:22:46,470
- Well, a real time world model.

480
00:22:46,470 --> 00:22:51,470
That's, I think, you know, this
will unlock a lot out there

481
00:22:52,399 --> 00:22:56,100
because we're still in
that world where, you know,

482
00:22:56,100 --> 00:22:59,590
for us to be able to analyze
video streams accurately,

483
00:22:59,590 --> 00:23:02,760
we need to go through a lot
of fine tuning and training

484
00:23:02,760 --> 00:23:05,280
on domain-specific data.

485
00:23:05,280 --> 00:23:06,727
There's definitely, you know,

486
00:23:06,727 --> 00:23:10,470
foundation models were
trained on all of the data

487
00:23:10,470 --> 00:23:13,020
that they could get their
hands on in the internet,

488
00:23:13,020 --> 00:23:14,640
which is not really representative

489
00:23:14,640 --> 00:23:17,730
of what you encounter in
the real world usually.

490
00:23:17,730 --> 00:23:18,900
So I'm really excited

491
00:23:18,900 --> 00:23:21,300
about the opportunity around world models

492
00:23:21,300 --> 00:23:22,710
and, you know, currently there.

493
00:23:22,710 --> 00:23:24,060
- Well, but you have to make sure

494
00:23:24,060 --> 00:23:25,305
Arjun has something to do, right?

495
00:23:25,305 --> 00:23:26,487
- Well, I'm pretty sure biology-

496
00:23:26,487 --> 00:23:28,500
- You're like, I'm gonna do world models,

497
00:23:28,500 --> 00:23:29,730
but what does the biology guy do?

498
00:23:29,730 --> 00:23:31,393
- But that's like, you know, I mean,

499
00:23:31,393 --> 00:23:34,830
a world model by definition
should encompass it all, right?

500
00:23:34,830 --> 00:23:37,050
It should have a deep
understanding of physics.

501
00:23:37,050 --> 00:23:37,883
- Maybe it's a world model

502
00:23:37,883 --> 00:23:40,224
where you have a robot that's, you know?

503
00:23:40,224 --> 00:23:41,057
- Exactly.

504
00:23:43,110 --> 00:23:46,260
Yeah, maybe Arjun, you can take that idea,

505
00:23:46,260 --> 00:23:49,290
and now I throw the ball over to you.

506
00:23:49,290 --> 00:23:53,313
- I would be very excited
about, you know, AI scientists.

507
00:23:54,960 --> 00:23:56,610
I was joking with a colleague of mine.

508
00:23:56,610 --> 00:23:57,723
Well, maybe joking.

509
00:23:59,160 --> 00:24:01,170
You know, the university
should just be buying

510
00:24:01,170 --> 00:24:02,788
fields of warehouse space

511
00:24:02,788 --> 00:24:07,020
to put a bunch of AI, you know, scientists

512
00:24:07,020 --> 00:24:08,326
to do all the science.

513
00:24:08,326 --> 00:24:09,840
- Isn't that what the genesis or something

514
00:24:09,840 --> 00:24:11,200
that the Trump, the White House?

515
00:24:11,200 --> 00:24:15,060
- Yeah, I think, and there
are many other, you know,

516
00:24:15,060 --> 00:24:17,310
science organizations who are interested

517
00:24:17,310 --> 00:24:20,130
in this sort of vision,
but I think, you know,

518
00:24:20,130 --> 00:24:21,852
the key thing is to really, like,

519
00:24:21,852 --> 00:24:25,020
if we want to turn it into a
reinforcement learning problem,

520
00:24:25,020 --> 00:24:27,724
I think that we need
to have robots somehow,

521
00:24:27,724 --> 00:24:30,870
and, you know, I think the state of that

522
00:24:30,870 --> 00:24:33,270
is still kinda more here than here,

523
00:24:33,270 --> 00:24:36,900
but I think using things like world models

524
00:24:36,900 --> 00:24:38,850
obviously would make a huge difference.

525
00:24:39,900 --> 00:24:41,610
The potential there is super exciting,

526
00:24:41,610 --> 00:24:44,558
and I think also, you
know, being able to handle

527
00:24:44,558 --> 00:24:48,300
also all of the data that's out there

528
00:24:48,300 --> 00:24:49,950
in the form of scientific literature

529
00:24:49,950 --> 00:24:51,570
and all this knowledge
that we spent, you know,

530
00:24:51,570 --> 00:24:54,675
hundreds of years and they're
trapped in these ancient,

531
00:24:54,675 --> 00:24:58,649
you know, photocopies of a
fax of a PDF or something.

532
00:24:58,649 --> 00:25:02,387
Being able to extract all of
that and use it in some way

533
00:25:02,387 --> 00:25:05,250
I think would be very exciting.

534
00:25:05,250 --> 00:25:07,290
- Yeah, that was actually
what I was getting to.

535
00:25:07,290 --> 00:25:09,014
I'll be the plumber.

536
00:25:09,014 --> 00:25:10,680
(panelists laugh)

537
00:25:10,680 --> 00:25:12,000
Because like, typically, but I think

538
00:25:12,000 --> 00:25:14,749
what you touched on earlier
is like very important.

539
00:25:14,749 --> 00:25:18,060
A lot of times, really
mission critical information

540
00:25:18,060 --> 00:25:19,770
is not in public.

541
00:25:19,770 --> 00:25:21,360
It is like, you know, whether it's like

542
00:25:21,360 --> 00:25:24,210
a research institution's
proprietary reports

543
00:25:24,210 --> 00:25:25,424
or it's, you know, companies

544
00:25:25,424 --> 00:25:26,938
like corporate business knowledge,

545
00:25:26,938 --> 00:25:29,370
those are not searchable online.

546
00:25:29,370 --> 00:25:31,080
So a lot of times when we are launching

547
00:25:31,080 --> 00:25:33,727
these big, you know,
groundbreaking initiatives,

548
00:25:33,727 --> 00:25:38,340
it requires tapping into
some triple knowledge

549
00:25:38,340 --> 00:25:40,800
that is in the form of
documents a lot of time,

550
00:25:40,800 --> 00:25:42,270
whether that's like physical documents,

551
00:25:42,270 --> 00:25:43,732
digitized document doesn't really matter.

552
00:25:43,732 --> 00:25:46,050
But because these are proprietary,

553
00:25:46,050 --> 00:25:49,380
a lot of time this hasn't been digitized.

554
00:25:49,380 --> 00:25:53,171
So we do this a lot with
like research institutions,

555
00:25:53,171 --> 00:25:56,223
we actually did this with one MPO

556
00:25:56,223 --> 00:26:01,223
that reports on the carbon
emission reports across the globe

557
00:26:02,520 --> 00:26:04,530
and they have like years of reports

558
00:26:04,530 --> 00:26:08,010
that is extremely complicated,
and we just, you know,

559
00:26:08,010 --> 00:26:12,360
unlocked the entire reports
that they had it in depository

560
00:26:12,360 --> 00:26:14,100
and that enabled them

561
00:26:14,100 --> 00:26:16,549
to evaluate all the monitoring progress,

562
00:26:16,549 --> 00:26:20,040
what are the trends that they
haven't been able to monitor

563
00:26:20,040 --> 00:26:25,040
when this information was
not easily searchable.

564
00:26:25,230 --> 00:26:29,340
So I think wherever I go,
plumber is needed everywhere

565
00:26:29,340 --> 00:26:31,290
so happy to collaborate.

566
00:26:31,290 --> 00:26:34,560
- All right, I think we are
coming up on with an idea.

567
00:26:34,560 --> 00:26:37,890
So we're gonna build a AI scientist robot

568
00:26:37,890 --> 00:26:39,720
that is powered by the
vision language models

569
00:26:39,720 --> 00:26:43,080
to take us through the
libraries that can do the OCR,

570
00:26:43,080 --> 00:26:44,653
read all the PDFs that you referenced,

571
00:26:44,653 --> 00:26:47,610
and make biological discoveries.

572
00:26:47,610 --> 00:26:49,923
Okay, good, let's go get some funding.

573
00:26:51,030 --> 00:26:52,503
- Any VCs in the audience?

574
00:26:53,718 --> 00:26:56,913
- Just use AMD hardware, that's all.

575
00:26:57,909 --> 00:27:02,909
Okay, that is fun, and I think
that is indicative of like,

576
00:27:04,470 --> 00:27:07,610
the transformative, you know,

577
00:27:07,610 --> 00:27:09,738
effect that AI is having, right?

578
00:27:09,738 --> 00:27:13,530
I think of it almost similar
to like electricity, right?

579
00:27:13,530 --> 00:27:16,380
Like yeah, we discovered
electricity, we lit up a bulb,

580
00:27:16,380 --> 00:27:18,495
but now it's like, oh, I can run a motor,

581
00:27:18,495 --> 00:27:21,570
I can power an engine, I
can get transportation.

582
00:27:21,570 --> 00:27:24,733
I can, you know, there are
like so many other pieces of it

583
00:27:24,733 --> 00:27:28,975
that electricity, you know, unlocked,

584
00:27:28,975 --> 00:27:32,485
and I think of like these
core foundational models

585
00:27:32,485 --> 00:27:37,050
and LLMs, and VLMs also.

586
00:27:37,050 --> 00:27:39,570
Enabling that level of like unlock

587
00:27:39,570 --> 00:27:42,930
that we are still at the
early stages of like,

588
00:27:42,930 --> 00:27:47,342
trying to understand and reason with.

589
00:27:47,342 --> 00:27:48,727
So that's super exciting.

590
00:27:48,727 --> 00:27:53,727
So are there places where
you think we are not...

591
00:27:56,717 --> 00:27:59,834
There are places where you
think we should be applying AI

592
00:27:59,834 --> 00:28:03,540
and we haven't yet unlocked a whole area

593
00:28:03,540 --> 00:28:08,540
of like, you know, like DNA sequencing

594
00:28:09,360 --> 00:28:11,861
or, you know, some areas that you think

595
00:28:11,861 --> 00:28:14,351
is underrepresented with AI

596
00:28:14,351 --> 00:28:19,080
so that somebody else can go
start a company right now.

597
00:28:19,080 --> 00:28:22,713
But thoughts on areas underrepresented?

598
00:28:23,610 --> 00:28:25,020
- Oh man, you should
start with these guys.

599
00:28:25,020 --> 00:28:26,610
- Okay. (laughs)

600
00:28:26,610 --> 00:28:27,443
- I feel like walked around
the hall and I'm like,

601
00:28:27,443 --> 00:28:29,761
well, pretty much every
area is represented.

602
00:28:29,761 --> 00:28:32,670
- What do you think, Roman?

603
00:28:32,670 --> 00:28:35,550
I can't really pinpoint
a specific vertical

604
00:28:35,550 --> 00:28:38,820
because we are still at
that stage where, you know,

605
00:28:38,820 --> 00:28:41,430
we haven't even, like,
most companies out there

606
00:28:41,430 --> 00:28:43,290
are not really using advanced AI

607
00:28:43,290 --> 00:28:45,360
in their day to day processes.

608
00:28:45,360 --> 00:28:47,310
So I feel like we are
still at the very beginning

609
00:28:47,310 --> 00:28:52,310
of the cycle of adapting AI
and figuring out, you know,

610
00:28:53,370 --> 00:28:56,490
how it can change the way we do things.

611
00:28:56,490 --> 00:28:57,323
- Right.

612
00:29:00,083 --> 00:29:02,010
- Hard to tell.

613
00:29:02,010 --> 00:29:02,910
I'm passing it on.

614
00:29:03,960 --> 00:29:07,279
- Well, I think physical AI
is obvious the next hot topic.

615
00:29:07,279 --> 00:29:11,400
That one thing that,
you know, it's, again,

616
00:29:11,400 --> 00:29:13,830
I'm coming from a data and, you know,

617
00:29:13,830 --> 00:29:15,295
the foundation point of view,

618
00:29:15,295 --> 00:29:18,630
we've collected all these
like text like language-based,

619
00:29:18,630 --> 00:29:22,290
text-based data across, you
know, scrapping entire internet.

620
00:29:22,290 --> 00:29:26,160
But for the physical AI,
basically how do we collect

621
00:29:26,160 --> 00:29:30,466
the real human interaction data

622
00:29:30,466 --> 00:29:34,920
for training a really strong work model

623
00:29:34,920 --> 00:29:36,570
or in a physical model?

624
00:29:36,570 --> 00:29:38,430
And I know there are a lot of startups

625
00:29:38,430 --> 00:29:41,129
who are doing that at a
very early stage, but like,

626
00:29:41,129 --> 00:29:43,500
if one can figure out

627
00:29:43,500 --> 00:29:48,500
how to systematically
collect these data points,

628
00:29:49,350 --> 00:29:51,870
for example, like how a human, you know,

629
00:29:51,870 --> 00:29:54,390
sweep the floor when there is a corner

630
00:29:54,390 --> 00:29:57,360
that's really hard to get,
like, robot's not gonna,

631
00:29:57,360 --> 00:29:59,280
I mean, it's not gonna figure that out,

632
00:29:59,280 --> 00:30:00,840
but like if someone's gonna actually like,

633
00:30:00,840 --> 00:30:02,400
put a bunch of like stuff on their hand

634
00:30:02,400 --> 00:30:03,810
and like, you know, collect that data,

635
00:30:03,810 --> 00:30:04,980
like, those kind of things,

636
00:30:04,980 --> 00:30:06,990
I think there's a big, big market there

637
00:30:06,990 --> 00:30:09,571
and that hasn't been tapped

638
00:30:09,571 --> 00:30:11,940
and I know like we are
trying to use the robotics

639
00:30:11,940 --> 00:30:13,440
to collect that data.

640
00:30:13,440 --> 00:30:16,054
So I think there's a
lot of creative thinking

641
00:30:16,054 --> 00:30:17,550
going around in the industry, but yeah,

642
00:30:17,550 --> 00:30:19,860
overall I think if we can figure that out,

643
00:30:19,860 --> 00:30:21,390
we can build a lot better model

644
00:30:21,390 --> 00:30:23,040
'cause garbage in, garbage out.

645
00:30:23,040 --> 00:30:24,780
So I think the data collection site

646
00:30:24,780 --> 00:30:27,390
will be the next really hot topic.

647
00:30:27,390 --> 00:30:28,958
- Don't look any further.

648
00:30:28,958 --> 00:30:29,916
- There we go.

649
00:30:29,916 --> 00:30:32,281
- This is at the core of what we're doing.

650
00:30:32,281 --> 00:30:33,239
- Yeah, exactly, exactly.

651
00:30:33,239 --> 00:30:36,909
- But that is a very
good point, and in fact,

652
00:30:36,909 --> 00:30:40,517
just a few weeks ago we
had like John Carmack

653
00:30:40,517 --> 00:30:45,517
trying out like the RYZEN Max
395, the strict halo product.

654
00:30:46,170 --> 00:30:50,833
He has a reinforcement
learning based AGI company,

655
00:30:53,130 --> 00:30:55,110
which is basically trying
to do exactly that.

656
00:30:55,110 --> 00:30:58,189
It's like you have a reinforcement
learning based method

657
00:30:58,189 --> 00:31:01,539
to quickly learn how to
get to that corner, right?

658
00:31:01,539 --> 00:31:03,434
And then you have a reward system,

659
00:31:03,434 --> 00:31:05,790
and there are companies built

660
00:31:05,790 --> 00:31:08,563
just to streamline the
reward system, right?

661
00:31:08,563 --> 00:31:10,169
just to streamline the
reward system, right?

662
00:31:10,169 --> 00:31:15,169
but when do you know, like,
just the reward itself is like,

663
00:31:15,303 --> 00:31:17,700
okay, this is right, this is wrong, right?

664
00:31:17,700 --> 00:31:20,179
Or it's trending towards
right, trending towards wrong.

665
00:31:20,179 --> 00:31:25,179
So there's a lot of that kind
of innovation that's ongoing.

666
00:31:25,587 --> 00:31:29,432
And I think, you know,
reinforcement learning itself

667
00:31:29,432 --> 00:31:34,037
is another way that
will help us, you know,

668
00:31:34,037 --> 00:31:35,850
get to the basics of like,

669
00:31:35,850 --> 00:31:39,261
how we learn how to walk or talk, right?

670
00:31:39,261 --> 00:31:43,648
It's a, you know, natural phenomena

671
00:31:43,648 --> 00:31:47,040
that we haven't yet
unlocked in terms of AI.

672
00:31:47,040 --> 00:31:50,193
I do think AI, my
personal opinion is like,

673
00:31:50,193 --> 00:31:55,193
on that same topic, AI will
kind of make its way into things

674
00:31:55,950 --> 00:31:57,270
that we don't even know as AI.

675
00:31:57,270 --> 00:32:00,690
It's like just indistinguishable
and we are just like,

676
00:32:00,690 --> 00:32:03,637
oh wow, now I can do that, right?

677
00:32:03,637 --> 00:32:07,200
And then suddenly it's
like that, you know,

678
00:32:07,200 --> 00:32:09,453
flight rebooking example that I use,

679
00:32:10,410 --> 00:32:14,100
and then it unlocks for
huge amounts of people

680
00:32:14,100 --> 00:32:17,010
that are not necessarily
thinking of it as AI, right?

681
00:32:17,010 --> 00:32:19,110
Like, they're just thinking of it as like,

682
00:32:20,021 --> 00:32:23,880
something that enhances their life, right?

683
00:32:23,880 --> 00:32:28,140
So I think it's incredibly exciting

684
00:32:28,140 --> 00:32:32,044
to be at that stage of like revolution.

685
00:32:32,044 --> 00:32:34,881
So, you know, let's switch gears

686
00:32:34,881 --> 00:32:39,881
just in terms of like
actual how your current,

687
00:32:41,352 --> 00:32:44,318
we talked about infrastructure.

688
00:32:44,318 --> 00:32:47,430
Are there other thoughts in terms of like,

689
00:32:47,430 --> 00:32:52,080
how do you make it, make
your companies, you know,

690
00:32:52,080 --> 00:32:54,570
operate in an AI era?

691
00:32:54,570 --> 00:32:59,310
Like, what is important for you
to be competitive, you know,

692
00:32:59,310 --> 00:33:02,911
but at the same time do the
research that you have to do,

693
00:33:02,911 --> 00:33:04,712
make sure you're, you know,

694
00:33:04,712 --> 00:33:08,010
targeting a market that's moving so fast.

695
00:33:08,010 --> 00:33:09,282
Any thoughts that, you know,

696
00:33:09,282 --> 00:33:10,890
you want to share just in general

697
00:33:10,890 --> 00:33:14,403
about like how you as a
company approach that?

698
00:33:16,731 --> 00:33:18,120
- I can start.

699
00:33:18,120 --> 00:33:21,927
Yeah, yeah, so one thing that's, you know,

700
00:33:21,927 --> 00:33:26,610
I think I haven't shared this
context earlier, but Upstage,

701
00:33:26,610 --> 00:33:29,730
our LLM we are positioning our LLM

702
00:33:29,730 --> 00:33:31,800
as a sovereign AI of Korea.

703
00:33:31,800 --> 00:33:36,800
So there's a very big like,
data sovereignty concept

704
00:33:37,736 --> 00:33:40,748
that is core of our identity.

705
00:33:40,748 --> 00:33:45,748
When we approach AI as really
a strong strategic asset

706
00:33:46,950 --> 00:33:50,947
that we should be able
to control and manage,

707
00:33:50,947 --> 00:33:55,327
not just the performance of a
single infrastructure provider

708
00:33:55,327 --> 00:33:57,210
is good enough.

709
00:33:57,210 --> 00:33:59,653
We need to be able to diversify

710
00:33:59,653 --> 00:34:02,520
just like how we are going multi-cloud.

711
00:34:02,520 --> 00:34:04,140
Like, a lot of enterprises are, you know,

712
00:34:04,140 --> 00:34:05,430
tapping into multi-cloud.

713
00:34:05,430 --> 00:34:07,030
So for the stability of the system,

714
00:34:07,030 --> 00:34:12,030
and I think when we approach
this AI infrastructure,

715
00:34:12,840 --> 00:34:17,741
we're thinking the same that
we are building that AI model,

716
00:34:17,741 --> 00:34:22,741
that our vision is this
is going to empower Korea

717
00:34:22,948 --> 00:34:24,578
to the next level,

718
00:34:24,578 --> 00:34:28,770
and we want to be that
AI layer for our economy.

719
00:34:28,770 --> 00:34:31,860
Then we need to think
about how do we make sure

720
00:34:31,860 --> 00:34:35,220
that we build the stability in
terms of the infrastructure?

721
00:34:35,220 --> 00:34:38,919
So, you know, we wanted to
make sure AMD is in the mix,

722
00:34:38,919 --> 00:34:41,670
all the other GPU
providers are in the mix.

723
00:34:41,670 --> 00:34:45,120
So all the risks are hedged, and frankly,

724
00:34:45,120 --> 00:34:46,410
like, we initially thought

725
00:34:46,410 --> 00:34:49,140
that it will be a
difficult transition for us

726
00:34:49,140 --> 00:34:51,030
to go from one to another,

727
00:34:51,030 --> 00:34:55,110
but I think there has been
enough improvement in the system

728
00:34:55,110 --> 00:34:57,270
that we can actually easily port over

729
00:34:57,270 --> 00:34:58,770
and make sure things are compatible,

730
00:34:58,770 --> 00:35:03,330
which our engineers are very
happy when we did a pilot.

731
00:35:03,330 --> 00:35:06,900
So for us, when we think about, you know,

732
00:35:06,900 --> 00:35:08,220
how we make sure we build

733
00:35:08,220 --> 00:35:10,965
the most compelling AI
layer for the country,

734
00:35:10,965 --> 00:35:13,674
we think about the hardware sovereignty,

735
00:35:13,674 --> 00:35:15,231
the data sovereignty,

736
00:35:15,231 --> 00:35:17,649
and all the training method

737
00:35:17,649 --> 00:35:20,010
and the approach that we are taking

738
00:35:20,010 --> 00:35:23,820
to make sure that what
we build is competitive

739
00:35:23,820 --> 00:35:25,680
but also authentic.

740
00:35:25,680 --> 00:35:28,410
So if there's any random variables

741
00:35:28,410 --> 00:35:31,260
happened in a macro level, micro level,

742
00:35:31,260 --> 00:35:33,300
we're able to hedge the risk.

743
00:35:33,300 --> 00:35:34,306
- Nice.

744
00:35:34,306 --> 00:35:36,900
That's great to hear that, you know,

745
00:35:36,900 --> 00:35:40,170
porting to AMD was seamless
because if it isn't,

746
00:35:40,170 --> 00:35:42,847
that's my problem to let you know,

747
00:35:43,755 --> 00:35:47,640
You can email me and be like,
Anush, we need this fixed

748
00:35:47,640 --> 00:35:49,140
and we'll make sure it's fixed.

749
00:35:49,140 --> 00:35:50,194
But that's great.

750
00:35:50,194 --> 00:35:52,699
Arjun, any thoughts from your side?

751
00:35:52,699 --> 00:35:54,780
- Yeah, I mean, for us, you know,

752
00:35:54,780 --> 00:35:58,830
and our team is very diverse.

753
00:35:58,830 --> 00:36:00,660
I mean, because we've got, you know,

754
00:36:00,660 --> 00:36:01,770
we've got software engineers,

755
00:36:01,770 --> 00:36:04,380
we have computational
biologists, which are, you know,

756
00:36:04,380 --> 00:36:06,390
bioinformatics people who are taking in

757
00:36:06,390 --> 00:36:09,510
the raw sequencing data and, you know,

758
00:36:09,510 --> 00:36:10,500
turning that into things

759
00:36:10,500 --> 00:36:12,120
that we could put into
machine learning models.

760
00:36:12,120 --> 00:36:13,950
We have a huge experimental team

761
00:36:13,950 --> 00:36:16,819
that's, you know,
actually making this data.

762
00:36:16,819 --> 00:36:19,860
For us, what that means
in terms of infrastructure

763
00:36:19,860 --> 00:36:23,220
is we need to have
infrastructure like AWS and AMD

764
00:36:23,220 --> 00:36:26,524
that is very flexible and seamless.

765
00:36:26,524 --> 00:36:31,244
So that we're, you know, our
resources are stretched thin,

766
00:36:31,244 --> 00:36:34,065
we have so many different
people doing different things.

767
00:36:34,065 --> 00:36:36,111
They need things to just work,

768
00:36:36,111 --> 00:36:39,360
and they need to just work
out of the box seamlessly

769
00:36:39,360 --> 00:36:42,231
so we're not spending a lot of time,

770
00:36:42,231 --> 00:36:45,300
you know, handling all of
that, all of those details,

771
00:36:45,300 --> 00:36:46,680
and rather people are focusing

772
00:36:46,680 --> 00:36:51,680
on where they have their main
sort of competence and talent.

773
00:36:52,380 --> 00:36:56,760
So yeah, I would say, you
know, along those lines,

774
00:36:56,760 --> 00:36:57,870
one of the things that's been great

775
00:36:57,870 --> 00:37:00,060
about working with AMD
is really, you know,

776
00:37:00,060 --> 00:37:03,049
we feel like we found a
partner not so much a vendor.

777
00:37:03,049 --> 00:37:08,049
So we found people that will
help us handle those details

778
00:37:08,130 --> 00:37:09,990
when they come up so that again,

779
00:37:09,990 --> 00:37:12,194
we can focus on what we need to do

780
00:37:12,194 --> 00:37:16,170
rather than worrying about
things that we're not experts in.

781
00:37:16,170 --> 00:37:17,220
- No, that's great to hear.

782
00:37:17,220 --> 00:37:20,820
I think from an AMD
ethos standpoint, right?

783
00:37:20,820 --> 00:37:24,350
Like, one of the things
that I really enjoy at AMD

784
00:37:24,350 --> 00:37:25,939
is that it's a open ecosystem

785
00:37:25,939 --> 00:37:28,650
and it's open source obviously, right?

786
00:37:28,650 --> 00:37:29,693
At a technical level,

787
00:37:29,693 --> 00:37:32,105
going back to your thing on sovereign AI,

788
00:37:32,105 --> 00:37:35,310
it can be air gapped, but
every line of code is like,

789
00:37:35,310 --> 00:37:37,320
you can build it and you own it

790
00:37:37,320 --> 00:37:38,789
and so you know what's in there.

791
00:37:38,789 --> 00:37:41,820
So it gives you, you know,
peace of mind saying,

792
00:37:41,820 --> 00:37:46,200
yes, this is ours, and
ours as a collective

793
00:37:46,200 --> 00:37:47,890
in terms of like how we enable you.

794
00:37:47,890 --> 00:37:50,610
But then ours as in like, your deployment,

795
00:37:50,610 --> 00:37:52,843
it's your deployment. Like, we
want to enable you to do that

796
00:37:52,843 --> 00:37:55,018
and we want you to be
able to like build on it

797
00:37:55,018 --> 00:37:57,960
and have your proprietary IP

798
00:37:57,960 --> 00:38:01,560
and your things in a safe environment

799
00:38:01,560 --> 00:38:04,786
that you're able to
like, verify and validate

800
00:38:04,786 --> 00:38:07,230
without, you know, some binary blobs

801
00:38:07,230 --> 00:38:08,063
that we can throw around

802
00:38:08,063 --> 00:38:11,610
that may not necessarily provide that.

803
00:38:11,610 --> 00:38:13,530
But yeah, I think the open ecosystem

804
00:38:13,530 --> 00:38:18,392
and the important point of
just working is another piece

805
00:38:18,392 --> 00:38:22,740
that we take very seriously,
and I do like how you put it.

806
00:38:22,740 --> 00:38:25,156
We do see, you know,
everyone as like partners

807
00:38:25,156 --> 00:38:27,930
and it's not just like, hey, buy our GPU

808
00:38:27,930 --> 00:38:30,202
and go download something
and go do something, right?

809
00:38:30,202 --> 00:38:35,202
You know, I personally
have seen deployments

810
00:38:35,220 --> 00:38:38,880
in, you know, go from like,
hey, let's have a discussion

811
00:38:38,880 --> 00:38:42,240
on how we could do this
to, in like, you know,

812
00:38:42,240 --> 00:38:44,010
a month or two they're deployed at scale

813
00:38:44,010 --> 00:38:47,310
in tens of thousands of
GPUs and it's just working

814
00:38:47,310 --> 00:38:48,600
is amazing to see.

815
00:38:48,600 --> 00:38:51,390
So it's great to see that.

816
00:38:51,390 --> 00:38:55,680
But Roman, I wouldn't want
you to miss your flight.

817
00:38:55,680 --> 00:38:56,976
- No, go for it.

818
00:38:56,976 --> 00:38:57,809
It's all good.

819
00:38:57,809 --> 00:39:00,030
- But we'd love to hear any, you know,

820
00:39:00,030 --> 00:39:02,250
any final thoughts from you.

821
00:39:02,250 --> 00:39:05,070
We'll keep them on stage
for a little bit longer

822
00:39:05,070 --> 00:39:06,990
so that you can peel off
whenever you're ready.

823
00:39:06,990 --> 00:39:09,030
- No, I think those are
all very important points

824
00:39:09,030 --> 00:39:12,120
that you guys made,
and I guess I wanna put

825
00:39:12,120 --> 00:39:14,850
one additional focus point on there,

826
00:39:14,850 --> 00:39:17,220
and this is kind of, we are at a point

827
00:39:17,220 --> 00:39:20,940
where, you know, open data sets

828
00:39:20,940 --> 00:39:22,230
become more and more important,

829
00:39:22,230 --> 00:39:24,090
and when I say open data sets,

830
00:39:24,090 --> 00:39:28,110
I'm not talking about some
random research dataset.

831
00:39:28,110 --> 00:39:30,390
I'm talking about high quality data sets

832
00:39:30,390 --> 00:39:33,990
that actually bring the models
from where they are today

833
00:39:33,990 --> 00:39:37,410
to the next level
because we are at a point

834
00:39:37,410 --> 00:39:40,590
where it's really about domain specificity

835
00:39:40,590 --> 00:39:45,590
and understanding environments
on a more granular basis.

836
00:39:48,090 --> 00:39:49,620
It's tough, right?

837
00:39:49,620 --> 00:39:54,000
Because certainly in the
industrial sector in that data,

838
00:39:54,000 --> 00:39:55,860
there's a lot of proprietary information.

839
00:39:55,860 --> 00:39:58,170
So there's of course
not a lot of willingness

840
00:39:58,170 --> 00:40:02,220
to share that data with
the wider community,

841
00:40:02,220 --> 00:40:05,250
but it's starting to stall the progress

842
00:40:05,250 --> 00:40:09,457
that we make on these
models and the capabilities,

843
00:40:10,500 --> 00:40:13,500
the generalization
capabilities of these models.

844
00:40:13,500 --> 00:40:18,500
So at Rambler, we are
kind of counteracting that

845
00:40:18,720 --> 00:40:23,100
by working on an open source data set.

846
00:40:23,100 --> 00:40:25,090
Really high quality

847
00:40:25,966 --> 00:40:29,628
with regards to the
annotations and labels,

848
00:40:29,628 --> 00:40:32,940
but of course we are, you
know, small fish, right?

849
00:40:32,940 --> 00:40:34,740
At the end of the day.

850
00:40:34,740 --> 00:40:37,497
So for the community to be willing

851
00:40:37,497 --> 00:40:42,497
to start contributing to that
pool of data that can be used,

852
00:40:43,613 --> 00:40:45,660
and maybe even a little bit outside

853
00:40:45,660 --> 00:40:47,790
of just a traditional research community.

854
00:40:47,790 --> 00:40:49,601
I think that will be critical

855
00:40:49,601 --> 00:40:54,601
to unlock the next
generation of these models.

856
00:40:54,720 --> 00:40:58,920
- Yeah, I do think, you
know, good data sets,

857
00:40:58,920 --> 00:41:00,900
good open source models also.

858
00:41:00,900 --> 00:41:01,999
- Correct.

859
00:41:01,999 --> 00:41:04,157
- That are good baselines

860
00:41:04,157 --> 00:41:07,257
so that you can still
build your, you know,

861
00:41:07,257 --> 00:41:12,257
proprietary, you know,
like modified version of it

862
00:41:13,560 --> 00:41:16,463
that solves a specific use case, right?

863
00:41:16,463 --> 00:41:20,040
We want you to have the
ability to build on top of it,

864
00:41:20,040 --> 00:41:22,560
but at the same time, this
gives you a good baseline

865
00:41:22,560 --> 00:41:25,110
that is like, oh, this is
what GPT assist does, right?

866
00:41:25,110 --> 00:41:27,000
Or this is what Llama does,

867
00:41:27,000 --> 00:41:31,020
and then the data sets that
they used for those training,

868
00:41:31,020 --> 00:41:33,150
you know, that also makes it powerful.

869
00:41:33,150 --> 00:41:36,137
So to make it available, you know,

870
00:41:36,137 --> 00:41:40,325
for the open community to innovate

871
00:41:40,325 --> 00:41:42,453
and move the ball forward.

872
00:41:43,624 --> 00:41:44,457
Cool.

873
00:41:44,457 --> 00:41:46,762
So I think, you know, what I'd like

874
00:41:46,762 --> 00:41:49,800
to kind of like bring the thoughts back,

875
00:41:49,800 --> 00:41:52,350
and then we'll have some,
you know, time for Q&A

876
00:41:52,350 --> 00:41:55,073
if folks have Q&A, but, you know,

877
00:41:55,073 --> 00:42:00,030
I think it's super exciting
to have everyone here,

878
00:42:00,030 --> 00:42:03,420
you know, talk about
different parts of AI, right?

879
00:42:03,420 --> 00:42:05,220
Like, they're almost like, you know,

880
00:42:06,111 --> 00:42:07,890
before getting on stage,

881
00:42:07,890 --> 00:42:10,560
it's like people here may not realize

882
00:42:10,560 --> 00:42:12,151
how diverse it is, right?

883
00:42:12,151 --> 00:42:13,530
And when you go to the expo flow,

884
00:42:13,530 --> 00:42:15,857
it's even like 10 X more diverse.

885
00:42:15,857 --> 00:42:19,316
But, you know, from an AMD
standpoint, we wanna make sure

886
00:42:19,316 --> 00:42:23,595
that you have choice in terms of hardware,

887
00:42:23,595 --> 00:42:26,892
you have freedom in terms of the software,

888
00:42:26,892 --> 00:42:31,892
and then you have like a partner
in terms of the ecosystem.

889
00:42:31,976 --> 00:42:35,880
So that we want to walk
that last mile of AI

890
00:42:35,880 --> 00:42:38,520
so that you can then bring value

891
00:42:38,520 --> 00:42:41,019
to each of the verticals
that you are going after.

892
00:42:41,019 --> 00:42:45,090
While we obviously are,
you know, quarterbacking

893
00:42:45,090 --> 00:42:48,874
and would love to see you
all succeed in that front,

894
00:42:48,874 --> 00:42:50,820
and it doesn't necessarily mean

895
00:42:50,820 --> 00:42:53,190
that we want to take, you know,

896
00:42:53,190 --> 00:42:54,720
it's not a vertically integrated thing

897
00:42:54,720 --> 00:42:59,720
to have a combination of
like Bio Nemo for you,

898
00:43:00,840 --> 00:43:03,653
or, you know, we are not
very prescriptive that way.

899
00:43:03,653 --> 00:43:05,820
We think of it as an open ecosystem

900
00:43:05,820 --> 00:43:08,400
where you should have the tools needed

901
00:43:08,400 --> 00:43:10,209
and the tools we will definitely provide.

902
00:43:10,209 --> 00:43:14,670
So that you can do the best
work that you can for that.

903
00:43:14,670 --> 00:43:16,500
Any last thoughts from you guys

904
00:43:16,500 --> 00:43:19,195
before we see if there are any questions?

905
00:43:19,195 --> 00:43:20,670
Roman?

906
00:43:20,670 --> 00:43:22,230
- No, I think you hit
the nail on the head.

907
00:43:22,230 --> 00:43:25,050
I think you fulfill a very important role

908
00:43:25,050 --> 00:43:28,420
also on the tool side to
enable companies out there

909
00:43:29,310 --> 00:43:31,230
to focus on, you know,

910
00:43:31,230 --> 00:43:34,980
building these more
domain-specific solutions

911
00:43:34,980 --> 00:43:37,680
and, you know, you doing
some of the groundwork.

912
00:43:37,680 --> 00:43:39,688
I think this is really the enabling factor

913
00:43:39,688 --> 00:43:42,180
also for new startups that come out

914
00:43:42,180 --> 00:43:47,180
that don't have the manpower,
the budget to build-

915
00:43:47,348 --> 00:43:48,181
- All the tools.

916
00:43:48,181 --> 00:43:50,610
- All the tools around
it, all the agent stacks,

917
00:43:50,610 --> 00:43:52,890
all the, you know, safety
security protocols.

918
00:43:52,890 --> 00:43:54,360
You can go down the list of things

919
00:43:54,360 --> 00:43:57,300
that you need in a large scale deployment.

920
00:43:57,300 --> 00:44:01,478
So thank you for putting in the hard work.

921
00:44:01,478 --> 00:44:03,003
- Kasey?

922
00:44:04,383 --> 00:44:08,370
- Yeah, I think it's related
to what the earlier point here

923
00:44:08,370 --> 00:44:11,730
that I just want to, I know
they're not in this room,

924
00:44:11,730 --> 00:44:14,373
but shout out to the AMD Ventures team.

925
00:44:15,240 --> 00:44:19,230
It was incredible working
with the venture side.

926
00:44:19,230 --> 00:44:22,207
We had, you know, before we're still

927
00:44:22,207 --> 00:44:24,150
in the process of making it,

928
00:44:24,150 --> 00:44:26,850
but before when we were
very small, you know,

929
00:44:26,850 --> 00:44:28,530
when we were just getting started,

930
00:44:28,530 --> 00:44:32,220
AMD believed in our vision,
supported our vision,

931
00:44:32,220 --> 00:44:35,553
and, you know, decided to be the partner

932
00:44:35,553 --> 00:44:37,740
and sponsor of our journey,

933
00:44:37,740 --> 00:44:42,480
and all the technical
support, all the, you know,

934
00:44:42,480 --> 00:44:44,850
leadership support has
been just incredible,

935
00:44:44,850 --> 00:44:48,976
and, you know, anytime
AMD's there will be there

936
00:44:48,976 --> 00:44:51,240
and, you know, really thankful

937
00:44:51,240 --> 00:44:53,760
for the support that you've shown, yeah.

938
00:44:53,760 --> 00:44:55,590
- Arjun, any final thoughts?

939
00:44:55,590 --> 00:44:57,913
- I would just echo the same
thing is that, you know,

940
00:44:57,913 --> 00:45:00,330
it's been wonderful to work with you guys,

941
00:45:00,330 --> 00:45:04,350
and, you know, hope it continues

942
00:45:04,350 --> 00:45:06,363
for foreseeable future.

943
00:45:06,363 --> 00:45:08,130
- We will make sure it continues,

944
00:45:08,130 --> 00:45:11,260
and looking forward to
making you all successful.

945
00:45:11,260 --> 00:45:13,350
If there are any questions,

946
00:45:13,350 --> 00:45:15,807
happy to take, you know,
a couple of questions.

947
00:45:15,807 --> 00:45:16,980
- I'm very sorry.

948
00:45:16,980 --> 00:45:18,120
- Thank you.

949
00:45:18,120 --> 00:45:19,608
Don't miss your flight.

950
00:45:19,608 --> 00:45:22,608
(attendees applaud)

