# AWS re:Invent 2025 技术会议总结

## 会议概述

本次会议由AWS的两位资深工程师Mustafa Turun和Majanadan主讲，重点探讨了AWS的运维卓越性（Operational Excellence）和可靠性实践。Mustafa在AWS工作了12年半，主要负责CloudWatch和可观测性团队；Majanadan领导全球专业解决方案架构团队，专注于云运维领域，在AWS工作近8年。

会议通过咖啡店的类比引入主题，说明了运维卓越性的重要性。演讲者强调，AWS将运维卓越性视为一项核心功能而非事后考虑，并通过建立机制（mechanisms）而非依赖良好意愿来实现持续改进。会议详细介绍了AWS内部使用的运维飞轮模型，包括四个关键驱动因素：可观测性（Observability）、事件响应（Incident Response）、审查（Review）和就绪性（Readiness）。这些驱动因素相互促进，形成良性循环，不断提升运维质量。

演讲还深入展示了CloudWatch Application Signals的实际应用，演示了如何通过SLO（服务级别目标）驱动的监控方式进行故障排查，以及如何利用开放标准（如OpenTelemetry）实现全面的可观测性。整个会议强调了AWS在架构设计、测试、部署和监控等各个环节对运维卓越性的投入和实践。

## 详细时间线

### 开场与概念介绍 (00:00 - 15:00)

00:00 - 02:30 - 开场互动
- 演讲者通过咖啡店关门维护的场景引入话题
- 讨论咖啡爱好者的痛点：到店后发现设备故障

02:30 - 05:00 - 演讲者自我介绍
- Mustafa Turun：AWS高级首席工程师，在AWS工作12.5年，主要负责CloudWatch和可观测性
- Majanadan：领导全球专业解决方案架构团队，专注云运维，在AWS工作近8年

05:00 - 08:00 - 卓越性vs完美主义
- 解释"卓越性"（Excellence）与"完美"（Perfection）的区别
- 引用Amazon两个领导力原则：偏向行动（Bias for Action）和坚持高标准（Insist on High Standards）
- 强调卓越性在速度和质量之间找到平衡，接受错误但从中学习

08:00 - 12:00 - AWS咖啡店类比
- 如果AWS运营咖啡店会如何做：
  - 基础设施层面增加冗余（多台咖啡机）
  - 运营多家店铺（类似多个数据中心）
  - 在不同区域部署（类似可用区）
  - 在全球不同地区部署（类似AWS区域）
- 介绍故障隔离边界的概念

12:00 - 15:00 - 架构选择
- 依赖隔离（Dependency Isolation）：为不同依赖创建独立线程池
- 蜂窝架构（Cellular Architecture）：创建多个堆栈副本，减少爆炸半径
- 推荐阅读Amazon Builder Library和Well-Architected Framework

### 运维卓越性机制 (15:00 - 35:00)

15:00 - 18:00 - 机制vs良好意愿
- 引用Jeff Bezos的话：良好意愿不够，需要机制
- 机制定义：有输入和输出的系统，从工具开始
- 介绍飞轮（Flywheel）概念

18:00 - 22:00 - Bezos的增长飞轮
- 客户体验驱动流量
- 流量吸引更多卖家
- 更多卖家带来更多选择
- 更多选择提升客户满意度
- 规模增长降低成本结构
- 低价格反馈到客户体验

22:00 - 25:00 - AWS运维卓越性飞轮
- 四个驱动因素：
  1. 可观测性（Observability）
  2. 事件响应（Incident Response）
  3. 审查（Review）
  4. 就绪性（Readiness）
- 这些因素相互促进，形成良性循环

### 就绪性（Readiness）(25:00 - 45:00)

25:00 - 28:00 - 运维就绪性审查（ORR）
- 服务上线前必须填写检查清单
- 关键问题示例：
  - 是否为客户体验指标定义了SLO并设置告警？
  - 是否有测试来发现和解决性能问题？
- 需要Bar Raiser审查和总监级别批准

28:00 - 35:00 - 测试实践
- 故障测试：在部署管道中持续创建故障场景
- 负载测试：每次代码提交都运行自动化负载测试
- 单用户测试：测试单个用户负载，避免嘈杂邻居问题
- 游戏日（Game Days）：手动破坏系统测试
  - 模拟网络中断、依赖故障
  - 测试运维人员响应能力
  - 验证运行手册和仪表板的有效性
- 推荐使用AWS Fault Injection Service

35:00 - 40:00 - 变更管理
- 人工操作需要详细的步骤文档（CM）
- CM需要Bar Raiser审查
- 关键要求：
  - 每个步骤都有回滚步骤
  - 在预生产环境测试过

40:00 - 45:00 - 发布卓越性
- 自动分析所有部署管道
- 根据规则检查管道合规性
- 不符合规则的管道会被阻止
- 典型管道要求：
  - 生产前有三个阶段
  - Gamma阶段视为生产环境
  - 包含充分的烘焙时间（Baking Time）
  - 运行各种测试包括负载测试
- 推荐阅读：Automating Safe Hands-off Deployments

### 可观测性（Observability）(45:00 - 70:00)

45:00 - 48:00 - 可观测性定义
- 来自控制理论的度量概念
- 系统越可观测，能获得的洞察越多
- 能够提出之前不知道该问的问题

48:00 - 52:00 - 实现可观测性的方法
- 仪器化（Instrumentation）系统
- 标准化数据收集
- 收集三大支柱：指标（Metrics）、日志（Logs）、追踪（Traces）

52:00 - 58:00 - AWS标准化实践
- Java示例：导入Activity类
- 即使不编写任何代码，也能自动获得：
  - 基础设施级别测量
  - 应用级别测量（持续时间、CPU、内存）
  - 请求ID、成功/失败状态
- 使用嵌入式指标格式（EMF - Embedded Metric Format）

58:00 - 63:00 - EMF详解
- 以JSON格式输出到CloudWatch Logs
- CloudWatch自动从日志中提取指标
- 开发者可以添加自定义业务指标
- 示例：bean_count、brew_time等自定义指标
- 自动生成可视化小部件

63:00 - 68:00 - 日志分析能力
- 使用CloudWatch Logs Insights进行查询
- 示例：按客户分组计算平均冲泡时间
- 每个请求都是一条日志
- 可以进行任意分析

68:00 - 70:00 - CloudWatch规模
- CloudWatch Logs：每月接收13 EB日志（每秒5 TB）
- CloudWatch Metrics：每月接收20千万亿（quadrillion）个指标数据点
- 演讲期间已接收约100 TB日志

### 客户需求与CloudWatch功能 (70:00 - 95:00)

70:00 - 73:00 - 开放标准
- 客户要求符合开放标准
- AWS Distro for OpenTelemetry (ADOT) SDK
- 自动捕获RED指标（请求率、错误、持续时间）和故障
- CloudWatch支持OTLP端点接收日志和追踪

73:00 - 76:00 - 易于设置
- EKS：CloudWatch Observability Add-on自动部署
- ECS：在任务定义中挂载自动仪器化容器
- Lambda：提供基于OpenTelemetry的Lambda层

76:00 - 80:00 - 开箱即用的关联
- 不想手动创建仪表板
- 不想手动关联信号（日志、指标、追踪）
- 不想手动关联基础设施和应用数据
- 需要高度主观的入门体验

80:00 - 83:00 - CloudWatch Application Signals
- 以应用为中心的可观测性
- AI驱动的根因分析
- 自动关联所有信号

83:00 - 88:00 - 基于SLO的监控
- 从业务SLA开始
- 建立SLO（服务级别目标）
- 设置错误预算
- 将业务需求与技术指标直接关联
- 可观测性成为业务功能而非仅技术关注点
- 减少数据收集量，提高平均解决时间（MTTR）

### 实际演示：故障排查 (88:00 - 120:00)

88:00 - 92:00 - 服务概览
- 进入Application Signals服务界面
- 显示多个微服务
- 根据SLO状态排序
- 识别不健康的应用和服务

92:00 - 96:00 - SLO详情
- 查看SLO列表
- 检查SLO状态、错误预算、延迟
- 选择可用性SLO进行调查
- SLO针对特定操作（visits）

96:00 - 100:00 - SLO配置
- 可以选择任何CloudWatch指标创建SLO
- 不限于Application Signals自动收集的指标
- 可以使用容器、EC2等任何指标
- 可以从日志中提取自定义指标
- 示例：每日测量，错误预算超过50%时告警

100:00 - 105:00 - 操作级别分析
- 查看操作的详细指标
- 开箱即用显示：
  - 请求率、错误、故障
  - 运行时指标（Java、.NET等）
  - 垃圾收集器问题可见
- 识别故障峰值（284个错误）

105:00 - 110:00 - 追踪分析
- 点击故障峰值查看spans
- 查看特定追踪
- 显示基础设施信息（节点、Pod）
- 深度链接到Container Insights
- 查看容器特定信息、部署、Pod状态

110:00 - 115:00 - 根因识别
- 展开追踪查看span时间线
- 显示请求处理流程
- 识别服务依赖（客户端、服务、DynamoDB）
- 所有数据基于OpenTelemetry
- 发现DynamoDB限流问题（trace event中的错误）

115:00 - 120:00 - 日志关联与分析
- 自动显示追踪期间捕获的日志事件
- 可以手动阅读或使用CloudWatch Logs Insights
- 自动填充日志组和查询
- 模式分析功能：
  - 自动分组日志事件
  - 提取令牌（token）
  - 识别端点（visits API）
  - 显示容器信息
- 快速定位根本原因

### 应用视图与总结 (120:00 - 结束)

120:00 - 125:00 - 应用地图
- 以应用为中心的视图
- 显示5个应用
- 识别有问题的应用
- 查看依赖的微服务
- 显示依赖关系图

125:00 - 130:00 - 应用级别故障排查
- 显示所有日志事件
- 自动日志审计识别明显问题
- 可以从应用视图进行故障排查
- 查看应用日志

130:00 - 结束 - 应用分组
- 基于拓扑图自动推断应用
- 支持自定义应用定义
- 可以使用AWS标签或OpenTelemetry属性分组
- 按环境、团队名称等分组
- 支持基于SLI状态、服务器故障等过滤
- 简化界面，快速识别问题应用