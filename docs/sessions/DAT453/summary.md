# AWS re:Invent 2025 DynamoDB 会议总结

## 会议概述

本次会议由 Craig Howard 主讲,他在 Amazon 工作了 20 年,其中 16 年在 AWS,过去 6 年专注于 DynamoDB。会议主要围绕 2025 年 10 月 20 日发生在 US East1 区域的 DynamoDB DNS 故障事件展开深入分析。Craig 首先向受影响的客户道歉,然后详细讲解了事件的技术细节、根本原因以及从中获得的宝贵经验教训。

DynamoDB 的核心优先级按顺序是:安全性、持久性、可用性和延迟。这些是永远不会改变的基本原则,正如 Jeff Bezos 曾经说过的,应该专注于那些 10 年后也不会改变的事情。本次故障事件恰恰影响了可用性这一核心指标,因此团队进行了全面的事后分析(COE - Correction of Error),目的不仅是改进 DynamoDB 和 AWS,更重要的是帮助客户构建更具弹性的系统。

会议深入探讨了 DynamoDB 如何使用 DNS、DNS 管理系统的架构设计、导致故障的具体竞态条件、事件期间的缓解措施,以及最重要的——从这次事件中学到的经验教训,这些教训可以应用到任何大规模分布式系统的设计和运维中。

## 详细时间线与关键要点

00:00 - 开场与核心原则
- DynamoDB 的优先级顺序:安全性 → 持久性 → 可用性 → 延迟
- 引用 Jeff Bezos 的理念:关注 10 年后不会改变的事情
- Craig Howard 自我介绍:在 Amazon 20 年,AWS 16 年,DynamoDB 6 年

02:30 - 事件概述与道歉
- 2025 年 10 月 20 日 US East1 区域发生可用性事件
- 向客户及其用户正式道歉
- 说明 AWS 的正式事后分析流程(COE)

05:00 - DynamoDB 规模背景
- 数百个表同时处理每秒 50 万次以上请求
- Amazon 商店在 Prime Day 达到每秒 1.51 亿次请求
- 每个区域有数百个负载均衡器,每个负载均衡器后有数百个实例
- 混合使用不同实例类型以优化成本
- 同时支持 IPv4 和 IPv6

08:00 - DNS 基础知识
- 客户端通过 DNS 名称(如 dynamodb.us-east-1.amazonaws.com)连接
- DNS 将域名解析为 IP 地址
- 演示 dig 命令的使用和输出解读
- 故障期间返回零个 IP 地址(无错误,但无应答)

12:00 - DNS 架构复杂性
- DNS 查询流程:本地缓存 → 递归解析器 → 权威服务器
- 配置工作流:操作员/自动化 → 控制平面 → 权威服务器
- 使用加权记录分配流量到不同容量的负载均衡器
- DNS 健康检查用于处理完全故障
- 部分故障需要手动 DNS 更新

18:00 - DNS 管理系统架构
- 两个核心组件:Planner(规划器)和 Enactor(执行器)
- Planner:查看区域状态,生成 JSON 格式的计划文件
- Enactor:读取计划并调用 Route 53 控制 API 配置 DNS
- 设计目标:在任何区域事件中都能正常工作
- 所有区域配置完全相同

22:00 - 高可用性设计
- 三个 Enactor 实例分布在三个可用区
- 所有实例执行相同工作(幂等操作)
- 最终一致性系统,在大规模下表现优异
- 不希望实例间相互通信以提高弹性

25:00 - 锁机制设计
- 需要序列化工作以便于推理
- 无法使用 DynamoDB 作为锁(循环依赖)
- 创新方案:使用 Route 53 TXT 记录作为锁
- 锁协议:通过控制平面 API 的事务性批量操作实现
- 删除-重建模式确保原子性

30:00 - DNS 树结构
- 使用树形结构管理 DNS 记录
- 叶节点:负载均衡器 IP 和权重
- 中间节点:加权轮询记录
- 根节点:别名记录指向当前活动计划
- 更新时构建全新树,测试后切换别名
- 回滚只需一次别名更新

33:00 - 设计反思
- 所有记录使用 UUID 命名(机器友好)
- 调试时发现 UUID 难以阅读,减慢故障排查速度
- 教训:必须考虑操作员在深夜疲惫时的调试体验

35:00 - 多端点管理
- 支持多种端点:IPv4-only、dual-stack、FIPS、cell-based
- 每个端点有独立的托管区域和锁
- 选择不跨端点共享锁以保持简单性

38:00 - 竞态条件详解
- 根本原因:安装新计划与清理旧记录之间的竞态
- 一个 Enactor 多次获取锁失败(不寻常的延迟)
- 退避协议导致该 Enactor 落后多个计划版本
- 最终该 Enactor 获得锁并安装了非常旧的计划

42:00 - 记录清理机制
- 构建新树会生成大量记录
- 清理器删除非常旧的计划树
- 保留一些最近的计划以支持回滚
- 竞态:旧计划被激活后立即被清理

45:00 - 故障序列
- Enactor 1 安装计划 145
- Enactor 2 开始安装计划 146
- Enactor 3(延迟的)安装旧计划 110
- 清理器运行,删除计划 110(因为太旧)
- 根别名指向不存在的计划

48:00 - 不一致状态
- 回滚记录设计用于快速恢复
- 回滚记录必须指向当前活动计划
- 当前计划被删除后,代码无法处理"指向空"的情况
- Enactor 无法继续工作,需要人工介入

50:00 - 事件时间线(UTC)
- **06:48** - 影响开始(删除活动记录)
- **07:03** - 团队收到数百个告警
- **07:18** - 在告警噪音中找到根本原因(用时 15 分钟)
- **07:38** - 理解根本原因
- **09:25** - DNS 恢复健康(安装健康树)
- **09:25-09:40** - 客户逐渐恢复(DNS 负缓存影响)
- **12:38** - 全球所有区域禁用自动化系统

55:00 - Route 53 表现
- 明确声明:Route 53 完全正常运行
- 没有任何异常行为
- 这是 DynamoDB 对 Route 53 的错误配置

57:00 - 告警系统反思
- 一个告警直接指向根本原因,但淹没在噪音中
- 不要盲目添加更多告警
- 需要考虑大型事件中如何处理告警洪流
- 平衡细粒度和粗粒度告警

59:00 - 工具失效
- 所有工具假设 Enactor 可用
- Enactor 恰好是故障组件
- 团队先修复内部工具以加速恢复
- 即使没有工具也能修复,但速度较慢

61:00 - 缓存的双刃剑
- 缓存通常有助于弹性
- DNS 负缓存延长了恢复时间
- 需要思考:缓存在故障时是帮助还是阻碍

63:00 - 冻结能力
- 能够暂停自动化系统冻结状态
- 防止问题扩散到其他区域
- 接受降级:无法紧急添加容量(可接受的权衡)

65:00 - 修复部署时间线
- **10月22日** - 修复竞态条件并验证
- **10月24日** - 部署到第一个区域
- **10月28日** - 全球所有区域部署完成,自动化恢复正常

68:00 - 经验教训 1:分析需要时间
- 两种分析:实时分类(快速恢复)vs 事后分析(系统改进)
- 凌晨 3 点,数百个告警,在日志中找 bug 如同大海捞针
- CloudWatch Logs Insights 对常见错误有帮助
- 复杂的时序问题需要更强大的工具

72:00 - 经验教训 2:日志是操作员的 API
- 日志文件是操作员调试的接口
- 多年累积的日志行可能不是理想的审计跟踪
- 需要精心设计日志以支持调试
- 考虑操作员在压力下的使用体验

75:00 - 会议结束
- 强调学习的重要性
- 目标是帮助客户构建更好的系统
- 分享经验以提高整个行业的弹性

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


核心要点总结:
- 大规模系统中,每个数量级增长都需要重新审视假设
- 最终一致性在超大规模下表现优异
- 简单性是弹性的关键
- 锁和并发控制需要仔细设计
- 竞态条件难以预测和测试
- 操作体验(日志、工具、命名)至关重要
- 告警系统需要考虑大规模事件场景
- 系统应具备"冻结"能力以控制影响范围