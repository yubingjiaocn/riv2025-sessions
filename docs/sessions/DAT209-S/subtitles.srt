1
00:00:01,260 --> 00:00:02,460
- [Speaker] Hi everyone.

2
00:00:03,630 --> 00:00:05,913
Thanks for turning the today's session.

3
00:00:06,770 --> 00:00:08,460
So we'll go over why knowledge graphs

4
00:00:08,460 --> 00:00:11,610
are great for AI and agentic AI

5
00:00:11,610 --> 00:00:14,130
and we'll see how it makes your AI

6
00:00:14,130 --> 00:00:17,010
more trustworthy and explainable, right?

7
00:00:17,010 --> 00:00:19,020
So we'll go through that.

8
00:00:19,020 --> 00:00:20,550
So what's the agenda?

9
00:00:20,550 --> 00:00:21,780
We'll go through some

10
00:00:21,780 --> 00:00:24,480
of the AI challenges we
have with enterprise data

11
00:00:24,480 --> 00:00:26,340
understanding context engineering.

12
00:00:26,340 --> 00:00:28,980
Some of you already know that term.

13
00:00:28,980 --> 00:00:31,974
We'll go over what is context engineering

14
00:00:31,974 --> 00:00:34,380
and why knowledge drives really help

15
00:00:34,380 --> 00:00:35,490
to build that context

16
00:00:35,490 --> 00:00:38,010
and make your data AI ready.

17
00:00:38,010 --> 00:00:39,990
I've not have time to
go through a demo today

18
00:00:39,990 --> 00:00:41,640
because a lot of slides,

19
00:00:41,640 --> 00:00:43,110
but if you stop by a booth,

20
00:00:43,110 --> 00:00:45,930
I think it's 1212 booth number,

21
00:00:45,930 --> 00:00:47,700
we'll go through the demo and you can also

22
00:00:47,700 --> 00:00:51,120
understand our new agents and MCP servers

23
00:00:51,120 --> 00:00:52,120
and stuff like that.

24
00:00:53,940 --> 00:00:56,220
So let's score some of
the challenges we have,

25
00:00:56,220 --> 00:00:58,380
especially with the
enterprise data, right?

26
00:00:58,380 --> 00:01:02,010
As you all know, AI is a
great accelerant, right,

27
00:01:02,010 --> 00:01:05,520
for new experiences and processes.

28
00:01:05,520 --> 00:01:08,130
It really defines, you know,

29
00:01:08,130 --> 00:01:11,640
to get new drive innovation,
reduce complexity,

30
00:01:11,640 --> 00:01:15,990
improve experiences, all
of that to lower cost,

31
00:01:15,990 --> 00:01:17,790
grow revenue, manage risk.

32
00:01:17,790 --> 00:01:21,437
So there is definitely a
lot of adoption with AI,

33
00:01:21,437 --> 00:01:24,990
but you'll be surprised
to know that only 5%

34
00:01:24,990 --> 00:01:26,280
of the projects actually go

35
00:01:26,280 --> 00:01:27,600
into production, right?

36
00:01:27,600 --> 00:01:30,180
95% don't go, don't reach production.

37
00:01:30,180 --> 00:01:31,325
So this is the new report report

38
00:01:31,325 --> 00:01:34,020
from MIT and Gartner's study

39
00:01:34,020 --> 00:01:36,660
where it shows that only 20%

40
00:01:36,660 --> 00:01:38,500
of the projects actually do a POC

41
00:01:39,360 --> 00:01:41,583
and of that only 5% go to production.

42
00:01:42,660 --> 00:01:44,700
So a lot of the survey

43
00:01:44,700 --> 00:01:46,350
that we surveyed customers say

44
00:01:46,350 --> 00:01:50,580
that the data is not AI ready, right?

45
00:01:50,580 --> 00:01:51,413
So that's a reason

46
00:01:51,413 --> 00:01:52,710
why they don't go to production.

47
00:01:52,710 --> 00:01:56,400
The reason might be the data is in silos,

48
00:01:56,400 --> 00:01:57,900
there might be security constraints,

49
00:01:57,900 --> 00:01:59,880
there are a lot of regulations

50
00:01:59,880 --> 00:02:01,170
and stuff like that, right?

51
00:02:01,170 --> 00:02:02,580
So those are the main reasons.

52
00:02:02,580 --> 00:02:05,223
So we'll get into some of that.

53
00:02:07,020 --> 00:02:09,870
So here's some of the AI challenges

54
00:02:09,870 --> 00:02:11,310
around enterprise data, right?

55
00:02:11,310 --> 00:02:13,800
So we know there's
hallucinations obviously,

56
00:02:13,800 --> 00:02:16,376
but that's improving on
the public internet data.

57
00:02:16,376 --> 00:02:20,850
But on the enterprise
data, it still needs a lot

58
00:02:20,850 --> 00:02:23,250
of improvement and AI really

59
00:02:23,250 --> 00:02:24,690
is like a black box, right,

60
00:02:24,690 --> 00:02:27,720
where enterprise don't really get you

61
00:02:27,720 --> 00:02:31,410
all the data to customers,

62
00:02:31,410 --> 00:02:32,610
and there's a lot of regulations

63
00:02:32,610 --> 00:02:34,320
and compliance around data, right?

64
00:02:34,320 --> 00:02:35,820
Those are the main reasons.

65
00:02:35,820 --> 00:02:39,180
And other big reason
is the context, right?

66
00:02:39,180 --> 00:02:43,500
So you really don't have a structured

67
00:02:43,500 --> 00:02:47,400
or connected context switch context

68
00:02:47,400 --> 00:02:49,050
that we can give to LLMs.

69
00:02:49,050 --> 00:02:50,640
We'll get into that a little bit,

70
00:02:50,640 --> 00:02:52,540
but those are the main reasons, right?

71
00:02:53,460 --> 00:02:55,470
So what we have done is we have bucketed

72
00:02:55,470 --> 00:02:57,780
that into three big buckets.

73
00:02:57,780 --> 00:03:00,240
There's a data organization problem

74
00:03:00,240 --> 00:03:03,180
where your data can live

75
00:03:03,180 --> 00:03:04,770
in many data sources, right?

76
00:03:04,770 --> 00:03:05,964
You can have data warehouses,

77
00:03:05,964 --> 00:03:10,662
lake houses, traditional
relation databases,

78
00:03:10,662 --> 00:03:12,780
document stores, and so on.

79
00:03:12,780 --> 00:03:15,690
So AI really cannot
access that information.

80
00:03:15,690 --> 00:03:17,790
So that's a challenge.

81
00:03:17,790 --> 00:03:18,623
The other is,

82
00:03:18,623 --> 00:03:20,040
you might have different schemas, right?

83
00:03:20,040 --> 00:03:23,520
Schemas, data models, format structures.

84
00:03:23,520 --> 00:03:27,510
So AI cannot really understand,

85
00:03:27,510 --> 00:03:29,190
sometimes interpret that information.

86
00:03:29,190 --> 00:03:30,870
So that's another challenge.

87
00:03:30,870 --> 00:03:32,310
So those first two,

88
00:03:32,310 --> 00:03:34,380
it's easy to interpret,
like a lot of enterprises

89
00:03:34,380 --> 00:03:36,180
are actually working on that.

90
00:03:36,180 --> 00:03:37,830
The third one is a big challenge

91
00:03:37,830 --> 00:03:41,430
where scale of query diversity, right,

92
00:03:41,430 --> 00:03:44,070
so let me go a little deeper on that.

93
00:03:44,070 --> 00:03:45,780
Query diversity is a big problem

94
00:03:45,780 --> 00:03:48,510
where you ask a question to LLM right,

95
00:03:48,510 --> 00:03:50,370
now with the enterprise
data, you have a lot

96
00:03:50,370 --> 00:03:53,820
of information, lot of sources to gather,

97
00:03:53,820 --> 00:03:55,140
take information and query.

98
00:03:55,140 --> 00:03:56,880
So it's not one query,

99
00:03:56,880 --> 00:03:59,970
it's not a one question
to one query, right?

100
00:03:59,970 --> 00:04:03,150
So you have lot of queries to gather

101
00:04:03,150 --> 00:04:06,630
and then get to a solution.

102
00:04:06,630 --> 00:04:07,980
Let me give you an example, right?

103
00:04:07,980 --> 00:04:10,300
Let's take a supply chain optimization

104
00:04:11,340 --> 00:04:14,070
as a use case.

105
00:04:14,070 --> 00:04:15,720
And the question is,

106
00:04:15,720 --> 00:04:18,210
you wanna find the best routes

107
00:04:18,210 --> 00:04:19,563
from point A to point B.

108
00:04:21,360 --> 00:04:23,190
That's your problem, that's
your question, right?

109
00:04:23,190 --> 00:04:24,840
But now you have to deal

110
00:04:24,840 --> 00:04:27,480
with a lot of data sources.

111
00:04:27,480 --> 00:04:29,490
You might have to get into ERP systems,

112
00:04:29,490 --> 00:04:34,290
your data warehouses,
many of those sources.

113
00:04:34,290 --> 00:04:37,200
Now you start asking deeper,

114
00:04:37,200 --> 00:04:38,887
probably you want to say,

115
00:04:38,887 --> 00:04:42,030
"You know what, I wanna
identify possible routes,

116
00:04:42,030 --> 00:04:44,520
I want to trace dependency chains.

117
00:04:44,520 --> 00:04:48,270
I want to ask the delays
and the lead times."

118
00:04:48,270 --> 00:04:50,970
So you start asking those questions.

119
00:04:50,970 --> 00:04:53,010
So that basically it's a lot of query.

120
00:04:53,010 --> 00:04:54,970
So now you are hitting it

121
00:04:55,912 --> 00:04:57,600
with a query diversity problem, right?

122
00:04:57,600 --> 00:04:59,340
So there are two ways to fix that.

123
00:04:59,340 --> 00:05:02,040
Either give a lot more context to the LLM

124
00:05:02,040 --> 00:05:03,720
so that it understands

125
00:05:03,720 --> 00:05:06,330
or consolidate the data somehow

126
00:05:06,330 --> 00:05:08,520
so you have a simpler query, right?

127
00:05:08,520 --> 00:05:10,433
So that's exactly what we're trying to do.

128
00:05:12,240 --> 00:05:14,550
Graphs help you do that.

129
00:05:14,550 --> 00:05:15,930
It obviously boosts accuracy

130
00:05:15,930 --> 00:05:17,873
and improve explainability.

131
00:05:19,604 --> 00:05:20,437
And the reason why you're here

132
00:05:20,437 --> 00:05:23,430
for the the stock is
it actually allows you

133
00:05:23,430 --> 00:05:25,050
to get you more context

134
00:05:25,050 --> 00:05:26,760
and make the data AI ready, right?

135
00:05:26,760 --> 00:05:28,233
We'll get to that in a bit.

136
00:05:29,100 --> 00:05:30,510
So before that, let's understand

137
00:05:30,510 --> 00:05:32,550
what is context engineering.

138
00:05:32,550 --> 00:05:34,773
Some of you already know that term here.

139
00:05:37,553 --> 00:05:39,540
It's basically a evolution

140
00:05:39,540 --> 00:05:41,433
of prompt engineering, right?

141
00:05:43,766 --> 00:05:46,320
So by definition it says

142
00:05:46,320 --> 00:05:48,540
that you just give enough information

143
00:05:48,540 --> 00:05:52,410
to the LLM so that it
can get to the next stage

144
00:05:52,410 --> 00:05:54,060
or next step, right?

145
00:05:54,060 --> 00:05:55,751
So you want the right data,

146
00:05:55,751 --> 00:05:59,820
at the right time, at the right structure

147
00:05:59,820 --> 00:06:02,103
so it knows what to do next.

148
00:06:03,330 --> 00:06:04,833
So why does it matter now?

149
00:06:07,050 --> 00:06:08,580
I mean, traditionally or even now,

150
00:06:08,580 --> 00:06:11,440
like what's happening is you expect

151
00:06:12,750 --> 00:06:14,280
one shot LLM prompts, right?

152
00:06:14,280 --> 00:06:17,160
So you give an answer, you ask a question,

153
00:06:17,160 --> 00:06:19,050
or you think that you'll give an answer

154
00:06:19,050 --> 00:06:20,520
that's very straightforward,

155
00:06:20,520 --> 00:06:21,750
but that's not the case

156
00:06:21,750 --> 00:06:22,710
with enterprise data, right?

157
00:06:22,710 --> 00:06:26,262
You have like multiple data sources.

158
00:06:26,262 --> 00:06:27,810
It has to reason.

159
00:06:27,810 --> 00:06:29,820
So especially with agentic AI,

160
00:06:29,820 --> 00:06:31,320
it has to reason, it has to plan.

161
00:06:31,320 --> 00:06:33,832
You have multi-step actions,

162
00:06:33,832 --> 00:06:37,380
you probably call multiple tools.

163
00:06:37,380 --> 00:06:40,260
So it has to fetch data,
all of that, right?

164
00:06:40,260 --> 00:06:42,540
So again, it comes back to the query.

165
00:06:42,540 --> 00:06:44,040
So it has to do multiple queries

166
00:06:44,040 --> 00:06:45,660
to get that information.

167
00:06:45,660 --> 00:06:48,840
So what we're saying is
give the enough context

168
00:06:48,840 --> 00:06:51,210
so it understands what to do next, right?

169
00:06:51,210 --> 00:06:52,360
So that's a basic idea.

170
00:06:54,360 --> 00:06:58,740
Again, that's a definition
by LangChain as well.

171
00:06:58,740 --> 00:07:01,470
So what are some of the
sources you have, right?

172
00:07:01,470 --> 00:07:04,230
So you have all the user interactions

173
00:07:04,230 --> 00:07:06,000
that you give to the LLMs.

174
00:07:06,000 --> 00:07:10,380
Now that can be your
prompts, your feedback

175
00:07:10,380 --> 00:07:13,740
and all the interactions
you have with LLMs.

176
00:07:13,740 --> 00:07:15,150
It keeps the state and history.

177
00:07:15,150 --> 00:07:18,189
So that's also can be part of the context.

178
00:07:18,189 --> 00:07:20,070
It has a short term long-term memory

179
00:07:20,070 --> 00:07:22,830
within the models so that
that can also be used.

180
00:07:22,830 --> 00:07:23,850
You have structured output,

181
00:07:23,850 --> 00:07:26,160
that is basically your APIs and data tools

182
00:07:26,160 --> 00:07:28,260
that you fetch data from, right?

183
00:07:28,260 --> 00:07:30,240
That is also part of the context.

184
00:07:30,240 --> 00:07:32,550
That other big thing is a RAG.

185
00:07:32,550 --> 00:07:34,920
So now you can actually
retrieve information

186
00:07:34,920 --> 00:07:37,830
from your vector database or your GraphRAG

187
00:07:37,830 --> 00:07:40,320
where you have like a graph database

188
00:07:40,320 --> 00:07:42,570
like NEO4j and that can be part

189
00:07:42,570 --> 00:07:44,670
of the context, right?

190
00:07:44,670 --> 00:07:46,680
So those are some of the sources.

191
00:07:46,680 --> 00:07:48,060
And this is the same view,

192
00:07:48,060 --> 00:07:49,590
but from a different angle

193
00:07:49,590 --> 00:07:51,720
where you have human interactions,

194
00:07:51,720 --> 00:07:54,600
you have cognitive layer of application,

195
00:07:54,600 --> 00:07:57,180
you have memory layer of the models,

196
00:07:57,180 --> 00:07:58,980
and you have data tools, right, the APIs.

197
00:07:58,980 --> 00:07:59,813
It's the same thing,

198
00:07:59,813 --> 00:08:01,503
but just laid out on a different view.

199
00:08:02,880 --> 00:08:04,320
So the other big thing

200
00:08:04,320 --> 00:08:05,850
which we need to consider,

201
00:08:05,850 --> 00:08:07,833
just because you have
data, I cannot give all

202
00:08:07,833 --> 00:08:09,693
that information to the LLMs.

203
00:08:10,680 --> 00:08:12,720
It's gonna hallucinate again, right,

204
00:08:12,720 --> 00:08:14,430
'cause it has too much information

205
00:08:14,430 --> 00:08:16,080
just as a context.

206
00:08:16,080 --> 00:08:18,930
So what we are saying is
there's something called

207
00:08:18,930 --> 00:08:21,480
as a minimal viable context.

208
00:08:21,480 --> 00:08:23,580
Just for the definition
of context engineering,

209
00:08:23,580 --> 00:08:25,047
again, it's just the right information

210
00:08:25,047 --> 00:08:28,923
for the LLMs to do the next step, right?

211
00:08:28,923 --> 00:08:33,000
So we have to make sure you have higher

212
00:08:33,000 --> 00:08:36,960
signal-to-noise ratio,
right to get to the LLMs.

213
00:08:36,960 --> 00:08:39,180
So that's another concept basically

214
00:08:39,180 --> 00:08:40,320
with context engineering.

215
00:08:40,320 --> 00:08:41,730
So at the crux, that's what it is, right?

216
00:08:41,730 --> 00:08:43,110
You give the right information.

217
00:08:43,110 --> 00:08:44,777
Even if you have agentic models,

218
00:08:44,777 --> 00:08:46,830
agents should understand what to do next.

219
00:08:46,830 --> 00:08:49,383
So you need that context information.

220
00:08:51,240 --> 00:08:52,479
So why graphs?

221
00:08:52,479 --> 00:08:54,800
So before I dig in...

222
00:08:55,710 --> 00:08:57,360
Oh, hold on.

223
00:08:57,360 --> 00:08:59,250
So before I dig in,

224
00:08:59,250 --> 00:09:02,280
what is graph database itself,

225
00:09:02,280 --> 00:09:03,840
so let's understand a concept

226
00:09:03,840 --> 00:09:05,730
of knowledge graphs, right?

227
00:09:05,730 --> 00:09:08,310
So basically by definition,
it's a design pattern

228
00:09:08,310 --> 00:09:11,490
to organize and access
connected data, right?

229
00:09:11,490 --> 00:09:13,140
You can have any connected data,

230
00:09:13,140 --> 00:09:14,900
everything is connected, right?

231
00:09:14,900 --> 00:09:18,510
So let's say you have a supply chain,

232
00:09:18,510 --> 00:09:20,550
you have financial data,
you have networking,

233
00:09:20,550 --> 00:09:23,070
access control, all of
that is connected, right?

234
00:09:23,070 --> 00:09:24,420
So by definition,

235
00:09:24,420 --> 00:09:26,910
you can have a supply
chain knowledge graph,

236
00:09:26,910 --> 00:09:28,227
you can have a financial knowledge graph,

237
00:09:28,227 --> 00:09:30,630
you can have any of the
knowledge graphs, right?

238
00:09:30,630 --> 00:09:33,335
So now it has specific information

239
00:09:33,335 --> 00:09:35,100
around that, right?

240
00:09:35,100 --> 00:09:37,200
The way we store data is something called

241
00:09:37,200 --> 00:09:38,500
as a property graph model.

242
00:09:39,960 --> 00:09:42,630
Instead of tables and columns,

243
00:09:42,630 --> 00:09:44,793
we have nodes and relationships, right?

244
00:09:46,653 --> 00:09:47,940
So again, coming back to the supply chain,

245
00:09:47,940 --> 00:09:50,670
think of a supplier and
a raw materials, right?

246
00:09:50,670 --> 00:09:52,710
Supplier is a node,

247
00:09:52,710 --> 00:09:54,813
and raw materials is a node as well.

248
00:09:56,100 --> 00:09:58,140
Supplier supplies raw materials.

249
00:09:58,140 --> 00:10:00,900
Supplies, it's a word,
that's a relationship.

250
00:10:00,900 --> 00:10:02,300
So that's how we store data.

251
00:10:04,110 --> 00:10:06,930
And within that information,

252
00:10:06,930 --> 00:10:08,850
you can store properties, right?

253
00:10:08,850 --> 00:10:12,090
I can say, hey, supplier
supplies raw materials,

254
00:10:12,090 --> 00:10:15,960
but what's the date it's supplied on?

255
00:10:15,960 --> 00:10:17,100
What's the lead time?

256
00:10:17,100 --> 00:10:17,970
What's the capacity?

257
00:10:17,970 --> 00:10:19,770
So those are the properties.

258
00:10:19,770 --> 00:10:21,060
Now that is the context

259
00:10:21,060 --> 00:10:22,590
that you can store inherently

260
00:10:22,590 --> 00:10:24,090
within the database, right?

261
00:10:24,090 --> 00:10:26,010
So that's a big, big difference.

262
00:10:26,010 --> 00:10:29,340
So I don't have to have JOINs and tables

263
00:10:29,340 --> 00:10:30,510
and to extract data.

264
00:10:30,510 --> 00:10:33,270
Everything is inherently stored, right?

265
00:10:33,270 --> 00:10:37,080
So think of this as
another example, right?

266
00:10:37,080 --> 00:10:38,460
So you have supplier,

267
00:10:38,460 --> 00:10:40,080
so now I have supplier graph,

268
00:10:40,080 --> 00:10:43,860
I have a product graph,
I have a consumer graph.

269
00:10:43,860 --> 00:10:46,770
So now all your business
can be all connected

270
00:10:46,770 --> 00:10:48,240
in one view, right?

271
00:10:48,240 --> 00:10:50,473
So now it solves two problems.

272
00:10:50,473 --> 00:10:51,840
Like I was saying,

273
00:10:51,840 --> 00:10:53,970
you have the query diversity problem.

274
00:10:53,970 --> 00:10:56,413
It's simpler to query with graph databases

275
00:10:56,413 --> 00:10:59,700
because you have all the connected view.

276
00:10:59,700 --> 00:11:01,200
I can do a multi hop query,

277
00:11:01,200 --> 00:11:02,790
I can do reasoning all of that

278
00:11:02,790 --> 00:11:04,020
because it's everything's connected

279
00:11:04,020 --> 00:11:06,150
and inherently stored, right?

280
00:11:06,150 --> 00:11:08,430
The other big challenge which we solve

281
00:11:08,430 --> 00:11:11,640
by this is giving the
right context, right?

282
00:11:11,640 --> 00:11:14,971
So now I can give a minimal context

283
00:11:14,971 --> 00:11:18,990
to the LLMs for that to
do the next step, right?

284
00:11:18,990 --> 00:11:20,220
So that's the reason why we say

285
00:11:20,220 --> 00:11:22,320
it's a AI ready data

286
00:11:22,320 --> 00:11:27,270
because you have all the
connections and context

287
00:11:27,270 --> 00:11:29,073
within the database.

288
00:11:31,350 --> 00:11:32,370
Again, it's the same thing.

289
00:11:32,370 --> 00:11:34,740
I'm not gonna go through that again.

290
00:11:34,740 --> 00:11:37,080
So think of this as a left

291
00:11:37,080 --> 00:11:37,913
and right brain, right?

292
00:11:37,913 --> 00:11:40,050
So right brain is basically your language,

293
00:11:40,050 --> 00:11:42,330
reasoning, creativity.

294
00:11:42,330 --> 00:11:44,280
And then your left brain is basically

295
00:11:44,280 --> 00:11:45,570
your knowledge layer, right?

296
00:11:45,570 --> 00:11:47,520
So you have context enrichment.

297
00:11:47,520 --> 00:11:49,590
Together, obviously you
have more explainable AI.

298
00:11:49,590 --> 00:11:50,840
So that's the whole idea.

299
00:11:53,880 --> 00:11:55,443
Coming back to RAG, this is part

300
00:11:55,443 --> 00:11:57,120
of the context engineer, right?

301
00:11:57,120 --> 00:11:59,160
So you're trying to provide

302
00:11:59,160 --> 00:12:00,330
as much context as possible.

303
00:12:00,330 --> 00:12:01,560
That's the whole idea, right?

304
00:12:01,560 --> 00:12:02,910
So traditionally what you have

305
00:12:02,910 --> 00:12:04,920
is you have a retriever

306
00:12:04,920 --> 00:12:06,330
where you retrieve information

307
00:12:06,330 --> 00:12:08,100
from a vector database, right?

308
00:12:08,100 --> 00:12:10,443
It can be NoSQL or vector database.

309
00:12:11,490 --> 00:12:15,300
With graph, it's basically
you're replacing that

310
00:12:15,300 --> 00:12:17,430
with a graph database
and that's a GraphRAG.

311
00:12:17,430 --> 00:12:18,510
That's all, right.

312
00:12:18,510 --> 00:12:20,370
But what we have now

313
00:12:20,370 --> 00:12:22,770
is since we have the connected view

314
00:12:22,770 --> 00:12:25,800
of all the information,
you have the context.

315
00:12:25,800 --> 00:12:27,913
Now I can provide a
lot more richer context

316
00:12:27,913 --> 00:12:29,370
to the LLMs.

317
00:12:29,370 --> 00:12:30,390
So that's a whole idea

318
00:12:30,390 --> 00:12:32,343
with the GraphRAG right.

319
00:12:34,290 --> 00:12:37,950
Now, example would be
going back to supply chain,

320
00:12:37,950 --> 00:12:39,909
the same question I asked before, right?

321
00:12:39,909 --> 00:12:41,490
What's the best route

322
00:12:41,490 --> 00:12:42,963
from point A to point B?

323
00:12:43,830 --> 00:12:45,960
With graph, I don't have to dig deeper

324
00:12:45,960 --> 00:12:48,330
into ERP solutions, spreadsheets,

325
00:12:48,330 --> 00:12:50,130
dashboards and all of that, right?

326
00:12:50,130 --> 00:12:52,447
I can just do a single query saying,

327
00:12:52,447 --> 00:12:53,700
"What's the shortest path?"

328
00:12:53,700 --> 00:12:55,980
That's a query, that's
an algorithm I can use,

329
00:12:55,980 --> 00:12:57,570
and you get the answer.

330
00:12:57,570 --> 00:12:59,250
It's as simple as that, right?

331
00:12:59,250 --> 00:13:02,400
So that makes it much easier.

332
00:13:02,400 --> 00:13:04,590
Also, you have other information

333
00:13:04,590 --> 00:13:05,681
that you can retrieve, right?

334
00:13:05,681 --> 00:13:08,400
You can do pattern matching, path finding.

335
00:13:08,400 --> 00:13:10,050
You have community driven algorithms

336
00:13:10,050 --> 00:13:12,251
that you can retrieve
from the graph databases.

337
00:13:12,251 --> 00:13:14,670
So it gives you an added benefit

338
00:13:14,670 --> 00:13:16,623
of using a graph database, right?

339
00:13:18,750 --> 00:13:22,500
So again, just to hit on
the architecture here,

340
00:13:22,500 --> 00:13:24,782
so you have a data platform that can be

341
00:13:24,782 --> 00:13:27,630
since we're the AWS conference,

342
00:13:27,630 --> 00:13:28,980
it can be anything, right,

343
00:13:28,980 --> 00:13:32,550
Aurora Redshift, S3 buckets and whatnot.

344
00:13:32,550 --> 00:13:34,440
You have LLM and knowledge graph

345
00:13:34,440 --> 00:13:35,730
can sit in between that

346
00:13:35,730 --> 00:13:39,303
as a context layer or a
knowledge layer, right?

347
00:13:40,170 --> 00:13:42,210
So a lot of companies, what they do is,

348
00:13:42,210 --> 00:13:43,800
they project the data

349
00:13:43,800 --> 00:13:47,370
from your traditional data platforms

350
00:13:47,370 --> 00:13:48,330
into knowledge graph.

351
00:13:48,330 --> 00:13:49,680
You don't have to project everything.

352
00:13:49,680 --> 00:13:51,660
You can just project
part of the data there

353
00:13:51,660 --> 00:13:53,070
where you wanna run algorithms

354
00:13:53,070 --> 00:13:54,810
or where you need the context from.

355
00:13:54,810 --> 00:13:57,330
And that can act as a context to LLMs.

356
00:13:57,330 --> 00:13:58,980
So a lot of companies are doing that.

357
00:13:58,980 --> 00:14:00,180
That just gives you an idea

358
00:14:00,180 --> 00:14:03,873
of how you wanna use knowledge graphs.

359
00:14:06,000 --> 00:14:07,979
And also the knowledge graphs

360
00:14:07,979 --> 00:14:09,600
lead to more accuracy.

361
00:14:09,600 --> 00:14:11,070
And this is not me saying it.

362
00:14:11,070 --> 00:14:14,160
This is the public report
which you can access.

363
00:14:14,160 --> 00:14:14,993
They've run a study

364
00:14:14,993 --> 00:14:17,790
where they run knowledge graphs

365
00:14:17,790 --> 00:14:19,625
against NoSQL and SQL databases

366
00:14:19,625 --> 00:14:22,290
and they've found that the accuracy

367
00:14:22,290 --> 00:14:23,650
is 3x more accurate

368
00:14:24,870 --> 00:14:27,573
in terms of responses they get from LLMs.

369
00:14:30,240 --> 00:14:33,633
So just to level set, right, why is that?

370
00:14:34,950 --> 00:14:36,330
Let's go to the semantics of it, right?

371
00:14:36,330 --> 00:14:37,320
Let's say have you have very

372
00:14:37,320 --> 00:14:39,780
simple example of apples and oranges.

373
00:14:39,780 --> 00:14:42,360
On the left, you can query, right?

374
00:14:42,360 --> 00:14:43,470
That's how it's stored.

375
00:14:43,470 --> 00:14:45,870
I don't have a vector representation.

376
00:14:45,870 --> 00:14:48,660
That's how it's stored
in the graph database.

377
00:14:48,660 --> 00:14:50,070
On the right, it's a vector database.

378
00:14:50,070 --> 00:14:51,030
It's a vector embeddings.

379
00:14:51,030 --> 00:14:53,230
That's how you store
the information, right?

380
00:14:55,410 --> 00:14:59,310
To do a search, you
probably do a Euclidean,

381
00:14:59,310 --> 00:15:01,683
or a Cosine, a similarity search.

382
00:15:03,849 --> 00:15:06,240
On the left, on the graph database,

383
00:15:06,240 --> 00:15:07,073
it's very easy.

384
00:15:07,073 --> 00:15:08,550
You can just query, right?

385
00:15:08,550 --> 00:15:10,554
You can do a lot more with it

386
00:15:10,554 --> 00:15:11,550
like pattern matching, path finding

387
00:15:11,550 --> 00:15:12,820
and a lot of those things

388
00:15:13,841 --> 00:15:15,041
with the graph database.

389
00:15:16,530 --> 00:15:18,700
And imagine now that

390
00:15:21,720 --> 00:15:23,610
you have just one information now, right?

391
00:15:23,610 --> 00:15:25,770
So let's say you have supplier graph,

392
00:15:25,770 --> 00:15:28,200
product graph, consumer graph,

393
00:15:28,200 --> 00:15:29,460
all of that information,

394
00:15:29,460 --> 00:15:31,320
now you can really analyze the data,

395
00:15:31,320 --> 00:15:32,880
you can do a lot more with it.

396
00:15:32,880 --> 00:15:36,630
Not only giving the context to LLMs,

397
00:15:36,630 --> 00:15:38,680
but you can do a lot more with it, right?

398
00:15:40,379 --> 00:15:42,990
So in essence that's advantage

399
00:15:42,990 --> 00:15:44,583
of using a graph database.

400
00:15:46,000 --> 00:15:49,860
So this is my last slide.

401
00:15:49,860 --> 00:15:53,190
Really, graphs go beyond GraphRAG, right?

402
00:15:53,190 --> 00:15:55,410
So like I was mentioning,

403
00:15:55,410 --> 00:15:58,140
you have context engineering

404
00:15:58,140 --> 00:16:00,390
where you give the right level of context.

405
00:16:00,390 --> 00:16:02,010
It allows you to do that

406
00:16:02,010 --> 00:16:03,900
because it has all the information stored

407
00:16:03,900 --> 00:16:06,030
within the graph database, right?

408
00:16:06,030 --> 00:16:08,160
Also, when you're interacting,

409
00:16:08,160 --> 00:16:10,290
all the user interactions
you have with LLMs,

410
00:16:10,290 --> 00:16:13,320
you can store that as
context as well, right?

411
00:16:13,320 --> 00:16:15,000
Within the RAG architecture, you can go,

412
00:16:15,000 --> 00:16:16,440
like after the response,

413
00:16:16,440 --> 00:16:17,430
you have all the interactions.

414
00:16:17,430 --> 00:16:18,450
You can store that as context.

415
00:16:18,450 --> 00:16:20,880
You can probably store that as a property

416
00:16:20,880 --> 00:16:22,530
or relationships or nodes

417
00:16:22,530 --> 00:16:23,670
within the graph database.

418
00:16:23,670 --> 00:16:26,400
So you have that as a memory, right?

419
00:16:26,400 --> 00:16:29,820
You can use that as a context as well.

420
00:16:29,820 --> 00:16:31,620
Beyond that you can
obviously visualize it.

421
00:16:31,620 --> 00:16:33,510
The other thing which we didn't talk

422
00:16:33,510 --> 00:16:35,100
about is a Cypher query.

423
00:16:35,100 --> 00:16:36,090
It's a GQL query.

424
00:16:36,090 --> 00:16:38,297
Just like a SQL, you have a GQL.

425
00:16:38,297 --> 00:16:40,440
GQL is graph query language.

426
00:16:40,440 --> 00:16:42,270
Using that you can do a lot of things

427
00:16:42,270 --> 00:16:45,480
like pattern matching,
path finding and so on.

428
00:16:45,480 --> 00:16:48,270
So that really allows you to visualize

429
00:16:48,270 --> 00:16:50,553
and explore data even further.

430
00:16:51,630 --> 00:16:52,740
I think that's all I had

431
00:16:52,740 --> 00:16:53,990
and if you have any questions,

432
00:16:53,990 --> 00:16:55,980
we have booth 1212

433
00:16:55,980 --> 00:16:57,300
and then we can probably go through demo.

434
00:16:57,300 --> 00:16:58,440
I didn't have time for the demo.

435
00:16:58,440 --> 00:17:00,390
I had a demo but I didn't have time.

436
00:17:00,390 --> 00:17:02,100
But if you can come through our booth,

437
00:17:02,100 --> 00:17:02,933
we'll go through demo.

438
00:17:02,933 --> 00:17:03,900
We also have our agents

439
00:17:03,900 --> 00:17:05,550
and other MCP service as well.

440
00:17:05,550 --> 00:17:09,033
Thanks for coming.
(audience clapping)

