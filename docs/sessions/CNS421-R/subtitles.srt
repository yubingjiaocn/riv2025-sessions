1
00:00:00,210 --> 00:00:01,710
- [Sai] Hello, ladies and gentlemen,

2
00:00:01,710 --> 00:00:03,390
thank you for joining us,

3
00:00:03,390 --> 00:00:07,020
spending your time with
us today for a Code Talk.

4
00:00:07,020 --> 00:00:09,930
If you're not familiar, a Code Talk is,

5
00:00:09,930 --> 00:00:13,140
it's not a recorded session,
it's a live coding session.

6
00:00:13,140 --> 00:00:16,140
Lucas and myself, we're gonna
be live coding for you today.

7
00:00:16,140 --> 00:00:17,040
My name is Sai Vennam,

8
00:00:17,040 --> 00:00:20,040
I'm a Principal Solutions
Architect with AWS.

9
00:00:20,040 --> 00:00:21,210
- [Lucas] Hey folks, nice to meet you all.

10
00:00:21,210 --> 00:00:23,507
I'm Lucas Duarte, a Principal
Solutions Architect here

11
00:00:23,507 --> 00:00:25,980
at AWS as well.
- Yeah.

12
00:00:25,980 --> 00:00:27,180
And today we're gonna talk

13
00:00:27,180 --> 00:00:31,650
about how you can streamline
EKS operations with Agentic AI.

14
00:00:31,650 --> 00:00:35,790
This is very much gonna be
an informal casual session.

15
00:00:35,790 --> 00:00:37,200
We want to give you folks an opportunity

16
00:00:37,200 --> 00:00:39,724
to ask questions at the end as well.

17
00:00:39,724 --> 00:00:41,310
We're gonna be going back and forth.

18
00:00:41,310 --> 00:00:44,850
Lucas and I, we've done
this a couple times before

19
00:00:44,850 --> 00:00:46,920
and we're excited to run through

20
00:00:46,920 --> 00:00:48,600
what we've built for you today.

21
00:00:48,600 --> 00:00:52,650
Last year, we did a similar
session about using AI.

22
00:00:52,650 --> 00:00:54,720
You know, this was before
the time of agents.

23
00:00:54,720 --> 00:00:57,270
This is even before MCP
was getting popular.

24
00:00:57,270 --> 00:01:00,150
So we built a lot of things from scratch.

25
00:01:00,150 --> 00:01:03,180
This year, we leveraged tools
that are available out there

26
00:01:03,180 --> 00:01:05,010
that make it even easier

27
00:01:05,010 --> 00:01:09,025
to build really robust
troubleshooting agents from scratch.

28
00:01:09,025 --> 00:01:12,660
So that's what we're
gonna talk about today.

29
00:01:12,660 --> 00:01:15,090
But first, I think it's
important to understand

30
00:01:15,090 --> 00:01:17,310
how the technology has progressed

31
00:01:17,310 --> 00:01:20,400
from where we were last year,
maybe even two years ago,

32
00:01:20,400 --> 00:01:21,753
to where we are today.

33
00:01:22,830 --> 00:01:24,420
- But we're gonna-
- Go for it.

34
00:01:24,420 --> 00:01:25,253
- [Lucas] Thanks.

35
00:01:25,253 --> 00:01:26,086
But before we talk about that,

36
00:01:26,086 --> 00:01:27,840
I just want to introduce to you folks,

37
00:01:27,840 --> 00:01:30,750
a new member of our team, the Kube Agent.

38
00:01:30,750 --> 00:01:32,400
So essentially right now,

39
00:01:32,400 --> 00:01:34,410
we have an agent that can be responsible

40
00:01:34,410 --> 00:01:35,970
to troubleshoot your clusters

41
00:01:35,970 --> 00:01:39,480
and also to remediate some issues based on

42
00:01:39,480 --> 00:01:43,200
root cause analysis
using MCP, using Agentic.

43
00:01:43,200 --> 00:01:46,047
So what we're building
here is not just a LLM

44
00:01:46,047 --> 00:01:49,470
and a chat bot, because that's too 2024.

45
00:01:49,470 --> 00:01:51,186
What we're doing right now exactly,

46
00:01:51,186 --> 00:01:54,330
building an AI agent
that can be your partner,

47
00:01:54,330 --> 00:01:57,390
that can help you to
accelerate your troubleshooting

48
00:01:57,390 --> 00:01:59,370
and actually reduce the meantime

49
00:01:59,370 --> 00:02:00,840
to remediation of your issues.

50
00:02:00,840 --> 00:02:03,630
So what we are trying to do
here is to empower network

51
00:02:03,630 --> 00:02:06,360
and operation center engineers
so they can use those type

52
00:02:06,360 --> 00:02:08,640
of tools to reduce the
meantime to remediation,

53
00:02:08,640 --> 00:02:09,900
because we know that Kubernetes

54
00:02:09,900 --> 00:02:11,760
are very spread out ecosystem.

55
00:02:11,760 --> 00:02:14,160
So that's the idea that we have
for our session, right Sai?

56
00:02:14,160 --> 00:02:14,993
- [Sai] Exactly.

57
00:02:14,993 --> 00:02:15,826
And here's the thing,

58
00:02:15,826 --> 00:02:17,520
we don't have anything running right now

59
00:02:17,520 --> 00:02:20,460
because our setup is completely clean.

60
00:02:20,460 --> 00:02:22,680
But we want to show you
what we're going to build,

61
00:02:22,680 --> 00:02:23,820
just like a little bit

62
00:02:23,820 --> 00:02:26,100
of what's possible with the technology.

63
00:02:26,100 --> 00:02:27,000
- [Lucas] Jarred of the possible.

64
00:02:27,000 --> 00:02:30,960
So here, if you can see, we
have a Slack channel, right?

65
00:02:30,960 --> 00:02:31,793
The Slack channel,

66
00:02:31,793 --> 00:02:33,510
it's where are we gonna receive
messages and everything.

67
00:02:33,510 --> 00:02:36,870
And then we have two
terminal tabs right there.

68
00:02:36,870 --> 00:02:38,880
One is running a memory agent.

69
00:02:38,880 --> 00:02:40,410
Stick to that information to the end

70
00:02:40,410 --> 00:02:41,783
because we're gonna build that up.

71
00:02:41,783 --> 00:02:44,580
And the other one is that
Kubernetes specialist agent.

72
00:02:44,580 --> 00:02:46,470
So what's going on right now is the agent

73
00:02:46,470 --> 00:02:47,790
is looking today's Slack.

74
00:02:47,790 --> 00:02:50,850
We have received an alert
using alert manager,

75
00:02:50,850 --> 00:02:53,130
and by the time we have received an alert,

76
00:02:53,130 --> 00:02:55,560
we have configured a troubleshooting agent

77
00:02:55,560 --> 00:02:57,960
to identify that alert and start

78
00:02:57,960 --> 00:03:00,870
to do troubleshooting
based on that information.

79
00:03:00,870 --> 00:03:01,890
So if you can take a look,

80
00:03:01,890 --> 00:03:04,950
we are saying monitoring
agent has been pending state

81
00:03:04,950 --> 00:03:06,780
for over one minute.

82
00:03:06,780 --> 00:03:09,120
And right now in the terminal tab,

83
00:03:09,120 --> 00:03:11,400
we are doing the Agentic loop.

84
00:03:11,400 --> 00:03:14,640
And we are gonna explain that
later in the presentation.

85
00:03:14,640 --> 00:03:16,980
But right now we are doing
the Agentic loop to try

86
00:03:16,980 --> 00:03:20,160
to fix the monitoring agent
problem that we saw earlier.

87
00:03:20,160 --> 00:03:22,230
Now the agent is doing the loop,

88
00:03:22,230 --> 00:03:26,246
executing the tools until is
able to find the last response.

89
00:03:26,246 --> 00:03:30,870
So let's see why the monitoring
agent was actually stuck

90
00:03:30,870 --> 00:03:33,033
in pending state for a long time.

91
00:03:33,930 --> 00:03:36,510
So in this case, it's
finishing the troubleshooting,

92
00:03:36,510 --> 00:03:38,880
doing the summary and soon enough,

93
00:03:38,880 --> 00:03:43,880
we should be able to have a
solution here in our thread.

94
00:03:43,920 --> 00:03:45,810
So of course, in this case,

95
00:03:45,810 --> 00:03:48,480
we're not having any human in the loop.

96
00:03:48,480 --> 00:03:51,360
We can have that later for
using GitHubs and everything.

97
00:03:51,360 --> 00:03:53,640
But just for the sake of
the art of the possible,

98
00:03:53,640 --> 00:03:55,200
what we're showing here is

99
00:03:55,200 --> 00:03:59,100
that the agent got the
alert from alert manager.

100
00:03:59,100 --> 00:04:00,900
It concluded run books

101
00:04:00,900 --> 00:04:03,450
that we have available
in our vector database.

102
00:04:03,450 --> 00:04:05,940
It fixed the issue by itself

103
00:04:05,940 --> 00:04:08,670
because of the information
that we gave to the agent.

104
00:04:08,670 --> 00:04:12,067
And as you can see here,
we have the issue resolved.

105
00:04:12,067 --> 00:04:15,870
"Oh, Lucas, but is not too
dangerous to let the MCP

106
00:04:15,870 --> 00:04:19,620
and the agent apply that stuff
in our production cluster?"

107
00:04:19,620 --> 00:04:20,490
Of course it is.

108
00:04:20,490 --> 00:04:22,320
That's just to show the
art of the possible,

109
00:04:22,320 --> 00:04:24,570
but we could integrate that
with GitHubs and everything.

110
00:04:24,570 --> 00:04:26,700
But that's for later in the presentation.

111
00:04:26,700 --> 00:04:27,930
But that's essentially

112
00:04:27,930 --> 00:04:29,460
what we're gonna be building today,

113
00:04:29,460 --> 00:04:31,410
our new teammate.
- Yeah, perfect.

114
00:04:31,410 --> 00:04:32,700
And of course, that was a recording.

115
00:04:32,700 --> 00:04:34,950
We just wanted to show you
kind of what's possible, right?

116
00:04:34,950 --> 00:04:38,130
Like these alert messages
that can automatically fire

117
00:04:38,130 --> 00:04:39,300
in your Slack channel,

118
00:04:39,300 --> 00:04:41,940
seeing that the agent
can pick those up quickly

119
00:04:41,940 --> 00:04:45,120
and respond with contextual information.

120
00:04:45,120 --> 00:04:46,620
And that's something important
that we're gonna dive

121
00:04:46,620 --> 00:04:47,970
into is, you know,

122
00:04:47,970 --> 00:04:50,310
we all know LLMs are just
as good as the amount

123
00:04:50,310 --> 00:04:52,080
of context you're able to provide them,

124
00:04:52,080 --> 00:04:55,380
and that's even more critical
for what we'll show today.

125
00:04:55,380 --> 00:04:58,320
So realistically, again, I
love that it's not a chat bot.

126
00:04:58,320 --> 00:05:01,219
That's right, 2024, we're going into 2026.

127
00:05:01,219 --> 00:05:03,090
We wanna go beyond that.

128
00:05:03,090 --> 00:05:05,340
It's not just a chat
bot. We want a teammate.

129
00:05:05,340 --> 00:05:07,147
And you might just be thinking,

130
00:05:07,147 --> 00:05:09,900
"Oh, well, you're just wrapping
chat messages in Slack."

131
00:05:09,900 --> 00:05:11,640
It's still a chat bot.

132
00:05:11,640 --> 00:05:12,900
By the end of today's session,

133
00:05:12,900 --> 00:05:14,130
I think you'll believe me

134
00:05:14,130 --> 00:05:16,620
that it's more than just a chat bot.

135
00:05:16,620 --> 00:05:19,500
And we're gonna dive
into that in a bit here.

136
00:05:19,500 --> 00:05:21,540
Last year we showed RAG,

137
00:05:21,540 --> 00:05:24,300
this is Retrieval Augmented Generation.

138
00:05:24,300 --> 00:05:25,980
It's important for us to understand this

139
00:05:25,980 --> 00:05:28,230
'cause then you'll see how
far we were able to come

140
00:05:28,230 --> 00:05:32,340
with Agentic architectures
over maybe simple RAG.

141
00:05:32,340 --> 00:05:34,350
With any sort of RAG pipeline,

142
00:05:34,350 --> 00:05:38,370
you have a massive set of source material.

143
00:05:38,370 --> 00:05:41,550
And in this case it can
be like Kubernetes logs

144
00:05:41,550 --> 00:05:44,280
and of course logs can
go into the megabytes,

145
00:05:44,280 --> 00:05:46,530
gigabytes, terabytes, tons of data.

146
00:05:46,530 --> 00:05:50,280
It would be crazy to store
all of that as raw data.

147
00:05:50,280 --> 00:05:54,210
And you know, LLMs, they
understand in a different language.

148
00:05:54,210 --> 00:05:56,010
It's embeddings, it's matrices.

149
00:05:56,010 --> 00:05:59,487
And so, the first thing you
do with any sort of, kind of,

150
00:05:59,487 --> 00:06:02,700
retrieval augmented generation
is you take that data source,

151
00:06:02,700 --> 00:06:04,710
you chunk it up, you
put it into embeddings,

152
00:06:04,710 --> 00:06:06,630
and you put it into a vector store.

153
00:06:06,630 --> 00:06:08,880
So that was the first thing
that we did last year.

154
00:06:08,880 --> 00:06:11,910
Then when the user asks a question,

155
00:06:11,910 --> 00:06:14,730
we take that question and we first look

156
00:06:14,730 --> 00:06:17,850
for any relevant context
in that vector store.

157
00:06:17,850 --> 00:06:19,830
And so that's what you kind of see here

158
00:06:19,830 --> 00:06:23,910
with the context over here
is you take that context

159
00:06:23,910 --> 00:06:26,757
and you put it along with the embeddings

160
00:06:27,630 --> 00:06:29,100
from the original search.

161
00:06:29,100 --> 00:06:31,440
Then now that you have the context,

162
00:06:31,440 --> 00:06:33,600
you pipe that into the original question

163
00:06:33,600 --> 00:06:36,450
and you pass it into a
large language model.

164
00:06:36,450 --> 00:06:38,850
So by the way, that embeddings model,

165
00:06:38,850 --> 00:06:40,680
this is kinda like a lightweight model,

166
00:06:40,680 --> 00:06:42,423
just to find the relevant context.

167
00:06:43,575 --> 00:06:46,350
The large language model uses that context

168
00:06:46,350 --> 00:06:48,840
plus the original prompt
gives you a response.

169
00:06:48,840 --> 00:06:50,460
Let's just quickly cover what we did.

170
00:06:50,460 --> 00:06:52,680
Chunk the logs into vector storage.

171
00:06:52,680 --> 00:06:54,270
The user asks the question,

172
00:06:54,270 --> 00:06:56,370
why is my app response time high?

173
00:06:56,370 --> 00:06:58,200
You take the relevant context,

174
00:06:58,200 --> 00:07:00,750
you pipe it in with the
original input, boom,

175
00:07:00,750 --> 00:07:02,880
you pass it into like a bedrock LLM,

176
00:07:02,880 --> 00:07:06,420
like a big agent, maybe Sonnet
or Haiku, whatever you want.

177
00:07:06,420 --> 00:07:09,750
And you get a response.
- The problem with that is,

178
00:07:09,750 --> 00:07:13,710
one, we are limited to
the context window, right?

179
00:07:13,710 --> 00:07:15,330
RAG can be really intensive.

180
00:07:15,330 --> 00:07:16,560
And also we're using right here

181
00:07:16,560 --> 00:07:19,470
because the model itself
is limited to the amount

182
00:07:19,470 --> 00:07:21,900
of training data that it was trained on.

183
00:07:21,900 --> 00:07:24,360
So now we need to inject that custom data,

184
00:07:24,360 --> 00:07:26,730
custom logs to be able to
do the troubleshooting.

185
00:07:26,730 --> 00:07:28,170
But this was last year approach.

186
00:07:28,170 --> 00:07:29,003
- [Sai] This was last year.

187
00:07:29,003 --> 00:07:30,690
And there's actually one
more downside of this,

188
00:07:30,690 --> 00:07:33,360
of, you know, that data
source chunking and storing

189
00:07:33,360 --> 00:07:34,710
into the vector database.

190
00:07:34,710 --> 00:07:36,360
We were doing that often, sure.

191
00:07:36,360 --> 00:07:39,000
But maybe like once every
30 minutes, once every hour.

192
00:07:39,000 --> 00:07:41,640
We weren't getting live
data from the cluster.

193
00:07:41,640 --> 00:07:43,380
So if an engineer just deployed a pod

194
00:07:43,380 --> 00:07:44,670
and they're troubleshooting it,

195
00:07:44,670 --> 00:07:46,020
that data might not have been chunked

196
00:07:46,020 --> 00:07:47,614
and stored into the Vector database yet.

197
00:07:47,614 --> 00:07:49,440
- [Lucas] And if the issue
is happening right now,

198
00:07:49,440 --> 00:07:51,720
how we are able to reduce
the meantime to remediation

199
00:07:51,720 --> 00:07:53,280
if we don't have live data?
- Yeah.

200
00:07:53,280 --> 00:07:54,840
And so what we saw last year was,

201
00:07:54,840 --> 00:07:56,550
developers would find an issue,

202
00:07:56,550 --> 00:07:57,960
they would go to the Kube cuddle,

203
00:07:57,960 --> 00:07:59,850
they would run some
commands, get them data,

204
00:07:59,850 --> 00:08:00,903
and then pass it into the LLM.

205
00:08:00,903 --> 00:08:03,060
It's like a lot of manual back and forth

206
00:08:03,060 --> 00:08:04,290
and context switching.

207
00:08:04,290 --> 00:08:07,320
And really this is why agents are here

208
00:08:07,320 --> 00:08:09,210
to kind of solve some of that.

209
00:08:09,210 --> 00:08:13,950
Strands is an open source
SDK for building agents.

210
00:08:13,950 --> 00:08:16,380
And it's a fundamental way

211
00:08:16,380 --> 00:08:18,570
that we're gonna build the
agent from scratch today.

212
00:08:18,570 --> 00:08:20,940
- [Lucas] Do anyone here
already using Strands agent

213
00:08:20,940 --> 00:08:22,410
or have tested the Strands agent?

214
00:08:22,410 --> 00:08:24,360
I see couple of hands raised.

215
00:08:24,360 --> 00:08:26,250
It's gonna be good.
- Yeah. Perfect.

216
00:08:26,250 --> 00:08:29,700
No, and we're gonna get
into why this is SDK is

217
00:08:29,700 --> 00:08:31,590
so good for building agents.

218
00:08:31,590 --> 00:08:33,630
They've really thought through
the different use cases

219
00:08:33,630 --> 00:08:35,670
of what agents might need to do.

220
00:08:35,670 --> 00:08:37,950
We're gonna start using some
of those things as well.

221
00:08:37,950 --> 00:08:38,783
In addition,

222
00:08:38,783 --> 00:08:40,740
we're starting to see
this trend in the industry

223
00:08:40,740 --> 00:08:44,220
of not just building one massive
agent powered by one LLM,

224
00:08:44,220 --> 00:08:49,080
but using smaller agents that
use the right LLM for the job.

225
00:08:49,080 --> 00:08:51,640
And so look, really,

226
00:08:51,640 --> 00:08:54,210
I don't wanna go too much
stepped into this architecture,

227
00:08:54,210 --> 00:08:57,240
just know that when a
user prompts this agent,

228
00:08:57,240 --> 00:08:59,730
that agent can use other agents,

229
00:08:59,730 --> 00:09:01,950
it can use multiple LLM models,

230
00:09:01,950 --> 00:09:04,710
it can talk directly to your AWS resources

231
00:09:04,710 --> 00:09:08,940
and it can hook into MCP servers
and the way it communicates

232
00:09:08,940 --> 00:09:12,000
and the prompts that the agent
uses to talk to one another.

233
00:09:12,000 --> 00:09:13,530
That's all customizable.

234
00:09:13,530 --> 00:09:15,030
And that's what we'll show you today

235
00:09:15,030 --> 00:09:18,180
with a very basic first getting started

236
00:09:18,180 --> 00:09:20,553
with a basic Strands architecture.

237
00:09:20,553 --> 00:09:23,520
It's gonna be a Slack interface

238
00:09:23,520 --> 00:09:25,320
that is reading chat messages

239
00:09:25,320 --> 00:09:28,560
that passes it to an Orchestrator agent.

240
00:09:28,560 --> 00:09:32,220
And the reason why we use
two agents here will be clear

241
00:09:32,220 --> 00:09:34,470
in a bit, but we use an Orchestrator agent

242
00:09:34,470 --> 00:09:37,590
that then route send message
to another agent that's able

243
00:09:37,590 --> 00:09:40,273
to load information directly from the API,

244
00:09:40,273 --> 00:09:42,013
directly from MCP.

245
00:09:42,013 --> 00:09:44,790
And what you'll see is
that we pre-configured

246
00:09:44,790 --> 00:09:48,360
that agent to do a couple
of things right off the bat.

247
00:09:48,360 --> 00:09:52,440
So let's get into it.
We'll show the demo here.

248
00:09:52,440 --> 00:09:55,530
So, again, don't have
anything running just yet

249
00:09:55,530 --> 00:09:59,370
and if we wanted to, we can-

250
00:09:59,370 --> 00:10:00,780
I'll actually just load up the ID

251
00:10:00,780 --> 00:10:03,750
and we'll walk through
some of the basic elements

252
00:10:03,750 --> 00:10:05,130
of the architecture.

253
00:10:05,130 --> 00:10:05,963
Right off the bat,

254
00:10:05,963 --> 00:10:07,323
I think this is the first
one that we want to see.

255
00:10:07,323 --> 00:10:08,550
- Zoom in a little.
- Here.

256
00:10:08,550 --> 00:10:09,993
Let's do that. Cool.

257
00:10:11,370 --> 00:10:12,810
Hopefully folks can see that.
- Yeah.

258
00:10:12,810 --> 00:10:15,031
- [Sai] Nice, I think
that's pretty big, right?

259
00:10:15,031 --> 00:10:16,500
Right off the bat you can see,

260
00:10:16,500 --> 00:10:19,860
we're importing the agent
capabilities from the Strands SDK.

261
00:10:19,860 --> 00:10:21,930
This is all in Python by the way.

262
00:10:21,930 --> 00:10:24,720
There's a lot of cookie
cutter boiler plate

263
00:10:24,720 --> 00:10:27,450
that we have in here already
that I'll quickly walk through

264
00:10:27,450 --> 00:10:29,940
that Orchestrator agent
that I talked about.

265
00:10:29,940 --> 00:10:34,230
Essentially, it receives
messages from Slack

266
00:10:34,230 --> 00:10:36,780
and it's able to do a
couple of things like,

267
00:10:36,780 --> 00:10:39,570
right now, we configured it with one tool,

268
00:10:39,570 --> 00:10:41,190
again, cookie cutter stuff.

269
00:10:41,190 --> 00:10:42,870
We haven't really cooked up MCP yet.

270
00:10:42,870 --> 00:10:44,550
It's not a very smart agent.

271
00:10:44,550 --> 00:10:47,280
We just manually coded this one.

272
00:10:47,280 --> 00:10:50,040
We say you have troubleshoot k8s, right?

273
00:10:50,040 --> 00:10:52,590
So let's jump into that one.

274
00:10:52,590 --> 00:10:54,120
And if we go into that,

275
00:10:54,120 --> 00:10:57,000
essentially it'll open
this file right here.

276
00:10:57,000 --> 00:10:58,803
This is our Kubernetes specialist.

277
00:11:00,120 --> 00:11:02,820
Some hints here saying we
will connect it to MCP,

278
00:11:02,820 --> 00:11:04,710
but it doesn't have MCP just yet so.

279
00:11:04,710 --> 00:11:06,782
- Spoiler alert.
- Yeah, ignore that for now.

280
00:11:06,782 --> 00:11:10,020
We've actually just configured
a couple of tools in here,

281
00:11:10,020 --> 00:11:11,820
so oops, don't wanna do that.

282
00:11:11,820 --> 00:11:12,990
A couple of tools here.

283
00:11:12,990 --> 00:11:15,150
So describe pod, get pods,

284
00:11:15,150 --> 00:11:18,183
and we've kind of manually
programmed these in.

285
00:11:19,050 --> 00:11:21,540
We'll talk about how these
work in a second here.

286
00:11:21,540 --> 00:11:23,880
We tell the agent to use
a specific, you know,

287
00:11:23,880 --> 00:11:27,750
bedrock model ID that's
configured in some config settings

288
00:11:27,750 --> 00:11:29,700
that we'll go through
here in just a second.

289
00:11:29,700 --> 00:11:31,585
And a troubleshoot command.

290
00:11:31,585 --> 00:11:34,290
This actually does the
troubleshooting itself.

291
00:11:34,290 --> 00:11:36,450
Okay, let's go through some

292
00:11:36,450 --> 00:11:39,150
of the properties that we've set up.

293
00:11:39,150 --> 00:11:42,510
So I think the one interesting
one here was the Model ID.

294
00:11:42,510 --> 00:11:46,713
So we're deciding to use
Claude 3 Sonnet for this one.

295
00:11:47,610 --> 00:11:48,960
Kind of a relatively older model,

296
00:11:48,960 --> 00:11:51,120
but perfectly good
enough for our use case.

297
00:11:51,120 --> 00:11:52,410
We also have some other properties

298
00:11:52,410 --> 00:11:55,200
in here like the AWS
Region, stuff for Slack,

299
00:11:55,200 --> 00:11:56,880
that kind of thing.

300
00:11:56,880 --> 00:11:58,410
There's a Slack handler.

301
00:11:58,410 --> 00:11:59,490
I don't wanna get too much into this.

302
00:11:59,490 --> 00:12:01,590
This is cookie cutter, boiler plate code.

303
00:12:01,590 --> 00:12:05,790
It just takes messages from
Slack, guides it to the agent.

304
00:12:05,790 --> 00:12:08,910
This stuff is really
well documented, I think.

305
00:12:08,910 --> 00:12:10,800
Think we coded this using Kiro, right?

306
00:12:10,800 --> 00:12:12,330
Just auto-generated this?
- Yeah,

307
00:12:12,330 --> 00:12:13,890
I just send a prompt to Kiro

308
00:12:13,890 --> 00:12:15,210
and actually Kiro code everything.

309
00:12:15,210 --> 00:12:17,100
I didn't even touch the code

310
00:12:17,100 --> 00:12:19,830
for the like handle
itself for the agent, yes.

311
00:12:19,830 --> 00:12:20,670
- [Sai] Exactly.

312
00:12:20,670 --> 00:12:22,440
And one last thing,

313
00:12:22,440 --> 00:12:23,760
let's just look at the requirements file.

314
00:12:23,760 --> 00:12:26,280
These are all the SDKs that are

315
00:12:26,280 --> 00:12:27,690
and tools that are loaded.

316
00:12:27,690 --> 00:12:31,830
And you'll see us use these
throughout, not that many here.

317
00:12:31,830 --> 00:12:32,663
Fairly straightforward.

318
00:12:32,663 --> 00:12:36,090
Some of the Strand's pieces,
MCP, that kind of thing.

319
00:12:36,090 --> 00:12:38,370
Okay, should we do the first demo?

320
00:12:38,370 --> 00:12:39,810
- [Lucas] I think so
let's do the first demo

321
00:12:39,810 --> 00:12:42,090
and just remembering folks that the agent

322
00:12:42,090 --> 00:12:44,580
that we have right now
doesn't have any access

323
00:12:44,580 --> 00:12:45,870
to MCP capabilities.

324
00:12:45,870 --> 00:12:48,930
So the only two that it has access to

325
00:12:48,930 --> 00:12:51,570
is describe pods and get pods.

326
00:12:51,570 --> 00:12:54,360
So what Sai is gonna do
now is send a question

327
00:12:54,360 --> 00:12:57,869
to the agent requesting
information that we know

328
00:12:57,869 --> 00:13:00,570
that the agent doesn't
have the capabilities for.

329
00:13:00,570 --> 00:13:01,403
But it's gonna try the best

330
00:13:01,403 --> 00:13:03,570
to respond in the best way as possible.

331
00:13:03,570 --> 00:13:04,403
- [Sai] So I'm gonna-

332
00:13:04,403 --> 00:13:05,236
Yeah, exactly.

333
00:13:05,236 --> 00:13:08,310
I'm gonna ask it what namespace
are in my EKS cluster?

334
00:13:08,310 --> 00:13:10,210
That's me, I'm Lucas.
- You're Lucas.

335
00:13:11,085 --> 00:13:13,230
- [Sai] But let's quickly take a look

336
00:13:13,230 --> 00:13:14,940
at the tools that we configured, right?

337
00:13:14,940 --> 00:13:18,090
So if we look at the agent Orchestrator,

338
00:13:18,090 --> 00:13:22,578
we actually only had configured
a couple of tools here.

339
00:13:22,578 --> 00:13:24,840
Describe pod and get pod.
- That's it.

340
00:13:24,840 --> 00:13:26,730
- [Sai] We didn't tell
it how to get namespaces.

341
00:13:26,730 --> 00:13:28,440
We didn't, it doesn't know how to,

342
00:13:28,440 --> 00:13:29,670
so it's gonna try its best.

343
00:13:29,670 --> 00:13:31,470
And before I show you
what it responded with,

344
00:13:31,470 --> 00:13:34,110
let's actually see how it kind of thought

345
00:13:34,110 --> 00:13:35,553
through the process.

346
00:13:37,020 --> 00:13:38,640
It doesn't know how to list namespaces.

347
00:13:38,640 --> 00:13:41,730
So first it's gonna get pods
and based on that output,

348
00:13:41,730 --> 00:13:43,710
it's gonna try and
intelligently figure out

349
00:13:43,710 --> 00:13:45,450
what namespaces are.

350
00:13:45,450 --> 00:13:46,560
Not great.

351
00:13:46,560 --> 00:13:48,570
It actually doesn't figure
out all the namespaces.

352
00:13:48,570 --> 00:13:49,500
It says there's three.

353
00:13:49,500 --> 00:13:51,063
And if we look at the response,

354
00:13:52,080 --> 00:13:53,790
you know, it says
there's three namespaces.

355
00:13:53,790 --> 00:13:54,840
That's actually not true.

356
00:13:54,840 --> 00:13:57,270
If we go to k9s, you know,

357
00:13:57,270 --> 00:14:00,090
it's just a handy CLI tool
to let us see what's running

358
00:14:00,090 --> 00:14:01,020
in our cluster.

359
00:14:01,020 --> 00:14:02,130
You can see there's actually a lot more

360
00:14:02,130 --> 00:14:03,481
than three namespaces.

361
00:14:03,481 --> 00:14:04,740
So we wanna make it better.

362
00:14:04,740 --> 00:14:07,020
And to do so, I think, maybe,

363
00:14:07,020 --> 00:14:09,840
I'll very quickly
introduce a new capability

364
00:14:09,840 --> 00:14:11,433
that we've just announced.

365
00:14:12,390 --> 00:14:13,920
I think it was last week, right?

366
00:14:13,920 --> 00:14:14,753
- Yeah.
- And that's-

367
00:14:14,753 --> 00:14:16,020
- [Lucas] Two weeks ago. Two weeks ago.

368
00:14:16,020 --> 00:14:16,980
- [Sai] Two weeks, two weeks.

369
00:14:16,980 --> 00:14:20,010
It's the hosted EKS MCP server.

370
00:14:20,010 --> 00:14:21,720
Essentially, instead of having

371
00:14:21,720 --> 00:14:26,400
to launch the MCP server yourself
locally, we do it for you.

372
00:14:26,400 --> 00:14:29,910
And so that means instead
of having to launch a proxy

373
00:14:29,910 --> 00:14:33,420
and tunnel permissions and
run the MCP server yourself

374
00:14:33,420 --> 00:14:34,740
and scale it-
- Run it locally,

375
00:14:34,740 --> 00:14:36,990
handling two process, a lot of mess.

376
00:14:36,990 --> 00:14:38,490
- [Sai] It's all in the cloud.

377
00:14:38,490 --> 00:14:40,920
And essentially you just,

378
00:14:40,920 --> 00:14:44,460
it leverages IAM so you can
identity access and permission.

379
00:14:44,460 --> 00:14:47,910
So you can use that to
grant the right permissions

380
00:14:47,910 --> 00:14:50,340
to the right set of people
who should be able to use it.

381
00:14:50,340 --> 00:14:51,750
So let's use that.

382
00:14:51,750 --> 00:14:53,490
And actually it's funny,

383
00:14:53,490 --> 00:14:56,610
right up until two weeks ago,
we were doing the old way,

384
00:14:56,610 --> 00:14:58,417
and as soon as this came out we thought,

385
00:14:58,417 --> 00:15:01,860
"Hey, we can really simplify
the MCP configuration

386
00:15:01,860 --> 00:15:03,600
for our live demo."

387
00:15:03,600 --> 00:15:06,390
And we switched it over.
- And if you're using EKS,

388
00:15:06,390 --> 00:15:07,830
if you have IAM permissions,

389
00:15:07,830 --> 00:15:11,640
you can just use it with
your favorite code helper.

390
00:15:11,640 --> 00:15:12,600
- [Sai] Exactly.

391
00:15:12,600 --> 00:15:15,120
And so here's that new
architecture, right?

392
00:15:15,120 --> 00:15:16,710
So that specialist agent,

393
00:15:16,710 --> 00:15:18,930
you'll just notice there's one more box.

394
00:15:18,930 --> 00:15:21,510
There's on the bottom left there,

395
00:15:21,510 --> 00:15:25,410
the manually coded tools
that we had from before.

396
00:15:25,410 --> 00:15:26,790
And then now with MCP.

397
00:15:26,790 --> 00:15:29,820
So now this Specialist agent can decide

398
00:15:29,820 --> 00:15:32,130
to use the MCP if it wanted to.

399
00:15:32,130 --> 00:15:34,580
Let's take a look at how
we would configure that.

400
00:15:35,848 --> 00:15:38,957
All right, we'll go back into Kiro-

401
00:15:40,103 --> 00:15:43,170
- [Lucas] No need to, just switch the-

402
00:15:43,170 --> 00:15:45,000
- [Sai] Oh yeah, hit the demo button.

403
00:15:45,000 --> 00:15:46,978
Should be good. Perfect, thank you.

404
00:15:46,978 --> 00:15:49,113
Alright, let's jump in here

405
00:15:49,113 --> 00:15:51,690
and we're gonna go first
to the settings file

406
00:15:51,690 --> 00:15:53,670
'cause we need a property

407
00:15:53,670 --> 00:15:56,737
and a property that will
essentially just tell it,

408
00:15:56,737 --> 00:16:00,330
"Hey, we want to enable
MCP," so we'll enable this,

409
00:16:00,330 --> 00:16:03,270
again, just looks at the
environment variables

410
00:16:03,270 --> 00:16:05,040
and then sets it.

411
00:16:05,040 --> 00:16:07,500
And so now in the actual code,

412
00:16:07,500 --> 00:16:09,270
we'll go to our Kubernetes specialist,

413
00:16:09,270 --> 00:16:11,460
which again, remember from the PowerPoint

414
00:16:11,460 --> 00:16:14,670
that we built this into
the Specialist itself.

415
00:16:14,670 --> 00:16:17,430
So it knows the MCP exists.

416
00:16:17,430 --> 00:16:22,430
First we'll need to actually
import the system libraries

417
00:16:22,500 --> 00:16:23,961
from, you know,

418
00:16:23,961 --> 00:16:25,680
so we import MCP

419
00:16:25,680 --> 00:16:27,930
and this is essentially
just using standard IO

420
00:16:27,930 --> 00:16:29,160
to talk to MCP.

421
00:16:29,160 --> 00:16:32,216
It's a standard protocol for
working with MCP servers.

422
00:16:32,216 --> 00:16:35,220
- [Lucas] And Strands too
already has a MCP client embedded

423
00:16:35,220 --> 00:16:36,053
on it.

424
00:16:36,053 --> 00:16:38,100
So you can make your
Strands agent be a client

425
00:16:38,100 --> 00:16:41,430
of MCP hosted servers
or even local servers.

426
00:16:41,430 --> 00:16:44,580
I mean, it's very, very few lines of code.

427
00:16:44,580 --> 00:16:46,050
- [Sai] Exactly.

428
00:16:46,050 --> 00:16:49,653
And so let me just get
the spacing here, right.

429
00:16:53,820 --> 00:16:56,395
- [Lucas] I think you need
to align the self one,

430
00:16:56,395 --> 00:16:58,860
all the way up.
- There we go.

431
00:16:58,860 --> 00:17:00,060
Perfect. All right.

432
00:17:00,060 --> 00:17:01,140
So essentially what this is doing,

433
00:17:01,140 --> 00:17:04,920
if a MCP is enabled, talk
to the hosted MCP server.

434
00:17:04,920 --> 00:17:08,190
Again, obviously this will
resolve to US West too

435
00:17:08,190 --> 00:17:09,720
where we're running this demo.

436
00:17:09,720 --> 00:17:11,880
That's a hosted MCP endpoint.

437
00:17:11,880 --> 00:17:13,290
One thing that we had to do in the backend

438
00:17:13,290 --> 00:17:14,700
was just set up the IAM role

439
00:17:14,700 --> 00:17:17,490
so that this app can talk to MCP

440
00:17:17,490 --> 00:17:19,119
and get the right info.

441
00:17:19,119 --> 00:17:21,810
And that's basically it,

442
00:17:21,810 --> 00:17:25,350
launch the standard IO client
and that should be good.

443
00:17:25,350 --> 00:17:26,220
Let me save it.

444
00:17:26,220 --> 00:17:28,380
Let me go back to the terminal here.

445
00:17:28,380 --> 00:17:29,945
Kill the python process.

446
00:17:29,945 --> 00:17:32,070
- [Lucas] We need to
add the deletion method

447
00:17:32,070 --> 00:17:33,390
as well.
- Right, right.

448
00:17:33,390 --> 00:17:34,707
- [Lucas] If you don't
add the deletion method,

449
00:17:34,707 --> 00:17:37,500
the MCP, the connection
will be open forever.

450
00:17:37,500 --> 00:17:38,580
And then we're gonna have a problem.

451
00:17:38,580 --> 00:17:39,840
But since it's a live code session,

452
00:17:39,840 --> 00:17:41,040
just remember inside to do that.

453
00:17:41,040 --> 00:17:42,450
So we don't have that issue.

454
00:17:42,450 --> 00:17:44,280
- [Sai] There we go. So
here's the cleanup step.

455
00:17:44,280 --> 00:17:45,930
We're gonna make sure we
clean up after ourselves.

456
00:17:45,930 --> 00:17:47,280
It's very important.
- Important.

457
00:17:47,280 --> 00:17:48,690
- [Sai] Okay. All right.

458
00:17:48,690 --> 00:17:49,680
We're gonna back here.

459
00:17:49,680 --> 00:17:52,410
And again, I think you were
saying this earlier, Lucas,

460
00:17:52,410 --> 00:17:53,940
but we're running this locally

461
00:17:53,940 --> 00:17:56,072
and so it makes it easy for live demo.

462
00:17:56,072 --> 00:17:57,526
So we're just gonna start it back up.

463
00:17:57,526 --> 00:17:59,850
So I killed it and then
I'm starting it back up,

464
00:17:59,850 --> 00:18:01,320
now with MCP.

465
00:18:01,320 --> 00:18:05,580
And we should see an indicator
that MCP is being used now

466
00:18:05,580 --> 00:18:09,180
because until then while we
had the library downloaded,

467
00:18:09,180 --> 00:18:10,710
we weren't actually using it.

468
00:18:10,710 --> 00:18:12,930
Of course, you'll remember right up here,

469
00:18:12,930 --> 00:18:16,830
we import it, we added
some code to talk to MCP.

470
00:18:16,830 --> 00:18:19,140
So now it's thinking through the process

471
00:18:19,140 --> 00:18:22,410
and oh, here we go.

472
00:18:22,410 --> 00:18:24,314
I think it's because I made it very big.

473
00:18:24,314 --> 00:18:25,147
- [Lucas] Yeah, just click on top of it.

474
00:18:25,147 --> 00:18:26,820
- [Sai] There we go. Perfect.

475
00:18:26,820 --> 00:18:28,260
All right, well the spacing got messed up,

476
00:18:28,260 --> 00:18:29,093
but you can see it.

477
00:18:29,093 --> 00:18:29,926
It says-
- Trust us.

478
00:18:29,926 --> 00:18:31,380
It's MCP.
(Sai chuckles)

479
00:18:31,380 --> 00:18:33,030
- [Sai] We're doing it live.

480
00:18:33,030 --> 00:18:34,230
Okay, perfect.

481
00:18:34,230 --> 00:18:37,170
Python app is up, it's
listening for Slack messages.

482
00:18:37,170 --> 00:18:40,890
And let's ask the exact
same question again.

483
00:18:40,890 --> 00:18:42,630
That's me. I'm Lucas.

484
00:18:42,630 --> 00:18:45,270
What namespace are in my EKS cluster?

485
00:18:45,270 --> 00:18:47,880
And it's thinking and now it should,

486
00:18:47,880 --> 00:18:50,610
you know, it's using the
trouble k8s method again

487
00:18:50,610 --> 00:18:52,920
and it's using a tool
that I've never heard of.

488
00:18:52,920 --> 00:18:56,040
We haven't coded this, list k8s resources.

489
00:18:56,040 --> 00:18:59,130
We don't have that. It's not in our code.

490
00:18:59,130 --> 00:19:00,269
- [Lucas] I haven't coded it.

491
00:19:00,269 --> 00:19:03,030
- [Sai] And in fact it's
only in the read me right,

492
00:19:03,030 --> 00:19:05,880
but in our documentation for MCP,

493
00:19:05,880 --> 00:19:07,980
but we haven't coded this anywhere,

494
00:19:07,980 --> 00:19:10,500
it's getting that tool
from the MCP server.

495
00:19:10,500 --> 00:19:15,090
It talks to that hosted
endpoint and it tells our agent,

496
00:19:15,090 --> 00:19:17,550
there's countless tools that it can use.

497
00:19:17,550 --> 00:19:20,880
But it says for namespaces,
this is the perfect one to use.

498
00:19:20,880 --> 00:19:22,440
List k8s resources,

499
00:19:22,440 --> 00:19:24,990
it actually gets the
correct set of namespaces.

500
00:19:24,990 --> 00:19:28,800
And now fingers crossed, I
go back to Slack, check it.

501
00:19:28,800 --> 00:19:30,000
Boom. All right.

502
00:19:30,000 --> 00:19:31,110
So that's the first step.

503
00:19:31,110 --> 00:19:34,080
And just a few steps
you've seen that we're able

504
00:19:34,080 --> 00:19:36,570
to make our bot that
much more intelligent.

505
00:19:36,570 --> 00:19:39,975
It's able to pull anything
from our EKS cluster

506
00:19:39,975 --> 00:19:42,780
that realistically-
- Imagine if we needed

507
00:19:42,780 --> 00:19:45,840
to create every single tool
for every single possibility

508
00:19:45,840 --> 00:19:47,727
of troubleshooting in our agent

509
00:19:47,727 --> 00:19:50,040
and would be replicating
tools here and there.

510
00:19:50,040 --> 00:19:53,400
So what I like to think as an
MCP almost got an API gated

511
00:19:53,400 --> 00:19:55,530
that we can centralize the communication,

512
00:19:55,530 --> 00:19:56,700
standardize the tools,

513
00:19:56,700 --> 00:20:00,330
and then reuse those tools
across multiple different agents.

514
00:20:00,330 --> 00:20:01,830
Soon enough we're gonna
be talking about how

515
00:20:01,830 --> 00:20:04,380
to break monolithic agents
to micro agents for sure.

516
00:20:04,380 --> 00:20:05,746
- [Sai] Yeah, yeah, exactly.

517
00:20:05,746 --> 00:20:07,980
You know, I think the analogy
a lot of folks have heard

518
00:20:07,980 --> 00:20:10,470
before for MCP is that
it's like the USB-C,

519
00:20:10,470 --> 00:20:12,510
universal plug for integrations.

520
00:20:12,510 --> 00:20:14,910
But I really see this as a solution

521
00:20:14,910 --> 00:20:17,820
for like an exponentially
complicated problem.

522
00:20:17,820 --> 00:20:19,170
Think about all the LLMs out there.

523
00:20:19,170 --> 00:20:21,390
You probably use three or four yourself

524
00:20:21,390 --> 00:20:24,090
and then you know all the
tools that it could talk to.

525
00:20:24,090 --> 00:20:25,530
You know, maybe your emails,

526
00:20:25,530 --> 00:20:28,560
maybe an EKS cluster, maybe
different AWS services.

527
00:20:28,560 --> 00:20:29,393
So think about it.

528
00:20:29,393 --> 00:20:31,770
So if you're trying to build
integrations for 10 LLMs

529
00:20:31,770 --> 00:20:33,840
to talk to a hundred different tools,

530
00:20:33,840 --> 00:20:36,720
10 times a hundred, that's
a lot of integrations.

531
00:20:36,720 --> 00:20:38,460
MCP is just that integration layer.

532
00:20:38,460 --> 00:20:41,730
So you build it once and all
your LLMs can talk to any

533
00:20:41,730 --> 00:20:43,260
of the tools that are built.

534
00:20:43,260 --> 00:20:45,540
Okay, so that, that takes it
from an exponential problem

535
00:20:45,540 --> 00:20:47,820
to an O-N problem.

536
00:20:47,820 --> 00:20:48,653
Perfect.

537
00:20:48,653 --> 00:20:50,520
So we've added MCP,

538
00:20:50,520 --> 00:20:52,800
our chat bot is that
much more intelligent.

539
00:20:52,800 --> 00:20:54,930
But there's actually
one thing that I wanted

540
00:20:54,930 --> 00:20:58,800
to show really quickly in Kiro,

541
00:20:58,800 --> 00:21:00,900
the way that we're actually classifying

542
00:21:00,900 --> 00:21:02,973
when we wanna respond to a message,

543
00:21:03,840 --> 00:21:05,190
if we look in the prompts,

544
00:21:05,190 --> 00:21:07,530
these are kind of the prompts
that we've configured,

545
00:21:07,530 --> 00:21:10,710
essentially telling the
Orchestrator how to behave.

546
00:21:10,710 --> 00:21:12,060
We have some for the Orchestrator,

547
00:21:12,060 --> 00:21:14,790
we have some from the system prompt.

548
00:21:14,790 --> 00:21:17,820
Basically, telling it its purpose in life.

549
00:21:17,820 --> 00:21:20,940
This agent, you're here
to solve problems for us.

550
00:21:20,940 --> 00:21:23,400
But we have this key words file

551
00:21:23,400 --> 00:21:26,640
and essentially we use these for kind

552
00:21:26,640 --> 00:21:30,660
of dumbly figuring out
when we should respond.

553
00:21:30,660 --> 00:21:31,860
So essentially,

554
00:21:31,860 --> 00:21:36,630
we should respond only when the
keywords are in the message.

555
00:21:36,630 --> 00:21:40,410
And so if we asked it a
question like what version

556
00:21:40,410 --> 00:21:42,093
is my EKS cluster?

557
00:21:43,890 --> 00:21:45,480
It's actually not gonna say anything.

558
00:21:45,480 --> 00:21:47,130
- [Lucas] I think closer is
actually gonna say something,

559
00:21:47,130 --> 00:21:48,570
'cause it's on the keywords.

560
00:21:48,570 --> 00:21:49,403
- Oh!
- That's right.

561
00:21:49,403 --> 00:21:50,236
It's live demo.

562
00:21:50,236 --> 00:21:51,840
Let's do it again.
- Let's do it again.

563
00:21:51,840 --> 00:21:54,540
But if I asked it what
version of EKS am I running,

564
00:21:54,540 --> 00:21:56,760
for example, it wouldn't
actually respond, right?

565
00:21:56,760 --> 00:22:00,930
Because we have this
manually worded approach

566
00:22:00,930 --> 00:22:04,200
for keywords and we wanna
be better, we wanna use AI,

567
00:22:04,200 --> 00:22:07,830
we want to figure out when we
should respond to a message.

568
00:22:07,830 --> 00:22:09,540
And that's because in Slack,

569
00:22:09,540 --> 00:22:12,450
you might have engineers
talking to one another

570
00:22:12,450 --> 00:22:13,650
and they might use one

571
00:22:13,650 --> 00:22:15,820
of those keywords when
they didn't mean to.

572
00:22:15,820 --> 00:22:20,250
We should find the intent of
what the message was about.

573
00:22:20,250 --> 00:22:22,590
If an engineer is talking about a problem

574
00:22:22,590 --> 00:22:25,950
and needs a solution, that's
when we should fire up our bot.

575
00:22:25,950 --> 00:22:28,745
Otherwise, if engineers are
just talking about their weekend

576
00:22:28,745 --> 00:22:32,490
or what they did, we
should kind of ignore that.

577
00:22:32,490 --> 00:22:34,470
Keywords is one simple approach to that.

578
00:22:34,470 --> 00:22:36,930
But let's use AI,

579
00:22:36,930 --> 00:22:39,570
we're gonna expand our
architecture a little bit here.

580
00:22:39,570 --> 00:22:41,673
- Didn't change.
- Oh, here we go.

581
00:22:45,000 --> 00:22:47,340
Okay, so we're gonna
expand our architecture

582
00:22:47,340 --> 00:22:51,240
and in the Orchestrator, we
wanna make it a bit more smart.

583
00:22:51,240 --> 00:22:53,040
When a Slack message is received,

584
00:22:53,040 --> 00:22:57,450
we're gonna use a
different LLM, Nova Micro,

585
00:22:57,450 --> 00:22:59,520
to classify the message intent.

586
00:22:59,520 --> 00:23:02,823
If it's for troubleshooting,
proceed, otherwise exit.

587
00:23:03,930 --> 00:23:05,870
I think the analogy I like here

588
00:23:05,870 --> 00:23:08,920
is you wouldn't put a PhD mathematician

589
00:23:08,920 --> 00:23:12,180
to run your hotel check-in process, right?

590
00:23:12,180 --> 00:23:13,200
It's overkill.

591
00:23:13,200 --> 00:23:15,810
You don't need that level of intelligence,

592
00:23:15,810 --> 00:23:18,390
you don't need that level of operations

593
00:23:18,390 --> 00:23:20,760
to route people to the right rooms.

594
00:23:20,760 --> 00:23:24,660
We want to use a more
lightweight, more efficient model.

595
00:23:24,660 --> 00:23:29,070
In fact, because the Slack
bot responds or listens

596
00:23:29,070 --> 00:23:31,470
to every single message in Slack,

597
00:23:31,470 --> 00:23:34,110
you can see how that could
exponentially get more

598
00:23:34,110 --> 00:23:36,060
and more expensive,

599
00:23:36,060 --> 00:23:39,150
if we're not being a little
bit more intelligent about

600
00:23:39,150 --> 00:23:40,200
when we respond.

601
00:23:40,200 --> 00:23:42,290
And so that's exactly why we want

602
00:23:42,290 --> 00:23:44,696
to use something like Nova Micro,

603
00:23:44,696 --> 00:23:47,550
which is a very lightweight
model that responds very quickly

604
00:23:47,550 --> 00:23:49,170
to respond to messages.

605
00:23:49,170 --> 00:23:50,610
And so now, Lucas,

606
00:23:50,610 --> 00:23:53,850
I'll pass it to you and he'll
show us how the magic is done.

607
00:23:53,850 --> 00:23:56,340
- [Lucas] Alright, let's
take a look into the,

608
00:23:56,340 --> 00:23:59,130
can you please switch to the terminal?

609
00:23:59,130 --> 00:23:59,963
Awesome.

610
00:23:59,963 --> 00:24:00,990
So let's take a look

611
00:24:00,990 --> 00:24:03,630
into the should respond method real quick.

612
00:24:03,630 --> 00:24:06,780
As you can see, if there is
any keyword that was defined

613
00:24:06,780 --> 00:24:10,050
on that list that we just defined it here,

614
00:24:10,050 --> 00:24:11,280
then we should respond.

615
00:24:11,280 --> 00:24:13,680
So if you look at the list
of keywords that we have,

616
00:24:13,680 --> 00:24:15,330
very limited amount of keywords.

617
00:24:15,330 --> 00:24:18,330
So we have a limited validation
method that we just created.

618
00:24:18,330 --> 00:24:19,950
So as Sai just said,

619
00:24:19,950 --> 00:24:22,560
we want to do that in a much better way.

620
00:24:22,560 --> 00:24:25,290
We want to be able to do
a smart classification.

621
00:24:25,290 --> 00:24:26,747
So the first thing that I'm gonna do

622
00:24:26,747 --> 00:24:29,820
is I'm gonna add a new
prompt for our classification

623
00:24:29,820 --> 00:24:31,350
that model that we are using.

624
00:24:31,350 --> 00:24:34,140
And then I'm calling that
classification prompt.

625
00:24:34,140 --> 00:24:36,840
So if you look at this prompt,
it's very, very simple.

626
00:24:36,840 --> 00:24:38,010
Is this message related

627
00:24:38,010 --> 00:24:40,830
to Kubernetes, system
troubleshooting, technical issues,

628
00:24:40,830 --> 00:24:42,060
or requests for help?

629
00:24:42,060 --> 00:24:43,320
Then we pass the message,

630
00:24:43,320 --> 00:24:45,210
then we're replacing
this variable right here

631
00:24:45,210 --> 00:24:46,260
and I'm telling the model,

632
00:24:46,260 --> 00:24:49,440
please just respond with yes or no.

633
00:24:49,440 --> 00:24:51,930
Remember that we pay
by the amount of tokens

634
00:24:51,930 --> 00:24:52,950
that gets generated.

635
00:24:52,950 --> 00:24:54,030
So if we limit it,

636
00:24:54,030 --> 00:24:56,340
the amount of tokens that
the model can generate

637
00:24:56,340 --> 00:24:58,680
and still doing a smart classification,

638
00:24:58,680 --> 00:25:00,780
should be good enough and
should be fast, right?

639
00:25:00,780 --> 00:25:02,310
This is exactly what we're gonna validate.

640
00:25:02,310 --> 00:25:05,040
So we have added a classification prompt.

641
00:25:05,040 --> 00:25:07,800
Now I'm gonna go over
to Agent Orchestrator

642
00:25:07,800 --> 00:25:10,350
and then adding some imports here.

643
00:25:10,350 --> 00:25:13,500
Let me just remove that
import from line five

644
00:25:13,500 --> 00:25:15,120
because we don't need that anymore.

645
00:25:15,120 --> 00:25:17,217
So json, boto3,

646
00:25:17,217 --> 00:25:21,150
and the most important thing
Before Invocation Event,

647
00:25:21,150 --> 00:25:24,390
so Strand itself already
has the capabilities

648
00:25:24,390 --> 00:25:26,400
of intercepting messages

649
00:25:26,400 --> 00:25:29,310
before the message
actually hits the agent.

650
00:25:29,310 --> 00:25:32,730
So what we're gonna do now is
we're gonna implement a method

651
00:25:32,730 --> 00:25:36,240
that it's able to do a smart
classification using Novo Micro

652
00:25:36,240 --> 00:25:39,030
before we send a message
to the agent itself.

653
00:25:39,030 --> 00:25:41,516
So we don't even pay
for the Claude 3.7 model

654
00:25:41,516 --> 00:25:43,200
that we're using on the agent.

655
00:25:43,200 --> 00:25:45,690
So this is what we call
Before Invocation Event.

656
00:25:45,690 --> 00:25:46,890
So before invocation,

657
00:25:46,890 --> 00:25:50,670
the agent please run
this method right here.

658
00:25:50,670 --> 00:25:51,930
What I'm gonna do now as well

659
00:25:51,930 --> 00:25:54,810
is I'm gonna replace the
construction method here

660
00:25:54,810 --> 00:25:56,798
with the one updated,

661
00:25:56,798 --> 00:25:59,460
with the smart classification that we did.

662
00:25:59,460 --> 00:26:01,380
So the only thing that is
different than the other one

663
00:26:01,380 --> 00:26:04,200
is we are instantiating boto3 client,

664
00:26:04,200 --> 00:26:07,020
just to be able to talk to bedrock

665
00:26:07,020 --> 00:26:08,913
and do the Novo Smart classification.

666
00:26:09,810 --> 00:26:10,969
The agent didn't change.

667
00:26:10,969 --> 00:26:14,580
And then here, line 41 is
the most important thing.

668
00:26:14,580 --> 00:26:18,330
So agent, hooks, add
callback, before invocation,

669
00:26:18,330 --> 00:26:21,420
and then the method that I want to call.

670
00:26:21,420 --> 00:26:24,000
The method that I want to
use to validate my message.

671
00:26:24,000 --> 00:26:27,600
And I'm calling that method,
callback message validator.

672
00:26:27,600 --> 00:26:31,290
Because it's very straightforward
name to my method.

673
00:26:31,290 --> 00:26:33,270
What we're gonna do
now is, as you can see,

674
00:26:33,270 --> 00:26:37,156
we don't have any method called
callback message validator,

675
00:26:37,156 --> 00:26:38,310
any function like that.

676
00:26:38,310 --> 00:26:39,500
So what we're gonna do now

677
00:26:39,500 --> 00:26:41,610
is we're gonna create that function

678
00:26:41,610 --> 00:26:44,460
and also the Nova classification function.

679
00:26:44,460 --> 00:26:47,430
We're gonna go over
those methods real quick

680
00:26:47,430 --> 00:26:48,600
so we can see what we are doing.

681
00:26:48,600 --> 00:26:51,210
So callback message validator,

682
00:26:51,210 --> 00:26:53,010
that's the method that's gonna be called.

683
00:26:53,010 --> 00:26:54,990
Once we send a message to our agent,

684
00:26:54,990 --> 00:26:57,450
then we're gonna trigger
classify with Nova method,

685
00:26:57,450 --> 00:26:59,757
passing the message,
the last user message.

686
00:26:59,757 --> 00:27:02,130
And if you go to classify with Nova,

687
00:27:02,130 --> 00:27:03,840
this is where the trick
is happening, right?

688
00:27:03,840 --> 00:27:06,540
So first we have the
classification prompt,

689
00:27:06,540 --> 00:27:09,270
we are replacing the
message that was a variable

690
00:27:09,270 --> 00:27:11,130
before with the current query

691
00:27:11,130 --> 00:27:12,900
that we're sending to the agent.

692
00:27:12,900 --> 00:27:14,850
And then here is the magic.

693
00:27:14,850 --> 00:27:19,850
So max tokens 10 because yes
and no are less than 10 tokens.

694
00:27:20,490 --> 00:27:23,130
So because we're limiting
the amount of tokens,

695
00:27:23,130 --> 00:27:25,350
we are able to get a really fast response.

696
00:27:25,350 --> 00:27:27,150
And because we're using Nova Micro,

697
00:27:27,150 --> 00:27:29,100
we can get that even faster. It's fast.

698
00:27:29,100 --> 00:27:30,750
- So the idea here-
- Some other models-

699
00:27:30,750 --> 00:27:31,583
- [Sai] No, exactly.

700
00:27:31,583 --> 00:27:34,650
And the idea here is, yes,
LLMs are non-deterministic.

701
00:27:34,650 --> 00:27:36,900
You can ask it the same
question multiple times

702
00:27:36,900 --> 00:27:38,760
and get a different response.

703
00:27:38,760 --> 00:27:40,173
But there are ways you
can get around this.

704
00:27:40,173 --> 00:27:42,060
- That's right.
- And that's exactly

705
00:27:42,060 --> 00:27:43,072
what this is doing.

706
00:27:43,072 --> 00:27:46,170
It's making that response
more deterministic.

707
00:27:46,170 --> 00:27:50,280
Now we know that like 99.9% of the time,

708
00:27:50,280 --> 00:27:51,420
I bet if you ask it this question,

709
00:27:51,420 --> 00:27:53,700
it's gonna come back with either yes or no

710
00:27:53,700 --> 00:27:56,130
and it'll likely come back
with that same response.

711
00:27:56,130 --> 00:27:58,983
So really just routing exactly the logic

712
00:27:58,983 --> 00:28:00,630
that that this goes through.

713
00:28:00,630 --> 00:28:03,060
And of course less tokens
means faster response.

714
00:28:03,060 --> 00:28:05,790
And since every Slack
message in the channel

715
00:28:05,790 --> 00:28:07,470
will be sent here, it's gotta be fast.

716
00:28:07,470 --> 00:28:09,450
- [Lucas] Yeah, imagine if we
have a channel with 500 people

717
00:28:09,450 --> 00:28:13,140
and for every message to
classify with Claude 3.7 Sonnet,

718
00:28:13,140 --> 00:28:14,100
it'd be really expensive.

719
00:28:14,100 --> 00:28:16,350
So Nova Micro here could be one.

720
00:28:16,350 --> 00:28:18,478
Another model that we tested was

721
00:28:18,478 --> 00:28:21,600
on top a small language
model on top of CPU.

722
00:28:21,600 --> 00:28:23,040
- That's right,
- We run that as well

723
00:28:23,040 --> 00:28:24,990
on our local comp-

724
00:28:24,990 --> 00:28:26,490
Like laptop. It worked.

725
00:28:26,490 --> 00:28:28,080
Of course Nova Micro
is a little bit better,

726
00:28:28,080 --> 00:28:30,930
but I mean if you have good enough CPUs,

727
00:28:30,930 --> 00:28:33,240
you can also try to do it
with small language models

728
00:28:33,240 --> 00:28:34,760
on top of CPU if you don't want

729
00:28:34,760 --> 00:28:36,570
to use like Nova Micro and anything.

730
00:28:36,570 --> 00:28:39,840
But going back to the code, return answer.

731
00:28:39,840 --> 00:28:43,290
So if the answer that
the model returns is yes,

732
00:28:43,290 --> 00:28:44,460
we should return true.

733
00:28:44,460 --> 00:28:46,710
If it's different than yes,
then we're gonna return false.

734
00:28:46,710 --> 00:28:49,200
And just one thing that I want to show

735
00:28:49,200 --> 00:28:52,560
to you folks right here, line
53, message classification.

736
00:28:52,560 --> 00:28:53,393
We're gonna look for

737
00:28:53,393 --> 00:28:57,510
that information once we
test the new implementation

738
00:28:57,510 --> 00:28:58,343
that we have done.

739
00:28:58,343 --> 00:28:59,550
But before we do that,

740
00:28:59,550 --> 00:29:04,420
we also need to remove that
method that we created before.

741
00:29:04,420 --> 00:29:06,210
Yeah, so should respond.

742
00:29:06,210 --> 00:29:08,700
And then this one you're
not using anymore.

743
00:29:08,700 --> 00:29:10,276
So we are not using the keywords,

744
00:29:10,276 --> 00:29:13,290
static keywords analysis anymore.

745
00:29:13,290 --> 00:29:16,830
Now we are gonna rely a
hundred percent on Nova Micro

746
00:29:16,830 --> 00:29:20,100
with the Before Invocation Event

747
00:29:20,100 --> 00:29:23,070
that we have just defined
and let's see if it works.

748
00:29:23,070 --> 00:29:24,150
- [Sai] And I actually like that better

749
00:29:24,150 --> 00:29:26,640
that we're using this
Before Agent Invocation

750
00:29:26,640 --> 00:29:30,000
rather than this manually
implemented callback approach.

751
00:29:30,000 --> 00:29:31,500
You know, again, I've
mentioned this before,

752
00:29:31,500 --> 00:29:33,630
but folks that built Strands,

753
00:29:33,630 --> 00:29:36,660
really figured out all of
the things you might need

754
00:29:36,660 --> 00:29:37,890
to do with an agent.

755
00:29:37,890 --> 00:29:41,940
So before the LLM invocation
do this custom bit,

756
00:29:41,940 --> 00:29:43,410
maybe after you want to do something

757
00:29:43,410 --> 00:29:45,420
to format the message in a certain way,

758
00:29:45,420 --> 00:29:47,280
these are all the kind
of things that we wanted

759
00:29:47,280 --> 00:29:48,780
to show you what's possible.

760
00:29:48,780 --> 00:29:50,730
Okay, so you're restarting the Python app.

761
00:29:50,730 --> 00:29:52,033
- I've just restart-
- No errors.

762
00:29:52,033 --> 00:29:53,700
- No errors, it's a live demo.

763
00:29:53,700 --> 00:29:55,140
As you can see, it's completely live.

764
00:29:55,140 --> 00:29:58,110
So if something breaks, it's my fault.

765
00:29:58,110 --> 00:30:00,240
Alright, so what version
of EKS am I running?

766
00:30:00,240 --> 00:30:02,700
I'm gonna send the same
query again to the model

767
00:30:02,700 --> 00:30:04,740
and hopefully if everything works,

768
00:30:04,740 --> 00:30:06,120
if we did it in the right way,

769
00:30:06,120 --> 00:30:08,640
we should be able to a
smart classification,

770
00:30:08,640 --> 00:30:10,260
then we should be able to see a response

771
00:30:10,260 --> 00:30:13,590
because EKS again was
not on the keyword list.

772
00:30:13,590 --> 00:30:14,913
So let's send it again.

773
00:30:17,430 --> 00:30:18,263
- And so before-
- Message received.

774
00:30:18,263 --> 00:30:19,590
Okay,

775
00:30:19,590 --> 00:30:22,080
Generating response,
message classification.

776
00:30:22,080 --> 00:30:22,913
There you go.

777
00:30:22,913 --> 00:30:24,300
So if you look at this,

778
00:30:24,300 --> 00:30:28,740
that's the log that I told you
and the content equals yes.

779
00:30:28,740 --> 00:30:32,250
So before we didn't reply
because EKS was not there,

780
00:30:32,250 --> 00:30:36,390
but now we are replying
because Nova decided to say yes

781
00:30:36,390 --> 00:30:38,310
because it thinks that
this query is related

782
00:30:38,310 --> 00:30:40,350
to system troubleshooting, Kubernetes,

783
00:30:40,350 --> 00:30:41,970
information and everything.

784
00:30:41,970 --> 00:30:44,430
So now, we did the classification

785
00:30:44,430 --> 00:30:48,150
and we should be able to see
a response from the agent

786
00:30:48,150 --> 00:30:50,820
that we didn't see before
because now we are doing

787
00:30:50,820 --> 00:30:52,740
that smart classification
mechanism, right?

788
00:30:52,740 --> 00:30:54,360
So as you can see here,

789
00:30:54,360 --> 00:30:56,880
before we didn't have
this smart classification,

790
00:30:56,880 --> 00:30:59,430
now we have these smart classification.

791
00:30:59,430 --> 00:31:02,850
So let me just try to
ask something random.

792
00:31:02,850 --> 00:31:03,683
- [Sai] Yeah, we should do
the negative use case, right?

793
00:31:03,683 --> 00:31:05,336
Yeah, just for-
- Hey folks,

794
00:31:05,336 --> 00:31:06,540
hopefully it works.

795
00:31:06,540 --> 00:31:11,433
Hey folks, what time we are
going to have lunch today?

796
00:31:12,960 --> 00:31:14,737
And then if we pray, there we go.

797
00:31:14,737 --> 00:31:16,120
(Sai chuckles)

798
00:31:16,120 --> 00:31:17,850
There we go, no.

799
00:31:17,850 --> 00:31:19,950
All right, so-
- And you saw how quick

800
00:31:19,950 --> 00:31:20,850
that came back too.

801
00:31:20,850 --> 00:31:22,020
Yes, it's an API call,

802
00:31:22,020 --> 00:31:25,508
but this model runs that
fast where you know,

803
00:31:25,508 --> 00:31:27,570
and if we looked at the cost of it,

804
00:31:27,570 --> 00:31:30,600
it's one token or maybe maybe
a few more for the processing,

805
00:31:30,600 --> 00:31:33,870
but essentially yeah, output token one.

806
00:31:33,870 --> 00:31:35,340
Exactly.
- Output token one.

807
00:31:35,340 --> 00:31:37,980
So I mean that's how much we're
paying for every execution.

808
00:31:37,980 --> 00:31:39,300
Again, if you don't wanna use bedrock,

809
00:31:39,300 --> 00:31:41,130
if you wanna use your
small language model,

810
00:31:41,130 --> 00:31:44,040
you can implement that same
architecture that we have done.

811
00:31:44,040 --> 00:31:46,260
And as Sai said, I think
these Strands folks,

812
00:31:46,260 --> 00:31:48,903
they have thought about
every single use case

813
00:31:48,903 --> 00:31:49,736
that we could do.

814
00:31:49,736 --> 00:31:51,900
We were doing these smart
classification in a different way

815
00:31:51,900 --> 00:31:53,407
and Sai approached me and said,

816
00:31:53,407 --> 00:31:54,420
"I think we already have that

817
00:31:54,420 --> 00:31:56,670
before the callback
handler that you can use."

818
00:31:56,670 --> 00:31:59,430
And then it was much easier
to implement actually.

819
00:31:59,430 --> 00:32:01,920
But now, before we move any forward,

820
00:32:01,920 --> 00:32:05,790
because if you look at the
summary of a recession,

821
00:32:05,790 --> 00:32:09,660
there's an important concept
that we talk about, right Sai?

822
00:32:09,660 --> 00:32:12,990
- [Sai] Yes, this is
something critical that,

823
00:32:12,990 --> 00:32:14,910
and I think this is gonna be the crux

824
00:32:14,910 --> 00:32:19,050
of what makes these agents so powerful

825
00:32:19,050 --> 00:32:21,810
and it's this concept of tribal knowledge.

826
00:32:21,810 --> 00:32:26,810
And I see this term being
coined in, of course,

827
00:32:26,970 --> 00:32:28,470
the context of tribes

828
00:32:28,470 --> 00:32:30,810
and software engineering
has been around for a while.

829
00:32:30,810 --> 00:32:32,370
I kind of credit that to Spotify

830
00:32:32,370 --> 00:32:35,130
and the Spotify model of
tribes and that kind of thing.

831
00:32:35,130 --> 00:32:38,220
But essentially it's this
idea that the knowledge

832
00:32:38,220 --> 00:32:39,660
that's in a company,

833
00:32:39,660 --> 00:32:42,270
the knowledge, it's in
the hearts and minds

834
00:32:42,270 --> 00:32:44,190
of the people that work there.

835
00:32:44,190 --> 00:32:46,290
And these people are talking over email,

836
00:32:46,290 --> 00:32:47,670
they're talking over Slack.

837
00:32:47,670 --> 00:32:50,317
And there's actually a
really interesting case here,

838
00:32:50,317 --> 00:32:52,353
an example I want to bring up,

839
00:32:53,405 --> 00:32:56,282
have you folks heard of
the Voyager one probe?

840
00:32:56,282 --> 00:33:00,420
The NASA, they sent it out in the 70s.

841
00:33:00,420 --> 00:33:02,460
I'm seeing a few folks
nodding your heads, yeah.

842
00:33:02,460 --> 00:33:05,850
Last year that Voyager probe had an issue,

843
00:33:05,850 --> 00:33:10,530
the memory chip failed and it
wasn't submitting data back

844
00:33:10,530 --> 00:33:13,800
to ground control in Houston and to solve-

845
00:33:13,800 --> 00:33:16,740
- Houston, we have a problem.
- Yeah, we absolutely do.

846
00:33:16,740 --> 00:33:18,390
And so the memory chip failed

847
00:33:18,390 --> 00:33:20,280
and to solve this problem,

848
00:33:20,280 --> 00:33:23,670
they had to bring up
documents from the 70s.

849
00:33:23,670 --> 00:33:24,990
They actually went back

850
00:33:24,990 --> 00:33:28,890
and pulled out cardboard boxes
full of old documentation.

851
00:33:28,890 --> 00:33:30,510
And here's the crazy thing.

852
00:33:30,510 --> 00:33:35,100
They pulled actual NASA
engineers out of retirement

853
00:33:35,100 --> 00:33:37,590
to consult with to solve the problem.

854
00:33:37,590 --> 00:33:39,320
And essentially with the minds

855
00:33:39,320 --> 00:33:41,820
of the people along
with the documentation,

856
00:33:41,820 --> 00:33:44,490
they were able to bypass that memory chip,

857
00:33:44,490 --> 00:33:47,790
solve the issue and get data routing back

858
00:33:47,790 --> 00:33:52,050
into their ground control
and all was good, right?

859
00:33:52,050 --> 00:33:54,145
But that's a concept that we know

860
00:33:54,145 --> 00:33:57,773
and we are all familiar with.

861
00:33:57,773 --> 00:34:00,690
Even when you have perfect documentation,

862
00:34:00,690 --> 00:34:02,580
well there really is no
such thing as perfect docs.

863
00:34:02,580 --> 00:34:05,670
But even when you have
really deep documentation

864
00:34:05,670 --> 00:34:08,384
and you have the folks that
are working there, you know,

865
00:34:08,384 --> 00:34:10,920
you really have this
concept of tribal knowledge

866
00:34:10,920 --> 00:34:15,240
that should be stored and it
should be present in the places

867
00:34:15,240 --> 00:34:17,730
that your developers
are already operating.

868
00:34:17,730 --> 00:34:19,920
And right now for a lot of our developers,

869
00:34:19,920 --> 00:34:22,740
it's Slack or Teams or
wherever you're conversing.

870
00:34:22,740 --> 00:34:24,600
And this is something that we wanted

871
00:34:24,600 --> 00:34:26,520
to build into the agent.

872
00:34:26,520 --> 00:34:29,220
Any time that an engineer talks

873
00:34:29,220 --> 00:34:31,770
about a specific design choice they made,

874
00:34:31,770 --> 00:34:33,570
or maybe a version of the image.

875
00:34:33,570 --> 00:34:36,510
- [Lucas] A tip or like
how much you should define

876
00:34:36,510 --> 00:34:38,610
for memory and CPU.

877
00:34:38,610 --> 00:34:41,793
We know that it's not
really easy to define that.

878
00:34:42,630 --> 00:34:43,463
- [Sai] Exactly.

879
00:34:43,463 --> 00:34:48,210
And the thing is you shouldn't
have your superstars, right?

880
00:34:48,210 --> 00:34:51,210
Your elite SREs constantly being bombarded

881
00:34:51,210 --> 00:34:54,180
with pings of "Hey Frank,
like what was the version of

882
00:34:54,180 --> 00:34:55,770
that image you were using?"

883
00:34:55,770 --> 00:34:59,160
And look, we want all of us
to be as efficient as possible

884
00:34:59,160 --> 00:34:59,993
in the workplace.

885
00:34:59,993 --> 00:35:03,900
And so when these conversations
do happen, let's store them.

886
00:35:03,900 --> 00:35:06,510
Let's store them in some
sort of knowledge database

887
00:35:06,510 --> 00:35:08,010
that can be accessed when

888
00:35:08,010 --> 00:35:12,720
that question inevitably comes
up three months down the line

889
00:35:12,720 --> 00:35:15,840
or in NASA's case, 50
years down the line, right?

890
00:35:15,840 --> 00:35:18,660
So we wanna store this type
of tribal knowledge somewhere

891
00:35:18,660 --> 00:35:21,390
and to do so, we're gonna
expand our architecture a bit.

892
00:35:21,390 --> 00:35:22,980
So this is what we had before.

893
00:35:22,980 --> 00:35:24,960
And to add tribal knowledge,

894
00:35:24,960 --> 00:35:27,330
we're gonna leverage an all new capability

895
00:35:27,330 --> 00:35:30,600
that we announced back
in July, S3 vectors.

896
00:35:30,600 --> 00:35:32,340
- [Lucas] So if you are thinking why they

897
00:35:32,340 --> 00:35:36,480
are using two agents layer
on top of one another,

898
00:35:36,480 --> 00:35:37,530
now you get a response

899
00:35:37,530 --> 00:35:39,180
because you're integrating
multiple agents.

900
00:35:39,180 --> 00:35:41,400
And if we have one,

901
00:35:41,400 --> 00:35:43,560
all those use cases in a single agent,

902
00:35:43,560 --> 00:35:44,880
trust me, I've tried,

903
00:35:44,880 --> 00:35:47,640
it would took much more time
to respond in the right way

904
00:35:47,640 --> 00:35:49,620
and hallucinate would
be a problem as well.

905
00:35:49,620 --> 00:35:52,050
- Yeah, up until now
that Orchestrator agent

906
00:35:52,050 --> 00:35:53,700
was just taking the message,

907
00:35:53,700 --> 00:35:54,840
figuring out if it's relevant

908
00:35:54,840 --> 00:35:56,400
and then passing it to the Specialist.

909
00:35:56,400 --> 00:36:00,690
But now we actually have kind
of a branching approach of,

910
00:36:00,690 --> 00:36:03,063
first we have to real think about,

911
00:36:04,540 --> 00:36:06,060
is it actually for troubleshooting

912
00:36:06,060 --> 00:36:08,190
or is this just a tip
that we should store away

913
00:36:08,190 --> 00:36:09,273
for later use, right?

914
00:36:09,273 --> 00:36:11,940
And the cool thing about this is,

915
00:36:11,940 --> 00:36:13,470
the longer it's implemented

916
00:36:13,470 --> 00:36:15,090
in your engineer's Slack channels

917
00:36:15,090 --> 00:36:18,510
and wherever this agent is
listening, the smarter it gets.

918
00:36:18,510 --> 00:36:22,151
It's storing these
solutions for future use.

919
00:36:22,151 --> 00:36:26,280
Essentially anytime there's
some information being shared

920
00:36:26,280 --> 00:36:27,360
in Slack,

921
00:36:27,360 --> 00:36:30,480
automatically take it
and stored in Vectors

922
00:36:30,480 --> 00:36:32,370
for a future recall.

923
00:36:32,370 --> 00:36:33,990
Oh, and by the way, Vectors, again,

924
00:36:33,990 --> 00:36:35,760
we talked about this quickly before,

925
00:36:35,760 --> 00:36:39,840
but it's a type of database
that works nicely with LLMs.

926
00:36:39,840 --> 00:36:43,530
Of course LLMs don't
think in terms of tokens,

927
00:36:43,530 --> 00:36:46,350
they work with embeddings
and number matrices

928
00:36:46,350 --> 00:36:47,460
and transformers.

929
00:36:47,460 --> 00:36:50,340
And so vectors are very efficient way

930
00:36:50,340 --> 00:36:52,679
of storing human readable text, right?

931
00:36:52,679 --> 00:36:55,020
So you take a bunch of
human readable texts,

932
00:36:55,020 --> 00:36:56,790
you encode it into embeddings

933
00:36:56,790 --> 00:37:00,180
and then when the LLM needs to
scan through that data later,

934
00:37:00,180 --> 00:37:03,240
it's a lot faster to go
through a vector database.

935
00:37:03,240 --> 00:37:05,100
But then it's able to
kind of reverse engineer

936
00:37:05,100 --> 00:37:06,930
that back into human readable text

937
00:37:06,930 --> 00:37:08,970
and give it back to the end user.

938
00:37:08,970 --> 00:37:11,820
So this is how we're gonna
expand the architecture

939
00:37:11,820 --> 00:37:13,654
and let me pass it back to you Lucas to-

940
00:37:13,654 --> 00:37:15,960
- [Lucas] And one thing
that I just wanna add

941
00:37:15,960 --> 00:37:17,430
on what was said, Sai,

942
00:37:17,430 --> 00:37:21,090
it's not either an agent or either an MCP,

943
00:37:21,090 --> 00:37:22,737
it's more a combination of different tools

944
00:37:22,737 --> 00:37:25,590
and capabilities to empower
the agent that you can use.

945
00:37:25,590 --> 00:37:28,860
So, we're using MCP for
the live data, right?

946
00:37:28,860 --> 00:37:30,930
So the data that we need in that time

947
00:37:30,930 --> 00:37:33,090
that is happening right now in my cluster,

948
00:37:33,090 --> 00:37:34,290
then we use MCP to do it.

949
00:37:34,290 --> 00:37:37,260
But maybe some tips run
books and everything,

950
00:37:37,260 --> 00:37:38,940
we can still rely on RAG.

951
00:37:38,940 --> 00:37:40,440
We don't need to use MCP for that.

952
00:37:40,440 --> 00:37:43,050
We could, but in this case we're using RAG

953
00:37:43,050 --> 00:37:44,370
on top of another agent.

954
00:37:44,370 --> 00:37:45,840
So it's a combination of everything.

955
00:37:45,840 --> 00:37:48,150
It's not like if I use MCP or agents,

956
00:37:48,150 --> 00:37:49,440
I'm not gonna use RAG anymore.

957
00:37:49,440 --> 00:37:51,687
I think it's what is
best for your use case.

958
00:37:51,687 --> 00:37:53,820
And every other essay probably would say,

959
00:37:53,820 --> 00:37:56,190
it depends on the use case.

960
00:37:56,190 --> 00:37:57,023
Yeah.

961
00:37:57,023 --> 00:37:59,430
So let's try to implement
the memory agent right now.

962
00:37:59,430 --> 00:38:01,080
Hopefully it's gonna work.

963
00:38:01,080 --> 00:38:02,670
So the first thing, yeah,

964
00:38:02,670 --> 00:38:05,700
the first thing that we're
gonna do is actually,

965
00:38:05,700 --> 00:38:08,910
Sai told us that we're
using another agent.

966
00:38:08,910 --> 00:38:12,810
So we created that memory
agent to be a standalone agent

967
00:38:12,810 --> 00:38:15,690
because other agents could rely

968
00:38:15,690 --> 00:38:17,130
on that memory agent as well.

969
00:38:17,130 --> 00:38:19,650
So I've created a Kubernetes
Troubleshooting chat bot,

970
00:38:19,650 --> 00:38:21,780
maybe, Sai's creating a database analytics

971
00:38:21,780 --> 00:38:23,130
troubleshooting chat bot.

972
00:38:23,130 --> 00:38:26,070
But we're saving and storing
the information maybe

973
00:38:26,070 --> 00:38:28,740
in the same place and we
can reuse those run books

974
00:38:28,740 --> 00:38:29,940
across multiple agents.

975
00:38:29,940 --> 00:38:32,250
So the agent that we're
gonna be building now

976
00:38:32,250 --> 00:38:35,220
has a server embedded
that's powered by Strands

977
00:38:35,220 --> 00:38:38,190
and then we're gonna
integrate that agent server

978
00:38:38,190 --> 00:38:40,470
with our current structure that we have,

979
00:38:40,470 --> 00:38:43,830
Orchestrator plus Specialist using a2a.

980
00:38:43,830 --> 00:38:44,970
And for those who don't know,

981
00:38:44,970 --> 00:38:48,930
a2a is just a way to communicate
with different agents.

982
00:38:48,930 --> 00:38:51,210
Json over HTP, essentially,

983
00:38:51,210 --> 00:38:54,780
it's nothing more than that.
- Agent to Agent.

984
00:38:54,780 --> 00:38:56,190
- [Lucas] Agent to agent. That's it.

985
00:38:56,190 --> 00:38:58,290
Really easy to understand.
- So, Lucas, I gotta say man,

986
00:38:58,290 --> 00:38:59,370
as you're going through that,

987
00:38:59,370 --> 00:39:02,853
it sounds a whole lot
like the 12 factor app

988
00:39:02,853 --> 00:39:05,790
microservices spiel that we heard,

989
00:39:05,790 --> 00:39:07,680
what like 12, 13 years ago now,

990
00:39:07,680 --> 00:39:10,500
in the early 2010s of
why we break monoliths

991
00:39:10,500 --> 00:39:12,720
into microservices, it's really the same.

992
00:39:12,720 --> 00:39:14,472
It's kind of this revolution,

993
00:39:14,472 --> 00:39:16,860
it's this cycle of of programming

994
00:39:16,860 --> 00:39:20,250
and it's the same reason why
we're breaking our agents apart

995
00:39:20,250 --> 00:39:21,090
because look,

996
00:39:21,090 --> 00:39:23,267
the memory agent has its own purpose

997
00:39:23,267 --> 00:39:27,120
that might be used outside of
the context of the Slack bot.

998
00:39:27,120 --> 00:39:28,147
- [Lucas] Just like a microservice, right?

999
00:39:28,147 --> 00:39:29,490
What is a microservice?

1000
00:39:29,490 --> 00:39:32,400
Something that should do that
use case in a very good way.

1001
00:39:32,400 --> 00:39:35,610
And then if you want to add
other use cases on top of that,

1002
00:39:35,610 --> 00:39:36,870
then maybe we need to start

1003
00:39:36,870 --> 00:39:38,760
to think about creating
a different microservice.

1004
00:39:38,760 --> 00:39:41,880
So for the agent is
exactly the same thing.

1005
00:39:41,880 --> 00:39:43,950
The agent should have a purpose.

1006
00:39:43,950 --> 00:39:47,340
We tried to have everything
in a single agent.

1007
00:39:47,340 --> 00:39:49,530
The response was really, really awful.

1008
00:39:49,530 --> 00:39:51,090
Once we break it down

1009
00:39:51,090 --> 00:39:53,509
and then we used the
agent as tools pattern

1010
00:39:53,509 --> 00:39:55,470
with the Orchestrator agent,

1011
00:39:55,470 --> 00:39:58,770
we got a much better response
and performance on top

1012
00:39:58,770 --> 00:40:00,810
of the agents that we're developing.

1013
00:40:00,810 --> 00:40:03,840
So specialist agents,
that's what I wanna say.

1014
00:40:03,840 --> 00:40:05,910
So I just have pasted the code right here.

1015
00:40:05,910 --> 00:40:08,700
I'm gonna go over the
code that we are building,

1016
00:40:08,700 --> 00:40:10,650
again, it's yet another agent.

1017
00:40:10,650 --> 00:40:14,850
So it's just more of that other
code that we have running.

1018
00:40:14,850 --> 00:40:16,560
So we have the construction method,

1019
00:40:16,560 --> 00:40:18,270
we're declaring some variables,

1020
00:40:18,270 --> 00:40:22,410
just we are initializing boto3
clients to talk to our S3

1021
00:40:22,410 --> 00:40:23,610
as vector database.

1022
00:40:23,610 --> 00:40:26,340
And then we are defining a system prompt.

1023
00:40:26,340 --> 00:40:28,830
So essentially the system prompt

1024
00:40:28,830 --> 00:40:30,900
is what you are giving to the agent.

1025
00:40:30,900 --> 00:40:32,640
You should behave like that.

1026
00:40:32,640 --> 00:40:34,560
You are an agent that behaves like that.

1027
00:40:34,560 --> 00:40:37,890
So you are a Kubernetes
troubleshooting memory specialist

1028
00:40:37,890 --> 00:40:40,740
and then your role is store solutions

1029
00:40:40,740 --> 00:40:42,810
and retrieve solutions.

1030
00:40:42,810 --> 00:40:45,795
After that, it's all
like some fixes and send,

1031
00:40:45,795 --> 00:40:47,910
don't use mark down and everything.

1032
00:40:47,910 --> 00:40:52,260
But two main tools that we
have is the store and retrieve

1033
00:40:52,260 --> 00:40:55,410
and then using Strands, again,
we are defining the agent,

1034
00:40:55,410 --> 00:40:57,420
we are defining the model
that we want to use.

1035
00:40:57,420 --> 00:40:59,880
- [Sai] Lucas, I just wanna
point one quick thing out,

1036
00:40:59,880 --> 00:41:00,840
you look at number three

1037
00:41:00,840 --> 00:41:02,317
and some of you might be thinking,

1038
00:41:02,317 --> 00:41:04,260
"Only do what you do and nothing more."

1039
00:41:04,260 --> 00:41:06,090
It's very direct.

1040
00:41:06,090 --> 00:41:08,100
You might even consider it to be rude.

1041
00:41:08,100 --> 00:41:13,020
But we've seen official
research papers released on,

1042
00:41:13,020 --> 00:41:15,480
when you start using words like please

1043
00:41:15,480 --> 00:41:18,000
or asking nicely for agents,

1044
00:41:18,000 --> 00:41:20,640
they actually do end up
hallucinating more often

1045
00:41:20,640 --> 00:41:22,590
and not retrieving solutions

1046
00:41:22,590 --> 00:41:24,168
and responding the right way, so.

1047
00:41:24,168 --> 00:41:26,400
- [Lucas] And if you say please
you're gonna pay even more

1048
00:41:26,400 --> 00:41:28,260
for the tokens that we're
saying to the model, so.

1049
00:41:28,260 --> 00:41:29,093
- [Sai] Exactly.

1050
00:41:29,093 --> 00:41:31,402
So you do want to be very
direct with these models

1051
00:41:31,402 --> 00:41:33,300
and they behave better

1052
00:41:33,300 --> 00:41:36,300
when you give them
those tight bound lines.

1053
00:41:36,300 --> 00:41:37,800
- [Lucas] Try to imagine
that is a co-worker

1054
00:41:37,800 --> 00:41:40,375
that you don't like and be very bold.

1055
00:41:40,375 --> 00:41:41,825
Don't do that, don't do that.

1056
00:41:42,660 --> 00:41:46,350
Alright, so the agent
bedrock model ID, two tools,

1057
00:41:46,350 --> 00:41:48,360
I'm not gonna go over all those tools

1058
00:41:48,360 --> 00:41:50,490
but essentially, it's two tools only,

1059
00:41:50,490 --> 00:41:51,660
but I'm not gonna go over the code

1060
00:41:51,660 --> 00:41:52,920
because I don't have a lot of time.

1061
00:41:52,920 --> 00:41:55,410
So one tool is to store a solution.

1062
00:41:55,410 --> 00:41:56,400
What it does?

1063
00:41:56,400 --> 00:41:58,530
Store solutions in S3 vector database.

1064
00:41:58,530 --> 00:42:00,840
And the other tool is
to retrieve a solution

1065
00:42:00,840 --> 00:42:03,300
from Vector database based on a query-

1066
00:42:03,300 --> 00:42:04,260
- Lucas, a question.
- What?

1067
00:42:04,260 --> 00:42:07,260
- [Sai] We have to do the
conversion into embeddings

1068
00:42:07,260 --> 00:42:08,760
or does S3 do that for us?

1069
00:42:08,760 --> 00:42:10,540
How does that work?
- I was about to say that.

1070
00:42:10,540 --> 00:42:13,500
So S3 will not embed the data for you,

1071
00:42:13,500 --> 00:42:15,210
you're gonna need to embed the data.

1072
00:42:15,210 --> 00:42:18,120
So essentially embedding
is just make the data

1073
00:42:18,120 --> 00:42:20,070
in a way that the model can understand

1074
00:42:20,070 --> 00:42:22,410
and interpret that data
to respond back to you.

1075
00:42:22,410 --> 00:42:25,590
So for S3 vectors, it's
just a vector database.

1076
00:42:25,590 --> 00:42:27,030
We still need to do the embedding.

1077
00:42:27,030 --> 00:42:29,675
So in this case we're using Amazon Titan

1078
00:42:29,675 --> 00:42:31,920
on top of bedrock to do the embeddings.

1079
00:42:31,920 --> 00:42:33,870
And once we embed,

1080
00:42:33,870 --> 00:42:37,290
we cannot deem embed the
embedding data, right?

1081
00:42:37,290 --> 00:42:40,740
So what we need to do is
we need to embed the query

1082
00:42:40,740 --> 00:42:43,170
that we're using to retrieve.

1083
00:42:43,170 --> 00:42:45,090
So in this case the store,

1084
00:42:45,090 --> 00:42:46,380
let's go to retrieve,

1085
00:42:46,380 --> 00:42:49,920
we need to embed the data
that we're using to retrieve,

1086
00:42:49,920 --> 00:42:50,820
there we go.

1087
00:42:50,820 --> 00:42:52,350
And then once we embed the data

1088
00:42:52,350 --> 00:42:53,670
that we're using to retrieve,

1089
00:42:53,670 --> 00:42:55,650
we can search for the embeddings

1090
00:42:55,650 --> 00:42:58,170
because we cannot deem
embed the embedded query.

1091
00:42:58,170 --> 00:43:00,420
So we need to embed using the same model.

1092
00:43:00,420 --> 00:43:01,610
And because we're using the same model,

1093
00:43:01,610 --> 00:43:03,840
we can use that chunk of data to search

1094
00:43:03,840 --> 00:43:05,837
for similarities in our vector database.

1095
00:43:05,837 --> 00:43:06,990
- [Sai] That's exactly right.

1096
00:43:06,990 --> 00:43:09,480
And essentially, we talked about earlier,

1097
00:43:09,480 --> 00:43:12,660
you don't wanna store the
actual human readable text

1098
00:43:12,660 --> 00:43:15,360
'cause it takes a lot
longer to scan through it

1099
00:43:15,360 --> 00:43:16,620
and find relevant data.

1100
00:43:16,620 --> 00:43:18,540
It's just faster when you're embedding

1101
00:43:18,540 --> 00:43:21,240
and Lucas, how many LLMs
are we up to at this point?

1102
00:43:21,240 --> 00:43:23,460
Is that our fourth or I think
that might be the fifth.

1103
00:43:23,460 --> 00:43:26,700
We're using Sonnet.
We're using Nova Micro.

1104
00:43:26,700 --> 00:43:28,780
We used a different version of Sonnet for-

1105
00:43:28,780 --> 00:43:29,781
- [Lucas] Titan for embedding.

1106
00:43:29,781 --> 00:43:32,040
So far four different models.

1107
00:43:32,040 --> 00:43:33,420
- [Sai] Exactly and look,

1108
00:43:33,420 --> 00:43:35,370
like this is how LLMs
are meant to be used.

1109
00:43:35,370 --> 00:43:37,410
You pick the right one for the tool

1110
00:43:37,410 --> 00:43:39,453
and it's more efficient.
- In every agent

1111
00:43:39,453 --> 00:43:42,540
that we had there could
also use a different model.

1112
00:43:42,540 --> 00:43:44,400
We're just using the same
model for the purpose of,

1113
00:43:44,400 --> 00:43:46,920
I just want to export one
single environment variable.

1114
00:43:46,920 --> 00:43:49,080
But we could use different models

1115
00:43:49,080 --> 00:43:51,030
for different agents
with different purposes.

1116
00:43:51,030 --> 00:43:51,863
So for instance,

1117
00:43:51,863 --> 00:43:55,440
Claude Haiku is much faster
than Cloud Sonnet 3.7.

1118
00:43:55,440 --> 00:43:58,620
But it's not as smart
as Claude Sonnet 3.7.

1119
00:43:58,620 --> 00:44:00,060
So we need to do those balances

1120
00:44:00,060 --> 00:44:02,880
and try to pick the best
one for our use case.

1121
00:44:02,880 --> 00:44:04,830
But in this case we
have the memory server.

1122
00:44:04,830 --> 00:44:06,960
Again, we have two tools,

1123
00:44:06,960 --> 00:44:10,200
one, store and the other one, retrieve.

1124
00:44:10,200 --> 00:44:11,580
And now what we're gonna do

1125
00:44:11,580 --> 00:44:13,650
is we're gonna launch an agent server.

1126
00:44:13,650 --> 00:44:15,060
But before we do that,

1127
00:44:15,060 --> 00:44:17,610
I'm gonna actually try to
use those tools manually.

1128
00:44:17,610 --> 00:44:20,250
So what we're gonna do is
I'm gonna get the variable

1129
00:44:20,250 --> 00:44:21,840
that I have here from a class,

1130
00:44:21,840 --> 00:44:25,083
I'm gonna call agent and I'm
gonna say something like-

1131
00:44:26,190 --> 00:44:29,190
- [Sai] So this just invokes
the agent as if, you know,

1132
00:44:29,190 --> 00:44:31,200
if imagine the Orchestrator agent

1133
00:44:31,200 --> 00:44:32,970
was talking to the memory agent,

1134
00:44:32,970 --> 00:44:35,640
we're just simulating that
for the sake of testing.

1135
00:44:35,640 --> 00:44:39,540
And so we're calling the
agent directly and yeah, okay,

1136
00:44:39,540 --> 00:44:41,640
so we're doing a real example.

1137
00:44:41,640 --> 00:44:46,640
So Lucas is copying over at
a real model recommendation

1138
00:44:46,770 --> 00:44:49,230
that we have for the node exporter image.

1139
00:44:49,230 --> 00:44:50,310
- [Lucas] So what I'm saying

1140
00:44:50,310 --> 00:44:55,310
is anyone deploying monitoring
agent should use this image.

1141
00:44:57,690 --> 00:44:59,820
If you watched the hook
of our presentation,

1142
00:44:59,820 --> 00:45:01,140
you probably know where we are going

1143
00:45:01,140 --> 00:45:02,100
with that information, right?

1144
00:45:02,100 --> 00:45:03,600
So what we are doing now

1145
00:45:03,600 --> 00:45:05,400
is we're triggering it manually first.

1146
00:45:05,400 --> 00:45:07,640
So hopefully this query right here

1147
00:45:07,640 --> 00:45:09,330
is gonna trigger the store

1148
00:45:09,330 --> 00:45:11,673
and then we want to create another query,

1149
00:45:12,690 --> 00:45:14,663
another agent invocation
to retrieve the solution.

1150
00:45:14,663 --> 00:45:16,230
So what I'm gonna say here

1151
00:45:16,230 --> 00:45:21,230
is what node exporter image should I use?

1152
00:45:21,237 --> 00:45:22,620
- [Sai] And these runs synchronously?

1153
00:45:22,620 --> 00:45:23,670
So one after the other.

1154
00:45:23,670 --> 00:45:24,690
- That's it.
- It'll give it time

1155
00:45:24,690 --> 00:45:26,370
to store the solution.
- Yeah.

1156
00:45:26,370 --> 00:45:27,933
So essentially the first one,

1157
00:45:28,835 --> 00:45:30,540
we are not telling which tool to use

1158
00:45:30,540 --> 00:45:32,180
but because we are using an agent,

1159
00:45:32,180 --> 00:45:33,996
it should use the store

1160
00:45:33,996 --> 00:45:36,360
and the other one should use the retrieve.

1161
00:45:36,360 --> 00:45:40,080
So what we're gonna do now
is I'm gonna go to the folder

1162
00:45:40,080 --> 00:45:42,780
where we have that agent created.

1163
00:45:42,780 --> 00:45:46,413
There you go. So we have
the memory agent server.

1164
00:45:47,590 --> 00:45:49,200
- [Sai] And you can already
notice the difference here.

1165
00:45:49,200 --> 00:45:52,200
Before we were just restarting
that one Python application,

1166
00:45:52,200 --> 00:45:55,650
which had the Orchestrator
and the the Specialist agent.

1167
00:45:55,650 --> 00:45:58,890
Now we have a separate memory
agent that lives separately.

1168
00:45:58,890 --> 00:46:01,800
So it is its own microservice.

1169
00:46:01,800 --> 00:46:03,207
Lucas, you came up with
a word for this earlier.

1170
00:46:03,207 --> 00:46:05,430
- Micro agent?
- Micro agent.

1171
00:46:05,430 --> 00:46:06,720
You heard it here first folks.

1172
00:46:06,720 --> 00:46:08,520
And so look by the way,

1173
00:46:08,520 --> 00:46:10,710
we do give you helm charts
to deploy all of this

1174
00:46:10,710 --> 00:46:11,820
and all the sample code as well.

1175
00:46:11,820 --> 00:46:13,110
We'll share with you at the end.

1176
00:46:13,110 --> 00:46:15,030
So you could deploy this
in a Kubernetes cluster.

1177
00:46:15,030 --> 00:46:16,860
So you're not doing it manually locally,

1178
00:46:16,860 --> 00:46:18,630
I think it's just for
the sake of the demo,

1179
00:46:18,630 --> 00:46:19,463
we're doing-
- Yeah,

1180
00:46:19,463 --> 00:46:21,210
we are doing it locally because
it's a live code session

1181
00:46:21,210 --> 00:46:23,580
but it's all abstracted into helm chart.

1182
00:46:23,580 --> 00:46:24,660
So if you just wanna take the shot

1183
00:46:24,660 --> 00:46:26,370
and deploy this architecture, you can,

1184
00:46:26,370 --> 00:46:28,470
we're gonna give access to the sample code

1185
00:46:28,470 --> 00:46:29,520
for you at the end.

1186
00:46:29,520 --> 00:46:32,340
But going back to what we are
doing, let's try to see Sai,

1187
00:46:32,340 --> 00:46:33,870
if the tools are gonna be able

1188
00:46:33,870 --> 00:46:35,970
to be executed in the right way.

1189
00:46:35,970 --> 00:46:37,286
So we are hoping to get store

1190
00:46:37,286 --> 00:46:39,960
and then retrieve the node exporter chip.

1191
00:46:39,960 --> 00:46:41,880
So I just triggered the memory agent.

1192
00:46:41,880 --> 00:46:42,900
- [Sai] And you commented that out

1193
00:46:42,900 --> 00:46:44,490
so that the server isn't starting.

1194
00:46:44,490 --> 00:46:45,323
- [Lucas] No.

1195
00:46:45,323 --> 00:46:47,220
- [Sai] We're just calling
the agent synchronously,

1196
00:46:47,220 --> 00:46:48,180
just to test.
- Yeah,

1197
00:46:48,180 --> 00:46:51,330
so the first two store
solution, key information,

1198
00:46:51,330 --> 00:46:54,180
problem team, uses
inconsistent corrected image.

1199
00:46:54,180 --> 00:46:55,997
That's the image that you should use.

1200
00:46:55,997 --> 00:46:58,500
And then for the second tool

1201
00:46:58,500 --> 00:47:00,227
to retrieve the information, there you go.

1202
00:47:00,227 --> 00:47:03,060
So the DevOps recommendation is that one,

1203
00:47:03,060 --> 00:47:05,070
that is the one that
we added into the code.

1204
00:47:05,070 --> 00:47:09,120
So now we have that information,
our S3 vector database.

1205
00:47:09,120 --> 00:47:12,750
So what I'm gonna do now is
I'm gonna go to a dashboard

1206
00:47:12,750 --> 00:47:16,320
that of course was
completely generated by AI

1207
00:47:16,320 --> 00:47:18,570
and then I'm gonna refresh it

1208
00:47:18,570 --> 00:47:21,660
and then we should be able
to see another solution

1209
00:47:21,660 --> 00:47:23,220
that dashboard is just seeing,

1210
00:47:23,220 --> 00:47:24,780
it's just requiring S3

1211
00:47:24,780 --> 00:47:27,180
to check the solutions
we have available on S3.

1212
00:47:27,180 --> 00:47:28,680
But as you can see,

1213
00:47:28,680 --> 00:47:32,400
we have a total of one solution
in that particular bucket.

1214
00:47:32,400 --> 00:47:35,463
If I search here for NodeExporter,

1215
00:47:36,570 --> 00:47:38,730
we should be able to see the solution

1216
00:47:38,730 --> 00:47:39,840
that we just persisted.

1217
00:47:39,840 --> 00:47:42,000
So Teams is inconsistent
or incorrect image

1218
00:47:42,000 --> 00:47:44,610
for Node Exporter in Kubernetes
monitoring deployments.

1219
00:47:44,610 --> 00:47:46,290
That's the image that you should use.

1220
00:47:46,290 --> 00:47:48,870
So we have that in the
vector database right now

1221
00:47:48,870 --> 00:47:51,960
because we tested
locally our memory agent.

1222
00:47:51,960 --> 00:47:52,920
So what we're gonna do now

1223
00:47:52,920 --> 00:47:55,579
is we're gonna remove
those local executions

1224
00:47:55,579 --> 00:48:00,240
that we have just done and
then we're gonna now, yes,

1225
00:48:00,240 --> 00:48:03,480
start the a2a server.

1226
00:48:03,480 --> 00:48:06,870
So if you look at here
we have the a2a server

1227
00:48:06,870 --> 00:48:07,860
that is essentially a library

1228
00:48:07,860 --> 00:48:11,463
that we have imported from
Strand multi-agent capabilities.

1229
00:48:12,480 --> 00:48:15,570
We're passing the agent that
we wanna run as a server

1230
00:48:15,570 --> 00:48:16,710
and then we do a serve.

1231
00:48:16,710 --> 00:48:20,220
Behind the scenes, it's gonna
start a uvicorn process.

1232
00:48:20,220 --> 00:48:23,280
So if you do python
memory agent server.py,

1233
00:48:23,280 --> 00:48:27,090
now we have agent running as a server.

1234
00:48:27,090 --> 00:48:28,200
So if it's running as a server,

1235
00:48:28,200 --> 00:48:29,610
you can expose to a load balancer

1236
00:48:29,610 --> 00:48:33,030
and now you can use that
agent with your other agent.

1237
00:48:33,030 --> 00:48:34,110
So you don't need to replicate

1238
00:48:34,110 --> 00:48:36,390
that memory agent code
again and again and again.

1239
00:48:36,390 --> 00:48:39,420
So that's it for now for
the memory agent server.

1240
00:48:39,420 --> 00:48:42,960
Now what we're gonna do is we need

1241
00:48:42,960 --> 00:48:45,806
to make the Orchestrator agent communicate

1242
00:48:45,806 --> 00:48:48,720
to the memory agent server, right?

1243
00:48:48,720 --> 00:48:51,180
And for that we're using a2a.

1244
00:48:51,180 --> 00:48:53,820
So what we're gonna do now
is we're gonna implement

1245
00:48:53,820 --> 00:48:58,020
that a2a communication on top
of our agent Orchestrator.

1246
00:48:58,020 --> 00:49:00,840
And remember for the agent Orchestrator,

1247
00:49:00,840 --> 00:49:04,170
we are running the agent S2's patterns.

1248
00:49:04,170 --> 00:49:06,000
So we have an Orchestrator agent

1249
00:49:06,000 --> 00:49:09,060
that is calling other agent S2s.

1250
00:49:09,060 --> 00:49:10,290
So if you can see here,

1251
00:49:10,290 --> 00:49:12,510
we have just the
troubleshooting Kubernetes tools

1252
00:49:12,510 --> 00:49:15,390
that will trigger the
Kubernetes specialist agent.

1253
00:49:15,390 --> 00:49:16,470
What we're gonna do now

1254
00:49:16,470 --> 00:49:21,470
is we're gonna create the memory
agent two that we will talk

1255
00:49:21,780 --> 00:49:24,960
to the other agent running
its own server using a2a.

1256
00:49:24,960 --> 00:49:27,600
So the first thing that
we need to do is we need

1257
00:49:27,600 --> 00:49:29,640
to import the library that we want.

1258
00:49:29,640 --> 00:49:31,710
So a2a client tool provider.

1259
00:49:31,710 --> 00:49:35,880
And this way we are able to
use the other agent tools

1260
00:49:35,880 --> 00:49:38,490
in our own agent without
replicating those tools

1261
00:49:38,490 --> 00:49:39,870
in our code.

1262
00:49:39,870 --> 00:49:41,730
So this is the first
thing that we need to do.

1263
00:49:41,730 --> 00:49:43,110
Now another thing that we need

1264
00:49:43,110 --> 00:49:45,210
to do is actually create a tool,

1265
00:49:45,210 --> 00:49:48,690
since we're using the agent
S2s pattern from Strands,

1266
00:49:48,690 --> 00:49:51,780
we need to also create a tool
to talk to our memory agent.

1267
00:49:51,780 --> 00:49:53,610
So I'm gonna copy and paste the method

1268
00:49:53,610 --> 00:49:55,770
that we have created here.

1269
00:49:55,770 --> 00:49:57,479
And as you can see, I
have a decorator here.

1270
00:49:57,479 --> 00:50:00,270
So this is particular for Strands.

1271
00:50:00,270 --> 00:50:02,280
If you have the decorator
on top of the method,

1272
00:50:02,280 --> 00:50:04,830
you can use that method
S2s in your agent, right?

1273
00:50:04,830 --> 00:50:07,470
So that's the way that the method is able

1274
00:50:07,470 --> 00:50:09,030
to be identified as a tool.

1275
00:50:09,030 --> 00:50:11,850
But most important thing,
a2a client tool provider,

1276
00:50:11,850 --> 00:50:13,230
that comes from Strand.

1277
00:50:13,230 --> 00:50:16,410
And then I'm passing the memory agent URL,

1278
00:50:16,410 --> 00:50:18,750
if you can see here, port 9,000,

1279
00:50:18,750 --> 00:50:21,150
that's exactly the same
port that we have here

1280
00:50:21,150 --> 00:50:23,070
for the memory agent running as a server.

1281
00:50:23,070 --> 00:50:25,230
So we already have
configured that variable.

1282
00:50:25,230 --> 00:50:30,230
And then what I'm doing is,
I'm creating that agent here.

1283
00:50:30,330 --> 00:50:34,320
And this agent is just an interface.

1284
00:50:34,320 --> 00:50:36,450
So we are using this agent

1285
00:50:36,450 --> 00:50:41,070
to discover other agents
available in our environment.

1286
00:50:41,070 --> 00:50:43,650
In this case, we just
gave one single agent.

1287
00:50:43,650 --> 00:50:45,510
But if you look at here,

1288
00:50:45,510 --> 00:50:48,870
we have a list, we could pass
multiple different agents

1289
00:50:48,870 --> 00:50:52,260
and our agent would figure out
which agent it should call.

1290
00:50:52,260 --> 00:50:53,934
How many times I said agent right now?

1291
00:50:53,934 --> 00:50:55,710
(Sai chuckles)
Like 70 times.

1292
00:50:55,710 --> 00:50:57,300
- [Sai] I'm gonna say it
a couple more times too

1293
00:50:57,300 --> 00:50:59,040
'cause I think it might
be worth really quickly.

1294
00:50:59,040 --> 00:51:01,060
I'm gonna switch here to the
Strands agent architecture.

1295
00:51:01,060 --> 00:51:02,220
- Okay.
- Just to show you

1296
00:51:02,220 --> 00:51:03,060
what we did, right?

1297
00:51:03,060 --> 00:51:05,130
So we have that Orchestrator agent,

1298
00:51:05,130 --> 00:51:07,200
that's that big box over here

1299
00:51:07,200 --> 00:51:08,640
and it kind of is able

1300
00:51:08,640 --> 00:51:11,700
to discover all the other
tools it's able to work with.

1301
00:51:11,700 --> 00:51:14,760
So this external tool slash AWS,

1302
00:51:14,760 --> 00:51:18,240
that in itself can be additional agents.

1303
00:51:18,240 --> 00:51:21,570
That in itself is the kind
of swarm we're building here.

1304
00:51:21,570 --> 00:51:23,340
Strands likes to call it swarms,

1305
00:51:23,340 --> 00:51:25,290
but essentially it's all
of these different agents

1306
00:51:25,290 --> 00:51:28,620
that are discovering each
other and only talking to them

1307
00:51:28,620 --> 00:51:30,570
when they realize you need it.

1308
00:51:30,570 --> 00:51:32,610
And so I think that's really the idea here

1309
00:51:32,610 --> 00:51:34,527
is you can have all of
these different tools,

1310
00:51:34,527 --> 00:51:37,861
the MCP server that we
deployed, this memory agent,

1311
00:51:37,861 --> 00:51:41,220
and then we have this actual
Kubernetes Specialist agent.

1312
00:51:41,220 --> 00:51:42,870
And realistically,

1313
00:51:42,870 --> 00:51:47,010
it's hard for us to even
code like an if-else chain

1314
00:51:47,010 --> 00:51:49,680
of when which one should
talk to the other.

1315
00:51:49,680 --> 00:51:52,800
So we offload that
responsibility in itself

1316
00:51:52,800 --> 00:51:54,718
to an agent call.
- Shift to left,

1317
00:51:54,718 --> 00:51:57,270
remove from if-elses
and send to the agent.

1318
00:51:57,270 --> 00:51:58,440
- [Sai] Exactly. Exactly.

1319
00:51:58,440 --> 00:51:59,370
You got it. All right.

1320
00:51:59,370 --> 00:52:01,890
So let's get back to it
and see how you did it.

1321
00:52:01,890 --> 00:52:04,530
- [Lucas] Alright, so that's
the memory agent provider.

1322
00:52:04,530 --> 00:52:07,050
That's my tool that's gonna
talk to our agent server.

1323
00:52:07,050 --> 00:52:11,373
Last thing that we need to
do is we need to add that to-

1324
00:52:13,584 --> 00:52:14,417
To our-

1325
00:52:14,417 --> 00:52:15,250
- [Sai] You were saying earlier,

1326
00:52:15,250 --> 00:52:18,450
it's the agent S2, kind of paradigm.

1327
00:52:18,450 --> 00:52:19,770
That's essentially what we did.

1328
00:52:19,770 --> 00:52:22,290
We took an agent and we threw
it in there as another tool,

1329
00:52:22,290 --> 00:52:25,530
just like we did with MCP
and the troubleshooting step.

1330
00:52:25,530 --> 00:52:27,210
We just threw it in there.
- Yeah.

1331
00:52:27,210 --> 00:52:32,210
So if you look at Strands,
that's actually a pattern.

1332
00:52:32,460 --> 00:52:34,890
Agent S2, that's the pattern
that we are following.

1333
00:52:34,890 --> 00:52:37,500
And then we are adding a2a
on top of that as well.

1334
00:52:37,500 --> 00:52:39,390
So that's essentially what we are doing.

1335
00:52:39,390 --> 00:52:41,250
We have an orchestrator
agent that is responsible

1336
00:52:41,250 --> 00:52:44,070
to route requests to
other specialized agents.

1337
00:52:44,070 --> 00:52:45,870
So now let's go back,

1338
00:52:45,870 --> 00:52:50,400
I have added already the
memory agent provider here

1339
00:52:50,400 --> 00:52:51,570
as a tool.

1340
00:52:51,570 --> 00:52:54,240
So the last thing that
we need to do is we need

1341
00:52:54,240 --> 00:52:56,430
to change the system prompt.

1342
00:52:56,430 --> 00:52:58,680
So let's go to the
Orchestrator system prompt.

1343
00:52:58,680 --> 00:53:01,140
And then if you look at the system prompt,

1344
00:53:01,140 --> 00:53:04,320
we're not saying anything about memory

1345
00:53:04,320 --> 00:53:05,820
or vectors or whatever.

1346
00:53:05,820 --> 00:53:07,163
We're just saying like we have access

1347
00:53:07,163 --> 00:53:10,080
to that Kubernetes Specialist
agent to troubleshoot.

1348
00:53:10,080 --> 00:53:11,970
That's the one you have. Go for it.

1349
00:53:11,970 --> 00:53:13,890
Now what we are doing
is we're gonna replace

1350
00:53:13,890 --> 00:53:15,510
that Orchestrator assistant prompt

1351
00:53:15,510 --> 00:53:19,950
with something more
aligned to the memory agent

1352
00:53:19,950 --> 00:53:21,150
that we have created.

1353
00:53:21,150 --> 00:53:23,460
And for every agent we
have assistant prompt.

1354
00:53:23,460 --> 00:53:24,997
So in this case I'm saying,

1355
00:53:24,997 --> 00:53:27,840
"Hey, always check memory first

1356
00:53:27,840 --> 00:53:29,670
before doing any troubleshooting.

1357
00:53:29,670 --> 00:53:31,350
If you are not able to find memory,

1358
00:53:31,350 --> 00:53:32,790
then go and troubleshoot.

1359
00:53:32,790 --> 00:53:34,650
If the information is good enough,

1360
00:53:34,650 --> 00:53:36,720
then persist that information for me

1361
00:53:36,720 --> 00:53:38,460
after you're done with
the trouble shootings."

1362
00:53:38,460 --> 00:53:40,080
And again, we can control that.

1363
00:53:40,080 --> 00:53:42,150
We can split responsibilities here.

1364
00:53:42,150 --> 00:53:43,800
We can make the agent fix.

1365
00:53:43,800 --> 00:53:45,930
Of course, we don't want
to do that in production.

1366
00:53:45,930 --> 00:53:47,070
If we're talking about production,

1367
00:53:47,070 --> 00:53:48,660
we can make the agent open a pool request

1368
00:53:48,660 --> 00:53:50,430
for GitHub repository.

1369
00:53:50,430 --> 00:53:51,300
And we already have that.

1370
00:53:51,300 --> 00:53:53,850
If you want to see that come
back to next year code session.

1371
00:53:53,850 --> 00:53:55,980
But for this year code session,

1372
00:53:55,980 --> 00:53:57,747
we are doing an Orchestrator agent

1373
00:53:57,747 --> 00:54:00,060
and then just passing the prompt here.

1374
00:54:00,060 --> 00:54:04,080
So now I'm gonna do and
hopefully everything will work,

1375
00:54:04,080 --> 00:54:08,040
I'm gonna trigger our main
agent that's gonna be able

1376
00:54:08,040 --> 00:54:11,760
to talk to the other
agent running as a server.

1377
00:54:11,760 --> 00:54:13,350
- [Sai] So I see, now
you've started them up

1378
00:54:13,350 --> 00:54:15,015
as two separate processes.

1379
00:54:15,015 --> 00:54:16,230
- Two separate process.
- One for that memory agent,

1380
00:54:16,230 --> 00:54:19,410
one for the actual main
Orchestrator plus specialist.

1381
00:54:19,410 --> 00:54:20,243
And so think about this,

1382
00:54:20,243 --> 00:54:23,430
if you were to deploy this
in Kubernetes, for example,

1383
00:54:23,430 --> 00:54:27,810
you could deploy each of these
as individual Python pods

1384
00:54:27,810 --> 00:54:32,220
and also scale them independently
of one another as well.

1385
00:54:32,220 --> 00:54:34,230
For example, the memory agent has

1386
00:54:34,230 --> 00:54:38,400
to respond every single time
a message is pasted in Slack,

1387
00:54:38,400 --> 00:54:40,320
whereas the troubleshooting
agent doesn't need

1388
00:54:40,320 --> 00:54:41,850
to respond as often.

1389
00:54:41,850 --> 00:54:46,050
So you could really scale in
response to demand and load.

1390
00:54:46,050 --> 00:54:46,883
- [Lucas] Yeah.

1391
00:54:46,883 --> 00:54:48,510
So let's see if it actually works.

1392
00:54:48,510 --> 00:54:50,820
So what I'm gonna say
is I'm just gonna try

1393
00:54:50,820 --> 00:54:53,790
to trigger the agent to
persist a tip and advise

1394
00:54:53,790 --> 00:54:56,520
that some of our DevOps
engineers have done.

1395
00:54:56,520 --> 00:54:57,873
So what I'm gonna say is,

1396
00:54:58,830 --> 00:55:03,830
if you don't know how
much CPU and memory define

1397
00:55:06,540 --> 00:55:11,540
for your limits always
define the same as requests,

1398
00:55:13,590 --> 00:55:15,450
and that that might be true, right?

1399
00:55:15,450 --> 00:55:17,363
So, that's a tip that I'm giving

1400
00:55:17,363 --> 00:55:22,363
and I'm gonna say, tip from DevOps squad.

1401
00:55:23,760 --> 00:55:28,760
So hopefully we are gonna be
able to classify this message.

1402
00:55:28,770 --> 00:55:30,960
The agent should respond to this message

1403
00:55:30,960 --> 00:55:32,880
because it's related to troubleshooting.

1404
00:55:32,880 --> 00:55:33,713
Okay? As you can see-

1405
00:55:33,713 --> 00:55:35,970
- [Sai] Oh, we didn't fix
the classification, did we?

1406
00:55:35,970 --> 00:55:37,620
- [Lucas] We didn't
fix the classification.

1407
00:55:37,620 --> 00:55:38,453
- [Sai] That's right.

1408
00:55:38,453 --> 00:55:41,850
So the classification
should know, right now,

1409
00:55:41,850 --> 00:55:44,370
if you look at the prompt
for the classification model,

1410
00:55:44,370 --> 00:55:46,710
let's take a look at it really quickly.

1411
00:55:46,710 --> 00:55:47,580
If it's related

1412
00:55:47,580 --> 00:55:50,430
to Kubernetes system
troubleshooting technical issues,

1413
00:55:50,430 --> 00:55:54,210
I bet if we updated this and
let's make it a little smarter

1414
00:55:54,210 --> 00:55:56,176
of if you have any tips to store, right?

1415
00:55:56,176 --> 00:55:57,607
- Do you wanna do that?
- Let's do it.

1416
00:55:57,607 --> 00:55:59,310
- [Lucas] We haven't asked this.

1417
00:55:59,310 --> 00:56:00,900
- Let's try-
- Let's see if it-

1418
00:56:00,900 --> 00:56:02,310
I think it's gonna work.

1419
00:56:02,310 --> 00:56:03,150
Let's see, let's see.

1420
00:56:03,150 --> 00:56:04,650
Is this message related to Kubernetes

1421
00:56:04,650 --> 00:56:08,853
or request for help or any tips?

1422
00:56:10,830 --> 00:56:11,663
Is it good enough?

1423
00:56:11,663 --> 00:56:12,570
- Pretty good
- If it doesn't work,

1424
00:56:12,570 --> 00:56:13,590
I'm gonna tag the agent.

1425
00:56:13,590 --> 00:56:15,510
- [Sai] That should cover all the tips.

1426
00:56:15,510 --> 00:56:18,300
But you know, if we
wanted to get more precise

1427
00:56:18,300 --> 00:56:20,160
in the future for troubleshooting tips

1428
00:56:20,160 --> 00:56:21,510
or something like that, we could add that,

1429
00:56:21,510 --> 00:56:23,640
for now, we're doing it live.

1430
00:56:23,640 --> 00:56:26,310
We wanna make sure that
classification responds yes

1431
00:56:26,310 --> 00:56:29,130
for a message like that.
- If it doesn't respond yes,

1432
00:56:29,130 --> 00:56:30,733
then I can tag the agent

1433
00:56:30,733 --> 00:56:34,590
and you can be sure that
this is a live demo, right?

1434
00:56:34,590 --> 00:56:37,050
So let's wait for the
Kubernetes Specialist agent

1435
00:56:37,050 --> 00:56:40,050
and orchestrator agent
to start, there we go.

1436
00:56:40,050 --> 00:56:43,320
Now I'm gonna send
exactly the same message

1437
00:56:43,320 --> 00:56:46,170
and if we do it in the right way,

1438
00:56:46,170 --> 00:56:48,930
we should be able to see as-
- Come on, demo gods.

1439
00:56:48,930 --> 00:56:50,040
One time.
- Yes!

1440
00:56:50,040 --> 00:56:51,420
- [Sai] There we go. See?

1441
00:56:51,420 --> 00:56:53,010
So here's the thing again,

1442
00:56:53,010 --> 00:56:54,930
it is non-deterministic by nature.

1443
00:56:54,930 --> 00:56:56,790
That's how LLMs operate.

1444
00:56:56,790 --> 00:56:59,880
But you saw with just that
little bit of prodding

1445
00:56:59,880 --> 00:57:02,310
of like changing that
classification prompt,

1446
00:57:02,310 --> 00:57:05,220
we were able to make it respond better

1447
00:57:05,220 --> 00:57:06,120
for something like this.

1448
00:57:06,120 --> 00:57:08,700
And so we're not saying you're
gonna find the perfect prompt

1449
00:57:08,700 --> 00:57:10,380
that fits your use case immediately.

1450
00:57:10,380 --> 00:57:11,610
Like of course, for example,

1451
00:57:11,610 --> 00:57:14,100
OpenAI has been refining their prompts

1452
00:57:14,100 --> 00:57:18,630
and prompt engineering their
base models for years now.

1453
00:57:18,630 --> 00:57:20,460
You're gonna want to keep optimizing

1454
00:57:20,460 --> 00:57:24,090
and with that small optimization
the classification worked.

1455
00:57:24,090 --> 00:57:25,657
- [Lucas] And then if
you can see the agent,

1456
00:57:25,657 --> 00:57:26,940
they talk to each other.

1457
00:57:26,940 --> 00:57:30,510
So first we send a message
to discover the agents

1458
00:57:30,510 --> 00:57:32,700
that we have using the agent card

1459
00:57:32,700 --> 00:57:34,350
that is available in our agent.

1460
00:57:34,350 --> 00:57:35,700
So if you look at here,

1461
00:57:35,700 --> 00:57:38,520
we use it a2a list discovered agents,

1462
00:57:38,520 --> 00:57:40,230
and then we discovered a memory agent.

1463
00:57:40,230 --> 00:57:41,460
And then with this,

1464
00:57:41,460 --> 00:57:42,930
we also discovered the tools

1465
00:57:42,930 --> 00:57:45,660
that the agent that we
are talking to have.

1466
00:57:45,660 --> 00:57:48,570
And now, we are sending a
message to the right tool.

1467
00:57:48,570 --> 00:57:50,760
We send a message to store solution

1468
00:57:50,760 --> 00:57:52,980
in our other agent running as a server.

1469
00:57:52,980 --> 00:57:54,330
And if you can look at here,

1470
00:57:54,330 --> 00:57:57,600
we have one tool that was
called on the memory agent

1471
00:57:57,600 --> 00:58:01,920
that was to start a solution
related to QOS guaranteed.

1472
00:58:01,920 --> 00:58:04,560
Essentially, same amount of
CPU and memory resources.

1473
00:58:04,560 --> 00:58:07,010
And then, there you go,
you have a response here.

1474
00:58:07,950 --> 00:58:08,783
- [Sai] Okay.

1475
00:58:08,783 --> 00:58:09,616
And by the way,

1476
00:58:09,616 --> 00:58:12,210
I think in the real scenario
it wouldn't even respond,

1477
00:58:12,210 --> 00:58:14,850
the bot would just sit
there silently listening

1478
00:58:14,850 --> 00:58:17,340
for any tip and just
storing it in the database.

1479
00:58:17,340 --> 00:58:18,360
But for the sake of the demo,

1480
00:58:18,360 --> 00:58:19,417
we have it respond saying,

1481
00:58:19,417 --> 00:58:21,120
"Hey, this is a good tip,

1482
00:58:21,120 --> 00:58:22,294
we'll store it in the database."

1483
00:58:22,294 --> 00:58:23,820
- [Lucas] And if you're not trusting me,

1484
00:58:23,820 --> 00:58:27,030
we had one solution
before, let's refresh it.

1485
00:58:27,030 --> 00:58:28,470
Now we have a total of two solutions.

1486
00:58:28,470 --> 00:58:32,160
Let's search for CPU limits

1487
00:58:32,160 --> 00:58:34,560
and see if we have that solution
that are available already.

1488
00:58:34,560 --> 00:58:35,700
- [Sai] And so this is going directly

1489
00:58:35,700 --> 00:58:37,144
to the S3 vectors database, right?

1490
00:58:37,144 --> 00:58:38,680
Just looking at what solutions we have.

1491
00:58:38,680 --> 00:58:40,740
- [Lucas] Yeah, absolutely.
So that's the thing.

1492
00:58:40,740 --> 00:58:43,020
I'm doing a RAG here in the same way

1493
00:58:43,020 --> 00:58:44,310
that we are doing for the agent.

1494
00:58:44,310 --> 00:58:45,690
So we are like just retrieving,

1495
00:58:45,690 --> 00:58:47,550
embedding the query and then
retrieving the solution.

1496
00:58:47,550 --> 00:58:50,370
So that's the solution
with the shortest distance.

1497
00:58:50,370 --> 00:58:52,860
So essentially that's the
solution that means the most

1498
00:58:52,860 --> 00:58:54,330
for our use case right here.

1499
00:58:54,330 --> 00:58:56,730
So if you can see, please
define the same amount

1500
00:58:56,730 --> 00:58:59,760
of CPU and memory that
you have for your servers.

1501
00:58:59,760 --> 00:59:00,593
That's great.

1502
00:59:00,593 --> 00:59:01,500
- [Sai] It's like a
confidence rating, right?

1503
00:59:01,500 --> 00:59:03,900
It's like the inverse
of a confidence rating.

1504
00:59:03,900 --> 00:59:07,410
So smaller distance means more confident.

1505
00:59:07,410 --> 00:59:09,540
And I think you saw
that second solution was

1506
00:59:09,540 --> 00:59:11,370
at a distance of like 0.9,

1507
00:59:11,370 --> 00:59:14,250
that node exporter tip, not very relevant,

1508
00:59:14,250 --> 00:59:17,280
for the question that was
asked about CPU limits.

1509
00:59:17,280 --> 00:59:18,113
- [Lucas] Yeah.

1510
00:59:18,113 --> 00:59:18,950
So last thing that I'm gonna try to do,

1511
00:59:18,950 --> 00:59:21,960
I know that we have just five minutes.

1512
00:59:21,960 --> 00:59:23,250
So what I'm gonna try to do now

1513
00:59:23,250 --> 00:59:25,890
is I'm gonna deploy some failing pods.

1514
00:59:25,890 --> 00:59:28,680
And remember that first demo that we saw

1515
00:59:28,680 --> 00:59:32,130
before fixing the memory,
the monitoring agent,

1516
00:59:32,130 --> 00:59:34,290
that's essentially what
we're gonna try to do now.

1517
00:59:34,290 --> 00:59:38,520
So let me deploy the failing
pods through our cluster.

1518
00:59:38,520 --> 00:59:42,540
We should be able to see
the demo app namespace here.

1519
00:59:42,540 --> 00:59:43,373
- [Sai] And you still

1520
00:59:43,373 --> 00:59:46,560
have the Python main
orchestrator running right?

1521
00:59:46,560 --> 00:59:48,177
Or did we kill that?
- No, I killed that,

1522
00:59:48,177 --> 00:59:49,590
but I'm gonna make it run again.

1523
00:59:49,590 --> 00:59:51,000
- Okay, cool.
- But essentially,

1524
00:59:51,000 --> 00:59:53,040
we have the pods not running.

1525
00:59:53,040 --> 00:59:56,220
Let me just trigger the agent again.

1526
00:59:56,220 --> 00:59:57,370
Agentic troubleshooting

1527
00:59:59,070 --> 01:00:01,220
and then I'm gonna
trigger the agent again.

1528
01:00:03,030 --> 01:00:03,960
There you go.

1529
01:00:03,960 --> 01:00:05,910
So now if you look at this,

1530
01:00:05,910 --> 01:00:07,470
we have a lot of issues going on.

1531
01:00:07,470 --> 01:00:09,810
We have the monitoring agent not working,

1532
01:00:09,810 --> 01:00:12,660
we have the back end API restarting,

1533
01:00:12,660 --> 01:00:16,080
we out of memory queued, front
end has some issues as well.

1534
01:00:16,080 --> 01:00:17,760
And then we have a redis here.

1535
01:00:17,760 --> 01:00:18,920
Let's try to debug

1536
01:00:18,920 --> 01:00:22,830
and fix the monitoring agent
using the recommended image

1537
01:00:22,830 --> 01:00:25,260
that we have stored in the solutions.

1538
01:00:25,260 --> 01:00:26,370
So before we do that,

1539
01:00:26,370 --> 01:00:30,213
let's see if the agent
has it started already?

1540
01:00:31,170 --> 01:00:33,270
Both apps running. There you go.

1541
01:00:33,270 --> 01:00:35,137
So what I'm gonna say is,

1542
01:00:35,137 --> 01:00:40,137
"Hey folks, my monitoring
agent on demo-app namespace

1543
01:00:44,490 --> 01:00:46,707
is not running for some reason.

1544
01:00:46,707 --> 01:00:48,237
- You know, there's usually-
- I'm a developer,

1545
01:00:48,237 --> 01:00:50,400
I don't know why it's not running.

1546
01:00:50,400 --> 01:00:53,250
- [Sai] And you know,
there's usually some poor SRE

1547
01:00:53,250 --> 01:00:55,140
that's always in this
channel having to respond

1548
01:00:55,140 --> 01:00:56,430
to these kind of messages.

1549
01:00:56,430 --> 01:01:00,360
This guy who's probably
overloaded with too many messages,

1550
01:01:00,360 --> 01:01:02,040
maybe it's some of you
in this room can relate

1551
01:01:02,040 --> 01:01:03,960
to this yourself.

1552
01:01:03,960 --> 01:01:07,950
Hopefully the agent can pick
this up and not one of you,

1553
01:01:07,950 --> 01:01:09,240
right?

1554
01:01:09,240 --> 01:01:10,980
Love the emojis. Let's see.
- I just try

1555
01:01:10,980 --> 01:01:13,380
to see if it's gonna fail
or not but there you go.

1556
01:01:13,380 --> 01:01:14,430
Yes.

1557
01:01:14,430 --> 01:01:15,870
So the first thing that it's gonna do,

1558
01:01:15,870 --> 01:01:16,950
because our system prompt,

1559
01:01:16,950 --> 01:01:18,900
it's gonna search in our vector database

1560
01:01:18,900 --> 01:01:21,810
to see if there is any
solution related to this.

1561
01:01:21,810 --> 01:01:23,970
Hopefully we're gonna get the right image

1562
01:01:23,970 --> 01:01:27,600
because that's related to node exporter.

1563
01:01:27,600 --> 01:01:30,750
There it goes to the first
image, the first solution,

1564
01:01:30,750 --> 01:01:33,840
the closest one to what we
search is a solution number one.

1565
01:01:33,840 --> 01:01:35,850
So it was able to get in the proper way,

1566
01:01:35,850 --> 01:01:37,920
but it's not enough information.

1567
01:01:37,920 --> 01:01:39,470
So what the agent is doing

1568
01:01:39,470 --> 01:01:42,180
is actually doing the
troubleshooting by itself

1569
01:01:42,180 --> 01:01:43,320
with that information in mind.

1570
01:01:43,320 --> 01:01:45,811
If we had more information,
it would use it.

1571
01:01:45,811 --> 01:01:46,644
So I-

1572
01:01:46,644 --> 01:01:47,477
- [Sai] Actually love
this question you asked

1573
01:01:47,477 --> 01:01:50,340
because it just demonstrated
all the features we developed.

1574
01:01:50,340 --> 01:01:53,430
On the left side, it founded
two memory solutions.

1575
01:01:53,430 --> 01:01:55,080
It realized this isn't relevant.

1576
01:01:55,080 --> 01:01:56,820
Then it went back to the
original Specialist agent,

1577
01:01:56,820 --> 01:02:00,930
talks to MCP to get more
information about what's failing.

1578
01:02:00,930 --> 01:02:03,960
MCP gives it all the application
logs and the pod logs

1579
01:02:03,960 --> 01:02:07,890
and you can see it all thinking
all orchestrated together

1580
01:02:07,890 --> 01:02:11,400
and ideally figures out what
the original problem is.

1581
01:02:11,400 --> 01:02:12,233
- [Lucas] Yeah.

1582
01:02:12,233 --> 01:02:13,770
So right now it's just
storing the solution

1583
01:02:13,770 --> 01:02:15,840
because it was able to
find the root cause.

1584
01:02:15,840 --> 01:02:18,030
So if anyone deploys that agent again

1585
01:02:18,030 --> 01:02:19,290
with that same root cause,

1586
01:02:19,290 --> 01:02:20,730
we don't need to do the
troubleshooting again.

1587
01:02:20,730 --> 01:02:22,560
We can go straight to the issue.

1588
01:02:22,560 --> 01:02:24,180
So our solution-
- Wait,

1589
01:02:24,180 --> 01:02:25,110
that's actually really cool.

1590
01:02:25,110 --> 01:02:26,700
So it found the solution

1591
01:02:26,700 --> 01:02:30,060
and decided to store it
in our solutions database?

1592
01:02:30,060 --> 01:02:31,200
- Yeah.
- We didn't even have

1593
01:02:31,200 --> 01:02:32,040
to code that in there.

1594
01:02:32,040 --> 01:02:35,730
It realized it and decided
let's just store this

1595
01:02:35,730 --> 01:02:39,570
for future use.
- And if you look at this,

1596
01:02:39,570 --> 01:02:42,390
we didn't got the response
that we were expecting to get.

1597
01:02:42,390 --> 01:02:45,990
So, let's try to ask that again.

1598
01:02:45,990 --> 01:02:49,530
What is going on? What is the issue?

1599
01:02:49,530 --> 01:02:51,150
- [Sai] You know, we've seen this before,

1600
01:02:51,150 --> 01:02:54,060
when it stores the
solution in the database,

1601
01:02:54,060 --> 01:02:55,230
it considers itself done.

1602
01:02:55,230 --> 01:02:57,480
It's like, "Found a solution, stored it."

1603
01:02:57,480 --> 01:02:59,211
We don't have to respond, there you go.

1604
01:02:59,211 --> 01:03:00,210
There you go.
- But since we have,

1605
01:03:00,210 --> 01:03:02,310
we still have the context on
the threads and everything,

1606
01:03:02,310 --> 01:03:03,840
it responded super fast.

1607
01:03:03,840 --> 01:03:06,390
So essentially the root cause is,

1608
01:03:06,390 --> 01:03:07,830
you are using the image,

1609
01:03:07,830 --> 01:03:10,890
nonexistent monitoring agent dot latest.

1610
01:03:10,890 --> 01:03:12,360
Of course this image doesn't exist.

1611
01:03:12,360 --> 01:03:14,220
So would you like me to guide you

1612
01:03:14,220 --> 01:03:15,570
to the steps to fix the issue?

1613
01:03:15,570 --> 01:03:17,610
No, I would like you to fix the issue.

1614
01:03:17,610 --> 01:03:20,790
So I'm gonna say k8s magic bot, please,

1615
01:03:20,790 --> 01:03:22,650
because you said that you
don't want me to add please.

1616
01:03:22,650 --> 01:03:23,483
I'm gonna say please

1617
01:03:23,483 --> 01:03:26,190
because I still, I watch
a terminator number two.

1618
01:03:26,190 --> 01:03:27,570
So I'm gonna say please.

1619
01:03:27,570 --> 01:03:32,570
So please, can you fix
the monitoring agent

1620
01:03:32,760 --> 01:03:37,470
for me using the recommended DevOps?

1621
01:03:37,470 --> 01:03:40,203
Oops. DevOps image?

1622
01:03:42,270 --> 01:03:43,680
- Okay, while this thing Lucas.

1623
01:03:43,680 --> 01:03:45,090
'cause we have 15 seconds left folks,

1624
01:03:45,090 --> 01:03:48,750
I wanna share with you some
resources really quickly.

1625
01:03:48,750 --> 01:03:51,810
So scan this QR code, it's
gonna take you to a GitHub

1626
01:03:51,810 --> 01:03:53,640
of all of the container sessions

1627
01:03:53,640 --> 01:03:54,990
that we're doing at reinvent.

1628
01:03:54,990 --> 01:03:56,970
So find our session here.

1629
01:03:56,970 --> 01:03:59,340
So with CNS421,

1630
01:03:59,340 --> 01:04:02,190
find our session and we'll
have the sample code,

1631
01:04:02,190 --> 01:04:05,070
we'll have all of the code
that we showed today linked

1632
01:04:05,070 --> 01:04:05,903
as well.

1633
01:04:05,903 --> 01:04:07,560
It's all on GitHub for you to go through.

1634
01:04:07,560 --> 01:04:09,630
We really appreciate you
spending your time here

1635
01:04:09,630 --> 01:04:10,590
with us today.

1636
01:04:10,590 --> 01:04:11,610
So scan that QR,

1637
01:04:11,610 --> 01:04:13,740
you'll find all of the
relevant resources there

1638
01:04:13,740 --> 01:04:16,140
and we would love for you
to leave us some feedback

1639
01:04:16,140 --> 01:04:17,070
in the app as well.

1640
01:04:17,070 --> 01:04:18,261
Thank you so much.
- Hold on, hold on,

1641
01:04:18,261 --> 01:04:19,094
hold on, hold hold, hold on.

1642
01:04:19,094 --> 01:04:20,360
Can you go back to the demo?

1643
01:04:22,230 --> 01:04:23,063
There it goes.

1644
01:04:23,063 --> 01:04:25,020
So now we have the
monitoring agent running

1645
01:04:25,020 --> 01:04:26,400
as you can see right there.

1646
01:04:26,400 --> 01:04:29,792
And then if we go to alert
managers, there we go, it's over.

1647
01:04:29,792 --> 01:04:31,220
(audience clapping)
Same deal.

1648
01:04:31,220 --> 01:04:32,330
We deserve it.

1649
01:04:32,330 --> 01:04:33,993
Thank you. Thank you so much.

