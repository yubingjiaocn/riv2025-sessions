1
00:00:00,480 --> 00:00:03,180
- [Justin] So, I wanna
start by asking a question.

2
00:00:03,180 --> 00:00:07,020
Who here, whose title
like, or job description

3
00:00:07,020 --> 00:00:10,080
officially like has the
word FinOps in it somewhere?

4
00:00:10,080 --> 00:00:10,913
How many hands?

5
00:00:10,913 --> 00:00:12,036
Raise your hands.

6
00:00:12,036 --> 00:00:13,080
You got like four or five.

7
00:00:13,080 --> 00:00:14,850
Okay, maybe like 10.

8
00:00:14,850 --> 00:00:17,100
Probably about what a
quarter of the room or so.

9
00:00:17,100 --> 00:00:19,710
Who's in the second group where your title

10
00:00:19,710 --> 00:00:21,030
has absolutely nothing to do with FinOps

11
00:00:21,030 --> 00:00:22,800
and you've kind of accidentally stumbled

12
00:00:22,800 --> 00:00:26,250
into having to do cost
allocation or cost reporting?

13
00:00:26,250 --> 00:00:27,990
Yeah, my hand's up for this one.

14
00:00:27,990 --> 00:00:29,070
Awesome.
(Jason chuckles)

15
00:00:29,070 --> 00:00:31,350
So I'm Justin Marks, I'm a
senior technical account manager

16
00:00:31,350 --> 00:00:32,850
with AWS Support.

17
00:00:32,850 --> 00:00:33,683
Jason.

18
00:00:33,683 --> 00:00:35,190
- [Jason] So this is
Jason, product manager

19
00:00:35,190 --> 00:00:38,280
for AWS Cost and Usage Report and FOCUS.

20
00:00:38,280 --> 00:00:39,180
- [Justin] Cool.

21
00:00:39,180 --> 00:00:40,320
And we're gonna talk to you today about

22
00:00:40,320 --> 00:00:42,870
advanced multi-cloud cost
reporting with FOCUS.

23
00:00:42,870 --> 00:00:45,720
But before we get into the FOCUS topic,

24
00:00:45,720 --> 00:00:47,970
I want to take everybody
back through probably

25
00:00:47,970 --> 00:00:51,750
a common scenario you've
dealt with over your career

26
00:00:51,750 --> 00:00:55,080
of dealing with cost and
usage data in the cloud.

27
00:00:55,080 --> 00:00:59,880
So you had a team who started using AWS

28
00:00:59,880 --> 00:01:02,490
and you had to figure out
four things about cost

29
00:01:02,490 --> 00:01:04,710
and usage data, how you're
gonna collect that data, right?

30
00:01:04,710 --> 00:01:06,210
Getting the reports turned on,

31
00:01:06,210 --> 00:01:08,152
where you're gonna deliver them.

32
00:01:08,152 --> 00:01:09,600
And then you're gonna have to figure out

33
00:01:09,600 --> 00:01:11,490
how to normalize it, get it into formats

34
00:01:11,490 --> 00:01:13,500
that the finance team cares about,

35
00:01:13,500 --> 00:01:16,020
get it into formats that
your engineering teams

36
00:01:16,020 --> 00:01:17,580
or the teams that wanna visualize

37
00:01:17,580 --> 00:01:19,950
like how to get it into those formats.

38
00:01:19,950 --> 00:01:22,290
You're gonna need to figure
out how to analyze it.

39
00:01:22,290 --> 00:01:23,640
What tools are you gonna use?

40
00:01:23,640 --> 00:01:25,110
Are you gonna go pick one off the shelf?

41
00:01:25,110 --> 00:01:27,660
Are you gonna try to
wing it with, you know,

42
00:01:27,660 --> 00:01:29,820
some of the native tooling depending on

43
00:01:29,820 --> 00:01:31,950
which cloud provider you're with?

44
00:01:31,950 --> 00:01:35,130
And then how are you gonna
derive insights out of that data?

45
00:01:35,130 --> 00:01:36,330
And finally how to visualize it, right?

46
00:01:36,330 --> 00:01:38,670
Ultimately folks end
up building dashboards

47
00:01:38,670 --> 00:01:41,610
and trying to find ways to build reports

48
00:01:41,610 --> 00:01:43,923
for their executives on how this is going.

49
00:01:45,090 --> 00:01:48,450
And it stops there, right? (chuckles)

50
00:01:48,450 --> 00:01:50,280
It wouldn't be a multi-cloud conversation

51
00:01:50,280 --> 00:01:51,450
if it didn't stop there.

52
00:01:51,450 --> 00:01:53,580
So then you get another
team who comes and says,

53
00:01:53,580 --> 00:01:56,610
Hey, we use this SaaS platform
and this SaaS platform

54
00:01:56,610 --> 00:01:58,920
has costs and usage and we
need the data from there too

55
00:01:58,920 --> 00:02:01,890
and we'd like to integrate
that in our reporting pipeline.

56
00:02:01,890 --> 00:02:04,470
So you have to go figure
out these four things

57
00:02:04,470 --> 00:02:05,793
for that provider too.

58
00:02:06,660 --> 00:02:08,520
And then when you know it,
you hear about this other team

59
00:02:08,520 --> 00:02:09,720
that's running in another cloud

60
00:02:09,720 --> 00:02:11,550
and now you gotta go figure out again.

61
00:02:11,550 --> 00:02:14,190
And you can see where I'm
going with this, right?

62
00:02:14,190 --> 00:02:17,880
So having to relearn
these things every time

63
00:02:17,880 --> 00:02:19,740
you adopt a new provider,

64
00:02:19,740 --> 00:02:22,170
you use a new SaaS
platform, it could be hard.

65
00:02:22,170 --> 00:02:24,900
And, Jason, what do we have to help folks

66
00:02:24,900 --> 00:02:26,640
manage this complexity?

67
00:02:26,640 --> 00:02:29,940
- [Jason] Sure. So the
thing of practitioners

68
00:02:29,940 --> 00:02:34,200
spend countless hours every
day to normalize the data.

69
00:02:34,200 --> 00:02:36,600
And this is because
different providers out there

70
00:02:36,600 --> 00:02:39,720
define the data differently
and we wanna solve that problem

71
00:02:39,720 --> 00:02:42,630
for our customers and we
wanna solve it at the root.

72
00:02:42,630 --> 00:02:44,700
So organized by the FinOps Foundation

73
00:02:44,700 --> 00:02:47,130
under the antitrust
compliance that we work

74
00:02:47,130 --> 00:02:51,630
with different FinOp practitioners
from different industries

75
00:02:51,630 --> 00:02:55,410
and created this new open
specification called FOCUS.

76
00:02:55,410 --> 00:02:57,870
So FOCUS stands for FinOps Open Cost

77
00:02:57,870 --> 00:02:59,460
and Usage Specification.

78
00:02:59,460 --> 00:03:03,240
It provides consistent cost and usage data

79
00:03:03,240 --> 00:03:06,813
such as building,
pricing and cost metrics.

80
00:03:07,710 --> 00:03:11,370
So, lemme take you
through a quick journey,

81
00:03:11,370 --> 00:03:12,840
how the FOCUS journey would look like

82
00:03:12,840 --> 00:03:15,150
when you start with the FOCUS.

83
00:03:15,150 --> 00:03:17,580
So when you start FOCUS,
you will first get the data

84
00:03:17,580 --> 00:03:19,230
from your data generators.

85
00:03:19,230 --> 00:03:21,810
This can be your cloud providers,

86
00:03:21,810 --> 00:03:23,100
it can be your SaaS providers

87
00:03:23,100 --> 00:03:25,260
or even your data center providers.

88
00:03:25,260 --> 00:03:29,250
So FOCUS is a open
specification anyone can create.

89
00:03:29,250 --> 00:03:32,580
And as of today the majority
of the large cloud providers

90
00:03:32,580 --> 00:03:35,430
has adopted FOCUS and we
are seeing increasing trend

91
00:03:35,430 --> 00:03:38,130
for the SaaS providers to adopt FOCUS.

92
00:03:38,130 --> 00:03:41,869
This will give you a universal
view of your cloud cost

93
00:03:41,869 --> 00:03:44,070
and use data across all
your technology stack,

94
00:03:44,070 --> 00:03:46,110
not just limiting to cloud.

95
00:03:46,110 --> 00:03:49,980
So once you get your
data from your providers,

96
00:03:49,980 --> 00:03:53,100
you inject that data to
your FinOps tool platforms,

97
00:03:53,100 --> 00:03:57,180
this can be Amazon Athena,
which we will be demoing today

98
00:03:57,180 --> 00:03:59,700
and for to query the data directly.

99
00:03:59,700 --> 00:04:02,220
And you can also visualize your FOCUS data

100
00:04:02,220 --> 00:04:05,520
using the Amazon QuickSight
or even plug those data

101
00:04:05,520 --> 00:04:09,420
into Excel for different insights.

102
00:04:09,420 --> 00:04:11,520
And once you have the data injected

103
00:04:11,520 --> 00:04:14,400
to your FinOps data platforms,
you can analyze the data

104
00:04:14,400 --> 00:04:17,610
for different use cases
such as demonstrating

105
00:04:17,610 --> 00:04:20,640
your business values, finding
optimization opportunities

106
00:04:20,640 --> 00:04:23,013
across the vendors that you have with.

107
00:04:24,330 --> 00:04:28,500
So now you understand how the
FOCUS look like in high level.

108
00:04:28,500 --> 00:04:30,603
So let's us do a quick exercise.

109
00:04:31,920 --> 00:04:35,640
Justin, can you help us to
run a quick exercise to see

110
00:04:35,640 --> 00:04:38,100
where people are with the FOCUS journey?

111
00:04:38,100 --> 00:04:39,930
- [Justin] Yeah, we're just
trying to see where folks are.

112
00:04:39,930 --> 00:04:42,000
I think I may have asked
a couple of you outside

113
00:04:42,000 --> 00:04:44,820
so I have a little bit of a
sample to base this off of,

114
00:04:44,820 --> 00:04:47,400
but hands up if you've
seen the FOCUS spec,

115
00:04:47,400 --> 00:04:50,880
like you've read some of
the documentation out there?

116
00:04:50,880 --> 00:04:52,533
It's about half the room.

117
00:04:53,580 --> 00:04:56,280
Okay, so for the folks
with their hands down,

118
00:04:56,280 --> 00:04:58,230
you've now seen part of the FOCUS spec.

119
00:04:59,130 --> 00:05:00,600
It's a big document.

120
00:05:00,600 --> 00:05:03,510
It covers things like
normative requirements,

121
00:05:03,510 --> 00:05:05,430
different columns, things about metadata

122
00:05:05,430 --> 00:05:08,430
and attributes for the
cost of usage data set.

123
00:05:08,430 --> 00:05:10,200
This is an example of
availability zone, right?

124
00:05:10,200 --> 00:05:12,330
You get a nice definition here.

125
00:05:12,330 --> 00:05:16,197
It explains the intention,
it calls out you might,

126
00:05:16,197 --> 00:05:18,180
and the bullet points here,
the first bullet point says

127
00:05:18,180 --> 00:05:19,860
it is recommended column, right?

128
00:05:19,860 --> 00:05:23,040
So it's not mandatory, it
may or may not be populated.

129
00:05:23,040 --> 00:05:25,080
That'll be important later.

130
00:05:25,080 --> 00:05:26,970
It's type string, things like that, right?

131
00:05:26,970 --> 00:05:28,470
So we can scratch this one off.

132
00:05:28,470 --> 00:05:31,440
Everybody in this room has
seen part of the FOCUS spec.

133
00:05:31,440 --> 00:05:35,220
So let's do hands up if you
have FOCUS reports like created

134
00:05:35,220 --> 00:05:37,950
and you're playing around
with that data today?

135
00:05:37,950 --> 00:05:39,420
A couple hands up.

136
00:05:39,420 --> 00:05:41,430
It's about half the room. Okay.

137
00:05:41,430 --> 00:05:43,530
How about if you have analyzed

138
00:05:43,530 --> 00:05:45,270
or visualized this FOCUS data before?

139
00:05:45,270 --> 00:05:46,290
So, it's not just there.

140
00:05:46,290 --> 00:05:48,990
You're actually like using it,
your teams are looking at it.

141
00:05:48,990 --> 00:05:50,373
Hands up if you've?

142
00:05:51,720 --> 00:05:52,553
Okay.

143
00:05:52,553 --> 00:05:56,160
And how about if you've
joined AWS FOCUS data

144
00:05:56,160 --> 00:05:57,673
with other providers?

145
00:05:57,673 --> 00:06:00,930
A quick show of hands who's
pulled in multiple providers?

146
00:06:00,930 --> 00:06:02,460
- [Jason] Including the SaaS providers,

147
00:06:02,460 --> 00:06:03,600
- [Justin] Including SaaS and other.

148
00:06:03,600 --> 00:06:05,460
Okay, we got four or five hands.

149
00:06:05,460 --> 00:06:06,630
Okay, great.

150
00:06:06,630 --> 00:06:08,760
So I mean it's a pretty
good understanding of,

151
00:06:08,760 --> 00:06:09,593
we have a good understanding now

152
00:06:09,593 --> 00:06:11,910
of the experience with FOCUS in the room.

153
00:06:11,910 --> 00:06:16,910
So, Jason, do you want
to talk to us about how,

154
00:06:16,950 --> 00:06:18,060
for the folks that had their hands down

155
00:06:18,060 --> 00:06:19,140
who haven't created the reports yet,

156
00:06:19,140 --> 00:06:23,580
how they can create FOCUS for AWS?

157
00:06:23,580 --> 00:06:24,540
- [Jason] Sure.

158
00:06:24,540 --> 00:06:28,290
So AWS data exports platform
is the centralized data

159
00:06:28,290 --> 00:06:32,580
hub for you to export all
your FinOps related data set.

160
00:06:32,580 --> 00:06:37,140
As of today we support
four different table types.

161
00:06:37,140 --> 00:06:40,530
The first one is AWS
Cost and Usage Report 2.0

162
00:06:40,530 --> 00:06:44,130
which is our native
supported cost and usage data

163
00:06:44,130 --> 00:06:48,840
and it provides the most
granular AWS cost and usage data.

164
00:06:48,840 --> 00:06:50,160
And the second is the FOCUS.

165
00:06:50,160 --> 00:06:52,890
We currently supporting 1.0 and 1.2

166
00:06:52,890 --> 00:06:54,690
that we just launched two weeks ago.

167
00:06:55,620 --> 00:06:58,260
And third is the cost
optimization recommendations,

168
00:06:58,260 --> 00:07:01,200
which pulls the data from
cost optimization hub

169
00:07:01,200 --> 00:07:05,250
to help you to identify the
cost optimization opportunities

170
00:07:05,250 --> 00:07:08,610
like right sizing or savings
plan recommendations.

171
00:07:08,610 --> 00:07:11,730
And lastly is the carbon
emissions exports,

172
00:07:11,730 --> 00:07:14,820
which provides you the
carbon footprint data

173
00:07:14,820 --> 00:07:17,880
associated with your
database usage to help you

174
00:07:17,880 --> 00:07:20,253
to better track your sustainability data.

175
00:07:22,230 --> 00:07:24,160
So let's dive a little bit deeper

176
00:07:25,151 --> 00:07:27,303
to the FOCUS data set with AWS Columns.

177
00:07:28,260 --> 00:07:31,620
So we launched FOCUS 1.0 last
year during the re:Invent

178
00:07:31,620 --> 00:07:35,520
and FOCUS 1.0 includes
the 48 columns total.

179
00:07:35,520 --> 00:07:39,690
43 columns from the FOCUS 1.0 spec itself

180
00:07:39,690 --> 00:07:42,330
and we added five additional AWS columns.

181
00:07:42,330 --> 00:07:45,480
This would help the
customers to better navigate

182
00:07:45,480 --> 00:07:48,063
the AWS resources with FOCUS itself.

183
00:07:48,960 --> 00:07:51,600
And there are eight columns
with conformance gaps

184
00:07:51,600 --> 00:07:54,630
and we have published those
in the conformance gap report

185
00:07:54,630 --> 00:07:56,343
and we also did that in the 1.2.

186
00:07:58,380 --> 00:08:00,660
So as mentioned FOCUS 1.2

187
00:08:00,660 --> 00:08:02,730
we have just launched two weeks ago.

188
00:08:02,730 --> 00:08:04,950
Definitely encourage to have a try

189
00:08:04,950 --> 00:08:08,553
for this enhanced version
of a FOCUS specification.

190
00:08:09,870 --> 00:08:14,280
So FOCUS 1.2 provides 14
new additional columns

191
00:08:14,280 --> 00:08:16,190
on top of FOCUS 1.0.

192
00:08:16,190 --> 00:08:20,040
It includes capabilities
like capacity reservation ID

193
00:08:20,040 --> 00:08:23,190
and status columns help
you to better manage

194
00:08:23,190 --> 00:08:26,280
your capacity reservations,
will break down

195
00:08:26,280 --> 00:08:29,280
your capacity reservation
use and unused status.

196
00:08:29,280 --> 00:08:31,800
It's included the invoice ID column

197
00:08:31,800 --> 00:08:34,680
which help you to better
reconcile your cost

198
00:08:34,680 --> 00:08:39,680
and usage data with the physical invoices.

199
00:08:39,900 --> 00:08:43,500
It also includes the capabilities
with for SaaS providers

200
00:08:43,500 --> 00:08:48,500
to generate the FOCUS data set
due to the newly increased,

201
00:08:48,570 --> 00:08:51,630
newly introduced the
pricing current columns.

202
00:08:51,630 --> 00:08:55,680
So enable SaaS providers
to integrate their pricing

203
00:08:55,680 --> 00:08:58,650
in the terms of tokens
and virtual currencies.

204
00:08:58,650 --> 00:09:02,460
And it also added more grand
narrative for SKU usage

205
00:09:02,460 --> 00:09:05,970
and for SKU usage and analysis.

206
00:09:05,970 --> 00:09:09,510
This includes your usage type
and also product attributes.

207
00:09:09,510 --> 00:09:13,620
And last one is the account
structure classification.

208
00:09:13,620 --> 00:09:17,340
It help you to identify whether your usage

209
00:09:17,340 --> 00:09:18,960
is coming from your management account

210
00:09:18,960 --> 00:09:21,270
or from the member account.

211
00:09:21,270 --> 00:09:24,780
And one more thing I'll
highlight here is FOCUS 1.2

212
00:09:24,780 --> 00:09:28,560
also start supporting hourly, daily

213
00:09:28,560 --> 00:09:31,980
and monthly time
granularity which FOCUS 1.0

214
00:09:31,980 --> 00:09:33,880
today we are only supporting our data.

215
00:09:35,640 --> 00:09:38,400
Okay, Justin, you gave a
great presentation last year

216
00:09:38,400 --> 00:09:40,770
about CUR 2.0 and this year you are given

217
00:09:40,770 --> 00:09:42,240
a presentation about FOCUS.

218
00:09:42,240 --> 00:09:43,320
What are the difference?

219
00:09:43,320 --> 00:09:46,800
- [Justin] Yeah, so who here
feels, we had half the room

220
00:09:46,800 --> 00:09:49,890
have like played around
with FOCUS or turned it on?

221
00:09:49,890 --> 00:09:51,390
How many folks feel
comfortable with like cost

222
00:09:51,390 --> 00:09:54,840
and usage reports CUR, have
like played around in CUR?

223
00:09:54,840 --> 00:09:56,073
Alright, a couple more.

224
00:09:57,150 --> 00:10:00,180
So, I think it's valuable
to just take a minute here

225
00:10:00,180 --> 00:10:03,690
and frame up some of the relations

226
00:10:03,690 --> 00:10:05,520
and stuff between the two data sets.

227
00:10:05,520 --> 00:10:08,610
One of the most common
questions I've got about FOCUS

228
00:10:08,610 --> 00:10:10,320
up to this point is like do these columns

229
00:10:10,320 --> 00:10:11,400
map to each other, right?

230
00:10:11,400 --> 00:10:14,700
And how do we map CUR 2.0
values to FOCUS values?

231
00:10:14,700 --> 00:10:17,730
So here's a quick example,
a non-exhaustive list.

232
00:10:17,730 --> 00:10:21,180
This is eight columns that I
picked out that map one-to-one.

233
00:10:21,180 --> 00:10:24,840
So this is things like your,
you know, account information,

234
00:10:24,840 --> 00:10:29,840
the charge periods, things
like the service names,

235
00:10:29,880 --> 00:10:31,380
resource IDs and tags, right?

236
00:10:31,380 --> 00:10:35,220
So if you look at usage
rows and in CUR 2.0,

237
00:10:35,220 --> 00:10:37,200
they map directly the values

238
00:10:37,200 --> 00:10:39,112
that you would see in FOCUS 1.0.

239
00:10:39,112 --> 00:10:42,030
There are also columns like blended cost

240
00:10:42,030 --> 00:10:45,240
and line item type that are related,

241
00:10:45,240 --> 00:10:47,190
but the values aren't
gonna map one to one.

242
00:10:47,190 --> 00:10:50,520
Sometimes things will map and sometimes

243
00:10:50,520 --> 00:10:54,360
there are requirements in
FOCUS 1.0 for specific values

244
00:10:54,360 --> 00:10:56,940
that you're not gonna see in CUR.

245
00:10:56,940 --> 00:10:58,770
So, they're related.

246
00:10:58,770 --> 00:11:02,310
One informs the other,
the CUR 2.0 values inform

247
00:11:02,310 --> 00:11:05,550
what you see in FOCUS, but
they're not gonna map one to one.

248
00:11:05,550 --> 00:11:06,780
There's also some net new columns

249
00:11:06,780 --> 00:11:08,940
that you get from adopting FOCUS.

250
00:11:08,940 --> 00:11:10,890
These are things like effective cost.

251
00:11:10,890 --> 00:11:14,250
Who here is a fan of
using net amortized view

252
00:11:14,250 --> 00:11:15,150
in Cost Explorer?

253
00:11:15,150 --> 00:11:18,090
Hands up if you've used
net amortized view.

254
00:11:18,090 --> 00:11:20,850
If you wished that was in in CUR.

255
00:11:20,850 --> 00:11:22,890
We don't have a column in there today,

256
00:11:22,890 --> 00:11:25,650
but there are ways, I'll
show you in a few minutes

257
00:11:25,650 --> 00:11:28,260
how to get this value out of
the cost and usage reports.

258
00:11:28,260 --> 00:11:31,980
But effective cost is essentially
the net amortized cost

259
00:11:31,980 --> 00:11:33,690
from Cost Explorer.

260
00:11:33,690 --> 00:11:37,200
So if you adopt FOCUS, you can
expect those values to align.

261
00:11:37,200 --> 00:11:39,720
We also have things like service category.

262
00:11:39,720 --> 00:11:42,990
So if you were using CUR to analyze

263
00:11:42,990 --> 00:11:45,210
all of your storage usage, let's say,

264
00:11:45,210 --> 00:11:47,190
or all of your compute usage,
you would have to build

265
00:11:47,190 --> 00:11:50,550
a big where statement, add
all the services, usage types,

266
00:11:50,550 --> 00:11:52,440
et cetera, that would, that you'd need

267
00:11:52,440 --> 00:11:54,840
to track there and report on.

268
00:11:54,840 --> 00:11:57,690
But you can use service category in FOCUS

269
00:11:57,690 --> 00:12:00,243
and it's already categorized for you.

270
00:12:03,300 --> 00:12:04,200
Cool.

271
00:12:04,200 --> 00:12:05,130
And like Jason had called out,

272
00:12:05,130 --> 00:12:10,130
we do ship five custom
columns into our FOCUS reports

273
00:12:10,980 --> 00:12:13,590
via data exports in the spec.

274
00:12:13,590 --> 00:12:15,210
They call out that, you
know, we can prefix,

275
00:12:15,210 --> 00:12:18,750
any provider can prefix
custom columns with an x_.

276
00:12:18,750 --> 00:12:20,670
These are valuable if you used

277
00:12:20,670 --> 00:12:22,410
some of these CUR 2.0 auto values, right?

278
00:12:22,410 --> 00:12:24,121
If you use cost categories today

279
00:12:24,121 --> 00:12:27,570
or if you're taking a
look for like operations

280
00:12:27,570 --> 00:12:30,960
or usage type, you can pull those values

281
00:12:30,960 --> 00:12:32,670
using these x_ columns.

282
00:12:32,670 --> 00:12:34,410
And then you'll see in our examples

283
00:12:34,410 --> 00:12:36,030
whenever you're joining these data sets

284
00:12:36,030 --> 00:12:38,730
from multiple providers, you're
gonna wanna leave these out

285
00:12:38,730 --> 00:12:40,560
unless you want a bunch
of nulls everywhere.

286
00:12:40,560 --> 00:12:43,260
So, alright.

287
00:12:43,260 --> 00:12:46,110
And then finally, before
we get to the demo,

288
00:12:46,110 --> 00:12:48,210
I wanna take a minute, a
few minutes here to touch,

289
00:12:48,210 --> 00:12:49,890
just talk about the architecture

290
00:12:49,890 --> 00:12:52,320
of like what we're working with today.

291
00:12:52,320 --> 00:12:54,900
So we have this FinOps account, right?

292
00:12:54,900 --> 00:12:57,210
This is where we're gonna
do all of our analysis.

293
00:12:57,210 --> 00:12:58,620
We're not gonna run this in a master payer

294
00:12:58,620 --> 00:13:00,750
because best practices say we
shouldn't run anything there

295
00:13:00,750 --> 00:13:02,280
if we can help it.

296
00:13:02,280 --> 00:13:04,050
And whenever you're trying to work

297
00:13:04,050 --> 00:13:06,600
with your AWS FOCUS data,

298
00:13:06,600 --> 00:13:08,550
we're gonna pull that data across, right?

299
00:13:08,550 --> 00:13:10,230
We're gonna replicate it from the bucket

300
00:13:10,230 --> 00:13:11,700
in your master payer account.

301
00:13:11,700 --> 00:13:15,120
We're gonna move it into this
FinOps account for analysis.

302
00:13:15,120 --> 00:13:17,130
And then you're gonna tie Glue together.

303
00:13:17,130 --> 00:13:20,290
Glue's going to crawl it,
add it to the data catalog

304
00:13:21,522 --> 00:13:24,900
and then we'll use Amazon
Athena to query that data.

305
00:13:24,900 --> 00:13:27,660
And if we were just doing AWS Data today,

306
00:13:27,660 --> 00:13:29,520
this is where this architecture
diagram would stop.

307
00:13:29,520 --> 00:13:31,440
But we want to show multiple clouds.

308
00:13:31,440 --> 00:13:33,780
So depending on, you know, the setup,

309
00:13:33,780 --> 00:13:37,200
you can use something like
the AWS Glue connectors

310
00:13:37,200 --> 00:13:39,060
to reach out to various data sources

311
00:13:39,060 --> 00:13:42,660
and pull other FOCUS data
in, put it in an S3 bucket.

312
00:13:42,660 --> 00:13:45,090
You can use AWS Lambda
to go out and grab things

313
00:13:45,090 --> 00:13:48,810
out of more custom kind
of places if needed.

314
00:13:48,810 --> 00:13:51,150
And some providers may provide options

315
00:13:51,150 --> 00:13:53,760
to push that FOCUS data into an S3 bucket.

316
00:13:53,760 --> 00:13:56,820
So a couple of these examples.

317
00:13:56,820 --> 00:14:00,240
Your use case may differ
depending on which one,

318
00:14:00,240 --> 00:14:03,540
but essentially the common
thing is get the data into S3.

319
00:14:03,540 --> 00:14:07,470
We're gonna use Glue to do
any transformations if needed

320
00:14:07,470 --> 00:14:10,746
and then do the cataloging
so that it's ready to go.

321
00:14:10,746 --> 00:14:14,130
And then finally, to tie it all together,

322
00:14:14,130 --> 00:14:18,330
today we're using a
consolidated view in Athena

323
00:14:18,330 --> 00:14:20,040
that unions all of this data together

324
00:14:20,040 --> 00:14:22,233
to give us one place to query,

325
00:14:23,370 --> 00:14:25,703
and we'll show you what
that view looks like too.

326
00:14:26,670 --> 00:14:31,080
And it doesn't have to be
Athena, you know, I jumped ahead.

327
00:14:31,080 --> 00:14:32,670
You can visualize on top of this too.

328
00:14:32,670 --> 00:14:34,800
So Athena can be a data
source for services

329
00:14:34,800 --> 00:14:38,250
like Amazon Managed Grafana,
for Amazon QuickSight,

330
00:14:38,250 --> 00:14:39,240
for any other BI tools

331
00:14:39,240 --> 00:14:41,880
that can tie into Athena as a data source.

332
00:14:41,880 --> 00:14:43,680
And then once you get
this consolidated view,

333
00:14:43,680 --> 00:14:46,650
you can build whatever graphics
visualizations you need.

334
00:14:46,650 --> 00:14:50,250
And again, it doesn't need to be Athena.

335
00:14:50,250 --> 00:14:52,860
Customers regularly use
Redshift here too, right?

336
00:14:52,860 --> 00:14:55,500
They may do scheduled data loads
or may run Lambda functions

337
00:14:55,500 --> 00:14:59,010
to get things loaded into
Redshift and then use things

338
00:14:59,010 --> 00:15:04,010
like the Redshift Query
Editor v2 to query that data

339
00:15:04,320 --> 00:15:08,370
and then same kind of
deal, any visualization

340
00:15:08,370 --> 00:15:10,540
solutions out there or
services like Grafana

341
00:15:10,540 --> 00:15:14,512
and QuickSight that can use
Redshift as a data source

342
00:15:14,512 --> 00:15:16,800
would work just as fine too.

343
00:15:16,800 --> 00:15:19,950
So, let's see FOCUS in action.

344
00:15:19,950 --> 00:15:23,070
So the first example
we'll have on our demo

345
00:15:23,070 --> 00:15:25,143
is talking through that Athena setup.

346
00:15:29,430 --> 00:15:31,170
Okay, quick spot check.

347
00:15:31,170 --> 00:15:32,370
Can everybody see this?

348
00:15:32,370 --> 00:15:34,203
Is this big enough?

349
00:15:35,430 --> 00:15:36,870
Okay, cool.

350
00:15:36,870 --> 00:15:37,740
Thumbs up. Great.

351
00:15:37,740 --> 00:15:41,160
So we're here in our Athena console.

352
00:15:41,160 --> 00:15:44,310
And just the quick tours,
you know we have our own,

353
00:15:44,310 --> 00:15:46,470
we have a database set up
just for FOCUS samples.

354
00:15:46,470 --> 00:15:51,060
We've pulled in a number
of tables of example data

355
00:15:51,060 --> 00:15:52,770
that we've been able to pull together

356
00:15:52,770 --> 00:15:57,090
from the Azure FinOps toolkit
from the FinOps Foundation

357
00:15:57,090 --> 00:15:59,103
and then our FOCUS reports.

358
00:16:00,060 --> 00:16:02,370
And then we built this
consolidation view down here,

359
00:16:02,370 --> 00:16:05,160
which is what we're gonna
be taking a look at now.

360
00:16:05,160 --> 00:16:10,160
So, this view is an example view

361
00:16:10,620 --> 00:16:12,510
that I've actually borrowed

362
00:16:12,510 --> 00:16:14,730
from the Cloud Intelligence Dashboards.

363
00:16:14,730 --> 00:16:16,530
Hopefully you've heard of them before.

364
00:16:16,530 --> 00:16:19,800
But if you haven't, you know,
it is a solution out here

365
00:16:19,800 --> 00:16:22,860
and they have a FOCUS dashboard available.

366
00:16:22,860 --> 00:16:25,380
And inside of here you can see a lot

367
00:16:25,380 --> 00:16:28,485
of very similar architecture diagrams.

368
00:16:28,485 --> 00:16:30,120
And out here on their
docks they actually have

369
00:16:30,120 --> 00:16:32,580
a published FOCUS consolidation view.

370
00:16:32,580 --> 00:16:33,413
So this is the same way

371
00:16:33,413 --> 00:16:36,660
that they have built their dashboards.

372
00:16:36,660 --> 00:16:38,965
So we've borrowed some
inspiration from them

373
00:16:38,965 --> 00:16:42,093
and then just tuned it kind
of as we needed for the demo.

374
00:16:44,340 --> 00:16:46,440
This line four here is pretty important.

375
00:16:46,440 --> 00:16:50,627
So remember how I called out
the availability zone example

376
00:16:51,570 --> 00:16:52,953
we had shown from the spec.

377
00:16:55,050 --> 00:16:57,420
It's not a mandatory field
so it may not be there.

378
00:16:57,420 --> 00:17:02,420
So there are times where we
use nulls to add these columns,

379
00:17:02,820 --> 00:17:03,770
so the unions work.

380
00:17:04,860 --> 00:17:06,870
So our first one here is just pulling in

381
00:17:06,870 --> 00:17:09,600
our FOCUS v1.0 report.

382
00:17:09,600 --> 00:17:11,760
And you can see we haven't changed much.

383
00:17:11,760 --> 00:17:13,410
We selected just about every column

384
00:17:13,410 --> 00:17:15,330
except for the custom columns.

385
00:17:15,330 --> 00:17:18,810
The one thing to call out
is that our tags field is,

386
00:17:18,810 --> 00:17:20,490
it's a map, map type.

387
00:17:20,490 --> 00:17:21,323
- [Jason] Map stream.

388
00:17:21,323 --> 00:17:22,920
- [Justin] It's a map stream.

389
00:17:22,920 --> 00:17:26,580
And the other examples that
we had were were in JSON

390
00:17:26,580 --> 00:17:28,620
and that would be a
little tough to work with.

391
00:17:28,620 --> 00:17:32,742
So we did cast our tags
to JSON and do a format

392
00:17:32,742 --> 00:17:35,242
just so that things are
nice and consistent today.

393
00:17:36,420 --> 00:17:38,070
Not necessary but is gonna make the demo

394
00:17:38,070 --> 00:17:39,240
a little bit easier.

395
00:17:39,240 --> 00:17:40,890
And then we do a union hall here

396
00:17:40,890 --> 00:17:44,010
where we pulled in the Azure
sample from the FinOps toolkit

397
00:17:44,010 --> 00:17:47,258
and you can see places like
availability zone here,

398
00:17:47,258 --> 00:17:49,770
we've nulled out because
this sample data set

399
00:17:49,770 --> 00:17:52,170
didn't even have that column,
but for the union to work

400
00:17:52,170 --> 00:17:53,220
we needed to have something there.

401
00:17:53,220 --> 00:17:55,950
So it's filled with nulls for now.

402
00:17:55,950 --> 00:17:57,180
And then there are some time places

403
00:17:57,180 --> 00:17:59,550
where we've done some
timestamp formatting,

404
00:17:59,550 --> 00:18:01,710
and that's just again for consistency.

405
00:18:01,710 --> 00:18:05,700
So like casting from ISO 8601

406
00:18:05,700 --> 00:18:07,740
to something a little bit more friendly

407
00:18:07,740 --> 00:18:09,040
for us to work with today.

408
00:18:10,290 --> 00:18:14,160
Alright, and then finally we
did one more union all here

409
00:18:14,160 --> 00:18:16,917
with the FinOps Foundation
sample and this includes

410
00:18:16,917 --> 00:18:20,490
lots of sample data
from multiple providers.

411
00:18:20,490 --> 00:18:23,130
Very similar story just dealing with

412
00:18:23,130 --> 00:18:26,250
some formatting for date times.

413
00:18:26,250 --> 00:18:28,320
For this one, we did have to use coalesce

414
00:18:28,320 --> 00:18:31,590
because some of the
samples had null values

415
00:18:31,590 --> 00:18:33,840
and I don't know if you've
ever tried to multiply

416
00:18:33,840 --> 00:18:36,510
or divide by null, but it
doesn't work out very well.

417
00:18:36,510 --> 00:18:38,370
So we used coalesce here to replace

418
00:18:38,370 --> 00:18:40,503
any of those null values with zeros.

419
00:18:43,410 --> 00:18:44,850
And I mean that's it.

420
00:18:44,850 --> 00:18:49,080
So this view and I can
give you a quick preview

421
00:18:49,080 --> 00:18:51,080
of kind of what we're dealing with here.

422
00:18:58,500 --> 00:19:02,130
Again, this is just a quick
sample of like the first,

423
00:19:02,130 --> 00:19:06,063
you know, first couple
columns that we see.

424
00:19:07,860 --> 00:19:10,223
It's everything that I
guess we would've expected.

425
00:19:11,730 --> 00:19:13,440
Let's go ahead and close outta this.

426
00:19:13,440 --> 00:19:17,910
Now that we've seen how to set this up,

427
00:19:17,910 --> 00:19:21,570
Jason, do you want to walk us through some

428
00:19:21,570 --> 00:19:24,420
of the cost columns and
how to derive savings

429
00:19:24,420 --> 00:19:26,280
and how to think about
like how the different

430
00:19:26,280 --> 00:19:27,630
cost columns work?

431
00:19:27,630 --> 00:19:28,860
- [Jason] Sure.

432
00:19:28,860 --> 00:19:31,200
So as the person who manage cloud costs

433
00:19:31,200 --> 00:19:35,400
and usage data, you
were likely to be asked

434
00:19:35,400 --> 00:19:37,650
the questions like how much have we spent

435
00:19:37,650 --> 00:19:42,180
on invoice last month or how
much money would our usage cost

436
00:19:42,180 --> 00:19:44,039
going to be look like if we do not have

437
00:19:44,039 --> 00:19:47,910
any commitment purchases or how much

438
00:19:47,910 --> 00:19:51,420
will be the amortized cost
if we purchase everything

439
00:19:51,420 --> 00:19:54,180
upfront with the savings plans.

440
00:19:54,180 --> 00:19:56,640
So this can be explained
with full data set

441
00:19:56,640 --> 00:19:59,850
via the full standardized cost today.

442
00:19:59,850 --> 00:20:01,500
Lemme just quickly show you that.

443
00:20:06,330 --> 00:20:10,530
So in the FOCUS data set you
can sum up your build cost,

444
00:20:10,530 --> 00:20:13,380
which is very simple as a build cost.

445
00:20:13,380 --> 00:20:17,433
And this give you the the
cost basis of your invoice.

446
00:20:18,390 --> 00:20:22,230
And for running this
query and you select them

447
00:20:22,230 --> 00:20:24,870
and just hit run, and this will give you

448
00:20:24,870 --> 00:20:27,870
the exact amount that
matches to your invoice.

449
00:20:27,870 --> 00:20:30,330
With FOCUS 1.2 invoice ID columns,

450
00:20:30,330 --> 00:20:33,540
you can actually add in
your invoice ID column

451
00:20:33,540 --> 00:20:35,820
and will show the invoice
that you have paid

452
00:20:35,820 --> 00:20:38,283
for each of the invoice ID.

453
00:20:39,360 --> 00:20:42,090
So this is the help you to
expand the first question,

454
00:20:42,090 --> 00:20:46,650
how much money have you
spent with the invoice

455
00:20:46,650 --> 00:20:48,660
across different providers?

456
00:20:48,660 --> 00:20:51,543
So let me remove that and
answer the second question.

457
00:20:52,590 --> 00:20:55,830
How much would we spend if
we do not have any discounts

458
00:20:55,830 --> 00:20:58,920
or commitment purchases with AWS?

459
00:20:58,920 --> 00:21:02,250
So for this question you
can use the list cost column

460
00:21:02,250 --> 00:21:05,250
which is the equivalent
to the own demand cost

461
00:21:05,250 --> 00:21:07,140
that showed up in the data set.

462
00:21:07,140 --> 00:21:11,070
And for this column will
show your usage costs

463
00:21:11,070 --> 00:21:14,040
without any discounts and
accompaniment purchases.

464
00:21:14,040 --> 00:21:17,490
For correlated column, you
can use a contracted cost

465
00:21:17,490 --> 00:21:20,850
which represent the
cost with the discounts

466
00:21:20,850 --> 00:21:23,043
but without the commitment purchases.

467
00:21:24,000 --> 00:21:28,070
And third, to answer
questions is what would be

468
00:21:29,100 --> 00:21:31,470
my amortized cost going to be look like

469
00:21:31,470 --> 00:21:34,770
if I purchase everything
upfront with the save spend?

470
00:21:34,770 --> 00:21:38,160
So this where Justin will
give a more deep dive here,

471
00:21:38,160 --> 00:21:41,760
but we introduce effective cost column,

472
00:21:41,760 --> 00:21:45,750
which shows your amortized
cost with order discounts

473
00:21:45,750 --> 00:21:50,070
and with order commitment
purchases, reduced rate impact.

474
00:21:50,070 --> 00:21:52,440
So after knowing those three cost columns,

475
00:21:52,440 --> 00:21:55,470
you can do a simple math
by using your list cost

476
00:21:55,470 --> 00:22:00,000
to minus your contract cost to know

477
00:22:00,000 --> 00:22:03,333
how much savings you have
achieved on the discounts.

478
00:22:06,930 --> 00:22:09,340
By using your contracted cost

479
00:22:10,260 --> 00:22:14,040
and to minus your effective costs,

480
00:22:14,040 --> 00:22:16,830
you will know how much
commitment purchase savings

481
00:22:16,830 --> 00:22:19,960
have achieved with your account.

482
00:22:23,100 --> 00:22:27,360
And you can also even do
the percentage of savings

483
00:22:27,360 --> 00:22:30,840
by using your sum of
list cost minus your sum

484
00:22:30,840 --> 00:22:34,080
of effective cost to
get your total savings

485
00:22:34,080 --> 00:22:36,040
and divide by the sum of list cost

486
00:22:37,170 --> 00:22:42,170
and times a hundred to get
the percentage discount.

487
00:22:46,830 --> 00:22:49,020
So in here we have to make a note

488
00:22:49,020 --> 00:22:51,450
that you probably already heard,

489
00:22:51,450 --> 00:22:54,120
I keep emphasizing usage.

490
00:22:54,120 --> 00:22:57,480
In FOCUS data set, the usage
record and the purchase record

491
00:22:57,480 --> 00:23:00,150
are both represented in the nineteens.

492
00:23:00,150 --> 00:23:03,840
In order to understand
different hypothetical scenarios

493
00:23:03,840 --> 00:23:06,960
with discount without a
commitment, you will need

494
00:23:06,960 --> 00:23:10,290
to apply one more filter,
which is called chart category.

495
00:23:10,290 --> 00:23:14,190
And you want to navigate
to the usage record only.

496
00:23:14,190 --> 00:23:16,590
This is because for the
situations like when you have

497
00:23:16,590 --> 00:23:20,310
a savings plan purchase or
upfront with a hundred dollars

498
00:23:20,310 --> 00:23:22,860
and if you have spent
that a hundred dollars

499
00:23:22,860 --> 00:23:25,110
on your cover usages already,

500
00:23:25,110 --> 00:23:27,270
if you don't apply this filter

501
00:23:27,270 --> 00:23:31,110
you will end up getting
your list cost of $200.

502
00:23:31,110 --> 00:23:33,540
So we want to make sure
when you do the analysis

503
00:23:33,540 --> 00:23:38,370
for the usage, make sure apply
this filters into a record.

504
00:23:38,370 --> 00:23:40,983
Okay, let's run the query.

505
00:23:42,210 --> 00:23:43,440
Okay.

506
00:23:43,440 --> 00:23:44,310
- [Justin] So, you may notice

507
00:23:44,310 --> 00:23:47,460
that we've been highlighting
subsections here.

508
00:23:47,460 --> 00:23:50,760
It's a way in Athena to
run like just sections

509
00:23:50,760 --> 00:23:53,640
of your query with a
bunch of the other stuff

510
00:23:53,640 --> 00:23:55,500
that we have further down at my break.

511
00:23:55,500 --> 00:23:57,710
So just highlight everything
that you wanna run there.

512
00:23:57,710 --> 00:23:58,625
- [Jason] Oh yes.

513
00:23:58,625 --> 00:24:00,330
- [Justin] Oh, and line seven.

514
00:24:00,330 --> 00:24:01,680
- [Jason] Yes, contracted cost.

515
00:24:01,680 --> 00:24:02,970
- [Justin] There we go.
- [Jason] Nice catch.

516
00:24:02,970 --> 00:24:05,760
You guys are already FOCUS satisfied.

517
00:24:05,760 --> 00:24:06,750
- [Justin] If we make typos,

518
00:24:06,750 --> 00:24:09,600
please yell them at us. (chuckles)

519
00:24:09,600 --> 00:24:11,190
- [Jason] Okay.

520
00:24:11,190 --> 00:24:12,033
Let's run it.

521
00:24:13,740 --> 00:24:15,183
Okay, let's run it again.

522
00:24:19,890 --> 00:24:20,940
Perfect.

523
00:24:20,940 --> 00:24:24,060
So this shows your usage record as showing

524
00:24:24,060 --> 00:24:27,510
if you do not have commitment
purchases or discounts,

525
00:24:27,510 --> 00:24:30,787
you will be end up paying for
the same usage for $5,130.

526
00:24:33,240 --> 00:24:35,440
And with the discounts
it's going to be less

527
00:24:36,483 --> 00:24:39,570
and your amortized cost going to be $4,300

528
00:24:39,570 --> 00:24:43,320
and your discount saving is 537.

529
00:24:43,320 --> 00:24:48,030
And you will also know your
total savings discount of 16%.

530
00:24:48,030 --> 00:24:50,760
So let me hand over to Justin to do

531
00:24:50,760 --> 00:24:54,450
a more advanced techniques
for the FOCUS queries.

532
00:24:54,450 --> 00:24:55,515
And one thing you need to note

533
00:24:55,515 --> 00:24:57,630
is what queries that we are showing today,

534
00:24:57,630 --> 00:25:00,720
you can also run against
the FOCUS 1.2 data set,

535
00:25:00,720 --> 00:25:02,463
so it's backward compatible.

536
00:25:05,580 --> 00:25:07,920
- [Justin] Alright, so let's
do a super quick demo here

537
00:25:07,920 --> 00:25:11,010
of amortized costs and effective costs.

538
00:25:11,010 --> 00:25:13,570
We had talked a little bit
about how this is possible

539
00:25:13,570 --> 00:25:18,570
with CUR, so I want to give
you just a quick glance

540
00:25:18,570 --> 00:25:20,340
at what that would look like.

541
00:25:20,340 --> 00:25:23,763
So if you're familiar with CUR 2.0,

542
00:25:24,690 --> 00:25:26,950
you'll know that this
may be a little harder

543
00:25:29,919 --> 00:25:31,470
than it would be if you used FOCUS.

544
00:25:31,470 --> 00:25:34,893
So let's see, we want to
grab billing, start date.

545
00:25:36,390 --> 00:25:40,800
Let's grab the, we're doing
a multi-cloud talk today,

546
00:25:40,800 --> 00:25:43,443
so let's grab the billing
entity and the payer.

547
00:25:46,320 --> 00:25:49,530
And we'll add this amortized
cost column, right?

548
00:25:49,530 --> 00:25:50,980
But that's not a column here.

549
00:25:53,906 --> 00:25:56,070
Has anyone ever used
the CUR Query Library,

550
00:25:56,070 --> 00:25:58,560
Cost and Usage Query Library,
hands up if you've ever heard

551
00:25:58,560 --> 00:26:00,750
of our library out there.

552
00:26:00,750 --> 00:26:03,870
So we have this, it's part
of well architected labs,

553
00:26:03,870 --> 00:26:06,990
chockfull of CUR and FOCUS queries

554
00:26:06,990 --> 00:26:09,570
if you're looking to get started
with some of this analysis.

555
00:26:09,570 --> 00:26:11,700
And one of the ones that we have out here

556
00:26:11,700 --> 00:26:13,770
under our library help section

557
00:26:13,770 --> 00:26:18,750
is how to calculate
amortize cost with CUR.

558
00:26:18,750 --> 00:26:20,850
So I've already done the hard work here,

559
00:26:20,850 --> 00:26:22,950
I'm just gonna borrow this so I don't have

560
00:26:22,950 --> 00:26:26,530
to take it all back out
and we'll paste it in here

561
00:26:28,470 --> 00:26:31,830
and then we're gonna FOCUS
in on our sample data set

562
00:26:31,830 --> 00:26:34,320
has all this data from September.

563
00:26:34,320 --> 00:26:38,253
I'm gonna borrow Jason's filter, alright?

564
00:26:40,080 --> 00:26:42,660
And then we're gonna see
what our amortized costs

565
00:26:42,660 --> 00:26:45,873
look like in this payer that
we're running it against.

566
00:26:48,990 --> 00:26:52,590
And I didn't add my table.

567
00:26:52,590 --> 00:26:54,750
I'm not working in the
same space on this one

568
00:26:54,750 --> 00:26:56,340
'cause this is our FOCUS samples,

569
00:26:56,340 --> 00:26:58,790
so I'm gonna grab it out
of a different database.

570
00:27:02,610 --> 00:27:04,680
And you know what, I did this earlier,

571
00:27:04,680 --> 00:27:06,090
I already used the FOCUS column,

572
00:27:06,090 --> 00:27:08,763
and I shouldn't have. (chuckles)

573
00:27:10,500 --> 00:27:11,760
There we go.

574
00:27:11,760 --> 00:27:12,603
Okay.

575
00:27:16,110 --> 00:27:18,720
So you can see here,
to get amortized costs,

576
00:27:18,720 --> 00:27:23,720
we had to copy and paste this
like nine line case statement

577
00:27:23,910 --> 00:27:28,140
where we're evaluating different
parts of the values here

578
00:27:28,140 --> 00:27:30,120
to determine what number we should use.

579
00:27:30,120 --> 00:27:32,610
And you can see for this
payer account we had 2,208.35

580
00:27:32,610 --> 00:27:34,680
as amortized, but we said effective cost

581
00:27:34,680 --> 00:27:36,210
was net amortized, right?

582
00:27:36,210 --> 00:27:38,010
So how do we figure out net amortized?

583
00:27:38,010 --> 00:27:42,063
So we have to pull in those
net fields, those net columns.

584
00:27:43,170 --> 00:27:46,260
And unfortunately for this demo
count there's no discounts,

585
00:27:46,260 --> 00:27:47,970
so a lot of those columns are null.

586
00:27:47,970 --> 00:27:50,520
We're using coalesce here to make sure

587
00:27:50,520 --> 00:27:51,900
that we handle those nulls correctly.

588
00:27:51,900 --> 00:27:56,520
If you've never used coalesce,
we have have another example

589
00:27:56,520 --> 00:27:58,260
in here and I'll show it the next time,

590
00:27:58,260 --> 00:28:00,150
but on the next query.

591
00:28:00,150 --> 00:28:03,060
But we're just gonna copy and
paste this net amortized one

592
00:28:03,060 --> 00:28:04,140
over our amortized cost.

593
00:28:04,140 --> 00:28:07,140
And what it should do is any
place where there's a value

594
00:28:07,140 --> 00:28:10,920
in our related net columns,
it will use those first

595
00:28:10,920 --> 00:28:14,820
else it'll grab our non amortized one.

596
00:28:14,820 --> 00:28:18,363
So this should give us the same values.

597
00:28:22,020 --> 00:28:22,853
Alright, there we go.

598
00:28:22,853 --> 00:28:25,350
So this payer, 2,208.35, great.

599
00:28:25,350 --> 00:28:26,610
So what would this look like

600
00:28:26,610 --> 00:28:28,470
if we were just using FOCUS today?

601
00:28:28,470 --> 00:28:30,570
So the same exact query in FOCUS

602
00:28:30,570 --> 00:28:34,350
is just selecting billing period start,

603
00:28:34,350 --> 00:28:38,040
provider name, billing account ID,

604
00:28:38,040 --> 00:28:43,040
and an effective cost instead
of a nine line case statement.

605
00:28:45,180 --> 00:28:47,700
And we're gonna grab this from
our FOCUS consolidated view

606
00:28:47,700 --> 00:28:51,167
that we set up earlier that should give us

607
00:28:53,040 --> 00:28:55,530
not just this payer account.

608
00:28:55,530 --> 00:28:56,682
- [Jason] I see.

609
00:28:56,682 --> 00:28:58,682
- [Justin] Oh, sum effective cost, yeah.

610
00:28:59,700 --> 00:29:00,603
Gotta sum this up.

611
00:29:11,700 --> 00:29:12,533
Great.

612
00:29:12,533 --> 00:29:13,366
And what we're getting now

613
00:29:13,366 --> 00:29:16,950
is not just our 228.35 here, right,

614
00:29:16,950 --> 00:29:18,750
same value, from this payer,

615
00:29:18,750 --> 00:29:20,730
but now we've pulled in our data

616
00:29:20,730 --> 00:29:22,773
from other providers, other accounts.

617
00:29:25,260 --> 00:29:26,093
Cool.

618
00:29:26,093 --> 00:29:27,570
So that's one of the ways

619
00:29:27,570 --> 00:29:29,850
that you can save some time
not having to build out

620
00:29:29,850 --> 00:29:34,850
your own effective amortized,
net amortized cost field.

621
00:29:34,920 --> 00:29:38,370
So let's talk about the
last example we have here

622
00:29:38,370 --> 00:29:42,720
where we've been tasked to figure out

623
00:29:42,720 --> 00:29:45,000
where workloads may be
running across accounts

624
00:29:45,000 --> 00:29:46,920
and/or providers.

625
00:29:46,920 --> 00:29:51,060
Let's say our boss has come to us

626
00:29:51,060 --> 00:29:56,060
and they've asked us to
track down where like our foo

627
00:29:57,695 --> 00:30:01,680
and far and bar applications are running

628
00:30:01,680 --> 00:30:02,943
and where they cross.

629
00:30:04,980 --> 00:30:06,570
So an example of the data

630
00:30:06,570 --> 00:30:07,860
might look something like this, right?

631
00:30:07,860 --> 00:30:10,920
They show up with a crude
drawing that says show me

632
00:30:10,920 --> 00:30:15,920
where like production
foo is 50% in one account

633
00:30:15,990 --> 00:30:19,334
and 50% in another account
and maybe where things

634
00:30:19,334 --> 00:30:21,633
span different providers as well.

635
00:30:22,680 --> 00:30:23,550
So this is kind of like

636
00:30:23,550 --> 00:30:25,550
what we're working backwards from today.

637
00:30:26,640 --> 00:30:27,540
So the first thing we wanna do

638
00:30:27,540 --> 00:30:29,340
is pull in our cost data, right?

639
00:30:29,340 --> 00:30:33,513
Let's figure out where all of this is.

640
00:30:37,050 --> 00:30:41,070
And this should give us
again very similar view

641
00:30:41,070 --> 00:30:44,730
to what we saw in our effective cost,

642
00:30:44,730 --> 00:30:47,070
one we just did, but we
brought in the account name now

643
00:30:47,070 --> 00:30:49,920
so we can kind of track down
provider's account names

644
00:30:49,920 --> 00:30:51,993
and how much that effective cost was.

645
00:30:55,410 --> 00:30:56,943
So now that we have that,

646
00:30:58,710 --> 00:31:00,660
we need to pull this across
apps and environments, right?

647
00:31:00,660 --> 00:31:02,250
We had production, we had development.

648
00:31:02,250 --> 00:31:03,330
Where are we gonna pull this from?

649
00:31:03,330 --> 00:31:04,830
Anybody have an idea where we'd pull

650
00:31:04,830 --> 00:31:06,180
those kinds of values from?

651
00:31:07,800 --> 00:31:08,633
- [Audience Member] Tags.

652
00:31:08,633 --> 00:31:09,810
- [Justin] Tags, exactly.

653
00:31:09,810 --> 00:31:12,240
So what did the tags look like?

654
00:31:12,240 --> 00:31:15,810
So, let's query our tags column here.

655
00:31:15,810 --> 00:31:16,770
We're gonna use distinct,

656
00:31:16,770 --> 00:31:19,830
so that we can just grab unique values

657
00:31:19,830 --> 00:31:21,150
so we can have an understanding

658
00:31:21,150 --> 00:31:23,580
of like what we're working with.

659
00:31:23,580 --> 00:31:25,650
And great, you can see it's all JSON

660
00:31:25,650 --> 00:31:29,010
thankfully for the JSON
format we did in the view.

661
00:31:29,010 --> 00:31:32,310
But you can see here that in some places

662
00:31:32,310 --> 00:31:36,270
we've used ENV for the environment key.

663
00:31:36,270 --> 00:31:38,310
Some other teams used environment.

664
00:31:38,310 --> 00:31:41,220
Ah, man, those teams, sometimes
they don't follow the tags

665
00:31:41,220 --> 00:31:43,020
exactly as we hope, right?

666
00:31:43,020 --> 00:31:45,240
And then sometimes we have
things like application

667
00:31:45,240 --> 00:31:49,860
and other places we have app
or something else, right?

668
00:31:49,860 --> 00:31:51,870
So we have to be able to like deal

669
00:31:51,870 --> 00:31:54,420
with all of these different values.

670
00:31:54,420 --> 00:31:59,420
So how do we extract some of
these values using Athena?

671
00:32:00,150 --> 00:32:02,940
So I've come up with two different ways

672
00:32:02,940 --> 00:32:03,840
that I think we could work this.

673
00:32:03,840 --> 00:32:06,000
One of them is using JSON extract,

674
00:32:06,000 --> 00:32:07,300
one of 'em is using RegEx.

675
00:32:08,970 --> 00:32:09,810
Does anyone have a preference?

676
00:32:09,810 --> 00:32:10,740
Hands up if you think we should do

677
00:32:10,740 --> 00:32:12,630
the JSON extract one first.

678
00:32:12,630 --> 00:32:15,030
Any idea, any preference?

679
00:32:15,030 --> 00:32:15,863
How about the RegEx?

680
00:32:15,863 --> 00:32:18,120
Anybody interested to see the RegEx one?

681
00:32:18,120 --> 00:32:19,320
We'll start with the JSON one.

682
00:32:19,320 --> 00:32:21,753
So the way JSON extract works,

683
00:32:22,740 --> 00:32:24,870
this is the general pattern you'll follow.

684
00:32:24,870 --> 00:32:25,800
You're gonna call this function.

685
00:32:25,800 --> 00:32:27,300
We're gonna run this over tags.

686
00:32:27,300 --> 00:32:29,580
And then you'd wanna run
this against the path.

687
00:32:29,580 --> 00:32:33,540
So if it's .env, for the key,

688
00:32:33,540 --> 00:32:35,100
that should work just fine.

689
00:32:35,100 --> 00:32:38,730
But like we saw if we run this

690
00:32:38,730 --> 00:32:40,780
it's only gonna give us a subset of them.

691
00:32:41,670 --> 00:32:43,500
So we have like a rough idea on what some

692
00:32:43,500 --> 00:32:45,900
of the environments are
if they use the EMV key.

693
00:32:47,610 --> 00:32:50,820
So in this example we used
another coalesce here,

694
00:32:50,820 --> 00:32:53,880
which again will give us
the first non-null value

695
00:32:53,880 --> 00:32:56,250
in a set of values that you feed it.

696
00:32:56,250 --> 00:32:58,860
You can use, there's
other ways to do this too,

697
00:32:58,860 --> 00:33:00,780
but we're gonna stick with coalesce today

698
00:33:00,780 --> 00:33:03,240
where we can like copy and paste this,

699
00:33:03,240 --> 00:33:06,933
and grab like EMV, we'll
grab like capital EMV,

700
00:33:07,846 --> 00:33:11,760
we'll grab environment
and this should give us

701
00:33:15,780 --> 00:33:19,290
an expanded list of values
here using JSON extract.

702
00:33:19,290 --> 00:33:21,210
Again this is gonna be
dependent on getting everything

703
00:33:21,210 --> 00:33:23,523
into like a nice consistent JSON format.

704
00:33:26,910 --> 00:33:27,930
And we can see here that we have

705
00:33:27,930 --> 00:33:29,973
a couple more values in here. Great.

706
00:33:32,340 --> 00:33:33,660
So, what if we don't have everything

707
00:33:33,660 --> 00:33:34,980
in a nice pretty JSON format?

708
00:33:34,980 --> 00:33:37,390
Well we can still use things like RegEx

709
00:33:38,385 --> 00:33:39,450
to just run it over a string, right?

710
00:33:39,450 --> 00:33:41,190
And JSON is also just a string,

711
00:33:41,190 --> 00:33:42,890
so it works just as fine for that.

712
00:33:44,520 --> 00:33:45,570
Same kind of syntax.

713
00:33:45,570 --> 00:33:46,800
We're gonna call RegEx extract.

714
00:33:46,800 --> 00:33:48,480
We're gonna run this against tags.

715
00:33:48,480 --> 00:33:51,540
And I am not gonna type
a RegEx pattern out

716
00:33:51,540 --> 00:33:53,390
in front of all of you unfortunately.

717
00:33:55,260 --> 00:33:56,220
These are all gonna be shared

718
00:33:56,220 --> 00:33:57,990
in the code examples at the end.

719
00:33:57,990 --> 00:34:00,570
But you know, here are some
examples of different ways

720
00:34:00,570 --> 00:34:01,800
that we can use RegEx extract

721
00:34:01,800 --> 00:34:04,050
to get things like environment.

722
00:34:04,050 --> 00:34:06,840
So we're gonna drop this here

723
00:34:06,840 --> 00:34:07,830
and talk through it real quick.

724
00:34:07,830 --> 00:34:09,540
We're gonna run RegEx against tags.

725
00:34:09,540 --> 00:34:10,590
This is our pattern.

726
00:34:10,590 --> 00:34:12,690
We're looking for any keys that have one

727
00:34:12,690 --> 00:34:16,080
of these four environment patterns.

728
00:34:16,080 --> 00:34:18,390
And then we're gonna be finding anything

729
00:34:18,390 --> 00:34:21,180
that's after the space
colon and double quotes

730
00:34:21,180 --> 00:34:23,130
and we're gonna grab that value.

731
00:34:23,130 --> 00:34:25,560
So that's what this should do for us.

732
00:34:25,560 --> 00:34:27,483
And let's see what that looks like.

733
00:34:28,800 --> 00:34:33,393
See if it looks any different
than our JSON extract.

734
00:34:40,380 --> 00:34:43,560
Okay, so you can see
with our RegEx pattern

735
00:34:43,560 --> 00:34:45,810
we actually captured a
little bit more values.

736
00:34:45,810 --> 00:34:48,030
So a little bit more flexibility here

737
00:34:48,030 --> 00:34:51,240
and I think it's a lot
nicer than having a coalesce

738
00:34:51,240 --> 00:34:54,090
or something with four or five
different values in there.

739
00:34:55,590 --> 00:34:56,630
And the other difference here

740
00:34:56,630 --> 00:34:58,320
is that you can see JSON extract

741
00:34:58,320 --> 00:34:59,940
wraps things in double quotes.

742
00:34:59,940 --> 00:35:03,120
The RegEx, the way that I
wrote it won't, won't wrap it.

743
00:35:03,120 --> 00:35:06,690
So let's, we got environment,
we still need application,

744
00:35:06,690 --> 00:35:09,540
so let's go grab our pattern
here for application.

745
00:35:09,540 --> 00:35:14,010
And you can see I've accounted
for capitalization changes,

746
00:35:14,010 --> 00:35:16,560
I've accounted for some of these teams

747
00:35:16,560 --> 00:35:19,320
using things like project
and the FinOps team

748
00:35:19,320 --> 00:35:21,360
used their own FinOps tag.

749
00:35:21,360 --> 00:35:24,570
So, we've pulled in the
data for all of these

750
00:35:24,570 --> 00:35:27,180
and we'll go ahead and just take

751
00:35:27,180 --> 00:35:29,430
the JSON extract outta here for now.

752
00:35:29,430 --> 00:35:33,720
This should give us a list
of distinct combinations

753
00:35:33,720 --> 00:35:37,320
between environment and application.

754
00:35:37,320 --> 00:35:40,740
So now we can see these
are all the environment

755
00:35:40,740 --> 00:35:45,183
and tag application
combinations in our FOCUS data.

756
00:35:46,020 --> 00:35:47,154
Cool.

757
00:35:47,154 --> 00:35:49,230
So this is how we're gonna
need to pull this data

758
00:35:49,230 --> 00:35:51,240
and to join it with this cost data now

759
00:35:51,240 --> 00:35:53,240
to start figuring out that distribution.

760
00:35:56,280 --> 00:35:58,560
So we figured out cost, we
figured this extraction,

761
00:35:58,560 --> 00:36:00,390
we're gonna join them
now and we're gonna try

762
00:36:00,390 --> 00:36:03,240
to figure out if this foo app
or whichever one of these apps

763
00:36:03,240 --> 00:36:06,523
is split like 50/50 between accounts,

764
00:36:06,523 --> 00:36:09,630
60/40 across providers,
something like that.

765
00:36:09,630 --> 00:36:10,530
So the first thing we're gonna do

766
00:36:10,530 --> 00:36:12,570
is take that first query we typed up

767
00:36:12,570 --> 00:36:14,370
and we wrap it in a with statement.

768
00:36:14,370 --> 00:36:17,490
So that lets us take
these results down here

769
00:36:17,490 --> 00:36:19,170
that we've been seeing the
whole time we're running them

770
00:36:19,170 --> 00:36:20,670
and put them in like
another temporary table,

771
00:36:20,670 --> 00:36:22,320
so we can do more work.

772
00:36:22,320 --> 00:36:26,640
So you can see here, we'll
run this subsection again

773
00:36:26,640 --> 00:36:29,880
just so folks can see we've
added some effective cost

774
00:36:29,880 --> 00:36:31,110
into the mix here.

775
00:36:31,110 --> 00:36:35,280
So this should give us our
provider, our account name,

776
00:36:35,280 --> 00:36:38,220
the environment and app tags
and then this effective cost.

777
00:36:38,220 --> 00:36:40,350
So you can see we have, you know,

778
00:36:40,350 --> 00:36:42,840
a couple of production apps
here costing a couple dollars

779
00:36:42,840 --> 00:36:44,290
in a couple different places.

780
00:36:49,020 --> 00:36:49,853
Cool.

781
00:36:51,900 --> 00:36:53,250
Now that we've wrapped that in a with,

782
00:36:53,250 --> 00:36:55,770
we can go ahead and run queries

783
00:36:55,770 --> 00:36:58,500
against this result set down here.

784
00:36:58,500 --> 00:36:59,970
What this is gonna let us do

785
00:36:59,970 --> 00:37:02,460
is we're gonna use window functions.

786
00:37:02,460 --> 00:37:04,710
I don't know if anyone's
ever used a window function,

787
00:37:04,710 --> 00:37:08,670
but we're going to, for
the sake of calculation,

788
00:37:08,670 --> 00:37:12,420
add each like total cost to the row

789
00:37:12,420 --> 00:37:14,190
for either that environment or that app,

790
00:37:14,190 --> 00:37:18,000
so that we can do more calculations here.

791
00:37:18,000 --> 00:37:19,680
So we're gonna do some effective costs

792
00:37:19,680 --> 00:37:21,540
and we're gonna use over here.

793
00:37:21,540 --> 00:37:23,340
That's gonna give us our window function.

794
00:37:23,340 --> 00:37:27,813
We're gonna partition this
by the RegEx environment tag.

795
00:37:29,460 --> 00:37:33,420
And what this is gonna give us

796
00:37:33,420 --> 00:37:37,383
is show you that column that it adds.

797
00:37:41,010 --> 00:37:46,010
So what this is saying now is
we have this last column here

798
00:37:46,140 --> 00:37:48,900
that shows us the environment cost, right?

799
00:37:48,900 --> 00:37:52,290
So if we scroll over here,
this is saying like our tag

800
00:37:52,290 --> 00:37:54,030
for non-production environments

801
00:37:54,030 --> 00:37:56,160
costs a total of 79.38,

802
00:37:56,160 --> 00:37:58,080
which doesn't seem
particularly interesting

803
00:37:58,080 --> 00:37:59,880
when it's the same
thing as effective cost,

804
00:37:59,880 --> 00:38:02,820
But as we scroll down and
take a look at like prod,

805
00:38:02,820 --> 00:38:06,210
this is our prod environment cost us $314.

806
00:38:06,210 --> 00:38:09,960
That lets us do some calculations
for like how much this row

807
00:38:09,960 --> 00:38:12,783
lines up with its aggregate here.

808
00:38:18,600 --> 00:38:21,090
We're gonna call this total
and the effective cost.

809
00:38:21,090 --> 00:38:23,520
And then what we'll do is
we're actually gonna add

810
00:38:23,520 --> 00:38:25,260
a second calculation
'cause we're not doing this

811
00:38:25,260 --> 00:38:27,210
just for environments, we wanna do this

812
00:38:27,210 --> 00:38:28,530
for apps and environments.

813
00:38:28,530 --> 00:38:33,530
So we're gonna add the
app tag in here as well.

814
00:38:33,750 --> 00:38:36,060
And what this will do is this
will show our environment

815
00:38:36,060 --> 00:38:40,053
and application effective
cost over the whole data set.

816
00:38:52,980 --> 00:38:54,780
Alright, so in this example we now have

817
00:38:54,780 --> 00:38:56,130
some dev stuff up here.

818
00:38:56,130 --> 00:39:00,780
We can see that development
costs us about 1,391 a month

819
00:39:00,780 --> 00:39:02,160
for that particular month.

820
00:39:02,160 --> 00:39:07,160
And that this particular
row, this particular app

821
00:39:07,500 --> 00:39:10,260
and environment tag, so
ActiveBoltMatrix and dev

822
00:39:10,260 --> 00:39:11,730
actually didn't cost
us anything that month,

823
00:39:11,730 --> 00:39:14,340
but there'll be examples
further in the data set here

824
00:39:14,340 --> 00:39:15,720
that where that's not the same.

825
00:39:15,720 --> 00:39:18,150
So these zeros aren't
particularly helpful.

826
00:39:18,150 --> 00:39:19,950
Let's go ahead and filter those out.

827
00:39:22,320 --> 00:39:23,490
So we're gonna take some effective cost

828
00:39:23,490 --> 00:39:24,900
as greater than zero.

829
00:39:24,900 --> 00:39:27,500
And now this should give
us the more interesting set

830
00:39:29,970 --> 00:39:31,023
to poke around in.

831
00:39:35,940 --> 00:39:40,380
Okay, so now we can see, we
have a couple of apps here.

832
00:39:40,380 --> 00:39:45,380
Prod foo has had different costs
here in different accounts.

833
00:39:45,720 --> 00:39:49,860
And the total app in here
cost was like 38 bucks.

834
00:39:49,860 --> 00:39:51,240
And this is where we're
gonna do this math.

835
00:39:51,240 --> 00:39:53,370
We're gonna take like
this row's effective cost

836
00:39:53,370 --> 00:39:56,310
and we're gonna divide it
by this combination cost

837
00:39:56,310 --> 00:39:58,950
to start figuring out where
things are distributed.

838
00:39:58,950 --> 00:40:03,950
So we're gonna wrap everything
in another width here

839
00:40:05,820 --> 00:40:07,440
and we're gonna call
it percentages, right?

840
00:40:07,440 --> 00:40:09,900
So we have our first query that we wrote.

841
00:40:09,900 --> 00:40:12,610
We have this second one where we've added

842
00:40:15,060 --> 00:40:16,920
our window functions.

843
00:40:16,920 --> 00:40:18,180
We filtered out these zeros.

844
00:40:18,180 --> 00:40:19,740
We're also gonna filter
down to production, right?

845
00:40:19,740 --> 00:40:21,840
We don't need, we're just trying

846
00:40:21,840 --> 00:40:23,890
to track down production costs right now.

847
00:40:35,640 --> 00:40:39,960
Okay, and then we're
going to filter out usage

848
00:40:39,960 --> 00:40:42,300
with no app tag because
we saw a couple of those.

849
00:40:42,300 --> 00:40:45,153
So we don't need to see ones
where there's no app tag.

850
00:40:47,790 --> 00:40:51,810
And finally we're gonna
run one final query

851
00:40:51,810 --> 00:40:55,320
over like all of that so that
we only see what we need.

852
00:40:55,320 --> 00:40:58,290
So, we're gonna select
things like provider name,

853
00:40:58,290 --> 00:41:00,930
account name, and then oh, we still need

854
00:41:00,930 --> 00:41:02,330
to calculate the percentage.

855
00:41:03,901 --> 00:41:04,734
So, what we're gonna do here

856
00:41:04,734 --> 00:41:09,650
is we took our sum effective
cost for the row, right,

857
00:41:11,310 --> 00:41:12,720
which is here.

858
00:41:12,720 --> 00:41:17,220
We're gonna divide it by the aggregate,

859
00:41:17,220 --> 00:41:20,307
like this window function
for that function.

860
00:41:20,307 --> 00:41:21,630
And we're going to multiply

861
00:41:21,630 --> 00:41:24,120
by a hundred to get the percentages

862
00:41:24,120 --> 00:41:27,240
and we're gonna select what
we need out of this set.

863
00:41:27,240 --> 00:41:31,890
So this should give us provider name,

864
00:41:31,890 --> 00:41:34,380
the accounts, the
environment app, the cost,

865
00:41:34,380 --> 00:41:36,660
and then these, this like split, right?

866
00:41:36,660 --> 00:41:39,360
And the other piece here is
we only want to see places

867
00:41:39,360 --> 00:41:41,360
where it's not a hundred percent right.

868
00:41:41,360 --> 00:41:43,410
If foo and dev only runs in one place,

869
00:41:43,410 --> 00:41:44,670
that's not interesting.

870
00:41:44,670 --> 00:41:47,880
So we're gonna filter
out places where this app

871
00:41:47,880 --> 00:41:51,400
or the percentage is less than a hundred

872
00:41:52,560 --> 00:41:54,420
and this should give us that report

873
00:41:54,420 --> 00:41:57,717
that we were kind of chasing from here.

874
00:42:07,260 --> 00:42:09,900
What did I miss here?

875
00:42:09,900 --> 00:42:11,213
Oh, I have two froms.

876
00:42:12,360 --> 00:42:13,923
Copy and pasted it wrong.

877
00:42:15,252 --> 00:42:16,085
Okay.

878
00:42:20,850 --> 00:42:21,960
And what this is showing us

879
00:42:21,960 --> 00:42:26,400
is we have two apps here, one called foo,

880
00:42:26,400 --> 00:42:30,240
one called databricks
that run in production

881
00:42:30,240 --> 00:42:34,140
and they're split both across
providers and accounts.

882
00:42:34,140 --> 00:42:38,520
And we can track down that,
you know, prod foo runs,

883
00:42:38,520 --> 00:42:42,450
you know, 2.5% in this AWS account

884
00:42:42,450 --> 00:42:46,140
and it runs about 50/50, 50/46

885
00:42:46,140 --> 00:42:49,050
and these two Microsoft accounts.

886
00:42:49,050 --> 00:42:51,450
And then finally for databricks
we can see, you know,

887
00:42:51,450 --> 00:42:53,850
a similar distribution where it's like 99%

888
00:42:53,850 --> 00:42:56,100
in this one AWS account.

889
00:42:56,100 --> 00:42:58,050
And then there's some workloads out there

890
00:42:58,050 --> 00:43:01,173
that are tagged as prod
databricks running elsewhere.

891
00:43:02,970 --> 00:43:04,414
Cool

892
00:43:04,414 --> 00:43:06,780
- [Jason] As we back to the presentation.

893
00:43:06,780 --> 00:43:08,760
- [Justin] Yeah, so
finally we wanna talk about

894
00:43:08,760 --> 00:43:10,530
visualization real quick.

895
00:43:10,530 --> 00:43:12,840
You know, we poked around in Athena.

896
00:43:12,840 --> 00:43:14,490
Looking at SQL results can be nice

897
00:43:14,490 --> 00:43:16,230
but it's not as pretty
as some of the graphs

898
00:43:16,230 --> 00:43:18,630
that I'm sure a lot of
folks would like to have.

899
00:43:18,630 --> 00:43:22,440
So wanna call out again to the
Cloud Intelligence Dashboards

900
00:43:22,440 --> 00:43:24,630
like that team has done wonderful work.

901
00:43:24,630 --> 00:43:27,690
It is an out of the box
solution visualizing on top

902
00:43:27,690 --> 00:43:31,170
of all the data that we kind
of presented to you guys today.

903
00:43:31,170 --> 00:43:34,800
It has that consolidation view.

904
00:43:34,800 --> 00:43:37,080
They have integrations documented for how

905
00:43:37,080 --> 00:43:41,730
to pull in data from Azure and
Google Cloud, Oracle Cloud.

906
00:43:41,730 --> 00:43:45,990
Today they support FOCUS
1.0 but they have plans

907
00:43:45,990 --> 00:43:50,250
to add 1.2 here soon since
we just recently announced

908
00:43:50,250 --> 00:43:52,860
two weeks, two, three
weeks ago that it was out.

909
00:43:52,860 --> 00:43:54,780
So keep an eye on their change logs.

910
00:43:54,780 --> 00:43:56,310
That's coming soon.

911
00:43:56,310 --> 00:43:59,520
Jason, let's wrap things up.
- [Jason] Sure.

912
00:43:59,520 --> 00:44:00,510
Yeah, thanks, Justin.

913
00:44:00,510 --> 00:44:02,970
The cost allocation and cost attribution

914
00:44:02,970 --> 00:44:06,090
is always a very hard problem
to solve in the cloud.

915
00:44:06,090 --> 00:44:09,475
Cost management especially
involve multi-cloud

916
00:44:09,475 --> 00:44:10,590
or SaaS vendors.

917
00:44:10,590 --> 00:44:12,720
So Justin gave a good demo

918
00:44:12,720 --> 00:44:15,480
to solve that problem with FOCUS data set.

919
00:44:15,480 --> 00:44:17,800
And that data set is also published

920
00:44:19,202 --> 00:44:20,700
in the our current query libraries

921
00:44:20,700 --> 00:44:23,820
that you guys can grab today.

922
00:44:23,820 --> 00:44:27,000
And let's recap what we have learned

923
00:44:27,000 --> 00:44:30,600
since from the question
we asked in the beginning.

924
00:44:30,600 --> 00:44:32,550
Have you seen the FOCUS data set?

925
00:44:32,550 --> 00:44:34,740
We have seen this all together.

926
00:44:34,740 --> 00:44:37,380
Have you analyzed the FOCUS data set?

927
00:44:37,380 --> 00:44:39,273
Which we have done this all together.

928
00:44:40,200 --> 00:44:43,650
And have you joined FOCUS data set?

929
00:44:43,650 --> 00:44:46,230
And in this practice we
joined FOCUS data set

930
00:44:46,230 --> 00:44:48,810
with other providers in Athena.

931
00:44:48,810 --> 00:44:52,323
And what's remaining is
put FOCUS into action.

932
00:44:53,490 --> 00:44:56,010
So after this section, very encourage you

933
00:44:56,010 --> 00:45:00,540
to create a FOCUS export from
the AWS data export platform

934
00:45:00,540 --> 00:45:02,160
and visualize your FOCUS data

935
00:45:02,160 --> 00:45:04,680
and get your hands with the FOCUS.

936
00:45:04,680 --> 00:45:06,240
- [Justin] Yeah, and getting hands on.

937
00:45:06,240 --> 00:45:08,070
Again, hopefully we can make this easy.

938
00:45:08,070 --> 00:45:10,650
We have a whole bunch of resources here

939
00:45:10,650 --> 00:45:13,020
that will link you out
to the code examples

940
00:45:13,020 --> 00:45:15,720
that we had today, the CUR Query Library

941
00:45:15,720 --> 00:45:19,260
where you can get started
either with CUR or FOCUS,

942
00:45:19,260 --> 00:45:20,940
the Cloud Intelligence Dashboards,

943
00:45:20,940 --> 00:45:22,680
a whole nother library of links

944
00:45:22,680 --> 00:45:26,130
if you feel like diving into
cost allocation strategies

945
00:45:26,130 --> 00:45:29,850
on AWS and then both mine and Jason's

946
00:45:29,850 --> 00:45:31,300
socials if you wanna connect.

947
00:45:33,510 --> 00:45:37,050
And of course you know
re:Invent is all week.

948
00:45:37,050 --> 00:45:38,940
There's lots of other sessions

949
00:45:38,940 --> 00:45:42,690
focused on FinOps
practitioners like yourself,

950
00:45:42,690 --> 00:45:46,020
whether it's AI for FinOps, FinOps for AI,

951
00:45:46,020 --> 00:45:49,710
unit cost or cost allocation strategies,

952
00:45:49,710 --> 00:45:51,690
multi-tenant cost allocation strategies,

953
00:45:51,690 --> 00:45:53,160
a whole lot going on.

954
00:45:53,160 --> 00:45:55,060
So check these other sessions out

955
00:45:56,550 --> 00:45:59,010
and come check the cloud ops kiosk.

956
00:45:59,010 --> 00:46:02,970
We do have a kiosk in the AWS
village in the Venetian Expo

957
00:46:02,970 --> 00:46:05,490
where folks like myself and Jason

958
00:46:05,490 --> 00:46:08,730
will be hanging out to
give one-on-one demos.

959
00:46:08,730 --> 00:46:10,620
There's swag and stickers.

960
00:46:10,620 --> 00:46:12,120
Feel free to come and say hey.

961
00:46:13,110 --> 00:46:13,943
And that's it.

962
00:46:13,943 --> 00:46:15,930
Thanks for your time today.

963
00:46:15,930 --> 00:46:18,600
I hope the rest of re:Invent is awesome.

964
00:46:18,600 --> 00:46:20,850
And Jason and I'll hang
out for a couple minutes

965
00:46:20,850 --> 00:46:22,440
if you have questions or
you wanna come up and talk.

966
00:46:22,440 --> 00:46:24,120
I think we have a couple of stickers

967
00:46:24,120 --> 00:46:27,060
that we'd be more than
happy to share with folks.

968
00:46:27,060 --> 00:46:29,640
And please if you could
complete the session survey

969
00:46:29,640 --> 00:46:31,440
in the AWS events app.

970
00:46:31,440 --> 00:46:35,250
We are a data-driven company
and we love all feedback.

971
00:46:35,250 --> 00:46:37,080
So, that's it.

972
00:46:37,080 --> 00:46:40,113
I hope everyone has a great
rest of your week here.

