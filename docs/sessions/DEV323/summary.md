# AWS re:Invent 2025 会议总结：Prime Video 的 AI 原生转型之旅

## 会议概览

本次会议由 Prime Video 的技术产品经理 Lilia Abiborva 和 AWS 首席软件工程师 James Hood 共同主讲,分享了 Prime Video 从 AI 辅助开发向 AI 原生转型的完整历程。会议深入探讨了如何在大型组织中规模化推广 AI 采用,以及如何从孤立的 AI 实验演进到全面的 AI 原生转型。

Lilia 专注于开发者体验,她的团队将所有 Prime Video 开发者视为客户,关注内部工具满意度和代码审查效率等指标。Prime Video 作为全球领先的流媒体平台,拥有数千个内容标题,支持大规模直播体育赛事,背后有数百名开发者持续创新。这种规模和复杂性正是 AI 原生转型能够带来巨大影响的场景。

会议强调了 AI 原生与 AI 辅助开发的根本区别:AI 辅助是在孤立任务中使用工具(如自动补全、聊天机器人),需要在工具间不断粘贴上下文;而 AI 原生则是将 AI 工具嵌入软件开发生命周期的每个阶段和每个角色中,使用能够端到端处理多步骤工作流的智能体,通过共享的上下文和基础设施实现组织级生产力转型。这种转型不是自上而下的强制推行,而是从基层建设者的实验和分享开始的草根运动。

## 详细时间线与关键要点

### 开场与背景介绍 (0:00 - 3:30)

0:00 - 0:45 - 开场互动:演讲者询问现场观众谁在大型组织中尝试推广 AI 采用时发现实际比博客文章描述的困难得多,现场大量观众举手表示认同。

0:45 - 1:30 - Lilia Abiborva 自我介绍:她是 Prime Video 的技术产品经理,与传统 PM 角色不同,她专注于开发者体验,将所有 Prime Video 开发者视为客户,关注内部工具满意度和代码审查平均修订次数等指标。

1:30 - 2:15 - 会议议程预告:首先定义"AI 原生"概念,然后 James 分享如何意外引发全公司 AI 采用运动,Lilia 讲解组织转型和成果测量,最后进行演示。

2:15 - 3:30 - Prime Video 背景介绍:展示全球覆盖数据和原创内容亮点,拥有数千个来自 Prime Video Studios 和合作伙伴的内容标题,大力投入直播体育。上周五同时流式传输一场 NFL 橄榄球赛和两场 NBA 比赛,在零售业最繁忙的日子之一平稳运行。背后有数百名开发者不断创新并确保系统稳定运行。

### AI 原生概念定义 (3:30 - 6:00)

3:30 - 4:15 - 回顾 2024 年历程:Lilia 提到去年在 re:Invent 分享了早期 AI 编码助手采用的旅程,当时 AI 从学徒助手演进为专家助手。今年讨论的是下一步演进:AI 原生开发转型。

4:15 - 5:30 - AI 辅助 vs AI 原生的区别:
- **AI 辅助工作流**:获取功能需求后粘贴到 AI 聊天工具中头脑风暴架构方案,然后在 IDE 中粘贴更多上下文编写代码(部分由自动补全生成,部分手写),功能完成后再粘贴上下文到另一个工具创建文档或发布公告。这种方式是以临时和孤立的方式使用工具,不断在工具间粘贴上下文,影响的是个人生产力和孤立任务。
- **AI 原生方法**:从根本上重新构想软件构建方式,AI 工具嵌入软件开发流程的每个步骤和每个角色(PM、开发者、设计师),使用能够端到端处理多步骤工作流的智能体,上下文在工具、基础设施和团队间嵌入和共享,带来组织生产力转型。

5:30 - 6:00 - 转型起源:强调这种转型不是自上而下的强制推行,而是从建设者的实验和分享开始的草根运动。

### James Hood 的个人转型故事 (6:00 - 15:30)

6:00 - 7:00 - James Hood 自我介绍:AWS 首席软件工程师,在亚马逊工作 16 年,大部分时间在 AWS,中间在零售履行软件部门工作过 5 年。他曾是 AI 怀疑论者。

7:00 - 8:15 - AI 怀疑论者的恶性循环:
- 看到炫目的 AI 演示,看起来令人兴奋
- 尝试在真实软件问题上使用,发现工具表现不佳
- 感到非常怀疑
- 这个循环是:演示引发好奇和兴奋 → 实验 → 失败或失望 → 怀疑。多次循环后很难再从怀疑回到好奇阶段。

8:15 - 9:00 - 转折点:推理模型改进、MCP(模型上下文协议)引入等技术创新。James 的顿悟时刻是意识到大语言模型是神秘的黑盒,根据提示方式会产生未被有意设计的涌现行为。他阅读技术文章发现了一些可复现的技术,工具加技术成就了"GenAI 超级用户"之路。

9:00 - 10:00 - 首个重大成功案例:使用这些技术为 Amazon Q Developer CLI 构建了一个主要功能。他不在该团队,不熟悉代码库,甚至不懂该语言,但从概念到拉取请求只用了 2 天,从概念到生产发布只用了 7 天。

10:00 - 11:30 - 常见误区:很多人说"AI 生成了大量代码,但我不喜欢,修改太多,还不如手写快"。这个论点的谬误在于给了模糊想法就期望得到精确实现。如果对人类也这样做,结果也一样。软件开发是一个过程,从粗略想法到实现需要经过:研究和需求澄清 → 设计解决方案 → 创建实施计划 → 实施。James 使用 AI 技术快速完成了这个过程。

11:30 - 13:00 - 详细工作流程:
- **研究代码库(5分钟)**:下载代码库,用 Q CLI 询问"这是什么代码库",了解主要组件,重点研究 Q chat 组件,让 AI 创建规划目录并写入 codebase.mmd 文件,然后写入 slashcommand.mmd 文件详细说明如何实现斜杠命令。
- **澄清需求(约40分钟)**:将粗略想法文档给 AI,让它一次问一个问题以制定详细规范。AI 成为合作伙伴,提出澄清性问题,有时 James 没有答案或不需要答案,AI 会提供选项供选择。经过约 24 个问题后完成需求澄清。
- **设计(约1小时)**:基于所有规划文档创建详细设计文档,以便开发者可以立即开始实施。
- **实施计划**:将设计文档的实施计划部分转换为一系列代码生成提示,以测试驱动方式实施每个步骤。生成了 14 个提示的计划和待办事项列表。

13:00 - 15:30 - 实施过程:
- 读取规划文件夹中的所有文档,实施提示 1 并更新待办事项
- 继续实施提示 2,之后需要弄清楚如何构建包(因为真的不熟悉代码库),在 AI 帮助下完成构建
- 到提示 5 时,能够使用自己构建的功能来构建剩余部分,这很有趣
- 强调这不是"氛围编码":虽然实施 14 个提示只需 2 小时,但整个拉取请求用了 2 天。虽然不懂该语言,但有 20 多年编程经验,能大致读懂代码,在实施过程中跟进,与智能体来回讨论代码的各个方面,利用人类判断和经验确保方向正确。

### 草根运动与组织支持 (15:30 - 20:00)

15:30 - 17:00 - AI 原生良性循环:
- 听说新事物或尝试新技术 → 对工具充满好奇 → 实验 → 无论成功或失败都与他人分享学习成果 → 回到好奇
- 强调良性循环和恶性循环都涉及怀疑论,对 AI 保持健康的怀疑论很重要,设定合理期望,保持好奇心测试,不要因为某些东西不起作用就认为整个事物毫无价值。

17:00 - 18:30 - 创建内部 Slack 频道:James 在 3 月创建了"Amazon Builder GenAI Power Users"频道,增长超出想象,现在有数万名成员,人们积极研究不同技术、分享学习成果和工具,这是一次令人难以置信的经历。

18:30 - 20:00 - 草根与自上而下结合:强调不能仅依靠自下而上或自上而下,需要两者结合。没有建设者社区的草根能量和兴奋,AI 原生转型无法成功。但转型也需要组织支持才能扩展。

### 组织转型三大支柱 (20:00 - 35:00)

20:00 - 21:00 - 三大支柱介绍:
1. 访问和基础设施:确保所有团队和角色都能访问一流的 AI 工具,访问上下文等没有摩擦
2. 文化和学习:学习飞轮成为文化的一部分
3. 信任和严谨:在堆栈的每一层和每个流程中内置控制和治理

21:00 - 24:00 - AI 访问和基础设施:
- 软件开发涉及跨职能团队(产品经理、设计师、开发者),经历从想法到编码、部署、运营、学习的阶段,这是软件开发生命周期(SDLC)
- 到目前为止,AI 辅助流程主要加速编码和测试部分,提供代码建议、生成单元测试、加快个人编程任务
- AI 原生方法超越编码,从根本上重新构想软件构建方式
- James 展示了如何使用 Q CLI 澄清需求、设计解决方案,现在已从个人工作流扩展到团队生产力

24:00 - 27:00 - SDLC 各阶段的 AI 工具:
- **Kira**:AI 原生开发智能体,有 IDE 和 CLI 界面,不仅开发者使用,PM 和设计师也在使用,用于原型设计,加速早期阶段,不会被工程团队阻塞
- **Quick Sweep**:商业智能智能体,帮助研究需求、从过去实验中学习、分析数据、为业务快速创建自动化智能体工作流
- **定制智能体**:许多团队构建了针对其领域、代码库和问题的定制智能体和解决方案,例如测试智能体(自动化数百个 Prime Video 支持设备的测试和质量验证)、运营智能体(使用 AI 和数百个数据源诊断、故障排除,有时甚至建议运营问题和事件的解决方案)

27:00 - 29:30 - 共享上下文和能力层:
- 使用知识库和模型上下文协议(MCP)确保所有角色可以共享相同上下文,无需在不同步骤和工具间粘贴
- 示例:PM 使用 AI 助手工具创建规范后,通过 MCP 集成在 Kira 中可用;开发团队构建和合并代码后,该代码连同指标、日志和其他数据源一起可供运营智能体使用

29:30 - 32:00 - 技术栈构建:
- **基础层**:在 AWS 上构建,使用 IAM、计算、可观测性等构建块。AWS Bedrock 拥有所有云提供商中最大的模型选择。还利用 Agent Core、SageMaker 等托管解决方案
- **上下文层**:MCP 服务器和钩子成为上下文骨干,将 AI 工具连接到最新的业务和技术内容。关键是平衡中央投资(如代码库或问题跟踪系统访问)和团队特定投资(如 Prime Video 目录元数据访问的知识库和 MCP 服务器)
- **本地层**:团队构建和共享提示或引导文件,以 James 展示的方式进行开发
- **体验和工具层**:混合使用现成工具(如 Kira)和团队为其需求构建的定制智能体

32:00 - 35:00 - PM 工作流转型案例:
- Lilia 定期撰写 AI 项目通讯,包含内外部新版本和成功故事
- 以前搜索外部来源、内部 Slack 频道、策划和编辑需要 2-3 小时
- 开始对个别任务使用 AI(如搜索与 AI 和开发工具相关的最新故事)
- 最终演进为智能体工作流:从内外部来源获取数据,构建可以从不同 Slack 频道提取和策划内容的智能体,然后使用 Kira 模板发布
- 现在这个过程缩短到约 30 分钟的润色和审查
- 在运营审查文档、数据分析等方面看到类似转型,PM、TPM 和经理(不仅是开发者)真正参与智能体能力

### 文化和学习 (35:00 - 42:00)

35:00 - 37:00 - AI 原生学习飞轮:
- 团队学习新技术 → 实验工作流 → 广泛分享结果 → 产生好奇心和健康怀疑论 → 引发下一波实验
- 这个循环而非自上而下的强制推行推动了持久的采用

37:00 - 39:00 - 构建飞轮的机制:
- **早期阶段**:安全沙箱、演示日、黑客马拉松,鼓励团队使用 AI 自动化尚未 AI 原生的流程部分(如为不同设备构建测试工作流或自动化待命操作)
- **正式化机制**:早期采用者成为官方 AI 倡导者;首席工程社区启动 AI 标杆项目(在亚马逊,标杆概念用于校准面试和提升事件后代码和后续行动的质量,现在应用于 AI 成熟度);将最佳实践编入快速入门指南,包含推荐工具和重要技术(如维护活文档架构规范或 James 演示的规范驱动开发)
- **嵌入仪式**:在各级仪式中嵌入 AI 反思,无论是团队回顾还是组织季度审查,都有 AI 学习部分或分配时间分享成功和挑战,这使实验真正正常化

39:00 - 42:00 - 针对不同角色的学习路径:
- 如果只加速流程的一部分或一个团队的一个角色,只是将瓶颈转移到其他地方。如果开发团队效率提高一倍但决策和需求仍遵循旧流程,组织整体效率并未真正提高
- 需要为每个角色设计学习路径,不仅教授新工具和提示技术,还教授新的工作和协作方式
- **工程师**:规范驱动开发技术研讨会
- **PM 和设计师**:智能体工作流创建培训,已大量使用 Claude 编写和创建规范,学习编码技术后开始做原型。最近为约 50 名 PM 举办研讨会,许多人第一次编码,对他们来说是真正的转型,意识到可以用 AI 工具探索更多想法和交互
- **数据团队**:创建自然语言查询界面,不必陷入创建简单查询,而是专注于更复杂的问题
- **领导层**:培训使用 MCP 简化目标报告或查询战略文档知识库
- **所有角色**:学习如何通过 MCP 访问和使用相关知识库和工具

### 信任和严谨 (42:00 - 48:00)

42:00 - 44:30 - 早期挑战:
- **代码审查过载**:AI 能够生成多文件更改后,技术负责人和高级工程师被大量大型代码审查淹没。虽然代码生成加速了,但在代码审查中产生了瓶颈。解决方案:强调亚马逊的所有权领导力原则(真正审查生成的每一行代码很重要);构建代码审查智能体集成到工作流中(始终需要人工审查,但在某些情况下可以利用智能体代码审查)。这些变化使代码审查速度再次流畅。
- **政策和流程摩擦**:团队开始构建更多智能体并自动化工作流(有时完全自主,甚至没有人工参与),智能体需要访问数据,但审查流程是为人工批准而非智能体批准构建的,创新因此摩擦而放缓。解决方案:与安全、隐私和其他利益相关者合作,现代化一些流程,甚至自动化一些治理步骤。

44:30 - 48:00 - 每层内置治理:
- **基础设施层**:容量控制(AI 使用可能迅速蔓延),IAM 策略和其他机制(应用于任何生产工作负载的机制也应用于开发工具和基础设施)
- **建模和能力层**:提示模板、回退机制、严格的评估集,以便每次新模型发布或其他变化时可以快速采用并有信心
- **上下文层**:为远程和本地 MCP 服务器启用正确的身份验证控制,在组织范围内编纂正确的方法,帮助解锁安全实验
- **体验层**:Kira 和特定工作流智能体基于亚马逊内部单点登录身份验证和智能体使用的服务到服务身份验证的组合强制执行正确的权限
- 有了这些控制,建设者不必担心合规性或对可以使用什么不确定,安全路径成为容易采取的路径

### 成果测量 (48:00 - 52:00)

48:00 - 49:30 - 测量方法:
- **早期**:专注于 AI 采用率,第一年痴迷于这个数字,但最终饱和(每个人都在为孤立任务使用 AI)
- **采用指标演进**:专注于 SDLC 不同阶段的特定工具、每个角色的采用率,仍密切监控但不仅仅是纯采用率

49:30 - 51:00 - 速度和效率成果:
- 使用 DORA 指标(行业标准速度指标)
- 开发部署速度和代码审查速度有显著提升
- 重要的是控制事件率和回滚率,始终与关注指标并行

51:00 - 52:00 - 特定用例指标:
- 深入研究用特定智能体试图改变的特定领域
- 跟踪效率提升、时间节省和最适合该用例的其他指标
- 最佳洞察来源:倾听建设者的声音,定期调查、访谈和领导层倾听会议

52:00 - 52:30 - 工程师反馈引用:
- 一位工程师过去在非编码工作上至少花费 3 周(设计、编写设计文档、与团队迭代、与不同利益相关者协调),使用 AI 工具后,文档编写在 3 天内完成,然后可以将时间集中在与利益相关者讨论集成用例上

### 演示环节 (52:30 - 结束)

52:30 - 54:00 - 演示引入:
- James 提到 3 月的故事在 AI 时间里是很久以前了,已经取得了长足进步
- 当时发布了内部博客,人们复制粘贴提示,但现在有了更好的方法
- 不到两周前开源了名为"Strands Agent SOPs"的工具

54:00 - 55:00 - Strands Agent SOPs 介绍:
- SOP 代表标准操作程序(Standard Operating Procedure)
- 标准操作程序是包含详细分步说明的文档,通常帮助人员执行常规任务或流程
- Agent SOPs 帮助智能体执行任务

55:00 - 结束 - GitHub 仓库展示:
- 展示了 GitHub 仓库界面
- 演示如何使用这些 Agent SOPs 来标准化和简化 AI 智能体的工作流程
- (字幕在此处截断)

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


## 核心要点总结

1. AI 原生的本质:不是孤立使用 AI 工具,而是将 AI 深度嵌入整个软件开发生命周期和所有角色中
2. 转型双轨制:需要草根运动的能量和组织支持的结构相结合
3. 三大支柱:访问和基础设施、文化和学习、信任和严谨缺一不可
4. 学习飞轮:持续的学习、实验、分享循环是成功的关键
5. 全员参与:不仅是开发者,PM、设计师、数据团队、领导层都需要 AI 赋能
6. 上下文共享:MCP 成为连接各工具和角色的关键技术
7. 测量导向:从采用率到速度指标再到特定用例效率的多维度测量