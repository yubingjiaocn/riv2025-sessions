# AWS re:Invent 2025 - 掌握Amazon Bedrock中的模型选择

## 会议概述

本次技术分享会由AWS Amazon Bedrock团队的首席全球AI专家Scott Munson、首席产品经理John Liu，以及CoinMarketCap的高级AI产品经理Brian Coe共同主讲。会议聚焦于如何在Amazon Bedrock中系统性地选择AI模型，解决当前AI模型数量爆炸式增长带来的选择困难。

演讲者介绍了一个简化的三步框架：识别候选模型、评估模型性能、优化模型配置。该框架基于AWS与客户的实际合作经验总结而成，旨在帮助组织建立系统性的模型选择流程。CoinMarketCap作为实际案例，展示了如何运用此框架为超过6500万月活用户提供AI服务，每日处理超过100亿个LLM令牌。

## 详细时间线与关键要点

### 00:00-05:00 开场与背景介绍
- 介绍演讲嘉宾和会议议程
- 强调当前AI模型选择的挑战：Hugging Face上有219万个公开模型，每10秒就有新模型发布
- 指出客户面临的核心问题：缺乏系统性的模型选择框架

### 05:00-10:00 Amazon Bedrock平台概述
- Amazon Bedrock提供无服务器推理服务，支持80多个模型
- 本周新增4个模型提供商：Google、Minimax、Nvidia、Moonshot
- 平台优势：简化部署、自动扩缩容、内置安全防护、支持自定义模型导入

### 10:00-20:00 模型选择框架 - 识别阶段
- **第一步：按模态筛选** - 根据输入输出类型（文本、图像、视频、音频）筛选相关模型
- **第二步：基准测试分析** - 利用Artificial Analysis等第三方资源比较模型性能和成本
- **第三步：差异化能力评估** - 重点关注推理模型、智能体能力、可定制性、领域专业性
- 以金融犯罪调查智能体为例，演示如何从全部模型筛选到Claude Sonnet、GPT-4o、DeepSeek V3等候选模型

### 20:00-35:00 模型选择框架 - 评估阶段
- **黄金数据集构建**：包含约100个用例，其中5%为对抗性测试用例
- **自动化数据集生成**：通过用户模拟器、任务智能体、评判智能体的三智能体系统扩展数据集
- **评估指标体系**：
  - 运营指标：成本、延迟、可扩展性
  - 语义指标：质量准确性、风格可用性、负责任AI
  - 自定义指标：点击率、用户覆盖率等业务KPI
- **评估方法**：程序化评估、人工评估、LLM作为评判者

### 35:00-45:00 模型选择框架 - 优化阶段
- **多模型路由策略**：基于规则的路由、机器学习路由、LLM智能路由的组合使用
- **模型定制化**：微调、蒸馏、Nova Forge等高级定制选项
- **推理优化**：通过推理层级（优先级层、标准层、弹性层）优化成本和延迟
- 实际案例：金融犯罪调查系统通过优化实现80%成本降低，同时将工作负载从5亿扩展到50亿次推理请求

### 45:00-55:00 CoinMarketCap实践案例
- **业务背景**：加密货币数据平台，6500万月活用户，每日100亿令牌消耗
- **AI应用场景**：信号发现、解释说明、预测分析、行动建议
- **模型分工策略**：
  - 情感提取器：要求低成本、高速度
  - 规划模块：需要强推理能力
  - 数据检索：专注工具调用准确性
  - 摘要生成：处理大量上下文信息
  - 自然语言转换：轻量级聊天模型即可胜任
- **评估系统GLAS**：通用LLM评判服务，支持快速模型评估和生产监控

### 55:00-56:30 总结与资源推荐
- 重申三步框架的核心价值
- 推荐相关资源：模型选择价值文章、GitHub评估工具、实践工作坊
- 强调持续评估和优化的重要性