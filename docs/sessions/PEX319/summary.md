# AWS re:Invent 2025 医疗工作流程中符合合规性的生成式AI系统架构

## 会议概述

本次会议由AWS全球合作伙伴解决方案架构团队的Vina Vasuvan、Sudhir Gupta以及合作伙伴Quantiphi的Sanjit共同主讲,重点探讨了如何利用生成式AI技术解决医疗保险理赔中的医疗编码问题。

在美国,每天处理约460万份保险理赔,其中10%因医疗编码错误而被拒绝。ICD-10代码(国际疾病分类第10版)是医疗账单的通用语言,目前有约70,000个标准化代码。传统的医疗编码流程依赖基于规则的系统和正则表达式进行模式匹配,准确率仅为60-70%,需要医疗编码员进行大量手工验证,这是一个容易出错且耗时的过程。这导致患者收到高额医疗账单,医疗服务提供商面临复杂的编码要求,整个医疗行业因此浪费数十亿美元。

会议展示了三种AI解决方案:直接使用基础模型(存在幻觉问题)、RAG(检索增强生成)结合LLM、以及模型微调。重点演示了后两种方法,使用Amazon Bedrock、OpenSearch Serverless、Bedrock Guardrails等AWS服务构建符合HIPAA合规的医疗编码助手,实现了自动化、准确的ICD-10代码生成,显著提高了编码效率和准确性。

## 详细时间线

### **开场介绍 (0:00-2:30)**
- 0:00 - 会议开始,欢迎参会者
- 0:30 - Vina Vasuvan自我介绍:AWS全球合作伙伴解决方案架构团队首席架构师
- 1:00 - Sudhir Gupta介绍:数据与AI专家,首席合作伙伴解决方案架构师
- 1:30 - Sanjit介绍:来自Quantiphi的实践负责人、AWS Hero和大使
- 2:00 - 会议主题确认:为医疗工作流程架构符合合规性的生成式AI系统

### **业务背景与问题陈述 (2:30-8:00)**
- 2:30 - 提出核心问题:保险理赔被拒绝的普遍性
- 3:00 - 数据展示:美国每天处理460万份保险理赔
- 3:30 - 关键统计:10%的理赔因医疗编码错误被拒绝
- 4:00 - ICD-10代码解释:国际疾病分类第10版,医疗账单的通用语言
- 4:30 - 示例说明:肺炎代码J18.9,骨折代码,甚至包括"被鸭子袭击"的代码W81.82
- 5:00 - 代码规模:约70,000个标准化ICD-10代码,且持续增加
- 5:30 - 实际场景:患者就诊后,放射科医生的诊断需要转换为ICD-10代码
- 6:30 - 传统流程问题:基于正则表达式的模式匹配,准确率仅60-70%
- 7:00 - 人工验证:医疗编码员需要手动验证和补充编码
- 7:30 - 系统缺陷:传统流程无法应对复杂性,容易出错

### **问题影响分析 (8:00-10:00)**
- 8:00 - 患者影响:收到高额医疗账单,理赔被拒后未重新提交
- 8:30 - 医疗服务提供商影响:面临复杂的编码要求
- 9:00 - 复杂场景示例:患者同时出现肺炎和骨折,需要映射到多个ICD-10代码
- 9:30 - 经济影响:医疗行业因此浪费数十亿美元
- 9:45 - 现代化需求:流程迫切需要通过生成式AI进行现代化改造

### **解决方案方法概述 (10:00-14:00)**
- 10:00 - 三种解决方案方法介绍
- 10:30 - 方法一:直接使用基础模型 - 最直接的方法,使用Anthropic Claude或Amazon Nova
- 11:00 - 方法一的缺陷:LLM容易产生幻觉,不适合垂直行业特定任务
- 11:30 - 方法二:RAG + LLM - 使用向量数据库提供上下文
- 12:00 - RAG方法优势:通过源数据锚定LLM响应,提供少样本示例,防止幻觉
- 12:30 - 方法三:模型微调 - 最准确的方法
- 13:00 - 微调优势:答案嵌入模型权重,延迟更低,无需语义搜索
- 13:30 - 微调缺点:资源密集型,可能需要数天时间,依赖数据质量和标注样本数量
- 13:45 - 会议重点:将详细演示方法二(RAG)和方法三(微调)

### **RAG解决方案架构介绍 (14:00-18:00)**
- 14:00 - Sudhir接手演示RAG方法
- 14:30 - Streamlit应用演示:医疗编码员输入叙述、印象和程序信息
- 15:00 - 系统流程:应用Guardrails → 提取短语 → 生成ICD-10代码
- 15:30 - 演示结果:系统成功生成三个短语的ICD-10代码
- 16:00 - 架构组件:Amazon OpenSearch Serverless作为知识库
- 16:30 - 数据源一:CMS数据,包含ICD-10代码和描述
- 17:00 - 数据源二:少样本示例,包含短语、病史和相关ICD-10代码
- 17:30 - 嵌入模型:使用Amazon Titan Embedding模型生成嵌入

### **数据处理与索引创建 (18:00-25:00)**
- 18:00 - 数据上传到S3,生成嵌入并导入知识库
- 18:30 - 用户交互方式:Jupyter Notebook、命令行或Streamlit应用
- 19:00 - Lambda函数工作流程详解
- 19:30 - 第一步:应用Bedrock Guardrails - 过滤非医疗问题,屏蔽敏感数据
- 20:00 - 第二步:第一次LLM调用 - 从OpenSearch执行语义搜索,获取前20个最佳匹配
- 20:30 - 第三步:第二次LLM调用 - 基于前20个匹配和用户输入生成最终ICD-10代码
- 21:00 - 输出处理:格式化为特定参数返回给应用
- 21:30 - GitLab代码库介绍:公开访问,包含完整实现代码
- 22:00 - 部署脚本:deploy.sh自动设置环境和资源
- 23:00 - 数据文件展示:样本数据(334条记录)和CMS数据(75,000+条记录)
- 24:00 - Notebook演示:索引创建和代码执行的教学目的

### **索引创建技术细节 (25:00-32:00)**
- 25:00 - Amazon Q代码辅助工具的使用
- 25:30 - Jupyter Notebook启动和索引创建演示
- 26:00 - 配置文件加载:项目名称、环境、区域、Bedrock Guardrails ARN
- 26:30 - OpenSearch索引名称和数据文件路径配置
- 27:00 - 并行处理优化 - 解决大规模数据索引的性能问题
- 27:30 - 线程配置:基于CPU和内存动态计算最大工作线程和批次大小
- 28:00 - 嵌入生成类创建:使用Bedrock Embedding模型
- 28:30 - OpenSearch索引定义:6列映射,向量维度1024
- 29:00 - 数据加载:334条少样本记录
- 29:30 - 并行处理执行:创建7个批次,每批约50条记录
- 30:30 - 索引验证:循环检查直到所有数据加载完成
- 31:00 - 性能对比:并行处理1-2分钟 vs 顺序处理15分钟
- 31:30 - 第二个索引:ICD描述索引,75,000+条记录,使用相同并行逻辑

### **Lambda函数核心逻辑 (32:00-42:00)**
- 32:00 - Lambda函数Notebook启动
- 32:30 - 关键文件介绍:modified_prompt_template和exp327
- 33:00 - 依赖库和配置参数加载
- 33:30 - Prompt模板详解 - 动态替换程序、叙述和印象信息
- 34:00 - 系统提示:定义为ICD医疗编码专家助手
- 34:30 - 输出格式定义:短语提取和ICD-10代码生成的两种格式
- 35:00 - 正负面识别 - 区分阳性诊断和阴性症状
- 35:30 - 两次LLM调用的不同提示和输出格式
- 36:00 - exp327核心库 - Lambda函数的"大脑",包含所有必要函数
- 36:30 - 函数库内容:Bedrock模型调用、相似性搜索、向量嵌入
- 37:00 - 配置加载:OpenSearch端点、Bedrock端点、Guardrails信息
- 37:30 - 客户端初始化:Claude Sonnet 4模型和推理配置文件
- 38:00 - Bedrock Runtime boto客户端设置
- 38:30 - OpenSearch客户端连接建立
- 39:00 - 测试数据输入:程序名称、叙述和印象
- 39:30 - 数据加载验证成功

### **Guardrails配置与应用 (42:00-48:00)**
- 42:00 - Bedrock Guardrails详细配置
- 42:30 - 有害内容过滤:仇恨言论、性内容等
- 43:00 - 提示攻击保护:防止恶意代码注入
- 43:30 - 拒绝主题:非医疗相关问题(如爱好、黑客攻击)
- 44:00 - PII保护 - 31个参数用于屏蔽患者姓名、电话、邮箱等敏感信息
- 44:30 - 上下文基础检查:验证输出准确性
- 45:00 - 阻止消息配置
- 45:30 - Guardrails应用:validate_and_mask_input函数调用
- 46:00 - 验证结果:相关记录未被屏蔽,原始数据通过验证
- 46:30 - 承诺演示PII屏蔽功能

### **RAG流程执行 (48:00-55:00)**
- 48:00 - 少样本示例检索 - 从索引2执行相似性搜索
- 48:30 - 获取前20个匹配结果
- 49:00 - 检索40个少样本示例并嵌入
- 49:30 - 第一次LLM调用:短语提取
- 50:00 - 调用get_invoke_bedrock_models函数
- 50:30 - 使用final_prompt_1和Claude Sonnet 4模型
- 51:00 - 提交系统提示和用户输入
- 51:30 - 生成前20个匹配结果(演示显示前500行)
- 52:00 - 从向量数据库检索上下文
- 52:30 - 第二次相似性搜索 - 针对临床短语在索引1中查找前20个最佳匹配
- 53:00 - 为每个短语生成ICD-10代码
- 53:30 - 第二次LLM调用:最终代码生成
- 54:00 - 使用final_prompt_2
- 54:30 - 应用Guardrails到输出 - 双重保护机制

### **输出处理与结果展示 (55:00-58:00)**
- 55:00 - Guardrails再次应用的原因:防止知识库中的敏感信息泄露
- 55:30 - 启用基础检查(grounding checks)以提高准确性
- 56:00 - 系统最终响应:JSON格式
- 56:30 - 提取的ICD-10代码:短语1、短语2、短语3、短语4及对应代码
- 57:00 - 后处理:转换为可读格式
- 57:30 - 四个短语及其ICD-10代码的最终展示
- 58:00 - Lambda函数核心功能总结

### **会议总结 (58:00-结束)**
- 58:00 - Guardrails演示预告
- 58:30 - 完整工作流程回顾
- 59:00 - 代码库访问信息和QR码分享提示

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


关键技术栈:
- Amazon Bedrock (Claude Sonnet 4, Amazon Nova Pro)
- Amazon OpenSearch Serverless
- Bedrock Guardrails
- Amazon Titan Embedding模型
- AWS Lambda
- Streamlit
- Python并行处理

核心创新点:
- 双重LLM调用策略提高准确性
- 并行索引处理大幅提升性能
- 双重Guardrails保护确保合规性
- 正负面诊断识别
- 动态少样本学习