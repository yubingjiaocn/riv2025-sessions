# AWS re:Invent 2025 事件管理会议总结

## 会议概述

本次会议由AWS企业支持团队的首席工程师Georgia和AWS事件管理团队的首席工程师Anthony主讲，两位讲师拥有超过20年的AWS事件管理综合经验。会议重点讨论了AWS如何在大规模环境下进行事件检测、响应和事后分析。讲师们分享了AWS内部使用的事件管理流程、工具和最佳实践，特别强调了从事件检测到解决方案实施的完整生命周期管理。

会议内容涵盖了AWS事件管理的三个核心阶段：检测与响应、协调与缓解、以及事后回顾与改进。讲师们详细介绍了AWS如何通过服务驱动指标、客户驱动指标和聚合告警来检测问题，如何通过技术呼叫（Tech Call）和支持呼叫（Support Call）来协调多团队响应，以及如何通过COE（Correction of Errors）文档进行深度根因分析。特别值得注意的是，AWS强调并行调查而非串行调查，以及通过"五个为什么"方法构建根因树而非简单的因果链，这些都是AWS在大规模事件管理中的独特实践。

会议还强调了事件管理不仅仅是创建文档，而是真正深入理解根本原因并采取预防措施。AWS的方法论注重快速缓解客户影响，同时保留详细的事件数据用于后续分析，并通过系统化的流程确保从每次事件中学习和改进。

## 详细时间线与关键要点

### 开场介绍 (00:00 - 02:30)
- 欢迎参会者参加AWS re:Invent 2025早上9点的会议
- 介绍讲师背景：Georgia（AWS企业支持首席工程师）和Anthony（AWS事件管理团队首席工程师）
- 两位讲师拥有超过20年的AWS事件管理综合经验
- 会议目标：分享AWS事件管理的经验教训、技巧和内部实践

### 会议议程概览 (02:30 - 04:00)
- 讨论AWS的事件管理流程
- 重点关注检测和响应机制
- 深入探讨事后回顾阶段
- 介绍如何在大规模组织中实施事件管理
- 强调事后分析不仅是文档创建，而是深入理解根本原因

### 事件检测机制 (04:00 - 08:30)
- **服务驱动检测**：包括服务层面的告警（如EC2启动延迟）和子系统层面的监控
- **合成监控（Canaries）**：模拟端到端的客户体验
- **聚合告警**：当多个服务或指标同时告警时触发，启动完整的事件响应
- **客户驱动检测**：监控流量异常和客户影响报告（社交媒体、支持案例等）

### AWS Dashboard介绍 (08:30 - 10:00)
- 2008-2009年由都柏林工程师在西雅图访问时创建
- 提供AWS服务和区域健康状况的集中视图
- 每个服务接入3-5个关键性能指标
- 可按分区深入查看服务健康状况

### 事件响应分类 (10:00 - 12:30)
- **单服务事件**：由服务告警触发，主要由服务团队处理，必要时联系AWS支持
- **多服务事件**：由聚合告警触发，涉及AWS事件响应团队（AWS IR）、AWS支持、所有受影响服务以及"常见嫌疑人"（基础服务如认证、DNS、网络等）

### 事件协调机制 (12:30 - 16:00)
- 通过工作流分解协调大规模事件响应
- **技术呼叫（Tech Call）**：工程师和服务领导参与，专注于快速缓解和解决
- **支持呼叫（Support Call）**：与受影响客户沟通，提供恢复建议和指导
- 采用并行调查而非串行调查方式

### 技术呼叫详解 (16:00 - 22:00)
- 由AWS事件响应团队（AWS IR）支持，该团队拥有整个流程和工具
- **呼叫领导者（Call Leader）**：在未知场景下做出关键决策的资深人员，全AWS仅个位数
- 呼叫与工单配对，明确区分口头讨论和书面记录的内容
- 严格的呼叫礼仪：明确谁可以发言，控制麦克风使用
- 服务团队可以分叉到独立呼叫进行深入调查，但保持至少一名工程师作为桥梁

### 技术工单示例 (22:00 - 26:00)
- **错误日志记录**：即使日志存储在其他地方，也要在工单中记录以便即时可见
- **回滚操作记录**：分享回滚启动信息和部署管道链接
- **指标分享**：显示稳定状态、异常开始、告警阈值和恢复情况
- **潜在关联发现**：工程师分享可能的指标关联，帮助其他团队识别问题

### 支持呼叫职责 (26:00 - 30:00)
- 由AWS事件管理团队运营，负责客户沟通
- 通过个人健康仪表板（PHD）和服务健康仪表板发送通知
- 主动联系客户团队，提供恢复指导和最佳实践
- 使用案例趋势和客户反馈验证缓解措施的有效性
- 与技术呼叫保持双向实时沟通

### Command Center工具演示 (30:00 - 32:30)
- AWS的一体化支持工具
- 左侧显示事件元数据：受影响的服务、开始时间、客户联系人
- 中间显示内部摘要，供面向客户的团队实时了解情况
- 消息标签显示已发送给客户的通信
- 情绪标签跟踪和报告客户反馈

### 客户沟通策略 (32:30 - 35:30)
- **速度优先**：尽快通知客户问题发生
- **准确性**：针对实际受影响的客户，提供相关和可操作的信息
- **深度**：清晰度随时间递增，首次通信可能较为通用，后续更新提供具体细节、解决方案和时间估计

### 缓解措施 (35:30 - 42:00)
- **转移故障**：从故障组件转移流量（如从故障可用区移除流量）
- **回滚**：事件开始时首先检查是否有部署，怀疑相关时立即回滚
- **扩展资源**：在云环境中增加资源以应对资源使用增加
- **重启组件**：清除缓存和缓冲区，但需保留部分节点用于调查
- **前滚**：仅在极度确信的情况下进行配置更改或部署新版本

### 解决阶段准备 (42:00 - 45:30)
- 与客户确认缓解措施有效性
- 评估问题复发风险，确保临时修复措施持久
- 检查其他服务是否使用相同的有问题组件
- 形成根本原因假设，为深入调查做准备

### 事件关闭前检查清单 (45:30 - 48:00)
- 验证所有防止复发的短期修复措施已完成
- 保存所有可能需要的数据和日志（包括开发人员笔记本中的截图）
- 为所有涉及团队分配事后分析任务
- 确保对后续步骤有共同理解和协调计划

### 事后分析原则 (48:00 - 51:00)
- 创建安全空间，理解决策背景
- 假设所有决策都是出于最佳意图
- 鼓励建设性批评
- 必要时进行多次回顾
- 深入分析每个希望防止复发的失败

### COE文档结构 (51:00 - 54:00)
- COE代表"纠错"（Correction of Errors）
- 包含影响摘要和事件时间线
- 详细描述客户体验和事件生命周期
- 通过"五个为什么"深入挖掘根本原因
- 从根因中提取经验教训和行动项

### 检测分析重点 (54:00 - 57:00)
- 对检测速度进行严格自我批评
- 验证内部指标是否准确反映客户体验
- 评估检测类似事件模式的能力
- 持续改进检测机制，直到实现即时检测和自动缓解

### 依赖关系分析 (57:00 - 61:00)
- 不允许团队简单地将问题归咎于依赖项
- 验证依赖项是否按承诺工作（可用性、RPO、RTO等）
- 检查依赖项的实现方式
- 分析故障模式是否可预期
- 寻找减少爆炸半径的机会（优雅降级、缓存结果等）

### "五个为什么"方法论 (61:00 - 67:00)
- "五"不是固定数字，应持续追问直到找到有意义的改进机会
- 不应视为链条而应视为树状结构
- 承认事件通常由多个因素共同导致
- **示例对比**：
  - 简单链条：API失败 → 主机返回500错误 → IO错误 → EBS卷问题 → 可用区部分故障
  - 树状分析：同时考虑健康检查失败、检测延迟等多个根因分支
- 添加具体数据（如3%错误率持续45分钟）使分析更精确

### 多维根因分析示例 (67:00 - 结束)
- 并行分析多个根因分支
- 发现健康检查配置错误（服务模板中的bug）
- 分析45分钟影响时长，发现前30分钟工程师未被通知
- 识别检测时间改进机会
- 强调全面分析比单一根因链更有价值