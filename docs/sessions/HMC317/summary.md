# AWS re:Invent 2025 技术会议总结

## 会议概述

本次会议由AWS的两位解决方案架构师Karim Ahnuk和Muhammad Salah主讲，重点探讨了如何利用AWS技术解决制造业中计划外停机（unplanned downtime）这一重大挑战。全球前500强制造商每年因计划外停机损失高达1.4万亿美元，相当于西班牙的GDP总量，占其年收入的11%。

会议展示了一个完整的解决方案架构，通过在AWS Outpost上部署AI代理应用，结合小语言模型（SLM）微调、检索增强生成（RAG）技术和实时遥测数据分析，帮助制造商实现智能化运维。该方案特别强调了边缘计算的重要性，确保在网络断开的情况下工厂仍能保持智能决策能力。演讲者通过现场编码演示，详细展示了从基础设施部署、数据准备、模型微调到AI代理开发的完整流程，并通过"LLM作为评判者"的评估方法证明微调模型在RAG任务中比基础模型性能提升了14%。

## 详细时间线与关键要点

### **开场介绍 (0:00-2:30)**
- **0:00** - Karim Ahnuk自我介绍：AWS高级解决方案架构师，在德国帮助大型制造商部署GenAI应用近三年
- **0:45** - Muhammad Salah介绍：负责中东地区公共部门的解决方案架构师

### **问题定义 (2:30-8:00)**
- **2:30** - 提出核心问题：工厂中的"沉默"——计划外停机导致生产线停止、订单延迟、成本激增
- **3:15** - 关键数据：全球前500强制造商每年因此损失1.4万亿美元，相当于西班牙GDP
- **4:00** - 四大挑战详解：
  - 数据孤岛：每台机器有独立数据库，缺乏端到端视图
  - 技能差距：资深专家的知识未能共享给初级员工
  - 生产延误：缺乏专业知识和数据连接导致无法及时响应
  - 运营中断：工厂位于偏远地区，网络不稳定影响云端访问

### **解决方案架构 (8:00-15:00)**
- **8:00** - 提出方案：在AWS Outpost上构建统一数据湖
- **9:00** - 集成挑战：不同OEM设备使用不同协议（MQTT、LoRaWAN、REST API、SFTP）
- **10:00** - 技术栈：使用EKS本地集群部署统一API，整合不同数据源
- **11:30** - 展示结果：生产线全景视图，实时监控机器状态和质量检测
- **13:00** - 弹性设计：部署多个小语言模型实现边缘智能，确保断网时仍可运行

### **应用场景演示 (15:00-20:00)**
- **15:00** - 饼干工厂案例：三台关键设备（成型机、冷冻隧道、质检机）
- **16:30** - 工作流程：质检机检测到破损饼干后，AI代理分析遥测数据和手册，提供解决方案
- **18:00** - 架构深入：展示完整的数据准备和模型微调管道

### **基础设施部署 (20:00-30:00)**
- **20:00** - 开始编码演示：使用EC2实例模拟AWS Outpost环境
- **21:00** - 互动环节：观众投票选择EC2实例所需依赖项
- **23:00** - 第一台EC2（代理服务器）依赖：代理代码、Docker运行时、Ollama、NVIDIA工具包、Python 3.10+
- **26:00** - 第二台EC2（微调模型服务器）依赖：Docker、微调模型、Ollama、SLM

### **模型部署策略 (30:00-40:00)**
- **30:00** - GPU硬件约束：G4DN.12xlarge配备4个T4 GPU，每个16GB显存
- **32:00** - 量化技术：将FP16模型量化为FP4，内存占用从40GB降至13GB
- **34:00** - 性能权衡：量化可节省65%内存，但准确率损失1-2%
- **36:00** - 两种部署策略：
  - 完整模型复制：适合低延迟工作负载，并行处理多客户端
  - 模型分片：跨GPU分片权重，增加KV缓存以支持更大上下文窗口

### **数据准备与微调 (40:00-55:00)**
- **40:00** - 数据源展示：CSV、文本和PDF文件，来自不同OEM厂商
- **42:00** - 微调目标：让模型理解操作步骤、严重性、合规性和安全要求
- **44:00** - 数据管道演示：读取文档、调用Bedrock生成结构化问答数据
- **47:00** - 关键技术点：
  - 使用Converse API实现模型灵活切换
  - 配置最大token数确保完整响应
  - 系统提示词包含详细指令和单样本示例
- **50:00** - 确定性验证：防止LLM幻觉，验证生成内容的正确性和结构
- **52:00** - 智能分片：确保段落和句子完整性
- **54:00** - 结果统计：请求50对问答，生成45对，拒绝5对（因验证失败）

### **SageMaker微调流程 (55:00-62:00)**
- **55:00** - 进入SageMaker AI Studio界面
- **56:00** - 选择模型：Meta Llama 3.2 3B Instruct
- **57:30** - 配置训练：选择数据集、设置S3输出路径、5个epoch
- **59:00** - 推荐配置：使用G5实例进行微调
- **60:30** - 提交微调任务

### **模型评估 (62:00-70:00)**
- **62:00** - 提出问题：为什么同时使用微调和RAG？
- **63:30** - 观众回答：数据库可能更新，需要检索最新信息
- **64:00** - 详细解释：微调获得技能和语气，RAG检索最新知识
- **65:00** - LLM作为评判者评估方法介绍
- **66:00** - 评估流程：
  - 微调模型和基础模型都基于测试数据生成答案
  - 使用三个评判模型：Claude 3.5 Sonnet、Claude 3.5 Haiku、Amazon Nova Pro
  - 三个评估标准：准确性、完整性、相关性
- **68:00** - 评估结果：微调模型平均性能提升14%（Haiku 17%、Sonnet 15%、Nova Pro 10%）

### **AI代理开发 (70:00-85:00)**
- **70:00** - SSH连接到EC2实例，进入工厂代理目录
- **71:00** - RAG工具开发：
  - 创建RAG检索器类
  - 使用ChromaDB作为向量存储
  - 实现搜索方法
- **74:00** - 添加生成部分：
  - 实例化Ollama客户端
  - 调用微调模型生成答案
  - 完成完整的RAG工具
- **77:00** - 遥测工具开发：
  - 读取CSV格式的实时遥测数据
  - 设备包括：冷冻隧道、饼干成型机
  - 传感器类型：温度、速度
- **80:00** - 创建遥测工具方法：
  - 使用@tool装饰器
  - 实现get_telemetry_data方法
  - 参数：设备名称、回溯分钟数
  - 使用Strands的current_time功能
- **82:00** - 工具测试：查询冷冻隧道最近5分钟数据
- **83:30** - 添加设备列表查询工具：帮助代理了解可用设备

### **代理集成与系统提示 (85:00-90:00)**
- **85:00** - 创建工厂代理类
- **86:00** - 使用GPT-OSS作为路由模型
- **87:00** - 系统提示结构：
  - 工具说明和访问权限
  - 场景示例和少样本提示
  - 用户交互示例和工具调用顺序
- **88:30** - 实例化Strands代理，整合所有工具
- **89:00** - 准备UI测试（由Kiro协助创建）

### **总结 (90:00-结束)**
- 完整演示了从基础设施到AI代理的端到端实现
- 强调边缘计算和离线能力的重要性
- 展示了微调+RAG组合方案的优势
- 提供了可复制的实践方法和代码示例