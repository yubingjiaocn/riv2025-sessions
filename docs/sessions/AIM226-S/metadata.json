{
  "title": "AWS re:Invent 2025 - High-performance inference for frontier AI models (AIM226)",
  "title_cn": "AWS re:Invent 2025 - 前沿AI模型的高性能推理 (AIM226)",
  "abstract": "How do you go from state-of-the-art foundation model to a globally available usage-based API? This session provides an overview of the roadmap and architecture from model performance optimization to multi-region GPU-based infrastructure setup to the precise mechanics of request prioritization, token accounting, and rate limiting. Building on an inference stack that includes technologies like NVIDIA Dynamo, TensorRT-LLM, and Amazon EKS, we'll trace the path from model weights to a robust production service. This presentation is brought to you by Baseten, an AWS Partner.",
  "abstract_cn": "如何从最先进的基础模型发展到全球可用的按使用量计费的API？本次会议概述了从模型性能优化到多区域GPU基础设施设置，再到请求优先级排序、令牌计费和速率限制的精确机制的路线图和架构。基于包括NVIDIA Dynamo、TensorRT-LLM和Amazon EKS等技术的推理堆栈，我们将追踪从模型权重到稳健生产服务的路径。本演示由AWS合作伙伴Baseten提供。",
  "presenter": [
    {
      "name": "Philip Kiely",
      "title": "Head of Developer Relations",
      "company": "Baseten"
    }
  ],
  "attributes": {
    "topic": "Developer Tools",
    "area_of_interest": [
      "Global Infrastructure",
      "Generative AI"
    ],
    "services": [],
    "type": "Lightning talk"
  },
  "video_url": "https://www.youtube.com/watch?v=iTcVCqpLsbU",
  "session_code": "AIM226-S"
}