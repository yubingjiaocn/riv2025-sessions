# AWS re:Invent 2025 技术分享会总结

## 会议概述

本次分享会由 CircleCI 首席工程师 Michael Webster 主讲,主题聚焦于 AI 代理(Agents)对软件开发生命周期(SDLC)的影响。演讲者通过分析 GitHub 公共数据和 CircleCI 内部数据,揭示了 AI 代理在实际开发中的快速增长趋势。数据显示,从 2025 年 5 月开始,AI 代理不仅仅停留在代码审查和问题分类阶段,而是开始真正推送代码到生产环境,其推送活动量已接近评论活动量。

然而,这种快速增长也带来了新的挑战。演讲者指出,尽管 AI 代理能够快速生成代码,但由于代码审查、测试和部署流程没有相应提速,导致出现了严重的队列积压问题。根据队列理论,当工作到达速度超过处理速度时,延迟会急剧增加。实际数据也印证了这一点:许多团队报告构建稳定性下降,开发人员倦怠增加,而整体交付效率提升仅约 10%,且主要集中在高级工程师群体。Webster 提出,解决方案的核心在于加速验证流程,而非仅仅优化 AI 提示词或模型选择。

## 详细时间线与关键要点

[00:00 - 01:30] 开场与演讲者介绍
- Michael Webster 自我介绍,CircleCI 首席工程师
- 会议主题:AI 代理对 SDLC 的影响及解决方案

[01:30 - 03:45] AI 代理工作流的发展历史
- 2021-2022 年:开发者在终端、IDE 和 ChatGPT 之间复制粘贴
- 中期阶段:IDE 集成的代理工具,具备长期规划和执行能力
- 当前阶段:无头代理(Headless Agents)出现,可通过 CLI 在 Docker 容器中运行,支持定时任务和 Webhook 触发

[03:45 - 06:30] GitHub 公共数据分析
- 分析了 GitHub 公共存档中的机器人活动数据(截至 2024 年底)
- 追踪了 5-6 个主流编码代理(Copilot、Claude、Codex 等)
- 数据显示代理活动呈现快速增长趋势
- 关键转折点:2025 年 5 月开始,代理从单纯的 PR 评论转向实际推送代码
- 到 10 月份,某些周的推送活动量已接近评论活动量

[06:30 - 08:15] CircleCI 内部数据验证
- CircleCI 平台数据显示类似的增长趋势
- 这些数据代表真实的生产环境工作,不仅是业余项目
- 统计的是实际触发 CI 流水线的活动(包含单元测试和部署配置)
- 数据为保守估计,未包含以个人名义提交的 AI 生成代码

[08:15 - 10:45] 问题识别:队列理论分析
- 核心问题:代码编写速度提升,但后续流程(审查、测试、部署)未能跟上
- PR 规模变大(有时达到 2000 行),审查时间延长
- 开源项目开始要求 AI 使用披露
- 构建稳定性未见改善
- 应用队列理论:当工作到达速度超过处理速度,延迟会累积

[10:45 - 12:30] 队列模拟演示
- 展示了不同 AI 加速场景下的队列延迟模拟
- 基线假设:代码处理速度是编写速度的 2 倍
- 结论:如果只提升编写速度而不提升处理速度,延迟会急剧增加
- 人类工作有自然限制,但代理可以持续工作,导致积压更严重

[12:30 - 14:00] 行业反馈与数据
- DORA 指标显示许多团队报告 AI 导致的不稳定性增加
- 产品效能提升有限
- 开发人员倦怠增加
- 行业基准显示 AI 带来约 10% 的改进,但分布不均
- 高水平开发者获益最多,普通开发者收益甚微甚至为负

[14:00 - 16:15] 解决方案:加速交付流程
- 核心策略:提升交付速度而非仅提升编码速度
- 模拟显示:即使 AI 不提升编码速度,加快交付也能减少延迟
- 这对使用或不使用 AI 的团队都有益

[16:15 - 19:30] 实施方法:基础工程实践
- 强调许多解决方案是传统工程实践,非尖端 AI 技术
- 关键实践:可靠的验收测试、高质量的自动化测试、快速的 CI/CD 流水线
- 需要对交付流水线进行投资
- AI 可以辅助这些改进(如将 Bash 脚本重写为编译型语言)

[19:30 - 23:45] 验证优先的方法论
- 核心理念:专注于验证而非提示工程
- 基本循环:制定计划 → 执行工作 → 评估质量 → 通过或重试
- 这是 TDD(测试驱动开发)和 CI 的基础模式

[23:45 - 26:30] 验证方法的优势
- 可扩展性:适用于单个任务到训练 RL 代理的各个层级
- 持久性:不受 AI 技术快速变化影响(链式思考、图式思考等)
- 可操作性:大多数组织都能实施,无需训练自定义模型

[26:30 - 29:15] 上下文管理策略
- 验证流水线的输出可作为代理的上下文输入
- 建议使用 AI 总结任务结果,反馈用于改进提示和工具
- 三个关键控制点:工具、任务/提示、检查机制
- 推荐自下而上的方法:从检查开始,改进任务定义,最后提取为工具

[29:15 - 31:45] CircleCI 的实践经验
- 使用 CI 流水线和本地测试反馈来优化模型输出
- 建立基线后,将过程提取为规则供团队复用
- 示例:修复 Playwright 不稳定测试的流程标准化
- 将一次性函数抽象为可复用的规则库

[31:45 - 35:30] Chunk 产品介绍
- CircleCI 开发的 AI 代理产品,基于验证优先原则构建
- 核心功能:确保软件始终经过验证
- 每次修改代码都会执行 CI 流水线验证
- 复用现有的 CI 环境和配置,无需重新发明轮子
- 保持软件生产就绪状态

[35:30 - 37:45] Chunk 的具体能力
- 首要任务:修复不稳定测试(Flaky Tests)
- 提升代码覆盖率,为代理提供更好的上下文
- 处理 CI 流水线维护工作
- 构建优化和性能提升
- 利用完整的变更历史(从提交到部署或回滚)来调优代理

[37:45 - 39:00] 总结与要点回顾
- AI 代理采用趋势真实且快速增长
- 当前数据可能低估了实际使用情况
- 并非所有组织都能均匀受益,存在负面影响
- 投资交付流程是良好起点
- 验证是保持代理快速可靠的基础

[39:00 - 39:30] 结束与互动邀请
- 邀请参会者到 CircleCI 展位(1451 号)了解更多信息和演示
- 演讲者会后可进行交流