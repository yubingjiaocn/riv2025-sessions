# AWS re:Invent 2025 会议总结：三星云 DynamoDB 大规模数据迁移实践

## 会议概述

本次会议由三星云（Samsung Cloud）的首席软件工程师 Manzo 主讲，分享了团队如何成功解决平台上的大规模技术挑战。三星云为全球数十亿 Galaxy 用户提供核心云服务，包括同步、备份和恢复功能，支持三星笔记、三星健康和三星浏览器等热门应用。平台每月处理超过 10 亿活跃设备，每天处理 500 亿次请求，使用 Amazon DynamoDB 作为主要数据库存储核心同步数据。

随着服务规模的增长，特别是三星浏览器的标签页数据不断生成和更新，数据量快速膨胀。到 2025 年初，单个表的大小已达到 1.2 PB，每月消耗数十万美元的 AWS 存储成本。团队面临双重任务：将存储成本削减 50%，并在三个月内收回全部优化投资。通过数据驱动的决策、深入的领域知识理解和以用户为中心的理念，团队最终在一周内完成了迁移，将表大小从 1.2 PB 缩减至 100 TB，实现了 150% 的目标，且整个过程中零客户投诉。

## 详细时间线与关键要点

00:00 - 开场介绍
- 演讲者 Manzo 介绍自己是三星云的首席软件工程师
- 将分享团队解决平台大规模技术挑战的故事

00:30 - 三星云平台介绍
- 三星云为全球数十亿 Galaxy 用户提供服务
- 提供同步、备份和恢复等核心云服务
- 支持三星笔记、三星健康、三星浏览器等应用
- 确保用户数据在所有设备间保持一致和可用

01:00 - 平台规模
- 每月处理超过 10 亿活跃设备
- 每天处理 500 亿次请求
- 选择 Amazon DynamoDB 作为主要数据库
- 使用 DynamoDB 存储核心同步数据

01:30 - 问题聚焦：标签页数据
- 重点关注三星浏览器的标签页数据集
- 标签页信息在用户打开、关闭或切换标签时不断生成和更新
- 随着服务增长，持续的创建和更新导致数据量快速增长

02:00 - 问题规模
- 到 2025 年初，表大小达到 1.2 PB
- 每月消耗数十万美元的 AWS 存储成本

02:30 - 任务目标
- 第一：将存储成本削减 50%
- 第二：在三个月内收回全部优化投资（关键 ROI 目标）

03:00 - 数据分析挑战
- 1.2 PB 的表包含数万亿条记录
- 无法分析所有数据，决定采样分析以了解数据特征

03:30 - 数据分析结果
- 发现 90% 的表数据由已删除记录或墓碑记录（tombstones）组成
- 当用户关闭标签页时，系统不会立即删除数据，而是将状态改为"已删除"并保留 6 个月
- 这种机制对于非活跃设备重新连接时接收完整同步历史很重要

04:00 - 深入分析发现技术债务
- 墓碑机制本身不是问题
- 深入挖掘发现 60% 的墓碑记录已超过 6 个月
- 早期专注于快速开发和稳定性，导致数据生命周期管理等长期任务被推迟
- 这是团队的技术债务

04:30 - 优化策略考虑
- 基于分析，决定通过删除所有超过 6 个月的数据来优化表
- 考虑两种主要策略：
  - 策略 A：清理现有表，直接查找和删除数据
  - 策略 B：创建新表，仅迁移需要保留的数据

05:00 - 策略 A 的问题
- 直接扫描和删除方法需要扫描数万亿条记录
- 消耗大量 RCU 和 WCU
- 预计需要超过 6 个月时间
- 总费用相当于数月的存储费用
- 无法达到 3 个月的 ROI 目标
- 立即排除策略 A

05:30 - 策略 B 的优势
- 仅迁移必要数据，处理的数据集更小
- 将需要处理的数据量减少到原始数据的 40%

06:00 - 策略 B 的挑战
- 虽然迁移 40% 的数据量是改进
- 但 RCU 和 WCU 仍需数十万美元
- 需要找到更好的方法

06:30 - 重新思考服务本质
- 从技术细节中退一步，重新聚焦服务的整体目的
- 系统为删除记录保留 6 个月的传播期
- 开始质疑这个基本假设：6 个月的保留窗口是否真正必要？

07:00 - 删除记录传播时间调查
- 删除记录的目的是在信号传播到所有设备后完成
- 测量删除记录完全传播到所有设备所需的时间
- 调查结果出乎意料

07:30 - 传播时间数据分析
- 少于 0.1% 的设备需要超过一周时间来传播标签页删除历史
- 剩余 99.9% 的设备在一周内完成传播
- 99% 的设备在 3 天或更短时间内接收到删除历史

08:00 - 关键决策点
- 基于数据，面临重要决策：是否将删除历史窗口从 6 个月缩短到 1 周
- 优势：迁移数据量将减少 96%（从 24 周减少到 1 周）
- 这将大幅降低存储和处理费用

08:30 - 决策的权衡
- 技术限制：约 0.1% 的设备将失去仅数据同步能力
- 这些用户将被迫获取完整数据集而非增量更改

09:00 - 全量同步风暴风险
- 长时间不活跃的设备会造成系统级风险
- 在三星云规模下，0.1% 仍然是数百万设备
- 如果这些设备同时请求全量同步，可能导致流量激增
- 可能使系统过载并触发限流或停机

09:30 - 突破点：99 标签页限制
- 与三星浏览器团队合作，了解到关键操作行为
- 99 标签页限制策略：任何设备都不能拥有超过 99 个打开的标签页
- 这是突破点

10:00 - 风险量化
- 全量同步风暴只有在负载无限且不可预测时才危险
- 99 标签页限制量化了风险
- 任何全量同步的最大数据量都保持在小而可预测的大小
- 这消除了最大的担忧

10:30 - 最终决策
- 有了数据传播洞察和 99 标签页策略
- 正式决定将删除历史窗口改为 1 周
- 需要迁移的总数据量从 40% 降至仅 10%
- 从数万亿条记录大幅减少到数千亿条记录

11:00 - 明确的任务
- 在 1.2 PB 表中找到符合标准的 10% 数据
- 迁移到新表
- 快速完成以最大化成本效益

11:30 - 核心原则建立
- 在构建任何东西之前，建立两个指导原则
- 第一原则：用户体验优先 - 项目不能给用户带来任何负面体验
- 第二原则：受控执行 - 每一步都必须可预测、可观察和完全可控

12:00 - 零停机目标
- 目标不是系统级零停机，而是用户体验的零停机
- 采用按用户迁移策略
- 未迁移的用户继续使用旧表
- 用户数据迁移完成后，所有请求重定向到新表

12:30 - 迁移期间的请求处理
- 设备数据传输期间，设备处于锁定状态
- 此期间到达的任何请求都会被临时拒绝
- 直到迁移完成并切换设备
- 如果用户遇到临时错误，客户端会在几秒内自动重试，确保无缝体验

13:00 - 控制塔：迁移状态表（MST）
- 引入迁移状态表（MST）解决路由问题
- MST 记录每个用户的迁移状态
- 对于每个同步请求，同步服务首先查询 MST
- 确定用户迁移状态并访问正确的表

13:30 - 单点故障识别
- 架构中的关键风险：迁移状态表本身
- 流量调节器保护新表，但没有保护 MST
- MST 是单点故障

14:00 - 应用 AWS 恒定工作原则
- 在 MST 前放置 Amazon ElastiCache 实例
- 使同步服务首先查询缓存
- 预热后备状态表，使底层 DynamoDB 表准备好立即服务流量
- 调整预配置容量的最小值，确保表始终接受完整请求（即使在缓存中断期间）

14:30 - 速度与控制的平衡
- 迁移的目标是速度，但只关注速度会损害稳定性和控制
- 采用受控执行原则
- 不是打开闸门，而是管理流量
- 限制并发迁移用户的最大数量，就像控制大坝防止下游洪水

15:00 - 受控执行的四大优势
- 保护旧表免受 RCU 问题影响
- 确保新表可预测地扩展
- 确保基础设施稳定和安全
- 通过使数据流精简和恒定来保证可观察性

15:30 - 流量调节器实现
- 使用作业馈送器（job feeder）和工作队列的组合创建流量调节器
- 作业馈送器向工作队列提供用户 ID
- 迁移工作器从工作队列拉取作业并执行数据迁移
- 队列严格限制正在迁移的最大用户数

16:00 - 背压机制
- 如果队列满，背压机制会自动暂停作业馈送器
- 这种自我调节系统确保吞吐量保持在计划水平

16:30 - 数据提取挑战
- 最后的技术障碍：如何在 1.2 PB 表中找到 10% 的必要数据
- 如果必须读取每个项目来决定是否需要，仍会产生大量 RCU 成本
- 会立即威胁项目时间表

17:00 - 突破：利用现有同步机制
- 突破不是来自新技术，而是查看现有同步服务的基本机制
- 基于时间戳的同步：通过跟踪下一次修改的确切时间戳工作
- 允许设备仅下载错过的更改
- 表包含按时间戳键控的本地二级索引（LSI）以支持此功能

17:30 - LSI 的关键优势
- LSI 将状态作为投影属性
- 这允许通过读取轻量级索引过滤掉 90% 的旧数据
- 无需触及主表
- 不是繁重的表扫描，而是运行过滤查询

18:00 - 两步数据提取过程
- 第一步：使用 LSI 查找要迁移的数据
  - 运行单个 LSI 查询获取两个目标组
  - 所有活跃标签页和上周的所有删除记录
- 第二步：使用第一步的标签页 ID 拉取实际数据
  - 不是逐个获取项目，而是使用 BatchGetItem API

18:30 - 数据提取效率
- LSI 查询成本效益高且快速，避免全表扫描
- BatchGetItem API 有效地收集所有数据
- 这种组合大幅降低了读取容量单位

19:00 - 迁移结果：技术指标
- 整个迁移在一周内完成
- 得益于受控执行原则，并发迁移用户数稳定在数万
- 旧表的写入吞吐量稳步下降，显示流量逐渐减少
- 新表的读写吞吐量平稳稳定增长，没有明显峰值

19:30 - 迁移结果：财务指标
- 影响立竿见影且巨大
- 表大小从 1.2 PB 减少到仅 100 TB
- 大幅削减存储账单
- 得益于策略，迁移成本最小
- 总费用不到一个月的节省
- 在下一张 AWS 账单到达之前就收回了全部投资
- 实现了原始目标的 150%

20:00 - 迁移结果：客户指标
- 最重要的指标：在整个迁移期间，收到零客户咨询或与迁移相关的故障报告
- 这是团队最自豪的数字
- 这是用户体验原则不是口号的最终证明

20:30 - 关键经验一：数据驱动决策
- 数据采样首次揭示了问题：60% 的表是旧墓碑记录
- 数据分析为解决方案提供了信心
- 分析日志发现 99.9% 的信号在一周内传播
- 做出最关键的决定：将删除历史窗口从 6 个月改为 1 周
- 数据消除了猜测工作
- 在每个关键节点应用数据优先方法

21:00 - 关键经验二：深入的领域理解
- 数据本身不够，数据给出数字，但只有领域知识给出意义
- 第一个洞察来自提出基本服务问题：墓碑记录的真正目的是什么？
- 这是允许首先挑战 6 个月规则的关键
- 第二个洞察不仅是发现 99 标签页限制策略
- 而是意识到该策略的意义：它自然地保持了全量同步的小规模，立即消除了最大的技术风险

21:30 - 关键经验三：以用户为中心的思维
- 这是指导每个决策的原则
- 如果损害用户体验，技术和财务成功毫无意义
- 这种思维方式是选择最安全路径而非简单路径的原因
- 团队学到了成功的真正衡量标准

22:00 - 总结
- 成功不是迁移了多少 PB 或节省了多少美元
- 而是与用户保持的信任
- 1.2 PB 迁移，零客户投诉

22:30 - 结束
- 演讲结束，掌声