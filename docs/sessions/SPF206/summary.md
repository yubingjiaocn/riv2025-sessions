# AWS re:Invent 2025 - Ticketmaster 利用 AWS 提升现场活动粉丝体验

## 会议概述

本次会议(SPF 206)由 AWS 和 Ticketmaster 联合呈现,重点探讨了如何通过 AWS Local Zones 解决延迟问题,从而提升现场活动的粉丝体验。Ticketmaster 作为拥有近50年历史的全球领先票务平台,每年销售超过6亿张门票,处理超过20亿次网站访问。会议由 AWS 边缘计算和推理团队的 Susita Marupaka、AWS EC2 Local Zones 产品经理 Sylvia Lu,以及 Ticketmaster 的杰出架构师 Mike Fuller 共同主讲。

会议深入讨论了 Ticketmaster 从传统数据中心架构向混合云架构的演进历程。在这个过程中,延迟成为影响用户体验的关键因素。当用户浏览活动详情页面、查看座位图、获取票务推荐时,每个交互都需要多个微服务和数据库的串行调用,延迟的累积会严重影响用户体验。通过部署 AWS Local Zones,Ticketmaster 成功将延迟从60毫秒降低到2毫秒以下,实现了接近本地数据中心的性能表现。

此外,Local Zones 还为 Ticketmaster 提供了弹性扩展能力。在大型演唱会门票开售等高峰时段,他们可以快速将工作负载从本地的20台服务器扩展到100台,而无需进行大量的资本投资。会议还介绍了 EKS Hybrid Nodes 如何帮助 Ticketmaster 实现工作负载的灵活部署,在本地数据中心、Local Zones 和 AWS 区域之间自由调度资源。

## 详细时间线

### 开场介绍 (0:00 - 3:30)
- **0:00** - 会议开始,多语言问候(Hello, Hola, Bonjour, Salam Alaikum, Namaste)
- **0:30** - Susita Marupaka 介绍自己,负责 AWS 边缘计算和推理的市场战略
- **1:15** - Sylvia Lu 自我介绍,AWS EC2 Local Zones 产品经理
- **2:00** - Mike Fuller 登场,Ticketmaster 杰出架构师,专注于基础设施解决方案和 AWS
- **3:00** - 现场互动:询问有多少人使用过 Ticketmaster 购票

### Ticketmaster 公司背景 (3:30 - 8:00)
- **3:30** - Ticketmaster 基本介绍:连接粉丝与现场活动的市场平台
- **4:00** - 公司历史:成立于1976年,与苹果公司同年,即将迎来50周年
- **4:45** - 业务规模:每年销售超过6亿张门票(每天近200万张),20亿次网站访问
- **5:30** - 业务范围:不仅销售门票,还处理入场验证、防欺诈检测
- **6:15** - B2B 业务:为艺术家和场馆提供活动规划、定价、座位管理等服务
- **7:00** - 全球业务:覆盖35个国家,拥有全球支持团队

### Ticketmaster 的 AWS 之旅 (8:00 - 11:30)
- **8:00** - AWS 旅程开始:大约10年前开始使用 AWS
- **8:30** - 初期使用:从基本的计算、存储、网络服务开始
- **9:00** - 现状:数百个账户、数百个 VPC、使用数百种 AWS 服务
- **9:30** - 混合架构:许多系统无法迁移到云端,保持强大的混合架构
- **10:00** - 选择 AWS 的原因之一:全球足迹,AWS 区域与 Ticketmaster 数据中心位置匹配
- **10:45** - 原因之二:清晰易用的 API 和服务,支持基础设施即代码和自动化
- **11:15** - 原因之三:快速开发和原型验证能力,降低前期投资风险

### 延迟的重要性 (11:30 - 18:00)
- **11:30** - 延迟概念:眨眼约100毫秒,需要在1毫秒内完成工作流程
- **12:00** - 用户体验影响:网站响应慢会导致用户流失
- **12:45** - 活动详情页面示例:展示 Sphere 场馆的票务信息
- **13:30** - 功能介绍:主要票务、转售票务、座位推荐、交互式座位图
- **14:15** - 技术挑战:每个交互需要不同的服务、微服务和数据库通信
- **15:00** - 地理分布:应用和数据库分布在全球各地,不在同一位置
- **15:45** - 串行依赖:必须先知道可用座位才能显示座位图和推荐
- **16:30** - 复合延迟问题:多个50-100毫秒的调用累积会严重影响用户体验
- **17:15** - 两个选择:接受糟糕体验(不可行)或限制网站功能(次优)

### 基础设施架构演进策略 (18:00 - 24:00)
- **18:00** - 三个关键演进阶段概述
- **18:30** - 阶段一:云之前 - 美国东西海岸数据中心(弗吉尼亚和凤凰城)
- **19:15** - 本地通信:同一数据中心内延迟低,不是问题
- **19:45** - 跨数据中心通信:凤凰城到弗吉尼亚约2000英里,延迟60毫秒
- **20:30** - 阶段二:早期云 - 10年前开始到最近
- **21:00** - 美国东部选择:弗吉尼亚 AWS 区域,与本地数据中心单位数毫秒延迟
- **21:45** - 西部挑战:凤凰城没有 AWS 区域,选择俄勒冈州波特兰
- **22:15** - 改进结果:通过 Direct Connect 将延迟降至30-40毫秒
- **22:45** - 阶段三:Local Zones - 约一年前开始
- **23:15** - 凤凰城 Local Zone 部署,距离数据中心很近
- **23:45** - 最终结果:通过 Direct Connect 实现低于2毫秒的延迟

### AWS Local Zones 概述 (24:00 - 32:00)
- **24:00** - Sylvia 接手讲解 Local Zones
- **24:30** - Local Zones 定义:将 AWS 云扩展到更接近用户和工作负载的位置
- **25:00** - 两大用例类型:基于延迟(单位数毫秒)和基于位置(数据驻留)
- **26:00** - 尼日利亚拉各斯案例:距离开普敦区域数千英里
- **26:45** - Local Zones 解决方案:实现单位数毫秒延迟和数据驻留需求
- **27:30** - 使用体验:类似可用区,只是物理位置不同
- **28:00** - 三步配置:选择 Local Zone、扩展 VPC、创建子网和资源
- **28:45** - 架构说明:数据平面在 Local Zone,控制平面在父区域
- **29:30** - 连接方式:Direct Connect(本地设施)和互联网网关(公共互联网)
- **30:15** - 一致体验:弹性按需、按使用付费、相同 API
- **31:00** - 安全性:相同的 AWS 安全核心服务和开发者体验
- **31:30** - 网络连接:通过多条冗余高速链路连接到父区域

### Local Zones 用例和服务 (32:00 - 37:00)
- **32:00** - 三大用例类别介绍
- **32:30** - 用例一:企业工作负载 - 迁移和现代化需求
- **33:00** - 后台应用和 SaaS 应用,由于相互依赖难以完全迁移
- **33:30** - Local Zones 作为混合架构或云迁移的跳板
- **34:00** - 用例二:数据处理 - 本地数据处理或数据驻留需求
- **34:30** - 数据密集型工作负载、数据安全、主权和地缘政治法规
- **35:00** - 用例三:低延迟 - 实时医疗影像、游戏、内容创作
- **35:45** - 核心服务:通用、内存、存储优化的 EC2 实例和 EBS 卷
- **36:15** - 特定服务:RDS、FSx、S3 在特定 Local Zones 可用
- **36:45** - AI/ML 能力:P5、P6、Trainium 等加速计算实例

### Local Zones 全球覆盖 (37:00 - 39:00)
- **37:00** - 当前覆盖:35个大都市区域
- **37:30** - 美国:17个 Local Zones,包括凤凰城、洛杉矶、拉斯维加斯
- **38:00** - 国际:18个 Local Zones
- **38:30** - 未来规划:10+ 个 Local Zones 已宣布,未来几年推出

### 低延迟网络架构 (39:00 - 45:00)
- **39:00** - Susita 讲解低延迟架构
- **39:30** - 物理限制:无法欺骗物理定律,光速限制
- **40:00** - 亚毫秒延迟估算:光在1毫秒内传播约150英里
- **40:45** - Local Zones 架构:左侧 AWS 区域,右侧 Local Zone
- **41:15** - 配置步骤:选择 Local Zone、扩展 VPC、创建子网
- **42:00** - 两个入口点:Direct Connect(本地设施)和互联网网关(公共互联网)
- **42:45** - 策略一:Direct Connect - 从本地设施到 Local Zone
- **43:15** - 策略二:全球连接 - 通过 Transit Gateway 连接到父区域和全球网络
- **43:45** - 策略三:东西向连接 - Local Zones 之间通过 VDX Gateway 低延迟连接
- **44:30** - 多 VPC 场景:数百个 VPC 和账户的架构

### Ticketmaster 网络实现 (45:00 - 48:00)
- **45:00** - Mike 展示 Ticketmaster 的实际网络架构
- **45:30** - 遵循 AWS 最佳实践
- **46:00** - 本地数据中心:凤凰城(右侧)
- **46:30** - 两个 Direct Connect:波特兰(连接父区域)和凤凰城(连接 Local Zones)
- **47:00** - 波特兰连接:通过 Transit Gateway 访问所有 VPC 和全球区域
- **47:30** - 凤凰城连接:专用 Direct Connect Gateway 连接凤凰城和洛杉矶 Local Zones
- **48:00** - 多路径优化:选择最低延迟路径

### 规模和弹性扩展 (48:00 - 52:00)
- **48:00** - Susita 询问如何处理大规模增长
- **48:30** - 两种销售类型:日常基线销售和高峰开售活动
- **49:00** - 开售挑战:需要大幅增加容量支持高峰流量
- **49:45** - AWS 弹性:使用自动扩展组快速扩展
- **50:15** - 本地资源挑战:无法在 AWS 运行的系统也需要扩展
- **50:45** - 传统方案:大量资本投资购买服务器,但闲置时浪费
- **51:15** - Local Zones 方案:突发到云端支持额外容量
- **51:45** - 实际案例:从日常20台服务器扩展到100台,活动后缩减

### EKS Hybrid Nodes (52:00 - 55:00)
- **52:00** - 工作负载放置灵活性目标
- **52:30** - Ticketmaster 是重度 Kubernetes 用户
- **53:00** - EKS Hybrid Nodes:Amazon 托管的 Kubernetes 服务
- **53:30** - 控制平面:运行在父区域(波特兰)
- **54:00** - 节点部署:可部署到本地、Local Zone 或父区域
- **54:30** - 灵活性:根据需要在三个位置之间转移工作负载
- **55:00** - Susita 补充:100% 上游 Kubernetes 兼容,访问全球社区创新
- **55:30** - 一致的开发者体验:构建一次,随处部署

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


会议总结: 本次会议展示了 AWS Local Zones 如何帮助 Ticketmaster 这样的大型企业解决延迟和混合云架构挑战,通过将云服务部署到更接近用户和数据中心的位置,实现了从60毫秒到2毫秒以下的延迟优化,同时提供了弹性扩展和工作负载灵活部署能力。