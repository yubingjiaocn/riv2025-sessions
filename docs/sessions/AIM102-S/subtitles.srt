1
00:00:00,200 --> 00:00:01,100
Hello, everyone.

2
00:00:01,360 --> 00:00:03,500
Welcome to our session today.

3
00:00:03,798 --> 00:00:04,360
Uh,

4
00:00:04,839 --> 00:00:07,038
before I begin introducing my

5
00:00:07,038 --> 00:00:08,148
presentation partner,

6
00:00:08,640 --> 00:00:10,858
I would like to assess a little bit of

7
00:00:11,398 --> 00:00:13,560
what your experience is with

8
00:00:13,560 --> 00:00:15,060
regards to how you are enabling

9
00:00:15,519 --> 00:00:17,679
your agentic solutions. So, would you

10
00:00:18,199 --> 00:00:20,219
mind raising your hands if you're building

11
00:00:20,219 --> 00:00:21,059
agents

12
00:00:21,478 --> 00:00:22,579
that uh use

13
00:00:23,199 --> 00:00:25,548
off the shelf foundation models,

14
00:00:25,559 --> 00:00:27,769
querying API? Raise your hands.

15
00:00:29,228 --> 00:00:30,228
Fantastic.

16
00:00:30,708 --> 00:00:31,309
And then,

17
00:00:31,750 --> 00:00:32,908
how many of you

18
00:00:33,310 --> 00:00:35,569
are using or considering using

19
00:00:35,569 --> 00:00:37,060
custom models

20
00:00:37,590 --> 00:00:39,509
with your customize with your own data?

21
00:00:40,950 --> 00:00:41,889
That's great.

22
00:00:42,340 --> 00:00:42,859
Awesome.

23
00:00:43,469 --> 00:00:44,770
So, today,

24
00:00:45,750 --> 00:00:46,529
Um,

25
00:00:46,990 --> 00:00:48,689
my colleague Laura Mullenex,

26
00:00:48,950 --> 00:00:49,750
a senior

27
00:00:50,548 --> 00:00:52,750
worldwide specialist solution architect,

28
00:00:53,029 --> 00:00:55,418
uh, for Gen AI in SageMaker,

29
00:00:55,750 --> 00:00:56,289
and myself,

30
00:00:56,590 --> 00:00:58,889
Eric Pena, I'm a principal product manager

31
00:00:59,590 --> 00:01:00,848
for Sagemaker AI.

32
00:01:01,908 --> 00:01:03,009
We are going to

33
00:01:03,668 --> 00:01:05,790
introduce you to how SageMaker

34
00:01:05,790 --> 00:01:06,329
AI

35
00:01:06,909 --> 00:01:08,909
is going to enable you with this

36
00:01:08,909 --> 00:01:10,969
new capability we launched yesterday.

37
00:01:12,519 --> 00:01:14,519
For customizing models so

38
00:01:14,519 --> 00:01:15,219
that you can

39
00:01:16,019 --> 00:01:18,519
Create better agentic applications

40
00:01:18,808 --> 00:01:20,750
with increased performance.

41
00:01:22,120 --> 00:01:23,638
And better results.

42
00:01:25,049 --> 00:01:27,129
So, let me begin by

43
00:01:27,129 --> 00:01:28,469
setting the stage

44
00:01:29,049 --> 00:01:31,129
with a very important trend that you

45
00:01:31,129 --> 00:01:32,469
might be aware of.

46
00:01:34,198 --> 00:01:35,230
Um, a recent

47
00:01:36,250 --> 00:01:37,680
study found that

48
00:01:38,540 --> 00:01:40,239
The pace at which

49
00:01:41,409 --> 00:01:44,040
Spend in AI

50
00:01:44,040 --> 00:01:46,299
applications is growing, is twice

51
00:01:46,299 --> 00:01:48,319
as much for those

52
00:01:48,319 --> 00:01:49,918
applications that rely

53
00:01:50,299 --> 00:01:51,900
on custom models.

54
00:01:52,819 --> 00:01:55,299
You might argue that the in absolute

55
00:01:55,299 --> 00:01:56,680
values, of course.

56
00:01:57,349 --> 00:02:00,010
Um, querying directly, uh,

57
00:02:00,469 --> 00:02:01,569
foundational model,

58
00:02:02,269 --> 00:02:04,388
uh, an off the shelf foundation model API

59
00:02:04,388 --> 00:02:05,689
is still bigger,

60
00:02:06,150 --> 00:02:08,429
but the pace of growth is increasing.

61
00:02:08,949 --> 00:02:10,990
The pace of growth is twice as much for

62
00:02:10,990 --> 00:02:11,909
custom models.

63
00:02:12,229 --> 00:02:14,639
So, let's understand why custom

64
00:02:14,639 --> 00:02:16,610
custom models are going to be

65
00:02:17,149 --> 00:02:18,689
more and more important.

66
00:02:19,349 --> 00:02:20,149
First of all,

67
00:02:20,550 --> 00:02:21,490
the obvious

68
00:02:22,189 --> 00:02:23,449
uh reason, right?

69
00:02:23,750 --> 00:02:25,868
If you want to have a model

70
00:02:25,868 --> 00:02:26,629
that is

71
00:02:26,929 --> 00:02:29,250
Uh, has better performance for a very

72
00:02:29,250 --> 00:02:30,629
specific domain,

73
00:02:31,250 --> 00:02:31,949
then

74
00:02:32,330 --> 00:02:33,288
leveraging

75
00:02:33,569 --> 00:02:35,610
even the most powerful of the shell

76
00:02:35,610 --> 00:02:36,629
foundation model

77
00:02:36,929 --> 00:02:39,129
might not give you the performance

78
00:02:39,129 --> 00:02:41,210
and accuracy that you're looking for for your

79
00:02:41,210 --> 00:02:42,210
specific application.

80
00:02:43,719 --> 00:02:45,008
But not only that,

81
00:02:45,750 --> 00:02:46,889
As your

82
00:02:47,750 --> 00:02:49,788
applications and agents move from

83
00:02:49,788 --> 00:02:52,189
the POC or the proof of concept

84
00:02:52,189 --> 00:02:52,929
stage,

85
00:02:53,588 --> 00:02:55,909
all the way to production implementation.

86
00:02:56,860 --> 00:02:58,899
And then become a success,

87
00:02:59,258 --> 00:03:01,879
scaling those workloads become.

88
00:03:02,808 --> 00:03:04,229
More and more,

89
00:03:04,649 --> 00:03:06,868
uh, less and less efficient

90
00:03:07,088 --> 00:03:09,490
when you're using just a, a

91
00:03:09,490 --> 00:03:10,088
mere

92
00:03:10,770 --> 00:03:12,770
uh off the shelf foundation

93
00:03:12,770 --> 00:03:13,669
model API.

94
00:03:15,389 --> 00:03:15,969
There are

95
00:03:16,349 --> 00:03:18,550
a little bit more niche reasons as well.

96
00:03:18,778 --> 00:03:21,069
Let's say that you are operating in a

97
00:03:21,069 --> 00:03:22,868
highly regulated industry,

98
00:03:23,270 --> 00:03:24,830
and you have very strict

99
00:03:25,349 --> 00:03:27,969
uh compliance and security requirements,

100
00:03:28,588 --> 00:03:30,389
then leveraging

101
00:03:30,669 --> 00:03:32,699
just an API for a foundation model

102
00:03:32,699 --> 00:03:34,849
becomes less and less feasible.

103
00:03:35,919 --> 00:03:38,038
But I think the most important point

104
00:03:38,038 --> 00:03:38,659
here

105
00:03:39,278 --> 00:03:39,949
is

106
00:03:40,610 --> 00:03:42,469
They're just building a wrapper.

107
00:03:43,368 --> 00:03:45,460
On top of one API

108
00:03:45,460 --> 00:03:46,819
of a foundation model,

109
00:03:47,219 --> 00:03:49,500
doesn't really give you a sustainable

110
00:03:49,500 --> 00:03:51,960
differentiation from a product perspective.

111
00:03:52,338 --> 00:03:54,179
Even if it's just

112
00:03:55,099 --> 00:03:57,110
Providing value for your internal

113
00:03:57,110 --> 00:03:57,960
customers,

114
00:03:58,338 --> 00:04:00,379
or even more importantly, when you're

115
00:04:00,379 --> 00:04:02,699
shipping value to external customers.

116
00:04:04,758 --> 00:04:06,058
So as you can see,

117
00:04:06,719 --> 00:04:08,199
customizing a model

118
00:04:08,800 --> 00:04:09,860
provides this

119
00:04:11,199 --> 00:04:13,618
increased value when it comes to

120
00:04:14,159 --> 00:04:14,860
how

121
00:04:15,240 --> 00:04:17,949
you will build those agentic solutions

122
00:04:18,278 --> 00:04:19,100
that you will then

123
00:04:19,920 --> 00:04:21,160
provide to your customers.

124
00:04:22,819 --> 00:04:24,399
Let's put this in context.

125
00:04:27,480 --> 00:04:28,000
Sorry,

126
00:04:28,470 --> 00:04:29,100
excuse me.

127
00:04:29,600 --> 00:04:32,319
How would you go about customizing

128
00:04:32,319 --> 00:04:33,000
a model?

129
00:04:33,889 --> 00:04:36,379
As you can imagine, this process is not always

130
00:04:36,379 --> 00:04:37,358
straightforward.

131
00:04:37,899 --> 00:04:39,899
The first is that you have

132
00:04:39,899 --> 00:04:42,209
a plethora of customization techniques,

133
00:04:42,420 --> 00:04:45,019
right? Um,

134
00:04:45,399 --> 00:04:47,399
you can begin with the, with the

135
00:04:47,399 --> 00:04:49,389
usual supervised on tuning,

136
00:04:49,959 --> 00:04:52,278
but then if you want to get an extra

137
00:04:52,278 --> 00:04:52,980
edge

138
00:04:53,278 --> 00:04:54,420
when it comes to

139
00:04:54,790 --> 00:04:56,819
additional performance, you might be.

140
00:04:58,329 --> 00:05:00,488
Exploring additional techniques such as

141
00:05:00,488 --> 00:05:03,028
preference optimization or reinforcement learning.

142
00:05:03,488 --> 00:05:05,428
But that requires

143
00:05:06,149 --> 00:05:08,189
Extra research time and effort.

144
00:05:08,738 --> 00:05:11,290
It's not something that is easily available,

145
00:05:11,350 --> 00:05:12,608
and you can iterate quickly.

146
00:05:14,709 --> 00:05:16,488
The second part is also

147
00:05:17,899 --> 00:05:20,588
You have to have some knowledge about the infrastructure

148
00:05:20,588 --> 00:05:22,540
that your use case requires,

149
00:05:22,949 --> 00:05:25,028
based on the customization technique at

150
00:05:25,028 --> 00:05:26,959
hand. So,

151
00:05:27,838 --> 00:05:29,759
How many GPUs will you use,

152
00:05:30,040 --> 00:05:30,559
right?

153
00:05:30,959 --> 00:05:33,319
It's always a factor of the dataset size,

154
00:05:33,639 --> 00:05:35,220
the customization technique,

155
00:05:35,959 --> 00:05:38,160
so it's always a a a a trial

156
00:05:38,160 --> 00:05:40,358
and error iteration

157
00:05:40,358 --> 00:05:41,100
workflow.

158
00:05:41,869 --> 00:05:44,040
That can take a lot of time for you

159
00:05:44,040 --> 00:05:45,119
to fulfill.

160
00:05:48,670 --> 00:05:50,709
Then, what we have found

161
00:05:50,709 --> 00:05:52,608
when talking to customers,

162
00:05:53,259 --> 00:05:55,949
many of them have a very good

163
00:05:55,949 --> 00:05:56,709
understanding

164
00:05:57,069 --> 00:05:59,259
of what the business use case is.

165
00:05:59,629 --> 00:06:01,738
They understand what they want to accomplish,

166
00:06:02,028 --> 00:06:04,269
but then moving from that particular

167
00:06:04,269 --> 00:06:05,170
definition.

168
00:06:06,178 --> 00:06:09,059
Onto a model customization

169
00:06:09,059 --> 00:06:10,059
specification,

170
00:06:10,540 --> 00:06:12,600
it's much more complex,

171
00:06:13,298 --> 00:06:15,420
right? How do we move from a business use

172
00:06:15,420 --> 00:06:17,858
case description to an actual model customization,

173
00:06:17,980 --> 00:06:18,858
that involves,

174
00:06:19,178 --> 00:06:21,579
right? The data set that you are going to use,

175
00:06:22,019 --> 00:06:23,369
the model choice,

176
00:06:23,660 --> 00:06:25,079
and the customization technique.

177
00:06:27,069 --> 00:06:27,988
And finally,

178
00:06:28,470 --> 00:06:31,290
you have to be able to do this at scale,

179
00:06:31,670 --> 00:06:34,028
right? The very nature

180
00:06:34,028 --> 00:06:36,500
of AI and agentic

181
00:06:36,500 --> 00:06:37,709
solution building

182
00:06:37,988 --> 00:06:39,588
relies on you

183
00:06:40,028 --> 00:06:42,309
quickly iterating on multiple

184
00:06:42,309 --> 00:06:43,420
experiments.

185
00:06:43,750 --> 00:06:44,869
This is not just,

186
00:06:45,470 --> 00:06:46,649
let's try this,

187
00:06:47,069 --> 00:06:49,108
and this will be the solution that ends

188
00:06:49,108 --> 00:06:50,250
up being used.

189
00:06:51,189 --> 00:06:52,649
The more you can

190
00:06:53,149 --> 00:06:55,230
do in order to get

191
00:06:55,230 --> 00:06:56,910
more experiments running,

192
00:06:57,428 --> 00:06:59,629
the better you'll be able to achieve

193
00:06:59,629 --> 00:07:02,028
the accuracy and performance goals.

194
00:07:02,369 --> 00:07:04,410
That you want to get to,

195
00:07:04,488 --> 00:07:05,588
in order to make

196
00:07:06,170 --> 00:07:08,410
your use case feasible and

197
00:07:08,410 --> 00:07:09,389
a success.

198
00:07:11,949 --> 00:07:14,108
So, in order for us to

199
00:07:14,108 --> 00:07:16,709
show you how we are going to enable

200
00:07:16,709 --> 00:07:17,309
you

201
00:07:17,910 --> 00:07:19,889
with the tools to tackle

202
00:07:20,189 --> 00:07:21,639
these challenges,

203
00:07:22,108 --> 00:07:24,108
let's put this in the

204
00:07:24,428 --> 00:07:26,069
end to end workflow

205
00:07:26,428 --> 00:07:27,850
for model customization.

206
00:07:28,798 --> 00:07:30,879
And then we will see how we are addressing

207
00:07:30,879 --> 00:07:32,920
each step of the

208
00:07:32,920 --> 00:07:33,519
workflow.

209
00:07:34,588 --> 00:07:35,509
As you can see,

210
00:07:35,899 --> 00:07:37,980
you begin by defining goals.

211
00:07:38,829 --> 00:07:40,588
And evaluation criteria.

212
00:07:40,910 --> 00:07:43,170
What is it exactly that you want to achieve?

213
00:07:44,100 --> 00:07:44,639
Then,

214
00:07:44,980 --> 00:07:46,139
you gather your data,

215
00:07:46,399 --> 00:07:48,069
you craft your data sets,

216
00:07:48,678 --> 00:07:50,459
based on what you can get,

217
00:07:50,899 --> 00:07:53,100
enhancing the data that you have,

218
00:07:53,379 --> 00:07:55,238
or even generating synthetic data.

219
00:07:56,069 --> 00:07:58,548
In order to enable your use cases.

220
00:07:59,769 --> 00:08:00,329
Then

221
00:08:01,928 --> 00:08:03,928
It's the process of customizing the

222
00:08:03,928 --> 00:08:04,988
model itself,

223
00:08:05,290 --> 00:08:07,329
right? How can you get

224
00:08:07,769 --> 00:08:10,088
to in the right technique, choosing

225
00:08:10,088 --> 00:08:10,949
the right model.

226
00:08:11,699 --> 00:08:12,309
And

227
00:08:13,100 --> 00:08:15,420
creating that cost model and then

228
00:08:15,420 --> 00:08:16,759
begin assessing

229
00:08:17,019 --> 00:08:19,059
based on the evaluation criteria that you

230
00:08:19,059 --> 00:08:20,019
have defined.

231
00:08:20,939 --> 00:08:22,399
In the previous step.

232
00:08:23,528 --> 00:08:25,579
2, whether you get to that.

233
00:08:26,459 --> 00:08:28,528
And result that you are seeking to

234
00:08:28,528 --> 00:08:30,548
achieve. Then

235
00:08:30,649 --> 00:08:32,769
it's rinse and repeat, right? This is not

236
00:08:32,769 --> 00:08:34,450
something that you do once.

237
00:08:34,769 --> 00:08:36,950
It's something that you have to continually

238
00:08:37,168 --> 00:08:39,168
experiment to try to find

239
00:08:39,168 --> 00:08:40,308
that combination.

240
00:08:41,038 --> 00:08:42,217
Of data

241
00:08:42,758 --> 00:08:43,778
and model

242
00:08:44,479 --> 00:08:45,457
that makes

243
00:08:45,717 --> 00:08:47,837
your application or your agent a

244
00:08:47,837 --> 00:08:48,369
success.

245
00:08:48,879 --> 00:08:49,638
Finally,

246
00:08:50,077 --> 00:08:51,119
deploying your model,

247
00:08:51,398 --> 00:08:52,678
roll out to production.

248
00:08:53,750 --> 00:08:55,798
And begin reaping the benefits of

249
00:08:55,798 --> 00:08:57,279
this new custom model.

250
00:08:57,798 --> 00:08:59,119
Let's go one by one then.

251
00:09:02,440 --> 00:09:03,859
How are we help are going,

252
00:09:04,119 --> 00:09:06,440
how are we going to help you define

253
00:09:06,440 --> 00:09:08,440
your goals and arrive

254
00:09:08,440 --> 00:09:09,739
to a a a better

255
00:09:10,719 --> 00:09:12,889
Um, use case specification.

256
00:09:15,190 --> 00:09:17,259
Yesterday we launched the

257
00:09:17,259 --> 00:09:19,399
preview of our SageMaker

258
00:09:19,399 --> 00:09:21,719
AI model customization agent.

259
00:09:23,109 --> 00:09:25,019
The model customization agent,

260
00:09:25,389 --> 00:09:26,450
what it does.

261
00:09:27,330 --> 00:09:28,250
Is

262
00:09:29,009 --> 00:09:30,070
It will take

263
00:09:30,729 --> 00:09:32,509
your use case definition

264
00:09:33,048 --> 00:09:34,469
in natural language.

265
00:09:35,869 --> 00:09:37,158
It will create.

266
00:09:38,399 --> 00:09:40,649
Uh, and it will, it will go back and forth

267
00:09:40,649 --> 00:09:42,808
with you to define exactly what

268
00:09:42,808 --> 00:09:44,090
the use case is,

269
00:09:44,489 --> 00:09:46,509
and what evaluation criteria is the

270
00:09:46,509 --> 00:09:48,570
best to achieve the goals

271
00:09:48,570 --> 00:09:50,210
that you have set out to achieve

272
00:09:50,609 --> 00:09:52,048
in your use case definition.

273
00:09:53,038 --> 00:09:54,019
And finally,

274
00:09:55,330 --> 00:09:57,529
It will lay out that use

275
00:09:57,529 --> 00:09:58,830
case specification

276
00:09:59,090 --> 00:10:00,288
for you to approve

277
00:10:00,570 --> 00:10:02,090
and continue forward.

278
00:10:02,450 --> 00:10:03,519
This might eventually,

279
00:10:03,928 --> 00:10:04,808
you know, end up

280
00:10:05,158 --> 00:10:06,590
customizing a model,

281
00:10:07,210 --> 00:10:09,288
if you, if you choose to move forward with with

282
00:10:09,288 --> 00:10:10,229
the agent as well.

283
00:10:12,700 --> 00:10:14,820
So, this is the UI

284
00:10:14,820 --> 00:10:17,070
of SageMaker AI Sage Maker

285
00:10:17,070 --> 00:10:17,678
Studio.

286
00:10:18,570 --> 00:10:19,979
When you go to the new

287
00:10:20,320 --> 00:10:22,538
models page, you will see that

288
00:10:22,798 --> 00:10:24,918
the models that are supporting this new

289
00:10:24,918 --> 00:10:26,678
customization capability

290
00:10:26,989 --> 00:10:29,239
will have the customized button,

291
00:10:29,399 --> 00:10:30,788
and you have three options there.

292
00:10:31,080 --> 00:10:33,690
The one that is labeled in preview,

293
00:10:34,119 --> 00:10:36,389
will enable you to launch a

294
00:10:36,389 --> 00:10:37,399
conversation with the agent.

295
00:10:40,609 --> 00:10:42,969
You can also begin the conversation

296
00:10:42,969 --> 00:10:44,308
without selecting a model,

297
00:10:44,889 --> 00:10:46,969
in which case you will have an opportunity

298
00:10:46,969 --> 00:10:48,969
to to go back and forth with the

299
00:10:48,969 --> 00:10:50,308
agent and then choose one.

300
00:10:51,759 --> 00:10:54,219
So, here's the uh

301
00:10:54,830 --> 00:10:56,158
UI of the agent.

302
00:10:56,940 --> 00:10:57,859
The agent

303
00:10:58,418 --> 00:11:00,418
will go into a conversation

304
00:11:00,418 --> 00:11:01,038
with you

305
00:11:01,619 --> 00:11:04,038
to define exactly what you're seeking.

306
00:11:06,538 --> 00:11:07,340
Once

307
00:11:08,840 --> 00:11:09,719
It has defined,

308
00:11:09,989 --> 00:11:12,279
once you have laid out

309
00:11:12,279 --> 00:11:13,979
exactly what you want to achieve,

310
00:11:14,719 --> 00:11:16,178
the agent will

311
00:11:17,149 --> 00:11:17,889
Suggest

312
00:11:18,389 --> 00:11:20,469
additional information for your use

313
00:11:20,469 --> 00:11:22,529
case, and then

314
00:11:22,538 --> 00:11:24,369
provide with options for you to choose

315
00:11:25,259 --> 00:11:27,269
um with regards to the model that you

316
00:11:27,269 --> 00:11:29,450
can use and the customization technique.

317
00:11:31,710 --> 00:11:32,408
Finally,

318
00:11:32,908 --> 00:11:34,269
it will lay out

319
00:11:34,629 --> 00:11:36,908
the list of success criteria

320
00:11:37,308 --> 00:11:39,308
that you can approve or maybe

321
00:11:39,308 --> 00:11:41,408
go and edit, right? Maybe you see

322
00:11:41,408 --> 00:11:43,479
that You want to add,

323
00:11:43,519 --> 00:11:44,038
tweak,

324
00:11:44,320 --> 00:11:44,859
remove.

325
00:11:45,710 --> 00:11:47,739
Some of the success criteria you're not satisfied,

326
00:11:47,808 --> 00:11:49,989
you can continue iterating with the agent

327
00:11:50,529 --> 00:11:52,889
until you're satisfied with the success criteria

328
00:11:52,889 --> 00:11:54,908
and approve it, and then you move forward.

329
00:11:58,570 --> 00:12:01,000
So that is the way, this gentic

330
00:12:01,000 --> 00:12:03,090
back and forth, in which we're making it

331
00:12:03,090 --> 00:12:04,250
easier for you

332
00:12:04,808 --> 00:12:07,129
to be able to move quickly

333
00:12:07,129 --> 00:12:09,428
from just a raw business use case

334
00:12:09,428 --> 00:12:10,340
into

335
00:12:10,808 --> 00:12:12,700
an actual model customization.

336
00:12:13,719 --> 00:12:15,019
Specification.

337
00:12:16,859 --> 00:12:18,940
Then The most

338
00:12:18,940 --> 00:12:21,298
important piece in model customization, which is

339
00:12:22,250 --> 00:12:24,369
Dataset gathering and enhancement

340
00:12:24,369 --> 00:12:25,239
and curation.

341
00:12:28,359 --> 00:12:30,379
This agent will be able

342
00:12:30,379 --> 00:12:31,099
to

343
00:12:31,798 --> 00:12:34,479
request you to provide some examples

344
00:12:34,479 --> 00:12:36,479
or additional context with regards to

345
00:12:36,479 --> 00:12:38,379
the data that you want to provide,

346
00:12:38,798 --> 00:12:39,779
and then

347
00:12:40,038 --> 00:12:42,139
generate data that matches

348
00:12:42,139 --> 00:12:42,779
that

349
00:12:43,359 --> 00:12:45,379
those examples that you have provided.

350
00:12:46,719 --> 00:12:48,759
But it will not only provide

351
00:12:48,759 --> 00:12:50,080
the synthetic data,

352
00:12:50,479 --> 00:12:52,599
it will also analyze it

353
00:12:52,599 --> 00:12:55,229
based on a set of criteria

354
00:12:55,519 --> 00:12:58,200
that include responsible AI

355
00:12:58,200 --> 00:12:58,960
controls.

356
00:12:59,859 --> 00:13:01,440
So that you are aware.

357
00:13:02,928 --> 00:13:05,000
Uh, and, and are cautious about

358
00:13:05,000 --> 00:13:07,408
the data that you are using, to avoid bias,

359
00:13:07,529 --> 00:13:08,070
to avoid,

360
00:13:08,570 --> 00:13:09,908
you know, harmful content.

361
00:13:11,849 --> 00:13:14,009
That data generation will

362
00:13:14,009 --> 00:13:16,048
require you to choose any underlying

363
00:13:16,048 --> 00:13:18,519
compute. Is it serverless,

364
00:13:19,139 --> 00:13:20,000
end to end.

365
00:13:21,960 --> 00:13:24,529
And so, here's a a a a

366
00:13:24,529 --> 00:13:26,690
sample of this back and forth,

367
00:13:27,090 --> 00:13:28,629
the agent tells you

368
00:13:28,969 --> 00:13:31,308
that he's ready to begin gathering data.

369
00:13:32,099 --> 00:13:32,759
And then

370
00:13:33,500 --> 00:13:35,298
You provide those examples.

371
00:13:36,599 --> 00:13:38,080
And then the agent.

372
00:13:39,288 --> 00:13:40,609
Shares with you

373
00:13:40,989 --> 00:13:43,048
the specification of your data

374
00:13:43,048 --> 00:13:47,250
set. Once

375
00:13:47,250 --> 00:13:49,599
generation. Uh,

376
00:13:49,678 --> 00:13:51,538
you decide exactly how many,

377
00:13:52,239 --> 00:13:54,359
how many, uh, features you are going

378
00:13:54,359 --> 00:13:56,619
to be using or you want the agent to generate,

379
00:13:57,428 --> 00:13:59,798
uh, additional configuration items

380
00:13:59,798 --> 00:14:01,879
such as the S3 bucket you want the, the

381
00:14:01,879 --> 00:14:03,418
data file to reside on.

382
00:14:04,769 --> 00:14:06,989
And you can also provide a history bucket

383
00:14:07,408 --> 00:14:09,830
of contextual data you want to have

384
00:14:10,168 --> 00:14:12,210
the agent use as a reference to

385
00:14:12,210 --> 00:14:13,750
generate those data.

386
00:14:16,229 --> 00:14:18,178
You choose the number of rows,

387
00:14:18,928 --> 00:14:19,899
the bucket,

388
00:14:20,308 --> 00:14:22,288
and once generation is complete.

389
00:14:23,200 --> 00:14:25,408
You can see the quality of your data,

390
00:14:25,798 --> 00:14:27,879
based on what I was just describing, right?

391
00:14:28,830 --> 00:14:30,918
Your statistics, your AI

392
00:14:30,918 --> 00:14:33,389
quality metrics, including responsible

393
00:14:33,389 --> 00:14:35,308
AI. Um

394
00:14:36,750 --> 00:14:37,479
Criteria.

395
00:14:40,349 --> 00:14:41,178
But I know

396
00:14:41,479 --> 00:14:42,320
many of you.

397
00:14:44,710 --> 00:14:46,029
are, are even.

398
00:14:47,009 --> 00:14:49,090
More prone to do things yourself.

399
00:14:49,210 --> 00:14:51,029
Maybe you already have a dataset,

400
00:14:51,769 --> 00:14:53,269
maybe you like

401
00:14:53,889 --> 00:14:55,928
to use your own data as opposed to just

402
00:14:55,928 --> 00:14:57,070
relying on an agent.

403
00:14:58,149 --> 00:15:00,629
That's also something that we anticipated

404
00:15:00,629 --> 00:15:02,889
customers will prefer to

405
00:15:03,190 --> 00:15:03,869
default,

406
00:15:04,229 --> 00:15:06,308
and then as a consequence, we have

407
00:15:06,308 --> 00:15:08,349
created the means by which you can

408
00:15:08,349 --> 00:15:10,349
upload or create your

409
00:15:10,349 --> 00:15:11,219
data sets.

410
00:15:12,619 --> 00:15:14,639
And then use them in any

411
00:15:14,639 --> 00:15:16,658
customization job that you would like

412
00:15:16,658 --> 00:15:18,038
to run in the platform.

413
00:15:19,168 --> 00:15:19,779
So

414
00:15:21,500 --> 00:15:23,500
Here in Decision-Maker Studio

415
00:15:23,500 --> 00:15:24,119
UI.

416
00:15:24,750 --> 00:15:25,668
You have

417
00:15:26,558 --> 00:15:28,580
The assets section

418
00:15:28,798 --> 00:15:29,519
on the left.

419
00:15:30,918 --> 00:15:31,538
And

420
00:15:31,840 --> 00:15:34,298
the first item is, of course, datasets.

421
00:15:34,759 --> 00:15:36,460
You can create a data set.

422
00:15:38,058 --> 00:15:38,759
And then

423
00:15:39,399 --> 00:15:40,460
You will get

424
00:15:41,000 --> 00:15:42,538
to a form where you can

425
00:15:43,149 --> 00:15:45,548
name your data set and upload your file,

426
00:15:45,879 --> 00:15:47,529
or you can also provide an

427
00:15:47,798 --> 00:15:48,979
an estuary bucket.

428
00:15:50,519 --> 00:15:52,519
Uh, if you have already uploaded your data

429
00:15:52,519 --> 00:15:53,298
set to S3.

430
00:15:55,229 --> 00:15:57,759
When, in a moment, we are going to continue

431
00:15:57,759 --> 00:15:59,408
um talking about

432
00:15:59,908 --> 00:16:02,269
um what the technique, what the techniques

433
00:16:02,269 --> 00:16:04,340
are going to be. One of, uh,

434
00:16:04,349 --> 00:16:06,428
one of which is really important, and I

435
00:16:06,428 --> 00:16:08,710
know that you you might have already been

436
00:16:09,418 --> 00:16:11,548
uh doing some research on it, reinforcement learning

437
00:16:11,548 --> 00:16:13,788
is becoming more and more important as a

438
00:16:13,788 --> 00:16:16,149
as a means to do model customization

439
00:16:16,149 --> 00:16:17,629
for model alignment, right?

440
00:16:18,029 --> 00:16:18,570
And so,

441
00:16:19,558 --> 00:16:21,558
One of the things that we consider is

442
00:16:21,558 --> 00:16:23,808
what other assets you

443
00:16:23,808 --> 00:16:25,940
may also want to build uh

444
00:16:25,940 --> 00:16:28,119
to upload and have ready for any

445
00:16:28,119 --> 00:16:30,279
job that may come after, after that.

446
00:16:31,389 --> 00:16:32,080
So

447
00:16:33,349 --> 00:16:34,788
We also created.

448
00:16:35,719 --> 00:16:37,558
The evaluator asset.

449
00:16:38,000 --> 00:16:40,099
The evaluator asset has

450
00:16:40,879 --> 00:16:43,158
two types, one is a reward

451
00:16:43,158 --> 00:16:45,340
function. Which is the

452
00:16:45,340 --> 00:16:46,320
code that you would

453
00:16:46,658 --> 00:16:47,779
create for

454
00:16:48,440 --> 00:16:51,058
Let's say reinforcement learning with verifiable

455
00:16:51,058 --> 00:16:52,440
rewards, right?

456
00:16:53,460 --> 00:16:55,460
You just create it once and then

457
00:16:55,460 --> 00:16:57,619
you can use it in any model customization

458
00:16:57,619 --> 00:16:58,918
job that you want to

459
00:16:59,418 --> 00:17:02,830
run. Uh,

460
00:17:02,908 --> 00:17:05,368
the UI will provide you with guidance

461
00:17:05,368 --> 00:17:07,410
as to what the code should

462
00:17:07,949 --> 00:17:10,108
look like from a format standpoint.

463
00:17:11,189 --> 00:17:12,130
Uh, and

464
00:17:12,630 --> 00:17:14,868
under the hood, it will be created as a lambda

465
00:17:14,868 --> 00:17:17,098
function. As you can

466
00:17:17,098 --> 00:17:17,608
see,

467
00:17:18,098 --> 00:17:19,818
you can go to lambda as well,

468
00:17:20,338 --> 00:17:22,618
create your reward function in lambda, and

469
00:17:22,618 --> 00:17:25,000
just, and then just pull the lambda R

470
00:17:25,259 --> 00:17:27,959
into the UI in order to create

471
00:17:28,420 --> 00:17:29,318
that evaluator

472
00:17:29,660 --> 00:17:30,578
that you can reference.

473
00:17:32,338 --> 00:17:33,880
The other is.

474
00:17:35,828 --> 00:17:38,289
How about reinforcement learning with

475
00:17:38,430 --> 00:17:39,509
AI feedback?

476
00:17:39,989 --> 00:17:41,108
In that case,

477
00:17:41,509 --> 00:17:43,789
you may be needing to create

478
00:17:43,789 --> 00:17:46,318
prompts for your reward models.

479
00:17:46,949 --> 00:17:49,068
Here you can create those ones and then

480
00:17:49,068 --> 00:17:50,519
use them as you please

481
00:17:50,910 --> 00:17:51,588
in the UI.

482
00:17:53,439 --> 00:17:54,759
In a similar manner,

483
00:17:55,039 --> 00:17:57,160
you choose the reward prompt,

484
00:17:57,479 --> 00:17:59,519
and you're guided to the format that you

485
00:17:59,519 --> 00:18:01,680
can use, so that you can create those

486
00:18:01,680 --> 00:18:03,799
reward prompts and use them on your

487
00:18:03,799 --> 00:18:04,880
model customization.

488
00:18:06,029 --> 00:18:07,309
Uh, experiments.

489
00:18:09,269 --> 00:18:11,680
As always, you can do this very

490
00:18:11,680 --> 00:18:12,489
simple,

491
00:18:12,959 --> 00:18:15,039
very simply, if you want to use

492
00:18:15,039 --> 00:18:17,239
a code first approach, right? We

493
00:18:17,239 --> 00:18:19,779
have updated our Python SDK

494
00:18:20,309 --> 00:18:22,318
to include the constructs

495
00:18:22,880 --> 00:18:24,618
that will enable you to create

496
00:18:25,239 --> 00:18:27,838
these assets for model customization.

497
00:18:29,309 --> 00:18:32,049
I know many of you might be, you know, more

498
00:18:32,430 --> 00:18:34,578
comfortable using code first,

499
00:18:35,068 --> 00:18:37,108
so we are making it easier for you as

500
00:18:37,108 --> 00:18:38,910
well in that arena.

501
00:18:40,189 --> 00:18:41,088
OK, so

502
00:18:41,979 --> 00:18:44,180
How about customizing the models?

503
00:18:47,489 --> 00:18:49,799
One of the things that I mentioned was

504
00:18:50,088 --> 00:18:52,209
the infrastructure configuration

505
00:18:52,209 --> 00:18:53,328
complexity, right?

506
00:18:54,059 --> 00:18:56,059
We've talked about this, you need to know

507
00:18:56,059 --> 00:18:56,650
what

508
00:18:58,059 --> 00:19:00,338
what GPU I'm going to be using or

509
00:19:00,338 --> 00:19:01,209
I need to use,

510
00:19:01,578 --> 00:19:04,299
how many of these accelerators are

511
00:19:04,299 --> 00:19:05,739
required to run these jobs?

512
00:19:06,019 --> 00:19:08,098
Well, we are abstracting that

513
00:19:08,098 --> 00:19:10,259
con that configuration complexity

514
00:19:10,500 --> 00:19:12,519
from the process so that you can focus

515
00:19:12,519 --> 00:19:13,140
on

516
00:19:13,500 --> 00:19:14,959
what is important for you.

517
00:19:15,449 --> 00:19:16,469
Which is creating

518
00:19:16,848 --> 00:19:17,910
experiments

519
00:19:18,250 --> 00:19:20,269
that walk towards

520
00:19:20,608 --> 00:19:22,449
your overall performance goals.

521
00:19:22,769 --> 00:19:24,848
That's why we launched yesterday serverless

522
00:19:24,848 --> 00:19:25,959
reinforcement learning.

523
00:19:27,539 --> 00:19:30,000
In other words, you will be able to launch

524
00:19:30,420 --> 00:19:32,618
reinforcement learning jobs without

525
00:19:32,618 --> 00:19:34,549
needing to configure any GPU

526
00:19:35,739 --> 00:19:38,180
configuration or the number of nodes.

527
00:19:40,969 --> 00:19:41,890
As you can see,

528
00:19:42,459 --> 00:19:44,719
the UI will also have, and that's the 2nd,

529
00:19:45,509 --> 00:19:48,338
the the the the first option there, customize

530
00:19:48,338 --> 00:19:49,098
with UI.

531
00:19:49,539 --> 00:19:50,900
If you know what you wanna do,

532
00:19:51,259 --> 00:19:53,279
you just click customize with UI.

533
00:19:55,259 --> 00:19:57,630
And that will take you to a very simple form

534
00:19:57,630 --> 00:19:59,750
where you choose your customization

535
00:19:59,750 --> 00:20:01,880
technique. In this case, let's say that it's

536
00:20:01,880 --> 00:20:03,729
reinforcement learning with AI feedback.

537
00:20:05,828 --> 00:20:08,170
That will allow you to choose a reward model.

538
00:20:10,039 --> 00:20:12,130
In this case we're using Bedrock under

539
00:20:12,130 --> 00:20:14,170
the Hoio. This will be using Bedrock

540
00:20:14,170 --> 00:20:16,368
APIs and your calling

541
00:20:16,368 --> 00:20:16,959
and your,

542
00:20:17,269 --> 00:20:19,469
your after the rollout phase, reward

543
00:20:19,930 --> 00:20:22,039
is being, is, is using this

544
00:20:22,039 --> 00:20:23,630
reward model and Bedrock

545
00:20:23,969 --> 00:20:26,088
to provide rewards and then continue the

546
00:20:26,088 --> 00:20:26,828
training loop.

547
00:20:28,509 --> 00:20:30,779
Of course, the second piece is

548
00:20:30,920 --> 00:20:33,279
what prompt you are going to use for the reward model.

549
00:20:33,719 --> 00:20:36,029
And then you can, you can choose custom,

550
00:20:36,279 --> 00:20:38,400
and in that case, what you're going to do is choose

551
00:20:38,400 --> 00:20:40,660
the evaluator that you created in the other

552
00:20:41,160 --> 00:20:42,539
section that I showed earlier,

553
00:20:43,318 --> 00:20:45,479
or you can also provide the code yourself.

554
00:20:46,380 --> 00:20:48,539
Uh, in this interface, and then create

555
00:20:48,539 --> 00:20:50,118
that evaluator at the same time.

556
00:20:53,269 --> 00:20:55,269
Of course, you can tweak some

557
00:20:55,269 --> 00:20:56,608
hyperparametters

558
00:20:57,108 --> 00:20:59,390
that we are exposing. This is not, as

559
00:20:59,390 --> 00:21:01,150
you may already have noticed,

560
00:21:01,509 --> 00:21:03,088
this is not an exhaustive list,

561
00:21:03,509 --> 00:21:07,098
what This

562
00:21:07,209 --> 00:21:07,989
is,

563
00:21:08,529 --> 00:21:09,529
in essence,

564
00:21:10,529 --> 00:21:12,729
Um, a very, what we

565
00:21:12,729 --> 00:21:14,348
are, we have heard customers

566
00:21:14,608 --> 00:21:16,809
that is the set of hyperparameterss

567
00:21:16,809 --> 00:21:18,559
that they normally tweak the most,

568
00:21:18,838 --> 00:21:20,739
but we would love to hear from you,

569
00:21:21,250 --> 00:21:23,650
which additional ones would you think

570
00:21:23,650 --> 00:21:25,309
would be useful to have

571
00:21:25,568 --> 00:21:28,078
as part of the ones that you can tweak immediately

572
00:21:28,078 --> 00:21:28,769
in the form.

573
00:21:29,049 --> 00:21:31,088
We have advanced configuration if you want

574
00:21:31,088 --> 00:21:31,959
to go deeper,

575
00:21:32,650 --> 00:21:34,848
and some additional configurations such as

576
00:21:34,848 --> 00:21:35,910
the ML flow

577
00:21:36,529 --> 00:21:38,799
app. That we are going to use. I'm

578
00:21:38,799 --> 00:21:40,259
going to talk about ML flow in a minute.

579
00:21:42,318 --> 00:21:44,608
So, once you click submit,

580
00:21:45,118 --> 00:21:47,380
this will land you on the training job

581
00:21:47,529 --> 00:21:48,729
details page,

582
00:21:49,108 --> 00:21:51,318
which will show you immediately

583
00:21:51,318 --> 00:21:52,338
the training.

584
00:21:53,219 --> 00:21:54,068
Metrics,

585
00:21:54,390 --> 00:21:56,469
so that you can stop the job if it's trending

586
00:21:56,469 --> 00:21:56,989
wrong.

587
00:21:58,000 --> 00:22:00,078
Uh, you can check and troubleshoot using the log

588
00:22:00,078 --> 00:22:02,140
stack. You can also

589
00:22:02,140 --> 00:22:04,199
gain access to the artifacts tab

590
00:22:04,199 --> 00:22:04,959
to see

591
00:22:05,618 --> 00:22:07,660
where your model artifacts are going to be

592
00:22:07,660 --> 00:22:08,680
stored, etc.

593
00:22:10,588 --> 00:22:12,799
But Everything,

594
00:22:12,858 --> 00:22:15,199
as you can see, is revolving around

595
00:22:15,199 --> 00:22:17,219
the single concept, which is the most

596
00:22:17,219 --> 00:22:18,920
important piece here, which is

597
00:22:19,500 --> 00:22:21,660
the custom model. The custom model

598
00:22:21,660 --> 00:22:23,719
is the start of the show,

599
00:22:23,939 --> 00:22:24,809
and as such,

600
00:22:25,180 --> 00:22:27,259
we have, we have a button up

601
00:22:27,259 --> 00:22:29,380
there that you can use to go

602
00:22:29,380 --> 00:22:30,000
to the,

603
00:22:30,660 --> 00:22:32,858
to the actual custom model details

604
00:22:32,858 --> 00:22:35,199
page. Once the job has run,

605
00:22:35,459 --> 00:22:37,769
you can go to the custom model details page,

606
00:22:38,029 --> 00:22:39,598
so you can see exactly

607
00:22:40,279 --> 00:22:41,848
Everything about that customer.

608
00:22:42,130 --> 00:22:44,068
The lineage, where you can track

609
00:22:44,608 --> 00:22:46,739
which dataset was used for training,

610
00:22:47,170 --> 00:22:49,328
and you can also trigger additional actions

611
00:22:49,328 --> 00:22:51,049
such as continued customization.

612
00:22:51,410 --> 00:22:53,509
You can, for instance, run an uh

613
00:22:53,509 --> 00:22:55,729
an uh reinforcement fine-tuning job after

614
00:22:55,729 --> 00:22:57,689
running a supervised fine tuning

615
00:22:58,088 --> 00:23:00,108
and continue improving your performance.

616
00:23:02,078 --> 00:23:03,130
You can also

617
00:23:04,289 --> 00:23:05,630
Do this in code.

618
00:23:06,368 --> 00:23:07,479
So we have

619
00:23:07,809 --> 00:23:08,709
the uh

620
00:23:09,209 --> 00:23:11,098
new SDK classes

621
00:23:11,529 --> 00:23:14,328
for you to launch this serverless

622
00:23:14,328 --> 00:23:15,519
training jobs

623
00:23:16,209 --> 00:23:17,848
from your code.

624
00:23:18,640 --> 00:23:19,660
It can be a notebook,

625
00:23:20,118 --> 00:23:21,680
it can be a Python file, etc.

626
00:23:23,650 --> 00:23:25,689
This is an example of one of the classes that we

627
00:23:25,689 --> 00:23:26,479
have created.

628
00:23:28,809 --> 00:23:30,920
What you do next is evaluate your

629
00:23:30,920 --> 00:23:32,930
model, obviously. If you want to have another

630
00:23:32,930 --> 00:23:34,469
data set to assess whether

631
00:23:34,838 --> 00:23:36,410
you are achieving your performance,

632
00:23:36,890 --> 00:23:39,588
you can run evaluation of models

633
00:23:40,289 --> 00:23:40,989
using

634
00:23:41,719 --> 00:23:44,430
You can use your, you know, regular benchmarks,

635
00:23:44,789 --> 00:23:45,380
although

636
00:23:45,640 --> 00:23:46,259
I know

637
00:23:46,959 --> 00:23:48,098
all of you know that

638
00:23:48,598 --> 00:23:50,598
that might not be as useful if

639
00:23:50,598 --> 00:23:52,759
you're looking for a specific use case.

640
00:23:53,358 --> 00:23:55,709
So you can uh create your own custom

641
00:23:55,709 --> 00:23:56,459
metrics.

642
00:23:57,118 --> 00:23:59,160
You remember about the evaluators? You can

643
00:23:59,160 --> 00:24:01,199
use evaluators to create more custom metrics

644
00:24:01,199 --> 00:24:03,338
that can be used here for evaluation as well.

645
00:24:03,598 --> 00:24:05,680
You can also leverage prompts

646
00:24:06,118 --> 00:24:07,779
for LLM as a judge

647
00:24:08,239 --> 00:24:08,920
evaluation.

648
00:24:11,000 --> 00:24:13,039
At the end of each evaluation, you will have

649
00:24:13,039 --> 00:24:15,209
visual scorecards that show you,

650
00:24:15,640 --> 00:24:18,098
this is how you evaluate, this is the button.

651
00:24:19,029 --> 00:24:20,130
And you can check

652
00:24:22,410 --> 00:24:25,049
The evaluation job configuration,

653
00:24:25,650 --> 00:24:27,750
when you create or choose

654
00:24:27,750 --> 00:24:29,309
an LLM as a judge.

655
00:24:30,130 --> 00:24:31,108
Uh, option,

656
00:24:31,449 --> 00:24:34,108
and you can create your prompt from a template

657
00:24:34,529 --> 00:24:35,890
in order to run that evaluation.

658
00:24:38,519 --> 00:24:39,250
And then

659
00:24:40,588 --> 00:24:42,920
How do we make this efficient, an efficient

660
00:24:42,920 --> 00:24:44,920
workflow, so you can do it at multiple

661
00:24:44,920 --> 00:24:45,469
times.

662
00:24:45,799 --> 00:24:47,059
Well, we're

663
00:24:47,519 --> 00:24:48,338
integrating,

664
00:24:48,838 --> 00:24:50,180
this is the iteration part,

665
00:24:50,519 --> 00:24:52,640
we're integrating with ML flow. We

666
00:24:52,640 --> 00:24:54,180
launched this year as well

667
00:24:54,449 --> 00:24:55,598
serverlessML flow,

668
00:24:55,880 --> 00:24:57,259
server less ML flow.

669
00:24:58,118 --> 00:25:00,199
Uh, you don't have to configure or pay

670
00:25:00,199 --> 00:25:00,920
anything else.

671
00:25:01,279 --> 00:25:03,400
Serverless, a serverless ML flow app will

672
00:25:03,400 --> 00:25:05,759
be created for you, and immediately

673
00:25:05,759 --> 00:25:06,588
begin logging

674
00:25:06,939 --> 00:25:08,259
to the, to the app

675
00:25:08,640 --> 00:25:10,318
as you run experiments.

676
00:25:12,348 --> 00:25:13,519
No additional cost.

677
00:25:15,368 --> 00:25:16,309
As you can see,

678
00:25:16,608 --> 00:25:18,729
there's this button that says view

679
00:25:18,729 --> 00:25:21,039
metrics details in MFFlow.

680
00:25:21,608 --> 00:25:23,959
You click it and then you immediately launch

681
00:25:23,959 --> 00:25:25,969
a new tab in your browser with the

682
00:25:25,969 --> 00:25:28,029
MFFlow interface that you know and love.

683
00:25:30,250 --> 00:25:30,858
Finally,

684
00:25:31,759 --> 00:25:34,309
Once you have conducted your experiments,

685
00:25:34,640 --> 00:25:35,618
now you have

686
00:25:36,358 --> 00:25:38,588
a uh a model that you are satisfied

687
00:25:38,588 --> 00:25:40,439
with, you can deploy it.

688
00:25:41,469 --> 00:25:43,750
So, let's see how we deployment easier.

689
00:25:44,930 --> 00:25:47,029
Sage Maker AI now

690
00:25:47,289 --> 00:25:49,729
enables you to either launch

691
00:25:49,729 --> 00:25:51,309
or deploy your custom model

692
00:25:51,568 --> 00:25:54,039
to Sage Maker AI inference endpoints,

693
00:25:54,380 --> 00:25:56,430
or Bedrock

694
00:25:56,430 --> 00:25:58,219
as well. So you can go,

695
00:25:58,838 --> 00:26:00,858
select your option and uh

696
00:26:00,858 --> 00:26:02,920
Lauren is going to show you how exactly it is

697
00:26:02,920 --> 00:26:04,939
done. You can

698
00:26:04,939 --> 00:26:07,098
launch and and create a model

699
00:26:07,098 --> 00:26:09,789
that you can then query through Bedrock APIs.

700
00:26:10,459 --> 00:26:12,640
Both are totally possible

701
00:26:12,779 --> 00:26:14,338
and you can do that from the UI.

702
00:26:15,969 --> 00:26:16,729
All right.

703
00:26:17,250 --> 00:26:17,969
So,

704
00:26:18,640 --> 00:26:20,799
This is kind of a whiz, a very

705
00:26:20,799 --> 00:26:21,380
quick

706
00:26:21,640 --> 00:26:23,430
pass through all the experience.

707
00:26:23,838 --> 00:26:26,118
I think now it's time for Lauren

708
00:26:26,118 --> 00:26:27,469
to come and

709
00:26:28,039 --> 00:26:29,660
show you exactly how this looks like.

710
00:26:31,309 --> 00:26:31,939
OK,

711
00:26:34,578 --> 00:26:37,239
Before I show everyone what the new model customization

712
00:26:37,239 --> 00:26:38,400
UI looks like,

713
00:26:38,818 --> 00:26:41,039
um, with Stage on StageMaker AI,

714
00:26:41,209 --> 00:26:42,338
let me set some context.

715
00:26:42,739 --> 00:26:44,140
So, as Eric just mentioned,

716
00:26:44,420 --> 00:26:46,618
the model customization process, it's

717
00:26:46,618 --> 00:26:48,400
often a month-long process.

718
00:26:49,068 --> 00:26:51,068
You have to spend time

719
00:26:51,068 --> 00:26:52,729
researching what model to use

720
00:26:53,150 --> 00:26:54,279
and what fine

721
00:26:54,618 --> 00:26:56,469
fine tuning techniques should you choose,

722
00:26:56,789 --> 00:26:59,189
as well as coordinating with your platform team

723
00:26:59,189 --> 00:27:00,309
for compute access.

724
00:27:00,750 --> 00:27:02,750
Then you spend time experimenting with

725
00:27:02,750 --> 00:27:04,809
different approaches and optimizations.

726
00:27:05,509 --> 00:27:07,588
The new model customization features that we

727
00:27:07,588 --> 00:27:08,868
have with StageMaker AI,

728
00:27:09,309 --> 00:27:11,568
they help remove friction from this process.

729
00:27:12,358 --> 00:27:14,519
The use case I'm about to demonstrate is for

730
00:27:14,519 --> 00:27:15,318
tool calling.

731
00:27:15,799 --> 00:27:17,789
So what exactly is tool calling?

732
00:27:18,199 --> 00:27:20,229
Tool calling enables models to

733
00:27:20,229 --> 00:27:22,068
interact with external systems.

734
00:27:22,358 --> 00:27:24,489
So you can do API calling, you can query

735
00:27:24,489 --> 00:27:25,539
a database,

736
00:27:26,049 --> 00:27:28,250
um, or you can also execute functions.

737
00:27:28,680 --> 00:27:30,900
So, this is what makes agents,

738
00:27:31,118 --> 00:27:32,338
uh, very useful,

739
00:27:32,598 --> 00:27:34,660
um, in production-ready environments.

740
00:27:35,439 --> 00:27:35,959
Now,

741
00:27:36,279 --> 00:27:38,959
base foundation models are often not

742
00:27:38,959 --> 00:27:40,439
production ready for tool calling.

743
00:27:41,259 --> 00:27:43,338
They hallucinate tools that don't

744
00:27:43,338 --> 00:27:45,858
exist. They

745
00:27:45,868 --> 00:27:47,949
fail to uh call

746
00:27:47,949 --> 00:27:50,029
tools that are readily available and they also

747
00:27:50,029 --> 00:27:52,039
execute on incomplete information.

748
00:27:52,269 --> 00:27:54,309
And this is where model customization can help with

749
00:27:54,309 --> 00:27:55,170
this process.

750
00:27:56,098 --> 00:27:58,140
So I'm about to show you how in less

751
00:27:58,140 --> 00:28:00,618
than an hour you can use the new model customization

752
00:28:00,618 --> 00:28:02,979
UI um on StageMaker

753
00:28:02,979 --> 00:28:03,640
Studio

754
00:28:04,019 --> 00:28:05,838
to select a model,

755
00:28:06,140 --> 00:28:08,189
evaluate its performance, fine tune it

756
00:28:08,189 --> 00:28:10,279
first, of course, evaluate its performance

757
00:28:10,500 --> 00:28:11,459
and then deploy it.

758
00:28:11,779 --> 00:28:12,799
So let's get started.

759
00:28:13,608 --> 00:28:15,680
Here I am in Sagemaker's studio, so

760
00:28:15,680 --> 00:28:17,640
I'm navigated to the model section.

761
00:28:18,640 --> 00:28:21,410
You can see here that we have over 1000

762
00:28:21,410 --> 00:28:22,068
models

763
00:28:22,449 --> 00:28:24,650
that we foundation models that we've vetted.

764
00:28:24,930 --> 00:28:26,989
We've also provided hundreds of fine

765
00:28:26,989 --> 00:28:28,289
tuning recipes for them.

766
00:28:29,809 --> 00:28:32,118
For this use case, I'm going to choose

767
00:28:32,118 --> 00:28:34,380
the Queen 2.57 beat

768
00:28:34,380 --> 00:28:35,420
instruct model.

769
00:28:36,000 --> 00:28:37,750
It's a good choice for tool calling

770
00:28:38,039 --> 00:28:40,279
because it has excellent instruction

771
00:28:40,279 --> 00:28:42,279
following capabilities and it has good

772
00:28:42,279 --> 00:28:43,420
performance for its size.

773
00:28:44,078 --> 00:28:46,078
So here, you can see that you can customize

774
00:28:46,078 --> 00:28:48,199
a model with an AI agent that's in preview that

775
00:28:48,199 --> 00:28:50,400
Eric just went over. I'm gonna specifically

776
00:28:50,400 --> 00:28:51,259
walk through

777
00:28:51,799 --> 00:28:53,959
the uh customize with the UI

778
00:28:53,959 --> 00:28:55,699
capability in SageMaker Studio.

779
00:28:56,750 --> 00:28:58,410
So all I do is click this.

780
00:29:00,009 --> 00:29:01,469
And you can see that we have this template

781
00:29:01,729 --> 00:29:04,078
uh for customizing Queen 2.57B

782
00:29:04,078 --> 00:29:04,670
instruct.

783
00:29:05,769 --> 00:29:08,009
There are different customization techniques

784
00:29:08,009 --> 00:29:08,709
you can choose.

785
00:29:09,049 --> 00:29:10,640
So supervised fine tuning,

786
00:29:11,049 --> 00:29:12,559
direct preference optimization,

787
00:29:12,848 --> 00:29:15,108
as well as reinforcement, um,

788
00:29:15,289 --> 00:29:16,269
learning techniques.

789
00:29:16,559 --> 00:29:18,568
Uh, so, we have reinforcement learning with

790
00:29:18,568 --> 00:29:21,289
verifiable rewards or LRVR

791
00:29:21,608 --> 00:29:23,650
or reinforcement learning from AI feedback,

792
00:29:23,848 --> 00:29:24,709
RLAIF.

793
00:29:25,368 --> 00:29:27,449
I'm going to walk through reinforcement

794
00:29:27,449 --> 00:29:29,348
learning with verifiable rewards.

795
00:29:29,969 --> 00:29:32,189
What exactly is RLVR?

796
00:29:33,259 --> 00:29:33,818
Well,

797
00:29:34,150 --> 00:29:36,250
um, we just talked about how

798
00:29:36,789 --> 00:29:39,108
models, base foundation models often struggle

799
00:29:39,108 --> 00:29:40,469
with tool calling precision.

800
00:29:41,108 --> 00:29:43,108
So, we need to find a way

801
00:29:43,108 --> 00:29:45,150
to improve the exact correctness of the

802
00:29:45,150 --> 00:29:46,049
outputs.

803
00:29:46,549 --> 00:29:48,279
So, with RLVR

804
00:29:48,670 --> 00:29:50,809
for each prompt, we generate

805
00:29:51,150 --> 00:29:52,779
multiple different responses.

806
00:29:53,189 --> 00:29:55,890
And then we have what's called a custom reward function,

807
00:29:56,189 --> 00:29:58,449
and that reward function then

808
00:29:58,670 --> 00:30:00,828
verifies if each response is

809
00:30:00,828 --> 00:30:03,219
correct. This enables the model

810
00:30:03,219 --> 00:30:04,479
to learn

811
00:30:04,939 --> 00:30:07,598
and that increases the probability

812
00:30:07,598 --> 00:30:09,759
of the correct outputs

813
00:30:10,019 --> 00:30:11,719
relative to the incorrect ones.

814
00:30:12,299 --> 00:30:14,039
This also uses what's called

815
00:30:14,338 --> 00:30:16,709
group relative policy optimization

816
00:30:16,709 --> 00:30:18,739
or GRPO. So

817
00:30:18,739 --> 00:30:19,608
for each prompt,

818
00:30:19,900 --> 00:30:22,140
those multiple responses are generated. We're

819
00:30:22,140 --> 00:30:23,199
gonna have 8 in this case.

820
00:30:23,660 --> 00:30:25,858
They're in a group, and they're ranked or

821
00:30:25,858 --> 00:30:26,680
scored

822
00:30:27,029 --> 00:30:28,219
by correctness here.

823
00:30:28,500 --> 00:30:29,900
So that's what I'll be showcasing.

824
00:30:30,759 --> 00:30:32,680
So if I choose RLVR,

825
00:30:33,479 --> 00:30:35,059
You'll see that I have the option

826
00:30:35,400 --> 00:30:37,549
to either use a built-in reward function,

827
00:30:38,199 --> 00:30:40,199
we have exact match or code execution

828
00:30:40,199 --> 00:30:42,219
math answers, but in this case,

829
00:30:42,479 --> 00:30:44,598
I really want to, you know, define

830
00:30:44,598 --> 00:30:46,618
what good looks like for my use case exactly.

831
00:30:46,880 --> 00:30:48,660
So I'm going to use a custom reward function.

832
00:30:49,949 --> 00:30:51,959
And so what this is, I'm gonna navigate

833
00:30:52,509 --> 00:30:54,170
to our evaluators page,

834
00:30:54,588 --> 00:30:56,828
and here I can create a ward

835
00:30:56,828 --> 00:30:58,328
function or a reward prompt.

836
00:30:59,949 --> 00:31:01,880
You can see that I've created one earlier,

837
00:31:02,150 --> 00:31:04,219
and all it is is Python code that

838
00:31:04,219 --> 00:31:04,809
I have.

839
00:31:06,170 --> 00:31:08,289
Uh, you can also, you know, upload your, your lambda

840
00:31:08,289 --> 00:31:10,459
function as well. See if I can zoom in.

841
00:31:10,858 --> 00:31:12,519
Um, but essentially,

842
00:31:12,900 --> 00:31:14,939
uh, this reward function that we're gonna

843
00:31:14,939 --> 00:31:17,479
use, it has, it's going to extract

844
00:31:17,818 --> 00:31:20,098
the tool calls from the model's

845
00:31:20,098 --> 00:31:22,299
responses and compare it to our

846
00:31:22,299 --> 00:31:23,118
ground truth.

847
00:31:23,459 --> 00:31:25,799
And it's in a three-tier scoring system.

848
00:31:26,479 --> 00:31:28,559
So what that means here is it's gonna

849
00:31:28,559 --> 00:31:30,880
give these different scores here in the middle. So

850
00:31:30,880 --> 00:31:31,459
one

851
00:31:31,838 --> 00:31:34,039
is a perfect match, which means it's

852
00:31:34,039 --> 00:31:36,818
calling the right function and the right parameters.

853
00:31:37,390 --> 00:31:39,400
0.5 is a partial match,

854
00:31:39,568 --> 00:31:41,939
so that's the right function but the wrong parameters,

855
00:31:42,318 --> 00:31:44,598
and 0 is wrong match

856
00:31:44,598 --> 00:31:46,019
or it's a missing tool call.

857
00:31:47,068 --> 00:31:49,068
Now, our reward function handles an

858
00:31:49,068 --> 00:31:50,670
important edge use case.

859
00:31:51,029 --> 00:31:52,529
What that means is sometimes

860
00:31:52,910 --> 00:31:55,150
it's correct to not do a tool

861
00:31:55,150 --> 00:31:57,170
call. For example,

862
00:31:57,299 --> 00:31:59,309
if you have a user who asks

863
00:31:59,309 --> 00:32:01,489
the model what's the weather like,

864
00:32:01,789 --> 00:32:03,469
but they don't specify a location,

865
00:32:03,989 --> 00:32:06,868
then the model should respond and ask for clarification

866
00:32:06,868 --> 00:32:08,739
instead of providing a bad API call.

867
00:32:09,068 --> 00:32:10,689
So this reward function

868
00:32:11,068 --> 00:32:13,289
recognizes and actually reinforces that behavior.

869
00:32:18,289 --> 00:32:20,289
Right. So now I'm gonna navigate back to

870
00:32:20,289 --> 00:32:20,828
my

871
00:32:21,088 --> 00:32:22,430
page for my training setup

872
00:32:23,009 --> 00:32:25,068
and I'm gonna choose that reward function that I already

873
00:32:25,068 --> 00:32:25,729
set up.

874
00:32:26,838 --> 00:32:29,130
And then you have the option here to, you know, upload

875
00:32:29,130 --> 00:32:31,479
a data set, have one that's already in S3,

876
00:32:31,529 --> 00:32:32,469
which I already do.

877
00:32:32,930 --> 00:32:35,088
So I'm going to select this existing training data

878
00:32:35,088 --> 00:32:35,910
set that I have.

879
00:32:36,868 --> 00:32:39,500
And this contains 1500

880
00:32:39,509 --> 00:32:40,250
tool calling,

881
00:32:40,509 --> 00:32:42,529
uh, samples. So it's a data set

882
00:32:42,910 --> 00:32:45,209
that's derived from the Nvidia's when to call.

883
00:32:45,789 --> 00:32:46,650
And it has

884
00:32:47,029 --> 00:32:48,949
examples of three different types of behavior.

885
00:32:49,229 --> 00:32:51,269
So it either executes a tool

886
00:32:51,269 --> 00:32:53,430
call when you have sufficient information,

887
00:32:53,949 --> 00:32:56,130
it clarifies when there's missing parameters,

888
00:32:56,469 --> 00:32:58,670
or it refuses the response

889
00:32:58,670 --> 00:33:00,910
to provide a response when there's harmful

890
00:33:00,910 --> 00:33:03,108
information, for example, which I'll show at the very end.

891
00:33:04,209 --> 00:33:06,489
You can also see that there's an option to provide

892
00:33:06,489 --> 00:33:08,009
your validation data set.

893
00:33:08,489 --> 00:33:10,430
Um, if you do not provide one,

894
00:33:10,769 --> 00:33:13,019
StageMaker AI will automatically

895
00:33:13,019 --> 00:33:14,410
split your training data set.

896
00:33:14,809 --> 00:33:16,949
So you'll have your validation data,

897
00:33:17,039 --> 00:33:19,358
um, metrics that are already provided, um,

898
00:33:19,368 --> 00:33:20,469
for you during training.

899
00:33:21,279 --> 00:33:23,098
And what this enables is

900
00:33:23,358 --> 00:33:25,680
that the model behavior, you know, can

901
00:33:25,680 --> 00:33:26,299
improve by,

902
00:33:26,759 --> 00:33:29,039
um, not seeing this actual, you know, validation

903
00:33:29,039 --> 00:33:31,309
examples, so it just doesn't learn on the training examples

904
00:33:31,309 --> 00:33:31,858
as well.

905
00:33:33,160 --> 00:33:35,348
Here's where we set our output, um,

906
00:33:35,479 --> 00:33:37,900
you know, artifact, model artifacts location at S3.

907
00:33:39,039 --> 00:33:41,118
Here's the hyperparameterss uh that

908
00:33:41,118 --> 00:33:43,140
we can configure. So for batch size,

909
00:33:43,318 --> 00:33:45,598
I'll leave this at 128. That sounds OK

910
00:33:45,598 --> 00:33:46,818
for the size of the model

911
00:33:47,088 --> 00:33:49,519
and uh for the amount of data

912
00:33:49,519 --> 00:33:50,459
records that I have.

913
00:33:51,029 --> 00:33:53,019
Update the learning rates and I'll have this

914
00:33:53,309 --> 00:33:55,019
passed through the data 3 times.

915
00:33:55,858 --> 00:33:57,939
Also, we have rollouts here that's set to 8.

916
00:33:58,219 --> 00:34:00,358
So that's essentially that we're generating 8

917
00:34:01,420 --> 00:34:03,199
responses for each prompt.

918
00:34:04,759 --> 00:34:05,400
Also,

919
00:34:05,759 --> 00:34:08,039
we are doing experiment tracking

920
00:34:08,039 --> 00:34:10,438
with our new Cerber-less ML

921
00:34:10,438 --> 00:34:12,550
flow. So I've already created a Cerber-less

922
00:34:12,550 --> 00:34:14,599
MLflow app, so you don't have to worry about

923
00:34:14,599 --> 00:34:16,829
any infrastructure provisioning there in MLflow,

924
00:34:16,918 --> 00:34:18,500
brand new capability we launched.

925
00:34:19,228 --> 00:34:21,378
And ML flow automatically tracks

926
00:34:21,378 --> 00:34:22,677
all our training metrics.

927
00:34:22,978 --> 00:34:24,398
So that includes our

928
00:34:24,858 --> 00:34:27,079
uh loss values, um,

929
00:34:27,217 --> 00:34:29,217
as well as our reward scores in this instance

930
00:34:29,217 --> 00:34:30,259
and hyperparametters.

931
00:34:30,539 --> 00:34:33,018
So that way you can compare your training runs

932
00:34:33,018 --> 00:34:35,338
and then also reproduce results.

933
00:34:36,849 --> 00:34:38,208
Now we also have some, of course,

934
00:34:38,489 --> 00:34:40,809
security, top of mind here, AWS so

935
00:34:40,809 --> 00:34:43,088
you can have this run in a private BBC

936
00:34:43,088 --> 00:34:45,387
for example, and then have encryption

937
00:34:45,387 --> 00:34:47,387
with, uh, you know, KMS keys for

938
00:34:47,387 --> 00:34:49,068
uh storage as well.

939
00:34:49,768 --> 00:34:52,028
So, let's just talk about what happens next.

940
00:34:52,407 --> 00:34:54,447
Uh, you may have noticed that I don't have

941
00:34:54,447 --> 00:34:57,009
to worry about any training configuration

942
00:34:57,009 --> 00:34:57,668
set up here.

943
00:34:58,048 --> 00:34:59,447
So, as Eric just mentioned,

944
00:34:59,768 --> 00:35:01,148
one of the key

945
00:35:01,809 --> 00:35:03,967
features that we just launched is

946
00:35:03,967 --> 00:35:04,927
serverless training.

947
00:35:05,929 --> 00:35:06,648
So

948
00:35:07,050 --> 00:35:09,168
in fine tuning, you often have to provision

949
00:35:09,168 --> 00:35:11,648
GPU clusters. You need to manage

950
00:35:11,648 --> 00:35:13,628
distributed training strategies,

951
00:35:14,050 --> 00:35:16,090
and you have to, um, yeah,

952
00:35:16,208 --> 00:35:18,750
configure communication between GPUs

953
00:35:19,050 --> 00:35:21,070
as well as, um,

954
00:35:21,489 --> 00:35:23,769
handling the fault tolerance and checkpointing.

955
00:35:23,929 --> 00:35:26,519
So that's often weeks of infrastructure

956
00:35:26,519 --> 00:35:27,989
work before you can even get started.

957
00:35:28,579 --> 00:35:29,239
So we've

958
00:35:29,639 --> 00:35:31,659
removed that infrastructure complexity here, so you

959
00:35:31,659 --> 00:35:34,000
don't have to worry about that all of this runs completely serverless.

960
00:35:34,300 --> 00:35:36,340
So let me, everything looks good here. I'm ready to submit

961
00:35:36,340 --> 00:35:38,079
my training job, my fine tuning

962
00:35:38,659 --> 00:35:40,739
job. So this will take about

963
00:35:40,739 --> 00:35:41,918
30 minutes to complete.

964
00:35:42,378 --> 00:35:44,539
So let me navigate to a training run that I've already

965
00:35:44,539 --> 00:35:45,840
completed to show you the results.

966
00:35:51,809 --> 00:35:53,349
So we'll see here, this took about

967
00:35:53,639 --> 00:35:56,199
a little over 30 minutes to complete on our 1500

968
00:35:56,199 --> 00:35:57,070
samples.

969
00:35:57,449 --> 00:36:00,090
And I have my um training metrics

970
00:36:00,250 --> 00:36:02,369
that are loading right here that have

971
00:36:02,369 --> 00:36:04,628
already been populated that you can also view in

972
00:36:04,628 --> 00:36:05,949
serverless ML flow.

973
00:36:06,570 --> 00:36:08,728
The main metric that I wanna focus on,

974
00:36:08,809 --> 00:36:11,000
the key one, is the train reward statistics.

975
00:36:11,329 --> 00:36:13,769
So what that means here is this is the model's

976
00:36:13,769 --> 00:36:14,918
reward score,

977
00:36:15,208 --> 00:36:17,489
or it's um how often

978
00:36:17,648 --> 00:36:20,389
the right tool was called with the right parameters.

979
00:36:21,309 --> 00:36:23,628
So it started off here at

980
00:36:23,628 --> 00:36:25,708
about only 25% it was

981
00:36:25,708 --> 00:36:27,780
able to make the right tool calls. The

982
00:36:27,780 --> 00:36:28,510
base model was.

983
00:36:28,829 --> 00:36:30,889
So during the 30 plus

984
00:36:30,889 --> 00:36:31,949
minutes of training,

985
00:36:32,228 --> 00:36:32,929
we hit

986
00:36:33,780 --> 00:36:35,869
0.67 or are now able to

987
00:36:35,869 --> 00:36:37,989
generate 67% of the time

988
00:36:37,989 --> 00:36:39,059
the right tool calls.

989
00:36:39,389 --> 00:36:41,500
So we, you know, essentially doubled our

990
00:36:41,500 --> 00:36:42,949
performance just in 30 minutes,

991
00:36:43,228 --> 00:36:45,168
um, doing fine tuning on this model.

992
00:36:46,398 --> 00:36:48,559
So this looks, you know, pretty good to me

993
00:36:48,559 --> 00:36:49,780
so far. So,

994
00:36:50,159 --> 00:36:52,878
what should we do now is that we need to evaluate

995
00:36:52,878 --> 00:36:53,739
on a held

996
00:36:54,039 --> 00:36:55,699
out, uh, test data set

997
00:36:56,000 --> 00:36:58,639
so that we can measure the model's real-world

998
00:36:58,639 --> 00:36:59,378
performance,

999
00:37:00,000 --> 00:37:01,898
um, on examples it's never seen before.

1000
00:37:02,820 --> 00:37:04,860
So we're able to do that as well with the new model

1001
00:37:04,860 --> 00:37:06,199
customization features.

1002
00:37:06,780 --> 00:37:08,360
Here we go to our custom model.

1003
00:37:09,938 --> 00:37:12,148
And then we're able to evaluate

1004
00:37:12,148 --> 00:37:14,489
it. Um, that's what I'll be doing.

1005
00:37:14,949 --> 00:37:17,079
You can also continue on, uh,

1006
00:37:17,099 --> 00:37:18,409
customization. So

1007
00:37:18,909 --> 00:37:21,769
perhaps you wanna adjust the hyperparametters. 67%

1008
00:37:21,769 --> 00:37:24,228
of, you know, tool calls isn't the

1009
00:37:24,228 --> 00:37:26,228
right metric you're looking for. You can also train

1010
00:37:26,228 --> 00:37:27,739
with a different technique as well.

1011
00:37:28,148 --> 00:37:30,070
So we're gonna move on to evaluation.

1012
00:37:31,458 --> 00:37:33,699
Eric just went over that there's a lot of different evaluation

1013
00:37:33,699 --> 00:37:34,329
types

1014
00:37:34,978 --> 00:37:37,300
for ROVR in this use case,

1015
00:37:37,500 --> 00:37:39,800
it makes sense to have a

1016
00:37:39,800 --> 00:37:41,898
custom uh reward function like we've been

1017
00:37:41,898 --> 00:37:43,898
using. So I'm

1018
00:37:43,898 --> 00:37:46,148
going to choose the custom reward function.

1019
00:37:46,458 --> 00:37:48,559
I'm gonna use the exact same one

1020
00:37:49,099 --> 00:37:51,418
and I'm gonna compare it with the base model too

1021
00:37:51,418 --> 00:37:52,918
in our evaluation runs.

1022
00:37:53,458 --> 00:37:55,619
I want to use the same reward function because

1023
00:37:55,619 --> 00:37:57,860
that's evaluating then this the

1024
00:37:57,860 --> 00:38:00,478
model on the same exact specific criteria

1025
00:38:00,820 --> 00:38:01,860
that we set for training.

1026
00:38:02,699 --> 00:38:04,280
So I picked that reward function.

1027
00:38:05,889 --> 00:38:07,918
And I've already uploaded a, you

1028
00:38:07,918 --> 00:38:10,128
know, similar data set for evaluation

1029
00:38:10,128 --> 00:38:12,489
with the similar behaviors that I talked

1030
00:38:12,489 --> 00:38:14,679
about earlier, so execute

1031
00:38:14,679 --> 00:38:16,349
or clarify or refuse.

1032
00:38:17,789 --> 00:38:19,829
This has 300 samples, so

1033
00:38:19,829 --> 00:38:21,489
definitely, you know, smaller for evaluation.

1034
00:38:22,559 --> 00:38:25,059
And here are the advanced configuration

1035
00:38:25,159 --> 00:38:26,708
uh parameters I need to sets.

1036
00:38:27,039 --> 00:38:29,059
This is just the context window.

1037
00:38:29,800 --> 00:38:32,099
So I'll have that at 2046,

1038
00:38:32,398 --> 00:38:34,519
and the max new tokens is just

1039
00:38:34,519 --> 00:38:36,429
the tool calls responses.

1040
00:38:36,719 --> 00:38:37,340
So

1041
00:38:37,800 --> 00:38:40,139
I'll set that tokens of 512.

1042
00:38:40,360 --> 00:38:42,438
I'll leave the temperature in the top K and the top

1043
00:38:42,438 --> 00:38:44,099
P, uh, the same.

1044
00:38:45,438 --> 00:38:47,579
And then I'll keep this in a,

1045
00:38:47,760 --> 00:38:49,378
that's the default as well.

1046
00:38:53,188 --> 00:38:54,570
So I'll submit that.

1047
00:38:55,550 --> 00:38:56,929
And this will take about

1048
00:38:57,510 --> 00:38:58,449
10 minutes

1049
00:38:58,708 --> 00:39:01,128
to actually run the evaluation

1050
00:39:01,128 --> 00:39:02,010
uh jobs

1051
00:39:02,708 --> 00:39:04,250
um on StageMaker

1052
00:39:04,550 --> 00:39:06,449
and we'll compare the base model

1053
00:39:06,750 --> 00:39:08,329
to the custom model.

1054
00:39:12,050 --> 00:39:14,429
So let me navigate to an already completed

1055
00:39:14,429 --> 00:39:15,728
um run here.

1056
00:39:21,659 --> 00:39:23,889
Let's take a look first at the lineage just to show you that

1057
00:39:23,889 --> 00:39:26,128
this is also available, which is very helpful

1058
00:39:26,128 --> 00:39:28,590
then, um, so you can do governance

1059
00:39:28,809 --> 00:39:31,010
and determine like where is your actual, you know, data

1060
00:39:31,010 --> 00:39:33,128
coming from, what have you been doing, you can see your,

1061
00:39:33,168 --> 00:39:35,199
your pipeline and then, um, you know,

1062
00:39:35,289 --> 00:39:37,369
could deploy this to production as well. So this

1063
00:39:37,369 --> 00:39:39,148
is all available, uh, here.

1064
00:39:39,418 --> 00:39:41,809
You also have logs that you could take a look at

1065
00:39:41,809 --> 00:39:43,280
to determine what the model's doing.

1066
00:39:43,610 --> 00:39:45,429
Maybe you need to do like some early stopping.

1067
00:39:46,478 --> 00:39:48,639
And then we have the evaluation

1068
00:39:48,639 --> 00:39:50,500
metrics that are already um.

1069
00:39:51,878 --> 00:39:53,958
Loaded for you here as well. These

1070
00:39:53,958 --> 00:39:56,429
are also available in ML flow

1071
00:39:56,429 --> 00:39:57,559
um by default.

1072
00:39:59,820 --> 00:40:01,969
So the main metrics that

1073
00:40:01,969 --> 00:40:04,269
I think are important to highlight

1074
00:40:04,530 --> 00:40:06,429
are the tool call reward.

1075
00:40:06,849 --> 00:40:08,309
So you can see that the base model,

1076
00:40:08,599 --> 00:40:10,849
it's at 0.35 and we were able to

1077
00:40:10,849 --> 00:40:12,469
increase that by 20 points

1078
00:40:12,809 --> 00:40:14,530
to 0.55.

1079
00:40:15,300 --> 00:40:17,219
So what does this actually mean? Is

1080
00:40:17,500 --> 00:40:19,500
that the model is making

1081
00:40:19,500 --> 00:40:21,849
the right decision either to

1082
00:40:21,849 --> 00:40:22,719
execute,

1083
00:40:23,179 --> 00:40:25,599
um, on to execute a tool,

1084
00:40:26,179 --> 00:40:28,500
uh, or clarify on,

1085
00:40:28,579 --> 00:40:30,878
you know, missing parameter if there's missing parameters

1086
00:40:31,099 --> 00:40:32,878
or refuse the request.

1087
00:40:33,340 --> 00:40:36,019
So we're able to do that now 55%

1088
00:40:36,019 --> 00:40:36,659
of the time.

1089
00:40:37,239 --> 00:40:39,329
And all we had to do was this took about,

1090
00:40:39,369 --> 00:40:41,610
you know, 40 minutes to do training and evaluation,

1091
00:40:41,889 --> 00:40:42,550
which is often,

1092
00:40:42,840 --> 00:40:45,148
you know, a multi-month process just to set this up.

1093
00:40:46,369 --> 00:40:48,458
The next metric that

1094
00:40:48,458 --> 00:40:50,688
I think is important is the F1

1095
00:40:50,688 --> 00:40:51,360
score

1096
00:40:51,648 --> 00:40:52,378
uh quasi

1097
00:40:52,809 --> 00:40:53,478
quasi.

1098
00:40:54,099 --> 00:40:56,099
So the base score you can see here is about

1099
00:40:56,099 --> 00:40:57,438
46%

1100
00:40:58,019 --> 00:41:00,179
and the custom score, so

1101
00:41:00,179 --> 00:41:02,039
our fine-tuned model, is now,

1102
00:41:02,300 --> 00:41:02,918
uh,

1103
00:41:03,219 --> 00:41:05,418
the results are 64.6%.

1104
00:41:05,699 --> 00:41:08,059
So this actually measures the output

1105
00:41:08,059 --> 00:41:08,648
quality.

1106
00:41:08,978 --> 00:41:11,478
What that means is that the model generate

1107
00:41:11,478 --> 00:41:13,079
the right function name.

1108
00:41:14,000 --> 00:41:16,478
The correct parameters and the

1109
00:41:16,478 --> 00:41:18,648
proper JSON formatting. So it's essentially

1110
00:41:18,648 --> 00:41:19,909
2/3 at a time.

1111
00:41:20,239 --> 00:41:22,398
The outputs are functionally correct here.

1112
00:41:23,590 --> 00:41:25,708
You can also view the full evaluation

1113
00:41:25,708 --> 00:41:27,750
results um in ML flow. There's a lot

1114
00:41:27,750 --> 00:41:29,208
more metrics you can take a look at.

1115
00:41:30,188 --> 00:41:32,530
So I can compare

1116
00:41:32,530 --> 00:41:33,449
the different.

1117
00:41:34,409 --> 00:41:35,148
Um,

1118
00:41:35,409 --> 00:41:36,590
training runs I had here.

1119
00:41:39,329 --> 00:41:41,780
So all I have to do is check those and then click compare

1120
00:41:42,438 --> 00:41:44,478
and then you can see here's our base model on the

1121
00:41:44,478 --> 00:41:46,478
left and our actually I probably just

1122
00:41:46,478 --> 00:41:48,559
clicked the wrong ones, but the custom model on

1123
00:41:48,559 --> 00:41:51,179
the right and you'll be able to see all the different metrics

1124
00:41:51,360 --> 00:41:53,019
and compare them. So there's more in here

1125
00:41:53,599 --> 00:41:55,780
that are, you know, system metrics and so forth.

1126
00:41:58,269 --> 00:42:00,300
OK, so now our evaluation,

1127
00:42:00,429 --> 00:42:02,438
you know, looks pretty good to me, and we're ready

1128
00:42:02,438 --> 00:42:04,619
to deploy this model and test it,

1129
00:42:04,679 --> 00:42:06,840
um, you know, for inference on some

1130
00:42:06,840 --> 00:42:07,739
requests that we have.

1131
00:42:10,260 --> 00:42:11,280
I have the option

1132
00:42:11,699 --> 00:42:12,708
to deploy

1133
00:42:12,978 --> 00:42:14,398
um on Bedrock

1134
00:42:15,019 --> 00:42:15,639
or

1135
00:42:16,019 --> 00:42:18,099
on StageMakker. So let's do

1136
00:42:18,099 --> 00:42:20,260
StageMaker for real-time inference. I'm

1137
00:42:20,260 --> 00:42:22,139
going to create a new endpoint.

1138
00:42:24,398 --> 00:42:25,739
And here I just

1139
00:42:26,119 --> 00:42:28,320
type in the endpoint name and by default

1140
00:42:28,320 --> 00:42:30,458
it's recommending an MLGXG6

1141
00:42:30,458 --> 00:42:32,679
12X large instance.

1142
00:42:33,119 --> 00:42:34,750
I can update that, um, you know,

1143
00:42:35,079 --> 00:42:36,159
depending on your needs

1144
00:42:36,519 --> 00:42:38,800
and you also have some options as far as updating

1145
00:42:38,800 --> 00:42:40,958
the, uh, you know, instance count, the max instance

1146
00:42:40,958 --> 00:42:43,039
count. There's also some auto-scaling that you can set as

1147
00:42:43,039 --> 00:42:45,219
well. If you notice here,

1148
00:42:45,300 --> 00:42:46,418
I don't have to

1149
00:42:46,699 --> 00:42:49,418
build an inference container or write any serving

1150
00:42:49,418 --> 00:42:51,458
codes. So we've extracted that away for you, so

1151
00:42:51,458 --> 00:42:53,119
it's very easy to deploy here.

1152
00:42:53,739 --> 00:42:55,079
So I'll just click deploy.

1153
00:43:00,360 --> 00:43:02,599
And this will take about 10 minutes

1154
00:43:02,599 --> 00:43:03,978
to provision that real-time

1155
00:43:04,349 --> 00:43:06,000
inference end point and stage maker.

1156
00:43:08,809 --> 00:43:10,849
So let me navigate to an endpoint that's

1157
00:43:10,849 --> 00:43:11,550
already up.

1158
00:43:13,239 --> 00:43:15,280
You can see that we have our base model and our

1159
00:43:15,280 --> 00:43:17,599
Laura adapter, so that's our, you know, pre-trained

1160
00:43:17,599 --> 00:43:19,699
weights combined with our learned adaptation.

1161
00:43:20,159 --> 00:43:22,349
And here we also have a

1162
00:43:22,349 --> 00:43:24,639
playground that you can test the

1163
00:43:24,639 --> 00:43:25,199
model's, you know,

1164
00:43:25,469 --> 00:43:26,179
responses.

1165
00:43:29,679 --> 00:43:31,760
So I'm gonna update this to a single prompt

1166
00:43:31,760 --> 00:43:34,000
mode and then here you can see

1167
00:43:34,000 --> 00:43:35,760
that we have a system prompt.

1168
00:43:36,159 --> 00:43:38,360
So this is uh very important for

1169
00:43:38,360 --> 00:43:39,320
uh tool calling.

1170
00:43:39,750 --> 00:43:40,289
Um,

1171
00:43:40,550 --> 00:43:43,070
because here you're able to define

1172
00:43:43,070 --> 00:43:44,769
the tools that are available

1173
00:43:45,030 --> 00:43:46,409
as well as,

1174
00:43:46,869 --> 00:43:48,909
um, so define the tools that are available as

1175
00:43:48,909 --> 00:43:51,228
well as the expected JSON, uh,

1176
00:43:51,269 --> 00:43:52,079
outputs,

1177
00:43:52,360 --> 00:43:54,628
and this also includes then our

1178
00:43:54,628 --> 00:43:56,340
three behaviors that we trained on.

1179
00:43:56,750 --> 00:43:59,510
So that would be the execute, clarify,

1180
00:43:59,628 --> 00:44:01,449
or refuse. So let's test out some

1181
00:44:02,139 --> 00:44:04,349
examples here to see what this looks like in action.

1182
00:44:06,159 --> 00:44:08,159
We also have some other metrics that we can add that

1183
00:44:08,159 --> 00:44:10,159
we can um update, um, or

1184
00:44:10,159 --> 00:44:11,739
sorry, some other parameters we can update.

1185
00:44:12,139 --> 00:44:14,159
So we have those output tokens such as

1186
00:44:14,159 --> 00:44:16,300
the the model's response

1187
00:44:16,639 --> 00:44:18,978
and as well as the randomness on diversity.

1188
00:44:19,239 --> 00:44:21,840
I want to keep the temperature pretty low

1189
00:44:21,840 --> 00:44:24,340
because I want these tool calls to be deterministic

1190
00:44:24,708 --> 00:44:26,760
and not be very creative. Top P looks

1191
00:44:26,760 --> 00:44:27,739
good to me as well.

1192
00:44:28,280 --> 00:44:30,280
And then I just enter my prompt here in the bottom.

1193
00:44:30,398 --> 00:44:32,599
So, first, I'll start with a

1194
00:44:32,599 --> 00:44:34,418
tool call, um, that should execute.

1195
00:44:35,059 --> 00:44:36,010
So I'll enter in

1196
00:44:36,369 --> 00:44:38,070
what is the stock price.

1197
00:44:40,250 --> 00:44:40,878
For Amazon.

1198
00:44:42,219 --> 00:44:43,329
And I can run that

1199
00:44:44,269 --> 00:44:46,360
And here it's actually gonna generate that tool call like

1200
00:44:46,360 --> 00:44:48,438
we expected. And then it could also, you

1201
00:44:48,438 --> 00:44:50,438
know, um, do an external API

1202
00:44:50,438 --> 00:44:52,519
call and we'll get the current stock price for Amazon.

1203
00:44:52,878 --> 00:44:54,958
So that's exactly what they expect the model

1204
00:44:54,958 --> 00:44:55,500
to do.

1205
00:44:56,119 --> 00:44:57,898
So that's that perfect match,

1206
00:44:58,159 --> 00:45:00,500
um, as well where it's the right,

1207
00:45:00,510 --> 00:45:02,179
uh, function and the right parameters.

1208
00:45:02,719 --> 00:45:03,228
OK.

1209
00:45:03,639 --> 00:45:05,760
Now let's do an example where the model

1210
00:45:05,760 --> 00:45:06,929
should ask to clarify.

1211
00:45:07,320 --> 00:45:09,438
So, you know, I asked, I mentioned

1212
00:45:09,438 --> 00:45:10,978
earlier like what's the weather like?

1213
00:45:12,579 --> 00:45:13,519
Well, right now,

1214
00:45:13,780 --> 00:45:16,500
you know, the model has no idea where I am. There's no like geolocation

1215
00:45:16,500 --> 00:45:18,539
enabled, so it's asking

1216
00:45:18,539 --> 00:45:19,619
for clarification.

1217
00:45:19,938 --> 00:45:20,829
So it's asking me,

1218
00:45:21,320 --> 00:45:23,500
could I please specify the city that I'm interested in.

1219
00:45:23,659 --> 00:45:25,159
So you know I could add that in it should,

1220
00:45:25,500 --> 00:45:26,719
um, you know, respond.

1221
00:45:28,659 --> 00:45:30,898
Now let's enter in a harmful

1222
00:45:30,898 --> 00:45:32,958
request that the model should refuse.

1223
00:45:33,500 --> 00:45:34,079
So,

1224
00:45:35,699 --> 00:45:38,228
How do I hack into an email

1225
00:45:38,228 --> 00:45:43,188
address? So,

1226
00:45:43,239 --> 00:45:45,269
just because, so since we fine tune our model, now

1227
00:45:45,269 --> 00:45:47,489
it's actually responding and saying that it can't assist

1228
00:45:47,949 --> 00:45:49,989
with hacking or any illegal activities. So

1229
00:45:49,989 --> 00:45:52,179
please provide a legitimate request for

1230
00:45:52,179 --> 00:45:52,688
assistance,

1231
00:45:53,030 --> 00:45:55,110
which is exactly what we want the model

1232
00:45:55,110 --> 00:45:56,309
to respond with.

1233
00:45:56,628 --> 00:45:58,989
So, results look pretty good to me. So

1234
00:45:58,989 --> 00:46:01,228
looks like this, this may be ready for production

1235
00:46:01,228 --> 00:46:03,228
or at least you can test this more

1236
00:46:03,228 --> 00:46:05,668
um in you know in your QA environment

1237
00:46:05,989 --> 00:46:08,110
and then determine um if this works

1238
00:46:08,110 --> 00:46:09,250
for your use case.

1239
00:46:10,800 --> 00:46:13,159
OK, so let's just recap

1240
00:46:13,159 --> 00:46:13,860
what we did.

1241
00:46:14,199 --> 00:46:16,458
We were able to use the new

1242
00:46:16,458 --> 00:46:18,280
model customization UI

1243
00:46:18,800 --> 00:46:20,699
um in Stage Maker Studio.

1244
00:46:21,760 --> 00:46:23,789
And we used RLVR

1245
00:46:24,438 --> 00:46:26,599
and fine-tuned with the custom reward

1246
00:46:26,599 --> 00:46:29,409
function. With

1247
00:46:29,409 --> 00:46:31,809
serverless infrastructure, so we didn't have to set up any

1248
00:46:31,809 --> 00:46:34,050
of that training, so we removed all the infrastructure

1249
00:46:34,050 --> 00:46:35,228
complexities there.

1250
00:46:36,090 --> 00:46:38,128
We were able to evaluate the model's

1251
00:46:38,128 --> 00:46:39,949
performance with a custom reward function.

1252
00:46:40,250 --> 00:46:43,090
You could also use more deterministic benchmarks

1253
00:46:43,090 --> 00:46:45,090
as well as LLM as a judge, for

1254
00:46:45,090 --> 00:46:46,389
example, on Bedrock,

1255
00:46:46,869 --> 00:46:48,889
and we were able to deploy the model

1256
00:46:48,889 --> 00:46:51,010
for real-time inference. And we were able

1257
00:46:51,010 --> 00:46:53,168
to do that in, you know, less

1258
00:46:53,168 --> 00:46:55,369
than. Uh, you know, all

1259
00:46:55,369 --> 00:46:56,349
less than an hour.

1260
00:46:56,969 --> 00:46:59,219
So instead of navigating the,

1261
00:46:59,398 --> 00:47:01,530
you know, model complexities that

1262
00:47:01,530 --> 00:47:03,648
often take months, you can really

1263
00:47:03,648 --> 00:47:05,070
define your use case

1264
00:47:05,329 --> 00:47:06,929
and, and focus on that.

1265
00:47:08,059 --> 00:47:09,840
You're able to iterate

1266
00:47:10,219 --> 00:47:13,300
in, you know, hours instead of weeks

1267
00:47:13,300 --> 00:47:15,539
or months with the new model customization features in StageMaker

1268
00:47:15,539 --> 00:47:17,659
AI. So I hope that you

1269
00:47:17,659 --> 00:47:18,599
try it out today

1270
00:47:19,059 --> 00:47:21,579
and start experimenting with your own use cases.

1271
00:47:21,938 --> 00:47:24,019
So thank you and let us know if you have any

1272
00:47:24,019 --> 00:47:31,989
questions. So

1273
00:47:35,530 --> 00:47:37,840
Thank you all, and please don't forget to

1274
00:47:38,059 --> 00:47:39,280
fill out the survey.

1275
00:47:40,309 --> 00:47:41,809
That's very important for us,

1276
00:47:42,188 --> 00:47:44,269
and we are happy to answer any questions if

1277
00:47:44,269 --> 00:47:45,128
you want to

1278
00:47:45,469 --> 00:47:47,550
stick around and chat with us. Thank you all.

