1
00:00:00,300 --> 00:00:01,890
- All right, hello everyone.

2
00:00:01,890 --> 00:00:04,230
I hope you are having an
amazing time in Vegas.

3
00:00:04,230 --> 00:00:05,670
I know I am.

4
00:00:05,670 --> 00:00:07,110
My name is Natalia Leon.

5
00:00:07,110 --> 00:00:08,760
I'm part of our strategic
partnerships team

6
00:00:08,760 --> 00:00:10,050
here at Salesforce.

7
00:00:10,050 --> 00:00:12,180
And today I'm joined by my colleague, Sid,

8
00:00:12,180 --> 00:00:14,010
who's one of our amazing product managers

9
00:00:14,010 --> 00:00:16,650
for our Data 360 platform at Salesforce,

10
00:00:16,650 --> 00:00:19,740
as well as Bill, who is an
amazing solutions architect

11
00:00:19,740 --> 00:00:21,240
over at AWS.

12
00:00:21,240 --> 00:00:22,920
Today, we're really
excited to share with you

13
00:00:22,920 --> 00:00:25,780
how Salesforce and AWS
are empowering customers

14
00:00:25,780 --> 00:00:28,260
to unlock the full potential of the data

15
00:00:28,260 --> 00:00:30,120
that they already have access to,

16
00:00:30,120 --> 00:00:32,010
to deliver better experiences

17
00:00:32,010 --> 00:00:34,470
and set the right foundation for AI.

18
00:00:34,470 --> 00:00:35,940
So during today's time,

19
00:00:35,940 --> 00:00:38,670
we will walk you through an
overview of the solution.

20
00:00:38,670 --> 00:00:40,080
We'll do a little bit of a deeper dive

21
00:00:40,080 --> 00:00:41,160
into the architecture.

22
00:00:41,160 --> 00:00:43,380
We'll showcase a demo, and
then we'll round it out

23
00:00:43,380 --> 00:00:45,183
with some customer success stories.

24
00:00:46,160 --> 00:00:47,250
As a reminder,

25
00:00:47,250 --> 00:00:49,590
please make sure that you
make any purchasing decisions

26
00:00:49,590 --> 00:00:52,170
based on information that is
publicly readily available

27
00:00:52,170 --> 00:00:53,550
to you.

28
00:00:53,550 --> 00:00:55,160
All right, so before we get technical,

29
00:00:55,160 --> 00:00:58,410
I'd like to just ground
us on a simple truth

30
00:00:58,410 --> 00:01:00,720
that I think we can all
relate to as customers

31
00:01:00,720 --> 00:01:03,440
of all the different companies
that we interact with

32
00:01:03,440 --> 00:01:06,690
and the expectations that come from that.

33
00:01:06,690 --> 00:01:08,550
As a customer, I know myself,

34
00:01:08,550 --> 00:01:10,590
I expect companies that I interact with

35
00:01:10,590 --> 00:01:12,360
to understand who I am,

36
00:01:12,360 --> 00:01:14,790
deliver personalized experiences to me,

37
00:01:14,790 --> 00:01:18,060
and anticipate my needs when
I'm interacting with them.

38
00:01:18,060 --> 00:01:21,870
And so based on those expectations,

39
00:01:21,870 --> 00:01:24,630
customers are really
struggling to deliver that

40
00:01:24,630 --> 00:01:25,920
to their end consumers

41
00:01:25,920 --> 00:01:29,100
because all of their
data tends to be siloed.

42
00:01:29,100 --> 00:01:31,500
I know myself, probably you too,

43
00:01:31,500 --> 00:01:32,730
was hopefully taking advantage

44
00:01:32,730 --> 00:01:34,200
of some of the Black Friday deals

45
00:01:34,200 --> 00:01:36,090
that just happened this past Friday.

46
00:01:36,090 --> 00:01:37,650
And when I was doing shopping,

47
00:01:37,650 --> 00:01:40,140
I caught myself expecting these companies

48
00:01:40,140 --> 00:01:44,283
to really get to know me and
deliver the right offers to me.

49
00:01:45,750 --> 00:01:49,440
And what was once an option for companies

50
00:01:49,440 --> 00:01:51,690
is now really truly essential for them

51
00:01:51,690 --> 00:01:54,160
to be able to unlock their
full value of their data

52
00:01:54,160 --> 00:01:56,550
and deliver those personalized experiences

53
00:01:56,550 --> 00:01:59,060
that we all expect from them.

54
00:01:59,060 --> 00:02:01,920
But this right now is really
challenging for companies.

55
00:02:01,920 --> 00:02:03,360
And the reason for that is because

56
00:02:03,360 --> 00:02:07,620
company's data remains fragmented
across multiple systems,

57
00:02:07,620 --> 00:02:11,400
across multiple formats,
leading to a lot of data silos.

58
00:02:11,400 --> 00:02:13,560
And data silos typically means that

59
00:02:13,560 --> 00:02:16,710
company's data is unreliable for insights.

60
00:02:16,710 --> 00:02:18,460
Besides being unreliable for insights,

61
00:02:18,460 --> 00:02:21,633
the data's actually also
really hard to act upon,

62
00:02:22,620 --> 00:02:26,580
impeding companies to be
able to meet customer needs.

63
00:02:26,580 --> 00:02:29,940
And so because of that, what
we've seen with companies

64
00:02:29,940 --> 00:02:33,630
is that their data tends to be siloed

65
00:02:33,630 --> 00:02:35,190
and they're unable to deliver

66
00:02:35,190 --> 00:02:37,050
these personalized connected experiences

67
00:02:37,050 --> 00:02:38,403
that we expect from them.

68
00:02:39,870 --> 00:02:41,460
Companies that are getting ahead

69
00:02:41,460 --> 00:02:43,470
and are really leading the charge

70
00:02:43,470 --> 00:02:47,460
are differentiated themselves
by providing their customers

71
00:02:47,460 --> 00:02:49,800
with the personalized customer experiences

72
00:02:49,800 --> 00:02:51,270
that we deserve and need.

73
00:02:51,270 --> 00:02:54,420
I found myself on Black Friday,

74
00:02:54,420 --> 00:02:56,070
clicking the checkout button pretty fast

75
00:02:56,070 --> 00:02:57,630
when a company was able to deliver

76
00:02:57,630 --> 00:02:59,010
a personalized offer to me

77
00:02:59,010 --> 00:03:01,080
and even provide shopping assistance

78
00:03:01,080 --> 00:03:03,660
for the pair of shoes that I
wanted on the Black Friday.

79
00:03:03,660 --> 00:03:07,050
So with that, because of that challenge

80
00:03:07,050 --> 00:03:08,970
that we're seeing customers experience,

81
00:03:08,970 --> 00:03:11,440
here at Salesforce, we
have partnered with AWS

82
00:03:11,440 --> 00:03:14,940
to help companies be
able to unify their data

83
00:03:14,940 --> 00:03:17,460
and activate it across
the entire enterprise,

84
00:03:17,460 --> 00:03:19,830
which is what we're gonna
be discussing today.

85
00:03:19,830 --> 00:03:21,690
Additionally, as part of this partnership,

86
00:03:21,690 --> 00:03:25,650
we are also enabling companies
to empower their agents

87
00:03:25,650 --> 00:03:27,900
with the right necessary
models and flexibility

88
00:03:27,900 --> 00:03:31,860
and control that they need to
deliver those AI experiences.

89
00:03:31,860 --> 00:03:35,610
Additionally, we are also
enabling multi-agent ecosystems,

90
00:03:35,610 --> 00:03:39,060
depending on the customer's
technology landscape,

91
00:03:39,060 --> 00:03:40,860
and then of course, providing companies

92
00:03:40,860 --> 00:03:44,430
with end-to-end trust and
compliance along the way.

93
00:03:44,430 --> 00:03:46,800
So with that, I'm gonna
pass it over to Sid,

94
00:03:46,800 --> 00:03:48,180
who's gonna show you how Data 360

95
00:03:48,180 --> 00:03:50,313
makes all of this possible.

96
00:03:52,800 --> 00:03:53,780
- All right.

97
00:03:53,780 --> 00:03:55,233
Oh, let me take the clicker.

98
00:04:00,780 --> 00:04:03,780
So the main topic of the
presentation is zero copy,

99
00:04:03,780 --> 00:04:05,850
and that's what Bill is gonna go over.

100
00:04:05,850 --> 00:04:07,830
But before that, I wanna describe

101
00:04:07,830 --> 00:04:10,620
what Data 360 is to everyone.

102
00:04:10,620 --> 00:04:12,180
So we know that in general,

103
00:04:12,180 --> 00:04:14,280
an organization's data state is home

104
00:04:14,280 --> 00:04:17,430
to many separate but related systems,

105
00:04:17,430 --> 00:04:21,060
data lake houses,
warehouses, message brokers,

106
00:04:21,060 --> 00:04:24,423
CRM, ERP, and a host
of other data products.

107
00:04:25,260 --> 00:04:29,460
But Data 360 is distinct
from those existing systems.

108
00:04:29,460 --> 00:04:31,200
It's not a system of record.

109
00:04:31,200 --> 00:04:33,330
It is not a warehouse.

110
00:04:33,330 --> 00:04:36,360
It is not a lake house, although
it is underpinned by one.

111
00:04:36,360 --> 00:04:38,120
It has a very singular purpose,

112
00:04:38,120 --> 00:04:41,850
and that is to harness, harmonize,

113
00:04:41,850 --> 00:04:46,080
and activate every single
data point in your data state,

114
00:04:46,080 --> 00:04:49,170
whether that data point
was generated a second ago,

115
00:04:49,170 --> 00:04:51,420
whether it was generated decades ago,

116
00:04:51,420 --> 00:04:54,540
whether it is structured,
whether it is unstructured,

117
00:04:54,540 --> 00:04:56,850
towards one of three ends.

118
00:04:56,850 --> 00:04:59,820
First and most importantly,
understand the customer.

119
00:04:59,820 --> 00:05:01,770
Second, to grow faster sales.

120
00:05:01,770 --> 00:05:04,980
And third, to improve
productivity, work faster.

121
00:05:04,980 --> 00:05:08,640
And this is why you
will often hear Data 360

122
00:05:08,640 --> 00:05:12,300
described as Salesforce's
activation engine.

123
00:05:12,300 --> 00:05:13,800
Activate is the most important

124
00:05:13,800 --> 00:05:15,960
of the three verbs that I mentioned.

125
00:05:15,960 --> 00:05:18,960
It is the bedrock of Customer 360,

126
00:05:18,960 --> 00:05:21,720
which is the applications
that you're all familiar with,

127
00:05:21,720 --> 00:05:24,900
Sales Cloud, Service Cloud,
Marketing Cloud, and Company,

128
00:05:24,900 --> 00:05:28,770
as well as Agentforce 360,
which is the agents that dwell

129
00:05:28,770 --> 00:05:32,610
and operate within and across
those distinct applications.

130
00:05:32,610 --> 00:05:34,050
Now, what you see on this slide

131
00:05:34,050 --> 00:05:37,020
are three building blocks of Data 360,

132
00:05:37,020 --> 00:05:40,740
and each one builds on the
previous one in some sense.

133
00:05:40,740 --> 00:05:44,160
The first thing is access
data wherever it resides,

134
00:05:44,160 --> 00:05:46,140
and in the manner that is most well-suited

135
00:05:46,140 --> 00:05:47,520
for the task at hand,

136
00:05:47,520 --> 00:05:52,520
optimizing both for
performance and for economics.

137
00:05:52,530 --> 00:05:54,930
Now, the connectivity
suite is extremely rich,

138
00:05:54,930 --> 00:05:57,180
and I will describe it
in further detail later,

139
00:05:57,180 --> 00:05:58,920
but if I was to summarize it in one word,

140
00:05:58,920 --> 00:06:00,870
that would be optionality.

141
00:06:00,870 --> 00:06:02,460
Now, the keystone or the crown jewel

142
00:06:02,460 --> 00:06:04,680
of the connectivity suite is zero copy,

143
00:06:04,680 --> 00:06:07,710
and that's what Bill is
gonna talk about more.

144
00:06:07,710 --> 00:06:08,920
Now, the second building block

145
00:06:08,920 --> 00:06:13,920
is a very important set of
datasets in your data state,

146
00:06:14,500 --> 00:06:17,520
and those are the ones about the customer.

147
00:06:17,520 --> 00:06:20,400
Now, in any engagement
with a prospective client

148
00:06:20,400 --> 00:06:23,250
or a current client, it makes sense

149
00:06:23,250 --> 00:06:25,560
that the more informed
I am about that client,

150
00:06:25,560 --> 00:06:28,360
the more fruitful that
engagement is gonna be,

151
00:06:28,360 --> 00:06:31,560
and typically, we see
that data about a customer

152
00:06:31,560 --> 00:06:34,530
can be spread across
multiple distinct systems,

153
00:06:34,530 --> 00:06:36,540
and so in Data 360, you can create

154
00:06:36,540 --> 00:06:40,080
that unified profile of a single customer,

155
00:06:40,080 --> 00:06:41,910
and that profile becomes the basic

156
00:06:41,910 --> 00:06:44,840
or the atomic unit of
segment of one personalized

157
00:06:44,840 --> 00:06:47,880
automation, analytics, AI,

158
00:06:47,880 --> 00:06:50,823
across sales, service,
and marketing, and more.

159
00:06:52,230 --> 00:06:54,810
The third building block builds on that,

160
00:06:54,810 --> 00:06:57,330
and that is building
the world for the agent,

161
00:06:57,330 --> 00:06:58,920
so just as every single one of us

162
00:06:58,920 --> 00:07:00,440
has a mental model of the world,

163
00:07:00,440 --> 00:07:03,300
we need to provide the same for an agent

164
00:07:03,300 --> 00:07:05,640
if it is to act effectively.

165
00:07:05,640 --> 00:07:08,850
The agent needs to know
what it can and can't do,

166
00:07:08,850 --> 00:07:09,990
of the things that it can do,

167
00:07:09,990 --> 00:07:11,910
what it should and should not do,

168
00:07:11,910 --> 00:07:15,930
and of the things that it should
do, how should it do them?

169
00:07:15,930 --> 00:07:17,550
And so defining that world,

170
00:07:17,550 --> 00:07:21,360
specifically all the nouns
and verbs for the agent,

171
00:07:21,360 --> 00:07:23,823
is something that takes place in Data 360.

172
00:07:26,250 --> 00:07:27,960
So how does data actually get activated?

173
00:07:27,960 --> 00:07:30,600
The first thing is to connect Data 360

174
00:07:30,600 --> 00:07:33,540
to the different systems
in your data state.

175
00:07:33,540 --> 00:07:35,280
And as I mentioned, the connectivity suite

176
00:07:35,280 --> 00:07:37,170
is incredibly rich.

177
00:07:37,170 --> 00:07:40,140
Structured, semi-structured, unstructured,

178
00:07:40,140 --> 00:07:43,380
real-time, streaming, batched, zero-copy.

179
00:07:43,380 --> 00:07:45,420
There are connectors for databases,

180
00:07:45,420 --> 00:07:46,890
for standalone query engines,

181
00:07:46,890 --> 00:07:51,150
data lake houses, warehouses,
application providers.

182
00:07:51,150 --> 00:07:52,650
Almost everything will be covered

183
00:07:52,650 --> 00:07:55,770
within that very expansive
set of connectors.

184
00:07:55,770 --> 00:07:57,510
And again, zero-copy is the focus,

185
00:07:57,510 --> 00:08:00,450
and we're gonna talk
about that more later.

186
00:08:00,450 --> 00:08:02,760
The second step is to harmonize data.

187
00:08:02,760 --> 00:08:06,600
And this is a verb that is
very often misunderstood.

188
00:08:06,600 --> 00:08:08,760
Harmonization simply means to standardize

189
00:08:08,760 --> 00:08:10,080
across the different schemas

190
00:08:10,080 --> 00:08:11,660
that you have in your data state,

191
00:08:11,660 --> 00:08:14,100
to resolve conflicting identities,

192
00:08:14,100 --> 00:08:16,233
and to construct those unified profiles.

193
00:08:17,070 --> 00:08:20,460
So think of this as creating
a blueprint for your business.

194
00:08:20,460 --> 00:08:24,030
Not the actual datasets that
are in your different systems,

195
00:08:24,030 --> 00:08:25,200
but if you were to identify

196
00:08:25,200 --> 00:08:27,390
all the different objects
that are important,

197
00:08:27,390 --> 00:08:30,000
and how do those objects
relate to one another,

198
00:08:30,000 --> 00:08:32,670
that's what we call the
data model object graph.

199
00:08:32,670 --> 00:08:36,090
And the process of creating
that is harmonization.

200
00:08:36,090 --> 00:08:38,850
So to express it in a different way,

201
00:08:38,850 --> 00:08:40,860
think of harmonization as an abstraction

202
00:08:40,860 --> 00:08:44,490
that allows you to decouple
the development of agents

203
00:08:44,490 --> 00:08:47,520
and applications, functions, and analytics

204
00:08:47,520 --> 00:08:50,790
from the source schemas
in your data state.

205
00:08:50,790 --> 00:08:53,820
It's a translation layer
that you build in Data 360,

206
00:08:53,820 --> 00:08:55,710
and it purely comprises metadata.

207
00:08:55,710 --> 00:08:58,760
And I'll show you an example
of what I mean by that.

208
00:08:58,760 --> 00:09:01,170
Once you've harnessed
and harmonized the data,

209
00:09:01,170 --> 00:09:03,120
the third step is to govern.

210
00:09:03,120 --> 00:09:07,080
And there is a rich,
malleable, auditable framework

211
00:09:07,080 --> 00:09:10,260
for creating policies
to manage permissions,

212
00:09:10,260 --> 00:09:12,900
ensure regulatory compliance,

213
00:09:12,900 --> 00:09:14,760
and different levels of granularity.

214
00:09:14,760 --> 00:09:17,670
At the level of the table, OLS,

215
00:09:17,670 --> 00:09:22,143
at the level of a record, FLS,
and at the level of a column.

216
00:09:23,280 --> 00:09:26,010
Now once the data has been
appropriately governed,

217
00:09:26,010 --> 00:09:28,290
not just for humans and automation,

218
00:09:28,290 --> 00:09:31,110
but also particularly for agents,

219
00:09:31,110 --> 00:09:32,670
it's time to activate the data.

220
00:09:32,670 --> 00:09:36,600
And I'm gonna combine columns
four and five into one.

221
00:09:36,600 --> 00:09:40,020
Now there are many, many
different activation services.

222
00:09:40,020 --> 00:09:42,360
And I'll give you three examples.

223
00:09:42,360 --> 00:09:45,390
The first one harkens
back to Data 360's origins

224
00:09:45,390 --> 00:09:47,310
as a customer data platform.

225
00:09:47,310 --> 00:09:50,370
Segmentation is something
that is a very commonly

226
00:09:50,370 --> 00:09:53,460
used workflow by marketers,

227
00:09:53,460 --> 00:09:55,560
where they segment those
different unified profiles

228
00:09:55,560 --> 00:09:59,180
and then conduct surgical
marketing campaigns.

229
00:09:59,180 --> 00:10:02,730
A different and newer one is
something called Document AI,

230
00:10:02,730 --> 00:10:05,640
where a document, unstructured content,

231
00:10:05,640 --> 00:10:07,280
is brought into Data 360.

232
00:10:07,280 --> 00:10:09,780
It's loaded, it's
chunked, it's vectorized,

233
00:10:09,780 --> 00:10:11,310
and it's analyzed.

234
00:10:11,310 --> 00:10:13,740
And then you can create
data actions that say,

235
00:10:13,740 --> 00:10:16,890
if I detect this text in this document,

236
00:10:16,890 --> 00:10:18,420
I want you to send it to an agent,

237
00:10:18,420 --> 00:10:20,310
because I think it's
pretty straightforward

238
00:10:20,310 --> 00:10:23,850
what needs to happen next in
maybe a contractual process.

239
00:10:23,850 --> 00:10:25,110
But if I don't detect that,

240
00:10:25,110 --> 00:10:27,513
then I want you to hand it off to a human.

241
00:10:28,770 --> 00:10:31,230
And then of course,
there's also predictive AI,

242
00:10:31,230 --> 00:10:34,350
which a lot of times gets
overshadowed by generative AI,

243
00:10:34,350 --> 00:10:36,570
but it's still equally important.

244
00:10:36,570 --> 00:10:38,640
For example, in a call center,

245
00:10:38,640 --> 00:10:40,800
it would be good to know
who is the appropriate team

246
00:10:40,800 --> 00:10:43,170
that I should route a support case to,

247
00:10:43,170 --> 00:10:45,930
based on the knowledge
base that I've created

248
00:10:45,930 --> 00:10:48,440
of support cases that have
been previously closed

249
00:10:48,440 --> 00:10:50,490
and were closed successfully,

250
00:10:50,490 --> 00:10:53,130
optimizing for some metric like CSAT.

251
00:10:53,130 --> 00:10:56,200
That's something that you can
create a predictive model for.

252
00:10:56,200 --> 00:10:58,500
There are many different applications.

253
00:10:58,500 --> 00:11:00,420
Those are just three examples.

254
00:11:00,420 --> 00:11:02,400
But the point is that
the first three steps

255
00:11:02,400 --> 00:11:04,710
form that trusted foundation,

256
00:11:04,710 --> 00:11:08,740
the bedrock that powers
Agent 360 and Customer 360.

257
00:11:08,740 --> 00:11:11,010
It's a model that you define once

258
00:11:11,010 --> 00:11:13,020
and that you can use
throughout your applications

259
00:11:13,020 --> 00:11:16,110
so that the distinct activation surfaces

260
00:11:16,110 --> 00:11:19,110
aren't interpreting your
data state in different ways

261
00:11:19,110 --> 00:11:20,310
when they don't have to.

262
00:11:24,180 --> 00:11:25,950
Now, Agent 4 is setting aside pricing

263
00:11:25,950 --> 00:11:27,180
and setting aside SKUs.

264
00:11:27,180 --> 00:11:30,000
Agent 4 is just built on Data 360.

265
00:11:30,000 --> 00:11:31,900
Architecturally, it is the foundation.

266
00:11:32,890 --> 00:11:35,220
But there are three important reasons

267
00:11:35,220 --> 00:11:38,330
why it's important to go through Data 360.

268
00:11:38,330 --> 00:11:40,860
The first thing is unstructured data.

269
00:11:40,860 --> 00:11:43,990
The unstructured data pipeline
resides entirely in Data 360,

270
00:11:43,990 --> 00:11:47,850
where documents get
loaded, they get chunked,

271
00:11:47,850 --> 00:11:49,320
they get vectorized,

272
00:11:49,320 --> 00:11:51,360
you can imbue them with semantic meeting,

273
00:11:51,360 --> 00:11:55,290
and then you can feed them into
a RAG pipeline for an agent.

274
00:11:55,290 --> 00:11:58,330
And we know that an agent's
quality, its effectiveness,

275
00:11:58,330 --> 00:11:59,910
is always going to be limited

276
00:11:59,910 --> 00:12:02,133
by the quality of data that it's fed.

277
00:12:03,060 --> 00:12:04,650
If the quality of data is low,

278
00:12:04,650 --> 00:12:07,530
we can't expect the agent to perform well.

279
00:12:07,530 --> 00:12:09,030
Setting aside unstructured data,

280
00:12:09,030 --> 00:12:11,190
the second pipeline is structured data,

281
00:12:11,190 --> 00:12:12,450
specifically NL to SQL.

282
00:12:12,450 --> 00:12:17,400
How can I ask an agent to
execute analytical queries,

283
00:12:17,400 --> 00:12:19,080
OLAP queries at scale,

284
00:12:19,080 --> 00:12:21,420
whether it's an interactive
agent with a human,

285
00:12:21,420 --> 00:12:24,210
or whether it's an agent
operating in the background?

286
00:12:24,210 --> 00:12:25,860
Going through Data 360 allows you

287
00:12:25,860 --> 00:12:27,290
to use its native query engine

288
00:12:27,290 --> 00:12:30,420
and execute those queries performantly,

289
00:12:30,420 --> 00:12:34,610
not by constructing SQL, but
by asking questions in English.

290
00:12:34,610 --> 00:12:36,060
The third thing is that

291
00:12:36,060 --> 00:12:37,890
when an agent interacts with a client,

292
00:12:37,890 --> 00:12:39,960
it's important for the
agent to realize and learn

293
00:12:39,960 --> 00:12:42,310
from previous engagements with that client

294
00:12:42,310 --> 00:12:45,183
rather than starting
fresh every single time.

295
00:12:46,170 --> 00:12:48,750
That's what memory for Agentforce does.

296
00:12:48,750 --> 00:12:51,590
It's a tightly governed
construct in Data 360

297
00:12:51,590 --> 00:12:54,993
that ensures continuity from
conversation to conversation.

298
00:12:57,910 --> 00:12:59,940
I'm actually gonna skip this one,

299
00:12:59,940 --> 00:13:01,920
'cause I think we covered it.

300
00:13:01,920 --> 00:13:03,360
So now we're getting into the details

301
00:13:03,360 --> 00:13:05,460
of the connectivity suite.

302
00:13:05,460 --> 00:13:08,373
And at a high level, there
are four different categories.

303
00:13:09,310 --> 00:13:11,010
The first thing that
we'll get out of the way

304
00:13:11,010 --> 00:13:13,290
is the unstructured data pipeline.

305
00:13:13,290 --> 00:13:15,180
I'm not gonna focus more on that,

306
00:13:15,180 --> 00:13:16,170
but that's what I alluded to

307
00:13:16,170 --> 00:13:18,513
with load, chunk, vectorize, index.

308
00:13:19,800 --> 00:13:23,040
Now for structured data,
there are three options.

309
00:13:23,040 --> 00:13:26,370
There's batch ingestion, which
is your standard ETL process,

310
00:13:26,370 --> 00:13:29,970
where data gets copied
into Data 360 periodically.

311
00:13:29,970 --> 00:13:32,410
Then there is the real-time data pipeline,

312
00:13:32,410 --> 00:13:37,410
where data can be pushed into
Data 360 in milliseconds.

313
00:13:37,910 --> 00:13:40,230
And then there is zero copy,

314
00:13:40,230 --> 00:13:44,460
which is accessing data at
runtime, as and when needed,

315
00:13:44,460 --> 00:13:47,220
and never persisting external data.

316
00:13:47,220 --> 00:13:48,690
Now, one thing I wanna clarify

317
00:13:48,690 --> 00:13:50,040
is that there is often confusion

318
00:13:50,040 --> 00:13:52,140
between real-time and zero copy,

319
00:13:52,140 --> 00:13:54,990
because zero copy is
described as real-time.

320
00:13:54,990 --> 00:13:56,790
The real-time pipeline in Data 360

321
00:13:56,790 --> 00:14:00,300
is underpinned by a very specific object.

322
00:14:00,300 --> 00:14:02,313
That's called a real-time data graph.

323
00:14:03,610 --> 00:14:05,730
A real-time data graph is effectively

324
00:14:05,730 --> 00:14:09,540
a materialized, denormalized view.

325
00:14:09,540 --> 00:14:12,390
The data gets materialized
inside of Data 360.

326
00:14:12,390 --> 00:14:14,490
Think of this as web engagement data

327
00:14:14,490 --> 00:14:16,680
that is brought into Data 360,

328
00:14:16,680 --> 00:14:18,270
and is used to personalize experience

329
00:14:18,270 --> 00:14:20,690
as a client is browsing a website.

330
00:14:20,690 --> 00:14:23,490
The data is pushed into Data 360.

331
00:14:23,490 --> 00:14:25,920
This is different from zero copy,

332
00:14:25,920 --> 00:14:27,180
where the data isn't pushed.

333
00:14:27,180 --> 00:14:31,290
It is requested precisely
when you launch a workflow

334
00:14:31,290 --> 00:14:32,883
that requires external data.

335
00:14:36,830 --> 00:14:39,710
So what is Data 360 zero copy exactly?

336
00:14:39,710 --> 00:14:42,250
Now, typically, let's say you have

337
00:14:42,250 --> 00:14:46,320
massive business-critical
datasets in a data warehouse.

338
00:14:46,320 --> 00:14:48,990
For zero copy, you would have
to duplicate those wholesale

339
00:14:48,990 --> 00:14:51,753
into the system that you want
to activate that data in.

340
00:14:52,770 --> 00:14:54,420
And any time you have two copies

341
00:14:54,420 --> 00:14:57,000
outside of some tightly
distributed system,

342
00:14:57,000 --> 00:14:59,670
one of those copies is
gonna be behind the other.

343
00:14:59,670 --> 00:15:00,957
That's just physics.

344
00:15:00,957 --> 00:15:02,940
And for some workflows, that's okay.

345
00:15:02,940 --> 00:15:03,960
But for many workflows,

346
00:15:03,960 --> 00:15:07,020
it's not okay to operate
on a stale snapshot.

347
00:15:07,020 --> 00:15:09,000
And that's assuming that the organization

348
00:15:09,000 --> 00:15:12,180
even allows you to duplicate
data in the first place.

349
00:15:12,180 --> 00:15:13,747
And many of our clients will outright say,

350
00:15:13,747 --> 00:15:17,647
"No, I am not willing to move
data out of my data warehouse.

351
00:15:17,647 --> 00:15:20,227
"It is managed by a
specific line of business,

352
00:15:20,227 --> 00:15:23,377
"and in order to activate
it, you must do so at rest.

353
00:15:23,377 --> 00:15:25,320
"I won't have two copies."

354
00:15:25,320 --> 00:15:27,240
So the thesis is very simple.

355
00:15:27,240 --> 00:15:29,640
Securely access the data at runtime.

356
00:15:29,640 --> 00:15:32,220
Your workflows always are powered,

357
00:15:32,220 --> 00:15:34,470
and your agents are
powered by the latest data,

358
00:15:34,470 --> 00:15:36,840
because there is only ever one copy,

359
00:15:36,840 --> 00:15:39,003
and that is the singular external copy.

360
00:15:40,110 --> 00:15:43,290
So fundamentally, this is
about maximizing the value

361
00:15:43,290 --> 00:15:44,850
of the investments that
you've already made

362
00:15:44,850 --> 00:15:46,200
in different data products.

363
00:15:47,490 --> 00:15:50,580
Now, Data 360 copy is
absolutely the keystone

364
00:15:50,580 --> 00:15:52,200
of the connectivity suite.

365
00:15:52,200 --> 00:15:54,810
But the biggest testament I can give you

366
00:15:54,810 --> 00:15:55,980
to how important it's been

367
00:15:55,980 --> 00:15:58,980
is that since 2024, its inception,

368
00:15:58,980 --> 00:16:01,890
it now powers over 50% of the traffic

369
00:16:01,890 --> 00:16:03,990
that comes into Data 360.

370
00:16:03,990 --> 00:16:06,660
The overwhelming majority of our clients

371
00:16:06,660 --> 00:16:09,450
strongly rely on zero copy to access data

372
00:16:09,450 --> 00:16:11,820
from their lake houses
and their warehouses.

373
00:16:11,820 --> 00:16:13,050
And someone asked a good question.

374
00:16:13,050 --> 00:16:14,670
Is that because of an outlier?

375
00:16:14,670 --> 00:16:16,290
Is it one tenant that went wild,

376
00:16:16,290 --> 00:16:18,480
or was it one query that was misfired?

377
00:16:18,480 --> 00:16:19,860
And the answer is no.

378
00:16:19,860 --> 00:16:21,690
The number of tenants that use zero copy

379
00:16:21,690 --> 00:16:24,330
has grown steadily quarter over quarter,

380
00:16:24,330 --> 00:16:26,730
and their footprint and
the workloads that they run

381
00:16:26,730 --> 00:16:30,010
have also increased in
size quarter over quarter.

382
00:16:30,010 --> 00:16:33,450
And so what we're gonna
focus on next in detail

383
00:16:33,450 --> 00:16:36,540
is the zero copy suite with AWS.

384
00:16:36,540 --> 00:16:38,610
And we'll talk about
the different patterns,

385
00:16:38,610 --> 00:16:40,470
the different connectors
that are available,

386
00:16:40,470 --> 00:16:42,150
and we'll show you a short demonstration.

387
00:16:42,150 --> 00:16:44,150
So with that, I'll hand it over to Bill.

388
00:16:47,070 --> 00:16:47,903
- Great.

389
00:16:49,560 --> 00:16:52,160
So we've heard a little
bit about partnership,

390
00:16:52,160 --> 00:16:54,450
and we've heard a little
bit about what it means

391
00:16:54,450 --> 00:16:57,510
to do Data 360 in terms of Salesforce.

392
00:16:57,510 --> 00:17:00,180
Hopefully, most of you
here are joint customers

393
00:17:00,180 --> 00:17:02,610
of AWS and Salesforce already.

394
00:17:02,610 --> 00:17:05,760
And this is really where
the magic starts to happen

395
00:17:05,760 --> 00:17:07,770
in terms of what we create.

396
00:17:07,770 --> 00:17:10,110
Because one of the things I've noticed

397
00:17:10,110 --> 00:17:13,180
ever since I started working
with Salesforce as an AWS SA

398
00:17:13,180 --> 00:17:15,840
is one of the primary
things we have in common

399
00:17:15,840 --> 00:17:19,200
is one of the leadership
principles of customer obsession.

400
00:17:19,200 --> 00:17:21,840
So when we listen to our
customers and they come to us

401
00:17:21,840 --> 00:17:23,520
and tell us that they have specific things

402
00:17:23,520 --> 00:17:25,440
they wanna do with their data,

403
00:17:25,440 --> 00:17:28,530
we work with them to try
to create those mechanisms.

404
00:17:28,530 --> 00:17:30,960
And I think that's
reflected on this slide,

405
00:17:30,960 --> 00:17:33,390
which isn't just a slide
of the current state,

406
00:17:33,390 --> 00:17:36,820
but also of the roadmap of what
we're building out together

407
00:17:36,820 --> 00:17:40,620
to make it easier for our
customers to have data freedom,

408
00:17:40,620 --> 00:17:43,800
to be able to put their
data where they need it.

409
00:17:43,800 --> 00:17:45,720
And as you've already heard, as Sid said,

410
00:17:45,720 --> 00:17:49,470
in this new agentic world,
your data has to be more fluid.

411
00:17:49,470 --> 00:17:51,210
It has to move to where you're running

412
00:17:51,210 --> 00:17:52,980
your agentic workloads.

413
00:17:52,980 --> 00:17:55,860
So let me talk about a customer example.

414
00:17:55,860 --> 00:17:57,570
So we'll walk you through
these different things

415
00:17:57,570 --> 00:18:00,150
on the slide in just a second,
but I was working with a

416
00:18:00,150 --> 00:18:02,610
FinTech customer earlier this year.

417
00:18:02,610 --> 00:18:04,770
Really great customer, loves Salesforce,

418
00:18:04,770 --> 00:18:07,050
has a bunch of different
Salesforce products,

419
00:18:07,050 --> 00:18:08,940
including Marketing Cloud, Data Cloud,

420
00:18:08,940 --> 00:18:13,200
using Agentforce, big fans,
love what they're doing.

421
00:18:13,200 --> 00:18:15,900
And so over time, their suite
of how they've integrated

422
00:18:15,900 --> 00:18:19,380
between their AWS estate
and Salesforce has evolved.

423
00:18:19,380 --> 00:18:22,590
Of course, they came to
us with RDMS databases.

424
00:18:22,590 --> 00:18:24,240
They had RDS in place,

425
00:18:24,240 --> 00:18:26,670
and they wanted to pull
that data into Salesforce.

426
00:18:26,670 --> 00:18:31,670
So RDGA now, we had built
what we call Query Foundation.

427
00:18:32,340 --> 00:18:33,870
And as you can see from the slide,

428
00:18:33,870 --> 00:18:36,330
it exposes several different AWS services,

429
00:18:36,330 --> 00:18:39,750
including Athena, RDS, Aurora, and more,

430
00:18:39,750 --> 00:18:41,280
as traditional data sources.

431
00:18:41,280 --> 00:18:44,190
Now, when I say a traditional data source,

432
00:18:44,190 --> 00:18:45,960
picture this if you're a programmer

433
00:18:45,960 --> 00:18:48,540
or if you've seen
applications working before.

434
00:18:48,540 --> 00:18:50,250
It's simply a call out to the database.

435
00:18:50,250 --> 00:18:52,710
It does a query and it
returns values to you.

436
00:18:52,710 --> 00:18:54,450
We'll dig into a little
bit of what that means

437
00:18:54,450 --> 00:18:55,500
on the next slide.

438
00:18:55,500 --> 00:18:57,180
But for the purpose of this customer,

439
00:18:57,180 --> 00:18:58,590
it did what they needed.

440
00:18:58,590 --> 00:19:00,300
They were able to query their data,

441
00:19:00,300 --> 00:19:02,610
bring it into Salesforce,
combine the data,

442
00:19:02,610 --> 00:19:04,320
and everything was good.

443
00:19:04,320 --> 00:19:06,870
Well, now fast forward a couple years.

444
00:19:06,870 --> 00:19:10,890
Now we're in 2025, and most
companies have data lakes.

445
00:19:10,890 --> 00:19:14,520
And data lakes take us into a
different set of AWS services.

446
00:19:14,520 --> 00:19:17,120
We're no longer talking
about our traditional RDMSs.

447
00:19:19,110 --> 00:19:23,880
We're talking about the flat
file systems like S3 and Glue.

448
00:19:23,880 --> 00:19:26,100
So now they have these estates of data,

449
00:19:26,100 --> 00:19:29,460
and their question to us was,
how do we now take this data

450
00:19:29,460 --> 00:19:32,460
and make it available to Salesforce?

451
00:19:32,460 --> 00:19:35,040
So we wanna use Customer 360.

452
00:19:35,040 --> 00:19:36,570
We're doing marketing campaigns.

453
00:19:36,570 --> 00:19:39,420
We're pulling in data from all
sorts of different sources.

454
00:19:39,420 --> 00:19:41,520
We would like to bring
those into Salesforce

455
00:19:41,520 --> 00:19:44,250
where we have our
customer source of record,

456
00:19:44,250 --> 00:19:48,510
use Customer 360 to identify
all of those unique customers

457
00:19:48,510 --> 00:19:50,100
who we're actually gonna reach out to

458
00:19:50,100 --> 00:19:52,680
so we're not wasting a
bunch of our marketing time.

459
00:19:52,680 --> 00:19:54,920
So the process that they
went through with us

460
00:19:54,920 --> 00:19:57,630
was starting with File Federation.

461
00:19:57,630 --> 00:19:58,890
And as you can see, File Federation

462
00:19:58,890 --> 00:20:00,870
is actually in beta right now,

463
00:20:00,870 --> 00:20:02,970
and it's gonna be GA in February.

464
00:20:02,970 --> 00:20:04,230
So they're already on board.

465
00:20:04,230 --> 00:20:06,090
They're starting to build this out now.

466
00:20:06,090 --> 00:20:07,320
And they're taking their data lake

467
00:20:07,320 --> 00:20:09,300
and exposing it over to Salesforce.

468
00:20:09,300 --> 00:20:12,180
The plan is to make this available,

469
00:20:12,180 --> 00:20:14,580
to let them create customer records.

470
00:20:14,580 --> 00:20:16,890
But now the interesting part.

471
00:20:16,890 --> 00:20:20,130
It's really not enough just to
have that data in Salesforce.

472
00:20:20,130 --> 00:20:22,200
So think about the sort of trade-offs

473
00:20:22,200 --> 00:20:25,380
between AWS and Salesforce
in terms of the roles

474
00:20:25,380 --> 00:20:27,813
who are consuming Salesforce and AWS.

475
00:20:28,920 --> 00:20:30,090
Most of the people you talk to

476
00:20:30,090 --> 00:20:32,340
who are actually logging
into an AWS console,

477
00:20:32,340 --> 00:20:33,360
they're techs, right?

478
00:20:33,360 --> 00:20:35,040
They're geeks like me.

479
00:20:35,040 --> 00:20:36,780
People who log into the console,

480
00:20:36,780 --> 00:20:38,910
they're willing to go
through these experiences.

481
00:20:38,910 --> 00:20:41,490
I generally don't expect the
business users on my team

482
00:20:41,490 --> 00:20:45,030
to come into that AWS console,
at least not frequently.

483
00:20:45,030 --> 00:20:48,120
On the other hand, while
I am a Salesforce user,

484
00:20:48,120 --> 00:20:50,580
I don't expect to do a
business person's job

485
00:20:50,580 --> 00:20:52,650
in terms of running queries
and marketing campaigns

486
00:20:52,650 --> 00:20:53,483
and everything else.

487
00:20:53,483 --> 00:20:55,830
I wanna unlock those capabilities for them

488
00:20:55,830 --> 00:20:57,570
so they don't make me do it.

489
00:20:57,570 --> 00:21:00,360
So in a nutshell, for this customer,

490
00:21:00,360 --> 00:21:03,240
they didn't just wanna bring
that data back into Salesforce.

491
00:21:03,240 --> 00:21:06,240
They wanted to round trip
it back to AWS as well.

492
00:21:06,240 --> 00:21:09,300
So this is the third column
we have here, data sharing.

493
00:21:09,300 --> 00:21:12,090
In a lot of ways, when
we get into the details

494
00:21:12,090 --> 00:21:14,970
about what file federation
and data sharing mean,

495
00:21:14,970 --> 00:21:16,710
they're actually kind of the same thing

496
00:21:16,710 --> 00:21:18,210
in opposite direction.

497
00:21:18,210 --> 00:21:21,210
We're unlocking bi-directional copy.

498
00:21:21,210 --> 00:21:23,070
For this customer, they wanted to create

499
00:21:23,070 --> 00:21:26,780
these customer 360 records,
copy them back to AWS

500
00:21:26,780 --> 00:21:29,730
so they can again enrich their data lake,

501
00:21:29,730 --> 00:21:31,400
take all of that data
that they've collected

502
00:21:31,400 --> 00:21:35,160
and make their AWS estate
of data more effective.

503
00:21:35,160 --> 00:21:38,490
So this bi-directional copy
really was gonna enable

504
00:21:38,490 --> 00:21:39,870
everything that they wanna do.

505
00:21:39,870 --> 00:21:42,450
And you can see a few
different services on here.

506
00:21:42,450 --> 00:21:44,400
So this is already GA now.

507
00:21:44,400 --> 00:21:47,820
You see EMR, you see Redshift,
you see Athena on here.

508
00:21:47,820 --> 00:21:51,090
All of these provide AWS capabilities

509
00:21:51,090 --> 00:21:52,620
for the other end of this.

510
00:21:52,620 --> 00:21:55,200
Basically, if you think of
this on the Salesforce side

511
00:21:55,200 --> 00:21:58,830
as Glue feeding data back
into these AWS services,

512
00:21:58,830 --> 00:22:00,750
you'd be pretty much correct.

513
00:22:00,750 --> 00:22:02,760
So Glue kind of in both directions,

514
00:22:02,760 --> 00:22:06,090
allowing us to access data
catalogs with Iceberg.

515
00:22:06,090 --> 00:22:08,010
And I'll get a little bit more
into the technical details

516
00:22:08,010 --> 00:22:09,960
in a couple slides.

517
00:22:09,960 --> 00:22:12,090
But using Iceberg data catalogs

518
00:22:12,090 --> 00:22:13,640
to allow us to expose the data

519
00:22:13,640 --> 00:22:18,090
and without having the same
type of copy and query,

520
00:22:18,090 --> 00:22:19,890
which I'll get to in a second,

521
00:22:19,890 --> 00:22:23,700
we're gonna be able access to Iceberg data

522
00:22:23,700 --> 00:22:25,290
and we're gonna enable us to have

523
00:22:25,290 --> 00:22:27,210
an interesting time sequence

524
00:22:27,210 --> 00:22:30,330
where we can get to that data frequently

525
00:22:30,330 --> 00:22:31,950
and less and more easily.

526
00:22:31,950 --> 00:22:34,440
And as we'll see on the next slide here,

527
00:22:34,440 --> 00:22:36,990
with a number of different advantages.

528
00:22:36,990 --> 00:22:38,730
So Query Federation, by the way,

529
00:22:38,730 --> 00:22:41,190
I'm not bad mouthing Query
Federation, it's great.

530
00:22:41,190 --> 00:22:43,700
If you need access to
your traditional databases

531
00:22:43,700 --> 00:22:46,020
and you wanna bring that
data into Salesforce,

532
00:22:46,020 --> 00:22:48,390
that remains absolutely valuable.

533
00:22:48,390 --> 00:22:50,400
Not going away, we're gonna support that

534
00:22:50,400 --> 00:22:53,340
as long as you guys keep
buying databases from us.

535
00:22:53,340 --> 00:22:54,810
On the other side though,

536
00:22:54,810 --> 00:22:57,630
there are some real
advantages of File Federation.

537
00:22:57,630 --> 00:22:59,000
And the very first line up here

538
00:22:59,000 --> 00:23:01,473
describes one of the main advantages.

539
00:23:02,640 --> 00:23:05,730
I'm an old programmer, I
programmed for a long time.

540
00:23:05,730 --> 00:23:08,370
JDBC drivers were something we did in Java

541
00:23:08,370 --> 00:23:10,320
back in the day, right?

542
00:23:10,320 --> 00:23:12,450
It's been around 20, 30 years,

543
00:23:12,450 --> 00:23:15,150
however long it's been since
we actually invented Java.

544
00:23:15,150 --> 00:23:17,130
I guess I should know since James Gosselin

545
00:23:17,130 --> 00:23:18,870
actually works for AWS now.

546
00:23:18,870 --> 00:23:23,870
But JDBC drivers simply provide
you a pipe to go get data.

547
00:23:23,970 --> 00:23:26,670
You say, hey, I'm gonna run the SQL query,

548
00:23:26,670 --> 00:23:30,660
SQL engine, you execute this
for me, return some data.

549
00:23:30,660 --> 00:23:32,130
It's always worked the same way.

550
00:23:32,130 --> 00:23:33,870
It works the same way here.

551
00:23:33,870 --> 00:23:37,260
We're outsourcing the
query to the engine itself

552
00:23:37,260 --> 00:23:39,020
and saying, you just
give me back the data.

553
00:23:39,020 --> 00:23:42,180
Every time I want that data,
I hand the same query over,

554
00:23:42,180 --> 00:23:43,780
it hands me back a pile of data.

555
00:23:44,880 --> 00:23:47,730
The Iceberg Catalog capabilities

556
00:23:47,730 --> 00:23:50,433
that come with File Federation
are entirely different.

557
00:23:51,270 --> 00:23:55,410
Because Iceberg is a catalog,
it allows us to, over time,

558
00:23:55,410 --> 00:23:58,943
create what we would
call change data flows,

559
00:24:00,510 --> 00:24:05,280
where we can actually say, hey,
I'm gonna pull this data in,

560
00:24:05,280 --> 00:24:07,710
but I'm gonna keep a sort
of a cached copy of it

561
00:24:07,710 --> 00:24:09,990
because I have access to the catalog.

562
00:24:09,990 --> 00:24:11,670
Now, instead of making real-time queries

563
00:24:11,670 --> 00:24:13,590
and every time saying,
hey, give me all the data,

564
00:24:13,590 --> 00:24:15,450
give me all the data,
give me all the data,

565
00:24:15,450 --> 00:24:17,160
I can create these change data sets

566
00:24:17,160 --> 00:24:20,100
and say, what has actually changed?

567
00:24:20,100 --> 00:24:23,130
And now, because this is
running on the Salesforce side

568
00:24:23,130 --> 00:24:26,400
and the queries are running in Data 360,

569
00:24:26,400 --> 00:24:28,290
I don't have to be going
back to that query engine

570
00:24:28,290 --> 00:24:30,330
every time and pulling
back all of that data.

571
00:24:30,330 --> 00:24:32,100
I actually know what has changed

572
00:24:32,100 --> 00:24:34,620
since the last time I called
it because of Iceberg.

573
00:24:34,620 --> 00:24:36,920
And this is a neat part
of the capability, right?

574
00:24:36,920 --> 00:24:40,980
It allows us to take the change data feed,

575
00:24:40,980 --> 00:24:43,950
understand exactly what's coming
in, what's come in before,

576
00:24:43,950 --> 00:24:46,800
and it makes it faster and more efficient.

577
00:24:46,800 --> 00:24:49,200
And because it's Iceberg on the AWS side,

578
00:24:49,200 --> 00:24:51,630
it's also a lot more
cost efficient, right?

579
00:24:51,630 --> 00:24:54,600
So you can keep your files
in S3, you can use Glue,

580
00:24:54,600 --> 00:24:57,450
and this unlocks a lot of
interesting cost advantages.

581
00:24:57,450 --> 00:25:00,750
And in addition, on the cost side,

582
00:25:00,750 --> 00:25:02,610
if you're doing query federation,

583
00:25:02,610 --> 00:25:06,990
as you can see on line number five there,

584
00:25:06,990 --> 00:25:10,290
you can actually see you're
paying twice for this data.

585
00:25:10,290 --> 00:25:12,420
You're paying to query
it, you're paying us

586
00:25:12,420 --> 00:25:15,690
to query it in Athena,
if your data's in Athena,

587
00:25:15,690 --> 00:25:18,960
and then you're paying for
the Data 360 side of that.

588
00:25:18,960 --> 00:25:21,030
That's different with
file federation as well.

589
00:25:21,030 --> 00:25:23,670
You're really just paying for
the Data 360 side of this,

590
00:25:23,670 --> 00:25:26,130
and you're not worrying about
having to pay the AWS side

591
00:25:26,130 --> 00:25:28,380
other than what you're already
paying us for your data lake.

592
00:25:28,380 --> 00:25:30,510
So it's actually a really nice advantage.

593
00:25:30,510 --> 00:25:31,830
There's another nice advantage

594
00:25:31,830 --> 00:25:35,220
that I don't wanna overlook,
and that's parallelization.

595
00:25:35,220 --> 00:25:37,650
Parallelization. (laughs)

596
00:25:37,650 --> 00:25:41,220
When we are talking about how
we get the data back over,

597
00:25:41,220 --> 00:25:43,320
this is an operation that allows us

598
00:25:43,320 --> 00:25:46,500
from the Data 360 side to actually run up

599
00:25:46,500 --> 00:25:48,990
multiple versions of the query.

600
00:25:48,990 --> 00:25:52,020
Remember how I said JDBC is
like a single pipe, right?

601
00:25:52,020 --> 00:25:54,540
I can only have a single
query however long that takes,

602
00:25:54,540 --> 00:25:56,340
however long it takes
it to stream back up.

603
00:25:56,340 --> 00:25:59,980
I can actually do
parallelization on Data 360

604
00:25:59,980 --> 00:26:02,850
with file federation specifically

605
00:26:02,850 --> 00:26:05,550
because we have data file level push down,

606
00:26:05,550 --> 00:26:07,470
we have partition level pruning,

607
00:26:07,470 --> 00:26:09,150
and data file level pruning.

608
00:26:09,150 --> 00:26:11,280
And all of those unlock parallelization

609
00:26:11,280 --> 00:26:14,160
in the native query engine
that they built from scratch

610
00:26:14,160 --> 00:26:15,990
inside of Data 360.

611
00:26:15,990 --> 00:26:18,810
So instead of relying on
our old school query engines

612
00:26:18,810 --> 00:26:20,040
that live on the other side,

613
00:26:20,040 --> 00:26:21,990
they built an entirely new query engine

614
00:26:21,990 --> 00:26:24,360
that lives in Data 360 and unlocks a lot

615
00:26:24,360 --> 00:26:26,780
of great capabilities that
you'll wanna take advantage

616
00:26:26,780 --> 00:26:27,800
if you're building.

617
00:26:27,800 --> 00:26:31,470
So if you're in any way
thinking about a data lake,

618
00:26:31,470 --> 00:26:33,210
if you're thinking about
building a data lake,

619
00:26:33,210 --> 00:26:36,260
remember that these capabilities
that we're creating today

620
00:26:36,260 --> 00:26:38,920
are gonna unlock these business use cases

621
00:26:38,920 --> 00:26:41,580
that go back, going back to my customer,

622
00:26:41,580 --> 00:26:45,240
enable them to do specific
business functions

623
00:26:45,240 --> 00:26:47,580
honestly they wouldn't have
been able to do otherwise.

624
00:26:47,580 --> 00:26:49,110
So it's pretty cool.

625
00:26:49,110 --> 00:26:50,940
It adds a lot of new capabilities.

626
00:26:50,940 --> 00:26:52,200
And there's other things on here

627
00:26:52,200 --> 00:26:53,790
that are a little bit different.

628
00:26:53,790 --> 00:26:56,370
You can do more files, bigger file sizes

629
00:26:56,370 --> 00:26:58,350
and more files with file federation.

630
00:26:58,350 --> 00:27:01,140
A lot of those details are
important for specific cases.

631
00:27:01,140 --> 00:27:03,480
But really, I want you
to focus on the fact

632
00:27:03,480 --> 00:27:06,360
that you're using different
types of services, right?

633
00:27:06,360 --> 00:27:08,520
Traditional data sources
versus data lakes.

634
00:27:08,520 --> 00:27:10,560
And that the iceberg allows us

635
00:27:10,560 --> 00:27:13,800
to keep a changed data set over time

636
00:27:13,800 --> 00:27:15,570
so that we're not having to reach back

637
00:27:15,570 --> 00:27:18,150
and pull back all of the
data every time we query.

638
00:27:18,150 --> 00:27:21,050
Pretty cool functionality and
I'm pretty excited about it.

639
00:27:21,960 --> 00:27:24,150
Let me bring up a slide
that kind of hopefully

640
00:27:24,150 --> 00:27:25,290
brings a lot of this together.

641
00:27:25,290 --> 00:27:27,030
I know I'm throwing a lot
of sort of different angles

642
00:27:27,030 --> 00:27:29,430
on this, but remember how I said

643
00:27:29,430 --> 00:27:32,070
the data is flowing in
and it's flowing out.

644
00:27:32,070 --> 00:27:34,650
This particular slide is
designed to sort of show you

645
00:27:34,650 --> 00:27:36,880
how these different pieces fit in.

646
00:27:36,880 --> 00:27:38,910
In your AWS customer account,

647
00:27:38,910 --> 00:27:40,770
again, you might have your databases,

648
00:27:40,770 --> 00:27:44,700
you've got your data
lakes, got S3, S3 tables,

649
00:27:44,700 --> 00:27:47,430
all of those different
data estate resources

650
00:27:47,430 --> 00:27:48,630
that are available to you.

651
00:27:48,630 --> 00:27:50,550
Well, Query Federation and File Federation

652
00:27:50,550 --> 00:27:54,600
are sitting there as pipes to
bring your data into Data 360.

653
00:27:54,600 --> 00:27:56,560
So you can see there,
we've got JDBC on there

654
00:27:56,560 --> 00:28:00,600
and then we have table scans,
which again, implies Iceberg.

655
00:28:00,600 --> 00:28:02,640
And you can see on the Data 360 side,

656
00:28:02,640 --> 00:28:05,400
if you look a couple
things down from Data 360,

657
00:28:05,400 --> 00:28:09,300
Iceberg tables, so Data
360 is also operating

658
00:28:09,300 --> 00:28:11,250
on Iceberg tables.

659
00:28:11,250 --> 00:28:13,860
In terms of what we're
actually working from,

660
00:28:13,860 --> 00:28:15,840
my customer use case, in their case,

661
00:28:15,840 --> 00:28:19,290
they were trying to unlock
some business solutions

662
00:28:19,290 --> 00:28:22,890
around marketing, but this
is important for AI agents.

663
00:28:22,890 --> 00:28:24,880
You could take the same
scenario with a customer

664
00:28:24,880 --> 00:28:28,140
and talk about how they wanna
run agents on both sides.

665
00:28:28,140 --> 00:28:30,930
They wanna run agent
force and execute agents

666
00:28:30,930 --> 00:28:33,360
against their customer data in Salesforce.

667
00:28:33,360 --> 00:28:36,540
Maybe they wanna run agent
core over on the AWS side

668
00:28:36,540 --> 00:28:38,730
and run that against their AWS data.

669
00:28:38,730 --> 00:28:40,720
Unlocking this data flow bidirectionally

670
00:28:40,720 --> 00:28:44,520
allows more agentic AI
flows to come to life.

671
00:28:44,520 --> 00:28:48,570
And of course, analytics and
the traditional ad platforms,

672
00:28:48,570 --> 00:28:49,860
AI/ML platforms,

673
00:28:49,860 --> 00:28:52,410
all of those are unlocked
by this data flow.

674
00:28:52,410 --> 00:28:54,420
Finally, at the bottom of
this, I wanna call out,

675
00:28:54,420 --> 00:28:56,100
remember, this is bidirectional.

676
00:28:56,100 --> 00:28:59,760
You can see that we actually
show a Glue data catalog,

677
00:28:59,760 --> 00:29:02,130
exposing this back into AWS.

678
00:29:02,130 --> 00:29:05,490
And again, I said that file federation

679
00:29:05,490 --> 00:29:07,410
and the data access going back,

680
00:29:07,410 --> 00:29:09,780
it's almost the same
thing just in reverse.

681
00:29:09,780 --> 00:29:12,870
Both sides are using Iceberg,
both sides are using Glue,

682
00:29:12,870 --> 00:29:14,880
and in fact, both sides are also using

683
00:29:14,880 --> 00:29:16,480
something called Lake Formation.

684
00:29:17,580 --> 00:29:20,670
Lake Formation allows us to
do fine-grained permissioning

685
00:29:20,670 --> 00:29:22,740
on data sources in AWS.

686
00:29:22,740 --> 00:29:24,450
Some of you may already
be familiar with it.

687
00:29:24,450 --> 00:29:26,880
If you're doing data lakes,
you might already be using this

688
00:29:26,880 --> 00:29:29,730
to apply permissions to your database.

689
00:29:29,730 --> 00:29:31,140
So as you can see,

690
00:29:31,140 --> 00:29:33,390
it can apply to a number
of different sources.

691
00:29:33,390 --> 00:29:34,920
We often see it come up, of course,

692
00:29:34,920 --> 00:29:37,860
with our data lake function,
with our data lake functions,

693
00:29:37,860 --> 00:29:39,690
and I think that's kind
of the key word there.

694
00:29:39,690 --> 00:29:41,370
It is a lake formation, right?

695
00:29:41,370 --> 00:29:43,530
But you can also use it with
a number of different sources

696
00:29:43,530 --> 00:29:45,480
as you're pulling them
into your data lake.

697
00:29:45,480 --> 00:29:47,790
Now that fine-grained access control

698
00:29:47,790 --> 00:29:49,180
is particularly important

699
00:29:49,180 --> 00:29:51,880
when we're talking about file federation.

700
00:29:51,880 --> 00:29:54,947
If you've ever done any sort
of remote work with AWS,

701
00:29:54,947 --> 00:29:57,090
one of the ways that
you can provide access

702
00:29:57,090 --> 00:29:59,760
to something remotely is to
take long-lived credentials

703
00:29:59,760 --> 00:30:02,070
and copy them over there.

704
00:30:02,070 --> 00:30:05,250
It's not really considered
a great practice to do that.

705
00:30:05,250 --> 00:30:07,860
I know you can find lots of
resources out there saying,

706
00:30:07,860 --> 00:30:09,840
hey, just get your key and your secret

707
00:30:09,840 --> 00:30:12,900
and copy it over here
and store it somewhere.

708
00:30:12,900 --> 00:30:15,400
It's kind of sad because there
was plenty of documentation

709
00:30:15,400 --> 00:30:17,610
saying to do that for years.

710
00:30:17,610 --> 00:30:20,700
But if you're doing anything today,

711
00:30:20,700 --> 00:30:22,620
if you can find a way to take advantage

712
00:30:22,620 --> 00:30:25,500
of short-lived credentials, please do.

713
00:30:25,500 --> 00:30:27,090
And this means IAM roles,

714
00:30:27,090 --> 00:30:30,030
and in this case, it means
using lake formation.

715
00:30:30,030 --> 00:30:33,390
Lake formation allows us to
vend short-term credentials

716
00:30:33,390 --> 00:30:35,910
from Data 360, so we don't have to keep

717
00:30:35,910 --> 00:30:39,330
those long-term credentials
on the Data 360 side

718
00:30:39,330 --> 00:30:41,490
specifically for file federation.

719
00:30:41,490 --> 00:30:44,040
And in fact, it's using
SIGV4 in this case.

720
00:30:44,040 --> 00:30:46,800
So if you wanna understand
how this actually works,

721
00:30:46,800 --> 00:30:48,120
you can kind of dig into it.

722
00:30:48,120 --> 00:30:51,810
We're taking SIGV4, we're
copying that over into Data 360,

723
00:30:51,810 --> 00:30:56,220
and that gives it API access
over to AWS through Glue.

724
00:30:56,220 --> 00:30:58,740
So this is actually an
important piece of the solution.

725
00:30:58,740 --> 00:31:00,930
And if you remember
nothing else out of that,

726
00:31:00,930 --> 00:31:03,630
that short-term vending credentials,

727
00:31:03,630 --> 00:31:05,700
that's really what unlocks better security

728
00:31:05,700 --> 00:31:07,623
for this file federation flow.

729
00:31:09,260 --> 00:31:11,250
I'm gonna end right before we go back

730
00:31:11,250 --> 00:31:12,960
and show a little bit of a demo of this.

731
00:31:12,960 --> 00:31:14,940
Talking a little bit about Glue,

732
00:31:14,940 --> 00:31:17,760
hopefully you've kind of
gotten a high-level visual.

733
00:31:17,760 --> 00:31:22,760
Glue allows us to do
Apache Iceberg, right?

734
00:31:23,790 --> 00:31:26,670
Apache Iceberg, if you
haven't worked with it before,

735
00:31:26,670 --> 00:31:29,640
allows you to take simple objects in S3

736
00:31:29,640 --> 00:31:31,053
and turn 'em into tables.

737
00:31:31,920 --> 00:31:33,360
It sounds a little crazy.

738
00:31:33,360 --> 00:31:34,317
How do you just take a bunch of files

739
00:31:34,317 --> 00:31:35,760
and turn 'em into tables?

740
00:31:35,760 --> 00:31:38,280
Well, it actually can
extract out a catalog

741
00:31:38,280 --> 00:31:40,830
that describes the data and also,

742
00:31:40,830 --> 00:31:44,250
going back to the changed data
follow we were talking about,

743
00:31:44,250 --> 00:31:47,250
captures what that data
state is over time.

744
00:31:47,250 --> 00:31:49,650
This is really where
Glue is pretty magical.

745
00:31:49,650 --> 00:31:51,810
And Glue does a little bit more than this.

746
00:31:51,810 --> 00:31:53,610
There's a couple things
I'd really wanna call out.

747
00:31:53,610 --> 00:31:55,350
You don't have to remember
all of these things,

748
00:31:55,350 --> 00:31:57,330
but it's serverless.

749
00:31:57,330 --> 00:31:59,550
Increasingly with AWS,
if you can find a way

750
00:31:59,550 --> 00:32:01,400
to take advantage of serverless function

751
00:32:01,400 --> 00:32:04,740
and not have to manage
compute on your own behalf,

752
00:32:04,740 --> 00:32:05,940
please do.

753
00:32:05,940 --> 00:32:07,680
This is the way a lot of things are going.

754
00:32:07,680 --> 00:32:09,060
If you're looking at Agent Core,

755
00:32:09,060 --> 00:32:10,440
it looks very similar, right?

756
00:32:10,440 --> 00:32:11,910
Manage services that are serverless

757
00:32:11,910 --> 00:32:13,770
and you don't have to manage the overhead.

758
00:32:13,770 --> 00:32:15,330
It's got great durability.

759
00:32:15,330 --> 00:32:17,760
Because this is backed by S3,

760
00:32:17,760 --> 00:32:20,190
all of the same types of functionality

761
00:32:20,190 --> 00:32:22,280
in terms of durability,
availability, scalability

762
00:32:22,280 --> 00:32:25,340
that you're relying on in
the underlying S3 instances

763
00:32:25,340 --> 00:32:28,200
also start to emerge in Glue as well.

764
00:32:28,200 --> 00:32:30,870
It integrates with all
sorts of different catalogs

765
00:32:30,870 --> 00:32:32,560
and of course, it provides through Athena

766
00:32:32,560 --> 00:32:35,180
additional querying in terms
of getting to your data.

767
00:32:35,180 --> 00:32:38,010
With that, I think we've
effectively covered

768
00:32:38,010 --> 00:32:40,770
most of the stuff here
around the AWS side,

769
00:32:40,770 --> 00:32:42,440
but I do wanna hand it back to Sid

770
00:32:42,440 --> 00:32:44,640
and we're gonna walk you
through what this looks like.

771
00:32:44,640 --> 00:32:45,840
Hopefully the internet holds up

772
00:32:45,840 --> 00:32:46,890
and we'll show it to you live.

773
00:32:46,890 --> 00:32:48,990
If not, we actually have
a bit of a recorded demo.

774
00:32:48,990 --> 00:32:51,300
Hopefully we won't need
to fall back on that.

775
00:32:51,300 --> 00:32:53,010
Thanks, Sid.
- Thanks, Bill.

776
00:32:53,010 --> 00:32:55,440
Okay, so there is an actual booth

777
00:32:55,440 --> 00:32:58,440
where there is a
full-fledged end-to-end demo

778
00:32:58,440 --> 00:33:00,840
and that's not what we're gonna show here.

779
00:33:00,840 --> 00:33:02,720
We'll just touch on a couple of components

780
00:33:02,720 --> 00:33:04,440
of what Bill described

781
00:33:04,440 --> 00:33:08,180
so that we can put some
pictures and actual components

782
00:33:08,180 --> 00:33:10,950
to the different things
that we talked about.

783
00:33:10,950 --> 00:33:14,010
So, this is Data 360's setup

784
00:33:14,010 --> 00:33:16,290
and it's where you
configure the connections

785
00:33:16,290 --> 00:33:18,540
to the different systems in AWS.

786
00:33:18,540 --> 00:33:21,660
And let's take a look at a couple of them

787
00:33:21,660 --> 00:33:23,820
because there are many
different AWS services

788
00:33:23,820 --> 00:33:25,700
that we can connect to.

789
00:33:25,700 --> 00:33:30,540
So, as Bill mentioned, we span
query engines such as Athena.

790
00:33:30,540 --> 00:33:33,690
They're your traditional
relational databases

791
00:33:33,690 --> 00:33:38,690
such as Aurora MySQL and the
corresponding RDS flavors.

792
00:33:38,700 --> 00:33:40,800
There's also Amazon Redshift.

793
00:33:40,800 --> 00:33:43,053
This is a query federation connection.

794
00:33:44,310 --> 00:33:46,620
And then there's AWS Glue.

795
00:33:46,620 --> 00:33:49,890
And so, I wanna briefly
clarify again one more thing

796
00:33:49,890 --> 00:33:52,530
with query federation just to emphasize.

797
00:33:52,530 --> 00:33:55,480
It's a single-threaded connection
to an external warehouse.

798
00:33:56,340 --> 00:33:59,040
And even though Data 360
will try to push down

799
00:33:59,040 --> 00:34:01,680
as many operators as possible,

800
00:34:01,680 --> 00:34:04,680
we're ultimately limited
to that single thread.

801
00:34:04,680 --> 00:34:07,710
And that's something that is
not true with file federation

802
00:34:07,710 --> 00:34:09,240
and is very important when it comes

803
00:34:09,240 --> 00:34:11,580
to massive volumes of data,

804
00:34:11,580 --> 00:34:15,603
which is typically what clients
use Data 360 to execute.

805
00:34:17,360 --> 00:34:18,720
So, let's take a look

806
00:34:18,720 --> 00:34:22,020
at the file federation connector for Glue,

807
00:34:22,020 --> 00:34:24,453
which is currently
offered as a beta feature.

808
00:34:25,620 --> 00:34:28,650
Now, as Bill mentioned,
there are two services

809
00:34:28,650 --> 00:34:31,320
when it comes to an
iceberg data lake house.

810
00:34:31,320 --> 00:34:34,410
There is the metadata catalog,
which is in this case Glue,

811
00:34:34,410 --> 00:34:36,450
and the underlying object storage bucket,

812
00:34:36,450 --> 00:34:38,013
which is in this case S3.

813
00:34:39,780 --> 00:34:43,440
Now here, you'll see that you
have to provide an access key

814
00:34:43,440 --> 00:34:48,360
and a secret access key, which
correspond to the IAM user

815
00:34:48,360 --> 00:34:50,400
that has been given the
appropriate permissions

816
00:34:50,400 --> 00:34:53,100
to communicate only with the catalog.

817
00:34:53,100 --> 00:34:55,500
Nothing long-lived related to storage

818
00:34:55,500 --> 00:34:58,260
needs to be given to Data 360,

819
00:34:58,260 --> 00:35:00,570
which is a security best practice.

820
00:35:00,570 --> 00:35:04,080
And that's because Glue will
vend temporary credentials,

821
00:35:04,080 --> 00:35:06,360
as Bill mentioned, at runtime.

822
00:35:06,360 --> 00:35:07,710
When the workflow terminates,

823
00:35:07,710 --> 00:35:09,480
the external data is forgotten,

824
00:35:09,480 --> 00:35:13,200
and so too are the
temporary S3 credentials.

825
00:35:13,200 --> 00:35:15,570
So, I have a couple of
different connections

826
00:35:15,570 --> 00:35:19,650
already configured to
Redshift, Query Federation,

827
00:35:19,650 --> 00:35:24,210
S3, Batch Ingestion, and Glue,
which is File Federation.

828
00:35:24,210 --> 00:35:27,780
Let's enter Data 360
the application proper.

829
00:35:27,780 --> 00:35:28,983
We'll exit Setup.

830
00:35:31,040 --> 00:35:33,360
So here are a couple
different data streams.

831
00:35:33,360 --> 00:35:35,910
Now, a data stream is
nothing more than a link

832
00:35:35,910 --> 00:35:40,710
between Data 360 and a
specific external table.

833
00:35:40,710 --> 00:35:44,340
It captures metadata,
particularly what are the columns

834
00:35:44,340 --> 00:35:47,340
that you want to project into Data 360.

835
00:35:47,340 --> 00:35:49,170
So, let's take a look at what happens

836
00:35:49,170 --> 00:35:51,993
when I try to create one for AWS Glue.

837
00:35:53,740 --> 00:35:55,830
I'll select the connection,

838
00:35:55,830 --> 00:35:59,400
and what happens here is we
query the metadata catalog

839
00:35:59,400 --> 00:36:02,343
to understand the objects
that are exposed to Data 360.

840
00:36:03,210 --> 00:36:04,980
The database picklist corresponds

841
00:36:04,980 --> 00:36:07,410
to the different namespaces
that you've configured

842
00:36:07,410 --> 00:36:10,200
in your Iceberg Glue catalog.

843
00:36:10,200 --> 00:36:13,200
Now, in this case, the
Schemas menu is empty,

844
00:36:13,200 --> 00:36:16,110
but if each one of these
namespaces, in turn,

845
00:36:16,110 --> 00:36:18,210
had a namespace, they would
be displayed over there

846
00:36:18,210 --> 00:36:19,960
because the specification for Iceberg

847
00:36:19,960 --> 00:36:23,610
allows for arbitrarily deep namespaces.

848
00:36:23,610 --> 00:36:26,790
These are the different
objects that are available,

849
00:36:26,790 --> 00:36:29,313
so let's see one of those in action.

850
00:36:31,820 --> 00:36:34,620
Now, there are a variety
of different applications,

851
00:36:34,620 --> 00:36:37,620
but it's not easy to demonstrate zero copy

852
00:36:37,620 --> 00:36:39,630
in a way that is visually illustrative,

853
00:36:39,630 --> 00:36:42,150
so I'm gonna take the simplest of them,

854
00:36:42,150 --> 00:36:44,010
which is Query Editor,

855
00:36:44,010 --> 00:36:46,620
and then we'll take a look at a CRM object

856
00:36:46,620 --> 00:36:49,233
that brings data in real time from AWS.

857
00:36:51,720 --> 00:36:52,830
So, in Query Editor,

858
00:36:52,830 --> 00:36:55,503
and this is just firing
a simple SQL query,

859
00:36:56,430 --> 00:36:59,613
I'm gonna select the Glue object,

860
00:37:00,510 --> 00:37:01,560
and we'll just run a query.

861
00:37:01,560 --> 00:37:02,560
We'll bump up the...

862
00:37:07,200 --> 00:37:09,540
And what happens here is we
fetch the data at runtime.

863
00:37:09,540 --> 00:37:11,430
Now, this looks really simple, right?

864
00:37:11,430 --> 00:37:12,375
It wasn't something crazy,

865
00:37:12,375 --> 00:37:15,120
but the point is that
we query the catalog,

866
00:37:15,120 --> 00:37:18,120
we get the metadata, we
parallelize execution,

867
00:37:18,120 --> 00:37:20,790
and when I close the tab,
the data is forgotten.

868
00:37:20,790 --> 00:37:22,800
So, let's take a look at something

869
00:37:22,800 --> 00:37:24,663
that is a little bit more practical,

870
00:37:25,660 --> 00:37:29,670
and we'll enter an
application, a CRM application,

871
00:37:29,670 --> 00:37:32,140
so one of the Customer 360 apps.

872
00:37:32,140 --> 00:37:34,830
Click on the contact record.

873
00:37:34,830 --> 00:37:37,980
Now, let's imagine that this is a resort,

874
00:37:37,980 --> 00:37:40,380
and they're bringing
in data from Redshift,

875
00:37:40,380 --> 00:37:42,570
and they're bringing in data from Glue,

876
00:37:42,570 --> 00:37:44,670
and they want that contact record

877
00:37:44,670 --> 00:37:48,360
to display information
relevant to the customer

878
00:37:48,360 --> 00:37:50,283
that resides in those two systems,

879
00:37:51,200 --> 00:37:54,630
and these are displayed as related lists.

880
00:37:54,630 --> 00:37:58,950
So, I'll click on Sofia Rodriguez,
and let's go to related,

881
00:37:58,950 --> 00:38:01,710
and this is where the data
doesn't live in Data 360,

882
00:38:01,710 --> 00:38:03,873
it's gonna be fetched once I go here.

883
00:38:04,860 --> 00:38:08,400
So, if I refresh the
tab, refresh here too,

884
00:38:08,400 --> 00:38:12,300
this is the data that is coming
from Redshift and from Glue,

885
00:38:12,300 --> 00:38:13,750
so it's not stored over here.

886
00:38:15,210 --> 00:38:17,400
Now, how exactly did this happen?

887
00:38:17,400 --> 00:38:18,820
Let's go back to Data Cloud,

888
00:38:18,820 --> 00:38:23,370
and I will show you an
example of what I mean

889
00:38:23,370 --> 00:38:25,720
by that blueprint that we talked about

890
00:38:25,720 --> 00:38:27,783
with all the nouns and verbs.

891
00:38:29,200 --> 00:38:31,113
I'm gonna switch to graph view,

892
00:38:33,360 --> 00:38:35,580
and so what I have here
are the different objects

893
00:38:35,580 --> 00:38:37,280
that are important to my business.

894
00:38:38,160 --> 00:38:40,830
The first thing is an individual.

895
00:38:40,830 --> 00:38:43,320
That has a relationship with reservations,

896
00:38:43,320 --> 00:38:44,920
which are stored in Redshift,

897
00:38:44,920 --> 00:38:47,280
and many other different objects,

898
00:38:47,280 --> 00:38:48,660
but the important thing to understand

899
00:38:48,660 --> 00:38:50,160
is that not every one of these

900
00:38:50,160 --> 00:38:52,680
is an actual table in Data 360.

901
00:38:52,680 --> 00:38:55,473
It's just a pointer to something in AWS.

902
00:38:56,430 --> 00:38:57,810
Metadata is something that pops up

903
00:38:57,810 --> 00:39:00,330
in almost every Salesforce presentation,

904
00:39:00,330 --> 00:39:02,070
but this is what we mean by that.

905
00:39:02,070 --> 00:39:03,400
We're just capturing information

906
00:39:03,400 --> 00:39:07,383
about how you have structured
your data state externally.

907
00:39:09,280 --> 00:39:12,180
Now, the last thing that I wanna show

908
00:39:12,180 --> 00:39:13,953
is identity resolution.

909
00:39:15,750 --> 00:39:20,750
Now, this is one specific
example of resolving information

910
00:39:21,220 --> 00:39:24,273
about the same customer that
resides in different datasets.

911
00:39:25,400 --> 00:39:28,170
Now, some of this information
came from Redshift,

912
00:39:28,170 --> 00:39:30,720
the guest data, and some
of it came from CRM,

913
00:39:30,720 --> 00:39:32,043
the existing contacts,

914
00:39:33,480 --> 00:39:36,930
and you won't actually see
zero copy in action here,

915
00:39:36,930 --> 00:39:40,020
but notice on the right
side the consolidation rate.

916
00:39:40,020 --> 00:39:42,860
That means that you had
multiple records in AWS

917
00:39:42,860 --> 00:39:45,840
and multiple records in CRM,

918
00:39:45,840 --> 00:39:48,960
but they weren't all
describing distinct clients.

919
00:39:48,960 --> 00:39:51,870
They were describing, in
many cases, the same person,

920
00:39:51,870 --> 00:39:54,480
and that's reflected in
the consolidation rate,

921
00:39:54,480 --> 00:39:57,090
saying that it turns out
that we only had 50 customers

922
00:39:57,090 --> 00:39:58,560
and not 100,

923
00:39:58,560 --> 00:40:02,160
and that's how you're able
to get that unified profile

924
00:40:02,160 --> 00:40:05,733
in CRM, which is the
contact that I showed you.

925
00:40:07,050 --> 00:40:09,600
Now, like I said, there's a
full-fledged demo at a booth,

926
00:40:09,600 --> 00:40:13,080
but before I go, there's one
more thing that I wanna show

927
00:40:13,080 --> 00:40:16,980
to clarify what Bill said
about changed data feeds,

928
00:40:16,980 --> 00:40:18,980
because that's something very important.

929
00:40:19,840 --> 00:40:22,773
Now, let's take a look at
something called a data action.

930
00:40:24,840 --> 00:40:26,703
I'm gonna create one manually.

931
00:40:29,040 --> 00:40:31,380
Let's see, I don't have
a data action target.

932
00:40:31,380 --> 00:40:33,400
Okay, let's see if I created one.

933
00:40:38,520 --> 00:40:41,970
All right, while this loads,
I'll explain it verbally,

934
00:40:41,970 --> 00:40:44,590
but the point is that a
data action target relies on

935
00:40:45,450 --> 00:40:48,360
it's a trigger that says
when a record gets created,

936
00:40:48,360 --> 00:40:50,160
I want you to go do something.

937
00:40:50,160 --> 00:40:52,770
When it gets deleted, I
want you to go do something.

938
00:40:52,770 --> 00:40:54,330
Now, in Query Federation,

939
00:40:54,330 --> 00:40:58,380
if you think about it conceptually,
there's no way to detect

940
00:40:58,380 --> 00:41:01,140
that something changed
in an external table,

941
00:41:01,140 --> 00:41:04,920
because all I ever see is
the most recent version,

942
00:41:04,920 --> 00:41:07,260
and to determine if something changed,

943
00:41:07,260 --> 00:41:09,150
I need to have a historical record

944
00:41:09,150 --> 00:41:11,620
of how the table evolved over time,

945
00:41:11,620 --> 00:41:13,710
but with Query Federation,

946
00:41:13,710 --> 00:41:16,230
you can do things like data actions,

947
00:41:16,230 --> 00:41:18,810
because the Iceberg
Catalog glue in this case

948
00:41:18,810 --> 00:41:21,900
gives us different snapshots
for the same object.

949
00:41:21,900 --> 00:41:25,770
So you say, if something
happened to my insurance table,

950
00:41:25,770 --> 00:41:29,160
I want you to go take an action,
and with File Federation,

951
00:41:29,160 --> 00:41:32,013
you don't have to copy
that table into Data 360.

952
00:41:32,940 --> 00:41:36,090
The second benefit is performance.

953
00:41:36,090 --> 00:41:38,130
For many workflows like segmentation

954
00:41:38,130 --> 00:41:41,640
and identity resolution,
with Query Federation,

955
00:41:41,640 --> 00:41:45,690
you're operating on the entire
table every single time,

956
00:41:45,690 --> 00:41:46,890
but with File Federation,

957
00:41:46,890 --> 00:41:48,960
you're only operating on the increment,

958
00:41:48,960 --> 00:41:50,400
and that's because we can calculate

959
00:41:50,400 --> 00:41:54,363
what that increment is by
looking at the Metadata Catalog.

960
00:41:55,260 --> 00:41:57,840
That results in both higher performance,

961
00:41:57,840 --> 00:41:59,883
and it results in lower costs.

962
00:42:01,860 --> 00:42:04,050
So these are the
different building blocks.

963
00:42:04,050 --> 00:42:07,050
I think that's pretty much
what we wanted to show.

964
00:42:07,050 --> 00:42:10,200
And Q&A, or customer stories, yes.

965
00:42:10,200 --> 00:42:11,610
- Awesome.

966
00:42:11,610 --> 00:42:12,600
Great, well, thanks, Sid.

967
00:42:12,600 --> 00:42:15,030
I think I would wanna stay
at Coral Cloud Resorts,

968
00:42:15,030 --> 00:42:17,280
given that it sounds like they know how to

969
00:42:17,280 --> 00:42:18,780
understand their customers,

970
00:42:18,780 --> 00:42:21,480
have a full picture of their customers,

971
00:42:21,480 --> 00:42:24,580
and be able to deliver
personalized experiences.

972
00:42:24,580 --> 00:42:27,030
But of course, that was
a fictional scenario,

973
00:42:27,030 --> 00:42:29,280
so we did actually want
to share with you guys

974
00:42:29,280 --> 00:42:31,590
the results that customers
are already seeing

975
00:42:31,590 --> 00:42:33,570
from taking advantage of this solution.

976
00:42:33,570 --> 00:42:38,160
So 1-800-ACCOUNT is a great
example of a customer.

977
00:42:38,160 --> 00:42:40,110
They are an accounting services firm

978
00:42:40,110 --> 00:42:41,910
who helps small businesses

979
00:42:41,910 --> 00:42:43,860
with all of their accounting needs.

980
00:42:43,860 --> 00:42:46,710
And I recently had the pleasure
of talking to their CTO,

981
00:42:46,710 --> 00:42:48,570
who was telling me that previously,

982
00:42:48,570 --> 00:42:50,880
their data was siloed
across multiple systems.

983
00:42:50,880 --> 00:42:52,590
They had Salesforce, they had Data Lake,

984
00:42:52,590 --> 00:42:54,960
they had custom tax software systems.

985
00:42:54,960 --> 00:42:57,810
And during the tax season,
that was really tough for them,

986
00:42:57,810 --> 00:43:00,640
because their client advisors
were spending a lot of time

987
00:43:00,640 --> 00:43:02,700
managing customer inquiries

988
00:43:02,700 --> 00:43:05,760
with data scattered all
around their systems.

989
00:43:05,760 --> 00:43:07,860
And so they decided
that they really needed

990
00:43:07,860 --> 00:43:08,940
to scale their workforce

991
00:43:08,940 --> 00:43:11,130
to be able to support their customers,

992
00:43:11,130 --> 00:43:12,690
and they leveraged Zero Copy

993
00:43:12,690 --> 00:43:16,080
to unify all of their different
systems that they had,

994
00:43:16,080 --> 00:43:17,730
and allowed their client advisors

995
00:43:17,730 --> 00:43:19,110
to actually be able to focus

996
00:43:19,110 --> 00:43:21,750
on high-value conversations
with their customers.

997
00:43:21,750 --> 00:43:24,540
They deployed AI agents
that were able to answer

998
00:43:24,540 --> 00:43:26,860
70% of the administrative questions

999
00:43:26,860 --> 00:43:31,680
that customers were
asking on a regular basis,

1000
00:43:31,680 --> 00:43:33,220
and really allowed their client advisors

1001
00:43:33,220 --> 00:43:36,810
to be more scalable for their workforce.

1002
00:43:36,810 --> 00:43:39,780
Additionally, another great
story was Buyer's Edge.

1003
00:43:39,780 --> 00:43:42,120
They are a procurement company

1004
00:43:42,120 --> 00:43:46,080
that helps in the food industry,
and they actually were able

1005
00:43:46,080 --> 00:43:49,410
to unify 20-plus different
systems together,

1006
00:43:49,410 --> 00:43:51,900
to again, be able to
create that unified view

1007
00:43:51,900 --> 00:43:54,240
of their customers and
be able to deliver them

1008
00:43:54,240 --> 00:43:56,550
with the right personalized offers.

1009
00:43:56,550 --> 00:43:59,040
So with that, I hope
you're inspired by the demo

1010
00:43:59,040 --> 00:44:00,750
and all these different customer stories.

1011
00:44:00,750 --> 00:44:03,870
Like Sid said, we have a
great, more in-depth demo

1012
00:44:03,870 --> 00:44:05,460
available at our Salesforce booth

1013
00:44:05,460 --> 00:44:07,410
and experts that would be really happy

1014
00:44:07,410 --> 00:44:08,730
to talk to you guys about this.

1015
00:44:08,730 --> 00:44:10,890
Additionally, you can scan this QR code

1016
00:44:10,890 --> 00:44:12,630
to learn more about our partnership.

1017
00:44:12,630 --> 00:44:14,190
And as always, feel free to contact

1018
00:44:14,190 --> 00:44:16,710
your Salesforce account team.

1019
00:44:16,710 --> 00:44:17,640
Awesome.

1020
00:44:17,640 --> 00:44:18,960
Thank you so much for your time.

1021
00:44:18,960 --> 00:44:20,660
We really appreciate it and, yeah.

