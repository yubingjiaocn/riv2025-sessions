# AWS 技术会议总结：Anthropic 在 2024 年构建 AI Agent 的经验

## 会议概述

本次会议由 Anthropic 应用 AI 团队成员 Cal 主讲，分享了 Anthropic 在 2024 年构建 AI Agent 方面的核心经验和洞察。Cal 在两年前加入 Anthropic，负责帮助客户在 Claude 模型上构建产品和功能，并参与了 Claude Code 产品的开发。

会议重点介绍了 Anthropic 从早期的简单问答聊天机器人，到如今强大的 AI Agent 系统的演进历程。2024 年是 AI Agent 发展的关键一年，特别是随着 Claude 3.5 Sonnet 和最新的 Claude Opus 4.5 模型的发布，AI 编码能力取得了突破性进展。Claude 在 SWE-Bench 基准测试中达到了 80% 的准确率，相比去年的 49% 有了显著提升。演讲者强调，构建成功的 AI Agent 不仅需要强大的模型，更需要精心设计的"harness"（工具框架）、上下文工程和提示工程。

Anthropic 将 AI Agent 定义为：给 LLM 提供一组工具，赋予其开放式问题，让模型在循环中运行并调用工具，直到完成任务。这种架构相比传统的工作流（Workflow）具有更强的灵活性和错误恢复能力。展望未来，Anthropic 预计 Claude 将从目前的"协作者"角色演进为能够解决人类尚未解决问题的"先驱者"。

## 详细时间线与关键要点

### 开场与背景介绍 (0:00-3:30)
- **0:00** - 会议开始，说明原定关于 Anthropic 和 Lovable 的演讲因后勤问题临时调整
- **0:30** - Cal 自我介绍：两年前加入 Anthropic，帮助创建应用 AI 团队
- **1:00** - 应用 AI 团队的使命：帮助客户和合作伙伴在 Claude 上构建优秀产品和功能

### Anthropic 早期发展 (3:30-6:00)
- **3:30** - 加入时 Anthropic 最好的模型是 Claude 2.1，当时并非业界最佳
- **4:00** - Claude 2.1 的两大优势：在 AWS Bedrock 上可用；拥有 200,000 tokens 的上下文窗口
- **4:30** - 入职 6 周后发布 Claude 3 模型家族（Opus、Sonnet、Haiku）
- **5:00** - Claude 3 Opus 被认为是当时的前沿模型或世界最佳模型
- **5:30** - 2024 年初主要工作：帮助客户构建问答聊天机器人和 RAG 系统

### Claude 3.5 Sonnet 的突破 (6:00-9:00)
- **6:00** - 开始研发 Claude 3.5 Sonnet，目标是超越 Opus 但更快更便宜
- **6:30** - 发现该模型在编写 HTML/JavaScript/CSS 方面表现出色
- **7:00** - 诞生了 Artifacts 功能：自动渲染 Claude 生成的 HTML 文件
- **7:30** - 早期 Artifacts 的局限：每次修改需要重写整个文件，无法进行增量编辑
- **8:00** - 内部开发了 Claude CLI 工具，工程师们开始使用并给予好评

### Claude CLI 的个人体验 (9:00-11:00)
- **9:00** - Cal 在某个周五晚上尝试 Claude CLI
- **9:30** - 使用 Claude CLI 在一个晚上构建了一个笔记应用，原本需要几天时间
- **10:00** - 次日向同事展示成果，决定加入 Claude Code 团队
- **10:30** - 成为 Cloud Code 的 AI 工程师，负责系统提示、工具设计和上下文工程
- **11:00** - 强调在 2024 年同时参与了 Cloud Code 产品开发和客户 Agent 项目

### Anthropic 公司介绍 (11:00-15:00)
- **11:00** - Anthropic 是专注于企业的 AI 研究和产品组织
- **11:30** - 应用 AI 团队服务从种子轮到 B 轮的初创公司
- **12:00** - 也与大型科技公司、重要行业和政府公共部门合作
- **12:30** - 2024 年因 Agent 和产品市场契合度，收入实现爆炸式增长

### AI 安全研究 (15:00-18:00)
- **15:00** - Anthropic 创始人相信 LLM 会持续改进并在十年内对社会产生变革性影响
- **15:30** - 安全工作分为两类：对齐（Alignment）和可解释性（Interpretability）
- **16:00** - 对齐研究：训练模型反映重要价值观，识别不对齐行为（如宪法 AI、潜伏代理）
- **16:30** - 可解释性研究：深入模型内部，理解模型行为的原因
- **17:00** - 目标是理解模型工作原理，实现对模型不同部分的控制

### 企业市场优势 (18:00-21:00)
- **18:00** - Anthropic 有意专注于企业市场
- **18:30** - Claude 的低幻觉率：在多项评估中表现最佳
- **19:00** - Claude 的特点：当不知道答案时会坦诚说"我不知道"
- **19:30** - 推出 MCP（模型上下文协议）打破数据孤岛
- **20:00** - 与 AWS 等公司的云合作伙伴关系
- **20:30** - 目前在企业 LLM 市场份额中处于领先地位

### 模型性能的重要性 (21:00-23:00)
- **21:00** - 构建强大 Agent 的最佳方法：使用最新最好的模型
- **21:30** - Cloud Code 的最大提升来自模型升级：Sonnet 3.5 v2 → 3.7 → 4
- **22:00** - 介绍 Claude Opus 4.5：8 天前发布的前沿模型
- **22:30** - 模型持续改进的趋势，每次都超出预期

### Claude Opus 4.5 性能 (23:00-28:00)
- **23:00** - Sonnet 模型因成本和延迟的良好平衡而受客户喜爱
- **23:30** - 长期以来 Sonnet 实际上是 Anthropic 的前沿模型
- **24:00** - 现在 Opus 重新领先
- **24:30** - 编码能力是 Anthropic 的核心优势
- **25:00** - SWE-Bench 基准测试：使用真实 GitHub 问题评估模型
- **25:30** - Claude Opus 4.5 在 SWE-Bench 上达到 80% 准确率
- **26:00** - 去年的 Claude Sonnet 3.5 v2 仅为 49%，一年内取得巨大进步
- **26:30** - Opus 4.5 不仅准确率更高，使用的 tokens 也更少
- **27:00** - 未来团队需要考虑任务级别的总成本，而非仅看每百万 tokens 价格
- **27:30** - 更昂贵的模型可能因效率更高而总成本更低

### 提示注入防护 (28:00-29:30)
- **28:00** - Opus 4.5 在提示注入攻击防护方面取得进展
- **28:30** - 提示注入示例：用户试图让 Agent 忽略原始指令
- **29:00** - 问题尚未完全解决，但正在改进
- **29:30** - 减少了构建额外防护措施的需求

### 未来发展方向 (29:30-33:00)
- **29:30** - 模型将持续改进，预计会有更好的 Sonnet 和 Opus 版本
- **30:00** - 长时间运行的 Agent：目前可运行数小时，目标是数天甚至数周
- **30:30** - 提升浏览器和计算机使用能力
- **31:00** - 许多业务逻辑和数据锁定在 GUI 和 Web 应用中
- **31:30** - 需要让模型像人类一样使用鼠标、键盘和屏幕截图
- **32:00** - 目前速度较慢但会持续改进
- **32:30** - 垂直领域扩展：网络安全和金融服务

### 特定应用场景 (33:00-35:00)
- **33:00** - 网络安全：防止恶意使用，提供白帽黑客能力
- **33:30** - 金融服务：量化分析、代码表达、专业判断
- **34:00** - Claude 将出现在电子表格等金融专业人士使用的工具中
- **34:30** - 提升特定任务能力：演示文稿制作
- **35:00** - 目标：明年能用 Claude 生成精美的演示文稿

### 从模型到 Harness (35:00-38:00)
- **35:00** - 优秀模型需要良好的 harness（工具框架）才能发挥作用
- **35:30** - Cloud Code 可以将数周的工程工作压缩到 2-3 天
- **36:00** - 展示视频：让 Claude 克隆 cloud.ai 网站
- **36:30** - Claude 1：无法开始，不知道如何使用工具
- **37:00** - Sonnet 3.5：写了 11,000 行代码但没有输出
- **37:30** - Sonnet 3.6：实现了登录页面，55,000 行代码

### 模型演进对比 (38:00-40:00)
- **38:00** - Sonnet 3.7：运行 6 小时，有些功能但存在 bug
- **38:30** - Sonnet 4：外观不像 Anthropic 品牌，但像 AI 聊天机器人
- **39:00** - Sonnet 4.5：完整实现聊天和 Artifacts 功能
- **39:30** - 11,000 行代码，5 小时不间断运行
- **40:00** - 强调需要在模型之上构建额外功能才能实现这些成果

### Claude 开发者平台 (40:00-42:30)
- **40:00** - 早期只有模型和简单的 API 端点
- **40:30** - 复杂性主要在单个 prompt 参数中
- **41:00** - 过去一年大力发展 Claude 开发者平台
- **41:30** - 新增构建模块：内存、网络搜索、研究、编排功能
- **42:00** - 支持多 Agent 设置
- **42:30** - 向更高层次发展，包括 Cloud Agent SDK

### AI 应用架构演进 (42:30-45:00)
- **42:30** - 2024 年：RAG 问答聊天机器人之年
- **43:00** - 2025 年：Claude 作为协作者，特别是在 Agent 循环中
- **43:30** - 人机协作，可交互式工作
- **44:00** - 未来：Claude 作为先驱者，解决人类未解决的问题
- **44:30** - 将在生物学、数学、物理等领域取得进展
- **45:00** - CEO Dario 的博客文章《Machines of Love and Grace》探讨了这一主题

### Agent 的定义 (45:00-49:00)
- **45:00** - 什么是 Agent？Anthropic 制定了技术定义
- **45:30** - 早期项目架构简单：文本输入，文本输出
- **46:00** - 主要是分类、摘要等任务
- **46:30** - 模型改进后，人们开始构建更复杂的系统
- **47:00** - 工作流（Workflow）：多个 LLM 调用链接在一起
- **47:30** - 工作流的优点：可单独调优每个部分，易于理解
- **48:00** - 工作流的问题：难以处理所有边缘情况
- **48:30** - 某客户有 50 个不同的提示链接在一起，难以维护

### 工作流的局限性 (49:00-51:00)
- **49:00** - 工作流难以实现强大的错误纠正
- **49:30** - 中间步骤出错时，最终输出质量会下降
- **50:00** - 去年底开始探索不同的架构
- **50:30** - Agent 架构：给 LLM 一组工具和开放式问题，让其在循环中运行
- **51:00** - Agent 定义：模型调用工具并在完成时通知

### Agent 的优势 (51:00-53:00)
- **51:00** - Agent 解决了工作流的两大问题
- **51:30** - 无需编码每个边缘情况，信任模型自行解决
- **52:00** - Agent 对错误更具鲁棒性
- **52:30** - Claude 遇到错误或意外结果时会尝试其他方法
- **53:00** - Agent 提供更强大、更丰富的应用能力

### 从提示工程到上下文工程 (53:00-56:00)
- **53:00** - 构建 Agent 需要良好的上下文
- **53:30** - 去年重点是提示工程：如何编写单个提示
- **54:00** - 一年前模型可控性较差，细节很重要（XML 标签、示例数量等）
- **54:30** - 现在模型更智能，转向 Agent 架构
- **55:00** - 提示工程的首要建议：将提示交给不了解业务的朋友阅读
- **55:30** - 如果朋友感到困惑，模型也会困惑
- **56:00** - 提示工程时代的技巧：所有内容放在用户消息中，不使用系统提示

### 上下文工程的复杂性 (56:00-58:00)
- **56:00** - 上下文工程比提示工程更复杂
- **56:30** - Agent 涉及多次 API 调用
- **57:00** - 需要考虑：系统提示、用户消息、工具定义、工具响应格式
- **57:30** - 内存管理：上下文窗口满时如何压缩
- **58:00** - 更丰富、更有趣的问题空间

### 上下文窗口限制 (58:00-60:00)
- **58:00** - 每个 LLM 都有最大 token 数限制
- **58:30** - 超过限制时 API 会返回错误
- **59:00** - 不是不会处理更多 tokens，而是超过某个点模型性能会下降
- **59:30** - Anthropic 设置了 200,000 tokens 的限制以确保模型表现强劲
- **60:00** - 这是 API 级别的硬性限制

### 系统提示的平衡 (60:00-63:00)
- **60:00** - 上下文工程的经验教训
- **60:30** - 系统提示的指令范围：从过于具体到过于模糊
- **61:00** - 案例：客户将 32 页的 SOP 文档直接放入提示
- **61:30** - 结果：太多 if-else 语句，模型不堪重负
- **62:00** - 另一极端：过于模糊，模型不理解要做什么
- **62:30** - "最佳朋友测试"：指令是否清晰易懂
- **63:00** - 目标：找到"金发姑娘区域"（Goldilocks zone）

### 最小但充分的指令 (63:00-66:00)
- **63:00** - 寻找最小但充分的指令让模型完成任务
- **63:30** - 迭代式方法：不要期望第一次就完美
- **64:00** - 模型会以意想不到的方式行事
- **64:30** - 首次编写提示时的建议
- **65:00** - 测试前、迭代前、展示给用户前
- **65:30** - （字幕在此处截断）

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


注： 本总结基于提供的字幕文本，字幕在约 65-66 分钟处截断，可能还有后续内容未包含在此总结中。