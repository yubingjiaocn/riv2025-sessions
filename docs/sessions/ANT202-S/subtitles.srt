1
00:00:00,719 --> 00:00:02,778
So, we're here to talk about uh

2
00:00:03,318 --> 00:00:05,440
deploying AI models in the edge in, you know, the

3
00:00:05,440 --> 00:00:07,059
world's largest cloud conference.

4
00:00:07,440 --> 00:00:08,220
So that's gonna be fun.

5
00:00:08,560 --> 00:00:10,679
I'm gonna start off with a, with a

6
00:00:10,679 --> 00:00:12,478
question that I want some of you all to guess.

7
00:00:13,198 --> 00:00:15,198
Um, you know, every time you take a

8
00:00:15,198 --> 00:00:17,449
picture on a smartphone, um, does

9
00:00:17,449 --> 00:00:20,079
anybody want to guess how many AI models runs

10
00:00:20,079 --> 00:00:21,100
while you take that picture?

11
00:00:25,199 --> 00:00:26,260
Someone said 10.

12
00:00:26,600 --> 00:00:27,818
OK. Anybody else?

13
00:00:31,260 --> 00:00:32,240
You said 4?

14
00:00:33,020 --> 00:00:33,798
40. OK.

15
00:00:34,399 --> 00:00:35,098
Anybody else?

16
00:00:38,990 --> 00:00:41,029
OK, good. There's only one wrong answer, which is 0.

17
00:00:41,109 --> 00:00:42,209
Nobody gave that answer.

18
00:00:42,548 --> 00:00:44,548
But it's in, it's in the 20 to 30 range. So

19
00:00:44,548 --> 00:00:46,668
there's a significant number of models that

20
00:00:46,668 --> 00:00:48,750
run in that, uh, and so both of you are not too

21
00:00:48,750 --> 00:00:50,750
far off. Uh, there are a significant number

22
00:00:50,750 --> 00:00:53,270
of models that runs on a device

23
00:00:53,548 --> 00:00:55,408
every time you take a picture. Um,

24
00:00:55,868 --> 00:00:56,630
and, you know,

25
00:00:56,939 --> 00:00:58,950
an average smartphone has about 1000

26
00:00:58,950 --> 00:01:01,259
or so, uh, models that are on there.

27
00:01:01,848 --> 00:01:03,990
Uh, and we have over 100,000 applications

28
00:01:03,990 --> 00:01:06,109
in, in a smartphone app app store

29
00:01:06,689 --> 00:01:07,349
that uses AI.

30
00:01:08,338 --> 00:01:09,579
But it's not just phones,

31
00:01:09,900 --> 00:01:12,079
uh, you also have it all over the place

32
00:01:12,079 --> 00:01:13,159
with cars. So,

33
00:01:13,500 --> 00:01:15,629
pretty much all of your ADIS systems are running,

34
00:01:16,260 --> 00:01:17,739
um, on device AI,

35
00:01:18,290 --> 00:01:19,359
um, you know,

36
00:01:20,698 --> 00:01:22,058
smart, smart parking assist,

37
00:01:22,500 --> 00:01:24,698
uh, any kind of like, you know, blindspot

38
00:01:24,698 --> 00:01:26,819
assistance, those kinds of things all use sensors

39
00:01:26,819 --> 00:01:28,000
and AI on the device.

40
00:01:28,459 --> 00:01:30,609
Uh, you also have drones, you have robots, uh,

41
00:01:30,739 --> 00:01:32,750
and you have PCs as well, a lot of, uh,

42
00:01:33,058 --> 00:01:35,088
your PC applications end up using AI

43
00:01:35,088 --> 00:01:35,838
on the device, so.

44
00:01:36,338 --> 00:01:39,000
I mean, the, the, the obvious question is, uh,

45
00:01:39,239 --> 00:01:41,349
why do it on the device, when you have access to

46
00:01:41,349 --> 00:01:42,150
a cloud with

47
00:01:42,430 --> 00:01:43,829
virtually unlimited compute,

48
00:01:44,150 --> 00:01:45,579
why do it on the device, right? And,

49
00:01:45,948 --> 00:01:48,109
um, the primary reason I've, I've

50
00:01:48,109 --> 00:01:50,019
seen people do it, um,

51
00:01:50,349 --> 00:01:52,510
is for the overall snapiness of the

52
00:01:52,510 --> 00:01:53,329
experience. So,

53
00:01:53,588 --> 00:01:55,790
certain things just can't be done uh

54
00:01:55,790 --> 00:01:57,730
by sending information to the cloud and back,

55
00:01:57,989 --> 00:02:00,058
and it's much snappier, much quicker, much

56
00:02:00,058 --> 00:02:00,808
more efficient.

57
00:02:01,150 --> 00:02:02,888
To do it on the device. And

58
00:02:03,189 --> 00:02:05,528
over the years as the device packed more and more

59
00:02:05,528 --> 00:02:08,069
uh compute, you can do more and more sophisticated

60
00:02:08,069 --> 00:02:09,569
things on those devices.

61
00:02:10,028 --> 00:02:12,169
So, latency is a big reason why people do it.

62
00:02:12,349 --> 00:02:13,990
Um, there's another one which is

63
00:02:14,308 --> 00:02:16,080
uh cost. Um,

64
00:02:16,550 --> 00:02:18,868
I was just recently talking to a gaming company

65
00:02:18,868 --> 00:02:21,008
who said they had like a nine-figure bill

66
00:02:21,229 --> 00:02:23,349
for doing AI on the devices. Well, it turns out

67
00:02:23,349 --> 00:02:25,528
you have gaming consoles that have virtually,

68
00:02:26,189 --> 00:02:27,710
you know, you know,

69
00:02:28,189 --> 00:02:30,270
Probably tens of flops that are available there for you

70
00:02:30,270 --> 00:02:32,368
to use. Um, and you can do pretty

71
00:02:32,368 --> 00:02:34,508
sophisticated things on it. So you can offload the

72
00:02:34,508 --> 00:02:36,508
cost to, uh, the

73
00:02:36,508 --> 00:02:38,588
consumers' devices. So cost is also a big thing.

74
00:02:38,629 --> 00:02:40,868
And, and, uh, there's also privacy,

75
00:02:40,909 --> 00:02:43,270
which is a, which is a big factor where you have

76
00:02:43,270 --> 00:02:45,469
everything that stays in the device,

77
00:02:45,629 --> 00:02:47,740
you know, everything that happens on the device stays on the

78
00:02:47,740 --> 00:02:49,308
device, as the way saying goes.

79
00:02:49,788 --> 00:02:52,069
So that, that privacy is also a

80
00:02:52,069 --> 00:02:53,588
big reason why people do this. So,

81
00:02:53,929 --> 00:02:55,360
So today we're going to talk about

82
00:02:55,618 --> 00:02:57,649
how you can get some of your applications

83
00:02:57,649 --> 00:02:58,520
that do

84
00:02:58,939 --> 00:03:00,199
AI on the device.

85
00:03:01,199 --> 00:03:02,058
And

86
00:03:02,379 --> 00:03:04,219
the, for the, for the largest time,

87
00:03:04,838 --> 00:03:06,879
what we saw was developers found

88
00:03:06,879 --> 00:03:09,000
it pretty challenging to take models of a

89
00:03:09,000 --> 00:03:10,240
train in clouds.

90
00:03:10,969 --> 00:03:13,129
And get them running on, you know, on various

91
00:03:13,129 --> 00:03:15,250
different devices that have different architectures

92
00:03:15,250 --> 00:03:17,288
in them and get the best out of the device.

93
00:03:17,368 --> 00:03:19,368
So this process was pretty onerous and over

94
00:03:19,368 --> 00:03:20,710
the last 3 to 5 years,

95
00:03:21,129 --> 00:03:23,199
uh, we at Qualcomm, we've streamlined

96
00:03:23,199 --> 00:03:25,210
that entire process, so you can train your models in the

97
00:03:25,210 --> 00:03:27,330
cloud. And we've built a ton

98
00:03:27,330 --> 00:03:29,569
of automation systems that you can leverage today

99
00:03:29,569 --> 00:03:30,429
completely for free.

100
00:03:30,770 --> 00:03:32,770
Um, you point your models at the

101
00:03:32,770 --> 00:03:34,389
automation and you can

102
00:03:35,439 --> 00:03:37,469
Then get a model that you can deploy

103
00:03:37,469 --> 00:03:38,229
on the device.

104
00:03:39,020 --> 00:03:41,099
And we've streamlined this so that it takes just a

105
00:03:41,099 --> 00:03:43,308
few minutes for you to get something compatible for the

106
00:03:43,308 --> 00:03:45,409
device and something you can run on the device.

107
00:03:46,528 --> 00:03:48,770
Uh, so today, we're gonna walk you through that

108
00:03:48,770 --> 00:03:50,149
process, um,

109
00:03:50,770 --> 00:03:51,689
where we're gonna,

110
00:03:51,960 --> 00:03:54,129
you know, showcase what it's like

111
00:03:54,129 --> 00:03:56,129
to build and deploy a custom

112
00:03:56,129 --> 00:03:57,969
AI application on a bunch of devices.

113
00:03:59,379 --> 00:04:01,508
Obviously, the training process is, uh,

114
00:04:01,550 --> 00:04:04,189
you do it in the cloud. Many of you are familiar with Sagemaker.

115
00:04:04,710 --> 00:04:06,868
We're not gonna go too deep into that, but the

116
00:04:06,868 --> 00:04:08,949
idea is you can use your existing training tools as

117
00:04:08,949 --> 00:04:11,028
is, you don't need to do anything sophisticated or

118
00:04:11,028 --> 00:04:13,088
different. Uh, and then

119
00:04:13,088 --> 00:04:15,210
you get to the stage where you take the model that was

120
00:04:15,210 --> 00:04:17,379
straight in the cloud and you, you optimize it for the

121
00:04:17,379 --> 00:04:19,420
device. Again, that uses a system that we

122
00:04:19,420 --> 00:04:21,420
provide free of cost to all our developers. It's called

123
00:04:21,420 --> 00:04:22,399
Q Qualcomm AI Hub.

124
00:04:23,459 --> 00:04:25,500
Uh, and then once you've, uh, you

125
00:04:25,500 --> 00:04:27,798
know, have an optimized model, we,

126
00:04:27,819 --> 00:04:29,988
uh, we have another system that is available

127
00:04:29,988 --> 00:04:32,059
for you called Edge Impulse, which allows you

128
00:04:32,059 --> 00:04:34,100
to take those models and create this kind

129
00:04:34,100 --> 00:04:36,230
of deployment pipelines that you can use

130
00:04:36,579 --> 00:04:38,689
to deploy on real devices,

131
00:04:38,699 --> 00:04:40,980
um, using other AWS services

132
00:04:40,980 --> 00:04:43,069
like Greengrass, IT Core, Bedrock, and so

133
00:04:43,069 --> 00:04:44,329
on. Uh,

134
00:04:44,639 --> 00:04:46,759
and we'll walk you through that entire journey

135
00:04:46,759 --> 00:04:49,059
of training the model from the cloud

136
00:04:49,059 --> 00:04:50,959
to deploying live on the fleets.

137
00:04:53,689 --> 00:04:56,069
And this is roughly speaking,

138
00:04:56,329 --> 00:04:57,829
uh, the architecture diagram.

139
00:04:58,170 --> 00:05:00,449
Uh, there's a lot of stuff going on there. Um, we'll

140
00:05:00,449 --> 00:05:02,028
go over that step by step,

141
00:05:02,608 --> 00:05:04,730
um, starting with the seven

142
00:05:04,730 --> 00:05:07,009
steps that are in the bottom listed out for you. There's

143
00:05:07,009 --> 00:05:08,170
the strain, optimize,

144
00:05:08,449 --> 00:05:10,790
prepare, deploy, run, and monitor.

145
00:05:11,149 --> 00:05:13,750
It's, it's technically 6 steps. Um,

146
00:05:14,329 --> 00:05:16,928
so we'll go over each of these steps, uh, involving

147
00:05:16,928 --> 00:05:19,170
different services that all seamlessly plug

148
00:05:19,170 --> 00:05:19,829
with each other.

149
00:05:21,069 --> 00:05:22,910
And the nice thing is that

150
00:05:23,230 --> 00:05:25,548
you can do most of these steps without

151
00:05:25,548 --> 00:05:27,670
needing a complicated device sitting on your

152
00:05:27,670 --> 00:05:29,750
desk, because there are lots of device

153
00:05:29,750 --> 00:05:31,750
farms that that abstract away

154
00:05:31,750 --> 00:05:33,829
the complications of having these devices. We make

155
00:05:33,829 --> 00:05:35,428
them available to you through the cloud as well.

156
00:05:35,750 --> 00:05:37,970
So you can do all your development and testing

157
00:05:38,350 --> 00:05:40,949
through your normal work environments and then finally

158
00:05:40,949 --> 00:05:42,410
see the results live.

159
00:05:43,720 --> 00:05:46,048
OK, so the first step is, uh, you know, training

160
00:05:46,048 --> 00:05:48,129
your model. You can use Sage Maker or pretty much

161
00:05:48,129 --> 00:05:50,389
any training service that you use, whether it's,

162
00:05:50,889 --> 00:05:52,790
uh, AWS provided or not.

163
00:05:53,410 --> 00:05:55,670
Uh, you can train, uh, models with,

164
00:05:55,678 --> 00:05:57,689
uh, in, in this, in these environments. You have

165
00:05:57,689 --> 00:05:59,588
enterprise security, you can bring your own data,

166
00:06:00,088 --> 00:06:01,809
you can manage training jobs, and,

167
00:06:02,088 --> 00:06:04,088
and what's nice about this is that once you're

168
00:06:04,088 --> 00:06:06,088
done with the training process, you can

169
00:06:06,088 --> 00:06:08,480
get an output which is an Onyx model or a Pytouch

170
00:06:08,480 --> 00:06:10,608
model. It is pretty standard open

171
00:06:10,608 --> 00:06:12,689
source format that is completely compatible

172
00:06:12,689 --> 00:06:13,829
with the on-device stack.

173
00:06:14,410 --> 00:06:16,449
So really the connection between what you do

174
00:06:16,449 --> 00:06:18,449
in the cloud and what you do on the

175
00:06:18,449 --> 00:06:18,988
edge

176
00:06:19,369 --> 00:06:21,449
is the Onyx model format

177
00:06:21,449 --> 00:06:23,548
or the Pytosh model format, whatever you're comfortable

178
00:06:23,548 --> 00:06:25,548
with. So,

179
00:06:25,649 --> 00:06:27,730
let's say in the first step, uh, you're going

180
00:06:27,730 --> 00:06:29,009
through a training process.

181
00:06:29,488 --> 00:06:31,488
Um, and today we're, we're actually going

182
00:06:31,488 --> 00:06:33,220
through an application that involves,

183
00:06:33,528 --> 00:06:35,540
uh, cameras in a factory,

184
00:06:35,850 --> 00:06:37,850
which you'll hear more about from our second

185
00:06:37,850 --> 00:06:38,369
speaker,

186
00:06:38,730 --> 00:06:41,108
um, where we have defect detection.

187
00:06:41,600 --> 00:06:43,720
So, let's say you're training a model, you use Sage

188
00:06:43,720 --> 00:06:44,910
maker, you collect some data

189
00:06:45,369 --> 00:06:47,410
for determining defects, and then, uh, sorry,

190
00:06:47,528 --> 00:06:49,470
for, you know, doing whatever you need to do.

191
00:06:49,809 --> 00:06:51,850
Uh, you train that model and you're good to

192
00:06:51,850 --> 00:06:54,079
go. And then you go to our, uh,

193
00:06:54,129 --> 00:06:56,790
our service, which is called Q Qualcomm Air Hub, um,

194
00:06:56,928 --> 00:06:59,129
as I mentioned, something freely available.

195
00:06:59,559 --> 00:07:01,750
And what it is, is basically a,

196
00:07:01,889 --> 00:07:04,269
a fully automatable service,

197
00:07:04,600 --> 00:07:06,869
which, which lets you to point,

198
00:07:07,488 --> 00:07:09,608
uh, which allows you to point at

199
00:07:09,608 --> 00:07:10,389
a train model.

200
00:07:11,129 --> 00:07:12,000
And then you pick a device,

201
00:07:12,298 --> 00:07:14,420
depending on what device you're deploying to. So, it

202
00:07:14,420 --> 00:07:16,420
could be a mobile application or it could be

203
00:07:16,420 --> 00:07:18,500
an IOT application, which is what we're going to show you right

204
00:07:18,500 --> 00:07:19,338
now, or it could be

205
00:07:19,660 --> 00:07:21,519
something in an automotive application as well.

206
00:07:21,980 --> 00:07:24,048
And once you pick that device and you say,

207
00:07:24,100 --> 00:07:26,119
OK, I'm deploying this model on this device,

208
00:07:26,738 --> 00:07:29,059
uh, the Edge, uh, Edge AI typically

209
00:07:29,059 --> 00:07:31,178
there are many different runtimes people use to

210
00:07:31,178 --> 00:07:32,678
deploy the model on the actual

211
00:07:33,129 --> 00:07:34,778
Device. So, some people use

212
00:07:35,139 --> 00:07:37,338
Tensorflow, some people use, um, you

213
00:07:37,338 --> 00:07:39,720
know, Onyx runtime, there's executorch,

214
00:07:39,819 --> 00:07:41,970
there's also the Qualcomm AI stack if you want to do

215
00:07:41,970 --> 00:07:42,889
something super native.

216
00:07:43,338 --> 00:07:44,879
So you can just pick your runtime

217
00:07:45,298 --> 00:07:47,100
and say, hey, here's the model that I've

218
00:07:47,500 --> 00:07:49,778
trained. This is the device that I care about, this is the runtime

219
00:07:49,778 --> 00:07:50,569
that I care about.

220
00:07:50,939 --> 00:07:53,100
Now, go, right? And then what happens

221
00:07:53,100 --> 00:07:55,100
is we'll, we'll optimize the model for that

222
00:07:55,100 --> 00:07:57,100
particular configuration, we'll do all the conversion

223
00:07:57,100 --> 00:07:58,889
that's needed, all the optimization that's needed,

224
00:07:59,238 --> 00:08:01,399
and the, at the end of it, you'll get an output.

225
00:08:01,829 --> 00:08:04,329
That you can, you can be sure

226
00:08:05,230 --> 00:08:06,428
will run on the device.

227
00:08:06,709 --> 00:08:08,790
And, and the reason you can be sure is because

228
00:08:08,790 --> 00:08:10,988
as part of this, this, this service,

229
00:08:11,309 --> 00:08:13,439
what we offer is a cloud

230
00:08:13,439 --> 00:08:14,889
of devices that are plugged in.

231
00:08:15,670 --> 00:08:18,569
To our cloud, and we'll do a simulation

232
00:08:18,569 --> 00:08:20,670
on those physical devices so that we can

233
00:08:20,670 --> 00:08:22,790
tell you exactly how fast it's going to run,

234
00:08:23,230 --> 00:08:24,910
uh, how much memory it's going to consume,

235
00:08:25,220 --> 00:08:27,230
and, um, and any kind

236
00:08:27,230 --> 00:08:28,910
of accuracy issues if you hit,

237
00:08:29,309 --> 00:08:31,850
uh, we also can check that for you. So,

238
00:08:31,899 --> 00:08:34,219
everything that you typically need to do to take a model that's

239
00:08:34,219 --> 00:08:36,210
trained in one environment, like the cloud,

240
00:08:36,469 --> 00:08:38,469
and deploy in a different environment, which is the edge,

241
00:08:38,509 --> 00:08:40,509
we do all of that in an automation. So it should

242
00:08:40,509 --> 00:08:41,750
take you just a few minutes to,

243
00:08:42,269 --> 00:08:43,058
to go and do that.

244
00:08:44,570 --> 00:08:46,769
Um, and with that, uh, I'm

245
00:08:46,769 --> 00:08:48,849
gonna introduce our next speaker who, who'll

246
00:08:48,849 --> 00:08:50,889
walk you through the process of now that you

247
00:08:50,889 --> 00:08:51,769
have a trained model,

248
00:08:52,090 --> 00:08:53,609
how do you actually go deploy it,

249
00:08:53,928 --> 00:08:56,090
uh, on an edge device and make

250
00:08:56,090 --> 00:08:57,750
sure you can run and deploy

251
00:08:58,048 --> 00:08:59,369
in a live environment.

252
00:08:59,690 --> 00:09:01,349
So, we'll walk you through that briefly.

253
00:09:02,750 --> 00:09:03,519
Perfect.

254
00:09:03,859 --> 00:09:05,979
And before I move on to step 3, I'll just

255
00:09:05,979 --> 00:09:08,038
briefly introduce myself. So I'm Ashman,

256
00:09:08,298 --> 00:09:10,649
and I'm a solutions engineer at Edge Impulse,

257
00:09:10,658 --> 00:09:12,769
and Edge Impulse was, uh,

258
00:09:12,779 --> 00:09:14,859
we joined forces with Q Qualcomm earlier this

259
00:09:14,859 --> 00:09:16,719
year. So I'm actually a Qualcomm engineer now,

260
00:09:17,178 --> 00:09:19,859
and, uh, I've been in the semiconductor

261
00:09:19,859 --> 00:09:22,090
industry for over 10 years based in Austin,

262
00:09:22,178 --> 00:09:22,879
Texas,

263
00:09:23,219 --> 00:09:25,340
and what I do day to day is I

264
00:09:25,340 --> 00:09:27,200
help our real world customers.

265
00:09:27,889 --> 00:09:29,969
Build real world AI applications.

266
00:09:30,048 --> 00:09:31,908
So that's what I wanna show today

267
00:09:32,330 --> 00:09:34,349
how to build this real world

268
00:09:34,349 --> 00:09:36,489
edge AI application that's capable

269
00:09:36,489 --> 00:09:39,029
of running in real time and really fast on

270
00:09:39,168 --> 00:09:41,200
any type of edge device and the edge device that we're

271
00:09:41,200 --> 00:09:43,408
focusing on today is um a

272
00:09:43,408 --> 00:09:44,450
Qualcomm processor.

273
00:09:45,119 --> 00:09:47,279
So let me jump into step 3, which is

274
00:09:47,279 --> 00:09:49,389
preparing the deployment in Edge

275
00:09:49,389 --> 00:09:51,469
Impulse. So right now what you heard from Krishna

276
00:09:51,469 --> 00:09:53,639
was you, you trained the model in

277
00:09:53,639 --> 00:09:56,080
SageMaker, right? You have a hardware optimized

278
00:09:56,080 --> 00:09:58,269
model through Q Qualcomm AI Hub,

279
00:09:58,558 --> 00:10:00,599
and now what you wanna do is you wanna bring

280
00:10:00,599 --> 00:10:02,840
that model into Edge Impulse. And

281
00:10:02,840 --> 00:10:03,840
what is Edge Impulse?

282
00:10:04,149 --> 00:10:06,279
Edge Impulse is a platform that allows

283
00:10:06,279 --> 00:10:08,418
you to build real world applications.

284
00:10:08,798 --> 00:10:10,899
It can be developers. It can be enterprises,

285
00:10:10,960 --> 00:10:13,080
it can be any type of data. In our case

286
00:10:13,080 --> 00:10:14,418
we're gonna show computer vision.

287
00:10:14,928 --> 00:10:16,639
And you can deploy it onto

288
00:10:17,009 --> 00:10:19,538
CPUs, GPUs, uh, MCUs

289
00:10:19,538 --> 00:10:20,119
as well.

290
00:10:20,739 --> 00:10:23,009
But let me, let me jump in and show you one of our features

291
00:10:23,009 --> 00:10:25,099
that we have in Edge impuls called BYOM,

292
00:10:25,219 --> 00:10:26,820
which stands for bring your own model.

293
00:10:27,259 --> 00:10:29,320
So what we do is we take the

294
00:10:29,779 --> 00:10:32,139
model file, it can be the Onyx file or TFlight

295
00:10:32,139 --> 00:10:33,460
as Krishna was mentioning,

296
00:10:33,779 --> 00:10:35,479
and we bring it into our platform.

297
00:10:36,029 --> 00:10:38,080
And what this allows us to do is

298
00:10:38,080 --> 00:10:40,359
you, you bring in your model and

299
00:10:40,359 --> 00:10:42,840
now you can actually develop and generate

300
00:10:42,840 --> 00:10:44,219
an HML package

301
00:10:44,678 --> 00:10:47,038
so we, we walk you through the pipeline, we get you

302
00:10:47,200 --> 00:10:49,619
a model that's hardware optimized.

303
00:10:49,869 --> 00:10:51,859
It doesn't require you to

304
00:10:52,239 --> 00:10:54,519
have any type of dependencies. You don't have to worry about Python

305
00:10:54,519 --> 00:10:56,629
dependency how it's fully, uh,

306
00:10:56,639 --> 00:10:58,759
kind of self-contained so you can really

307
00:10:58,759 --> 00:11:01,080
bring it into your hardware and be confident

308
00:11:01,080 --> 00:11:01,859
that's gonna run,

309
00:11:02,279 --> 00:11:04,320
uh, fully sufficiently and hardware

310
00:11:04,320 --> 00:11:05,099
optimized.

311
00:11:05,629 --> 00:11:07,859
And our platform lets you walk, uh,

312
00:11:07,908 --> 00:11:10,158
it steps you through the process, so it, it shows you,

313
00:11:10,229 --> 00:11:12,729
uh, it lets you choose what output formats,

314
00:11:12,989 --> 00:11:15,149
um, it lets you bring in some sample

315
00:11:15,149 --> 00:11:16,168
data so you can

316
00:11:16,548 --> 00:11:18,548
eye check and, and make sure that your model passes

317
00:11:18,548 --> 00:11:19,330
the eye test

318
00:11:19,668 --> 00:11:21,788
and once you're happy with the model,

319
00:11:22,048 --> 00:11:24,269
uh, you can do which is on, uh, on the right

320
00:11:24,269 --> 00:11:26,349
side which is deploy.

321
00:11:26,500 --> 00:11:27,369
So we have

322
00:11:27,710 --> 00:11:29,940
a wide array of what you can

323
00:11:29,940 --> 00:11:31,950
deploy on and because our

324
00:11:31,950 --> 00:11:34,389
device is the 6490, a Qualcomm

325
00:11:34,389 --> 00:11:36,389
processor. Uh, we can choose

326
00:11:36,389 --> 00:11:38,269
that easily in our, in our UI.

327
00:11:39,168 --> 00:11:41,210
So once you have the actual

328
00:11:41,210 --> 00:11:41,908
model,

329
00:11:42,369 --> 00:11:44,509
the next step is to.

330
00:11:46,599 --> 00:11:48,639
Deploy the model so you've

331
00:11:48,639 --> 00:11:50,840
generated your model file now how do you get it onto

332
00:11:50,840 --> 00:11:52,908
your fleet of devices, right? So

333
00:11:52,908 --> 00:11:55,000
the use case that we've been talking about is pill

334
00:11:55,000 --> 00:11:56,219
defect detection so.

335
00:11:56,500 --> 00:11:58,820
Imagine you have a whole factory

336
00:11:58,820 --> 00:12:01,009
floor or multiple factory floors that

337
00:12:01,009 --> 00:12:01,879
all have

338
00:12:02,700 --> 00:12:05,000
conveyor belts and they're pills going down the conveyor

339
00:12:05,000 --> 00:12:07,288
belt and you wanna go and put your model

340
00:12:07,288 --> 00:12:09,119
onto each one of these devices.

341
00:12:09,700 --> 00:12:11,899
Now you could individually go

342
00:12:11,899 --> 00:12:14,019
and and update the firmware of all of these

343
00:12:14,019 --> 00:12:14,928
models, right, and

344
00:12:15,298 --> 00:12:17,099
individually go put update the model.

345
00:12:17,875 --> 00:12:19,994
But obviously that's time consuming

346
00:12:19,994 --> 00:12:21,994
and that's also very expensive so

347
00:12:22,354 --> 00:12:24,754
what we can utilize is uh AWS

348
00:12:24,754 --> 00:12:26,974
IUT Greengrass which allows you to

349
00:12:27,234 --> 00:12:29,354
deploy onto your entire fleet of

350
00:12:29,354 --> 00:12:30,014
devices

351
00:12:30,433 --> 00:12:32,663
so it requires 3 steps,

352
00:12:32,673 --> 00:12:35,114
um, and if for those of you all who are familiar

353
00:12:35,114 --> 00:12:36,494
with IOT Greengrass, you might

354
00:12:36,875 --> 00:12:37,913
see these images and.

355
00:12:38,308 --> 00:12:39,460
Uh, resonate with them,

356
00:12:39,788 --> 00:12:42,269
but the first step is you actually install

357
00:12:42,269 --> 00:12:44,489
Greengrass on your Edge device and because

358
00:12:44,750 --> 00:12:46,788
we're using a Q Qualcomm processor, it's running

359
00:12:46,788 --> 00:12:47,548
Linux OS.

360
00:12:47,820 --> 00:12:49,859
In our case, uh, Qualcomm Linux,

361
00:12:50,070 --> 00:12:52,469
it's actually really easy to install Greengrass.

362
00:12:52,500 --> 00:12:54,629
It's just a couple of dependencies that you have to install

363
00:12:54,629 --> 00:12:56,340
and, and we have instructions, uh,

364
00:12:56,629 --> 00:12:58,710
online for all of this. So feel free to ask me, and

365
00:12:58,710 --> 00:13:00,210
I can, I can point you in the right direction.

366
00:13:01,019 --> 00:13:03,379
And uh one note, even if you're using

367
00:13:03,379 --> 00:13:05,538
another OS like Ubuntu, it's exactly

368
00:13:05,538 --> 00:13:07,658
the same steps as well so we really allow you

369
00:13:07,658 --> 00:13:09,759
to choose uh whatever you want to use

370
00:13:10,058 --> 00:13:12,460
and then the next step is customizing

371
00:13:12,460 --> 00:13:14,500
your YAO recipes and what

372
00:13:14,500 --> 00:13:15,979
is this and why are, why are we doing this?

373
00:13:16,283 --> 00:13:18,673
Well, what are we trying to deploy,

374
00:13:18,844 --> 00:13:20,875
right? Like we, we wanna deploy

375
00:13:20,875 --> 00:13:22,994
something that will allow us to get the model and

376
00:13:22,994 --> 00:13:24,994
also test the model on our Edge device,

377
00:13:25,364 --> 00:13:27,465
and Edge Impulse helps you do that

378
00:13:27,683 --> 00:13:29,844
with a tool, with a software tool called

379
00:13:29,844 --> 00:13:31,065
Edge Impulse Linux Runner.

380
00:13:31,558 --> 00:13:33,879
So what the Yama recipe

381
00:13:33,879 --> 00:13:35,918
is setting up is, is setting how to get

382
00:13:35,918 --> 00:13:37,989
this edge impulse Linux runner on all

383
00:13:37,989 --> 00:13:39,058
of your devices

384
00:13:39,440 --> 00:13:41,479
and once you set that up, you create

385
00:13:41,479 --> 00:13:43,820
the component, you put it in an S3 bucket,

386
00:13:44,080 --> 00:13:46,599
and, uh, the, the final step is actually

387
00:13:46,599 --> 00:13:48,139
deploying it on your device

388
00:13:48,399 --> 00:13:50,479
and something that I was very pleasantly

389
00:13:50,479 --> 00:13:52,950
surprised about, uh. With using AWS,

390
00:13:53,389 --> 00:13:55,599
all of this stuff, all of these steps that you see right here

391
00:13:55,599 --> 00:13:57,750
were done through the management console. So

392
00:13:57,750 --> 00:13:58,969
when I was setting up the demo

393
00:13:59,229 --> 00:14:01,500
and for those of y'all who stopped by the Q Qualcomm

394
00:14:01,500 --> 00:14:03,788
booth, you might have seen this, this pill defect detection

395
00:14:03,788 --> 00:14:04,590
running live.

396
00:14:04,989 --> 00:14:07,190
Um, all of these steps, uh, the,

397
00:14:07,229 --> 00:14:09,690
the green grass steps were all set up in the

398
00:14:09,830 --> 00:14:11,609
AWS management console,

399
00:14:11,950 --> 00:14:14,029
and it's super intuitive, super easy,

400
00:14:14,070 --> 00:14:15,408
and you don't actually have to

401
00:14:15,769 --> 00:14:17,950
run some complicated scripts

402
00:14:17,950 --> 00:14:19,849
locally just, just to get up and running.

403
00:14:20,759 --> 00:14:22,940
OK, so now we've talked about

404
00:14:23,330 --> 00:14:24,379
generating the model

405
00:14:24,639 --> 00:14:26,590
and now we've talked about deploying the model.

406
00:14:26,879 --> 00:14:28,960
Now the next step is actually running

407
00:14:28,960 --> 00:14:31,058
the model that is actually on your device.

408
00:14:31,558 --> 00:14:33,750
So why do we wanna do this?

409
00:14:33,840 --> 00:14:35,500
Well, in our use case,

410
00:14:35,798 --> 00:14:37,139
we don't want to

411
00:14:37,519 --> 00:14:39,558
just you wanna be able to

412
00:14:39,558 --> 00:14:41,599
do something with your models, right? You wanna have him

413
00:14:41,599 --> 00:14:43,019
do some action. So,

414
00:14:43,428 --> 00:14:46,048
uh, what we wanna do here is

415
00:14:46,519 --> 00:14:48,519
run the edge and bolt cynics runner which I

416
00:14:48,519 --> 00:14:49,960
talked about in the previous slide.

417
00:14:50,320 --> 00:14:52,519
And what this allows you to do is essentially

418
00:14:52,519 --> 00:14:54,558
get two types of outputs, and it really depends on

419
00:14:54,558 --> 00:14:56,979
what you're trying to do at that moment in time. So

420
00:14:57,200 --> 00:14:59,460
one of the types of output is just simple

421
00:14:59,639 --> 00:15:01,639
text bounding box inference in our use

422
00:15:01,639 --> 00:15:03,918
case because we're trying to see uh

423
00:15:03,918 --> 00:15:06,000
where the pills are, right? So you can see the bounding

424
00:15:06,000 --> 00:15:08,190
boxes where the normal pills are and where the bounding

425
00:15:08,190 --> 00:15:09,700
boxes, where the defects are.

426
00:15:10,129 --> 00:15:10,719
And

427
00:15:11,139 --> 00:15:13,340
that eventually we will send up to the cloud

428
00:15:13,340 --> 00:15:15,619
for further monitoring and analysis,

429
00:15:15,658 --> 00:15:17,899
but before I jump to that part, um,

430
00:15:17,979 --> 00:15:20,058
I also wanted to quickly note that the Linux

431
00:15:20,058 --> 00:15:22,099
runner also lets you visualize

432
00:15:22,099 --> 00:15:24,099
all of your, your inference results,

433
00:15:24,178 --> 00:15:26,219
right? So on the bottom right what

434
00:15:26,219 --> 00:15:28,379
you just saw was just

435
00:15:28,379 --> 00:15:30,500
local processing, right? So you're not actually

436
00:15:30,500 --> 00:15:32,840
taking images, having the video stream,

437
00:15:32,889 --> 00:15:34,359
and sending it up to the cloud.

438
00:15:34,619 --> 00:15:36,840
What you're actually doing is running the model

439
00:15:37,019 --> 00:15:39,298
on the edge locally and.

440
00:15:39,739 --> 00:15:40,369
If I

441
00:15:40,950 --> 00:15:43,029
kind of go back and and play this animation

442
00:15:43,029 --> 00:15:45,250
again you'll you'll see just how fast

443
00:15:45,428 --> 00:15:47,428
this model is running, right? So this

444
00:15:47,428 --> 00:15:49,428
is honestly not just a

445
00:15:49,428 --> 00:15:51,548
nice to have in a manufacturing use

446
00:15:51,548 --> 00:15:52,349
case that we have,

447
00:15:52,668 --> 00:15:54,779
but it's, it's a necessity to be able

448
00:15:54,779 --> 00:15:56,830
to have a model that's running so

449
00:15:56,830 --> 00:15:59,308
fast and when you have some crucial

450
00:15:59,308 --> 00:16:01,460
aspects, let's say like you, you have a,

451
00:16:01,469 --> 00:16:03,469
a, a large defect trend, you wanna be

452
00:16:03,469 --> 00:16:05,509
able to stop your assembly line

453
00:16:05,509 --> 00:16:07,609
and, and have a technician go check it out so.

454
00:16:07,979 --> 00:16:10,070
It's really important to to not always send all

455
00:16:10,070 --> 00:16:11,710
your images up to the cloud at some point.

456
00:16:12,548 --> 00:16:14,908
All right, so now we've discussed training the model, we've

457
00:16:14,908 --> 00:16:17,070
discussed, uh, deploying the model and now

458
00:16:17,070 --> 00:16:19,389
running the model, and now the, the

459
00:16:19,389 --> 00:16:21,668
next step and almost the

460
00:16:21,668 --> 00:16:23,808
pretty much the final step is actually doing

461
00:16:23,808 --> 00:16:25,889
something with this data. So you're monitoring,

462
00:16:26,109 --> 00:16:27,168
you're analyzing.

463
00:16:27,519 --> 00:16:29,798
And for, for any of the, the AWS

464
00:16:29,798 --> 00:16:31,580
experts out out in the audience,

465
00:16:31,879 --> 00:16:33,960
once you get it onto some AWS

466
00:16:33,960 --> 00:16:36,019
component, you can really do anything

467
00:16:36,399 --> 00:16:38,519
with it, right? So in our case what

468
00:16:38,519 --> 00:16:40,940
we did was we sent the data,

469
00:16:41,320 --> 00:16:43,479
uh, uh, pretty much the, the inference

470
00:16:43,479 --> 00:16:44,599
results in text format

471
00:16:45,080 --> 00:16:47,009
to AWS IUT core.

472
00:16:47,428 --> 00:16:49,428
And once it was an IOT core,

473
00:16:49,479 --> 00:16:51,038
we were able to publish it,

474
00:16:51,349 --> 00:16:54,119
um, add it into a time stream, uh, database,

475
00:16:54,399 --> 00:16:56,529
and then from there we just, we, we showed a Grafana

476
00:16:56,529 --> 00:16:58,639
dashboard that was querying from this database,

477
00:16:58,678 --> 00:17:00,779
and that's what we showed at the booth for anyone,

478
00:17:00,879 --> 00:17:01,918
uh, who stopped by.

479
00:17:02,320 --> 00:17:04,400
Um, but, but what this is really there

480
00:17:04,400 --> 00:17:06,439
to show is it, it's up to you, it's up to the

481
00:17:06,439 --> 00:17:07,180
use case,

482
00:17:07,439 --> 00:17:09,439
um, and it's up to the customer to decide what

483
00:17:09,439 --> 00:17:11,420
they wanna be able to do. So in our

484
00:17:11,759 --> 00:17:13,799
use case we're trying to find defects,

485
00:17:13,838 --> 00:17:15,838
right? How many there are, where they

486
00:17:15,838 --> 00:17:17,949
are, and is it trending in the right

487
00:17:17,949 --> 00:17:20,039
direction or wrong direction. So by

488
00:17:20,039 --> 00:17:22,039
seeing the, the graphic on the bottom right

489
00:17:22,039 --> 00:17:24,439
you're seeing that we're, we're, we're having a decrease

490
00:17:24,439 --> 00:17:25,439
in the defect rate.

491
00:17:26,449 --> 00:17:27,549
All right, so

492
00:17:27,809 --> 00:17:29,969
we've gone through all of the steps, right? So we, we

493
00:17:29,969 --> 00:17:32,509
started with the training, we went to optimizing,

494
00:17:33,009 --> 00:17:35,078
we prepared the model on Edge and

495
00:17:35,078 --> 00:17:37,170
pulse, we deployed and ran it using

496
00:17:37,170 --> 00:17:37,868
green grass,

497
00:17:38,130 --> 00:17:40,269
and now we're also monitoring. So

498
00:17:40,328 --> 00:17:42,150
with that we've completed the pipeline

499
00:17:42,449 --> 00:17:44,328
from kind of. Start to finish

500
00:17:44,630 --> 00:17:46,848
and let me just kind of go through a

501
00:17:46,848 --> 00:17:49,029
couple of the kind of the the learnings

502
00:17:49,029 --> 00:17:49,779
that we found.

503
00:17:50,229 --> 00:17:52,309
So one is we reduced

504
00:17:52,309 --> 00:17:53,250
the training time

505
00:17:53,509 --> 00:17:55,549
uh by using Amazon Sage Maker and as

506
00:17:55,549 --> 00:17:56,390
Krishna mentioned

507
00:17:57,130 --> 00:17:59,189
by using SageMaker you can train your model. In our case it

508
00:17:59,189 --> 00:18:00,009
was computer vision.

509
00:18:00,578 --> 00:18:01,680
And also

510
00:18:01,939 --> 00:18:04,078
going from Sagemaker to Q Qualcomm AI hub,

511
00:18:04,380 --> 00:18:06,699
we were able to achieve 20 times faster

512
00:18:06,699 --> 00:18:08,858
throughput by optimizing the model. So

513
00:18:08,858 --> 00:18:10,900
the whole point of AI Hub was

514
00:18:10,900 --> 00:18:13,479
to optimize your model for your specific hardware

515
00:18:13,848 --> 00:18:16,059
and also with AI

516
00:18:16,059 --> 00:18:18,180
Hub and then Edge Impulse we're also able to

517
00:18:18,180 --> 00:18:20,479
create a, a model that was so efficient

518
00:18:20,479 --> 00:18:21,019
that it.

519
00:18:21,680 --> 00:18:24,019
Had just a few milliseconds of latency,

520
00:18:24,088 --> 00:18:26,130
so the inference speed was really fast, and

521
00:18:26,130 --> 00:18:28,170
we were able to see it in, in the, the

522
00:18:28,170 --> 00:18:30,170
graphic in the last slide where you see the pills

523
00:18:30,170 --> 00:18:32,250
being defect, uh, detected

524
00:18:32,250 --> 00:18:34,160
for defects in, in real time.

525
00:18:34,689 --> 00:18:36,709
And then finally, thanks to the integration

526
00:18:36,709 --> 00:18:38,729
of uh Greengrass and Edge Impulse,

527
00:18:38,809 --> 00:18:40,469
we were able to deploy

528
00:18:40,769 --> 00:18:42,809
the entire fleet of devices

529
00:18:42,809 --> 00:18:45,559
that you have set up in ADWS with

530
00:18:45,559 --> 00:18:46,199
your models.

531
00:18:46,969 --> 00:18:47,568
And

532
00:18:47,858 --> 00:18:50,059
for, for final takeaways which what what

533
00:18:50,059 --> 00:18:51,759
I wanna leave you with is, um,

534
00:18:52,140 --> 00:18:54,279
kind of just what is the flow,

535
00:18:54,338 --> 00:18:56,318
what, what do we actually see today?

536
00:18:56,779 --> 00:18:58,858
One was obviously we, we started with

537
00:18:58,858 --> 00:18:59,640
Sagemaker,

538
00:18:59,979 --> 00:19:02,098
um, that's really speeds up your

539
00:19:02,098 --> 00:19:04,420
development time and, and we have examples

540
00:19:04,420 --> 00:19:06,459
for all of this on our websites and I'll, I'll send you

541
00:19:06,459 --> 00:19:08,699
some links and QR codes, uh, shortly

542
00:19:08,699 --> 00:19:10,699
so you can, you can check out how to get set up with your

543
00:19:10,699 --> 00:19:11,559
own use case,

544
00:19:11,939 --> 00:19:13,549
um. We took the model

545
00:19:13,930 --> 00:19:16,009
we had AI hub really optimize the

546
00:19:16,009 --> 00:19:18,049
model. We had Edge Impulse

547
00:19:18,049 --> 00:19:20,250
take that model, put it into a more

548
00:19:20,250 --> 00:19:22,848
easily deployable, uh, artifact

549
00:19:23,250 --> 00:19:25,549
that the Edge Impulse Nex runner was able to

550
00:19:25,709 --> 00:19:28,250
deploy onto multiple devices using

551
00:19:28,250 --> 00:19:30,289
Greengrass. And with that you

552
00:19:30,289 --> 00:19:31,189
can see how

553
00:19:31,689 --> 00:19:33,848
we really use the best of both worlds, right? We

554
00:19:33,848 --> 00:19:35,868
used Q Qualcomm technologies to show

555
00:19:36,328 --> 00:19:37,250
that we have.

556
00:19:37,854 --> 00:19:39,953
AI we have called Kameahub we have edge Impulse to really

557
00:19:39,953 --> 00:19:41,213
optimize your model

558
00:19:41,515 --> 00:19:43,634
and and get it something that's really edge

559
00:19:43,634 --> 00:19:45,914
optimized so you can run it really fast and

560
00:19:45,914 --> 00:19:48,233
then we also use AWS technologies

561
00:19:48,233 --> 00:19:51,015
to, to take advantage of their cloud infrastructure

562
00:19:51,233 --> 00:19:53,814
to, to get the model out into

563
00:19:53,875 --> 00:19:55,055
the real world and then

564
00:19:55,515 --> 00:19:57,594
not just get the model out there but also start

565
00:19:57,594 --> 00:19:59,394
monitoring and analyzing and,

566
00:19:59,963 --> 00:20:01,963
and doing some real world use cases with it.

567
00:20:02,594 --> 00:20:04,953
So with that, that, that concludes

568
00:20:04,953 --> 00:20:06,193
our presentations and.

569
00:20:06,519 --> 00:20:08,779
Um, here are the QR codes that I promised, so

570
00:20:08,779 --> 00:20:11,000
if you want to get up and ready

571
00:20:11,000 --> 00:20:12,640
with, um, edge impulse,

572
00:20:12,900 --> 00:20:14,160
uh, there's a, there's a.

573
00:20:14,660 --> 00:20:16,709
Our landing page for uh a free sign up that you

574
00:20:16,709 --> 00:20:18,229
can go and test out and

575
00:20:18,630 --> 00:20:20,630
one other thing to note is right now

576
00:20:20,630 --> 00:20:22,709
what Krishna and I talked about was a computer

577
00:20:22,709 --> 00:20:23,750
vision use case,

578
00:20:24,078 --> 00:20:24,769
right? But

579
00:20:25,029 --> 00:20:27,068
let's say you have another use case you've got some like

580
00:20:27,068 --> 00:20:29,189
audio-based use case or motion-based use

581
00:20:29,189 --> 00:20:31,390
case. What you can do is upload

582
00:20:31,390 --> 00:20:33,670
whatever data set that you have or your customer has

583
00:20:33,910 --> 00:20:35,910
into our portal. We'll train a model

584
00:20:35,910 --> 00:20:36,868
similarly what

585
00:20:37,299 --> 00:20:39,509
what, what I showed you for computer vision, but for

586
00:20:39,509 --> 00:20:40,380
the other data sets,

587
00:20:40,670 --> 00:20:42,670
and we can kind of walk you through the whole pipeline

588
00:20:42,670 --> 00:20:43,430
just like I showed.

589
00:20:43,809 --> 00:20:45,809
And then similarly, we have uh the landing page for

590
00:20:45,809 --> 00:20:47,390
Qualcomm AI hub as well.

591
00:20:47,930 --> 00:20:50,509
So, yeah, with that, uh,

592
00:20:50,670 --> 00:20:51,949
that concludes our presentation.

593
00:20:52,449 --> 00:20:53,150
Thank you.

