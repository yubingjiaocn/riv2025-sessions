# AWS re:Invent 2025 边缘AI模型部署技术会议总结

## 会议概述

本次技术会议重点讨论了如何在边缘设备上部署AI模型，由Qualcomm和Edge Impulse的技术专家主讲。会议通过一个工厂缺陷检测的实际案例，展示了从云端训练到边缘部署的完整流程。演讲者强调了边缘AI的重要性，指出现代智能手机每次拍照时会运行20-30个AI模型，平均包含约1000个模型，而应用商店中超过10万个应用使用AI技术。

会议介绍了一套完整的解决方案架构，结合AWS服务（如SageMaker、IoT Greengrass、IoT Core）与Qualcomm技术（AI Hub、Edge Impulse），实现了从模型训练、优化、部署到监控的端到端自动化流程。这种方法解决了传统边缘AI部署中的复杂性问题，使开发者能够在几分钟内完成模型的设备适配和部署。

## 详细时间线与关键要点

### 0:00-3:00 边缘AI应用现状与必要性
- 智能手机拍照时运行20-30个AI模型，设备平均包含约1000个模型
- 边缘AI广泛应用于汽车ADAS系统、无人机、机器人和PC应用
- 边缘部署的三大驱动因素：
  - 延迟优化：提供更快速的用户体验
  - 成本控制：游戏公司通过边缘计算节省九位数云端费用
  - 隐私保护：数据在设备本地处理，不上传云端

### 3:00-6:00 解决方案架构概述
- 传统云端训练到边缘部署过程复杂且耗时
- Qualcomm提供免费自动化系统简化整个流程
- 六步部署流程：训练、优化、准备、部署、运行、监控
- 支持通过云端设备农场进行开发测试，无需本地复杂设备

### 6:00-9:00 步骤1：云端模型训练
- 使用Amazon SageMaker或其他训练服务
- 支持企业级安全、自定义数据和训练任务管理
- 输出标准开源格式（ONNX或PyTorch模型）
- 演示案例：工厂缺陷检测模型训练

### 9:00-12:00 步骤2：Qualcomm AI Hub模型优化
- 免费提供的全自动化服务
- 支持移动、IoT、汽车等多种应用场景
- 多运行时支持：TensorFlow、ONNX Runtime、ExecuTorch、Qualcomm AI Stack
- 提供云端物理设备仿真，准确预测性能、内存消耗和精度

### 12:00-15:00 步骤3：Edge Impulse部署准备
- Edge Impulse平台介绍：支持开发者和企业构建实际AI应用
- BYOM（Bring Your Own Model）功能：导入ONNX或TFLite模型
- 生成硬件优化的自包含HML包，无需Python依赖
- 支持多种输出格式和设备类型，包括Qualcomm 6490处理器

### 15:00-17:00 步骤4：AWS IoT Greengrass批量部署
- 解决工厂多设备批量部署挑战
- 三步部署流程：
  - 在边缘设备安装Greengrass（支持Qualcomm Linux和Ubuntu）
  - 自定义YOCTO配方配置Edge Impulse Linux Runner
  - 通过AWS管理控制台完成组件创建和S3存储

### 17:00-19:00 步骤5-6：模型运行与监控
- Edge Impulse Linux Runner提供两种输出：文本边界框推理和可视化结果
- 实时本地处理，无需将视频流上传云端
- 数据流向：推理结果→AWS IoT Core→TimeStream数据库→Grafana仪表板
- 支持实时缺陷趋势监控和预警

### 19:00-20:30 性能优化成果与总结
- 关键性能提升：
  - 通过SageMaker减少训练时间
  - AI Hub优化实现20倍吞吐量提升
  - 实现毫秒级推理延迟
  - Greengrass实现整个设备群的批量部署
- 技术栈整合：AWS云基础设施 + Qualcomm边缘优化技术
- 提供免费注册链接和多种用例支持（计算机视觉、音频、运动检测）