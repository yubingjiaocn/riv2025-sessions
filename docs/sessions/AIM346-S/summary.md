# AWS re:Invent 2025 Breakout Session 综合总结

## 会议概述

本次会议主要介绍了 Elastic 公司推出的全新 AI 驱动的日志分析引擎 —— Elastic Streams。演讲者从传统可观测性面临的挑战出发,阐述了当前日志管理的痛点:数据管道复杂、日志数据丢失、缺乏上下文的告警、以及非结构化日志难以分析等问题。这些问题导致企业在故障排查时耗费大量时间,系统停机时间延长。

演讲者强调,虽然业界一直建议将日志转换为指标或追踪数据,但实际上日志包含了丰富的上下文信息,不应被丢弃。Elastic Streams 通过结合强大的平台能力和 AI 技术,实现了日志的自动分区、结构化处理、问题检测和根因分析。该解决方案采用 LogsDB 索引模式,通过列式存储和合成源技术,可节省高达 70% 的存储成本。更重要的是,它支持使用 OpenTelemetry 语义约定,确保数据以标准格式存储。整个系统通过 LLM 自动识别日志来源系统、生成 Grok 解析模式、检测潜在问题并创建告警,极大地简化了日志管理流程,让工程师能够专注于解决实际问题而非处理数据管道。

## 详细时间线

### 开场与问题陈述 (0:00 - 5:30)
- **0:00** - 演讲者开场,感谢观众来到 Mandalay Bay 听取关于日志的演讲
- **0:15** - 展示由 Sora 生成的 AI 图片,演示 AI 的可能性
- **1:00** - 阐述当前可观测性面临的核心问题:依赖数据收集、专有代理、仪表板和可视化,但难以获得答案
- **1:30** - 指出告警缺乏上下文的问题,例如收到 CPU 使用率或内存不足的告警,但不知道如何处理
- **2:15** - 讨论数据管道的复杂性:需要大量工作构建日志管道(如 Logstash),导致数据丢失
- **3:00** - 强调客户反馈:约一半的日志在传输过程中被丢弃
- **3:45** - 提出核心问题:"为什么"一直缺失,系统变得极其复杂(微服务、Kubernetes 无处不在)

### 日志的价值与挑战 (5:30 - 10:00)
- **5:30** - 质疑业界建议:不应将日志转换为指标或追踪,因为无法对所有内容进行追踪(调查显示追踪覆盖率仅 50-60%)
- **6:15** - 分析 SRE 不使用日志的原因:日志杂乱无章、非结构化、需要编写复杂的正则表达式
- **7:00** - 展示搜索结果:最复杂的正则表达式示例就是用于解析日志行
- **7:30** - 列举日志的三大挑战:数量庞大(数百万条)、来源分散(不同系统、不同格式)
- **8:15** - 强调日志的优势:易于收集(包括 SaaS 应用、大型机、ATM 机等),包含丰富上下文(用户 ID、解释说明等)
- **9:00** - 总结日志管理需求:可扩展平台、成本效益的存储、AI 驱动的分析

### Elastic 现有能力介绍 (10:00 - 13:30)
- **10:00** - 介绍 Elastic 的现有优势:大量集成、高度可扩展的平台
- **10:45** - 客户反馈:迁移到 Elastic 后查询速度提升一倍,仪表板加载时间大幅缩短
- **11:15** - 介绍 ML 驱动的模式分析、异常检测功能
- **11:45** - 重点推荐 ESQL 查询语言:最近 GA 了 JOIN 功能,可在查询中直接调用 LLM 进行分析
- **12:30** - 介绍 LogsDB 索引模式:通过索引排序和合成源技术,采用列式存储格式
- **13:00** - 强调存储成本优化:客户使用 LogsDB 可节省高达 70% 的数据存储成本

### Elastic Streams 核心功能 (13:30 - 17:00)
- **13:30** - 预告即将推出的压缩日志处理器:对重复日志行进行模板化,可再节省 50% 存储空间
- **14:15** - 引入 LLM 后的能力提升:自动提供可操作的洞察,而非手动搜索数据
- **15:00** - 介绍 Streams 的第一步:使用 LLM 自动识别日志来源系统(如 Elasticsearch、Nginx、Hadoop、Spark)
- **15:45** - 自动分区功能:将不同系统的日志发送到专用索引(如 Hadoop 索引、Spark 索引、订单处理索引)
- **16:30** - 展示层级组织结构:支持多层分区(如按 Kubernetes 分组,或按错误/信息日志分离)

### 数据处理流程 (17:00 - 20:30)
- **17:00** - 第二步:从非结构化日志中提取意义,将其结构化以便进行分析
- **18:00** - 第三步:识别重大事件,使用 LLM 分析特定系统(如 Spark)可能遇到的问题类型
- **18:45** - 自动生成查询:定期运行以检测新问题(如内存不足错误)
- **19:15** - 第四步:生成资产,包括仪表板、SLO、可视化
- **19:45** - 利用 Elastic 向量数据库:通过检索增强生成(RAG)技术,将系统信息存储到知识库
- **20:15** - AI 助手集成:在自然语言对话中引用系统信息,加速根因分析

### 架构与集成 (20:30 - 22:30)
- **20:30** - 展示端到端架构图:仍支持现有 Elastic Agent、Logstash 等集成
- **21:00** - 传统方式:使用集成时数据已预先组织,跳过分区步骤
- **21:30** - 新方式:支持 OpenTelemetry Collector、Fluent Bit 等任何工具,直接发送到日志端点
- **22:00** - 强调无需边缘处理:所有处理工作转移到 Elastic 端,简化数据管道

### 现场演示 - 基础功能 (22:30 - 28:00)
- **22:30** - 开始演示:展示 Discover 中的 ESQL 查询,显示完全非结构化的交易日志数据
- **23:15** - 点击"Convert to Streams"按钮,创建新处理器
- **23:45** - 使用"Generate Pattern"功能:AI 自动生成 Grok 模式,识别出股票代码、数量、价格等字段
- **24:30** - 强调使用 OpenTelemetry 语义约定:数据以标准格式存储在 Elastic 中
- **25:15** - 保存更改后返回 Discover,展示结构化后的分析能力
- **25:45** - 演示 ESQL 分析:按云区域汇总交易数量,显示工作负载在各区域均匀分布
- **26:30** - 对比说明:非结构化数据难以进行此类分析,或需手动创建处理管道

### 现场演示 - Streams 新功能 (28:00 - 35:00)
- **28:00** - 切换到新方式:展示直接发送到 logs 索引的数据
- **28:30** - 手动创建分区:创建名为"Spark"的分区,使用字段属性过滤 Spark 日志
- **29:15** - 展示层级结构:logs 顶层索引下出现 Spark 子索引
- **29:45** - 使用"Suggest Partitions with AI"功能:AI 自动识别并分离 Hadoop 和 Spark 日志
- **30:30** - 保存更改后显示完整层级:日志流被分为 Hadoop 和 Spark 两个独立索引
- **31:00** - 对分区后的日志应用处理器:使用 AI 生成 Grok 模式,提取严重性文本
- **31:45** - 确认更改后运行 ESQL 查询,展示更便捷的数据分析能力

### 现场演示 - 问题检测与告警 (35:00 - 38:30)
- **35:00** - 进入 Spark 日志分区,点击"Detect Systems"
- **35:30** - AI 自动添加 Spark 系统的详细描述:包括系统功能和可能遇到的问题类型
- **36:00** - 将系统信息添加到 Streams,生成问题建议列表
- **36:30** - 展示建议列表:Spark 调试事件、Spark 警告、Spark 内存不足异常等
- **37:00** - 使用变更点检测(机器学习技术):监控日志数量的峰值、下降或分布变化
- **37:45** - 创建告警:基于 AI 生成的查询,设置内存不足异常告警
- **38:15** - 强调优势:无需手动创建查询,LLM 对 Spark 系统的了解可能超过人类

### 现场演示 - 数据管理功能 (38:30 - 43:00)
- **38:30** - 展示 Streams UI 简化的保留期和数据质量管理
- **39:00** - 演示保留期设置:快速将 Spark 日志保留期改为 30 天
- **39:30** - 调整 ILM 策略:设置 2 天热存储、30 天温存储,或使用冻结层进一步节省成本
- **40:00** - 介绍数据质量功能:两种类型 - 字段级问题和整个文档失败
- **40:30** - 演示文档失败:故意破坏正则表达式,系统捕获并显示错误详情
- **41:15** - 展示失败存储:显示"提供的 Grok 表达式与字段值不匹配"的错误信息
- **41:45** - 演示字段级问题:创建超长主机名,系统标记为"降级文档"
- **42:30** - 说明处理方式:忽略有问题的主机名字段,但仍摄取文档的其他所有数据

### 总结与展望 (43:00 - 45:00)
- **43:00** - 修复演示中的问题,恢复正常状态
- **43:30** - 总结平台需求:扩展到数十亿日志、成本效益的存储
- **44:00** - 强调简化摄取:无需处理管道、避免数据丢失、尽可能自动化
- **44:30** - AI 的作用:自动化日志处理,让工程师专注于解决问题而非构建管道
- **44:45** - 未来愿景:将 Streams 功能扩展到追踪和指标数据
- **45:00** - 演讲结束,感谢观众从 Venetian 赶来参加会议