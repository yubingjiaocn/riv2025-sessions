# AWS re:Invent 2025 - 使用 Amazon Bedrock 构建 AI 和智能体平台

## 会议概述

本次会议主题为"使用 Amazon Bedrock 构建 AI 和智能体平台"，由 Amazon Bedrock 团队和 Vercel 公司共同呈现。会议重点探讨了从概念验证(POC)到生产环境部署过程中面临的挑战，以及如何利用 Amazon Bedrock 服务构建和管理企业级 AI 平台。

演讲者指出，研究显示平均有 46% 的 AI POC 项目在到达生产环境之前被取消。主要原因包括：平台架构过于静态、难以跟上技术变化的步伐、模型输出的非确定性难以管理、应用可见性不足，以及传统软件开发生命周期无法直接适用于 AI 开发。为解决这些问题，Amazon Bedrock 提供了一个全面的 AI 平台解决方案，涵盖五大支柱：模型、部署与编排、数据基础、安全与治理、以及智能体(Agents)。

会议深入讲解了三个关键领域：模型切换、评估和可观测性。这三个领域相互关联、相互强化，是构建成功 AI 平台的核心要素。Vercel 公司分享了他们如何使用 Bedrock 和自研工具(AI SDK、AI Gateway)快速构建和部署生产级 AI 应用的实践经验，包括 v0 代码生成平台和 Vercel Agent 代码审查工具等产品案例。

## 详细时间线

### 开场介绍 (0:00 - 2:30)
- **0:00** - 会议开始，欢迎参加 re:Invent 2025 第四天
- **0:30** - 介绍演讲团队：Lowry(Bedrock 市场团队)、Julia Bodea(高级技术产品经理)、Dan Ericson(Vercel AI 工程总监)
- **1:00** - 会议议程概览：POC 到生产的挑战、AI 平台支柱、Bedrock 服务介绍
- **1:30** - 三大重点领域：模型切换、评估、可观测性

### POC 到生产的挑战 (2:30 - 6:00)
- **2:30** - 引用研究数据：46% 的 AI POC 项目在生产前被取消
- **3:00** - 分析取消原因：平台过于静态、难以应对变化、非确定性输出管理困难
- **3:30** - 客户反馈的核心问题：可见性不足、传统开发流程不适用
- **4:00** - 展示 AI 平台的复杂性：从简单的模型调用到完整的平台架构
- **5:00** - 介绍 AI 平台的五大支柱：模型、部署编排、数据基础、安全治理、智能体
- **5:30** - 重点介绍 Agent Core：用于大规模构建和部署智能体的工具

### 模型切换 (6:00 - 11:30)
- **6:00** - 核心理念：从第一天起就应该能够轻松切换模型
- **6:30** - Bedrock 的价值主张：提供多种前沿模型(Anthropic、Nova、Llama 等)
- **7:00** - 模型切换的重要性：每年发布数百个新模型、模型生命周期短
- **7:30** - 其他切换原因：区域可用性、成本优化、性能改进、竞争优势
- **8:00** - 模型切换的挑战：没有统一接口、不同模型行为差异大
- **8:30** - 介绍 Converse API：统一接口调用所有 Bedrock 模型
- **9:00** - 介绍多种 API 选项：Invoke API、Responses API、OpenAI Completions SDK
- **9:30** - Converse API 特性：标准化输入输出格式、跨模型提供商一致性
- **10:00** - Strands Agent SDK：模型无关的智能体框架，可轻松切换模型
- **10:30** - Amazon Bedrock Guardrails：统一的安全 AI 策略
- **11:00** - Guardrails 功能：有害内容过滤、PII 编辑、幻觉检测、代码安全检查
- **11:30** - Guardrails 工作原理：输入输出检查、适用于所有模型

### 模型评估 (11:30 - 17:00)
- **11:30** - Julia 接手演讲，介绍评估的重要性
- **12:00** - 评估目标：分析性能、权衡质量成本延迟、监控偏见
- **12:30** - 评估挑战：选择模型、选择指标算法、准备数据集
- **13:00** - 更多挑战：搭建评估基础设施、人工审核、结果综合
- **13:30** - 评估是迭代过程：需要为每个新模型和应用重复
- **14:00** - Bedrock 评估工具概览：LLM as a Judge、自带模型/应用、Agent Core Evaluations
- **14:30** - LLM as a Judge：使用 LLM 评估其他 LLM，替代程序化和人工评估
- **15:00** - 自带推理：可评估任何地方托管的模型和应用
- **15:30** - Agent Core Evaluations 三大优势：实时评分、自定义评估、完全托管
- **16:00** - 13 个内置评估器：正确性、有用性、目标成功率等
- **16:30** - Agent Core Evaluations 工作原理：选择评估器、自动调用最佳模型、提供根因分析

### 可观测性 (17:00 - 22:30)
- **17:00** - 可观测性的重要性：评估系统健康、根因分析、性能监控
- **17:30** - 可观测性三大支柱：日志、指标、追踪
- **18:00** - 可观测性挑战：分散的追踪、评估扩展困难、性能可见性不足
- **18:30** - 解决方案：Amazon CloudWatch 和 Agent Core Observability
- **19:00** - CloudWatch 功能：开箱即用的洞察、统一视图、端到端提示追踪
- **19:30** - 重要提示：模型调用日志默认未启用，需手动开启
- **20:00** - CloudWatch 仪表板：延迟、令牌数、错误计数、工具使用等指标
- **20:30** - CloudWatch Logs Insights：跨日志模式识别和根因分析
- **21:00** - Agent Core Observability 三大优势：端到端视图、实时仪表板、第三方集成
- **21:30** - 支持任何框架：Strands、LangGraph、Crew AI、Vercel AI SDK
- **22:00** - 数据格式：OpenTelemetry 标准格式，可发送到任何工具
- **22:30** - CloudWatch 仪表板功能：360 度视图、自定义属性、高级分析

### Vercel 案例分享 (22:30 - 结束)
- **22:30** - Dan Ericson 介绍 Vercel 和 AI 构建经验
- **23:00** - AI 构建挑战：快速变化、新模型频出、需要深度可见性
- **23:30** - Vercel 简介：开源框架(Next.js)、自驱动基础设施、全球部署
- **24:00** - Vercel 的 AI 理念：从想法到生产的快速路径
- **24:30** - v0 产品介绍：AI 驱动的代码生成平台，通过对话生成应用
- **25:00** - Vercel Agent：代码审查智能体，检查 PR、发现 bug、调查生产异常
- **25:30** - 内部智能体应用：市场团队、财务团队、数据团队的 BI 聊天机器人
- **26:00** - 共同点：所有应用都基于 Amazon Bedrock
- **26:30** - Bedrock 优势：高质量模型、安全合规、可扩展性、快速实验
- **27:00** - Vercel 的秘密武器：AI SDK 和 AI Gateway
- **27:30** - Vercel AI SDK：模型无关的抽象层，统一开发体验
- **28:00** - AI SDK 功能：聊天、智能体、工具调用、流式响应、内置可观测性
- **28:30** - AI Gateway：控制平面，追踪所有模型调用、延迟、成本
- **29:00** - AI Gateway 优势：跨提供商可见性、安全测试新模型、轻松切换
- **29:30** - 从简单智能体到复杂系统的演进...