1
00:00:01,639 --> 00:00:03,539
OK Hello everyone.

2
00:00:03,919 --> 00:00:06,198
Thank you for coming to the session, Lighting Talks

3
00:00:06,198 --> 00:00:07,400
CNS 428.

4
00:00:08,269 --> 00:00:10,390
So my name is Juraj Mahapatra.

5
00:00:10,509 --> 00:00:12,550
I'm the principal specialist solutions architect. I

6
00:00:12,550 --> 00:00:14,750
focus on Amazon Bedrock and Agent Core,

7
00:00:15,269 --> 00:00:17,429
and I focus on startup customers. I've been with AWS

8
00:00:17,429 --> 00:00:19,530
for 6 years, a little bit more than 6 years,

9
00:00:20,068 --> 00:00:22,149
and this aspect of what we're going to talk

10
00:00:22,149 --> 00:00:23,629
about as human in the loop,

11
00:00:24,030 --> 00:00:26,149
it is applicable to all workflows,

12
00:00:26,228 --> 00:00:28,228
microservices, and now we are talking about

13
00:00:28,228 --> 00:00:30,228
gentic systems and why this is useful.

14
00:00:31,239 --> 00:00:32,978
So just a show of hands.

15
00:00:33,478 --> 00:00:35,598
I asked this question before, but how many

16
00:00:35,598 --> 00:00:37,478
of you are using agents in production today?

17
00:00:39,189 --> 00:00:40,649
None. How many of you are using

18
00:00:41,000 --> 00:00:43,149
uh inferencing, LLM influencing in

19
00:00:43,149 --> 00:00:44,418
production today? So most of them.

20
00:00:44,908 --> 00:00:46,389
So what I wanted to show is

21
00:00:47,569 --> 00:00:49,609
How did we evolve from normal

22
00:00:49,609 --> 00:00:50,348
assistance

23
00:00:50,728 --> 00:00:52,810
to actually autonomous agents

24
00:00:52,810 --> 00:00:55,168
and why autonomous agents are important in this era?

25
00:00:56,009 --> 00:00:58,109
And where human in the loop is important to

26
00:00:58,109 --> 00:00:58,740
implement

27
00:00:59,240 --> 00:01:01,679
and how can you implement which

28
00:01:01,679 --> 00:01:03,509
HITL with some of the mechanics,

29
00:01:03,880 --> 00:01:06,159
some of the key takeaways and

30
00:01:06,418 --> 00:01:08,659
a couple of resources that I find very useful

31
00:01:08,659 --> 00:01:09,859
for you. OK,

32
00:01:10,400 --> 00:01:12,400
so as this progression, this is

33
00:01:12,400 --> 00:01:13,058
a timeline

34
00:01:13,638 --> 00:01:15,799
that shows you like how we started with

35
00:01:15,799 --> 00:01:16,540
simple

36
00:01:16,959 --> 00:01:19,319
generative AI assistance and mostly

37
00:01:19,319 --> 00:01:21,000
towards chatbots functionality,

38
00:01:21,359 --> 00:01:23,620
but we slowly evolved over time.

39
00:01:24,239 --> 00:01:26,359
But right now we're talking about all the way in the

40
00:01:26,359 --> 00:01:26,939
right,

41
00:01:27,319 --> 00:01:29,319
where we are talking about agentic AI

42
00:01:29,319 --> 00:01:29,939
systems.

43
00:01:30,549 --> 00:01:32,588
Agentic AI system doesn't mean that it has

44
00:01:32,588 --> 00:01:35,109
to be front-ended by a chatbot,

45
00:01:35,510 --> 00:01:37,909
right? You can invoke agents

46
00:01:37,909 --> 00:01:40,308
asynchronously. Let's say something happened

47
00:01:40,308 --> 00:01:41,430
in your system,

48
00:01:41,750 --> 00:01:43,948
it omitted an event, and you have an

49
00:01:43,948 --> 00:01:44,989
event subscriber

50
00:01:45,359 --> 00:01:47,418
that can go and work with multiple agents,

51
00:01:47,588 --> 00:01:49,750
right? So agents can work

52
00:01:49,750 --> 00:01:51,930
behind the scenes. It doesn't have to be a customer

53
00:01:52,430 --> 00:01:54,250
sitting at the front on a chat board.

54
00:01:55,198 --> 00:01:56,299
So that's where we are

55
00:01:57,088 --> 00:01:59,418
As and when you go right, you will see

56
00:01:59,959 --> 00:02:01,260
we are focusing

57
00:02:01,918 --> 00:02:04,138
higher degree of human oversight

58
00:02:04,439 --> 00:02:06,480
to low degree of human oversight when

59
00:02:06,480 --> 00:02:08,300
you're moving towards autonomous systems.

60
00:02:08,919 --> 00:02:09,899
However,

61
00:02:10,479 --> 00:02:12,479
there is a concept of ownership in every

62
00:02:12,479 --> 00:02:13,080
aspect,

63
00:02:13,360 --> 00:02:15,080
like when you build applications.

64
00:02:16,689 --> 00:02:18,778
And you have agents in place.

65
00:02:19,508 --> 00:02:21,588
When you run them in production and something goes

66
00:02:21,588 --> 00:02:23,770
wrong, you can't blame an agent.

67
00:02:24,069 --> 00:02:26,368
It's the developer or it's the person who

68
00:02:26,710 --> 00:02:27,909
owns that application

69
00:02:28,349 --> 00:02:29,639
has to take the ownership, right?

70
00:02:30,069 --> 00:02:31,050
So that's where

71
00:02:31,319 --> 00:02:33,389
agentic AI with some degree

72
00:02:33,389 --> 00:02:35,649
of human in the loop is very important to

73
00:02:35,909 --> 00:02:38,189
build. So before we jump into

74
00:02:38,189 --> 00:02:40,270
how and when HITL should

75
00:02:40,270 --> 00:02:41,379
be implemented,

76
00:02:41,750 --> 00:02:43,788
I wanted to give you a background of how we

77
00:02:43,788 --> 00:02:45,330
started with model inferencing,

78
00:02:46,028 --> 00:02:48,149
specifically on AWS and where we are

79
00:02:48,149 --> 00:02:48,868
right now.

80
00:02:49,189 --> 00:02:51,270
And that will give a clear picture of why we

81
00:02:51,270 --> 00:02:53,308
should think about human in the loop right

82
00:02:53,308 --> 00:02:55,508
from the very beginning when we build agentic

83
00:02:55,508 --> 00:02:56,229
AI systems.

84
00:02:57,610 --> 00:02:59,659
Couple of years ago, if you have to build,

85
00:02:59,960 --> 00:03:02,159
or if you have to use a model on AWS,

86
00:03:02,599 --> 00:03:04,258
these are the options you had. So

87
00:03:04,879 --> 00:03:06,819
as a user, you'll come, you need a

88
00:03:07,080 --> 00:03:09,659
compute layer where you have to run a model for influencing,

89
00:03:10,038 --> 00:03:12,278
and some of the options for you were Sage Maker.

90
00:03:12,520 --> 00:03:14,020
Today we have Bedrock.

91
00:03:14,778 --> 00:03:16,838
Uh, you can run your model getting from hugging

92
00:03:16,838 --> 00:03:19,000
face, and you can run it on ICS, EC2, or

93
00:03:19,000 --> 00:03:19,558
EKS.

94
00:03:20,469 --> 00:03:22,520
And then this is a simple example of

95
00:03:22,520 --> 00:03:24,750
a chat GPT if you think about it, right? You

96
00:03:24,750 --> 00:03:25,379
have a model,

97
00:03:25,879 --> 00:03:27,960
you can ask questions, you get answers back,

98
00:03:28,159 --> 00:03:28,960
so on and so forth.

99
00:03:29,710 --> 00:03:31,909
Then we evolved into systems where you need

100
00:03:31,909 --> 00:03:33,770
some context or some

101
00:03:34,508 --> 00:03:36,949
history to maintain, to be maintained in that session

102
00:03:36,949 --> 00:03:38,149
or in that discussion

103
00:03:38,508 --> 00:03:40,240
so that you can get better results,

104
00:03:40,710 --> 00:03:42,750
right? That's why we talked about having a

105
00:03:42,750 --> 00:03:43,849
persistent store

106
00:03:45,258 --> 00:03:45,929
where you can

107
00:03:46,469 --> 00:03:48,050
purchase some of the chat history

108
00:03:48,319 --> 00:03:50,349
and then when the LLM is coming back with

109
00:03:50,349 --> 00:03:52,788
a response, it can understand the chat

110
00:03:52,788 --> 00:03:53,909
history and provide a response.

111
00:03:54,909 --> 00:03:56,949
Then we evolved our systems to

112
00:03:56,949 --> 00:03:57,558
build

113
00:03:57,868 --> 00:03:58,929
contextual

114
00:03:59,469 --> 00:04:00,099
responses,

115
00:04:00,389 --> 00:04:02,088
right, with chat history as well.

116
00:04:02,469 --> 00:04:03,449
So now you have.

117
00:04:04,319 --> 00:04:05,270
A user calling

118
00:04:05,569 --> 00:04:06,788
a level of compute

119
00:04:07,330 --> 00:04:08,449
that talks to a model,

120
00:04:08,770 --> 00:04:10,929
but before talking to a model it has to use

121
00:04:10,929 --> 00:04:13,550
a vector store to get additional context

122
00:04:14,288 --> 00:04:16,569
for your organization or anything. This is simple drag.

123
00:04:17,559 --> 00:04:19,699
Get the vector embeddings and

124
00:04:20,000 --> 00:04:22,000
augment that embeddings to the

125
00:04:22,000 --> 00:04:23,819
LLM to get a better response.

126
00:04:24,358 --> 00:04:25,519
So this is where we were.

127
00:04:26,889 --> 00:04:28,309
Excuse me, in this scenario.

128
00:04:29,709 --> 00:04:31,980
All of those contextual data is

129
00:04:31,980 --> 00:04:34,250
mostly static in nature, so I have my

130
00:04:34,250 --> 00:04:35,259
organizational standards,

131
00:04:35,588 --> 00:04:38,139
I want to bring my architectural standards,

132
00:04:38,379 --> 00:04:40,470
and if I want to use that as part of a vector

133
00:04:40,470 --> 00:04:41,730
store, these are all

134
00:04:42,069 --> 00:04:43,629
static data that I have to deal with.

135
00:04:44,358 --> 00:04:46,790
But what if you actually want to leverage

136
00:04:46,790 --> 00:04:48,970
the power of LLMs with real-time

137
00:04:48,970 --> 00:04:51,069
data? Like, that's

138
00:04:51,069 --> 00:04:52,528
where the discussion around

139
00:04:53,040 --> 00:04:53,769
tools

140
00:04:54,069 --> 00:04:55,750
and agents come into the picture,

141
00:04:56,069 --> 00:04:58,160
right? In addition to doing

142
00:04:58,160 --> 00:05:00,149
RAG or LLM inferencing,

143
00:05:00,559 --> 00:05:02,678
if you have to deal with real-time data, you

144
00:05:02,678 --> 00:05:04,259
have to build something like this

145
00:05:04,678 --> 00:05:05,579
with agents

146
00:05:05,920 --> 00:05:07,959
and a bunch of tools that can go out on

147
00:05:07,959 --> 00:05:09,660
your behalf, call an API,

148
00:05:10,119 --> 00:05:11,959
uh, execute a database query,

149
00:05:12,238 --> 00:05:13,819
and get real-time information,

150
00:05:14,199 --> 00:05:16,278
and that information will be augmented to

151
00:05:16,278 --> 00:05:18,579
the context of the last language model

152
00:05:18,910 --> 00:05:19,769
to do some work,

153
00:05:20,160 --> 00:05:21,809
right? Now

154
00:05:22,959 --> 00:05:25,079
this evolves because when you

155
00:05:25,079 --> 00:05:26,959
start building agents and tools,

156
00:05:27,519 --> 00:05:29,798
the very next step comes into the picture is

157
00:05:29,798 --> 00:05:31,410
how can I secure the setup?

158
00:05:31,879 --> 00:05:33,879
How can I get observability, because when you build

159
00:05:33,879 --> 00:05:36,079
APIs or application, you need that observability

160
00:05:36,079 --> 00:05:36,730
in place.

161
00:05:37,079 --> 00:05:39,238
So with agent and tools you will still

162
00:05:39,238 --> 00:05:41,059
need the same observability in practice.

163
00:05:42,369 --> 00:05:44,970
So you need some inbound authentication

164
00:05:44,970 --> 00:05:46,509
on who can call the agents,

165
00:05:47,250 --> 00:05:49,488
outbound authentication on who the agent

166
00:05:49,488 --> 00:05:50,369
can call to.

167
00:05:51,079 --> 00:05:53,439
So on and so forth, and then you need guard rails

168
00:05:53,439 --> 00:05:54,189
around bedrock,

169
00:05:54,608 --> 00:05:56,730
some observability using cloud watch or

170
00:05:56,730 --> 00:05:58,509
third party providers, so on and so forth.

171
00:05:59,319 --> 00:06:01,519
This also evolves when you think about

172
00:06:01,720 --> 00:06:02,540
concepts like.

173
00:06:03,858 --> 00:06:06,250
Right? So we are evolving from

174
00:06:06,250 --> 00:06:08,439
simple LLM influencing to how we are building

175
00:06:08,778 --> 00:06:10,769
agents today with MCP servers.

176
00:06:11,178 --> 00:06:13,798
And if you look at it now, the big picture,

177
00:06:14,379 --> 00:06:15,298
how you do

178
00:06:15,600 --> 00:06:17,699
agents on AWS, it will look

179
00:06:17,699 --> 00:06:18,259
like this.

180
00:06:19,238 --> 00:06:21,259
Which will have agents running on a set of

181
00:06:21,259 --> 00:06:23,428
compute, some memory

182
00:06:23,428 --> 00:06:25,329
that maintains history and long-term memory.

183
00:06:26,769 --> 00:06:29,040
MCP server integrations for external tools

184
00:06:29,040 --> 00:06:30,178
that you want to use

185
00:06:30,639 --> 00:06:32,639
and also A2A integration. If

186
00:06:32,639 --> 00:06:34,858
you know A2A is a protocol that

187
00:06:35,079 --> 00:06:36,019
Google came up with

188
00:06:36,278 --> 00:06:38,278
for agent to agent communication and

189
00:06:38,278 --> 00:06:40,170
while they're doing all of these things,

190
00:06:40,519 --> 00:06:42,519
you need observability with travel

191
00:06:42,519 --> 00:06:43,798
watch or third party tools.

192
00:06:44,709 --> 00:06:47,278
So This is

193
00:06:47,290 --> 00:06:47,988
one agent.

194
00:06:48,879 --> 00:06:51,139
We're talking about capability of one agent

195
00:06:51,139 --> 00:06:53,160
that talks to multiple MCP servers

196
00:06:53,160 --> 00:06:56,009
or tools or or other agents

197
00:06:56,009 --> 00:06:58,160
with some capability of memory and

198
00:06:58,160 --> 00:06:58,798
identity.

199
00:06:59,819 --> 00:07:02,259
However, when you want to run in production,

200
00:07:02,738 --> 00:07:04,920
the actual production scenario will look like this,

201
00:07:05,500 --> 00:07:07,858
right? So you'll have an

202
00:07:07,858 --> 00:07:10,019
agent in your purview, but then

203
00:07:10,019 --> 00:07:12,420
multiple agents in your department, in your

204
00:07:12,420 --> 00:07:14,500
organization, and then you have to integrate with

205
00:07:14,500 --> 00:07:16,309
external tools, so on and so forth.

206
00:07:16,939 --> 00:07:17,639
So you can

207
00:07:18,149 --> 00:07:20,660
imagine the complexity that you have to deal with, the chaos

208
00:07:20,660 --> 00:07:23,079
of this whole setup that you have to deal with,

209
00:07:23,420 --> 00:07:25,548
right? So that's where you

210
00:07:25,548 --> 00:07:28,189
have to figure out like if you build systems,

211
00:07:28,629 --> 00:07:30,629
how and when in which areas that you have

212
00:07:30,629 --> 00:07:32,730
to build human in the loop capabilities.

213
00:07:33,488 --> 00:07:35,559
Right? So you have to

214
00:07:35,559 --> 00:07:36,970
find those checkpoints

215
00:07:37,250 --> 00:07:39,509
where human judgment is very necessary

216
00:07:40,048 --> 00:07:42,209
and if possible, whatever

217
00:07:42,209 --> 00:07:44,028
human insight that was given

218
00:07:44,488 --> 00:07:46,889
goes back to the AI system

219
00:07:46,889 --> 00:07:48,809
so that it can do a better judgment next time.

220
00:07:49,540 --> 00:07:51,160
So what are those points? So,

221
00:07:51,980 --> 00:07:54,449
excuse me. Think about high stakes

222
00:07:54,449 --> 00:07:55,238
decision points.

223
00:07:55,850 --> 00:07:57,889
So I'll take an example. Like if a doctor

224
00:07:57,889 --> 00:08:00,129
has to subscribe prescribe

225
00:08:00,129 --> 00:08:01,809
a medicine to a patient.

226
00:08:02,889 --> 00:08:05,048
You need some intervention and

227
00:08:05,048 --> 00:08:07,329
not rely on the entire agentic system

228
00:08:07,329 --> 00:08:09,528
to build a prescription for the agent, right?

229
00:08:09,608 --> 00:08:10,910
The doctor has to provide

230
00:08:11,369 --> 00:08:13,449
some capabilities to, OK,

231
00:08:13,528 --> 00:08:15,769
this is a good medicine I can prescribe.

232
00:08:16,649 --> 00:08:18,850
Then there will be cases where you

233
00:08:18,850 --> 00:08:20,838
have to deal with irreversible actions.

234
00:08:21,250 --> 00:08:21,869
What if

235
00:08:22,449 --> 00:08:24,528
money gets debited from one account to the other

236
00:08:24,528 --> 00:08:26,329
account, which you cannot undo?

237
00:08:27,238 --> 00:08:28,178
What if you

238
00:08:28,838 --> 00:08:30,858
completed a transaction which you cannot undo?

239
00:08:31,278 --> 00:08:33,500
This is where those are the high touch points

240
00:08:33,719 --> 00:08:35,580
where a human in the loop will be very

241
00:08:36,359 --> 00:08:36,979
influential.

242
00:08:37,989 --> 00:08:40,119
What about regulatory compliance?

243
00:08:40,918 --> 00:08:42,960
There are countries and compliance standards

244
00:08:42,960 --> 00:08:45,269
where a human oversight is always needed.

245
00:08:46,019 --> 00:08:48,379
So finding out those places in the setup,

246
00:08:48,739 --> 00:08:49,798
you will have to

247
00:08:50,190 --> 00:08:52,440
add some checkpoints where a human can come

248
00:08:52,700 --> 00:08:54,739
and provide a decision to move

249
00:08:54,739 --> 00:08:58,080
forward. Most

250
00:08:58,080 --> 00:09:00,158
important part is the trust building phase. So let's say

251
00:09:00,158 --> 00:09:02,239
if you're starting new with agentic

252
00:09:02,239 --> 00:09:02,979
AI,

253
00:09:03,399 --> 00:09:05,719
it will be really good to have human

254
00:09:05,719 --> 00:09:07,418
aspect in the entire setup

255
00:09:07,759 --> 00:09:09,178
so that you are building trust

256
00:09:09,479 --> 00:09:10,330
with the system.

257
00:09:10,808 --> 00:09:12,840
Once you see that the human is actually

258
00:09:12,840 --> 00:09:14,418
repeating the same task

259
00:09:14,798 --> 00:09:17,038
and it has figured out that the AI or the

260
00:09:17,038 --> 00:09:18,580
agent is actually building

261
00:09:19,200 --> 00:09:21,658
what it is supposed to do, then you can slowly

262
00:09:22,158 --> 00:09:24,029
remove the human intervention part out, so.

263
00:09:25,210 --> 00:09:27,308
So this is the trust building part is where

264
00:09:27,690 --> 00:09:29,769
if you're doing a proof of concept, if

265
00:09:29,769 --> 00:09:31,879
you're starting with agents, then it will become

266
00:09:31,879 --> 00:09:32,869
very easy to

267
00:09:33,330 --> 00:09:35,250
start with human in the loop and then go from there.

268
00:09:36,739 --> 00:09:38,639
Plus there will be some edge cases

269
00:09:39,219 --> 00:09:41,298
and some uh uh ambiguity

270
00:09:41,298 --> 00:09:42,840
where you will definitely need

271
00:09:43,379 --> 00:09:44,808
human in the loop, where,

272
00:09:45,279 --> 00:09:46,899
where, wherever it is necessary.

273
00:09:47,219 --> 00:09:49,320
So, going back to the big picture.

274
00:09:50,178 --> 00:09:51,690
There will be areas where you need.

275
00:09:52,798 --> 00:09:55,119
Human in the loop where you're dealing with let's say MCP

276
00:09:55,119 --> 00:09:55,859
server integration

277
00:09:56,769 --> 00:09:59,239
or A2A integration with different agents

278
00:09:59,239 --> 00:10:01,269
or finally when you're sending responses

279
00:10:01,269 --> 00:10:02,099
to the customer,

280
00:10:03,219 --> 00:10:05,469
right, you need some oversight to see whether, OK,

281
00:10:05,989 --> 00:10:06,830
everything is OK

282
00:10:07,239 --> 00:10:09,519
now we should be good to send responses back

283
00:10:09,519 --> 00:10:10,099
to the user

284
00:10:10,519 --> 00:10:12,250
or call it completing a task.

285
00:10:13,489 --> 00:10:14,308
So what are the,

286
00:10:14,969 --> 00:10:16,989
now, now that we talked about where human in the loop

287
00:10:16,989 --> 00:10:17,769
is required,

288
00:10:18,369 --> 00:10:20,529
where are the cases where human in the loop can be

289
00:10:20,529 --> 00:10:22,629
avoided? Like let's say you have a case where

290
00:10:23,168 --> 00:10:23,788
you have

291
00:10:24,048 --> 00:10:24,750
confidence

292
00:10:25,250 --> 00:10:26,649
in the threshold that you have set.

293
00:10:27,389 --> 00:10:29,869
So let's say the agent came up with some

294
00:10:29,869 --> 00:10:31,950
response and the confidence score is

295
00:10:31,950 --> 00:10:32,558
higher.

296
00:10:32,908 --> 00:10:33,889
That's where you can

297
00:10:35,259 --> 00:10:35,950
avoid human being in the loop.

298
00:10:37,038 --> 00:10:39,190
If you maintain high audit trails

299
00:10:39,369 --> 00:10:41,408
and you go through those matrices

300
00:10:41,609 --> 00:10:43,969
and you know that the agent is doing or the multi-agent

301
00:10:43,969 --> 00:10:45,969
system is doing whatever it is supposed to do,

302
00:10:46,330 --> 00:10:48,609
then you can slowly remove the human aspect

303
00:10:48,609 --> 00:10:50,450
from the whole setup.

304
00:10:51,440 --> 00:10:53,440
If you build a feedback loop as I

305
00:10:53,440 --> 00:10:54,759
was talking earlier,

306
00:10:55,450 --> 00:10:57,798
If the human can feed it back to the system,

307
00:10:58,019 --> 00:10:59,389
then eventually

308
00:10:59,769 --> 00:11:02,048
you will tend to removing the human aspect

309
00:11:02,048 --> 00:11:03,090
from the entire setup.

310
00:11:03,820 --> 00:11:06,029
And this will give you a

311
00:11:06,029 --> 00:11:08,168
good process to gracefully degrade.

312
00:11:09,149 --> 00:11:11,428
When human aspects are not required

313
00:11:11,428 --> 00:11:12,710
anymore, right?

314
00:11:13,769 --> 00:11:14,830
So what we're

315
00:11:15,099 --> 00:11:17,668
talking about here is a progressive autonomy.

316
00:11:17,808 --> 00:11:19,849
So you start with the highest level of

317
00:11:19,849 --> 00:11:21,308
control with humans in the place,

318
00:11:21,928 --> 00:11:24,038
but you slowly progress toward getting the

319
00:11:24,038 --> 00:11:26,500
full autonomy when you have built the trust in the system

320
00:11:26,729 --> 00:11:28,570
and for your clients and for your customers.

321
00:11:29,428 --> 00:11:31,639
If you want to build human in the loop aspect,

322
00:11:31,750 --> 00:11:34,090
in the case of MCP, MCP provides

323
00:11:34,389 --> 00:11:36,469
this capability called elicitations. If you look

324
00:11:36,469 --> 00:11:37,529
at this example,

325
00:11:37,989 --> 00:11:39,288
if the request is

326
00:11:39,590 --> 00:11:41,590
what is the flight status, then the MCP

327
00:11:41,590 --> 00:11:43,129
server will ask a question.

328
00:11:43,469 --> 00:11:45,469
Give me a flight number, then I'll be providing you

329
00:11:45,469 --> 00:11:46,408
a flight status.

330
00:11:46,788 --> 00:11:48,820
So this is the core capability of MCP as the

331
00:11:48,820 --> 00:11:50,489
protocol, elicitations.

332
00:11:50,989 --> 00:11:51,548
You can use it.

333
00:11:52,450 --> 00:11:54,509
If you're using step functions as

334
00:11:54,509 --> 00:11:56,239
a service to build workflows,

335
00:11:56,609 --> 00:11:58,950
then step functions has this capability of wait

336
00:11:58,950 --> 00:11:59,869
for callback.

337
00:12:00,779 --> 00:12:03,178
The step functions workflow can wait for you

338
00:12:03,178 --> 00:12:05,178
until an approval or a task

339
00:12:05,178 --> 00:12:07,418
token that is sent back with a success message,

340
00:12:07,779 --> 00:12:09,719
and then it'll go. So this is how it works.

341
00:12:10,259 --> 00:12:12,580
When you ask for a token to be sent externally.

342
00:12:13,479 --> 00:12:15,519
The token will be sent through different applications

343
00:12:15,519 --> 00:12:16,479
or to an approver,

344
00:12:17,038 --> 00:12:18,279
and if the approver says, OK,

345
00:12:18,599 --> 00:12:19,580
everything looks good.

346
00:12:20,570 --> 00:12:21,269
Then

347
00:12:21,570 --> 00:12:23,349
the the token is sent back

348
00:12:23,969 --> 00:12:26,250
and then the step functions will resume the

349
00:12:26,250 --> 00:12:27,349
workflow execution

350
00:12:27,609 --> 00:12:29,029
and it'll go to the next steps.

351
00:12:29,570 --> 00:12:31,690
Now, if you have heard the keynote earlier, we

352
00:12:31,690 --> 00:12:32,629
talked about

353
00:12:32,969 --> 00:12:35,009
durable functions in lambda also,

354
00:12:35,369 --> 00:12:37,450
right? So durable functions will

355
00:12:37,450 --> 00:12:39,649
do the same, uh, similar uh

356
00:12:39,649 --> 00:12:41,769
work what step functions has to provide.

357
00:12:43,340 --> 00:12:45,239
If you're using tools like line graph

358
00:12:45,979 --> 00:12:46,739
for your agents.

359
00:12:48,080 --> 00:12:50,320
Some of the capabilities include like this, you can have

360
00:12:50,320 --> 00:12:51,950
a human aspect

361
00:12:52,529 --> 00:12:54,639
if a response is coming back from LLM

362
00:12:54,639 --> 00:12:57,469
and the human can approve, if it approves,

363
00:12:57,889 --> 00:12:59,928
then it goes to node B or

364
00:12:59,928 --> 00:13:01,739
the graph node B or A,

365
00:13:02,330 --> 00:13:04,269
and then it goes to graph node C if

366
00:13:05,048 --> 00:13:06,009
there is a disapproval.

367
00:13:07,580 --> 00:13:10,178
You can change the state behind the scenes

368
00:13:10,178 --> 00:13:12,460
if a human is in place. So if a human says,

369
00:13:12,779 --> 00:13:14,340
I'm getting an input which says F bar,

370
00:13:15,070 --> 00:13:16,320
now I want to change that

371
00:13:16,690 --> 00:13:17,239
to

372
00:13:17,538 --> 00:13:19,960
bars, and then the next node will get

373
00:13:20,418 --> 00:13:22,580
the latest updated value for the

374
00:13:22,580 --> 00:13:23,519
underlying state.

375
00:13:24,019 --> 00:13:26,168
So these are, these are the ways where a human can

376
00:13:26,168 --> 00:13:26,960
intervene

377
00:13:27,259 --> 00:13:27,879
and

378
00:13:28,379 --> 00:13:30,460
change the course of action that the agent was supposed

379
00:13:30,460 --> 00:13:32,639
to take. The last one is a human

380
00:13:32,639 --> 00:13:34,668
can intervene and say whether I want to execute a

381
00:13:34,668 --> 00:13:36,678
tool or I don't want to, or should I

382
00:13:36,678 --> 00:13:37,859
execute a different tool.

383
00:13:38,279 --> 00:13:39,279
This is in Landgraf.

384
00:13:41,288 --> 00:13:43,889
If you're building interagent communications with MCP

385
00:13:43,889 --> 00:13:45,889
and A2A, then there

386
00:13:45,889 --> 00:13:48,168
are other capabilities. So if you take about

387
00:13:48,168 --> 00:13:49,798
an example of a travel agent,

388
00:13:50,288 --> 00:13:52,330
here is an example which I built using API

389
00:13:52,330 --> 00:13:54,450
gateway, and A2A is the protocol,

390
00:13:54,489 --> 00:13:56,548
which is A2A client in a lambda function,

391
00:13:57,250 --> 00:13:59,269
calls a weather agent, which is again

392
00:14:00,219 --> 00:14:02,259
API gate an API gateway with A2A

393
00:14:02,259 --> 00:14:03,599
server behind the scenes,

394
00:14:03,928 --> 00:14:06,288
and the A2A server sends a push notification

395
00:14:06,288 --> 00:14:08,219
back to travel agents saying

396
00:14:08,529 --> 00:14:09,788
what is the weather right now.

397
00:14:10,340 --> 00:14:11,918
At this point in time I can

398
00:14:13,210 --> 00:14:14,830
Put some HITL

399
00:14:15,298 --> 00:14:17,690
aspect of it, either using step functions

400
00:14:17,690 --> 00:14:18,750
or other capabilities,

401
00:14:19,250 --> 00:14:21,450
and then I feedback that information to a state

402
00:14:21,450 --> 00:14:23,509
that the lambda can use, the

403
00:14:23,509 --> 00:14:25,769
ATA client can use, or I can send responses

404
00:14:25,769 --> 00:14:27,048
back directly to the user.

405
00:14:28,058 --> 00:14:29,229
So this is another example.

406
00:14:30,590 --> 00:14:31,250
So now

407
00:14:32,210 --> 00:14:33,599
The other aspect of

408
00:14:34,298 --> 00:14:36,379
I talked about is when human in the loop

409
00:14:36,379 --> 00:14:37,349
will slowly

410
00:14:37,690 --> 00:14:39,950
go away when you're building autonomous systems, right?

411
00:14:40,450 --> 00:14:42,609
So as continuous

412
00:14:42,609 --> 00:14:44,469
agent evaluation grows,

413
00:14:44,808 --> 00:14:47,210
you will see the human in the loop aspect will slowly

414
00:14:47,210 --> 00:14:49,509
reduce. Now if you've heard the keynote,

415
00:14:49,899 --> 00:14:51,928
we talked about agent core

416
00:14:51,928 --> 00:14:53,750
evaluations in preview mode.

417
00:14:54,330 --> 00:14:56,440
So that is if you're running agents on

418
00:14:56,440 --> 00:14:57,229
agent core,

419
00:14:57,570 --> 00:14:59,649
then agent core evaluation is something that

420
00:14:59,649 --> 00:15:00,590
you can use.

421
00:15:01,019 --> 00:15:03,269
To make sure that you get more autonomy

422
00:15:03,269 --> 00:15:04,509
and less human intervention.

423
00:15:05,239 --> 00:15:07,279
So as and when you see

424
00:15:07,279 --> 00:15:08,298
the evaluation

425
00:15:08,599 --> 00:15:10,678
maturity grows, the percentage grows

426
00:15:10,678 --> 00:15:11,590
in the x axis,

427
00:15:11,960 --> 00:15:13,759
your human in the loop aspect will grow down.

428
00:15:15,759 --> 00:15:18,099
So overall what we're talking

429
00:15:18,099 --> 00:15:18,619
about

430
00:15:18,960 --> 00:15:19,570
is

431
00:15:21,408 --> 00:15:23,440
When you want human oversight, and you will need

432
00:15:23,440 --> 00:15:25,658
it in different places, that's where

433
00:15:25,658 --> 00:15:27,899
you need those critical decision gatekeeping

434
00:15:27,899 --> 00:15:28,759
capabilities.

435
00:15:29,548 --> 00:15:30,739
That's where you need humans.

436
00:15:31,379 --> 00:15:33,658
If you have workflows that build

437
00:15:33,658 --> 00:15:35,899
and have errors that you have to recover

438
00:15:35,899 --> 00:15:38,340
from, you can have a human insight

439
00:15:38,340 --> 00:15:40,340
or human presence in the place to

440
00:15:40,340 --> 00:15:42,340
provide you some capabilities to recover from

441
00:15:42,340 --> 00:15:43,019
those errors.

442
00:15:43,908 --> 00:15:46,149
You want to build trust and transparency. I talked

443
00:15:46,149 --> 00:15:47,678
about this progressive autonomy, right?

444
00:15:48,029 --> 00:15:49,210
You start with

445
00:15:50,038 --> 00:15:52,229
human controls, and as and when you grow and

446
00:15:52,229 --> 00:15:54,239
mature in your agenttic setup or multi-agent

447
00:15:54,239 --> 00:15:56,428
setup, you can build the

448
00:15:56,428 --> 00:15:58,950
trust and the transparency, plus

449
00:15:58,950 --> 00:16:01,029
having those agent evaluations in place

450
00:16:01,029 --> 00:16:01,590
will help you.

451
00:16:02,279 --> 00:16:04,849
And then most importantly, gracefully degradation,

452
00:16:04,969 --> 00:16:06,109
so things break

453
00:16:06,489 --> 00:16:07,288
in production

454
00:16:07,609 --> 00:16:10,048
and our CTO also mentioned that in

455
00:16:10,048 --> 00:16:12,250
multiple keynotes that things

456
00:16:12,250 --> 00:16:13,029
will break

457
00:16:13,649 --> 00:16:15,649
if you have a capability to fall

458
00:16:15,649 --> 00:16:17,308
back and gracefully degrade.

459
00:16:17,769 --> 00:16:19,879
Why not have a human in the

460
00:16:19,879 --> 00:16:20,649
whole set up

461
00:16:20,928 --> 00:16:21,590
so that

462
00:16:22,369 --> 00:16:24,389
the trustworthiness will still be alive

463
00:16:24,529 --> 00:16:26,529
and the human can decide how to degrade this

464
00:16:26,529 --> 00:16:28,168
whole setup gracefully.

465
00:16:29,288 --> 00:16:31,408
So, there are some resources here.

466
00:16:31,529 --> 00:16:33,649
The QR code will have all the information.

467
00:16:34,168 --> 00:16:36,389
This is the blog that I wrote on

468
00:16:36,389 --> 00:16:38,629
uh Agent AI using AWS Servius.

469
00:16:39,580 --> 00:16:41,928
There are some technical papers, most importantly,

470
00:16:41,940 --> 00:16:43,529
the one from Harvard.

471
00:16:44,288 --> 00:16:46,450
That talks about the human algorithm

472
00:16:46,450 --> 00:16:47,229
Centaur.

473
00:16:47,558 --> 00:16:49,580
The concept of a centaurian system,

474
00:16:49,798 --> 00:16:51,678
which is half human and half horse

475
00:16:52,190 --> 00:16:53,038
is well

476
00:16:54,558 --> 00:16:56,599
mentioned here in this Howard paper, so I

477
00:16:56,599 --> 00:16:58,418
would encourage you to go read that

478
00:16:58,879 --> 00:17:01,080
and how eventually we should move

479
00:17:01,080 --> 00:17:03,129
towards building that Centaurion system

480
00:17:03,519 --> 00:17:05,549
so that the human and the machines or

481
00:17:05,549 --> 00:17:07,680
the AI agents will symbiotically

482
00:17:07,680 --> 00:17:09,338
work properly together

483
00:17:09,759 --> 00:17:11,019
without hampering each other.

484
00:17:12,410 --> 00:17:14,559
It's a sample application and then in the GitHub

485
00:17:14,559 --> 00:17:16,269
that I built uh using

486
00:17:16,650 --> 00:17:18,709
the lambda functions example that I showed,

487
00:17:19,170 --> 00:17:21,608
a travel agent and weather agent which uses A2A

488
00:17:21,608 --> 00:17:22,608
client and server.

489
00:17:23,009 --> 00:17:25,250
You can definitely check that out and

490
00:17:25,410 --> 00:17:26,910
add a human in the loop aspect.

491
00:17:27,368 --> 00:17:29,229
So, yep, this

492
00:17:29,650 --> 00:17:31,140
is the lightning talk for you,

493
00:17:31,539 --> 00:17:33,689
and if you have questions, we can head

494
00:17:33,689 --> 00:17:35,439
down and we can discuss more,

495
00:17:35,969 --> 00:17:36,750
but uh.

496
00:17:37,239 --> 00:17:38,880
The resources are here to check out.

497
00:17:39,289 --> 00:17:41,529
There are resources in the QR code.

498
00:17:41,650 --> 00:17:43,769
It also talks about different sessions that I did

499
00:17:43,769 --> 00:17:46,068
earlier around Agent EKI and AWS Servius.

500
00:17:46,930 --> 00:17:47,949
So please check them out.

501
00:17:48,568 --> 00:17:49,199
And with that,

502
00:17:49,489 --> 00:17:50,390
thank you everyone

503
00:17:50,769 --> 00:17:51,410
for being here.

