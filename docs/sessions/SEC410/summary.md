# AWS re:Invent 2025 AI安全会议总结

## 会议概述

本次会议是AWS re:Invent 2025的一场400级高级AI安全专题讲座，由AWS首席合作伙伴解决方案架构师Riggs Goodman和专注于AWS行业客户的首席安全解决方案架构师Jason Garman主讲。会议深入探讨了如何使用AWS原生功能、开源框架等技术来保护AI工作负载的安全。

讲座采用分阶段的结构化方式，根据构建不同AI工作负载的阶段来确定相应的安全策略，涵盖工具、代理、数据源等各个方面。演讲者通过API调用和代码示例来拆解"黑盒"，帮助听众从安全角度理解Amazon Bedrock、AgentCore、Strands等AWS托管服务的工作原理。整个会议强调了一个核心原则：在模型外部实施安全控制，而不是依赖大语言模型本身来执行安全策略。

## 详细时间线与关键要点

### 0:00-10:00 会议开场与基础概念
- 介绍演讲者背景和会议结构
- 解释分阶段方法论的原因
- 介绍AgentCore服务及其组件（Runtime、Memory、Identity、Gateway）
- 强调这是400级深度技术会议，将通过API调用和代码来解析黑盒

### 10:00-20:00 第一阶段：基础LLM架构
- 展示最基本的生成式AI应用架构（应用程序直接与LLM交互）
- 详细解析Amazon Bedrock的底层架构：VPC私有端点、安全组、角色权限
- 介绍传统安全控制：DDoS防护、WAF、身份验证、CloudWatch、CloudTrail、GuardDuty
- 强调80%的AI工作负载安全仍是传统安全，20%需要特殊考虑

### 20:00-30:00 大语言模型深度解析
- 解释LLM的工作原理：复杂数学运算、词汇关联、token预测
- 强调LLM架构中不存在身份认证机制
- 讨论微调模型的安全考虑
- 介绍Amazon Bedrock Converse API的使用方式
- 提出核心安全原则：数据到达模型前必须经过授权

### 30:00-40:00 Amazon Bedrock Guardrails
- 介绍Guardrails的功能：拒绝特定主题、内容过滤、敏感信息过滤、词汇过滤
- 强调Guardrails专注于负责任AI而非安全
- 演示prompt注入防护示例
- 解释确定性控制与非确定性控制的区别
- 总结基础层的四个关键点：LLM非确定性、无法过滤特定数据、无连续训练、无内置授权

### 40:00-50:00 第二阶段：数据源安全
- 介绍四种数据源：上下文工程、向量数据库/知识库、工具、记忆
- 详细解析检索增强生成（RAG）的工作流程：索引、分块、向量化、查询
- 介绍元数据在向量数据库中的应用和限制
- 演示魔法学校防御咒语的实际案例
- 讨论权限管理的四种架构模式：统一授权、检索后过滤、按用户/组分离、检索前元数据过滤

### 50:00-61:00 工具安全与代理架构
- Jason接手讲解工具定义和安全影响
- 介绍模型上下文协议（MCP）的标准化作用
- 详细解析OAuth在MCP中的应用：双腿OAuth vs 三腿OAuth
- 介绍AgentCore Identity服务
- 解释代理循环（agentic loop）的工作原理
- 对比多代理工作流与单代理设计的优缺点
- 介绍Strands Agent SDK和人工干预机制
- 总结核心安全原则：在模型外部放置安全控制，使用身份验证进行工具调用