# AWS re:Invent 2025 - AI 安全会议总结

## 会议概述

这是一场关于 AWS 人工智能安全的 400 级高级技术会议，由 AWS 的两位首席解决方案架构师 Rick Goodman 和 Jason Garmin 主讲。会议深入探讨了如何使用 AWS 原生功能、开源框架等技术来保护 AI 工作负载的安全。

会议的核心观点是：**大约 80% 的 AI 工作负载安全措施是传统安全控制，而剩余 20% 需要针对 AI 特性进行特殊考虑**。演讲者通过 API 调用和代码示例，深入剖析了大语言模型（LLM）、Agent、工具（Tools）等"黑盒"的工作原理，帮助听众从安全角度理解这些技术。

会议将 AI 安全分为多个阶段进行讲解，包括基础层（LLM 本身）、数据源层（RAG、向量数据库、记忆系统）和工具层（MCP 协议）。最重要的安全原则是：**在模型外部实施安全控制，而不是依赖 LLM 本身来执行安全策略**，因为 LLM 不具备身份认证和授权机制，且其输出是非确定性的。

## 详细时间线

### 开场与会议介绍 (00:00 - 03:30)
- **00:00** - 会议开始，讲师询问参会者参加 re:Invent 的次数
- **01:15** - Rick Goodman 自我介绍，AWS 首席合作伙伴解决方案架构师，专注于 AI 安全
- **01:35** - Jason Garmin 自我介绍，AWS 首席安全解决方案架构师，专注于行业客户
- **02:00** - 介绍会议结构：按不同阶段划分，包含思考问题和 QR 码链接
- **03:00** - 强调这是 400 级会议，将通过 API 调用和代码深入讲解

### 第一阶段：基础层 - LLM 安全 (03:30 - 15:00)
- **03:30** - 介绍 Amazon Bedrock Agent Core 服务
- **04:45** - 展示基础架构：应用程序与 LLM 的交互
- **05:30** - 深入讲解架构细节：VPC、私有端点、安全组、IAM 角色等传统安全控制
- **07:00** - 核心问题：LLM 内部没有身份认证机制
- **08:15** - 详细解释 LLM 工作原理：复杂的矩阵运算和 token 预测
- **09:00** - 强调 LLM 不是数据库，没有行、列、表的概念
- **10:00** - 讨论模型微调（Fine-tuning）的安全隐患
- **11:00** - 介绍 Converse API 及其使用方式
- **12:30** - 关键原则：到达模型的数据必须经过用户或 Agent 的授权
- **13:45** - 介绍 Amazon Bedrock Guardrails：负责任 AI 的工具
- **14:30** - Guardrails 功能：主题拒绝、内容过滤、敏感信息过滤、词汇过滤

### 第一阶段总结 (15:00 - 17:00)
- **15:00** - 总结要点：LLM 是功能性非确定性的
- **15:30** - 无法从 LLM 中过滤特定数据
- **16:00** - 模型不进行持续训练
- **16:30** - 核心结论：模型内部不存在授权机制

### 第二阶段：数据源安全 (17:00 - 32:00)
- **17:00** - 介绍数据源的多种来源
- **17:45** - 上下文工程（Context Engineering）：通过添加上下文影响 LLM 响应
- **19:00** - 检索增强生成（RAG）详解
- **20:00** - RAG 索引过程：文档分块、向量化、存储
- **21:30** - RAG 查询过程：用户查询转换为嵌入向量，进行相似度搜索
- **23:00** - 元数据（Metadata）的作用：为文档添加键值对进行过滤
- **24:00** - 重要限制：元数据应用于整个文档，而非单个分块
- **25:00** - 魔法学校示例：使用元数据过滤防御咒语
- **27:00** - RAG 权限管理的重要性
- **28:00** - 四种权限架构模式：
  - 所有用户授权访问
  - 检索后过滤（Post-retrieval filtering）
  - 每用户/每组向量数据库
  - 检索前元数据过滤
- **30:00** - 记忆系统（Memory）介绍
- **30:45** - 短期记忆 vs 长期记忆
- **31:30** - 记忆命名空间（Memory Namespaces）用于数据隔离

### 第二阶段总结 (32:00 - 33:30)
- **32:00** - 数据源可来自多个地方：查询、系统提示、RAG、记忆、工具
- **33:00** - 核心原则重申：授权必须在数据到达 LLM 之前完成

### 第三阶段：工具（Tools）安全 (33:30 - 48:00)
- **33:30** - Jason 接手讲解工具部分
- **34:00** - 工具定义：让 AI 应用执行操作（控制浏览器、写文件、调用 API）
- **35:00** - 工具定义结构：名称、描述、参数
- **36:30** - 关键点：LLM 从不直接与工具交互，只生成工具调用请求
- **37:30** - 工具定义示例：加法工具
- **39:00** - Converse API 中的工具配置
- **40:30** - LLM 响应工具调用请求，而非直接返回答案
- **42:00** - 应用程序负责执行工具调用并实施安全策略
- **43:30** - 多轮对话：将所有上下文传递给 LLM
- **45:00** - 模型上下文协议（MCP）介绍
- **46:00** - MCP 架构：客户端-服务器模式
- **47:00** - MCP 请求流程：应用启动时查询工具定义

### 会议结束
- **48:00** - 字幕内容在此处截断

## 核心安全原则

1. 在模型外部实施安全控制 - LLM 不具备身份认证和授权能力
2. 授权先于模型 - 所有发送到 LLM 的数据必须预先授权
3. 传统安全仍然重要 - 80% 的安全措施是传统控制（IAM、VPC、安全组等）
4. 应用程序负责安全 - 工具调用的安全检查由应用程序执行，而非 LLM