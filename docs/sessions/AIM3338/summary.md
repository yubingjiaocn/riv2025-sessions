# AWS re:Invent 2025 - Amazon SageMaker HyperPod 无检查点与弹性训练

## 会议概述

本次技术分享会重点介绍了 Amazon SageMaker HyperPod 的两项突破性功能：弹性训练（Elastic Training）和无检查点训练（Checkpointless Training）。演讲者包括 SageMaker HyperPod 团队的高级产品经理 Anurudh Vishnu 和首席工程师 Arun Nagarajan，以及来自 Salesforce AI 研究团队的 Antonio，他分享了作为 HyperPod 用户近两年的实践经验。

会议首先介绍了 Amazon SageMaker HyperPod 作为专为基础模型训练和部署而构建的基础设施服务，能够自动处理集群创建和环境管理的繁重工作。随着 AI 集群规模从数百个加速器扩展到数十万个加速器，故障概率显著增加。在拥有 1000 个节点的集群中，每 4-5 小时就可能发生一次故障，导致大量计算资源在恢复过程中闲置。传统的基于检查点的恢复机制需要回滚到上一个保存点，重做已完成的工作，造成时间和成本的浪费。

两项新功能从根本上解决了这些挑战：弹性训练允许训练作业根据可用集群容量动态扩展或缩减，无需手动干预；无检查点训练则将故障恢复时间从数小时缩短到几分钟以内，在拥有 2000+ GPU 的集群上实现了 95% 以上的有效利用率。这些创新使 Amazon Nova 模型能够在数千个 AI 加速器上高效训练，为客户节省了数百万美元的训练成本。

## 详细时间线

### 开场介绍 (0:00-2:30)
- **0:00** - 会议开始，Anurudh Vishnu 介绍自己是 Amazon SageMaker HyperPod 团队的高级产品经理，专注于大规模分布式训练和框架级优化
- **0:30** - Arun Nagarajan 自我介绍，担任 Amazon SageMaker AI 团队首席工程师，为包括 HyperPod 在内的多个产品提供技术领导
- **1:00** - 特邀嘉宾 Antonio 来自 Salesforce AI 研究团队，已使用 HyperPod 近两年
- **1:30** - 介绍会议议程：HyperPod 概述、大规模训练背景、弹性训练、无检查点训练、Salesforce 案例分享

### Amazon SageMaker HyperPod 概述 (2:30-5:00)
- **2:30** - HyperPod 提供专为基础模型训练和部署构建的基础设施
- **3:00** - 核心优势：极高的弹性训练环境，主动对每个节点进行健康检查
- **3:30** - 支持单脊拓扑（single spine topology）实现最佳训练吞吐量
- **4:00** - 支持多种实例类型，包括最新的 GPU 和 Trainium 加速器
- **4:30** - 架构说明：支持 Amazon EKS 或 Slurm 编排，兼容 PyTorch、TensorFlow、Nemo 等框架

### 大规模模型训练的挑战 (5:00-9:00)
- **5:00** - 展示 Epoch AI 数据：过去十年集群规模增长了 20 倍，从数百个加速器增长到数十万个
- **6:00** - 关键图表分析：集群规模越大，故障概率越高
- **6:30** - 1000 节点集群（8000 GPU）在 0.2% 故障率下，每 4-5 小时会发生一次故障
- **7:00** - 每次故障恢复可能需要一小时，意味着每天有 4-5 小时的闲置时间
- **7:30** - 传统检查点恢复流程：回滚到上次保存点，重做步骤，然后恢复训练
- **8:00** - 第二个挑战：集群利用率不足，特别是在夜间和周末存在大量闲置容量
- **8:30** - 推理工作负载的昼夜模式导致集群利用率波动

### 弹性训练功能介绍 (9:00-15:00)
- **9:00** - 弹性训练解决基础设施利用率不足的问题
- **9:30** - 当前挑战：训练作业从开始到结束使用固定数量的节点
- **10:00** - 扩展或缩减需要停止作业、重新配置超参数、然后恢复
- **10:30** - 弹性训练允许作业根据可用容量自动扩展和缩减
- **11:00** - 简化运维：无需手动监控集群和重新配置参数
- **11:30** - 保持训练收敛性：确保全局批次大小在整个训练过程中保持恒定
- **12:00** - 动画演示：作业从 4 节点扩展到 8 节点，再到 12 节点
- **12:30** - 当高优先级工作负载需要资源时，从 12 节点缩减到 8 节点
- **13:00** - 关键观察：尽管节点数量波动，损失函数持续下降
- **13:30** - 可通过 HyperPod recipes 或自定义脚本轻松开始使用

### 弹性训练技术架构 (15:00-22:00)
- **15:00** - Arun 介绍弹性训练的技术架构
- **15:30** - 四个关键特性：持续集群监控、优雅抢占、自动训练栈重配置、自动工作负载管理
- **16:00** - 持续集群监控：当新资源可用时发送扩展通知
- **16:30** - 优雅抢占：低优先级作业可以部分释放资源而不是完全终止
- **17:00** - 这是游戏规则改变者：低优先级作业继续运行，集群利用率保持高位
- **17:30** - 自动训练栈重配置：根据世界大小自动调整训练参数
- **18:00** - 用户可以指定扩展策略，SageMaker 自动应用参数
- **18:30** - 自动工作负载管理：与 HyperPod 任务治理系统协同工作
- **19:00** - 端到端扩展流程：系统监控资源变化
- **19:30** - 发送同步协调信号给所有训练进程
- **20:00** - 训练进程保存检查点
- **20:30** - 操作器终止并使用新配置重启训练进程
- **21:00** - 训练进程加载检查点、重新配置并继续训练
- **21:30** - 整个过程只需几秒钟完成

### 弹性训练入门指南 (22:00-25:00)
- **22:00** - 使用标准架构（Llama、Qwen、DeepSeek）可以零代码更改开始
- **22:30** - 只需提供数据并设置最小和最大节点数
- **23:00** - 使用 kubectl 命令或 HyperPod CLI 启动训练
- **23:30** - HyperPod recipes 处理所有繁重工作
- **24:00** - 自定义训练脚本需要更多配置
- **24:30** - 需要在作业规范中提供弹性扩展策略
- **25:00** - 需要导入弹性事件处理器并处理操作器发送的事件

### 弹性训练实际效果 (25:00-27:00)
- **25:00** - 演示弹性扩展作业的可视化
- **25:30** - 世界大小从 1 变化到 2 到 8
- **26:00** - 每秒令牌数紧密跟随可用的世界大小
- **26:30** - 损失持续下降，训练作业未中断
- **27:00** - 弹性训练标志着 AI 基础设施思维方式的根本转变

### 无检查点训练功能介绍 (27:00-32:00)
- **27:00** - Anurudh 介绍无检查点训练，在 Swami 主题演讲中宣布
- **27:30** - 核心挑战：基于检查点的恢复导致训练期间的闲置时间
- **28:00** - 恢复过程是一系列阻塞和顺序的事件
- **28:30** - 步骤包括：检测故障、重新初始化通信、重新加载检查点、重新加载数据加载器
- **29:00** - 在大型集群上，这意味着数百万美元的计算资源在恢复期间浪费
- **29:30** - 无检查点训练将恢复时间从数小时降至几分钟以内
- **30:00** - 加速恢复时间意味着更快上市
- **30:30** - 长时间运行的训练工作负载可能在恢复操作上花费数天时间
- **31:00** - 故障恢复完全自动化，无需手动开销
- **31:30** - 无需回滚到上次保存的检查点即可保持持续训练进度

### 检查点恢复对比 (32:00-35:00)
- **32:00** - 对比传统检查点恢复与无检查点训练的可视化
- **32:30** - 节点 7 发生故障的场景
- **33:00** - 传统方法：顺序重新初始化每个节点，需要几分钟
- **33:30** - 然后重新加载上次保存的检查点
- **34:00** - 重新加载数据加载器，然后恢复训练
- **34:30** - 整个恢复操作可能需要数十分钟到一小时
- **35:00** - 无检查点训练可以在几分钟内恢复

### 无检查点训练性能数据 (35:00-38:00)
- **35:00** - Amazon Nova 模型使用此功能在数千个 AI 加速器上训练
- **35:30** - 在 2000+ GPU 集群上进行内部测试
- **36:00** - 传统恢复：15-30 分钟；无检查点训练：不到 2 分钟
- **36:30** - 故障恢复能力提升 80%
- **37:00** - 在较小集群（16-256 GPU）上也有类似结果
- **37:30** - 传统恢复约 5 分钟，无检查点训练不到 1 分钟
- **38:00** - 在数千个加速器的集群上实现 95% 以上的有效利用率

### 成本节省分析 (38:00-40:00)
- **38:00** - 2300 GPU 集群的实际案例
- **38:30** - 为期两个月的训练运行
- **39:00** - 传统检查点恢复开销累计可达数天
- **39:30** - 无检查点训练将其降至几分钟
- **40:00** - 在训练运行期间节省数百万美元的训练成本

### 无检查点训练技术架构 (40:00-48:00)
- **40:00** - Arun 介绍无检查点训练的四个关键创新
- **40:30** - 第一：优化的集合通信初始化
- **41:00** - 分布式系统中的进程需要相互通信
- **41:30** - 传统的集中式协调系统在数千个进程时成为瓶颈
- **42:00** - 通过 HyperPod 信号转向点对点连接建立
- **42:30** - 将初始化时间从分钟级降至秒级
- **43:00** - 第二：内存映射数据加载
- **43:30** - 训练进程需要在开始训练前预处理数据
- **44:00** - 预处理可能需要几分钟，每次故障都要重复
- **44:30** - 使用共享内存和内存映射文件的缓存解决
- **45:00** - 训练进程恢复时可以立即访问预处理数据
- **45:30** - 第三：进程内恢复
- **46:00** - 传统系统需要终止整个作业并重启所有进程
- **46:30** - 新系统用热备用进程替换故障进程
- **47:00** - 健康进程保持其状态不变
- **47:30** - 第四：无检查点恢复本身

### 无检查点恢复机制 (48:00-50:00)
- **48:00** - 新加入的训练进程不从检查点加载
- **48:30** - 而是直接从其他健康进程通过高速网络补充内存
- **49:00** - 训练中断时间大幅减少
- **49:30** - 这就是实现亚分钟级恢复和 95% 有效利用率的方式
- **50:00** - 即使在大规模集群上也能保持高性能

### 无检查点训练入门指南 (50:00-54:00)
- **50:00** - 两种入门方式：HyperPod recipes 和自定义路径
- **50:30** - 使用标准架构可以通过 recipes 开始
- **51:00** - Recipes 处理所有繁重工作：设置操作器、集合通信优化、内存映射数据加载器
- **51:30** - 这是大多数团队最快的采用路径
- **52:00** - 自定义训练代码有增量采用路径
- **52:30** - 每个组件都已模块化，可以逐步采用
- **53:00** - 第一个组件：优化的集合通信初始化，只需设置环境变量
- **53:30** - 第二个组件：内存映射数据加载器，使用提供的库包装器

### 高级组件采用 (54:00-57:00)
- **54:00** - 进程内恢复和无检查点恢复组件需要更多改动
- **54:30** - 需要将 PyTorch 训练代码的策略更改为 HyperPod 指定的无检查点策略
- **55:00** - 指示框架使用重启无关检查点而非经典检查点
- **55:30** - 需要用 HyperPod 包装器注解包装训练循环
- **56:00** - 包装器处理健康检查和与 HyperPod PyTorch 操作器的协调
- **56:30** - 从健康对等节点重新补充状态的复杂握手由这两个更改处理
- **57:00** - 总结：消除了传统分布式训练系统中的框架级限制和瓶颈

### Salesforce 案例分享 (57:00-结束)
- **57:00** - Tony 介绍 Salesforce 作为 HyperPod 客户超过两年的经验
- **57:30** - 工作负载非常异构：标准 LLM 训练、多模态处理（语音和图像）
- **58:00** - 大量微调和强化学习作业，这些是高容量、短期作业
- **58:30** - 批量推理作业在不同时间段以不同规模运行
- **59:00** - 无检查点和弹性训练帮助轻松管理这种异构性
- **59:30** - 深入批量推理：使用 SGLANG 开源服务框架
- **60:00** - 架构：JavaScript 在头节点上进行负载均衡
- **60:30** - 每个工作节点运行简单的 SGLANG 服务器
- **61:00** - 所有工作节点通过分布式文件系统或 S3 连接