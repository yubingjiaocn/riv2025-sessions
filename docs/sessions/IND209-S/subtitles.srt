1
00:00:00,000 --> 00:00:01,110
- My name is Chris Joynt.

2
00:00:01,110 --> 00:00:04,410
I'm from Securiti AI, an AWS partner,

3
00:00:04,410 --> 00:00:06,000
and I'm going to talk to
you today a little bit

4
00:00:06,000 --> 00:00:09,930
about how leveraging Graph
Insights can help you turbocharge

5
00:00:09,930 --> 00:00:13,230
your deployment of Amazon Q for business.

6
00:00:13,230 --> 00:00:17,610
Now, we all know, of course,
AI is disrupting everything.

7
00:00:17,610 --> 00:00:20,160
It's disrupting how work is
done, how we build value,

8
00:00:20,160 --> 00:00:21,393
how we deliver value.

9
00:00:22,380 --> 00:00:24,150
I think a lot of us would agree,

10
00:00:24,150 --> 00:00:27,420
if we've been in the
IT sector for a while,

11
00:00:27,420 --> 00:00:30,900
we've probably never seen
anything like this before, right?

12
00:00:30,900 --> 00:00:34,320
More hype, more
capability, more, you know,

13
00:00:34,320 --> 00:00:37,500
everything happening kind of all at once.

14
00:00:37,500 --> 00:00:40,080
I also do think it's fair to say, however,

15
00:00:40,080 --> 00:00:44,490
that the kind of ability to capture value

16
00:00:44,490 --> 00:00:48,450
is still catching up to what models can do

17
00:00:48,450 --> 00:00:51,450
and what AI can do these days, right?

18
00:00:51,450 --> 00:00:55,770
And that's one of the reasons why Amazon Q

19
00:00:55,770 --> 00:00:59,520
is such an effective solution, right?

20
00:00:59,520 --> 00:01:04,170
It's kind of built to
very easily help you,

21
00:01:04,170 --> 00:01:06,060
you know, sit on top of your data

22
00:01:06,060 --> 00:01:08,013
and deliver value to your users.

23
00:01:08,970 --> 00:01:12,300
And it's also secure
and private by design,

24
00:01:12,300 --> 00:01:15,030
which is important
because one of the things

25
00:01:15,030 --> 00:01:17,640
that's a major roadblock
for a lot of organizations

26
00:01:17,640 --> 00:01:22,640
that want to roll out AI is
concerns about data security.

27
00:01:23,130 --> 00:01:24,360
That's the number one roadblock

28
00:01:24,360 --> 00:01:26,250
for anybody trying to roll out AI.

29
00:01:26,250 --> 00:01:29,550
So Amazon Q is secure
and private by design

30
00:01:29,550 --> 00:01:31,320
to help alleviate that, right?

31
00:01:31,320 --> 00:01:34,320
And what it'll do is
it'll respect identities

32
00:01:34,320 --> 00:01:36,690
and roles and permissions,

33
00:01:36,690 --> 00:01:38,730
ensuring that personalized interactions

34
00:01:38,730 --> 00:01:42,210
are based on the user's actual data access

35
00:01:42,210 --> 00:01:43,043
that they have, right?

36
00:01:43,043 --> 00:01:46,020
So Amazon Q does respect permissions,

37
00:01:46,020 --> 00:01:49,230
and it also offers data
privacy in the sense that

38
00:01:49,230 --> 00:01:52,140
Amazon is not taking
your data and using it,

39
00:01:52,140 --> 00:01:53,220
you know, to improve their models

40
00:01:53,220 --> 00:01:54,840
or storing it anywhere, right?

41
00:01:54,840 --> 00:01:56,223
Your data stays private.

42
00:01:59,070 --> 00:02:01,680
And Amazon Q, however,

43
00:02:01,680 --> 00:02:05,550
makes it very, very easy
to search data, right?

44
00:02:05,550 --> 00:02:08,280
The speed and power and scale of AI,

45
00:02:08,280 --> 00:02:10,830
it's just different than a
human user going somewhere

46
00:02:10,830 --> 00:02:13,050
and kind of search and destroy method,

47
00:02:13,050 --> 00:02:15,600
going to different data sources
and trying to query them.

48
00:02:15,600 --> 00:02:17,640
You know, when you have
AI that can crawl deeply

49
00:02:17,640 --> 00:02:21,360
through your data on a very
granular level, you know,

50
00:02:21,360 --> 00:02:24,423
and do it, you know, at every query.

51
00:02:25,500 --> 00:02:29,400
What will happen, it'll surface
whatever it finds, right?

52
00:02:29,400 --> 00:02:31,380
So it's sort of a double-edged sword

53
00:02:31,380 --> 00:02:34,890
where you can very easily,
if you don't have things,

54
00:02:34,890 --> 00:02:35,910
you know, tightly controlled,

55
00:02:35,910 --> 00:02:39,540
you can very easily have
unintended data exposure, right?

56
00:02:39,540 --> 00:02:42,510
So you could have an
employee say, you know,

57
00:02:42,510 --> 00:02:45,690
I want salary information
for employees in the US

58
00:02:45,690 --> 00:02:48,300
or what companies are
we evaluating for M&A,

59
00:02:48,300 --> 00:02:50,490
or could I get social security numbers

60
00:02:50,490 --> 00:02:52,650
for our employees, right?

61
00:02:52,650 --> 00:02:55,470
If you don't have your
underlying data structure,

62
00:02:55,470 --> 00:02:57,060
you know, properly permissioned

63
00:02:57,060 --> 00:02:59,730
and knowledge of where all
of your sensitive data is

64
00:02:59,730 --> 00:03:01,650
and all of your policies in order,

65
00:03:01,650 --> 00:03:03,720
you could very easily expose that

66
00:03:03,720 --> 00:03:04,950
with the speed and power

67
00:03:04,950 --> 00:03:07,173
that AI gives to any user, right?

68
00:03:10,620 --> 00:03:12,000
The problem with that, however,

69
00:03:12,000 --> 00:03:15,570
is data states are
incredibly complex, right?

70
00:03:15,570 --> 00:03:18,090
Especially when we're
talking about getting down

71
00:03:18,090 --> 00:03:21,570
to the file level where we
need to have intelligence

72
00:03:21,570 --> 00:03:23,310
and we need to have control, right?

73
00:03:23,310 --> 00:03:24,480
At a deep file level.

74
00:03:24,480 --> 00:03:27,270
We're not talking about securing AI

75
00:03:27,270 --> 00:03:29,910
by securing a data system.

76
00:03:29,910 --> 00:03:31,710
We're talking about we
need to have intelligence

77
00:03:31,710 --> 00:03:33,060
at the file level.

78
00:03:33,060 --> 00:03:36,120
And that's incredibly complex, right?

79
00:03:36,120 --> 00:03:39,780
When we look at the size
of, you know, a data state,

80
00:03:39,780 --> 00:03:42,330
it could be tens or hundreds
of billions of files,

81
00:03:42,330 --> 00:03:44,460
you know, hundreds of millions of tables,

82
00:03:44,460 --> 00:03:46,320
thousands of streams, and you know,

83
00:03:46,320 --> 00:03:48,810
petabytes upon petabytes of data.

84
00:03:48,810 --> 00:03:50,910
We actually have one
large enterprise customer

85
00:03:50,910 --> 00:03:54,150
that generates just in
logs in a given day,

86
00:03:54,150 --> 00:03:58,080
you know, unstructured
multistructured logs, in one day,

87
00:03:58,080 --> 00:03:59,790
more than a petabyte of data, right?

88
00:03:59,790 --> 00:04:01,803
So it's just absolutely absurd,

89
00:04:02,940 --> 00:04:06,390
you know, numbers there and
you have different file types,

90
00:04:06,390 --> 00:04:09,090
you know, different sensitivity
levels of different data,

91
00:04:09,090 --> 00:04:11,670
different types of
sensitive data, you know,

92
00:04:11,670 --> 00:04:16,670
different regulations that
that data might be beholden to,

93
00:04:17,070 --> 00:04:19,470
permission structures, policies.

94
00:04:19,470 --> 00:04:21,783
It's very complex, right?

95
00:04:23,520 --> 00:04:25,120
So what we do and how we help

96
00:04:26,130 --> 00:04:29,010
is we actually take your data, right?

97
00:04:29,010 --> 00:04:30,690
And you know, kind of scan through it

98
00:04:30,690 --> 00:04:34,020
on a deeply granular level, right?

99
00:04:34,020 --> 00:04:36,240
And extract from the file level

100
00:04:36,240 --> 00:04:38,610
thousands of pieces of metadata

101
00:04:38,610 --> 00:04:42,090
that we can then associate back in a graph

102
00:04:42,090 --> 00:04:44,880
that will kind of show
you all of the connections

103
00:04:44,880 --> 00:04:46,187
between things in your data, right?

104
00:04:46,187 --> 00:04:49,500
So you see connections
between users and groups

105
00:04:49,500 --> 00:04:53,340
and permissions and policies and data.

106
00:04:53,340 --> 00:04:57,363
You'll see the geographies and the,

107
00:04:58,980 --> 00:05:02,940
you know, regulations
that they're beholden to

108
00:05:02,940 --> 00:05:04,710
kind of all visualized in a graph

109
00:05:04,710 --> 00:05:06,960
that makes it very, very easy to see

110
00:05:06,960 --> 00:05:09,330
where there might be issues, right?

111
00:05:09,330 --> 00:05:11,730
So this allows us to sort of give you

112
00:05:11,730 --> 00:05:13,410
a deep level of intelligence

113
00:05:13,410 --> 00:05:15,990
that gives you sensitive
data protection, right?

114
00:05:15,990 --> 00:05:18,690
And a policy enforcement layer

115
00:05:18,690 --> 00:05:22,020
so you can write policy against that data.

116
00:05:22,020 --> 00:05:26,190
It gives you a very granular
data access intelligence

117
00:05:26,190 --> 00:05:29,670
that helps you to identify
any overpermissioning

118
00:05:29,670 --> 00:05:31,620
that might be problematic or,

119
00:05:31,620 --> 00:05:34,470
you know, where you know you
have permissioning issues

120
00:05:34,470 --> 00:05:38,398
that might not be in line
with regulations, right?

121
00:05:38,398 --> 00:05:40,350
And it also gives you the
ability to remediate any

122
00:05:40,350 --> 00:05:44,280
of those issues and make
your underlying data safe

123
00:05:44,280 --> 00:05:47,190
for the usage with AI, right?

124
00:05:47,190 --> 00:05:50,670
And we'll do this across all
of your data sources, right?

125
00:05:50,670 --> 00:05:52,530
Not just data in AWS,

126
00:05:52,530 --> 00:05:56,340
but data across your
entire environment, right?

127
00:05:56,340 --> 00:05:57,420
So this is what we do.

128
00:05:57,420 --> 00:05:59,940
We kind of build this
graph structure for you

129
00:05:59,940 --> 00:06:03,810
and kind of auto-populate
this graph from the metadata

130
00:06:03,810 --> 00:06:07,083
that we're able to extract from
the file level of your data.

131
00:06:08,370 --> 00:06:09,270
Okay?

132
00:06:09,270 --> 00:06:14,270
And then what we'll also
do is we can via API,

133
00:06:14,640 --> 00:06:18,690
you know, push out, you
know, policy recommendations

134
00:06:18,690 --> 00:06:22,140
and things of that nature to
external systems and apps.

135
00:06:22,140 --> 00:06:24,540
So if you wanted to connect with, say,

136
00:06:24,540 --> 00:06:28,470
like a CNAPP or a SOC
for security purposes,

137
00:06:28,470 --> 00:06:31,020
or use that data command API,

138
00:06:31,020 --> 00:06:34,473
I'll show you a way that we
can use that with AI as well.

139
00:06:36,810 --> 00:06:38,790
So how do we work with Amazon Q, right?

140
00:06:38,790 --> 00:06:41,760
We're sort of a parallel
companion solution

141
00:06:41,760 --> 00:06:44,040
for Amazon Q, right?

142
00:06:44,040 --> 00:06:47,010
Where what Amazon Q is going
to do is it's going to,

143
00:06:47,010 --> 00:06:49,830
you know, index data
from your data systems.

144
00:06:49,830 --> 00:06:54,150
And like I said before,
respect the permissioning

145
00:06:54,150 --> 00:06:55,740
and everything that you have in that data,

146
00:06:55,740 --> 00:06:57,690
it's going to respect the labels

147
00:06:57,690 --> 00:06:59,880
and the policies on how to deal with data

148
00:06:59,880 --> 00:07:01,830
given those labels, right?

149
00:07:01,830 --> 00:07:02,940
So what Securiti is going to do

150
00:07:02,940 --> 00:07:05,790
is we're going to do the
classification and the labeling.

151
00:07:05,790 --> 00:07:09,120
We're going to enforce
privileged data access.

152
00:07:09,120 --> 00:07:11,760
We're going to reduce data exposures

153
00:07:11,760 --> 00:07:16,760
and also removal of old,
redundant, obsolete or trivial data

154
00:07:18,750 --> 00:07:21,603
that could be causing security issues or,

155
00:07:22,650 --> 00:07:25,710
you know, reducing the
quality of AI outputs, right?

156
00:07:25,710 --> 00:07:27,240
So what we'll do is we'll kind of

157
00:07:27,240 --> 00:07:29,550
inspect those data systems,

158
00:07:29,550 --> 00:07:31,860
show you insights in our graph,

159
00:07:31,860 --> 00:07:34,800
and then push remediations
back into those data systems

160
00:07:34,800 --> 00:07:38,910
so that Amazon Q can then
safely index that data

161
00:07:38,910 --> 00:07:40,563
for business usage, okay?

162
00:07:43,770 --> 00:07:46,680
So let's go into some of
those in detail, right?

163
00:07:46,680 --> 00:07:47,513
So I said we're going to do

164
00:07:47,513 --> 00:07:50,190
data classification and labeling first.

165
00:07:50,190 --> 00:07:52,380
That's kind of the most important piece.

166
00:07:52,380 --> 00:07:53,460
At that file level,

167
00:07:53,460 --> 00:07:56,206
we have more than 400 classifiers

168
00:07:56,206 --> 00:07:59,460
that will classify different
types of sensitive data,

169
00:07:59,460 --> 00:08:02,130
and then give you the policy engine

170
00:08:02,130 --> 00:08:05,280
to label that data as you wish.

171
00:08:05,280 --> 00:08:06,750
So you could say something like,

172
00:08:06,750 --> 00:08:08,490
for executives only, right?

173
00:08:08,490 --> 00:08:11,040
Or something like that that gives Amazon Q

174
00:08:11,040 --> 00:08:12,930
the information that it needs

175
00:08:12,930 --> 00:08:15,183
to properly handle that data, right?

176
00:08:16,350 --> 00:08:19,170
After we do classification and labeling,

177
00:08:19,170 --> 00:08:24,170
then we can talk about removal
of ROT data or stale data.

178
00:08:24,210 --> 00:08:28,830
This is actually a bigger
thing than you might think.

179
00:08:28,830 --> 00:08:33,830
So ROT data can destroy
trust and accuracy, right?

180
00:08:34,650 --> 00:08:36,060
So with duplicate fields, you know,

181
00:08:36,060 --> 00:08:38,730
copies of files all over the place,

182
00:08:38,730 --> 00:08:41,103
you know, AI might not know,

183
00:08:42,286 --> 00:08:43,800
that's going to confuse AI,

184
00:08:43,800 --> 00:08:46,260
it's going to throw off
your results, right?

185
00:08:46,260 --> 00:08:51,260
It also gives you kind of a
poor employee experience, right?

186
00:08:51,930 --> 00:08:54,930
And we know that people are very brutal

187
00:08:54,930 --> 00:08:56,850
when it comes to whether they trust AI

188
00:08:56,850 --> 00:08:58,440
and they're going to adopt it or not.

189
00:08:58,440 --> 00:09:00,060
If they don't get the
answer they're looking for

190
00:09:00,060 --> 00:09:03,540
after two or three times,
or they get some junk,

191
00:09:03,540 --> 00:09:05,820
they're very quick to write off AI

192
00:09:05,820 --> 00:09:07,650
and kind of move on to another one,

193
00:09:07,650 --> 00:09:10,053
so it has a big impact on adoption.

194
00:09:11,130 --> 00:09:13,350
But also there can be security issues

195
00:09:13,350 --> 00:09:16,620
that are caused by this kind
of redundant and stale data,

196
00:09:16,620 --> 00:09:18,870
copies of things all over the place,

197
00:09:18,870 --> 00:09:20,460
might have different security settings,

198
00:09:20,460 --> 00:09:22,350
might have different access privileges,

199
00:09:22,350 --> 00:09:25,140
and create kind of a loophole

200
00:09:25,140 --> 00:09:27,540
that you need to clean up, right?

201
00:09:27,540 --> 00:09:28,410
So one of the things that we'll do

202
00:09:28,410 --> 00:09:32,520
is we'll identify and
remove redundant data.

203
00:09:32,520 --> 00:09:34,770
This alone can have a huge, huge ROI

204
00:09:34,770 --> 00:09:39,510
that can fund, you know, your
whole project to begin with,

205
00:09:39,510 --> 00:09:42,393
just the removal of stale data.

206
00:09:44,430 --> 00:09:46,590
Next, you know, we'll
talk about preventing

207
00:09:46,590 --> 00:09:49,470
inappropriate data access, right?

208
00:09:49,470 --> 00:09:52,533
So this shift from structured
to unstructured data,

209
00:09:54,060 --> 00:09:54,893
you know,

210
00:09:55,920 --> 00:09:58,800
we have to now govern things like emails,

211
00:09:58,800 --> 00:10:01,923
documents, chats, things of that nature.

212
00:10:03,411 --> 00:10:06,963
It's a bit different than
the structured data world.

213
00:10:08,100 --> 00:10:10,800
And you know, we need
granular access intelligence

214
00:10:10,800 --> 00:10:13,233
across billions and
billions of files, right?

215
00:10:14,280 --> 00:10:18,570
And the ability to apply
context aware and conditional

216
00:10:18,570 --> 00:10:21,030
attribute based access controls, right?

217
00:10:21,030 --> 00:10:23,610
So here's just a visualization of,

218
00:10:23,610 --> 00:10:25,830
you know, what we'll show
you in the graph, right?

219
00:10:25,830 --> 00:10:28,920
You can see a piece of
financial data, you know,

220
00:10:28,920 --> 00:10:30,870
and the specific policies

221
00:10:30,870 --> 00:10:34,440
and the specific permissions, right?

222
00:10:34,440 --> 00:10:35,520
That's mapped to it, right?

223
00:10:35,520 --> 00:10:37,890
The entitlements that are mapped to it

224
00:10:37,890 --> 00:10:40,380
against a certain piece of financial data,

225
00:10:40,380 --> 00:10:41,790
you'll see that across, you know,

226
00:10:41,790 --> 00:10:44,400
your entire data state
giving you the ability

227
00:10:44,400 --> 00:10:47,040
to remediate data access issues

228
00:10:47,040 --> 00:10:48,870
and over permissioning issues

229
00:10:48,870 --> 00:10:52,053
that could lead to inappropriate
data access via AI, right?

230
00:10:53,940 --> 00:10:55,080
And then, okay,

231
00:10:55,080 --> 00:10:57,130
so once we have things kind of cleaned up

232
00:10:58,020 --> 00:11:00,600
from a data access standpoint,

233
00:11:00,600 --> 00:11:02,160
we've done our
classification and labeling,

234
00:11:02,160 --> 00:11:03,540
we've done ROT data removal,

235
00:11:03,540 --> 00:11:05,670
then we talk about, you
know, what about fresh data,

236
00:11:05,670 --> 00:11:06,723
fresh data coming in?

237
00:11:08,444 --> 00:11:11,760
Securiti data command center can act

238
00:11:11,760 --> 00:11:14,640
as sort of the policy engine, right?

239
00:11:14,640 --> 00:11:17,460
To validate incoming data

240
00:11:17,460 --> 00:11:19,350
before it's indexed by Q, right?

241
00:11:19,350 --> 00:11:23,040
So we can consult the graph
via the data command graph API

242
00:11:23,040 --> 00:11:25,800
and say, "Should I index this, yes or no?"

243
00:11:25,800 --> 00:11:26,633
Right?

244
00:11:26,633 --> 00:11:30,600
Is this safe based on how
this data is classified,

245
00:11:30,600 --> 00:11:32,700
what sensitive data might be in there,

246
00:11:32,700 --> 00:11:34,830
and what policies we need to apply to it?

247
00:11:34,830 --> 00:11:36,810
Should I index this, yes or no?

248
00:11:36,810 --> 00:11:40,710
So this is a way that we can
kind of, on a continual basis,

249
00:11:40,710 --> 00:11:43,693
you know, operationalize
the data AI security

250
00:11:43,693 --> 00:11:48,693
and keep feeding Amazon
Q fresh, safe data.

251
00:11:58,734 --> 00:12:00,330
All right.

252
00:12:00,330 --> 00:12:02,700
So I just wanted to point
out real quick that,

253
00:12:02,700 --> 00:12:05,703
you know, this layer, this
information governance layer,

254
00:12:07,770 --> 00:12:09,580
this information governance layer

255
00:12:10,500 --> 00:12:13,560
is the foundation of the
Gartner AI TRiSM stack.

256
00:12:13,560 --> 00:12:15,570
I'm sorry, it's covered up here

257
00:12:15,570 --> 00:12:17,760
by a mysterious white box for some reason,

258
00:12:17,760 --> 00:12:21,690
but that's a foundational capability.

259
00:12:21,690 --> 00:12:22,800
But this is, you know,

260
00:12:22,800 --> 00:12:25,470
kind of very simple four step process.

261
00:12:25,470 --> 00:12:26,760
We've helped a lot of customers through

262
00:12:26,760 --> 00:12:29,550
that have gone through this path.

263
00:12:29,550 --> 00:12:32,730
You know, first detect, classify
and label sensitive data

264
00:12:32,730 --> 00:12:34,620
per your enterprise policies,

265
00:12:34,620 --> 00:12:37,980
reduce old data usage, ROT data usage,

266
00:12:37,980 --> 00:12:40,110
and then you can start to layer on

267
00:12:40,110 --> 00:12:43,020
least privileged data access and then,

268
00:12:43,020 --> 00:12:45,240
you know, scaling usage with fresh data

269
00:12:45,240 --> 00:12:49,083
and kind of, you know, ongoing
data sanitization, right?

270
00:12:52,170 --> 00:12:56,190
So why use Securiti and our graph?

271
00:12:56,190 --> 00:12:58,860
To enable the safe adoption
of Amazon Q for business,

272
00:12:58,860 --> 00:13:01,590
prevent unintended sharing of data,

273
00:13:01,590 --> 00:13:03,480
you know, with intelligent risk detection

274
00:13:03,480 --> 00:13:05,730
and automated remediation,

275
00:13:05,730 --> 00:13:09,603
improve the quality of AI
response by reducing ROT data,

276
00:13:10,770 --> 00:13:13,200
and the ability to secure all your data

277
00:13:13,200 --> 00:13:15,900
and AI across environments, okay?

278
00:13:15,900 --> 00:13:19,470
So those are kind of three
reasons to use Securiti

279
00:13:19,470 --> 00:13:21,723
along with Amazon Q for business.

280
00:13:22,920 --> 00:13:25,140
And just wanted to throw it out there.

281
00:13:25,140 --> 00:13:28,020
This same process works the same way

282
00:13:28,020 --> 00:13:31,380
right alongside Amazon Quick Suite,

283
00:13:31,380 --> 00:13:34,200
if any of you are considering
Amazon Quick Suite

284
00:13:34,200 --> 00:13:37,683
to build AI agent applications, okay?

285
00:13:38,670 --> 00:13:43,670
So feel free to come stop
by the booth, we're in 1966,

286
00:13:44,130 --> 00:13:48,003
or you can kind of scan the QR
code here to request a demo.

287
00:13:48,840 --> 00:13:50,790
We've got all kinds of collateral

288
00:13:50,790 --> 00:13:52,353
and demos at the booth as well.

289
00:13:53,370 --> 00:13:56,580
And I also have, I can show you,

290
00:13:56,580 --> 00:13:59,670
we have another product that goes along

291
00:13:59,670 --> 00:14:01,230
with the data command graph,

292
00:14:01,230 --> 00:14:06,230
our Gencore AI Securiti solution

293
00:14:06,690 --> 00:14:10,770
that will protect data in motion, right?

294
00:14:10,770 --> 00:14:14,850
By kind of detecting policy
violations across an AI system

295
00:14:14,850 --> 00:14:16,680
as data moves across the system

296
00:14:16,680 --> 00:14:20,666
without requiring you to
influence the behavior

297
00:14:20,666 --> 00:14:22,980
of an AI model, kind of protecting it

298
00:14:22,980 --> 00:14:25,620
by restricting the flow
of data across the system.

299
00:14:25,620 --> 00:14:27,360
So we'll be demoing that as well,

300
00:14:27,360 --> 00:14:28,350
and I'm excited about that.

301
00:14:28,350 --> 00:14:30,720
That should be available soon as the MCP

302
00:14:30,720 --> 00:14:32,400
for any of you who are building things

303
00:14:32,400 --> 00:14:34,560
in Bedrock and Agent Core.

304
00:14:34,560 --> 00:14:36,803
So we'll be showing that
at the booth as well.

305
00:14:37,740 --> 00:14:39,843
But that's all I had today.

