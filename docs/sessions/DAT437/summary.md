# AWS re:Invent 2025 ElastiCache Serverless 高性能应用优化会议总结

## 会议概述

本次会议由AWS ElastiCache团队的Alad和Jeron主讲,重点介绍了如何使用ElastiCache Serverless for Valkey构建高性能、大规模的应用程序。会议以构建大型多人在线游戏为例,详细讲解了在需要支持数十万用户、每秒数百万请求的场景下,如何实现亚毫秒级延迟。

ElastiCache Serverless消除了开发者在安全补丁、版本升级、集群规模调整等方面的顾虑,能够自动扩展以应对应用负载的增长。会议深入探讨了多个性能优化技术,包括持久连接管理、连接池、流水线处理、热点数据处理等。这些优化不仅适用于ElastiCache Serverless,也适用于自管理的Redis或Valkey集群。

Valkey是从Redis分叉出来的开源内存数据库,在Redis改变许可证后由Linux基金会维护,得到了包括AWS在内的多个云服务提供商和行业领导者的支持。通过专门设计的代理层和智能扩展机制,ElastiCache Serverless能够在12分钟内从零扩展到每秒500万请求,同时保持连接的持久性和数据的一致性。

## 详细时间线与关键要点

### 开场介绍 (00:00 - 02:30)
- **00:00** - 会议开始,欢迎参会者参加re:Invent
- **00:30** - 介绍会议场景:构建一个大型多人在线游戏,需要支持数十万用户
- **01:00** - 说明性能需求:每秒数百万请求,极低延迟
- **01:30** - 介绍ElastiCache Serverless for Valkey的核心优势:可预测的低延迟和大规模支持
- **02:00** - 讲师自我介绍:Alad和Jeron,均来自ElastiCache团队

### ElastiCache Serverless核心优势 (02:30 - 04:00)
- **02:30** - ElastiCache Serverless消除的运维负担:安全补丁、版本升级
- **03:00** - 最重要的优势:无需担心集群规模调整和自动扩展
- **03:30** - 会议适用范围:优化技术适用于Serverless、自管理集群和开源Redis/Valkey

### Valkey介绍 (04:00 - 05:00)
- **04:00** - Valkey是开源内存数据库,从Redis分叉而来
- **04:30** - Redis许可证变更后,Valkey由Linux基金会维护
- **04:45** - Valkey社区活跃,包括行业领导者和AWS等云服务提供商

### 延迟分析基础 (05:00 - 10:00)
- **05:00** - 从游戏POC开始:客户端连接Node.js服务器
- **05:30** - 实验室环境延迟:约100微秒往返时间
- **06:00** - 延迟主要来自操作系统、网络栈、内核与用户模式通信
- **06:30** - 内存访问时间:几十纳秒
- **07:00** - 磁盘延迟:接近1毫秒,且变化大
- **07:30** - 磁盘延迟变化原因:对象存储在不同块上,需要多次访问
- **08:00** - 生产环境变化:用户在互联网上,使用多个应用实例
- **08:30** - 数据库延迟:1毫秒到100毫秒,变化大
- **09:00** - Valkey优势:专门使用内存提供可预测的低延迟
- **09:30** - 同可用区延迟:远低于1毫秒(亚毫秒级)

### 网络延迟详解 (10:00 - 15:00)
- **10:00** - 跨可用区延迟:最高1毫秒
- **10:30** - 跨区域延迟:可达数毫秒,受限于光速
- **11:00** - 实际测量数据:US East 1区域的跨可用区延迟
- **11:30** - 跨可用区延迟大多低于700微秒
- **12:00** - 可用区内延迟:约100微秒或更低
- **12:30** - 延迟变化因素:区域、可用区位置、距离
- **13:00** - 介绍AWS Network Manager工具
- **13:30** - 可以查看不同区域和可用区之间的延迟
- **14:00** - 建议:根据延迟数据优化应用架构
- **14:30** - 从副本读取可以保持低延迟

### 连接管理最佳实践 (15:00 - 22:00)
- **15:00** - 展示错误示例:每次请求创建新连接
- **15:30** - 问题分析:DNS查询、TCP握手、TLS初始化
- **16:00** - 还包括集群发现、槽位映射
- **16:30** - 最佳实践:使用持久连接
- **17:00** - 持久连接适用于EC2、ECS、Kubernetes和Lambda
- **17:30** - Lambda函数在热状态下保持连接
- **18:00** - 流水线(Pipelining)概念介绍
- **18:30** - 流水线:在同一TCP连接上发送多个请求而不等待响应
- **19:00** - 异步代码自动创建隐式流水线
- **19:30** - 流水线优势:批量处理,减少IO操作
- **20:00** - 高并发下的问题:队头阻塞(Head-of-line blocking)
- **20:30** - RESP协议是有序的,响应必须按请求顺序返回
- **21:00** - 大响应会阻塞后续请求
- **21:30** - 数据包丢失影响:TCP重传至少需要200微秒

### 连接池策略 (22:00 - 26:00)
- **22:00** - 解决方案:使用多个连接
- **22:30** - 限制每个连接的并发度
- **23:00** - 减少数据包丢失的影响范围
- **23:30** - 可以为慢请求使用专用连接
- **24:00** - 横向扩展应用实例也能降低并发
- **24:30** - 连接池:从同一应用实例使用多个连接
- **25:00** - 许多异步客户端不内置连接池
- **25:30** - 展示自建连接池代码示例

### 连接池实现 (26:00 - 28:00)
- **26:00** - 创建多个持久连接的循环
- **26:30** - 选择连接的策略:模运算、随机、轮询
- **27:00** - 示例使用用户ID模运算进行负载均衡
- **27:30** - 可根据应用逻辑选择合适的策略

### 热点问题处理 (28:00 - 35:00)
- **28:00** - 场景:集群资源充足但性能下降
- **28:30** - 热点问题:大量流量集中在一个节点
- **29:00** - 原因:热键(hot keys)被频繁访问
- **29:30** - Valkey/Redis中每个键属于单个分片
- **30:00** - 诊断方法:检查网络带宽指标
- **30:30** - 热点表现:一个分片的带宽显著高于其他分片
- **31:00** - 案例:100KB的城堡地图,非常受欢迎
- **31:30** - R7g.large节点:937 Mbps带宽
- **32:00** - 计算:只能支持约1000请求/秒
- **32:30** - 解决方案1:扩展节点规模
- **33:00** - Serverless自动纵向扩展
- **33:30** - 但扩展有限制,可能需要10倍、50倍甚至100倍
- **34:00** - 解决方案2:复制对象
- **34:30** - 创建多个副本,分布在不同分片

### 对象复制策略 (35:00 - 40:00)
- **35:00** - 每个副本是不同的键,存储在不同分片
- **35:30** - 读取时选择不同的副本
- **36:00** - 在分片间负载均衡
- **36:30** - Serverless可扩展到数百个节点
- **37:00** - 100个副本可获得100倍吞吐量
- **37:30** - 也可以从副本节点读取
- **38:00** - 展示代码示例:选择副本的逻辑
- **38:30** - 使用worker ID模运算选择副本
- **39:00** - 缺点:更新时需要更新所有副本
- **39:30** - 适用场景:读多写少

### 对象分割策略 (40:00 - 43:00)
- **40:00** - 解决方案3:将对象拆分为更小的部分
- **40:30** - 示例:将城堡拆分为房间或区域
- **41:00** - 使用流水线读取所有部分
- **41:30** - 在应用端组装完整对象
- **42:00** - 负载分散到多个分片
- **42:30** - 进一步优化:只获取需要的部分

### ElastiCache Serverless架构 (43:00 - 50:00)
- **43:00** - Jeron接手讲解Serverless设计
- **43:30** - Serverless优势:无需容量规划和集群调整
- **44:00** - 可实现每秒数百万请求,亚毫秒响应时间
- **44:30** - 自动跨多个可用区分布基础设施
- **45:00** - 目的:高可用性和优秀性能
- **45:30** - 架构:通过VPC端点连接
- **46:00** - 流量经过NLB(网络负载均衡器)
- **46:30** - NLB将流量分配到Serverless代理
- **47:00** - 代理负责将请求路由到正确的缓存节点
- **47:30** - 代理能定位同可用区的本地代理
- **48:00** - 最小化延迟
- **48:30** - 代理使用多路复用技术
- **49:00** - 单个TCP通道承载多个客户端连接
- **49:30** - 减少连接数和系统调用

### 多租户环境和热管理 (50:00 - 56:00)
- **50:00** - 运行在多租户环境的物理主机上
- **50:30** - 热管理服务持续监控
- **51:00** - 监控整个集群的物理主机
- **51:30** - 共享CPU、内存和网络资源
- **52:00** - 缓存节点运行在物理主机内的VM中
- **52:30** - 每个缓存节点大小不同,工作负载不同
- **53:00** - 确保有足够的额外容量
- **53:30** - 热管理持续监控物理主机状态
- **54:00** - 检测达到阈值的物理主机
- **54:30** - 使用"两个随机选择的幂"算法
- **55:00** - 选择两个最热的缓存节点
- **55:30** - 只移动第二热的节点

### 节点迁移策略 (56:00 - 60:00)
- **56:00** - 避免中断最繁忙的节点
- **56:30** - 让最繁忙的节点完成扩展操作
- **57:00** - 移动能释放足够资源的节点
- **57:30** - 代理保持连接持久性
- **58:00** - 后台变更对客户端透明
- **58:30** - 代理负责将连接迁移到新节点
- **59:00** - 保持整个集群平衡
- **59:30** - 确保有足够资源

### 突发流量处理 (60:00 - 66:00)
- **60:00** - 某些情况下热管理不够快
- **60:30** - 需要处理突发工作负载
- **61:00** - 事件驱动的流量激增
- **61:30** - Serverless的纵向扩展技术
- **62:00** - 使用没有固定内存或CPU占用的平台技术
- **62:30** - 可以即时重新调整规模
- **63:00** - 基于多租户环境,保持成本最小
- **63:30** - 可以快速扩展使用更多核心和内存
- **64:00** - 按需支持8倍吞吐量
- **64:30** - 纵向扩展为横向扩展争取时间
- **65:00** - 横向扩展三个阶段:检测、配置、数据迁移
- **65:30** - 检测阶段非常快速

### 横向扩展机制 (66:00 - 72:00)
- **66:00** - 能够预测即将到来的工作负载
- **66:30** - 持续监控工作负载模式
- **67:00** - 预测未来几分钟的工作负载
- **67:30** - 可以预先扩展集群
- **68:00** - 配置阶段:使用温池(Warm Pool)
- **68:30** - 温池是预定义、预安装的缓存节点列表
- **69:00** - 等待快速附加到集群
- **69:30** - 最后阶段:数据迁移
- **70:00** - 从原始分片移动数据到新分片
- **70:30** - 监控槽位内的数据
- **71:00** - 确定哪些槽位是热的,哪些是冷的
- **71:30** - 并行移动槽位内的数据

### 扩展性能指标 (72:00 - 75:00)
- **72:00** - 可以并行分配多个目标
- **72:30** - 并行传输数据到不同目标
- **73:00** - 扩展速度非常快
- **73:30** - 每2分钟可以使集群吞吐量翻倍
- **74:00** - 从零到每秒500万请求只需12分钟
- **74:30** - 强调代理的重要性

### 代理层详解 (75:00 - 82:00)
- **75:00** - 代理设计原因:单一逻辑入口点
- **75:30** - 代理主要工作:路由请求到缓存节点
- **76:00** - 封装底层集群拓扑
- **76:30** - 处理故障转移、断连、扩展
- **77:00** - 所有变更在后台发生
- **77:30** - 应用只需单个连接到代理
- **78:00** - 代理维护到集群的数千个连接
- **78:30** - 应用无需关心连接管理
- **79:00** - 可以即时扩展吞吐量
- **79:30** - 利用代理技术和自动扩展
- **80:00** - 12分钟内从零到每秒500万请求
- **80:30** - 从副本读取功能
- **81:00** - 适用于延迟敏感且一致性要求不强的应用
- **81:30** - 每个分片默认创建1个主节点和2个副本

### 从副本读取 (82:00 - 86:00)
- **82:00** - 连接时标记要从副本读取
- **82:30** - 代理自动处理
- **83:00** - 代理始终从本地可用区读取
- **83:30** - 无论主节点还是副本
- **84:00** - 实现微秒级响应时间
- **84:30** - 代码示例:连接到ElastiCache Serverless
- **85:00** - 启用TLS(Serverless仅支持TLS连接)
- **85:30** - 标记连接以从副本读取

### 代码示例演示 (86:00 - 92:00)
- **86:00** - 三个代码块示例
- **86:30** - 第一个:填充键到缓存
- **87:00** - 第二个:循环获取数据
- **87:30** - 第三个:使用流水线批量获取
- **88:00** - 所有请求通过代理
- **88:30** - 代理将请求分发到正确的分片
- **89:00** - 代理处理断连、扩展、故障转移
- **89:30** - 不会中断连接
- **90:00** - 代理确保从本地可用区读取
- **90:30** - 代码保持简洁
- **91:00** - 无需特殊代码处理
- **91:30** - 一切由代理管理

### Valkey技术演进 (92:00 - 结束)
- **92:00** - 回顾Valkey历史
- **92:30** - Valkey最初设计为单线程进程
- **93:00** - 原因:简单性
- **93:30** - 无竞态条件,无需同步
- **94:00** - 仍可通过分片横向扩展
- **94:30** - (字幕在此处截断)

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


注: 本总结基于提供的字幕文本,字幕在约94分钟处截断,可能还有后续内容未包含在此总结中。