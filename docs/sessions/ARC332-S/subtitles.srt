1
00:00:00,960 --> 00:00:01,971
- Hi everyone.

2
00:00:01,971 --> 00:00:04,740
First of all, I just wanna
say thank you for joining

3
00:00:04,740 --> 00:00:06,990
and taking the time to attend our session.

4
00:00:06,990 --> 00:00:09,510
And I want to, today
we're here to talk about,

5
00:00:09,510 --> 00:00:13,200
talk about cloud mesh and
potential different solutions.

6
00:00:13,200 --> 00:00:15,510
I'm Frank, and this is Jakub.

7
00:00:15,510 --> 00:00:17,910
- Hi, Frank, hi everybody,
my name is Jakub,

8
00:00:17,910 --> 00:00:21,663
and I first wanted to ask who
has heard of HAProxy before?

9
00:00:22,980 --> 00:00:23,813
It's a lot of people.

10
00:00:23,813 --> 00:00:25,833
And who uses HAProxy right now?

11
00:00:26,820 --> 00:00:27,653
Awesome.

12
00:00:27,653 --> 00:00:29,460
So some of you, see my
colleague in the back,

13
00:00:29,460 --> 00:00:30,780
we have a T-shirt for you.

14
00:00:30,780 --> 00:00:32,760
Thank you for using HAProxy.

15
00:00:32,760 --> 00:00:35,910
If he runs out, then
please see us at the booth

16
00:00:35,910 --> 00:00:37,323
and we'll get you on.

17
00:00:38,550 --> 00:00:39,870
- All right, so for today,

18
00:00:39,870 --> 00:00:42,300
we wanted to talk about
"Multi-Cloud Chaos,

19
00:00:42,300 --> 00:00:44,375
The Unified Cloud Mesh Architecture."

20
00:00:44,375 --> 00:00:46,740
We want to tell you
some tales of the field.

21
00:00:46,740 --> 00:00:48,330
We work on the enterprise side

22
00:00:48,330 --> 00:00:50,940
and we talked to a lot
of different enterprises

23
00:00:50,940 --> 00:00:54,180
and they're looking at
service mesh solutions.

24
00:00:54,180 --> 00:00:55,987
So I'll start with a statement,

25
00:00:55,987 --> 00:00:58,800
"The Service Mesh was designed
to solve connectivity."

26
00:00:58,800 --> 00:01:00,450
However, for most organizations,

27
00:01:00,450 --> 00:01:02,700
it simply shifted complexity elsewhere.

28
00:01:02,700 --> 00:01:03,900
Let's dive into something,

29
00:01:03,900 --> 00:01:05,850
some of the issues that we've observed.

30
00:01:06,889 --> 00:01:09,990
If you look at today's
modern infrastructure,

31
00:01:09,990 --> 00:01:11,760
it's fractured.

32
00:01:11,760 --> 00:01:13,800
It wasn't built, it evolved.

33
00:01:13,800 --> 00:01:15,660
There's multiple clouds, multiple regions,

34
00:01:15,660 --> 00:01:19,200
on-prem data centers, legacy
applications that can't change,

35
00:01:19,200 --> 00:01:22,920
and most service meshes weren't
built with this in mind.

36
00:01:22,920 --> 00:01:25,620
They struggled to integrate
the brownfield enterprise.

37
00:01:27,450 --> 00:01:29,283
Then, you have the mesh tax.

38
00:01:30,120 --> 00:01:32,700
The two most prominent
architectures and service meshes,

39
00:01:32,700 --> 00:01:33,810
you have the sidecar architecture

40
00:01:33,810 --> 00:01:36,210
and the sidecar-less architecture.

41
00:01:36,210 --> 00:01:38,220
When you look at the sidecar architecture,

42
00:01:38,220 --> 00:01:42,420
it's basically one sidecar per pod

43
00:01:42,420 --> 00:01:45,510
or per instance of your service.

44
00:01:45,510 --> 00:01:47,940
And this simply becomes too expensive

45
00:01:47,940 --> 00:01:49,203
and complex as we scale.

46
00:01:50,730 --> 00:01:52,440
Then, you have the
sidecar-less architecture,

47
00:01:52,440 --> 00:01:56,310
which is better, however
complexity is shifted elsewhere

48
00:01:56,310 --> 00:01:57,180
to different components.

49
00:01:57,180 --> 00:02:01,080
You have the Layer 4
proxy, usually per node,

50
00:02:01,080 --> 00:02:02,490
and then you have Layer 7 proxy,

51
00:02:02,490 --> 00:02:03,812
which is a Layer 7 proxy,

52
00:02:03,812 --> 00:02:06,150
so it's split into distributed components,

53
00:02:06,150 --> 00:02:08,400
usually per namespace or service account

54
00:02:08,400 --> 00:02:11,100
if you're using Kubernetes
and these types of things.

55
00:02:11,100 --> 00:02:13,470
So it's less overall,

56
00:02:13,470 --> 00:02:16,200
but there's still operational complexity

57
00:02:16,200 --> 00:02:17,250
in dealing with that.

58
00:02:18,210 --> 00:02:21,060
And crucially, both
architectures still fail at

59
00:02:21,060 --> 00:02:24,180
preventing resource sprawl as you scale,

60
00:02:24,180 --> 00:02:25,560
managing North-South traffic,

61
00:02:25,560 --> 00:02:27,540
they primarily focus on East-West only,

62
00:02:27,540 --> 00:02:30,344
and federation or
multi-cloud region setups

63
00:02:30,344 --> 00:02:32,670
have difficulty or emerging right now.

64
00:02:32,670 --> 00:02:34,170
They require additional components

65
00:02:34,170 --> 00:02:36,933
or were not considered with
the initial architecture.

66
00:02:38,160 --> 00:02:40,650
So the problem isn't the
service, it's the boundary.

67
00:02:40,650 --> 00:02:42,450
We've been hyper-focused on services,

68
00:02:42,450 --> 00:02:44,790
but the real challenge
is the network boundary.

69
00:02:44,790 --> 00:02:47,280
What if we stop trying to
manage sprawling sidecar

70
00:02:47,280 --> 00:02:48,570
and proxy deployments

71
00:02:48,570 --> 00:02:51,783
and instead deploy strategic
gateways at network boundaries?

72
00:02:53,250 --> 00:02:55,110
This on the HAProxy side

73
00:02:55,110 --> 00:02:57,090
is what we call the universal mesh.

74
00:02:57,090 --> 00:03:00,000
So if you take a look at
it, this is a mock-up,

75
00:03:00,000 --> 00:03:01,860
but it's basically you can have

76
00:03:01,860 --> 00:03:03,150
an outer edge and an inner edge

77
00:03:03,150 --> 00:03:05,340
because HAProxy is omnidirectional.

78
00:03:05,340 --> 00:03:07,800
So it could do North-South or East-West.

79
00:03:07,800 --> 00:03:09,900
And you could take, on the outer edge,

80
00:03:09,900 --> 00:03:12,210
some of the most popular
things are TLS termination,

81
00:03:12,210 --> 00:03:14,730
security, centralized
logging, rate limiting,

82
00:03:14,730 --> 00:03:15,660
and on the inner edge,

83
00:03:15,660 --> 00:03:17,940
it's mostly East-West traffic.

84
00:03:17,940 --> 00:03:21,090
So think about rate limiting,

85
00:03:21,090 --> 00:03:22,740
think about traffic splitting,

86
00:03:22,740 --> 00:03:23,880
other complexities that you see

87
00:03:23,880 --> 00:03:25,593
in today's modern infrastructure.

88
00:03:27,150 --> 00:03:28,710
So if to sum it up,

89
00:03:28,710 --> 00:03:32,637
essentially our universal
mesh is simpler, flexible,

90
00:03:32,637 --> 00:03:35,283
and a more powerful
architecture backed by HAProxy

91
00:03:35,283 --> 00:03:38,013
with 20 years of proven
reverse proxy excellence.

92
00:03:38,910 --> 00:03:41,970
We focus on convergence, federation,

93
00:03:41,970 --> 00:03:43,440
and that gives you the universal mesh.

94
00:03:43,440 --> 00:03:45,480
So on the convergence side,

95
00:03:45,480 --> 00:03:48,450
it's the ingress, the mesh,
and proxies all become one.

96
00:03:48,450 --> 00:03:50,340
It's one HAProxy managing that.

97
00:03:50,340 --> 00:03:52,290
Federation, it's out of the box.

98
00:03:52,290 --> 00:03:54,570
We've built this, we've built
federation with this in mind,

99
00:03:54,570 --> 00:03:57,900
so it's most effortless multi-cluster

100
00:03:57,900 --> 00:03:59,640
or multi-cloud or multi-region

101
00:03:59,640 --> 00:04:01,500
And that gives you unified security,

102
00:04:01,500 --> 00:04:02,820
connectivity and observability,

103
00:04:02,820 --> 00:04:05,010
which is the primary purpose of the mesh.

104
00:04:05,010 --> 00:04:06,390
- Frank, I would just add that I think

105
00:04:06,390 --> 00:04:08,940
that the multi-cloud kind of connectivity

106
00:04:08,940 --> 00:04:11,280
and multi-cluster
connectivity problem is real.

107
00:04:11,280 --> 00:04:12,750
I don't know if you've noticed,

108
00:04:12,750 --> 00:04:16,620
but AWS announced I think
today morning that they're,

109
00:04:16,620 --> 00:04:18,990
they have a new solution
called multi-connect

110
00:04:18,990 --> 00:04:20,310
or something like that,

111
00:04:20,310 --> 00:04:22,500
where they're actually partnering with GCP

112
00:04:22,500 --> 00:04:25,950
to do connectivity between AWS
GCP and then other networks.

113
00:04:25,950 --> 00:04:28,680
So something that you
were able to do before,

114
00:04:28,680 --> 00:04:30,690
but now there's a single API call

115
00:04:30,690 --> 00:04:31,980
to connect all of these clouds.

116
00:04:31,980 --> 00:04:35,640
And they operate on a Layer
3, so different than us,

117
00:04:35,640 --> 00:04:39,600
but this kind of shows you
how much demand there is

118
00:04:39,600 --> 00:04:42,540
for basically multi-cloud, multi-connect,

119
00:04:42,540 --> 00:04:44,640
multi-cluster connectivity

120
00:04:44,640 --> 00:04:47,090
because everybody's trying
to solve this problem.

121
00:04:50,130 --> 00:04:53,763
- So we think the universe mesh
solves impossible problems.

122
00:04:54,900 --> 00:04:55,980
It connects everything.

123
00:04:55,980 --> 00:04:57,420
It's a single pattern that simplifies

124
00:04:57,420 --> 00:05:00,120
operational complexity
and resource utilization.

125
00:05:00,120 --> 00:05:02,940
It's multi-cluster and federation-ready,

126
00:05:02,940 --> 00:05:05,820
so it understands resources
and understands infrastructure,

127
00:05:05,820 --> 00:05:09,150
spans cluster without forcing
architectural compromises.

128
00:05:09,150 --> 00:05:10,650
It's the same pattern everywhere.

129
00:05:10,650 --> 00:05:13,050
And there's flexible deployment.

130
00:05:13,050 --> 00:05:15,060
You can run gateways
external to Kubernetes,

131
00:05:15,060 --> 00:05:20,060
inside Kubernetes, inside
EC2 instances, EKS, ECS.

132
00:05:21,120 --> 00:05:22,203
It's really flexible.

133
00:05:23,790 --> 00:05:24,900
So if you want to take a look at this,

134
00:05:24,900 --> 00:05:27,300
this is kind of a typical mock-up

135
00:05:27,300 --> 00:05:29,280
of an architectural diagram.

136
00:05:29,280 --> 00:05:31,320
You'd have the control
plane, which is fusion.

137
00:05:31,320 --> 00:05:33,360
All service meshes kind of have,

138
00:05:33,360 --> 00:05:35,580
they're broken up with a
control plane and a data plane,

139
00:05:35,580 --> 00:05:38,010
and then you'd have the data
plane layer, which is HAProxy,

140
00:05:38,010 --> 00:05:39,840
which empowers all of the features

141
00:05:39,840 --> 00:05:41,580
that you can see on the side,

142
00:05:41,580 --> 00:05:44,580
and that this is proxying
to any number of services.

143
00:05:44,580 --> 00:05:47,970
If we're talking about AWS, you have,

144
00:05:47,970 --> 00:05:50,280
you can use ECS or
Elastic Container Service,

145
00:05:50,280 --> 00:05:53,340
EC2, auto-scaling groups
as well, Kubernetes,

146
00:05:53,340 --> 00:05:55,530
basically anything we can route to

147
00:05:55,530 --> 00:05:57,120
or we can route to anything.

148
00:05:57,120 --> 00:05:59,880
And then we can also do the
same for any virtual machine

149
00:05:59,880 --> 00:06:01,890
or any on-premise or any other region.

150
00:06:01,890 --> 00:06:03,240
It's basically all controlling

151
00:06:03,240 --> 00:06:05,040
or all controlled
through the control plane

152
00:06:05,040 --> 00:06:07,083
in a single management plane.

153
00:06:08,220 --> 00:06:10,410
So that gives you kind
of the building blocks

154
00:06:10,410 --> 00:06:11,550
of a modern mesh.

155
00:06:11,550 --> 00:06:15,390
On the inside, you want to talk

156
00:06:15,390 --> 00:06:16,890
the most important features are,

157
00:06:16,890 --> 00:06:18,210
you're looking for performance,

158
00:06:18,210 --> 00:06:20,040
you're looking for zero trust,

159
00:06:20,040 --> 00:06:21,990
you're looking for multi-layered security,

160
00:06:21,990 --> 00:06:24,000
authentication and authorization,

161
00:06:24,000 --> 00:06:25,450
and federation again as well.

162
00:06:26,550 --> 00:06:29,229
So let's dive into our sweet spot.

163
00:06:29,229 --> 00:06:32,190
We are the world's fastest
application delivery

164
00:06:32,190 --> 00:06:33,630
and security platform,

165
00:06:33,630 --> 00:06:35,850
and we do have the proof to back it up.

166
00:06:35,850 --> 00:06:39,840
In 2021, we released our article

167
00:06:39,840 --> 00:06:42,570
showing that you can achieve
2 million requests per second

168
00:06:42,570 --> 00:06:44,266
on a single AWS instance.

169
00:06:44,266 --> 00:06:47,340
It was a Graviton2 at the time.

170
00:06:47,340 --> 00:06:50,820
And basically, this has been never seen.

171
00:06:50,820 --> 00:06:52,140
So it's really sheer performance

172
00:06:52,140 --> 00:06:54,570
and it's one of the
core tenets of HAProxy.

173
00:06:54,570 --> 00:06:56,490
In everything that we deliver,

174
00:06:56,490 --> 00:06:59,910
its performance,
reliability, and scalability,

175
00:06:59,910 --> 00:07:01,383
all of that is in mind.

176
00:07:03,060 --> 00:07:06,422
What happened though
is after that release,

177
00:07:06,422 --> 00:07:10,620
in 2023, we realized there was
a dramatic performance loss

178
00:07:10,620 --> 00:07:12,570
in the new LTS version of the current

179
00:07:12,570 --> 00:07:14,820
TLS library we were using,

180
00:07:14,820 --> 00:07:16,080
and efforts with the authors

181
00:07:16,080 --> 00:07:18,030
failed to yield acceptable results.

182
00:07:18,030 --> 00:07:19,080
So what did we do?

183
00:07:19,080 --> 00:07:23,520
In 2024, we reworked our entire TLS stack

184
00:07:23,520 --> 00:07:26,820
to support modern TLS libraries.

185
00:07:26,820 --> 00:07:31,290
And in 2025, released a
performance build using AWS-LC.

186
00:07:31,290 --> 00:07:33,960
That was the one we, that
was the library we selected

187
00:07:33,960 --> 00:07:36,090
as a default TLS library,

188
00:07:36,090 --> 00:07:39,090
and we also have modern
alternative support.

189
00:07:39,090 --> 00:07:41,970
So compatibility supports
for anything that's delivered

190
00:07:41,970 --> 00:07:44,010
by the OS as well, if
you want to use that.

191
00:07:44,010 --> 00:07:46,230
And it's always our commitment
is to do whatever it takes

192
00:07:46,230 --> 00:07:48,360
to deliver the best performance.

193
00:07:48,360 --> 00:07:51,420
And then, we didn't really
release a benchmark,

194
00:07:51,420 --> 00:07:55,350
but we just released HAProxy 3.3,

195
00:07:55,350 --> 00:07:57,420
and we're sharing some of
our internal benchmarks.

196
00:07:57,420 --> 00:07:59,910
So what we've done is we did

197
00:07:59,910 --> 00:08:03,600
the exact same test that we did in 2021.

198
00:08:03,600 --> 00:08:06,967
And obviously, the natural
sentiment we think,

199
00:08:06,967 --> 00:08:10,830
"Oh, since 2021, the hardware has become

200
00:08:10,830 --> 00:08:12,180
so much more powerful.

201
00:08:12,180 --> 00:08:13,470
You should see an increase."

202
00:08:13,470 --> 00:08:18,150
But the reality in today's
world, since 2021 to 2025,

203
00:08:18,150 --> 00:08:20,520
we've actually released
10 separate versions.

204
00:08:20,520 --> 00:08:23,070
And what you're seeing in modern software

205
00:08:23,070 --> 00:08:25,080
is the phenomenon of software bloat.

206
00:08:25,080 --> 00:08:26,821
Every release has more features,

207
00:08:26,821 --> 00:08:30,120
more resource, it takes more resources,

208
00:08:30,120 --> 00:08:32,760
so it basically takes
away from the advantages

209
00:08:32,760 --> 00:08:34,290
that you're gaining from the hardware.

210
00:08:34,290 --> 00:08:38,070
So what we saw when we benched
it on the exact same test,

211
00:08:38,070 --> 00:08:40,200
right now it's pretty much
the exact same instance

212
00:08:40,200 --> 00:08:41,760
except it's the Graviton4,

213
00:08:41,760 --> 00:08:43,680
the most recent graviton
that's been released,

214
00:08:43,680 --> 00:08:46,893
we were able to achieve 2.54
million requests per second.

215
00:08:48,150 --> 00:08:51,240
And to make sure that we're
testing on the same platform,

216
00:08:51,240 --> 00:08:54,630
we re-ran the exact same
version on the exact instance.

217
00:08:54,630 --> 00:08:56,100
So it's not anything related to hardware.

218
00:08:56,100 --> 00:08:58,740
So we took the same instance, we ran 3.3,

219
00:08:58,740 --> 00:09:01,470
then we ran 2.3, which is
the one we ran at the time,

220
00:09:01,470 --> 00:09:03,450
and we yielded better results.

221
00:09:03,450 --> 00:09:05,730
But however, the reality is that

222
00:09:05,730 --> 00:09:09,360
even in 2021, we reached
hardware limitations.

223
00:09:09,360 --> 00:09:12,270
So when you're doing such benchmarks,

224
00:09:12,270 --> 00:09:14,670
you're really limited by the communication

225
00:09:14,670 --> 00:09:16,190
in the internal CPU cache, right?

226
00:09:16,190 --> 00:09:18,420
So if you're doing millions of operations,

227
00:09:18,420 --> 00:09:20,700
the CPU cache and the
communication between it,

228
00:09:20,700 --> 00:09:23,580
there's some resource problems

229
00:09:23,580 --> 00:09:25,260
that are just not there yet on the chips.

230
00:09:25,260 --> 00:09:26,460
And then you're also limited

231
00:09:26,460 --> 00:09:28,980
by the network packets per second.

232
00:09:28,980 --> 00:09:31,710
So even on the most modern CPUs,

233
00:09:31,710 --> 00:09:34,170
there's only 16 network queues available.

234
00:09:34,170 --> 00:09:36,270
And that does seem like a lot,

235
00:09:36,270 --> 00:09:39,679
but when you're talking 4 to
5 million packets per second,

236
00:09:39,679 --> 00:09:42,480
there's a lot of chances that
stuff gets into user land,

237
00:09:42,480 --> 00:09:44,403
so it's consuming resources.

238
00:09:45,240 --> 00:09:46,830
So what we've decided,

239
00:09:46,830 --> 00:09:48,810
because we're reaching the hardware,

240
00:09:48,810 --> 00:09:51,647
we decided that instead of
trying to go for a bigger number,

241
00:09:51,647 --> 00:09:54,390
'cause in reality nobody
really needs this much traffic,

242
00:09:54,390 --> 00:09:57,000
or if you do, it's great to have something

243
00:09:57,000 --> 00:09:58,700
that does it on a single instance,

244
00:09:59,580 --> 00:10:02,700
but we fixed other pieces
of our architecture

245
00:10:02,700 --> 00:10:06,510
such as we optimize more
load-balancing algorithm.

246
00:10:06,510 --> 00:10:10,800
So our least con algorithm,
our default algorithms,

247
00:10:10,800 --> 00:10:13,710
we switched it from round robin to random

248
00:10:13,710 --> 00:10:17,700
and we focused on a lot
of tuning in our queues

249
00:10:17,700 --> 00:10:19,170
and in our counters

250
00:10:19,170 --> 00:10:22,410
to enable to help with other bottlenecks.

251
00:10:22,410 --> 00:10:25,470
'cause once you're at
the reverse proxy level,

252
00:10:25,470 --> 00:10:27,030
you're load balancing traffic

253
00:10:27,030 --> 00:10:28,530
in front of application servers.

254
00:10:28,530 --> 00:10:31,200
And most people provision
their application servers

255
00:10:31,200 --> 00:10:32,640
not to full utilization.

256
00:10:32,640 --> 00:10:34,740
So if you can use the load balancer

257
00:10:34,740 --> 00:10:35,820
to get more efficiency

258
00:10:35,820 --> 00:10:38,100
on your entire form of
application servers,

259
00:10:38,100 --> 00:10:40,327
then you're really gaining overall.

260
00:10:40,327 --> 00:10:42,150
So our queuing system,

261
00:10:42,150 --> 00:10:44,520
it really allows you to utilize

262
00:10:44,520 --> 00:10:46,530
100% performance of your
application servers.

263
00:10:46,530 --> 00:10:49,200
So we're not only empowering performance

264
00:10:49,200 --> 00:10:50,340
on the load balancer level,

265
00:10:50,340 --> 00:10:51,450
we're empowering your performance

266
00:10:51,450 --> 00:10:53,280
on your entire application level as well.

267
00:10:53,280 --> 00:10:57,780
And then if I'm on the
other side of the fence

268
00:10:57,780 --> 00:10:59,340
and I'm actually running something

269
00:10:59,340 --> 00:11:01,560
that needs 2 million
requests per second or more,

270
00:11:01,560 --> 00:11:03,360
I wanna know how much that costs, right?

271
00:11:03,360 --> 00:11:04,470
That's really the most important.

272
00:11:04,470 --> 00:11:06,007
If you go to your CTO, he's gonna ask you,

273
00:11:06,007 --> 00:11:08,110
"How much will it cost me to actually run

274
00:11:09,523 --> 00:11:11,190
this entire workload?"

275
00:11:11,190 --> 00:11:14,434
And if you look at the quick
back of the napkin nap,

276
00:11:14,434 --> 00:11:16,950
back of the napkin math,

277
00:11:16,950 --> 00:11:20,222
you can realize that a billion request,

278
00:11:20,222 --> 00:11:22,770
a billion request actually costs 41 cents

279
00:11:22,770 --> 00:11:24,030
on this instance type.

280
00:11:24,030 --> 00:11:26,610
And we've benched it
that we can get it down

281
00:11:26,610 --> 00:11:28,639
to something on the 20-cent range

282
00:11:28,639 --> 00:11:31,170
if you go for, if you don't need

283
00:11:31,170 --> 00:11:33,003
these amount of cores, 64 cores.

284
00:11:34,440 --> 00:11:38,760
All this to say that when
it comes to performance,

285
00:11:38,760 --> 00:11:41,250
there's nothing that can match HAProxy.

286
00:11:41,250 --> 00:11:45,237
- I would say, Frank,
notice the c8gn instances.

287
00:11:47,520 --> 00:11:50,370
My team actually benchmarks all instances

288
00:11:50,370 --> 00:11:52,354
on AWS with HAProxy,

289
00:11:52,354 --> 00:11:55,320
and we are a very
network-heavy application.

290
00:11:55,320 --> 00:11:58,680
And so, if you go with like c8g instances,

291
00:11:58,680 --> 00:12:00,780
you will very quickly run
out of network limits.

292
00:12:00,780 --> 00:12:04,860
So notice that a lot of the
benchmarks use cgn instances

293
00:12:04,860 --> 00:12:07,020
with the network-optimized cards

294
00:12:07,020 --> 00:12:09,750
because otherwise you're
gonna run out of PPS limits

295
00:12:09,750 --> 00:12:11,850
and bandwidth limit exceeded

296
00:12:11,850 --> 00:12:13,500
and everything else on the instances.

297
00:12:13,500 --> 00:12:15,030
So in these cases,

298
00:12:15,030 --> 00:12:17,730
it's very important to
use the gn instances.

299
00:12:17,730 --> 00:12:18,563
And as you can see,

300
00:12:18,563 --> 00:12:20,940
we're very big fans of
the Graviton ones as well.

301
00:12:20,940 --> 00:12:22,923
So they're the sweet spot for HAProxy.

302
00:12:26,861 --> 00:12:28,680
- Then it comes to federation.

303
00:12:28,680 --> 00:12:33,450
So two HAProxy, NIP as an
IP as long as it's routable.

304
00:12:33,450 --> 00:12:36,570
So that empowers us to
use the control plane

305
00:12:36,570 --> 00:12:40,920
to configure each of our
proxies independently.

306
00:12:40,920 --> 00:12:42,780
So if you take a look at this picture,

307
00:12:42,780 --> 00:12:45,060
the control plane can send
a different configuration

308
00:12:45,060 --> 00:12:48,630
to US-east and to US-west to
each one of those instances,

309
00:12:48,630 --> 00:12:50,940
however since the
control plane knows about

310
00:12:50,940 --> 00:12:52,680
US-east and US-west,

311
00:12:52,680 --> 00:12:54,660
it can also send that
information to all the proxies.

312
00:12:54,660 --> 00:12:56,430
So if there's ever a situation,

313
00:12:56,430 --> 00:12:57,990
and we have a lot of use cases

314
00:12:57,990 --> 00:12:59,340
like on the payment provider side

315
00:12:59,340 --> 00:13:01,650
where people are looking for
the redundancy or backup,

316
00:13:01,650 --> 00:13:03,870
so when a transaction costs money

317
00:13:03,870 --> 00:13:04,830
and if there is a failure,

318
00:13:04,830 --> 00:13:07,020
there are no servers available
in a single instance,

319
00:13:07,020 --> 00:13:08,425
they do want to crossover

320
00:13:08,425 --> 00:13:12,870
even though it may cost a monetary value.

321
00:13:12,870 --> 00:13:13,740
All of these things,

322
00:13:13,740 --> 00:13:15,510
having the control plane outside

323
00:13:15,510 --> 00:13:17,010
talking to the infrastructure

324
00:13:17,010 --> 00:13:18,300
and being aware of the infrastructure,

325
00:13:18,300 --> 00:13:21,180
really enables flexibility

326
00:13:21,180 --> 00:13:24,210
and allows us to be truly any platform,

327
00:13:24,210 --> 00:13:26,370
any service, any infrastructure.

328
00:13:26,370 --> 00:13:29,220
And a lot of the use cases that we see

329
00:13:29,220 --> 00:13:32,130
take full advantage of this.

330
00:13:32,130 --> 00:13:33,000
If you take a look at,

331
00:13:33,000 --> 00:13:36,960
we have a lot of, we have
an ad tech recommendation

332
00:13:36,960 --> 00:13:39,960
for HAProxy in partnership with AWS.

333
00:13:39,960 --> 00:13:43,440
We've worked with a lot of
the 5G or mobile providers

334
00:13:43,440 --> 00:13:47,310
to really expand their coverage
in wavelength zones for AWS

335
00:13:47,310 --> 00:13:51,000
where we install our own software

336
00:13:51,000 --> 00:13:52,440
and then we discover resources

337
00:13:52,440 --> 00:13:54,390
for the 5G Kubernetes cluster,

338
00:13:54,390 --> 00:13:57,570
and basically we offer
native load balancing

339
00:13:57,570 --> 00:13:59,400
for a 5G network in a remote region

340
00:13:59,400 --> 00:14:01,050
where there's only wavelength zones.

341
00:14:01,050 --> 00:14:03,810
And then as I mentioned
on payment provider side,

342
00:14:03,810 --> 00:14:06,450
a lot of payment providers nowadays,

343
00:14:06,450 --> 00:14:09,450
popular ones that are, you could
take a look at our website,

344
00:14:09,450 --> 00:14:11,520
basically they have redundancy across

345
00:14:11,520 --> 00:14:13,588
three or four different regions or zones

346
00:14:13,588 --> 00:14:16,091
and they want to switch over.

347
00:14:16,091 --> 00:14:18,060
They want region affinity,

348
00:14:18,060 --> 00:14:21,480
so they want to stay on the
first one as much as possible.

349
00:14:21,480 --> 00:14:23,400
But in the event of a service failure,

350
00:14:23,400 --> 00:14:24,657
they allow them to cross over

351
00:14:24,657 --> 00:14:29,040
and they want us to prioritize
which ones to cross over to,

352
00:14:29,040 --> 00:14:31,410
and that's all configurable
out of the control plane

353
00:14:31,410 --> 00:14:32,860
and out of the configuration.

354
00:14:35,010 --> 00:14:37,710
Then, a key point of a
service mesh is zero trust.

355
00:14:37,710 --> 00:14:41,370
So in terms of TLS, in
terms of certificates,

356
00:14:41,370 --> 00:14:43,650
this is all handled between HAProxy

357
00:14:43,650 --> 00:14:45,030
and the control plane itself,

358
00:14:45,030 --> 00:14:48,300
either renewing the certificates,

359
00:14:48,300 --> 00:14:49,950
accepting and verifying the certificates,

360
00:14:49,950 --> 00:14:51,780
even on health checks
to the back-end servers,

361
00:14:51,780 --> 00:14:54,540
client certificates, CA certificates,

362
00:14:54,540 --> 00:14:57,540
all that stuff is handled
out of the box with HAProxy.

363
00:14:57,540 --> 00:15:00,120
And then, we slide back
to the slide before,

364
00:15:00,120 --> 00:15:01,520
you look at the performance.

365
00:15:02,520 --> 00:15:06,270
We optimize performance at
level and we monitor it,

366
00:15:06,270 --> 00:15:10,350
as I mentioned before,
we even move to AWS-LC,

367
00:15:10,350 --> 00:15:13,200
which is kind of giving us more options on

368
00:15:13,200 --> 00:15:18,200
the new types of quantum
encryption and stuff like that.

369
00:15:18,390 --> 00:15:19,650
Haven't seen many use cases yet,

370
00:15:19,650 --> 00:15:22,530
but we're trying to move
to a modern TLS library

371
00:15:22,530 --> 00:15:25,980
that can enable these
workloads in the future.

372
00:15:25,980 --> 00:15:29,190
And we're always on the
precipice of new technology,

373
00:15:29,190 --> 00:15:30,023
we are looking...

374
00:15:30,023 --> 00:15:32,910
We just released our experimental
version of kernel TLS

375
00:15:32,910 --> 00:15:34,740
and Encrypted Client Hello,

376
00:15:34,740 --> 00:15:36,300
so we're really being on the forefront

377
00:15:36,300 --> 00:15:39,243
of all these platforms
and our all these RFCs.

378
00:15:41,130 --> 00:15:44,460
Then another piece
that's really interesting

379
00:15:44,460 --> 00:15:46,740
when it comes to a service mesh is really

380
00:15:46,740 --> 00:15:48,543
authentication or authorization.

381
00:15:50,310 --> 00:15:52,590
Basically, this diagram kind of shows you

382
00:15:52,590 --> 00:15:54,840
how authentication and SSO modules work.

383
00:15:54,840 --> 00:15:58,664
We do have modules on the enterprise side.

384
00:15:58,664 --> 00:16:01,890
We can handle anything from openid, saml,

385
00:16:01,890 --> 00:16:04,893
we even have adfs proxy protocol as,

386
00:16:05,880 --> 00:16:09,150
there's a specific
Microsoft standard for adfs.

387
00:16:09,150 --> 00:16:10,590
We have a module for that.

388
00:16:10,590 --> 00:16:15,590
But in theory, basically, client
presents itself to HAProxy,

389
00:16:15,983 --> 00:16:20,850
HAProxy can redirect or talk
to the IDP in the background,

390
00:16:20,850 --> 00:16:24,210
and then pass on that information
to the back-end server.

391
00:16:24,210 --> 00:16:25,773
So it's kind of seamless.

392
00:16:27,420 --> 00:16:29,940
Then, you just have, maybe you have APIs

393
00:16:29,940 --> 00:16:31,740
or you're using JWTs.

394
00:16:31,740 --> 00:16:34,410
We have native support for JSON and JWTs.

395
00:16:34,410 --> 00:16:37,230
So basically, these
functions can help you find

396
00:16:37,230 --> 00:16:41,040
the algorithm, the issuer,
the expiry, the scope,

397
00:16:41,040 --> 00:16:43,440
all that information
can all be natively done

398
00:16:43,440 --> 00:16:46,860
inside of HAProxy and
has been for a while.

399
00:16:46,860 --> 00:16:49,579
And then you can, based on what you find,

400
00:16:49,579 --> 00:16:52,560
you can actually deny, approve,

401
00:16:52,560 --> 00:16:55,560
and you can build your own
access control list on that side.

402
00:16:55,560 --> 00:16:58,890
- [Jakub] As a side note,
HAProxy 3.3 that was released

403
00:16:58,890 --> 00:17:00,690
yesterday, not yesterday, last week.

404
00:17:00,690 --> 00:17:01,523
- Last week, yeah.

405
00:17:01,523 --> 00:17:04,140
- [Jakub] ... last week
added support for JWE tokens.

406
00:17:04,140 --> 00:17:07,080
So those are the encrypted JWT tokens.

407
00:17:07,080 --> 00:17:10,410
So you can actually now
not just verify JWT tokens,

408
00:17:10,410 --> 00:17:13,380
but you can decrypt them
first and then verify them.

409
00:17:13,380 --> 00:17:16,350
So that was added to 3.3.

410
00:17:16,350 --> 00:17:17,183
- Exactly.

411
00:17:18,270 --> 00:17:21,866
And then common, sometimes
you want to have a language

412
00:17:21,866 --> 00:17:24,030
based on the results
that you're gonna get,

413
00:17:24,030 --> 00:17:25,920
and we see a lot of it in the field,

414
00:17:25,920 --> 00:17:28,740
we see a lot of OPA,
so open policy agents.

415
00:17:28,740 --> 00:17:30,630
So we do have support for that as well.

416
00:17:30,630 --> 00:17:34,410
So if you need more complex policies,

417
00:17:34,410 --> 00:17:36,900
you can define a policy in Rego

418
00:17:36,900 --> 00:17:38,970
and basically we parse the input

419
00:17:38,970 --> 00:17:41,820
and we decide to allow
it or not based on that.

420
00:17:41,820 --> 00:17:43,320
So it's really super flexible

421
00:17:43,320 --> 00:17:45,570
in terms of authentication
and authorization.

422
00:17:47,010 --> 00:17:48,480
And then, I'm gonna hand it over to Jakub

423
00:17:48,480 --> 00:17:51,543
to go over our multi-layered
security capabilities.

424
00:17:53,550 --> 00:17:54,383
- Thank you.

425
00:17:54,383 --> 00:17:55,980
So I'm gonna talk about
multi-layered security,

426
00:17:55,980 --> 00:17:59,790
and really first introduce
what it means to me

427
00:17:59,790 --> 00:18:01,830
to talk about multi-layered security.

428
00:18:01,830 --> 00:18:04,500
And then, I'll talk about
how we're achieving that

429
00:18:04,500 --> 00:18:08,100
in HAProxy in context
of performance, right?

430
00:18:08,100 --> 00:18:10,920
Because you've noticed that we
talk about performance a lot

431
00:18:10,920 --> 00:18:13,080
because in many cases,

432
00:18:13,080 --> 00:18:16,260
security means performance implications,

433
00:18:16,260 --> 00:18:19,140
and we don't think that
should be true, right?

434
00:18:19,140 --> 00:18:24,140
So to me, multi-layered
security means a lot

435
00:18:24,780 --> 00:18:27,420
combined with authentication,
authorization,

436
00:18:27,420 --> 00:18:29,160
everything that Frank talked about,

437
00:18:29,160 --> 00:18:32,310
but also detecting
application-layer DDoS attacks,

438
00:18:32,310 --> 00:18:35,430
web scraping, brute forcing, comment spam,

439
00:18:35,430 --> 00:18:38,430
vulnerability scanning, some
specific targeted exploitation.

440
00:18:38,430 --> 00:18:40,710
And I'm gonna talk about the details here.

441
00:18:40,710 --> 00:18:43,349
The web scraping, to me, is
one of the most important ones

442
00:18:43,349 --> 00:18:47,190
because obviously with AI,

443
00:18:47,190 --> 00:18:49,050
since we're all using AI, right,

444
00:18:49,050 --> 00:18:52,500
there are a lot of websites
out there announcing

445
00:18:52,500 --> 00:18:56,160
they're struggling with AI bots
scraping all of their sites

446
00:18:56,160 --> 00:18:57,660
and there are many protections,

447
00:18:57,660 --> 00:19:00,750
and you can definitely use
protections from HAProxy,

448
00:19:00,750 --> 00:19:03,480
but there are many others to stop AI bots

449
00:19:03,480 --> 00:19:05,190
from scraping your site

450
00:19:05,190 --> 00:19:09,210
while you're fighting some
targeted attacks from AI scrapers

451
00:19:09,210 --> 00:19:12,150
that are just trying to get
everything from your website.

452
00:19:12,150 --> 00:19:15,330
So I usually define this as

453
00:19:15,330 --> 00:19:18,237
multiple layers of
detection and decisioning.

454
00:19:18,237 --> 00:19:20,640
And the reality is that
I'm gonna talk about

455
00:19:20,640 --> 00:19:23,490
these layers as four separate layers,

456
00:19:23,490 --> 00:19:26,220
but they all actually
work at the same time.

457
00:19:26,220 --> 00:19:30,660
So the fact that I have
chosen to place these layers

458
00:19:30,660 --> 00:19:34,200
in this order is just my choice, right?

459
00:19:34,200 --> 00:19:35,580
In the end, they all,

460
00:19:35,580 --> 00:19:38,550
all of what I'm gonna talk
about happens at the same time.

461
00:19:38,550 --> 00:19:43,470
So I should be able to choose
which layer reacts first,

462
00:19:43,470 --> 00:19:46,470
or just do all of the detection first

463
00:19:46,470 --> 00:19:49,740
and then make a decision later
with some exceptions, right?

464
00:19:49,740 --> 00:19:52,650
Because, for example here,
we're applying access control.

465
00:19:52,650 --> 00:19:54,690
So if I'm applying the access control,

466
00:19:54,690 --> 00:19:59,490
and for example, I'm denylisting
a specific IP address,

467
00:19:59,490 --> 00:20:01,410
well if I've denylisted an IP address,

468
00:20:01,410 --> 00:20:04,560
it doesn't make sense to try
to detect if it's a bot or not.

469
00:20:04,560 --> 00:20:05,670
It doesn't matter to me.

470
00:20:05,670 --> 00:20:07,050
I'm gonna deny it anyway, right?

471
00:20:07,050 --> 00:20:08,940
So I can just deny right away.

472
00:20:08,940 --> 00:20:13,350
So access control, like
deny specific IP addresses,

473
00:20:13,350 --> 00:20:15,540
allow internal IP addresses,

474
00:20:15,540 --> 00:20:18,240
allow specific monitoring systems

475
00:20:18,240 --> 00:20:20,640
or deny specific fingerprints

476
00:20:20,640 --> 00:20:22,860
or IP addresses coming from bots, right?

477
00:20:22,860 --> 00:20:26,670
This is where we're kind of
starting that idea of the bots.

478
00:20:26,670 --> 00:20:30,090
The idea that we use in HAProxy,

479
00:20:30,090 --> 00:20:33,210
and this is thanks to
the HAProxy community

480
00:20:33,210 --> 00:20:35,250
support for large files,

481
00:20:35,250 --> 00:20:37,260
is that you can actually put millions

482
00:20:37,260 --> 00:20:39,360
of IP addresses inside HAProxy

483
00:20:39,360 --> 00:20:41,760
and say "Deny based on this list."

484
00:20:41,760 --> 00:20:45,000
And looking up that IP
address in that list,

485
00:20:45,000 --> 00:20:46,500
whether you're looking up the first one

486
00:20:46,500 --> 00:20:50,280
or the number 1 million will
take a constant amount of time,

487
00:20:50,280 --> 00:20:54,600
so you don't have to
worry about how to scale

488
00:20:54,600 --> 00:20:57,240
for a large amount of IP address blocks.

489
00:20:57,240 --> 00:21:00,480
This is all thanks to Will Tarreau,

490
00:21:00,480 --> 00:21:02,340
who's the founder of HAProxy,

491
00:21:02,340 --> 00:21:04,230
created this unique data structure

492
00:21:04,230 --> 00:21:05,940
called Elastic Binary Tree.

493
00:21:05,940 --> 00:21:07,500
I recommended write-up.

494
00:21:07,500 --> 00:21:10,860
If you ever Google Elastic Binary Tree,

495
00:21:10,860 --> 00:21:12,510
he has a big write-up on how it works

496
00:21:12,510 --> 00:21:14,913
and how it scales to millions of items.

497
00:21:16,530 --> 00:21:19,290
Then, I start rate calculation.

498
00:21:19,290 --> 00:21:23,940
So I'm not denying, but I'm
calculating specific rates.

499
00:21:23,940 --> 00:21:26,310
And even here I'm saying,
"Is it over a rate limit?"

500
00:21:26,310 --> 00:21:28,740
But I don't care if it's
over a rate limit yet,

501
00:21:28,740 --> 00:21:30,630
I'm just calculating a rate, right?

502
00:21:30,630 --> 00:21:35,190
So I'm figuring out
based on an IP address,

503
00:21:35,190 --> 00:21:38,520
bandwidth, label of a bot, URL

504
00:21:38,520 --> 00:21:42,420
what's the rate of the request
from this specific client?

505
00:21:42,420 --> 00:21:46,260
So rate limit is all
about grouping clients

506
00:21:46,260 --> 00:21:50,077
or identifying individual
clients and saying,

507
00:21:50,077 --> 00:21:51,660
"What's the rate of their request

508
00:21:51,660 --> 00:21:53,277
so I can make decisions later?"

509
00:21:54,450 --> 00:21:56,910
The problem is that in our experience,

510
00:21:56,910 --> 00:21:59,940
static limits are hard, and
we think there's a better way.

511
00:21:59,940 --> 00:22:03,270
I don't know if you've ever
ran rate limit in practice

512
00:22:03,270 --> 00:22:06,690
in your own HAProxy or
any other reverse proxy,

513
00:22:06,690 --> 00:22:07,620
but every time...

514
00:22:07,620 --> 00:22:10,230
I think, Frank, in production,
you ran this, right?

515
00:22:10,230 --> 00:22:11,880
Every time you set up rate limits,

516
00:22:11,880 --> 00:22:14,370
you get it wrong every single time,

517
00:22:14,370 --> 00:22:16,650
and now you don't know what the
rate limit should be, right?

518
00:22:16,650 --> 00:22:18,613
Should it be 100 requests a second,

519
00:22:18,613 --> 00:22:20,460
1,000 requests a second?

520
00:22:20,460 --> 00:22:23,460
What if my traffic is normally
100 requests a second,

521
00:22:23,460 --> 00:22:26,190
but I spike 2,000 requests
a second every day

522
00:22:26,190 --> 00:22:27,660
during a specific hour?

523
00:22:27,660 --> 00:22:29,160
Then I have to set the rate limit up

524
00:22:29,160 --> 00:22:31,830
to that specific very high rate, right?

525
00:22:31,830 --> 00:22:36,180
But then I can be attacked
during the low traffic periods.

526
00:22:36,180 --> 00:22:40,140
So we built something we call
a global profiling engine

527
00:22:40,140 --> 00:22:43,230
that allows me to aggregate statistics

528
00:22:43,230 --> 00:22:47,020
and aggregate rates across
multiple instances of HAProxy

529
00:22:47,910 --> 00:22:50,940
and then calculate
statistical aggregation.

530
00:22:50,940 --> 00:22:52,567
So I can do things like,

531
00:22:52,567 --> 00:22:57,567
"Hey, I'm gonna rate limit bots
over 1.5 to 95th percentile

532
00:22:58,080 --> 00:23:00,930
of the rate same hour yesterday."

533
00:23:00,930 --> 00:23:04,050
So I take a look at what's
the rate of the requests

534
00:23:04,050 --> 00:23:06,570
during the same hour yesterday,

535
00:23:06,570 --> 00:23:09,390
and then I take a 95th percentile on that,

536
00:23:09,390 --> 00:23:10,980
and that's a specific number.

537
00:23:10,980 --> 00:23:13,200
And I don't wanna probably block

538
00:23:13,200 --> 00:23:16,290
or deny on that specific number

539
00:23:16,290 --> 00:23:19,320
because that's a 95 percentile, right?

540
00:23:19,320 --> 00:23:21,900
But let's decide on a ratio, 1.52,

541
00:23:21,900 --> 00:23:23,670
depending on who it is.

542
00:23:23,670 --> 00:23:27,060
And I start blocking on that
or rate limited on that,

543
00:23:27,060 --> 00:23:29,850
and that gives me dynamic rate limit.

544
00:23:29,850 --> 00:23:33,030
So I no longer have to
set static rate limits.

545
00:23:33,030 --> 00:23:34,770
I do it dynamically.

546
00:23:34,770 --> 00:23:37,710
And basically, the rate
limit actually changes

547
00:23:37,710 --> 00:23:40,470
every hour or every second
or every five seconds

548
00:23:40,470 --> 00:23:42,183
depending on how I set it up.

549
00:23:43,380 --> 00:23:45,753
Next is bot detection.

550
00:23:46,980 --> 00:23:48,420
There are a lot of bots out there.

551
00:23:48,420 --> 00:23:51,300
There are bot-scraping
companies at the expo

552
00:23:51,300 --> 00:23:54,720
right next to us selling
bot solutions, right?

553
00:23:54,720 --> 00:23:58,110
And so, the reality is
that a lot of people

554
00:23:58,110 --> 00:24:02,730
want to detect if the request
came from a bot or not.

555
00:24:02,730 --> 00:24:05,820
And I'm not saying that if
the request came from a bot,

556
00:24:05,820 --> 00:24:06,930
that's a bad thing.

557
00:24:06,930 --> 00:24:07,980
It might not be a bad thing

558
00:24:07,980 --> 00:24:10,380
for your specific situation, right?

559
00:24:10,380 --> 00:24:12,159
But maybe you need to know

560
00:24:12,159 --> 00:24:15,090
and you need to be able to identify those

561
00:24:15,090 --> 00:24:16,440
and identify crawlers,

562
00:24:16,440 --> 00:24:18,600
and that's the AI thing right now, right?

563
00:24:18,600 --> 00:24:22,080
Can you identify crawlers
that are based on AI

564
00:24:22,080 --> 00:24:24,397
that are good companies
out there that will say,

565
00:24:24,397 --> 00:24:26,880
"Hey, I'm OpenAI," right,

566
00:24:26,880 --> 00:24:29,580
and there are bad companies
out there that will hide

567
00:24:29,580 --> 00:24:33,540
they're an AI scraper and
try to hide that from you

568
00:24:33,540 --> 00:24:36,240
so they present themselves
as a standard browser

569
00:24:36,240 --> 00:24:38,640
while it's one of the top four

570
00:24:38,640 --> 00:24:41,280
or top five AI companies out there.

571
00:24:41,280 --> 00:24:42,530
I'm not gonna name there.

572
00:24:44,610 --> 00:24:47,070
And then, so think about this,

573
00:24:47,070 --> 00:24:50,610
I did access control, I determined rates,

574
00:24:50,610 --> 00:24:52,945
I determined if it's a bot or not,

575
00:24:52,945 --> 00:24:55,800
now I need to do some security

576
00:24:55,800 --> 00:24:58,950
in terms of attacks, right?

577
00:24:58,950 --> 00:25:03,540
So I should run a web
application firewall.

578
00:25:03,540 --> 00:25:06,690
And the problem with web
application firewalls usually

579
00:25:06,690 --> 00:25:09,030
is latency and throughput.

580
00:25:09,030 --> 00:25:12,720
So if you just enable standard
web application firewall

581
00:25:12,720 --> 00:25:15,000
like one of the open source versions,

582
00:25:15,000 --> 00:25:18,180
you will find out that
your latency goes up

583
00:25:18,180 --> 00:25:21,480
and your throughput on your
reverse proxies goes down

584
00:25:21,480 --> 00:25:25,890
because it just takes a lot to
actually detect the traffic.

585
00:25:25,890 --> 00:25:28,470
So we actually built a WAF

586
00:25:28,470 --> 00:25:32,250
with a latency that is not detectable.

587
00:25:32,250 --> 00:25:35,430
So we had our own conference

588
00:25:35,430 --> 00:25:37,627
and we had a customer of
ours came in and said,

589
00:25:37,627 --> 00:25:40,170
"We enabled the WAF,
and then we got confused

590
00:25:40,170 --> 00:25:42,810
because it felt like nothing happened,"

591
00:25:42,810 --> 00:25:45,390
because they couldn't detect
a statistical difference

592
00:25:45,390 --> 00:25:48,097
in first time to bite
when they enabled the WAF.

593
00:25:49,320 --> 00:25:52,140
And then, I did a lot of detection.

594
00:25:52,140 --> 00:25:54,695
And the reality is, as I mentioned,

595
00:25:54,695 --> 00:25:59,310
you should decide early
in specific situations.

596
00:25:59,310 --> 00:26:01,350
If an IP address is on a denylist,

597
00:26:01,350 --> 00:26:02,850
we'll deny it right away.

598
00:26:02,850 --> 00:26:06,930
We don't need to go all through
the hassle of bot detection,

599
00:26:06,930 --> 00:26:08,880
WAF filter and everything else.

600
00:26:08,880 --> 00:26:10,320
Deny it right away, right,

601
00:26:10,320 --> 00:26:13,410
so you can do some early decisioning.

602
00:26:13,410 --> 00:26:17,130
But very often we see the
customers do decisioning later

603
00:26:17,130 --> 00:26:18,990
once they do all of the detection,

604
00:26:18,990 --> 00:26:20,490
and they decide on a response.

605
00:26:20,490 --> 00:26:22,183
So I can deny the request,

606
00:26:22,183 --> 00:26:24,033
I can allow it, I can tarpit it.

607
00:26:24,033 --> 00:26:26,945
It's a very popular thing where,

608
00:26:26,945 --> 00:26:28,710
for example, on our network,

609
00:26:28,710 --> 00:26:30,240
I don't know if you wanna mention that,

610
00:26:30,240 --> 00:26:34,770
we tarpit customers or bots or bad clients

611
00:26:34,770 --> 00:26:36,570
instead of denying them.

612
00:26:36,570 --> 00:26:38,010
Because if we deny them,

613
00:26:38,010 --> 00:26:40,410
they will detect we've denied them

614
00:26:40,410 --> 00:26:45,410
and they will adjust, right,
so we tarpit them instead.

615
00:26:45,480 --> 00:26:47,520
- Yeah, blocking is not
something we often see

616
00:26:47,520 --> 00:26:49,800
or people usually have options to to do.

617
00:26:49,800 --> 00:26:52,110
So it takes a lot of
decisions on the product side

618
00:26:52,110 --> 00:26:54,300
or as an organization has to go through

619
00:26:54,300 --> 00:26:55,440
change requests and stuff like that.

620
00:26:55,440 --> 00:26:56,730
So it's not something we see commonly.

621
00:26:56,730 --> 00:27:00,570
So we do offer you the ability
to make any decision, right,

622
00:27:00,570 --> 00:27:03,090
or label it, observe it,
and make the decision later.

623
00:27:03,090 --> 00:27:05,190
So this is, it's completely configurable

624
00:27:05,190 --> 00:27:07,650
and that's some of the power
that we're offering as well.

625
00:27:07,650 --> 00:27:09,240
- Yeah, most of our customers tarpit

626
00:27:09,240 --> 00:27:12,090
or send traffic to limited back-end.

627
00:27:12,090 --> 00:27:14,730
So like if you have a back-end
with your real servers

628
00:27:14,730 --> 00:27:18,000
that can handle 10,000 requests a second,

629
00:27:18,000 --> 00:27:21,210
they'll send the bad
behavior to a back-end

630
00:27:21,210 --> 00:27:23,700
that can handle 100 requests a second.

631
00:27:23,700 --> 00:27:26,370
So the users will not get blocked,

632
00:27:26,370 --> 00:27:28,650
the bad users will not get blocked,

633
00:27:28,650 --> 00:27:31,170
but at some point they're
gonna run out of resources

634
00:27:31,170 --> 00:27:35,100
and think, "Oh I succeeded,
I brought your website down,"

635
00:27:35,100 --> 00:27:36,810
and they might stop, right?

636
00:27:36,810 --> 00:27:39,120
But in the end, your
normal users are still

637
00:27:39,120 --> 00:27:40,680
going through the fast back-end

638
00:27:40,680 --> 00:27:43,350
because you just limited the bad behavior.

639
00:27:43,350 --> 00:27:46,590
So you don't show the
users, the bad users,

640
00:27:46,590 --> 00:27:48,360
what happened and what you're doing

641
00:27:48,360 --> 00:27:50,640
because, again, once
you start blocking them,

642
00:27:50,640 --> 00:27:53,700
our experience is that
they start adjusting.

643
00:27:53,700 --> 00:27:56,495
And so, you will be
playing a cat and mouse.

644
00:27:56,495 --> 00:27:59,340
The other thing that very often we see is

645
00:27:59,340 --> 00:28:02,310
show a captcha or some
kind of a challenge.

646
00:28:02,310 --> 00:28:04,620
This is one of the popular
solutions recently.

647
00:28:04,620 --> 00:28:07,110
I don't know if you've heard
of like JavaScript challenges,

648
00:28:07,110 --> 00:28:09,997
Anubis, and a few others, which is really,

649
00:28:09,997 --> 00:28:12,420
"I'm gonna allow the request
but I'm gonna ask you

650
00:28:12,420 --> 00:28:15,660
to calculate two prime numbers first

651
00:28:15,660 --> 00:28:19,560
and I want you to take 500
milliseconds doing that," right,

652
00:28:19,560 --> 00:28:22,057
to slow them down with the idea of,

653
00:28:22,057 --> 00:28:23,640
"I'm not gonna block them

654
00:28:23,640 --> 00:28:26,100
but I wanna make it a
little bit more expensive

655
00:28:26,100 --> 00:28:28,020
for them to succeed,

656
00:28:28,020 --> 00:28:30,720
to kind of reduce the amount
of traffic they can run."

657
00:28:33,660 --> 00:28:37,110
And then, again, we said
we're taking all of the layers

658
00:28:37,110 --> 00:28:38,610
and we're making business decisions now.

659
00:28:38,610 --> 00:28:41,070
And this is the important part, this is,

660
00:28:41,070 --> 00:28:43,477
you should not let anybody to say,

661
00:28:43,477 --> 00:28:44,610
"Hey, this is what you should do."

662
00:28:44,610 --> 00:28:47,160
It's a business decision
to allow a request

663
00:28:47,160 --> 00:28:49,860
or to deny a request or block a bot

664
00:28:49,860 --> 00:28:52,350
or give them a JavaScript challenge.

665
00:28:52,350 --> 00:28:54,300
And then finally we route them, right?

666
00:28:54,300 --> 00:28:56,670
And so we're a reverse
proxy, we're a load balancer.

667
00:28:56,670 --> 00:29:00,450
So we route the requests, but
we augment them with data.

668
00:29:00,450 --> 00:29:03,360
So GeoIP data, we rewrite the headers,

669
00:29:03,360 --> 00:29:05,940
device information, and
a few things like that.

670
00:29:05,940 --> 00:29:08,610
And some of the standard
routing you're used to

671
00:29:08,610 --> 00:29:11,940
from reverse proxies like
based on SNI, cookies,

672
00:29:11,940 --> 00:29:14,850
path, or anything else in the request,

673
00:29:14,850 --> 00:29:18,030
we uniquely have access to
the entire HTP request, right?

674
00:29:18,030 --> 00:29:20,430
So we can decide how to route,

675
00:29:20,430 --> 00:29:23,280
we can decide to route on an AI model.

676
00:29:23,280 --> 00:29:25,740
If the request is for a specific AI model,

677
00:29:25,740 --> 00:29:27,600
we can route it to a different back-end

678
00:29:27,600 --> 00:29:29,673
based on the data in the request itself.

679
00:29:30,510 --> 00:29:33,750
So again, the idea is
that we're gonna protect

680
00:29:33,750 --> 00:29:35,700
against application layer attacks,

681
00:29:35,700 --> 00:29:37,830
web scrapers, brute forces,

682
00:29:37,830 --> 00:29:40,740
spam on forms and everything else,

683
00:29:40,740 --> 00:29:44,013
targeted exploitation,
scanning, and everything else.

684
00:29:45,690 --> 00:29:47,730
I talked about this actually last year

685
00:29:47,730 --> 00:29:48,750
at a different conference,

686
00:29:48,750 --> 00:29:51,660
but there are obviously
Edge cases to this, right,

687
00:29:51,660 --> 00:29:53,640
at the Edge, as I call it.

688
00:29:53,640 --> 00:29:56,160
So for example, LLMs.

689
00:29:56,160 --> 00:29:57,780
Everybody's doing vibe coding now,

690
00:29:57,780 --> 00:30:00,060
everybody's doing AI.

691
00:30:00,060 --> 00:30:04,500
And the idea of securing AI
is pretty unique and new.

692
00:30:04,500 --> 00:30:08,640
So we are seeing customers
doing new kind of protections

693
00:30:08,640 --> 00:30:11,490
like rate limiting based on
tokens instead of requests

694
00:30:11,490 --> 00:30:14,250
because requests are cheap,
tokens are expensive.

695
00:30:14,250 --> 00:30:15,840
PII detection,

696
00:30:15,840 --> 00:30:18,480
this is very prevalent
in like big enterprises

697
00:30:18,480 --> 00:30:21,660
where they don't wanna send PII to the AI,

698
00:30:21,660 --> 00:30:24,660
they don't wanna output PII, right,

699
00:30:24,660 --> 00:30:25,885
but most likely,

700
00:30:25,885 --> 00:30:29,550
most often they don't wanna
send the PII to the AI.

701
00:30:29,550 --> 00:30:32,250
So they wanna detect that
as quickly as possible

702
00:30:32,250 --> 00:30:35,700
and figure out if there's any
PII and block the request.

703
00:30:35,700 --> 00:30:38,650
And then API key protection,
which is standard API gateway.

704
00:30:40,050 --> 00:30:44,104
So I'm gonna show you an
example implementation of this,

705
00:30:44,104 --> 00:30:46,170
and then actually when I do my demo,

706
00:30:46,170 --> 00:30:48,210
I'll show you everything running.

707
00:30:48,210 --> 00:30:51,240
But this is an implementation
that I did myself.

708
00:30:51,240 --> 00:30:53,280
You don't have to
implement the same thing,

709
00:30:53,280 --> 00:30:55,470
you can if you want, but I did it myself.

710
00:30:55,470 --> 00:30:58,770
So I've decided that we're
gonna do a couple of things,

711
00:30:58,770 --> 00:31:00,870
we're gonna deny, rate limit, challenge,

712
00:31:00,870 --> 00:31:02,760
sandbox, and then allow.

713
00:31:02,760 --> 00:31:05,970
And so, I'm denylisting
bots and IP addresses

714
00:31:05,970 --> 00:31:08,430
that are on a specific list.

715
00:31:08,430 --> 00:31:11,710
I'm denylisting anybody
who's triggering a WAF

716
00:31:12,570 --> 00:31:15,660
over three triggers that's a human.

717
00:31:15,660 --> 00:31:17,645
This is another thing that we've noticed.

718
00:31:17,645 --> 00:31:20,227
Even our largest customers,
very often they say,

719
00:31:20,227 --> 00:31:22,350
"You know what, we're running a WAF.

720
00:31:22,350 --> 00:31:25,440
We don't wanna block
traffic even with the WAF

721
00:31:25,440 --> 00:31:27,420
because that's a big decision."

722
00:31:27,420 --> 00:31:31,020
So they allow one or two
violations to go through

723
00:31:31,020 --> 00:31:33,210
before they start denylisting the traffic.

724
00:31:33,210 --> 00:31:37,950
So if I'm a human, I can
trigger the WAF once, twice,

725
00:31:37,950 --> 00:31:41,640
but three times, then
I'm gonna be denylisted.

726
00:31:41,640 --> 00:31:43,448
So we see that all the time.

727
00:31:43,448 --> 00:31:47,310
Rate limit bots over a specific
anomalous threshold, right?

728
00:31:47,310 --> 00:31:50,230
Like, very often what I do is

729
00:31:51,180 --> 00:31:56,130
allow humans to do 3x the 95th percentile,

730
00:31:56,130 --> 00:32:01,130
allow suspicious clients to do
2x and allow bots 1.5, right?

731
00:32:01,410 --> 00:32:03,900
So humans have the most leeway

732
00:32:03,900 --> 00:32:07,800
in terms of how much rate
they can actually run

733
00:32:07,800 --> 00:32:12,026
versus bots have the
least amount of leeway.

734
00:32:12,026 --> 00:32:13,890
- And in today's day and age,

735
00:32:13,890 --> 00:32:15,600
you kind of have to have
both sides of the coin.

736
00:32:15,600 --> 00:32:17,370
You have to have reputational signals,

737
00:32:17,370 --> 00:32:18,810
which we're providing here as well,

738
00:32:18,810 --> 00:32:20,843
but you also have to behavioral

739
00:32:20,843 --> 00:32:22,620
because with AI and agents nowadays,

740
00:32:22,620 --> 00:32:24,750
it's almost undetectable,

741
00:32:24,750 --> 00:32:26,160
headless browsers and these types things.

742
00:32:26,160 --> 00:32:28,050
So you need a lot of combinations,

743
00:32:28,050 --> 00:32:30,330
and this allows you to
kind of perform that

744
00:32:30,330 --> 00:32:31,710
with all of our tools.

745
00:32:31,710 --> 00:32:32,940
- Yeah, absolutely.

746
00:32:32,940 --> 00:32:37,170
And so, we talked about the whats,

747
00:32:37,170 --> 00:32:39,720
and let's talk a little
bit more about the how.

748
00:32:39,720 --> 00:32:43,290
So this is how we do the configuration

749
00:32:43,290 --> 00:32:45,540
and this is how we show our customers

750
00:32:45,540 --> 00:32:47,130
how to do the configuration.

751
00:32:47,130 --> 00:32:48,930
And we ultimately centralize everything

752
00:32:48,930 --> 00:32:50,280
into the control plane.

753
00:32:50,280 --> 00:32:51,300
And with the control plane,

754
00:32:51,300 --> 00:32:52,860
we centralize all of the policies

755
00:32:52,860 --> 00:32:54,300
so you can then deploy them

756
00:32:54,300 --> 00:32:57,180
across all of your public clouds, VMs,

757
00:32:57,180 --> 00:33:00,330
on-premises, Kubernetes,
and anywhere else.

758
00:33:00,330 --> 00:33:05,330
And the way we do it is
through a unified control plane

759
00:33:05,400 --> 00:33:08,430
where you basically
deploy configuration once

760
00:33:08,430 --> 00:33:11,490
and it's deployed to all
of your HAProxy instances

761
00:33:11,490 --> 00:33:13,590
and you apply security profiles.

762
00:33:13,590 --> 00:33:16,230
So think about like all
of the security you need

763
00:33:16,230 --> 00:33:18,600
to configure on all of the configuration.

764
00:33:18,600 --> 00:33:22,890
When I first made the security
recipe I've shown you before,

765
00:33:22,890 --> 00:33:26,160
it was like 200 lines of configuration.

766
00:33:26,160 --> 00:33:28,320
It was not code, but it was configuration.

767
00:33:28,320 --> 00:33:31,050
We've abstracted away that
specific configuration

768
00:33:31,050 --> 00:33:32,430
to a security profile.

769
00:33:32,430 --> 00:33:34,830
So I can basically on the
left, add all the signals,

770
00:33:34,830 --> 00:33:36,390
those are the detections,

771
00:33:36,390 --> 00:33:39,450
and on the right, I do all
of the decisions, right?

772
00:33:39,450 --> 00:33:40,927
So on the left, I say,

773
00:33:40,927 --> 00:33:42,570
"Hey, is this web scraping?"

774
00:33:42,570 --> 00:33:46,110
On the right, I decide what's
the decision I'm gonna take

775
00:33:46,110 --> 00:33:49,200
to actually react to the web scraping?

776
00:33:49,200 --> 00:33:52,500
And when I do that, I can then
deploy the security profile

777
00:33:52,500 --> 00:33:53,700
to all of my instances.

778
00:33:53,700 --> 00:33:55,830
So again, our customers don't run

779
00:33:55,830 --> 00:33:58,860
one or two instances of load balancers.

780
00:33:58,860 --> 00:34:01,710
They run hundreds across
all of the clouds,

781
00:34:01,710 --> 00:34:03,510
all of their on-premise infrastructure,

782
00:34:03,510 --> 00:34:04,980
all of their regions,

783
00:34:04,980 --> 00:34:07,770
all of their availability zones as well,

784
00:34:07,770 --> 00:34:09,720
because sometimes they try to avoid

785
00:34:09,720 --> 00:34:13,293
cross AZ traffic for many purposes.

786
00:34:14,250 --> 00:34:19,250
So basically I take all of
the steps on the left again

787
00:34:19,380 --> 00:34:22,800
and I decide what are the
decisions on the right to take.

788
00:34:22,800 --> 00:34:26,010
And very quickly, I'm
actually gonna get to this,

789
00:34:26,010 --> 00:34:28,410
and then I can start inspecting

790
00:34:28,410 --> 00:34:30,510
what's gonna happen to the traffic.

791
00:34:30,510 --> 00:34:32,670
So in this case, you can see we...

792
00:34:32,670 --> 00:34:34,770
I think this was a screenshot I took

793
00:34:34,770 --> 00:34:35,880
for the last five minutes.

794
00:34:35,880 --> 00:34:40,260
So in the last five minutes,
we saw 65,000 requests,

795
00:34:40,260 --> 00:34:44,100
we allowed about 46%, so 30,000 of them,

796
00:34:44,100 --> 00:34:49,100
and we took an action on
about half of that as well.

797
00:34:49,170 --> 00:34:51,240
And notice we're calling
it taking an action

798
00:34:51,240 --> 00:34:53,280
'cause we can't say we denied something.

799
00:34:53,280 --> 00:34:54,210
We don't know in advance

800
00:34:54,210 --> 00:34:55,697
what's the action we're gonna take, right?

801
00:34:55,697 --> 00:34:58,320
And in this case, the action, I'm sorry,

802
00:34:58,320 --> 00:35:00,210
in this case, the action was

803
00:35:00,210 --> 00:35:02,730
we're gonna tarpit some
brute force attacks,

804
00:35:02,730 --> 00:35:05,790
we're gonna deny high risk
countries and everything else.

805
00:35:05,790 --> 00:35:08,763
So that's the actual
action that were taken.

806
00:35:11,250 --> 00:35:13,050
So Frank, do you wanna
talk a little bit about

807
00:35:13,050 --> 00:35:15,050
some of the service patterns we've seen?

808
00:35:17,790 --> 00:35:20,310
- And again, all these patterns, again,

809
00:35:20,310 --> 00:35:21,663
they're all possible with HAProxy,

810
00:35:21,663 --> 00:35:24,240
it's just a question of configuration.

811
00:35:24,240 --> 00:35:27,060
So you see the common
ones that that we have are

812
00:35:27,060 --> 00:35:30,570
on the API gateway or circuit
breaker within an API gateway.

813
00:35:30,570 --> 00:35:32,881
And then basically,
you'll see the users will,

814
00:35:32,881 --> 00:35:34,077
they'll be hitting HAProxy

815
00:35:34,077 --> 00:35:36,270
and then you'll have SSL termination,

816
00:35:36,270 --> 00:35:38,700
rate limiting or throttling
as you've seen before,

817
00:35:38,700 --> 00:35:40,260
and different microservices

818
00:35:40,260 --> 00:35:42,960
or circuit breakers of services down,

819
00:35:42,960 --> 00:35:44,810
or if you're consuming too much time.

820
00:35:46,021 --> 00:35:49,170
And then you have other
traffic splitting initiatives

821
00:35:49,170 --> 00:35:51,300
which are kind of like simple

822
00:35:51,300 --> 00:35:53,910
weight-based or other value-based.

823
00:35:53,910 --> 00:35:55,860
So like, typical canary deployments,

824
00:35:55,860 --> 00:36:00,030
or if you're sending 10%
of traffic to version B

825
00:36:00,030 --> 00:36:02,220
but your stable version is version A,

826
00:36:02,220 --> 00:36:04,265
if you're in Kubernetes,
you can roll deployments,

827
00:36:04,265 --> 00:36:06,090
and these types of things.

828
00:36:06,090 --> 00:36:07,380
Blue/green is a similar.

829
00:36:07,380 --> 00:36:09,870
If you have a blue
cluster or green cluster,

830
00:36:09,870 --> 00:36:12,270
HAProxy makes the decision
based on the value

831
00:36:12,270 --> 00:36:13,103
however you pass it to it

832
00:36:13,103 --> 00:36:14,820
and then it switches over to the traffic.

833
00:36:14,820 --> 00:36:16,380
And it's really flexible,

834
00:36:16,380 --> 00:36:18,150
it's really flexible for any pattern.

835
00:36:18,150 --> 00:36:19,410
Again, the whole point of this,

836
00:36:19,410 --> 00:36:21,600
the control plane makes it a lot simpler.

837
00:36:21,600 --> 00:36:24,150
All this configuration is
all possible in the HAProxy.

838
00:36:24,150 --> 00:36:27,300
Control plane gives you
API and client libraries

839
00:36:27,300 --> 00:36:30,630
to be able to simply do this
and make it more seamless

840
00:36:30,630 --> 00:36:32,380
and apply it to different clusters.

841
00:36:36,540 --> 00:36:39,180
And now let's, there's been a lot of talk,

842
00:36:39,180 --> 00:36:40,260
thank you for your patience,

843
00:36:40,260 --> 00:36:42,690
let's see some of this in action.

844
00:36:42,690 --> 00:36:43,523
- Cool, thank you.

845
00:36:43,523 --> 00:36:46,830
So we introduced a couple
of concepts, right?

846
00:36:46,830 --> 00:36:49,410
We introduced the concept
of universal mesh,

847
00:36:49,410 --> 00:36:51,480
we introduced the concept of security.

848
00:36:51,480 --> 00:36:54,270
And so, traffic through the universal mesh

849
00:36:54,270 --> 00:36:56,460
flows through either externally,

850
00:36:56,460 --> 00:36:58,200
that's the north-south traffic,

851
00:36:58,200 --> 00:37:01,200
or internally, that's
the east-west traffic.

852
00:37:01,200 --> 00:37:02,760
And I'm gonna talk about it later.

853
00:37:02,760 --> 00:37:05,430
So imagine that you are an Acme Corp

854
00:37:05,430 --> 00:37:08,970
and you're running a universal
mesh on mesh.acme.com.

855
00:37:08,970 --> 00:37:10,200
And the point is that we're doing

856
00:37:10,200 --> 00:37:11,850
explicit routing of traffic.

857
00:37:11,850 --> 00:37:15,090
So if I'm a service or
if I'm a user out there,

858
00:37:15,090 --> 00:37:16,410
either an external user

859
00:37:16,410 --> 00:37:19,020
or you're mapping to some public domain,

860
00:37:19,020 --> 00:37:21,180
you want to talk to a payment gateway

861
00:37:21,180 --> 00:37:23,160
that's on-premise, right?

862
00:37:23,160 --> 00:37:26,463
You're gonna call
mesh.acme.com/paymentgateway.

863
00:37:27,330 --> 00:37:32,167
And what's gonna happen is
your first HAProxy will ask,

864
00:37:32,167 --> 00:37:34,560
"Hey, where's payment gateway,"

865
00:37:34,560 --> 00:37:35,647
and we'll find out,

866
00:37:35,647 --> 00:37:38,700
"Oh, payment gateway is on this
HAProxy that's on-premise."

867
00:37:38,700 --> 00:37:40,230
So we'll send the traffic there,

868
00:37:40,230 --> 00:37:42,900
and the HAProxy on-premise
receives this traffic

869
00:37:42,900 --> 00:37:44,227
and says, "Where's payment gateway?"

870
00:37:44,227 --> 00:37:45,480
"Oh, that's this spot in this

871
00:37:45,480 --> 00:37:47,070
on-premise Kubernetes cluster,"

872
00:37:47,070 --> 00:37:48,570
and we'll send it there.

873
00:37:48,570 --> 00:37:50,490
Compared to internal traffic,

874
00:37:50,490 --> 00:37:52,230
which actually looks exactly the same.

875
00:37:52,230 --> 00:37:57,230
If I'm a service in a
pod, in US-west-1 in AWS

876
00:37:57,780 --> 00:38:00,360
and I want to talk to the
payment gateway on-premise,

877
00:38:00,360 --> 00:38:04,860
I do the same thing I call
mesh.acme.com/paymentgateway

878
00:38:04,860 --> 00:38:07,530
and the HAProxy that's closest to me

879
00:38:07,530 --> 00:38:10,230
will find out where's payment gateway.

880
00:38:10,230 --> 00:38:13,080
It's on-premise in this
specific data center.

881
00:38:13,080 --> 00:38:13,913
We'll send it there,

882
00:38:13,913 --> 00:38:16,890
and that HAProxy will send
the traffic there again.

883
00:38:16,890 --> 00:38:19,830
So I've made a demo of exactly this.

884
00:38:19,830 --> 00:38:23,280
So if you wanna scan this, I
hope the QR code still works,

885
00:38:23,280 --> 00:38:24,480
if you wanna scan this,

886
00:38:24,480 --> 00:38:26,733
it's the page that I'm gonna show now.

887
00:38:28,500 --> 00:38:30,450
So you should arrive on this page,

888
00:38:30,450 --> 00:38:34,830
mesh.hapee-demo.com/payment-gw, right?

889
00:38:34,830 --> 00:38:38,040
So now, I'm sending traffic externally

890
00:38:38,040 --> 00:38:42,120
from my browser to the
universal mesh and back to,

891
00:38:42,120 --> 00:38:44,730
this is actually a pod
in a Kubernetes cluster.

892
00:38:44,730 --> 00:38:47,820
So if I load this page,
I get an answer and it,

893
00:38:47,820 --> 00:38:48,900
this is because again,

894
00:38:48,900 --> 00:38:52,470
the external HAProxy
decides what's happening,

895
00:38:52,470 --> 00:38:55,110
finds out where to go with the traffic,

896
00:38:55,110 --> 00:38:56,883
and then sends the traffic over.

897
00:38:58,530 --> 00:39:00,180
What I'm gonna do is I'm gonna,

898
00:39:00,180 --> 00:39:01,800
actually I'm gonna hack myself.

899
00:39:01,800 --> 00:39:04,530
So I'm gonna say path=/etc/password.

900
00:39:04,530 --> 00:39:06,060
There's a path argument,

901
00:39:06,060 --> 00:39:07,590
and if you give it a path of a file,

902
00:39:07,590 --> 00:39:08,700
it will give you the file.

903
00:39:08,700 --> 00:39:10,050
It's kind of fun, right?

904
00:39:10,050 --> 00:39:12,210
So you can do that, but obviously

905
00:39:12,210 --> 00:39:14,326
that's not gonna work
because this is a demo.

906
00:39:14,326 --> 00:39:17,040
So you get 403 Forbidden.

907
00:39:17,040 --> 00:39:18,410
So let's take a look at what happens

908
00:39:18,410 --> 00:39:19,650
in the background, right,

909
00:39:19,650 --> 00:39:21,720
how's this traffic being routed.

910
00:39:21,720 --> 00:39:26,720
So I'm gonna go to the
control plane for HAProxy,

911
00:39:27,630 --> 00:39:31,020
and the first thing I'm gonna
see is there's this request,

912
00:39:31,020 --> 00:39:35,760
payment-gw/ or path=/etc/password.

913
00:39:35,760 --> 00:39:36,593
So that's the one.

914
00:39:36,593 --> 00:39:40,154
And you can see we got a 403 response.

915
00:39:40,154 --> 00:39:44,790
But when I go to the detail,
we actually took an action,

916
00:39:44,790 --> 00:39:47,070
and the action was we blocked this request

917
00:39:47,070 --> 00:39:50,610
because we deemed it
suspicious as a client

918
00:39:50,610 --> 00:39:51,780
and at the same time,

919
00:39:51,780 --> 00:39:53,580
it triggered the web application firewall.

920
00:39:53,580 --> 00:39:55,650
So that was my business decision, right?

921
00:39:55,650 --> 00:39:57,420
I talked about the business decisions.

922
00:39:57,420 --> 00:40:00,720
And my business decision is
if it's a suspicious client,

923
00:40:00,720 --> 00:40:04,500
then do more than to humans.

924
00:40:04,500 --> 00:40:06,360
And you can see the bot management

925
00:40:06,360 --> 00:40:08,640
said that this is a suspicious client

926
00:40:08,640 --> 00:40:11,100
'cause I have some things
in my browser installed

927
00:40:11,100 --> 00:40:12,780
that made me look suspicious.

928
00:40:12,780 --> 00:40:17,310
So as a suspicious client,
we decided to block this

929
00:40:17,310 --> 00:40:21,000
and we triggered an obvious probe

930
00:40:21,000 --> 00:40:22,800
with the path=/etc/password.

931
00:40:22,800 --> 00:40:24,120
That's pretty obvious, right?

932
00:40:24,120 --> 00:40:26,420
So we don't have to talk
about that much more.

933
00:40:28,020 --> 00:40:31,350
The other thing that
we're gonna look at is

934
00:40:31,350 --> 00:40:34,470
instead of looking at the
specific requests that we blocked,

935
00:40:34,470 --> 00:40:35,430
let's actually take a look

936
00:40:35,430 --> 00:40:36,870
at the requests that worked, right?

937
00:40:36,870 --> 00:40:38,730
Some of you actually loaded these,

938
00:40:38,730 --> 00:40:42,123
so some of you will be
these specific URLs.

939
00:40:43,947 --> 00:40:47,730
Obviously, I can't say who's
who in the audience, right?

940
00:40:47,730 --> 00:40:50,730
So somebody requested /payment-gw

941
00:40:50,730 --> 00:40:53,790
and we routed this request to US-east.

942
00:40:53,790 --> 00:40:56,970
That's the HAProxy inside US-east.

943
00:40:56,970 --> 00:40:59,907
And then, we traverse
to the other HAProxy.

944
00:40:59,907 --> 00:41:01,560
And I wanna know what happened to that,

945
00:41:01,560 --> 00:41:04,230
so what I'm gonna do is I'm
gonna click on the search here

946
00:41:04,230 --> 00:41:05,880
next to the correlation ID.

947
00:41:05,880 --> 00:41:08,640
So now you see the two requests

948
00:41:08,640 --> 00:41:11,520
as they traverse the network.

949
00:41:11,520 --> 00:41:12,600
And in fact, to the client,

950
00:41:12,600 --> 00:41:13,950
this is a single request, right,

951
00:41:13,950 --> 00:41:15,360
but we see it as two

952
00:41:15,360 --> 00:41:18,780
'cause the first one right
from the client to the HAProxy,

953
00:41:18,780 --> 00:41:22,110
the second was from the
HAProxy to the far end HAProxy

954
00:41:22,110 --> 00:41:25,530
that originates or that's the
destination of this traffic.

955
00:41:25,530 --> 00:41:26,700
And that's this one.

956
00:41:26,700 --> 00:41:28,980
And in here, we're sending the traffic

957
00:41:28,980 --> 00:41:32,010
to this specific payment
gateway service in Kubernetes.

958
00:41:32,010 --> 00:41:35,400
If I make this even bigger,
you can see that, right?

959
00:41:35,400 --> 00:41:39,990
So I'm automatically
detecting all services

960
00:41:39,990 --> 00:41:41,940
inside my Kubernetes clusters,

961
00:41:41,940 --> 00:41:43,800
and here I'm sending the traffic

962
00:41:43,800 --> 00:41:45,600
to this specific Kubernetes cluster.

963
00:41:46,500 --> 00:41:49,210
The last thing I'm gonna demo on this is

964
00:41:49,210 --> 00:41:51,630
we're actually gonna
do some terminal work,

965
00:41:51,630 --> 00:41:53,730
and I'm gonna deploy a new demo.

966
00:41:53,730 --> 00:41:58,623
So here, if you take a
look, if it lets me through,

967
00:42:04,620 --> 00:42:07,950
if you take a look, I
have this new manifest,

968
00:42:07,950 --> 00:42:10,710
and I'm calling this
manifest demoone, right?

969
00:42:10,710 --> 00:42:14,790
And this manifest says that
I'm gonna deploy a new service

970
00:42:14,790 --> 00:42:17,820
and the path of the
service should be /demoone

971
00:42:17,820 --> 00:42:19,890
in the US-east.

972
00:42:19,890 --> 00:42:21,900
And at the top of it,

973
00:42:21,900 --> 00:42:24,660
I have some web server with
just basic information.

974
00:42:24,660 --> 00:42:26,610
So I actually applied it before,

975
00:42:26,610 --> 00:42:29,430
but I'm gonna re-apply it
in my Kubernetes cluster.

976
00:42:29,430 --> 00:42:33,450
So I've created the service,
I've created the deployment.

977
00:42:33,450 --> 00:42:34,470
So if you take a look,

978
00:42:34,470 --> 00:42:38,100
I have some pods of
the deployment demoone.

979
00:42:38,100 --> 00:42:39,240
So that's run in.

980
00:42:39,240 --> 00:42:41,820
I can actually scale the deployment.

981
00:42:41,820 --> 00:42:43,383
I think it was called demoone.

982
00:42:46,320 --> 00:42:48,573
So I'll give it three replicas instead.

983
00:42:51,000 --> 00:42:55,657
But now, if I go to mesh.hapee-demo.com,

984
00:42:57,540 --> 00:42:59,070
I actually get an answer.

985
00:42:59,070 --> 00:43:02,040
And the the point is that the HTML

986
00:43:02,040 --> 00:43:04,470
is the same as the
previous service, right?

987
00:43:04,470 --> 00:43:06,420
But suddenly without me doing anything,

988
00:43:06,420 --> 00:43:10,657
just by deploying a service
in Kubernetes and saying,

989
00:43:10,657 --> 00:43:13,560
"Hey, service path should be /demoone,"

990
00:43:13,560 --> 00:43:16,590
every client in the network

991
00:43:16,590 --> 00:43:20,430
and every HAProxy now
knows how to route demoone.

992
00:43:20,430 --> 00:43:24,330
So if I now go to
mesh.hapee-demo.com/demoone

993
00:43:24,330 --> 00:43:27,000
from externally in this case

994
00:43:27,000 --> 00:43:28,590
and internally at the same time,

995
00:43:28,590 --> 00:43:31,860
I arrive on the pods of
this specific service.

996
00:43:31,860 --> 00:43:33,540
And if I scale the pods,

997
00:43:33,540 --> 00:43:36,333
again, if I change the
number of the replicas, oops,

998
00:43:37,380 --> 00:43:39,720
if I change the number of the replicas,

999
00:43:39,720 --> 00:43:43,230
then this will be automatically updated

1000
00:43:43,230 --> 00:43:44,730
and I will be sending traffic

1001
00:43:44,730 --> 00:43:46,500
to the five replicas now

1002
00:43:46,500 --> 00:43:48,993
instead of the three
replicas that I had before.

1003
00:43:50,730 --> 00:43:52,500
So just to recap,

1004
00:43:52,500 --> 00:43:55,920
we talked about service discovery

1005
00:43:55,920 --> 00:43:58,170
and basically creating
services inside Kubernetes

1006
00:43:58,170 --> 00:44:00,870
and automatically
configuring them in HAProxy,

1007
00:44:00,870 --> 00:44:03,030
and running multi-layered
security on top of them

1008
00:44:03,030 --> 00:44:05,745
where I'm observing in the
control plane what's happening.

1009
00:44:05,745 --> 00:44:08,730
And we think that this
is really a solution

1010
00:44:08,730 --> 00:44:10,680
to the connectivity problems

1011
00:44:10,680 --> 00:44:12,720
that a lot of our customers are having

1012
00:44:12,720 --> 00:44:17,430
in terms of talking between
services inside AWS,

1013
00:44:17,430 --> 00:44:20,850
but also AWS to GCP and a few other clouds

1014
00:44:20,850 --> 00:44:22,170
that they're seeing out there

1015
00:44:22,170 --> 00:44:24,147
and they're requesting solutions for that.

1016
00:44:24,147 --> 00:44:27,420
And Frank, I don't know
if you wanna close us up.

1017
00:44:27,420 --> 00:44:29,870
- Oh, in the end, just, oops...

1018
00:44:31,110 --> 00:44:32,160
- Yeah, there you go.

1019
00:44:33,450 --> 00:44:34,283
- We just wanna say thank you,

1020
00:44:34,283 --> 00:44:38,430
and you can come see us at booth 1179

1021
00:44:38,430 --> 00:44:39,287
and you can visit HAProxy

1022
00:44:39,287 --> 00:44:41,250
to see some of our
other solutions as well.

1023
00:44:41,250 --> 00:44:44,160
But in general, we're happy to discuss.

1024
00:44:44,160 --> 00:44:46,350
And just another thing, all
these things are available,

1025
00:44:46,350 --> 00:44:49,440
HAProxy is available in
the marketplace in MI.

1026
00:44:49,440 --> 00:44:51,930
So it's definitely any form
factor, everything works.

1027
00:44:51,930 --> 00:44:54,600
And if you have any questions,

1028
00:44:54,600 --> 00:44:55,800
feel free to come and see us.

1029
00:44:55,800 --> 00:44:57,570
And thank you for your time.

1030
00:44:57,570 --> 00:44:58,457
- Thank you.

1031
00:44:58,457 --> 00:45:00,875
(audience clapping)

