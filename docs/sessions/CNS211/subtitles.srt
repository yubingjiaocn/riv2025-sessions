1
00:00:00,008 --> 00:00:00,529
Awesome.

2
00:00:01,739 --> 00:00:03,809
Uh, I think, I think we're, we're starting a little

3
00:00:03,809 --> 00:00:05,860
early, so I just, I just wanted to just to see if you can get

4
00:00:05,860 --> 00:00:07,038
a little energy in the room,

5
00:00:07,860 --> 00:00:09,179
um, and, and, you know,

6
00:00:09,460 --> 00:00:11,608
myself and Janek, we have an awesome set of, uh,

7
00:00:11,659 --> 00:00:13,819
slides and awesome set of demos so I could show you. We're actually

8
00:00:13,819 --> 00:00:15,220
gonna build some stuff together here.

9
00:00:15,538 --> 00:00:17,620
We usually don't do that in a breakout session, but I think it's

10
00:00:17,620 --> 00:00:18,589
gonna be really cool.

11
00:00:19,100 --> 00:00:21,138
Um, just a quick show of hands, how many of

12
00:00:21,138 --> 00:00:21,920
you are developers?

13
00:00:23,339 --> 00:00:25,440
Wow, that's a lot of developers. Awesome.

14
00:00:25,579 --> 00:00:27,620
So that's good. That's a good part because you're gonna enjoy the

15
00:00:27,620 --> 00:00:28,359
building part here.

16
00:00:28,940 --> 00:00:30,978
Um, how many of you have heard

17
00:00:30,978 --> 00:00:33,579
about the like the two really big transformational

18
00:00:33,579 --> 00:00:35,829
launches in Lambda, this reinvent?

19
00:00:36,380 --> 00:00:38,618
OK, a few hands, so I think that's gonna be useful

20
00:00:38,618 --> 00:00:39,759
to a lot of developers.

21
00:00:40,259 --> 00:00:42,139
Uh, how many of you are engineering leaders?

22
00:00:43,609 --> 00:00:45,609
OK, lots of you are engineering leaders. Awesome,

23
00:00:45,810 --> 00:00:47,840
awesome. So I think there's, there's gonna be a bit of

24
00:00:47,840 --> 00:00:49,950
a mix of both things here today.

25
00:00:50,408 --> 00:00:51,098
Um,

26
00:00:51,569 --> 00:00:53,618
I'll introduce myself in a second. Um,

27
00:00:53,770 --> 00:00:55,990
there's, there's gonna be a little bit of a mix of,

28
00:00:56,289 --> 00:00:56,908
um,

29
00:00:57,319 --> 00:00:59,490
lambda strategy or serverless strategy all up.

30
00:00:59,609 --> 00:01:00,429
What are we trying to do?

31
00:01:00,770 --> 00:01:03,029
Um, I'm gonna actually share, I, I,

32
00:01:03,118 --> 00:01:05,129
I mostly speak to a lot of customers

33
00:01:05,129 --> 00:01:05,668
this week.

34
00:01:06,209 --> 00:01:08,400
I'll share some anecdotes about that too is, uh,

35
00:01:08,609 --> 00:01:10,650
you know, every reinvent has a bit of a surprise. I think this

36
00:01:10,650 --> 00:01:12,409
is my 9th reinvent, um,

37
00:01:12,730 --> 00:01:14,769
so why don't we get going and I'll, I'll share my

38
00:01:14,769 --> 00:01:16,808
stories with you guys and we'll, we're gonna build some cool

39
00:01:16,808 --> 00:01:17,969
stuff together. So, OK,

40
00:01:18,448 --> 00:01:19,469
we're talking about

41
00:01:19,730 --> 00:01:21,859
the build, building the future with AWS

42
00:01:21,859 --> 00:01:24,129
Serverless, and we've actually played around with the,

43
00:01:24,269 --> 00:01:26,269
with the title a little bit. We're saying we were gonna talk about

44
00:01:26,269 --> 00:01:27,909
the future of Serverless, but I think

45
00:01:28,448 --> 00:01:30,129
one of the things we wanted to share with you

46
00:01:30,388 --> 00:01:32,510
is what is our strategy, how we think people

47
00:01:32,510 --> 00:01:34,558
are gonna build in the future, and why Serverless is

48
00:01:34,558 --> 00:01:35,230
so key here.

49
00:01:35,819 --> 00:01:38,230
Um, I'm gonna introduce, let my partner introduce

50
00:01:38,230 --> 00:01:40,269
himself, when, when he comes up to do the,

51
00:01:40,349 --> 00:01:42,549
the first of the demos, but I'm Osman Khalid, folks.

52
00:01:42,629 --> 00:01:43,930
I'm the head of serverless compute.

53
00:01:44,629 --> 00:01:46,829
Uh, I've been with AWS for almost 12.5

54
00:01:46,829 --> 00:01:48,829
years, and I started my role, uh,

55
00:01:48,989 --> 00:01:51,138
with a little known service called Autoscaling

56
00:01:51,510 --> 00:01:53,900
and auto scaling groups, which was a precursor

57
00:01:53,900 --> 00:01:56,099
and it's still the thing that powers, uh,

58
00:01:56,219 --> 00:01:57,969
lambda, ECS, EKS.

59
00:01:58,528 --> 00:02:00,540
Um, and I've been with the ser in the server space

60
00:02:00,540 --> 00:02:02,540
with Eventbridge step functions. Uh, these

61
00:02:02,540 --> 00:02:03,760
services are under me as well.

62
00:02:04,019 --> 00:02:06,418
Uh, at AWS since 2018,

63
00:02:06,480 --> 00:02:07,400
2019.

64
00:02:07,739 --> 00:02:09,949
So it's been quite a few years with the, with the team here,

65
00:02:10,338 --> 00:02:12,618
um, and still going strong, and my passion always

66
00:02:12,618 --> 00:02:14,659
has been developers. I've been a developer myself. If

67
00:02:14,659 --> 00:02:15,679
you were to Google my name,

68
00:02:16,179 --> 00:02:18,118
you'll see I made a break dancing puzzle game

69
00:02:18,460 --> 00:02:20,538
that not a lot of people bought, but, OK, it

70
00:02:20,538 --> 00:02:22,000
was a great learning experience.

71
00:02:22,349 --> 00:02:24,500
Uh, so I know I'm not a break dancer

72
00:02:24,500 --> 00:02:26,050
in case you're wondering, um,

73
00:02:26,379 --> 00:02:27,800
so. That's me,

74
00:02:28,058 --> 00:02:30,550
uh, and why, why you should listen to me is basically

75
00:02:30,550 --> 00:02:32,610
because this is, I'm the guy who sets

76
00:02:32,610 --> 00:02:34,649
the strategy for Servius, and, and, and Jennek

77
00:02:34,649 --> 00:02:36,069
and I work really well together

78
00:02:36,599 --> 00:02:38,689
to work through this, and we, that's why we want to share with you. We wanted

79
00:02:38,689 --> 00:02:40,389
to share with you in this for the next hour

80
00:02:41,368 --> 00:02:43,479
the things we've obviously done and how they connect with

81
00:02:43,479 --> 00:02:45,550
that overall strategy and what we're, where we're taking

82
00:02:45,550 --> 00:02:47,729
Servius because Servius, you know, we celebrated 10 years

83
00:02:47,729 --> 00:02:48,830
of lambda last year.

84
00:02:49,399 --> 00:02:51,449
Um, but it really is, it's at an

85
00:02:51,449 --> 00:02:52,830
inflection point, and I think

86
00:02:53,088 --> 00:02:53,750
all of us,

87
00:02:54,088 --> 00:02:56,250
we're all in technology, lots of developers, lots of

88
00:02:56,250 --> 00:02:57,149
engineering leaders here,

89
00:02:57,808 --> 00:02:59,879
we're all seeing this inflection point in technology,

90
00:02:59,889 --> 00:03:02,008
kind of like what, what the Internet did in the early

91
00:03:02,008 --> 00:03:04,449
2000s. I was a little too young for that, although

92
00:03:04,449 --> 00:03:06,110
my gray hair speak otherwise,

93
00:03:06,569 --> 00:03:07,409
um,

94
00:03:07,929 --> 00:03:10,088
and, but I think with AI, and look, I'm not gonna

95
00:03:10,088 --> 00:03:12,210
talk tons about AI and I'm, I'm, and I'm

96
00:03:12,210 --> 00:03:14,210
still learning how to use it myself and.

97
00:03:14,699 --> 00:03:16,288
And no, I don't believe it's gonna change,

98
00:03:16,649 --> 00:03:18,740
you know, all our jobs, but I think it, it already is

99
00:03:18,740 --> 00:03:21,189
accelerating us, so I'm gonna share some of the anecdote anecdotes

100
00:03:21,189 --> 00:03:22,050
for that. So

101
00:03:22,508 --> 00:03:23,490
I'm gonna set the stage

102
00:03:24,189 --> 00:03:26,118
for what the strategy is and the agenda.

103
00:03:26,588 --> 00:03:28,588
We have this build a challenge, so we're gonna build a few

104
00:03:28,588 --> 00:03:30,669
things. Janek is gonna kick that off, and then

105
00:03:30,669 --> 00:03:33,008
we'll, we're gonna talk about some of our other innovations

106
00:03:33,189 --> 00:03:34,129
which were launched

107
00:03:34,508 --> 00:03:36,618
a week before we invent. So you might have missed

108
00:03:36,618 --> 00:03:38,710
those as well. And then we kind of recap and kind of

109
00:03:38,710 --> 00:03:40,788
share with you where we're going next. That's what we're gonna

110
00:03:40,788 --> 00:03:42,050
cover today. Sounds good.

111
00:03:42,719 --> 00:03:44,719
Yes, nodding heads? Awesome.

112
00:03:45,689 --> 00:03:47,159
Alright, so,

113
00:03:47,500 --> 00:03:49,758
uh, I love this quote. Uh,

114
00:03:50,219 --> 00:03:50,778
you know, I,

115
00:03:51,159 --> 00:03:53,419
you know, we all the engineering leaders all here

116
00:03:53,419 --> 00:03:55,538
and the engineering and the engineers themselves, you know

117
00:03:55,538 --> 00:03:57,110
that changes is constant, right?

118
00:03:57,618 --> 00:03:59,819
But my favorite quote at all change is about change,

119
00:03:59,860 --> 00:04:02,258
and I actually found that the, who actually

120
00:04:02,258 --> 00:04:04,258
said the original one is PJ O'Rourke. He's a journalist,

121
00:04:04,368 --> 00:04:05,689
a US journalist, um.

122
00:04:06,449 --> 00:04:08,639
And look, I already kinda signaled this to you folks.

123
00:04:08,689 --> 00:04:10,770
We are going through change, right? And, and

124
00:04:10,770 --> 00:04:13,088
kind of like the big takeaway for me talking to customers

125
00:04:13,088 --> 00:04:13,830
at Reinvent,

126
00:04:14,169 --> 00:04:16,170
especially when they, when they're talking to me about Serverless and

127
00:04:16,170 --> 00:04:17,829
the future of Serverless, is really

128
00:04:18,250 --> 00:04:20,369
the maybe their their old platform strategy,

129
00:04:20,470 --> 00:04:22,509
the old way of doing things is just

130
00:04:22,509 --> 00:04:24,649
not working time and time again when I hear

131
00:04:24,649 --> 00:04:26,889
from developers, developer, development leaders,

132
00:04:27,048 --> 00:04:27,910
platform leaders.

133
00:04:28,350 --> 00:04:29,059
Is that

134
00:04:29,470 --> 00:04:31,588
there's an even bigger struggle with the engineering

135
00:04:31,588 --> 00:04:33,750
teams between the engineering and platform teams now

136
00:04:33,750 --> 00:04:35,869
because the engineers just wanna try things when the

137
00:04:35,869 --> 00:04:37,410
cost of trying something has

138
00:04:37,709 --> 00:04:38,629
just plummeted,

139
00:04:38,949 --> 00:04:41,009
you can, and I'm not talking about vibe coding, I'm talking

140
00:04:41,009 --> 00:04:43,108
about real production engineering here, and that's what we do

141
00:04:43,108 --> 00:04:45,220
at Lambda and then Serverless as well. We have,

142
00:04:45,230 --> 00:04:47,009
and this is some of the stuff we're gonna show you

143
00:04:47,379 --> 00:04:49,389
how we were able to accelerate that because

144
00:04:49,389 --> 00:04:51,389
we, we use AI as a, as a tool, as an

145
00:04:51,389 --> 00:04:53,459
accelerant. When things have become so

146
00:04:53,459 --> 00:04:56,079
much faster, if your deployments, if your

147
00:04:56,079 --> 00:04:58,389
operations, if your patching activities are

148
00:04:58,389 --> 00:04:59,338
getting in the way,

149
00:04:59,738 --> 00:05:01,949
if you've just kind of inverted the, the entire

150
00:05:01,949 --> 00:05:03,439
SDLC, frankly,

151
00:05:03,750 --> 00:05:06,028
and that's not just at AWS, multiple

152
00:05:06,028 --> 00:05:07,730
customers are seeing the same thing and that's why

153
00:05:08,108 --> 00:05:10,709
I had more so more, more customer

154
00:05:10,709 --> 00:05:12,790
conversations this year than uh in the last few years

155
00:05:12,790 --> 00:05:13,649
simply because.

156
00:05:14,189 --> 00:05:16,189
You know, people are coming around and saying, yeah, we had

157
00:05:16,189 --> 00:05:18,230
a community based based platform, but

158
00:05:18,230 --> 00:05:20,600
like what can we do more with Servius because our developers

159
00:05:20,600 --> 00:05:22,709
just wanna go faster and faster

160
00:05:22,910 --> 00:05:25,309
and they don't wanna have all the liabilities

161
00:05:25,309 --> 00:05:26,488
of, of managing the code.

162
00:05:27,528 --> 00:05:28,108
So

163
00:05:28,730 --> 00:05:30,809
really what what I'm really trying to say is that we

164
00:05:30,809 --> 00:05:32,809
are at an evolutionary time. We all feel it.

165
00:05:32,850 --> 00:05:34,988
I don't have to, I don't have to convince it whether

166
00:05:34,988 --> 00:05:36,869
what the final stage of this is we don't know.

167
00:05:37,250 --> 00:05:39,528
I certainly don't know and I'm not claiming that I know,

168
00:05:40,048 --> 00:05:42,178
but we are going through an evolutionary period.

169
00:05:42,250 --> 00:05:44,369
And so one of the things that, uh, as which

170
00:05:44,369 --> 00:05:46,569
is a key part of our strategy at Servius, we, we

171
00:05:46,569 --> 00:05:47,869
always focused on developers.

172
00:05:48,209 --> 00:05:50,309
Maybe we didn't focus enough on the developer

173
00:05:50,309 --> 00:05:52,769
experience, but we have, so, and we, that's a key pillar of our strategy

174
00:05:52,769 --> 00:05:54,338
so far, but.

175
00:05:55,509 --> 00:05:57,639
It was all about speed and evolution and

176
00:05:57,639 --> 00:05:59,639
creating evolutionary architectures and I'll show you in the

177
00:05:59,639 --> 00:06:01,670
architecture and what I mean by that, but if,

178
00:06:01,838 --> 00:06:03,920
if, if we're living in a in a in a time and we

179
00:06:03,920 --> 00:06:05,720
are where things are changing rapidly.

180
00:06:06,569 --> 00:06:08,699
If your systems, your processes, your people are

181
00:06:08,699 --> 00:06:09,699
able to evolve,

182
00:06:10,019 --> 00:06:12,220
those are the ones that are gonna be the most successful, the companies

183
00:06:12,220 --> 00:06:14,298
who actually are able to evolve and transition

184
00:06:14,500 --> 00:06:16,730
are gonna be the most successful, so why not your architecture

185
00:06:16,730 --> 00:06:17,858
as well? So

186
00:06:18,230 --> 00:06:20,338
for I didn't check how many of you were system architects, but

187
00:06:20,338 --> 00:06:22,619
I'm guessing a lot of you, a lot of the engineers are systems

188
00:06:22,619 --> 00:06:24,699
designers as well. You all know that there's no such thing as the

189
00:06:24,699 --> 00:06:25,639
right architecture,

190
00:06:26,178 --> 00:06:27,588
right? It's only the right trade-offs,

191
00:06:28,048 --> 00:06:29,449
um, witherless.

192
00:06:30,189 --> 00:06:32,548
Yeah, you have a, you build highly evolutionary

193
00:06:32,548 --> 00:06:34,629
architectures, but just to, so I kick

194
00:06:34,629 --> 00:06:36,819
off and get into the early part of the

195
00:06:36,819 --> 00:06:39,028
conversation, I'm not here to sell you anything either, so

196
00:06:39,028 --> 00:06:41,278
I'll be, I'll be as balanced as possible, obviously

197
00:06:41,278 --> 00:06:43,389
I'm a, I, I, I'm very passionate about the

198
00:06:43,389 --> 00:06:45,088
space, but there are trade-offs

199
00:06:45,559 --> 00:06:47,629
if you have a high, highly, highly evolutionary

200
00:06:47,629 --> 00:06:49,750
system, you're, it's very hard to manage

201
00:06:49,750 --> 00:06:52,189
change. It's very hard to observe what's

202
00:06:52,189 --> 00:06:54,230
broken because things are more decoupled because, uh,

203
00:06:54,238 --> 00:06:56,028
are, are, are changing very rapidly.

204
00:06:56,379 --> 00:06:58,449
Um, for some of the platform team owners,

205
00:06:58,699 --> 00:07:00,798
one of the things that's weighing on their mind is control.

206
00:07:00,939 --> 00:07:03,100
How do I, how do I govern? How do I make

207
00:07:03,100 --> 00:07:05,259
everything compliant? How do I, while, while my developers

208
00:07:05,259 --> 00:07:07,238
wanna move faster and faster and faster, so yeah,

209
00:07:07,579 --> 00:07:08,980
there are trade-offs that we have to manage.

210
00:07:10,500 --> 00:07:12,939
But the final thing that I always tell when we have this

211
00:07:12,939 --> 00:07:15,069
conversation is like look evolution is is not a new

212
00:07:15,069 --> 00:07:17,350
thing in in tech like just because Gen AI

213
00:07:17,350 --> 00:07:19,509
has captured the hearts and minds of so much and it

214
00:07:19,509 --> 00:07:21,509
has been so disruptive for us, the

215
00:07:21,509 --> 00:07:22,670
engineering community here.

216
00:07:23,480 --> 00:07:25,778
Speed always has mattered in business, and

217
00:07:25,778 --> 00:07:27,959
the, the fastest you are, the the more

218
00:07:27,959 --> 00:07:28,899
likely you are to win.

219
00:07:29,528 --> 00:07:31,079
So let's go to about the server list.

220
00:07:31,439 --> 00:07:33,480
I don't know if this is the biggest secret, and Jane believes it's

221
00:07:33,480 --> 00:07:35,879
the biggest secret in server list, but look, server, serverless

222
00:07:35,879 --> 00:07:36,778
was always running,

223
00:07:37,079 --> 00:07:39,189
you know, I, I operate a fleet of literally

224
00:07:39,189 --> 00:07:40,670
hundreds of thousands of servers,

225
00:07:41,108 --> 00:07:43,119
bare metal servers too, so those are extra fun

226
00:07:43,119 --> 00:07:44,449
to patch and scale.

227
00:07:45,170 --> 00:07:47,238
But what we've done is we've created a facade

228
00:07:47,238 --> 00:07:49,410
for developers where the developers just don't

229
00:07:49,410 --> 00:07:50,509
have to worry about

230
00:07:50,889 --> 00:07:52,889
the, the management of the servers, management

231
00:07:52,889 --> 00:07:55,028
of runtime, scaling, load balancing,

232
00:07:55,488 --> 00:07:57,649
you know, request routing a lot of those

233
00:07:57,649 --> 00:07:58,889
things are just taken care of

234
00:07:59,189 --> 00:08:00,189
us directly.

235
00:08:01,079 --> 00:08:03,250
But so while there's hundreds of thousands

236
00:08:03,250 --> 00:08:05,798
of servers in our fleet and from USC1

237
00:08:05,798 --> 00:08:07,798
all the way in Asia and I don't

238
00:08:07,798 --> 00:08:10,069
think we have an we have an African region now too, right?

239
00:08:10,119 --> 00:08:11,600
So there you go all over the planet.

240
00:08:12,420 --> 00:08:14,670
But to you or the developer or to the engineering

241
00:08:14,670 --> 00:08:16,829
leaders who are who've built a surveless architecture,

242
00:08:16,879 --> 00:08:18,899
this is what it kind of looks like in the in this pic this

243
00:08:18,899 --> 00:08:19,608
picture here

244
00:08:19,869 --> 00:08:22,059
is simply me trying to play around with

245
00:08:22,059 --> 00:08:24,149
an idea of like, hey, I wanna build an

246
00:08:24,149 --> 00:08:26,389
agent or build an application that can guide

247
00:08:26,389 --> 00:08:28,108
users during national emergencies.

248
00:08:28,980 --> 00:08:31,000
So yeah I'm talking a lot of MCPs

249
00:08:31,000 --> 00:08:33,259
here I'm talking to a bunch of different

250
00:08:33,259 --> 00:08:35,259
uh services that are available

251
00:08:35,259 --> 00:08:37,700
I think I have FEMA here etc.

252
00:08:38,788 --> 00:08:41,259
What I, what I mean by evolutionary here is that

253
00:08:41,259 --> 00:08:43,308
each feature, each facet of my idea is

254
00:08:43,308 --> 00:08:45,869
actually one of those, those, these, these horizontal

255
00:08:45,869 --> 00:08:48,090
lines you see that see that go through lambda. I'm

256
00:08:48,090 --> 00:08:48,729
obviously using an,

257
00:08:48,989 --> 00:08:51,070
uh, an AI, uh, I'm using Bedrock

258
00:08:51,070 --> 00:08:52,210
to host my models,

259
00:08:52,950 --> 00:08:55,149
but if I imagine if I in this particular architecture

260
00:08:55,149 --> 00:08:57,149
I wanted to add a new feature, I, I deliberately didn't put

261
00:08:57,149 --> 00:08:59,298
it on a slide. I wanted to add a notification

262
00:08:59,298 --> 00:09:01,798
feature where customers can sign up to a notification

263
00:09:02,070 --> 00:09:04,239
and maybe over SMS or email I can

264
00:09:04,239 --> 00:09:06,009
email them notifications or SMS them.

265
00:09:06,548 --> 00:09:08,570
Um, if my, my advice from my

266
00:09:08,570 --> 00:09:10,590
app, for example, if the sign up, that would just be a

267
00:09:10,590 --> 00:09:11,219
branch.

268
00:09:11,570 --> 00:09:13,639
I'm not updating a bunch of microservices,

269
00:09:13,879 --> 00:09:15,969
that is just a branch and one of the key things,

270
00:09:16,009 --> 00:09:18,048
and again I know the tools are heavily evolving

271
00:09:18,048 --> 00:09:20,250
even in the last 6 months that they're heavily evolving, one

272
00:09:20,250 --> 00:09:22,450
of the things that I, I've seen my engineering teams

273
00:09:22,450 --> 00:09:24,639
do is that smaller changes,

274
00:09:24,889 --> 00:09:27,070
smaller contexts, smaller files

275
00:09:27,690 --> 00:09:29,729
just are so much better, so much faster to

276
00:09:29,729 --> 00:09:31,969
iterate on, and the AI is far more right.

277
00:09:32,349 --> 00:09:34,519
And, uh, building those things and it is just like

278
00:09:34,519 --> 00:09:36,519
one shotting, I mean white coding I think

279
00:09:36,519 --> 00:09:38,580
really is a marketing term at this point, frankly,

280
00:09:39,200 --> 00:09:41,320
uh, and guess what, all of these things are a single

281
00:09:41,320 --> 00:09:43,359
responsibility of lambda functions and super

282
00:09:43,359 --> 00:09:45,399
easy to manage and update and super

283
00:09:45,399 --> 00:09:47,590
fast and, and Janek is gonna show you some of these things

284
00:09:47,590 --> 00:09:48,759
when he comes and talks about it.

285
00:09:49,500 --> 00:09:51,899
And look, at the end of the day when you build that architecture,

286
00:09:51,950 --> 00:09:54,548
yeah, there were lots of parts to it. There's IAC

287
00:09:54,548 --> 00:09:56,849
that you had to, to probably use to actually

288
00:09:57,109 --> 00:09:59,308
create and manage the, the, the, the

289
00:09:59,308 --> 00:09:59,849
system.

290
00:10:00,139 --> 00:10:01,769
But once you have that set up,

291
00:10:02,349 --> 00:10:03,750
I like to talk about the ilities.

292
00:10:04,779 --> 00:10:06,779
Right, and maybe, maybe you folks have a platform

293
00:10:06,779 --> 00:10:08,940
team where there's other humans who go and

294
00:10:08,940 --> 00:10:10,979
manage and scale servers for you. They fixed

295
00:10:10,979 --> 00:10:12,599
focus on reliability, durability,

296
00:10:13,139 --> 00:10:15,298
but that's not actually true, right? Even in the platform

297
00:10:15,298 --> 00:10:17,279
team case they don't know your software,

298
00:10:17,538 --> 00:10:19,779
so many things that are that are that are

299
00:10:19,779 --> 00:10:20,519
around like

300
00:10:20,928 --> 00:10:22,940
security and, and scalability all the

301
00:10:22,940 --> 00:10:25,019
way go into the software that the developers are writing

302
00:10:25,019 --> 00:10:27,320
too. And if you're choosing an underlying

303
00:10:27,320 --> 00:10:28,399
infrastructure technology.

304
00:10:29,330 --> 00:10:31,889
Then you are responsible for those things, and if you ever

305
00:10:31,889 --> 00:10:33,928
start thinking about your ideas going to global scale, you

306
00:10:33,928 --> 00:10:35,269
can see how hard it gets.

307
00:10:36,469 --> 00:10:38,519
And look at the heart of it,

308
00:10:38,830 --> 00:10:40,090
what, what customers love

309
00:10:40,389 --> 00:10:42,418
with and why they build, sorry I went too

310
00:10:42,418 --> 00:10:44,428
fast, why, why customers love building with Servius

311
00:10:44,428 --> 00:10:44,989
is that

312
00:10:45,369 --> 00:10:47,489
those ilities that I had in the previous slide

313
00:10:47,750 --> 00:10:49,729
are all managed by us.

314
00:10:50,389 --> 00:10:52,389
That is kind of like the heart of Servius at the end of the

315
00:10:52,389 --> 00:10:53,889
day. It's not about having those servers.

316
00:10:54,359 --> 00:10:56,840
It's about having no servers to manage and no infrastructure

317
00:10:56,840 --> 00:10:59,070
to manage and then expressing your logic the fastest

318
00:10:59,070 --> 00:10:59,798
way possible.

319
00:11:00,200 --> 00:11:02,359
OK, so speed is the key thing. I

320
00:11:02,359 --> 00:11:04,359
mean, I already set that up like speed always wins

321
00:11:04,359 --> 00:11:06,450
and that is our number one goal.

322
00:11:06,519 --> 00:11:08,379
Our number one goal has been always

323
00:11:08,639 --> 00:11:10,879
how can we be the fastest to

324
00:11:10,879 --> 00:11:12,580
market? How can we take an idea

325
00:11:13,000 --> 00:11:15,219
that customers have and be the fastest way

326
00:11:15,219 --> 00:11:17,259
to do this? And I, I mean the funny. Anecdote I would share

327
00:11:17,259 --> 00:11:17,798
with you,

328
00:11:18,219 --> 00:11:20,340
uh, many years ago, I think it was 2013, 2014,

329
00:11:20,418 --> 00:11:22,460
it was about a year of working on auto scaling. My

330
00:11:22,460 --> 00:11:24,609
boss asked me like, Hey, what's the charter for auto scaling?

331
00:11:24,779 --> 00:11:26,519
This is before lambda. This is before

332
00:11:26,859 --> 00:11:28,928
ECS and Kubernetes, and I was like,

333
00:11:29,019 --> 00:11:30,359
Hey, it's the fastest way

334
00:11:30,779 --> 00:11:33,038
to go take an idea and take it to scale,

335
00:11:33,099 --> 00:11:35,219
and the best idea, let the best ideas win. Obviously

336
00:11:35,219 --> 00:11:37,500
we've come a long way from just using auto scaling

337
00:11:37,500 --> 00:11:38,269
VMs now,

338
00:11:38,700 --> 00:11:40,700
but, uh, this, this statement is

339
00:11:40,700 --> 00:11:42,739
at least has been true for me, and as I've been

340
00:11:42,739 --> 00:11:44,798
in this space of helping people move faster.

341
00:11:45,210 --> 00:11:47,210
And faster because this is what matters. I think

342
00:11:47,210 --> 00:11:49,250
this is the thing that that matters all

343
00:11:49,250 --> 00:11:51,058
the way from what why customers adopt the cloud

344
00:11:51,649 --> 00:11:53,750
all the way to how they build cloud natively

345
00:11:53,928 --> 00:11:54,788
to move faster.

346
00:11:55,529 --> 00:11:57,558
OK, and I wanted to share, uh, a

347
00:11:57,558 --> 00:11:59,558
really quick anecdote. This is a very recent anecdote as

348
00:11:59,558 --> 00:12:01,969
well the last couple of months where, um, Cyber

349
00:12:01,969 --> 00:12:04,210
Arc, which is a platform

350
00:12:04,210 --> 00:12:06,250
engineering, and a team in Cyber Arc, basically built

351
00:12:06,250 --> 00:12:07,729
their entire platform on Serverless,

352
00:12:08,408 --> 00:12:10,450
and they were able to do this, uh, the

353
00:12:10,450 --> 00:12:12,609
automation work that they need to do, uh,

354
00:12:12,729 --> 00:12:14,729
and, and, and basically

355
00:12:14,729 --> 00:12:16,808
save something like 4 months out of the 12 months it took

356
00:12:16,808 --> 00:12:18,048
them to build new services.

357
00:12:18,908 --> 00:12:21,000
Um, I mean this code itself is probably 6

358
00:12:21,000 --> 00:12:23,239
months old. I, I would say this number is probably much, much

359
00:12:23,239 --> 00:12:25,099
lower now given the way the state of tools is.

360
00:12:25,399 --> 00:12:27,369
And again, once something is written.

361
00:12:27,989 --> 00:12:29,989
I mean, I think the final, final stage, I, I have

362
00:12:29,989 --> 00:12:32,090
a Tesla as well, but then I unfortunately played full,

363
00:12:32,190 --> 00:12:34,190
full self-driving for it, which it doesn't

364
00:12:34,190 --> 00:12:35,668
do after many years,

365
00:12:36,029 --> 00:12:38,609
uh, because at the end of the day it's liabilities,

366
00:12:39,190 --> 00:12:39,750
uh, the last

367
00:12:40,099 --> 00:12:41,129
LT is liability,

368
00:12:41,590 --> 00:12:43,190
and when you serve us,

369
00:12:43,548 --> 00:12:45,590
more of the responsibility is on our line

370
00:12:45,590 --> 00:12:47,729
of the fence. At the end of the day, myself and engineering

371
00:12:47,729 --> 00:12:49,330
teams are the ones who are responsible

372
00:12:49,629 --> 00:12:50,690
for the scale

373
00:12:50,950 --> 00:12:53,229
and patching and security of your applications versus

374
00:12:53,229 --> 00:12:54,019
you doing so.

375
00:12:54,349 --> 00:12:56,428
I mean there's still a shared responsibility, but a lot of

376
00:12:56,428 --> 00:12:57,629
it is on our side of the fence.

377
00:12:58,109 --> 00:13:00,178
And look, it's not a new technology

378
00:13:00,178 --> 00:13:02,308
anymore, although I, as we get into the thing, I think

379
00:13:02,308 --> 00:13:04,580
we've, what we've done over the last 12 months and launch,

380
00:13:04,590 --> 00:13:05,690
launch and reinvent

381
00:13:06,149 --> 00:13:08,178
really transforms this 10 year old technology as well,

382
00:13:08,229 --> 00:13:10,269
but several this is already everywhere. I'm obviously not gonna

383
00:13:10,269 --> 00:13:12,408
go through all of these things. I just wanted to kind of highlight to you

384
00:13:12,830 --> 00:13:14,009
how many big names

385
00:13:14,269 --> 00:13:16,469
have major applications at scale

386
00:13:16,469 --> 00:13:17,629
applications running on lambda today.

387
00:13:18,469 --> 00:13:20,580
OK, so let's go. Let's enough

388
00:13:20,580 --> 00:13:22,710
talking about like the context of why we're here. I

389
00:13:22,710 --> 00:13:24,830
think a lot of people aren't familiar with the feature,

390
00:13:24,950 --> 00:13:26,950
so I wanna get into it and have, uh, introduce

391
00:13:26,950 --> 00:13:28,969
my, my partner Jana Agarwal, who

392
00:13:28,969 --> 00:13:31,200
will come introduce himself, and he's walk us through some

393
00:13:31,200 --> 00:13:33,489
actual of some, some actual building things.

394
00:13:34,058 --> 00:13:35,428
Thank you Audible.

395
00:13:37,739 --> 00:13:39,269
No, Am I audible now?

396
00:13:39,739 --> 00:13:40,928
All right, I'll thank Usman again.

397
00:13:41,259 --> 00:13:43,298
So, hello everyone, I'm Janna Kagarwal.

398
00:13:43,619 --> 00:13:45,849
I used to be a developer for around 8 years,

399
00:13:46,019 --> 00:13:48,538
so my perspective on Serves has really been informed

400
00:13:48,538 --> 00:13:50,119
by both sides of the equation

401
00:13:50,719 --> 00:13:51,899
of being a developer,

402
00:13:52,359 --> 00:13:54,379
uh, you know, whose services need to run in production,

403
00:13:54,460 --> 00:13:55,320
you know, flawlessly.

404
00:13:56,210 --> 00:13:58,320
And now you're trying to build tools and

405
00:13:58,320 --> 00:14:00,489
services that developers can trust to run

406
00:14:00,489 --> 00:14:01,928
their critical workloads on.

407
00:14:02,759 --> 00:14:04,798
So, I like to still think of myself as a

408
00:14:04,798 --> 00:14:06,308
good developer, but I'm probably not,

409
00:14:06,719 --> 00:14:08,759
uh, but I am a product manager and

410
00:14:08,759 --> 00:14:10,440
I lead uh PM for Lambda.

411
00:14:11,658 --> 00:14:12,239
So,

412
00:14:13,259 --> 00:14:15,460
Lambda has been around for a decade now.

413
00:14:16,710 --> 00:14:18,798
And as with any product or

414
00:14:18,798 --> 00:14:20,960
technology that manages to stick around for around

415
00:14:20,960 --> 00:14:21,979
a decade and more,

416
00:14:22,558 --> 00:14:23,950
there's some notions that build up,

417
00:14:24,320 --> 00:14:26,440
there's some preconceived notions, biases

418
00:14:26,440 --> 00:14:28,629
even about what the technology can do,

419
00:14:28,840 --> 00:14:30,840
what it cannot do, what is it good for, what is

420
00:14:30,840 --> 00:14:32,080
it not good for, and so on.

421
00:14:33,190 --> 00:14:35,239
But then there's always some inflection points that come

422
00:14:35,239 --> 00:14:37,719
in, and I believe, I really believe that Serveus

423
00:14:37,719 --> 00:14:39,899
is at such an inflection point now.

424
00:14:41,219 --> 00:14:43,340
So, what we're going to do next is we're

425
00:14:43,340 --> 00:14:44,840
gonna have some fun, you know, over the next

426
00:14:45,178 --> 00:14:47,529
30 minutes or so, we're going to build an

427
00:14:47,529 --> 00:14:49,580
application, and along the way, I'll

428
00:14:49,580 --> 00:14:51,580
show you some of the capabilities that we

429
00:14:51,580 --> 00:14:52,239
launched

430
00:14:52,979 --> 00:14:55,538
that allow you to now bring workloads to serverless

431
00:14:55,750 --> 00:14:56,918
that you could not before.

432
00:14:57,788 --> 00:15:00,869
OK. So

433
00:15:00,869 --> 00:15:02,029
here is what we're going to build.

434
00:15:02,349 --> 00:15:04,548
It's a note taking application, you know, it's

435
00:15:04,548 --> 00:15:06,739
going to have create, read, update, delete, uh,

436
00:15:06,750 --> 00:15:07,769
as functionalities.

437
00:15:08,509 --> 00:15:10,389
Uh, we're gonna scale the application.

438
00:15:10,869 --> 00:15:12,869
We're going to then build new features

439
00:15:12,869 --> 00:15:15,229
that our customers will want encryption

440
00:15:15,229 --> 00:15:17,450
and decryption of notes, analyzing the sentiment.

441
00:15:17,469 --> 00:15:19,509
And finally, for those who really

442
00:15:19,509 --> 00:15:21,989
like to write lengthy notes, the

443
00:15:21,989 --> 00:15:22,649
generation is not,

444
00:15:22,989 --> 00:15:25,070
uh, at least research says the attention

445
00:15:25,070 --> 00:15:27,070
spans are going down, so we're going to use AI to

446
00:15:27,070 --> 00:15:28,090
summarize our notes.

447
00:15:28,940 --> 00:15:31,808
OK. So

448
00:15:31,808 --> 00:15:34,038
let's move on to phase one. We're going to build our

449
00:15:34,038 --> 00:15:35,950
foundation now, the CRD APIs.

450
00:15:37,129 --> 00:15:39,269
And I'm not going to show you my typing speed.

451
00:15:39,690 --> 00:15:41,690
What we are going to leverage here is uh

452
00:15:41,690 --> 00:15:43,830
vibe coding, as Usman was talking about.

453
00:15:44,678 --> 00:15:46,168
And uh a key to

454
00:15:46,450 --> 00:15:48,509
uh VIP coding or successful VIP coding

455
00:15:48,509 --> 00:15:50,529
is uh is a technology that we released

456
00:15:50,529 --> 00:15:53,048
earlier this year. It's the serverless MCP

457
00:15:53,048 --> 00:15:55,200
server. What it

458
00:15:55,200 --> 00:15:56,538
enables your favorite

459
00:15:57,119 --> 00:15:58,960
AI coding assistant to do

460
00:15:59,320 --> 00:16:01,399
is to convert your national language

461
00:16:01,399 --> 00:16:03,479
prompts better into well-architected

462
00:16:03,479 --> 00:16:05,558
codes, which are uh compliant to,

463
00:16:05,678 --> 00:16:07,580
you know, you can run it in production very fast.

464
00:16:10,320 --> 00:16:11,678
So let us get to it.

465
00:16:12,389 --> 00:16:14,229
We're gonna do it in 3 phases, OK?

466
00:16:14,668 --> 00:16:17,210
So, the first is we're gonna install our MCP servers,

467
00:16:17,830 --> 00:16:19,950
and my personal, personal preference is

468
00:16:19,950 --> 00:16:22,369
to also install the DOC MCP server.

469
00:16:22,788 --> 00:16:24,928
I found it to be really useful

470
00:16:24,928 --> 00:16:27,099
in using new technologies which have been

471
00:16:27,099 --> 00:16:28,099
recently announced,

472
00:16:28,629 --> 00:16:30,658
and uh I love to hear, and I'm pretty sure all

473
00:16:30,658 --> 00:16:32,678
of us love to hear that you are absolutely

474
00:16:32,678 --> 00:16:34,500
right. Uh,

475
00:16:34,879 --> 00:16:36,899
the DOC MCP server reduces it.

476
00:16:37,279 --> 00:16:39,149
If you know, you know what I'm talking about,

477
00:16:39,479 --> 00:16:40,879
but, uh, I, I like to use it.

478
00:16:41,609 --> 00:16:43,950
In the second phase, uh, we're going to actually

479
00:16:43,950 --> 00:16:46,070
write code for our CRUD APIs.

480
00:16:46,619 --> 00:16:48,979
Uh, it's going to be a fully serverless architecture, so

481
00:16:48,979 --> 00:16:50,808
API gateway for ingress,

482
00:16:51,119 --> 00:16:53,379
lambda functions for CRD operations.

483
00:16:53,700 --> 00:16:56,000
Uh, we're gonna use Dynamo DB tables for

484
00:16:56,000 --> 00:16:57,629
serverless, uh, databases,

485
00:16:58,168 --> 00:16:58,979
uh, cloud watch,

486
00:16:59,259 --> 00:17:01,538
structured logging, you know, observability is really critical

487
00:17:01,538 --> 00:17:02,918
in server-less architectures.

488
00:17:03,928 --> 00:17:06,170
And I like to think that I'm still a developer, so

489
00:17:06,170 --> 00:17:08,358
I like my types. I'm going to be using TypeScript

490
00:17:08,358 --> 00:17:10,358
for this. And

491
00:17:10,509 --> 00:17:13,038
then finally comes the build and deployment phases,

492
00:17:13,428 --> 00:17:15,909
and what we will see is that the MCP

493
00:17:15,909 --> 00:17:17,928
server defaults to using this tool

494
00:17:18,229 --> 00:17:20,188
for build and deployment called SAM.

495
00:17:20,868 --> 00:17:22,249
SAM stands for serverless application model.

496
00:17:23,749 --> 00:17:26,108
We've uh purpose built it for serverless

497
00:17:26,108 --> 00:17:27,269
builds and deployments.

498
00:17:27,749 --> 00:17:29,847
Uh, it really simplifies your

499
00:17:30,347 --> 00:17:32,347
uh builds, your deployments,

500
00:17:32,468 --> 00:17:34,587
and uh also enables you, enables

501
00:17:34,587 --> 00:17:36,528
you to simplify your local testing phases.

502
00:17:39,930 --> 00:17:42,439
So what I've done is I installed the

503
00:17:42,439 --> 00:17:44,509
serverless MCP server, and here's a

504
00:17:44,509 --> 00:17:46,500
picture that shows you the tools.

505
00:17:47,299 --> 00:17:48,838
At the time when I captured the picture,

506
00:17:49,449 --> 00:17:51,880
around about a week before reinvent, you know, we had 25

507
00:17:51,880 --> 00:17:54,039
tools. These tools are now available

508
00:17:54,039 --> 00:17:55,539
for the AI coding assistant.

509
00:17:56,660 --> 00:17:58,000
Some of the critical tools

510
00:17:58,380 --> 00:18:00,539
are, uh, you know, it gets guidance in

511
00:18:00,539 --> 00:18:02,660
what workloads are good for lambda, what are not good

512
00:18:02,660 --> 00:18:03,299
for lambda,

513
00:18:03,779 --> 00:18:05,779
how to build and deploy web apps, how to

514
00:18:05,779 --> 00:18:07,809
build and deploy event-driven architectures,

515
00:18:07,979 --> 00:18:10,019
including your Kinesis and Kafka,

516
00:18:10,338 --> 00:18:11,519
ESMs and so on.

517
00:18:12,489 --> 00:18:13,920
It also knows how to,

518
00:18:14,250 --> 00:18:16,828
when I see tools there to get metric, you know, to

519
00:18:17,130 --> 00:18:19,170
uh get metrics for cloudwatch, you know,

520
00:18:19,250 --> 00:18:21,289
you have to know which metric, where to get it

521
00:18:21,289 --> 00:18:22,789
from, and so on. It helps to

522
00:18:23,118 --> 00:18:24,328
uh fine tune that for you.

523
00:18:24,939 --> 00:18:26,348
And also assist SSE.

524
00:18:29,289 --> 00:18:31,650
Next, we're going to write the code.

525
00:18:32,479 --> 00:18:34,519
So, I threw in the prompt that we saw on

526
00:18:34,519 --> 00:18:35,979
the previous slide,

527
00:18:36,598 --> 00:18:38,739
and in around about 5 to 10 seconds,

528
00:18:39,078 --> 00:18:41,068
uh, Quiro, you know, my AI assistant,

529
00:18:41,469 --> 00:18:43,509
uh, it's gonna tell me that the code files

530
00:18:43,509 --> 00:18:45,640
are already done, and the next step is

531
00:18:45,640 --> 00:18:46,818
to build and deploy.

532
00:18:48,920 --> 00:18:50,920
So I've magnified some images

533
00:18:50,920 --> 00:18:53,059
here for us to examine what it did under

534
00:18:53,059 --> 00:18:55,309
the hood. So you see the project

535
00:18:55,309 --> 00:18:56,568
structure that uh

536
00:18:56,868 --> 00:18:58,969
Quiro or my AI coding assistant made

537
00:18:58,969 --> 00:19:00,568
with the help of the MCP server.

538
00:19:02,029 --> 00:19:04,078
Uh, you see the template. YAML file,

539
00:19:04,318 --> 00:19:06,318
you, that is the IAC assistance that

540
00:19:06,318 --> 00:19:07,459
you get out of the box.

541
00:19:08,519 --> 00:19:09,799
The package.JSN

542
00:19:10,239 --> 00:19:12,479
enables you to simplify dependency management

543
00:19:12,479 --> 00:19:14,598
for your application. The TS file is obviously

544
00:19:14,598 --> 00:19:15,598
the business logic,

545
00:19:16,078 --> 00:19:17,199
and the TS config

546
00:19:17,949 --> 00:19:20,098
uh helps you to simplify the build or know

547
00:19:20,108 --> 00:19:22,279
knows the build steps to run

548
00:19:22,279 --> 00:19:24,318
as you transile the TypeScript to JavaScript.

549
00:19:27,049 --> 00:19:29,809
And then there's some error handling which is now automatically

550
00:19:29,809 --> 00:19:31,858
built in. So without the MCP server,

551
00:19:31,900 --> 00:19:33,939
this was not built in. I don't have a before picture,

552
00:19:34,019 --> 00:19:35,279
but the after picture is here.

553
00:19:35,660 --> 00:19:37,979
You see there's sufficient input validation. We're

554
00:19:37,979 --> 00:19:40,098
doing 3 retries when it comes to

555
00:19:40,098 --> 00:19:42,439
writing to Dynamo TV, you know, good practices.

556
00:19:44,068 --> 00:19:46,400
Uh, here are some additional best practices built in.

557
00:19:46,920 --> 00:19:48,959
Uh, you see the global error handler

558
00:19:48,959 --> 00:19:51,130
here. We have consistent

559
00:19:51,130 --> 00:19:52,479
HTTP status codes,

560
00:19:52,930 --> 00:19:55,130
uh, structured logging with CloudWatch, all,

561
00:19:55,250 --> 00:19:57,250
you know, unavailable from the get-go in the

562
00:19:57,250 --> 00:19:59,930
V0 of the code that was written automatically.

563
00:20:00,250 --> 00:20:02,729
So the code generation process, you know, it's, it's

564
00:20:02,729 --> 00:20:04,809
much more compliant to a well architected framework

565
00:20:04,809 --> 00:20:07,838
with this. The

566
00:20:07,838 --> 00:20:10,019
next step for us is to build and deploy.

567
00:20:10,459 --> 00:20:12,660
So I've thrown in the command to build and deploy to my

568
00:20:12,660 --> 00:20:13,318
assistant.

569
00:20:13,939 --> 00:20:16,160
What it does is, you know, SAM will take over.

570
00:20:16,578 --> 00:20:18,818
It will use the YAML files, the TS config

571
00:20:18,818 --> 00:20:20,680
files, and the package files to

572
00:20:20,989 --> 00:20:22,400
run the deployment for us.

573
00:20:22,779 --> 00:20:24,779
It will enforce best practices along

574
00:20:24,779 --> 00:20:26,618
the way, you know, we'll magnify this image in a bit.

575
00:20:27,229 --> 00:20:29,529
It will show us the cloud formation

576
00:20:29,529 --> 00:20:31,650
change stack or the change set

577
00:20:31,650 --> 00:20:33,608
uh that shows the delta of

578
00:20:33,989 --> 00:20:34,890
all of the

579
00:20:35,549 --> 00:20:37,719
work that we're going to deploy to AWS.

580
00:20:38,269 --> 00:20:40,410
It will upload the code to S3.

581
00:20:41,189 --> 00:20:43,239
In a second, hopefully, that is complete. Here's the

582
00:20:43,239 --> 00:20:43,818
change set,

583
00:20:44,318 --> 00:20:46,858
and then as we go to the console,

584
00:20:47,680 --> 00:20:49,799
we will see that our functions then

585
00:20:49,799 --> 00:20:50,660
begin to light up.

586
00:20:51,410 --> 00:20:53,430
The council should load any moment now.

587
00:20:55,459 --> 00:20:56,049
There you go.

588
00:20:56,380 --> 00:20:58,459
So, here are all of the 5 functions that

589
00:20:58,459 --> 00:21:00,838
we wrote, and they're right there available

590
00:21:02,098 --> 00:21:03,939
for us to sort of serve traffic to.

591
00:21:05,809 --> 00:21:07,630
So, here's some uh magnified images.

592
00:21:08,049 --> 00:21:10,348
So while building, you know, Sam detected

593
00:21:10,348 --> 00:21:12,759
that our APIs had no authentication.

594
00:21:13,209 --> 00:21:15,250
It was asking me to confirm if this is really what I

595
00:21:15,250 --> 00:21:15,890
want to do

596
00:21:16,209 --> 00:21:18,390
and uh since this was a demo, you know, I

597
00:21:18,390 --> 00:21:19,750
chose to go yes.

598
00:21:21,140 --> 00:21:23,140
Here's a snapshot of the change set

599
00:21:23,140 --> 00:21:25,118
that it is walking us through. It is adding

600
00:21:25,380 --> 00:21:27,459
uh all of these files, these rules and

601
00:21:27,459 --> 00:21:29,459
permissions for databases and functions and so

602
00:21:29,459 --> 00:21:31,469
on. So your build

603
00:21:31,469 --> 00:21:33,670
and deployment steps are also much simpler

604
00:21:33,670 --> 00:21:34,189
with SAM.

605
00:21:36,449 --> 00:21:38,459
So if you think about it, uh, I don't know if

606
00:21:38,459 --> 00:21:40,059
I spoke more than 57 minutes,

607
00:21:40,420 --> 00:21:42,660
uh, but in around about 5 to 7 minutes, we

608
00:21:42,660 --> 00:21:45,098
have a fully working back end and the cloud

609
00:21:45,098 --> 00:21:46,880
operations, the cloud APIs are deployed

610
00:21:47,618 --> 00:21:49,118
fully using natural language

611
00:21:49,459 --> 00:21:51,459
with well architected framework, you know, sort of

612
00:21:51,459 --> 00:21:51,979
baked in.

613
00:21:52,759 --> 00:21:54,769
And when we talk to customers, you know,

614
00:21:54,848 --> 00:21:57,250
they do tell us that generative AI has actually

615
00:21:57,250 --> 00:21:59,229
sped up the code generation process,

616
00:21:59,689 --> 00:22:01,890
but it's not resulting in shipping the

617
00:22:01,890 --> 00:22:03,400
actual software faster.

618
00:22:03,739 --> 00:22:05,949
That's because the ship cycle has a much more,

619
00:22:06,338 --> 00:22:08,519
you know, process baked into it, you know, there's IAC,

620
00:22:08,568 --> 00:22:10,029
there's code reviews, and so on,

621
00:22:10,608 --> 00:22:12,608
and all of that is not really becoming

622
00:22:12,608 --> 00:22:13,500
faster with Gen AI,

623
00:22:14,049 --> 00:22:16,049
and that is where Survellus has tried to innovate

624
00:22:16,049 --> 00:22:17,189
right across the stack.

625
00:22:17,739 --> 00:22:19,939
So we enforce best practices while you

626
00:22:19,939 --> 00:22:22,059
generate the code, we just saw that

627
00:22:22,059 --> 00:22:24,259
during build steps and also during deployment steps.

628
00:22:27,209 --> 00:22:29,209
The key takeaways I want us to sort of focus

629
00:22:29,209 --> 00:22:31,250
on here are that uh MCP

630
00:22:31,250 --> 00:22:32,588
server helps you to

631
00:22:32,930 --> 00:22:34,969
uh generate, you know, best practices

632
00:22:34,969 --> 00:22:37,049
sort of code baked in, the best practices baked into

633
00:22:37,049 --> 00:22:39,368
the code. And I work

634
00:22:39,368 --> 00:22:40,989
with a lot of developers.

635
00:22:41,729 --> 00:22:43,848
And their productivity is high,

636
00:22:44,088 --> 00:22:46,449
you know, but they are now actually able to ship software

637
00:22:46,449 --> 00:22:47,219
also faster.

638
00:22:48,618 --> 00:22:50,219
Because the IAC is baked in

639
00:22:50,670 --> 00:22:52,709
and uh what they love the most is the

640
00:22:52,709 --> 00:22:55,088
code that is produced is of a consistent quality

641
00:22:55,588 --> 00:22:57,709
because a lot of people, you know, a lot of customers also

642
00:22:57,709 --> 00:22:59,039
sort of complain that, hey,

643
00:22:59,390 --> 00:23:01,509
uh, some people just wipe code and then send out a

644
00:23:01,509 --> 00:23:03,170
code review without, you know,

645
00:23:03,549 --> 00:23:04,779
making sense of what it is.

646
00:23:05,150 --> 00:23:07,269
It sort of helps you to minimize those problems

647
00:23:07,269 --> 00:23:09,588
by producing a code of uh consistent quality.

648
00:23:12,299 --> 00:23:12,848
Alright.

649
00:23:13,848 --> 00:23:14,838
So moving on,

650
00:23:15,739 --> 00:23:17,939
let's say our application was picked up by

651
00:23:17,939 --> 00:23:19,818
some news media outlet.

652
00:23:20,900 --> 00:23:22,539
Now, what that has resulted in

653
00:23:22,858 --> 00:23:24,939
is a bunch of concurrent traffic,

654
00:23:25,098 --> 00:23:26,059
you know, right off the bat.

655
00:23:28,000 --> 00:23:30,309
So the way customers tell us they handle this scenario

656
00:23:30,809 --> 00:23:32,890
is uh they overprovision

657
00:23:32,890 --> 00:23:34,890
capacity. When I say overprovision, meaning, you know, they

658
00:23:34,890 --> 00:23:35,930
provision for peak

659
00:23:36,368 --> 00:23:38,489
with the, with the understanding that

660
00:23:38,489 --> 00:23:40,608
hey, at some point in time, you know, I'll go back in

661
00:23:40,920 --> 00:23:43,489
as a developer of that application and try to optimize

662
00:23:43,489 --> 00:23:45,549
my, you know, costs by

663
00:23:45,769 --> 00:23:47,660
applying the right scaling policies.

664
00:23:48,670 --> 00:23:50,759
But this provisioning for peak leads to higher

665
00:23:50,759 --> 00:23:51,420
costs

666
00:23:51,719 --> 00:23:53,900
and also a bunch of human-led maintenance.

667
00:23:54,848 --> 00:23:56,368
And, you know, tomorrow never comes.

668
00:23:56,828 --> 00:23:58,828
Um, the, the scaling policies, you know,

669
00:23:58,910 --> 00:24:01,068
you're constantly having to optimize, but you find

670
00:24:01,068 --> 00:24:03,229
ways to just build features instead of focusing on also

671
00:24:03,229 --> 00:24:04,170
on optimizations.

672
00:24:06,479 --> 00:24:08,289
So how do we handle that with serverless?

673
00:24:09,469 --> 00:24:11,939
So with Serverless, we give you hands-free scaling

674
00:24:11,939 --> 00:24:14,150
options. Our scaling rate is

675
00:24:14,150 --> 00:24:14,769
pretty much

676
00:24:15,029 --> 00:24:17,170
uh fastest amongst all compute

677
00:24:17,170 --> 00:24:18,410
choices that you have.

678
00:24:19,250 --> 00:24:21,449
So we give you 1000 execution environments

679
00:24:21,449 --> 00:24:22,410
every 10 seconds.

680
00:24:23,130 --> 00:24:25,618
So if you think about it, if your function's

681
00:24:25,618 --> 00:24:27,729
execution time is 100 milliseconds,

682
00:24:28,098 --> 00:24:30,098
what you're really getting is 10,000

683
00:24:30,098 --> 00:24:30,900
RPS

684
00:24:31,180 --> 00:24:32,420
every 10 seconds,

685
00:24:33,140 --> 00:24:34,900
right off the bat without lifting a finger.

686
00:24:36,239 --> 00:24:37,229
Let's uh

687
00:24:37,630 --> 00:24:38,449
run a load test.

688
00:24:39,959 --> 00:24:42,039
So, I've designed a very basic custom load

689
00:24:42,039 --> 00:24:44,338
test. Uh, I'm around

690
00:24:44,338 --> 00:24:46,420
about a minute in here, and you see that

691
00:24:46,420 --> 00:24:48,539
I've literally 700, 800xed

692
00:24:48,539 --> 00:24:50,799
the traffic in like 25, 30 seconds.

693
00:24:51,559 --> 00:24:53,559
And there is not a single error, there's

694
00:24:53,559 --> 00:24:54,598
not one throttle.

695
00:24:54,900 --> 00:24:56,920
You know, lambda is able to just absorb it

696
00:24:56,920 --> 00:24:58,019
right off the bat, and

697
00:24:58,279 --> 00:25:00,390
you didn't have to lift a single finger to

698
00:25:00,390 --> 00:25:02,420
do so. So this is

699
00:25:02,420 --> 00:25:04,420
the power that Serveus gives you. This is

700
00:25:04,420 --> 00:25:06,779
the kind of workload that Serveus really shines

701
00:25:06,779 --> 00:25:08,939
in, uh, leads to a lot

702
00:25:08,939 --> 00:25:11,318
of happy new users, end users,

703
00:25:11,880 --> 00:25:14,199
and all of this without any idle costs.

704
00:25:15,568 --> 00:25:17,439
So the key takeaways are like,

705
00:25:17,838 --> 00:25:20,000
our scaling rate is really fast, you

706
00:25:20,000 --> 00:25:21,459
know, fastest amongst all compute.

707
00:25:22,160 --> 00:25:24,160
And let us call this type of a traffic, you

708
00:25:24,160 --> 00:25:25,299
know, needlepoint traffic.

709
00:25:26,279 --> 00:25:28,489
So, imagine that, you know, you're building an

710
00:25:28,489 --> 00:25:29,239
application where,

711
00:25:29,598 --> 00:25:32,118
uh, you know, hundreds of thousands of spectators

712
00:25:32,118 --> 00:25:34,160
in the stadium have to scan a

713
00:25:34,160 --> 00:25:34,959
QR code

714
00:25:35,239 --> 00:25:36,578
whenever a goal is scored.

715
00:25:37,608 --> 00:25:39,739
You can just, uh, you know, seamlessly handle

716
00:25:39,739 --> 00:25:41,900
that. Or, you know, there's a flash

717
00:25:41,900 --> 00:25:42,420
sale,

718
00:25:42,739 --> 00:25:44,818
and I see a bunch of people wearing shoes of that

719
00:25:44,818 --> 00:25:46,078
company, and, you know, you can,

720
00:25:46,410 --> 00:25:47,180
uh,

721
00:25:47,699 --> 00:25:50,019
a new shoe drops, a new flash sale

722
00:25:50,019 --> 00:25:52,299
starts, you know, you can just handle that seamlessly.

723
00:25:53,660 --> 00:25:55,858
And uh testing is quite simple

724
00:25:55,858 --> 00:25:58,299
because you're literally only testing your

725
00:25:58,299 --> 00:26:00,380
application logic. You're not testing scaling at all, it

726
00:26:00,380 --> 00:26:02,750
just works. Lambda provides it to you out of the box.

727
00:26:03,640 --> 00:26:05,880
And multiple pieces of the functionality

728
00:26:05,880 --> 00:26:06,500
in our application,

729
00:26:06,799 --> 00:26:09,039
so you, you saw we had 4 or 5 APIs

730
00:26:09,039 --> 00:26:09,739
that we built,

731
00:26:10,318 --> 00:26:12,439
all of them scale at the same rate independently

732
00:26:12,439 --> 00:26:13,420
of each other without

733
00:26:13,900 --> 00:26:16,239
affecting scaling rates of anything else. So the, the

734
00:26:16,239 --> 00:26:18,880
noisy neighbor problem that you have is sort of eliminated.

735
00:26:19,559 --> 00:26:20,420
And this is all

736
00:26:21,430 --> 00:26:23,078
without managing any infrastructure.

737
00:26:26,078 --> 00:26:26,979
Right, so far, so good.

738
00:26:27,348 --> 00:26:28,410
Let's uh move on.

739
00:26:28,838 --> 00:26:30,900
So, you know, we're good people, you know, we listen to our

740
00:26:30,900 --> 00:26:31,618
customers,

741
00:26:31,910 --> 00:26:34,049
and based on the customer feedback, we

742
00:26:34,049 --> 00:26:36,150
are now building this new feature called

743
00:26:36,150 --> 00:26:36,949
encrypting,

744
00:26:37,299 --> 00:26:39,500
decrypting notes and analyzing, analyzing

745
00:26:39,500 --> 00:26:40,469
its sentiment.

746
00:26:42,049 --> 00:26:44,098
So if you think about it carefully as a

747
00:26:44,098 --> 00:26:44,689
developer,

748
00:26:45,098 --> 00:26:47,180
the, the profile of your workload here is

749
00:26:47,180 --> 00:26:47,779
shifting.

750
00:26:48,559 --> 00:26:50,699
It's no longer just CRD APIs,

751
00:26:51,420 --> 00:26:53,439
uh, it is a more CPU intensive

752
00:26:53,439 --> 00:26:53,959
workload.

753
00:26:55,250 --> 00:26:57,368
You know, because we listen to our customers, you know, the

754
00:26:57,368 --> 00:26:59,160
feature also achieves popularity.

755
00:26:59,729 --> 00:27:01,729
Uh, what I mean by that is the scale

756
00:27:01,729 --> 00:27:04,009
to zero aspect is no longer super

757
00:27:04,009 --> 00:27:04,868
important for you.

758
00:27:05,289 --> 00:27:07,608
There's always some traffic to serve, always

759
00:27:07,608 --> 00:27:08,890
some users to service,

760
00:27:09,250 --> 00:27:11,449
so there's always, in other words, you know, some steady-state

761
00:27:11,449 --> 00:27:11,979
traffic.

762
00:27:12,630 --> 00:27:14,989
And I'm loosely defining steady-state here as,

763
00:27:15,318 --> 00:27:17,598
you know, with a peak to main traffic ratio of

764
00:27:17,598 --> 00:27:18,118
around 2.

765
00:27:19,358 --> 00:27:21,078
How do we handle that with serverless?

766
00:27:21,848 --> 00:27:22,910
Well, it was hard.

767
00:27:23,328 --> 00:27:24,828
So when we talk to customers,

768
00:27:25,368 --> 00:27:26,509
this is what they tell us.

769
00:27:27,130 --> 00:27:29,170
In this phase of the application, they really

770
00:27:29,170 --> 00:27:30,588
want to drive optimizations.

771
00:27:31,130 --> 00:27:32,618
They want to optimize costs,

772
00:27:33,088 --> 00:27:35,449
they want to optimize performance, pro probably

773
00:27:35,449 --> 00:27:37,890
by leveraging the latest in compute, memory,

774
00:27:38,049 --> 00:27:39,789
network intensive instances and so on.

775
00:27:41,049 --> 00:27:43,209
And they want to do all of that with a familiar

776
00:27:43,209 --> 00:27:44,828
developer experience that they

777
00:27:45,098 --> 00:27:47,130
currently, you know, use, they like, they

778
00:27:47,130 --> 00:27:49,189
love with all of the integrations

779
00:27:49,809 --> 00:27:51,588
and with fully surveillance operations, you know,

780
00:27:51,848 --> 00:27:53,890
so in different words, they don't want to

781
00:27:53,890 --> 00:27:56,239
remove the focus away from core business logic,

782
00:27:56,598 --> 00:27:58,608
they want to continue to leverage the practices

783
00:27:58,608 --> 00:28:00,930
that they use today but get more choices.

784
00:28:04,500 --> 00:28:06,160
So what did they do before

785
00:28:06,420 --> 00:28:07,000
this week was,

786
00:28:07,900 --> 00:28:10,019
you know, we, we saw that they would just focus on

787
00:28:10,019 --> 00:28:12,180
rearchitecting the solution away from

788
00:28:12,180 --> 00:28:12,699
serverless,

789
00:28:13,130 --> 00:28:13,900
away from lambda.

790
00:28:15,348 --> 00:28:17,838
And that was an incredibly inefficient

791
00:28:17,838 --> 00:28:19,118
use of engineering time.

792
00:28:19,900 --> 00:28:22,358
It dilutes the focus away from business logic,

793
00:28:23,219 --> 00:28:25,269
results in an increase in ongoing maintenance

794
00:28:25,269 --> 00:28:26,959
costs in perpetuity,

795
00:28:27,578 --> 00:28:29,019
and again, incredibly inefficient.

796
00:28:30,269 --> 00:28:32,279
So we wanted to design a better way to

797
00:28:32,279 --> 00:28:33,640
support such scenarios.

798
00:28:34,578 --> 00:28:35,818
In serverless on lambda.

799
00:28:36,699 --> 00:28:39,059
Uh, and we're delighted to introduce to you

800
00:28:39,059 --> 00:28:40,640
Lambda's managed instances.

801
00:28:41,140 --> 00:28:43,199
So the mental model behind this feature

802
00:28:43,660 --> 00:28:45,769
is that we want to give you all of the Lambda's sim

803
00:28:45,769 --> 00:28:47,900
simplicity in developer experience

804
00:28:47,900 --> 00:28:49,420
and integrations and tooling.

805
00:28:50,420 --> 00:28:52,618
And marry it with EC2's

806
00:28:52,618 --> 00:28:54,858
specificity and flexibility of choices

807
00:28:54,858 --> 00:28:56,858
and compute and network and memory that you

808
00:28:56,858 --> 00:28:59,108
get. So,

809
00:28:59,118 --> 00:29:00,299
with the LMI

810
00:29:00,920 --> 00:29:02,269
you get access to latest,

811
00:29:02,559 --> 00:29:04,880
you know, for instance, families like Graviton

812
00:29:04,880 --> 00:29:07,039
4, you know, or probably Graviton

813
00:29:07,039 --> 00:29:08,519
5 as soon as it comes out.

814
00:29:08,880 --> 00:29:09,680
You're going to get

815
00:29:09,959 --> 00:29:12,000
uh the latest generation in instances

816
00:29:12,000 --> 00:29:13,180
in memory compute,

817
00:29:13,519 --> 00:29:14,420
network optimized.

818
00:29:15,598 --> 00:29:17,959
All of this continues to be fully managed

819
00:29:18,199 --> 00:29:20,328
as Usman was saying earlier, you know, surveillance

820
00:29:20,328 --> 00:29:21,818
is not the absence of

821
00:29:22,358 --> 00:29:24,390
servers, you know, we just manage the servers

822
00:29:24,390 --> 00:29:26,479
for you. Here we're giving you those options,

823
00:29:26,519 --> 00:29:28,489
but we continue to manage the servers for you,

824
00:29:28,880 --> 00:29:31,130
so we're going to continue to scale them, you know, patch

825
00:29:31,130 --> 00:29:33,199
them, route requests to them, you know, the

826
00:29:33,199 --> 00:29:35,289
whole thing. You

827
00:29:35,289 --> 00:29:37,930
continue to get the same extensive event source integrations

828
00:29:37,930 --> 00:29:40,009
that you used to get with lambda and

829
00:29:40,009 --> 00:29:41,289
you still get with lambda rather.

830
00:29:43,519 --> 00:29:45,598
And with this uh LMI we're also

831
00:29:45,598 --> 00:29:46,539
adding a new

832
00:29:46,838 --> 00:29:47,380
feature

833
00:29:47,719 --> 00:29:49,059
called multi-concurrency,

834
00:29:49,400 --> 00:29:51,640
or the ability to serve multiple requests

835
00:29:51,640 --> 00:29:53,759
from the same execution environment, which has been a

836
00:29:53,759 --> 00:29:55,358
long-standing customer ask.

837
00:29:55,949 --> 00:29:56,759
And uh

838
00:29:57,160 --> 00:29:59,250
when you combine this feature with EC2's

839
00:29:59,250 --> 00:30:01,279
pricing incentives of savings plan,

840
00:30:01,358 --> 00:30:02,838
reserved instances, and so on,

841
00:30:03,358 --> 00:30:05,719
your cost really, really optimizes.

842
00:30:06,420 --> 00:30:07,680
And we'll see in a second how.

843
00:30:09,759 --> 00:30:10,459
So using

844
00:30:10,959 --> 00:30:13,118
lambda managed instances is as

845
00:30:13,118 --> 00:30:15,199
easy as just creating a capacity

846
00:30:15,199 --> 00:30:17,699
provider. When you create a capacity

847
00:30:17,699 --> 00:30:20,059
provider, you have the option to specify

848
00:30:20,059 --> 00:30:22,219
any choice you want, and again, I, I

849
00:30:22,219 --> 00:30:24,219
focus on the word option because this is

850
00:30:24,219 --> 00:30:25,098
really an option,

851
00:30:25,618 --> 00:30:27,039
optional setting that you specify.

852
00:30:27,299 --> 00:30:28,439
Any instance types,

853
00:30:28,699 --> 00:30:30,779
any scaling policies, you know, maximin, all

854
00:30:30,779 --> 00:30:31,930
of that is configurable,

855
00:30:32,219 --> 00:30:34,578
but optionally. You can just be hands-free

856
00:30:34,578 --> 00:30:36,380
and let lambda and AWS take care of it.

857
00:30:37,229 --> 00:30:38,049
Once you do that,

858
00:30:38,309 --> 00:30:40,578
you will create your function the way you, uh, you do

859
00:30:40,578 --> 00:30:42,750
today. You'll just configure it to a capacity provider.

860
00:30:43,430 --> 00:30:45,630
And then lambda will scale it, patch it,

861
00:30:45,828 --> 00:30:48,368
you know, run it, provision the instances,

862
00:30:48,828 --> 00:30:50,910
uh, it will pick the suitable instances for your

863
00:30:50,910 --> 00:30:53,130
workload and, and drive this continuous

864
00:30:53,130 --> 00:30:55,630
optimization loop for the utilization.

865
00:30:58,439 --> 00:31:00,439
Now, adding servers to server list, you

866
00:31:00,439 --> 00:31:01,539
know, it's a tricky

867
00:31:02,358 --> 00:31:03,750
thing to sort of get right.

868
00:31:04,078 --> 00:31:06,118
So we did uh try to do deep research

869
00:31:06,118 --> 00:31:08,328
here to make sure that the experience is as simple

870
00:31:08,328 --> 00:31:09,920
as, as it possibly could.

871
00:31:10,868 --> 00:31:11,809
Let us see how.

872
00:31:13,489 --> 00:31:15,598
So, I'm on the Lambda console now, and

873
00:31:15,598 --> 00:31:17,630
I head to capacity providers, the new feature

874
00:31:17,630 --> 00:31:18,578
that lights up.

875
00:31:19,199 --> 00:31:21,368
I'll create the capacity provider, give it a name,

876
00:31:21,880 --> 00:31:23,920
give it a VPC, subnet,

877
00:31:24,680 --> 00:31:25,719
security groups,

878
00:31:26,108 --> 00:31:28,559
and an operator role that has

879
00:31:28,559 --> 00:31:30,088
access to manipulate my EC-2,

880
00:31:30,588 --> 00:31:32,759
and then I head over to the advanced settings where the action

881
00:31:32,759 --> 00:31:33,338
really is.

882
00:31:33,799 --> 00:31:35,880
So here you can choose your architectures,

883
00:31:35,959 --> 00:31:37,719
you know, from Graviton or X86.

884
00:31:38,039 --> 00:31:40,759
You can uh include or exclude certain

885
00:31:40,759 --> 00:31:42,910
instance types or, you know, just let Lambda

886
00:31:42,910 --> 00:31:43,539
pick for you.

887
00:31:43,880 --> 00:31:45,880
You can apply scaling policies, you know, a

888
00:31:45,880 --> 00:31:47,858
max to cap your costs,

889
00:31:48,199 --> 00:31:50,799
or a min to always have some pre-warmed

890
00:31:50,799 --> 00:31:52,858
instances available to serve your traffic.

891
00:31:53,358 --> 00:31:54,680
You can tag them for tracking,

892
00:31:55,828 --> 00:31:58,059
tracking purposes, and so on.

893
00:31:58,479 --> 00:32:00,559
And when you head back here in a second, you'll see that

894
00:32:00,559 --> 00:32:02,338
the capacity provider is now active.

895
00:32:03,160 --> 00:32:05,390
Now, at this point, you know, there is no EC2

896
00:32:05,390 --> 00:32:07,838
instance that has started because it's just the capacity

897
00:32:07,838 --> 00:32:09,578
provider construct that you've created.

898
00:32:09,920 --> 00:32:11,920
There's no charge for creating this capacity provider.

899
00:32:14,630 --> 00:32:16,818
The next thing we have, we,

900
00:32:16,868 --> 00:32:18,910
we thought of getting right or we just wanted to get

901
00:32:18,910 --> 00:32:19,769
right was the

902
00:32:20,029 --> 00:32:22,029
same developer experience that you have

903
00:32:22,029 --> 00:32:22,910
with Lambda today.

904
00:32:24,140 --> 00:32:25,199
Let's see how we did.

905
00:32:25,699 --> 00:32:27,979
So, here's the updated create function

906
00:32:27,979 --> 00:32:30,059
flow. You can see that it is the

907
00:32:30,059 --> 00:32:31,108
exact same,

908
00:32:31,380 --> 00:32:33,838
but there's just one new additional parameter,

909
00:32:34,098 --> 00:32:36,019
which is the capacity provider config.

910
00:32:37,160 --> 00:32:39,170
And along with here, I wanted to highlight two

911
00:32:39,170 --> 00:32:41,608
additional features. One is the multi-concurrency

912
00:32:41,608 --> 00:32:43,289
support that we've discussed in a second,

913
00:32:43,689 --> 00:32:44,430
a second back.

914
00:32:45,328 --> 00:32:47,759
And then there's also the ability to customize

915
00:32:47,759 --> 00:32:49,479
the memory to CPU ratio.

916
00:32:50,689 --> 00:32:52,848
Just like EC2 instances, you

917
00:32:52,848 --> 00:32:55,250
can now choose your memory to CPU ratio

918
00:32:55,250 --> 00:32:56,049
on lambda

919
00:32:56,309 --> 00:32:58,368
to conform to the compute-intensive

920
00:32:58,368 --> 00:33:00,608
or memory-intensive or, you know, general-purpose

921
00:33:00,608 --> 00:33:01,130
instances.

922
00:33:02,239 --> 00:33:04,239
So you can imagine the classes of new workloads

923
00:33:04,239 --> 00:33:06,439
that you can now run on lambda, which you could not

924
00:33:06,439 --> 00:33:09,130
before. So

925
00:33:09,130 --> 00:33:10,969
what we'll do next is I've,

926
00:33:11,368 --> 00:33:13,368
I'll throw in that create config command

927
00:33:13,368 --> 00:33:14,289
to my assistant.

928
00:33:15,068 --> 00:33:17,150
And I'll then create my function, I'll

929
00:33:17,150 --> 00:33:18,160
go back in there,

930
00:33:18,509 --> 00:33:20,630
and when I see the configuration tab,

931
00:33:20,989 --> 00:33:23,410
there it is, it's configured to the capacity provider.

932
00:33:24,068 --> 00:33:26,390
I'll go in, change the memory settings

933
00:33:26,390 --> 00:33:28,959
to 4 GB for the function for demo purposes,

934
00:33:29,699 --> 00:33:31,789
and I'll go back into that other setting in

935
00:33:31,789 --> 00:33:34,170
a second, and I will shift

936
00:33:34,170 --> 00:33:34,689
the

937
00:33:35,029 --> 00:33:37,380
multi-concurrent setting to 64

938
00:33:37,380 --> 00:33:39,430
concurrent requests from the same execution

939
00:33:39,430 --> 00:33:41,789
environment, change the memory to VCPU

940
00:33:41,789 --> 00:33:42,848
to 4S2 1.

941
00:33:43,469 --> 00:33:44,809
And when I hit save,

942
00:33:45,348 --> 00:33:47,430
and then head back to the capacity

943
00:33:47,430 --> 00:33:49,640
provider, I'll see that

944
00:33:49,640 --> 00:33:51,140
the function is now active.

945
00:33:51,910 --> 00:33:54,150
And it is at this point that my EC2

946
00:33:54,150 --> 00:33:56,150
instances will be created. Here's the EC2

947
00:33:56,150 --> 00:33:56,729
console.

948
00:33:57,439 --> 00:33:59,640
And uh if you notice uh carefully,

949
00:33:59,719 --> 00:34:02,078
you know, the, when I provided subnets

950
00:34:02,078 --> 00:34:04,358
initially while creating the capacity provider, I

951
00:34:04,358 --> 00:34:05,828
provided it in 3 AZs.

952
00:34:06,400 --> 00:34:08,519
So my EC2 instances are also across 3

953
00:34:08,519 --> 00:34:09,260
AZs now.

954
00:34:09,599 --> 00:34:11,668
So my instances and by extension,

955
00:34:11,760 --> 00:34:12,619
my application

956
00:34:12,958 --> 00:34:15,039
is also now finally AZ balanced.

957
00:34:16,019 --> 00:34:18,320
And at this point, once the function is active, the

958
00:34:18,320 --> 00:34:19,570
EC2 instances are spun up,

959
00:34:19,860 --> 00:34:22,320
your execution environments are pre-warmed

960
00:34:22,320 --> 00:34:24,438
with multi-concurrency support enabled,

961
00:34:24,699 --> 00:34:26,019
ready to serve your traffic.

962
00:34:29,628 --> 00:34:31,719
So let's start a load test with our synthetic

963
00:34:31,719 --> 00:34:32,340
workload.

964
00:34:33,188 --> 00:34:34,208
And uh

965
00:34:34,708 --> 00:34:37,030
I'm around about 13 minutes into the load

966
00:34:37,030 --> 00:34:39,369
test. I enhanced the load test tool for this.

967
00:34:40,000 --> 00:34:42,188
Um, you see, the traffic is much

968
00:34:42,188 --> 00:34:44,510
more steady-state. It's still increasing, but

969
00:34:44,510 --> 00:34:46,708
still steady-state in, in, in our definition

970
00:34:46,708 --> 00:34:48,938
here. And we see that the

971
00:34:48,938 --> 00:34:51,019
scale up from 3 is now to

972
00:34:51,019 --> 00:34:51,719
7.

973
00:34:52,139 --> 00:34:54,898
We've achieved a utilization of around 25%.

974
00:34:55,579 --> 00:34:57,820
The utilization of memory

975
00:34:57,820 --> 00:34:59,398
and VCPU and the

976
00:34:59,938 --> 00:35:02,260
instances, the underlying EC2 instances, utilization

977
00:35:02,260 --> 00:35:05,039
is still pretty healthy, you know, between 15 to 35%.

978
00:35:06,079 --> 00:35:08,519
And, and remember, the higher the utilization,

979
00:35:08,840 --> 00:35:10,958
the more the cost optimization

980
00:35:10,958 --> 00:35:13,159
for you. So really, the, the

981
00:35:13,159 --> 00:35:15,280
key aspect here is the utilization is baked

982
00:35:15,280 --> 00:35:18,139
in. And

983
00:35:18,139 --> 00:35:20,458
now around an hour into the load test, you

984
00:35:20,458 --> 00:35:22,579
see the traffic is still steady state, increasing but

985
00:35:22,579 --> 00:35:23,360
steady state.

986
00:35:23,860 --> 00:35:26,219
There's throttles, 932 throttles

987
00:35:26,219 --> 00:35:26,978
to be exact,

988
00:35:27,340 --> 00:35:29,369
but again, throttles are good, you know, we can handle it

989
00:35:29,369 --> 00:35:31,378
in our code by way of retries or queuing or

990
00:35:31,378 --> 00:35:33,320
so on, but there's not a single error.

991
00:35:34,500 --> 00:35:35,769
The error rate is still 0.

992
00:35:36,349 --> 00:35:38,389
We've scaled up to 21 instances

993
00:35:38,389 --> 00:35:40,429
now, and if you observe carefully,

994
00:35:40,668 --> 00:35:43,030
the scale up and scale down has both

995
00:35:43,030 --> 00:35:43,789
been triggered.

996
00:35:44,309 --> 00:35:46,469
Uh, it sort of tracks the

997
00:35:46,469 --> 00:35:48,889
CPU utilization of the capacity provider,

998
00:35:49,239 --> 00:35:51,599
and we're still at around 25% utilization,

999
00:35:51,668 --> 00:35:53,728
22.5% in this case to be exact.

1000
00:35:56,059 --> 00:35:58,090
So I let the load tests

1001
00:35:58,090 --> 00:35:59,320
run for around 90 minutes.

1002
00:36:00,449 --> 00:36:02,599
And here's a key result I wanted to highlight.

1003
00:36:03,438 --> 00:36:05,469
So when we talk to customers, a

1004
00:36:05,469 --> 00:36:07,550
bunch of customers tell us that, hey, they take

1005
00:36:07,550 --> 00:36:09,668
this technical debt when they provision

1006
00:36:09,668 --> 00:36:11,869
for peak, when the workload profile shifts.

1007
00:36:12,938 --> 00:36:15,099
And when they take this technical debt, they don't apply

1008
00:36:15,099 --> 00:36:17,418
the scaling policies properly or they don't

1009
00:36:17,418 --> 00:36:18,889
spend time in optimizing it,

1010
00:36:19,260 --> 00:36:21,239
you know, they achieve low utilization rates.

1011
00:36:22,128 --> 00:36:24,300
So at around about 6% utilization rate,

1012
00:36:24,820 --> 00:36:26,898
the, the, my synthetic workload, you know, the load

1013
00:36:26,898 --> 00:36:29,398
test would have cost me $8.5

1014
00:36:30,280 --> 00:36:32,699
but if I improve it to 9%, you know, manually,

1015
00:36:32,739 --> 00:36:35,418
it would be $5.67.

1016
00:36:36,340 --> 00:36:38,619
But with lambda managed instances or LMI,

1017
00:36:39,059 --> 00:36:40,978
the auto-scaling is actually built in.

1018
00:36:41,688 --> 00:36:43,769
You, you actively have to go in and

1019
00:36:43,769 --> 00:36:45,849
choose to turn the auto scaling off, so from the

1020
00:36:45,849 --> 00:36:47,099
get-go, you're optimized,

1021
00:36:47,530 --> 00:36:49,849
and at the lower end of the scale we're able to achieve

1022
00:36:49,849 --> 00:36:51,969
around about 25% optimization off

1023
00:36:51,969 --> 00:36:54,050
the bat. This is literally a 60 to 90 minute

1024
00:36:54,050 --> 00:36:56,090
test, and in 130 minutes

1025
00:36:56,090 --> 00:36:58,128
itself, you, you could see earlier that the

1026
00:36:58,128 --> 00:37:00,699
utilization had reached 28.5%.

1027
00:37:01,909 --> 00:37:03,289
So, with that utilization,

1028
00:37:03,628 --> 00:37:05,969
you know, my costs just for the EC-2

1029
00:37:06,309 --> 00:37:08,168
would have been $2.05.

1030
00:37:08,789 --> 00:37:09,739
Now, on top of this,

1031
00:37:10,030 --> 00:37:12,070
Lambda managed instances applies a

1032
00:37:12,070 --> 00:37:14,168
management fee of around 15%

1033
00:37:14,510 --> 00:37:15,789
for EC2 instances.

1034
00:37:16,760 --> 00:37:18,800
Now, in that 15%, think about

1035
00:37:18,800 --> 00:37:19,648
what are you're getting.

1036
00:37:20,159 --> 00:37:22,478
You know, it's uh automatic scaling, you know, provisioning,

1037
00:37:22,639 --> 00:37:24,949
patching, continuous optimizations

1038
00:37:24,949 --> 00:37:26,889
based on your workload profile shifting.

1039
00:37:27,469 --> 00:37:29,989
There is literally no need for you to rearchitect

1040
00:37:29,989 --> 00:37:31,360
the solution away from lambda.

1041
00:37:31,679 --> 00:37:33,340
So you're saving all of that time.

1042
00:37:33,639 --> 00:37:35,780
You have to continue to use the same CICD

1043
00:37:35,780 --> 00:37:37,800
pipelines, the same observatory

1044
00:37:37,800 --> 00:37:40,179
tool set, and the same integrations are all available.

1045
00:37:45,090 --> 00:37:46,458
So, some key takeaways here,

1046
00:37:46,929 --> 00:37:49,010
uh, with lambda managed instances, you know, the

1047
00:37:49,010 --> 00:37:51,050
mental model again is to give you the simplicity

1048
00:37:51,050 --> 00:37:52,570
of lambda and serverless

1049
00:37:52,840 --> 00:37:54,929
with the specificity and the flexibility that

1050
00:37:54,929 --> 00:37:55,909
ECT gives to you.

1051
00:37:57,110 --> 00:37:58,349
And it is simple to maintain,

1052
00:37:58,628 --> 00:38:00,820
you know, out of, let's say, the 5 functions that

1053
00:38:00,820 --> 00:38:02,949
make up your application, you know, 4

1054
00:38:02,949 --> 00:38:04,949
require scale to 0, you can leave them

1055
00:38:04,949 --> 00:38:05,648
where they are.

1056
00:38:06,030 --> 00:38:08,070
The one that has achieved steady state or has

1057
00:38:08,070 --> 00:38:09,648
a different workload profile,

1058
00:38:10,070 --> 00:38:11,659
CPU intensive, you can move to

1059
00:38:12,059 --> 00:38:13,688
lambda's managed instances.

1060
00:38:15,070 --> 00:38:17,269
We continuously optimize the utilization

1061
00:38:17,269 --> 00:38:19,809
for you to give you the benefit of costs.

1062
00:38:20,389 --> 00:38:22,728
There is zero infrastructure management here,

1063
00:38:23,269 --> 00:38:24,010
and with the new

1064
00:38:24,349 --> 00:38:26,429
functionality of configuring CPU to

1065
00:38:26,429 --> 00:38:28,550
memory ratio, you know, you're able to bring in much

1066
00:38:28,550 --> 00:38:30,570
more workloads that you were not able to

1067
00:38:30,570 --> 00:38:32,050
run on serverless very easily.

1068
00:38:32,889 --> 00:38:35,070
And the managed instances, it just works.

1069
00:38:35,539 --> 00:38:37,579
Usman was talking about the ilities,

1070
00:38:37,719 --> 00:38:40,039
as he calls it earlier, you know, the reliability,

1071
00:38:40,409 --> 00:38:41,938
patching, you know, scalability,

1072
00:38:42,208 --> 00:38:44,659
availability, all of that, you know, AWS

1073
00:38:44,659 --> 00:38:46,079
and Lambda continues to be,

1074
00:38:46,360 --> 00:38:47,519
uh, responsible for

1075
00:38:48,128 --> 00:38:50,340
and all of this with the same developer experience

1076
00:38:50,340 --> 00:38:51,760
that you get with Lambda today

1077
00:38:52,179 --> 00:38:53,739
without having to rearchitect anything.

1078
00:38:56,110 --> 00:38:58,869
Next, we're gonna build a workflow-based architecture.

1079
00:38:59,188 --> 00:39:01,570
I'm gonna request Usman to come in, uh,

1080
00:39:01,719 --> 00:39:02,898
show how to build that,

1081
00:39:03,188 --> 00:39:05,199
and also talk a little bit about our strategy.

1082
00:39:05,668 --> 00:39:06,969
So, thank you very much.

1083
00:39:08,760 --> 00:39:09,719
All right thank you Janet.

1084
00:39:10,619 --> 00:39:13,478
Ah. No,

1085
00:39:13,679 --> 00:39:15,760
I, I think LMI does this or deserve a clap. It

1086
00:39:15,760 --> 00:39:17,878
I actually it was really, really cool. So a couple of cool, cool,

1087
00:39:17,958 --> 00:39:20,059
cool stories. I didn't do this in my rehearsal, so because

1088
00:39:20,059 --> 00:39:20,978
I would be mad at me.

1089
00:39:21,519 --> 00:39:23,559
The engineers were actually really mad at his demo.

1090
00:39:23,679 --> 00:39:25,679
I don't know if you guys saw what he was doing in this demo. He

1091
00:39:25,679 --> 00:39:27,840
was basically creating these spiky traffic,

1092
00:39:27,918 --> 00:39:29,750
1000 TPS for 1 2nd only.

1093
00:39:30,668 --> 00:39:32,789
And for those of you who operate the distributed

1094
00:39:32,789 --> 00:39:34,829
systems and uh scale distributed systems,

1095
00:39:35,039 --> 00:39:37,458
you know this is pretty much the worst workload. So the

1096
00:39:37,809 --> 00:39:39,840
engineers are like this is, we talk about synthetic workload.

1097
00:39:39,878 --> 00:39:41,878
This is as synthetic as it gets. But

1098
00:39:41,878 --> 00:39:43,909
again you can see the results of how the system, uh,

1099
00:39:43,918 --> 00:39:45,978
scales and works. Uh, it was a fun,

1100
00:39:46,119 --> 00:39:48,320
uh, fun last few weeks getting it out

1101
00:39:48,320 --> 00:39:49,059
the, out the door,

1102
00:39:49,320 --> 00:39:51,360
OK. And the second thing I wanted to connect with

1103
00:39:51,360 --> 00:39:53,628
you just to kind of connect to what I was speaking to you folks

1104
00:39:53,628 --> 00:39:54,199
at the beginning.

1105
00:39:54,898 --> 00:39:57,059
I I talked about trade-offs.

1106
00:39:57,099 --> 00:39:59,458
I talked about observability. I talked about

1107
00:39:59,458 --> 00:40:01,570
control. I talked about, um,

1108
00:40:01,688 --> 00:40:03,820
evolutionary architectures and how you have to use

1109
00:40:03,820 --> 00:40:05,969
ISC. Let's talk about where we are

1110
00:40:05,969 --> 00:40:07,978
with the trade-offs now with the, with the, with, with

1111
00:40:07,978 --> 00:40:10,300
what Judang just talked about. And then I'm gonna

1112
00:40:10,300 --> 00:40:11,599
show you a couple more things here

1113
00:40:11,978 --> 00:40:14,168
that we just recently launched. This was launched on Tuesday.

1114
00:40:14,418 --> 00:40:15,519
What I'm about to show you,

1115
00:40:15,860 --> 00:40:17,039
um, so

1116
00:40:17,378 --> 00:40:19,418
one of the, one in the picture, if you, for

1117
00:40:19,418 --> 00:40:21,800
those of you who remember the picture I showed about that FEMA

1118
00:40:21,800 --> 00:40:23,840
or res emergency response

1119
00:40:23,840 --> 00:40:25,909
application. What was the, what was the, what was the

1120
00:40:25,909 --> 00:40:27,010
challenging thing about it?

1121
00:40:27,280 --> 00:40:29,360
Your, your application now is highly

1122
00:40:29,360 --> 00:40:31,719
evolutionary single responsibility.

1123
00:40:31,800 --> 00:40:32,918
You don't have monoliths.

1124
00:40:33,398 --> 00:40:35,519
You're using infrastructure as code. And then what

1125
00:40:35,519 --> 00:40:37,559
Jane showed you with, with the power

1126
00:40:37,559 --> 00:40:38,860
of AI, uh,

1127
00:40:39,280 --> 00:40:41,360
actually generating SAM with the best serverless

1128
00:40:41,360 --> 00:40:43,438
practices pulled in is taking that

1129
00:40:43,438 --> 00:40:45,510
trade-off away. One of the hard, I mean for me personally

1130
00:40:45,510 --> 00:40:47,599
as a developer, I, I've shared with you folks, I, I

1131
00:40:47,599 --> 00:40:49,840
used to be a video game programmer, a hardcore C++

1132
00:40:49,840 --> 00:40:50,378
developer.

1133
00:40:50,898 --> 00:40:52,978
Writing YAL was always hard. It's

1134
00:40:52,978 --> 00:40:55,079
still always hard. I don't know why I can't do it, but

1135
00:40:55,260 --> 00:40:56,478
no, no, I don't have to do it.

1136
00:40:56,820 --> 00:40:59,458
I actually get really, really, really awesome

1137
00:40:59,458 --> 00:41:01,860
results from our MCP server with the best practices

1138
00:41:01,860 --> 00:41:03,898
built in. So that's one problem taken away

1139
00:41:03,898 --> 00:41:06,280
from developers and from infrastructure developers.

1140
00:41:06,659 --> 00:41:09,079
Second, uh, problem, and we, and

1141
00:41:09,079 --> 00:41:11,139
I, I'll be again very direct and forthright with you,

1142
00:41:11,219 --> 00:41:13,320
people used to say, Hey, lambda is too expensive at scale.

1143
00:41:13,579 --> 00:41:15,398
If my idea ever got big,

1144
00:41:15,780 --> 00:41:18,099
I will hate it or my boss will hate it if I'm an engineer

1145
00:41:18,099 --> 00:41:19,260
like because the costs go high.

1146
00:41:19,849 --> 00:41:21,659
And I was Jenakaki showed you with LMI

1147
00:41:22,208 --> 00:41:24,510
how we're able to deliver incredible usage

1148
00:41:25,039 --> 00:41:27,050
and look folks, I, I shared with you that I, I used to

1149
00:41:27,050 --> 00:41:29,329
run auto scaling. I've created hundreds of auto scaling

1150
00:41:29,329 --> 00:41:31,369
groups in, in my time at AWS.

1151
00:41:31,688 --> 00:41:34,050
I don't think I've ever managed to run code on those auto scaling

1152
00:41:34,050 --> 00:41:36,458
groups simply because I was just testing the service.

1153
00:41:36,668 --> 00:41:38,929
This is where I can go from infrastructure to code

1154
00:41:38,929 --> 00:41:40,469
to highly utilized code

1155
00:41:40,889 --> 00:41:42,610
literally in, in. In a couple of minutes

1156
00:41:42,869 --> 00:41:45,010
and that is, that is the most incredible thing about LMI.

1157
00:41:45,469 --> 00:41:47,550
So almost two fundamental things about

1158
00:41:47,550 --> 00:41:49,708
Serverless which was like, hey, it's expensive at scale,

1159
00:41:49,750 --> 00:41:51,938
or my, if I have to, I, uh, my idea gets

1160
00:41:51,938 --> 00:41:53,978
big, I have to rearchitect or I

1161
00:41:53,978 --> 00:41:55,519
have to deal with ISC and that's complex.

1162
00:41:55,989 --> 00:41:57,989
We've actually tackled those things, uh, really,

1163
00:41:58,070 --> 00:41:58,869
really well this year.

1164
00:41:59,418 --> 00:42:01,449
Now let's talk about a third thing which is,

1165
00:42:01,579 --> 00:42:03,719
hey, lambda doesn't run long run running

1166
00:42:03,719 --> 00:42:05,918
workflows or rather long running jobs, and if I ever,

1167
00:42:06,340 --> 00:42:08,500
uh, have this long running issue, I'll hit in a 15

1168
00:42:08,500 --> 00:42:09,199
minute timeout

1169
00:42:09,619 --> 00:42:11,000
and again I really hate my life.

1170
00:42:11,539 --> 00:42:13,610
So let's talk about workflows now and look folks, I've been

1171
00:42:13,610 --> 00:42:15,860
with the workflow services for a long time. Auto scaling

1172
00:42:15,860 --> 00:42:17,978
was one of the, is still one of the largest

1173
00:42:17,978 --> 00:42:20,059
users of simple workflow, so a little bit

1174
00:42:20,059 --> 00:42:20,820
behind the scenes.

1175
00:42:21,260 --> 00:42:21,878
Um,

1176
00:42:22,228 --> 00:42:24,458
I, I've, I own Simple Workflow as well. I, I'm

1177
00:42:24,458 --> 00:42:26,208
the engineering leader for Simple Workflow too.

1178
00:42:26,539 --> 00:42:28,780
One of the things we talked about, we've been talking to customers,

1179
00:42:28,820 --> 00:42:30,820
at least I've been talking to customers about workflow for

1180
00:42:30,820 --> 00:42:33,219
workflows for 12 years. Developers

1181
00:42:33,219 --> 00:42:35,409
just didn't get it unless you worked at Amazon, obviously,

1182
00:42:35,500 --> 00:42:36,750
because then we really get it,

1183
00:42:37,188 --> 00:42:39,219
uh, internally we, we know when you wanna

1184
00:42:39,219 --> 00:42:41,409
do reliable distributor systems you need a workflow.

1185
00:42:41,619 --> 00:42:43,619
The thing that has really brought workflows back

1186
00:42:43,619 --> 00:42:45,958
front and center, not everyone wants to talk about workflows,

1187
00:42:45,978 --> 00:42:48,059
obviously is AI agents or AI-based

1188
00:42:48,059 --> 00:42:48,619
workflows.

1189
00:42:49,168 --> 00:42:51,409
Um, so you obviously there's a ton of

1190
00:42:51,409 --> 00:42:53,438
interest in this, but look, this is, this is the system

1191
00:42:53,438 --> 00:42:53,949
we're building,

1192
00:42:54,438 --> 00:42:57,000
uh, and, and why we wanna do this is because orchestration

1193
00:42:57,000 --> 00:42:59,280
is important in the type of

1194
00:42:59,280 --> 00:43:01,489
applications, the new type of applications customers are building,

1195
00:43:01,728 --> 00:43:03,728
right? So in, in this particular, particular case I'm

1196
00:43:03,728 --> 00:43:05,769
talking about an enhancement to the, the

1197
00:43:05,769 --> 00:43:07,429
thing that, that Jenna kicked off

1198
00:43:07,688 --> 00:43:09,949
where I wanna be able to summarize the note from our

1199
00:43:09,949 --> 00:43:12,199
no note taking application. So these are some of the steps,

1200
00:43:12,329 --> 00:43:14,349
right? You'll have to retrieve the note from the storage

1201
00:43:14,570 --> 00:43:16,409
space. I think in my example is Dynamo DB.

1202
00:43:17,090 --> 00:43:19,539
You need to have, I, I mean, here's the thing with LLMs

1203
00:43:19,539 --> 00:43:21,750
they are asynchronous. You are waiting

1204
00:43:21,938 --> 00:43:24,019
for, for a response from them, and if you wanna scale

1205
00:43:24,019 --> 00:43:25,039
your LLM,

1206
00:43:25,369 --> 00:43:27,780
you have to make it more, more asynchronous versus

1207
00:43:27,780 --> 00:43:29,039
everything is synchronous around it.

1208
00:43:29,458 --> 00:43:31,458
Um, you, you generate the summary and

1209
00:43:31,458 --> 00:43:33,500
you need to store the result. Those are your steps

1210
00:43:33,500 --> 00:43:35,809
that quite literally map into a workflow,

1211
00:43:35,938 --> 00:43:38,239
right? And look, if

1212
00:43:38,239 --> 00:43:40,340
you were to write code today, you can run this code on anything,

1213
00:43:40,398 --> 00:43:42,320
EC2, any, any compute,

1214
00:43:42,599 --> 00:43:44,599
we can run this code on lambda as, as it is

1215
00:43:44,599 --> 00:43:45,139
right now.

1216
00:43:45,668 --> 00:43:47,869
You are now responsible for the reliability

1217
00:43:47,869 --> 00:43:48,780
of all these steps.

1218
00:43:49,110 --> 00:43:51,110
If, if you're not using a workflow system, you

1219
00:43:51,110 --> 00:43:52,849
are responsible for figuring out, OK,

1220
00:43:53,349 --> 00:43:54,739
when to handle retries,

1221
00:43:55,070 --> 00:43:57,148
when to roll back things

1222
00:43:57,148 --> 00:43:59,188
if things have gone, gone, gone incorrect, and

1223
00:43:59,188 --> 00:43:59,728
you can see,

1224
00:44:00,139 --> 00:44:02,309
you know, I have manual checkpointing

1225
00:44:02,309 --> 00:44:04,539
here somewhere. I don't have the line numbers unfortunately,

1226
00:44:04,550 --> 00:44:06,829
and I'm doing a bunch of sleeps and weights and

1227
00:44:06,829 --> 00:44:08,989
while you're waiting, especially if you're waiting on lambda.

1228
00:44:09,789 --> 00:44:10,929
You're paying for the compute

1229
00:44:11,860 --> 00:44:13,860
Right, OK, so what we heard

1230
00:44:13,860 --> 00:44:15,978
from developers basically was, look, I,

1231
00:44:16,099 --> 00:44:18,119
I, I don't wanna write code this way,

1232
00:44:18,219 --> 00:44:19,489
even if I, if I, it's simple,

1233
00:44:19,780 --> 00:44:21,639
AI can write this code for me really simply.

1234
00:44:22,139 --> 00:44:24,139
I don't wanna write this code myself and make it figure

1235
00:44:24,139 --> 00:44:25,378
out how to do it reliably.

1236
00:44:25,699 --> 00:44:28,000
Obviously I wanna still just still write code

1237
00:44:28,208 --> 00:44:29,978
and I wanna use my tools and ID.

1238
00:44:30,610 --> 00:44:32,688
Um, pausing and resuming is a really

1239
00:44:32,688 --> 00:44:33,869
powerful step simply

1240
00:44:34,188 --> 00:44:36,360
because if you, if you look at the most powerful use

1241
00:44:36,360 --> 00:44:37,188
of AI today.

1242
00:44:37,878 --> 00:44:40,079
It's basically AI code generation and guess

1243
00:44:40,079 --> 00:44:42,119
who who where the human is in the loop? It's, it's

1244
00:44:42,119 --> 00:44:43,739
uh, it's you guys, it's the developers

1245
00:44:44,159 --> 00:44:46,159
and so it's super powerful to be able to pause a

1246
00:44:46,159 --> 00:44:47,599
workflow and then resume it,

1247
00:44:48,010 --> 00:44:50,139
um, and finally I wanna use

1248
00:44:50,139 --> 00:44:52,280
my favorite programming languages and so look,

1249
00:44:52,360 --> 00:44:54,300
we, we heard you and now we're introducing

1250
00:44:54,708 --> 00:44:56,789
lambda durable functions or our Matt already

1251
00:44:56,789 --> 00:44:58,938
introduced it and so our lambda durable functions that you do

1252
00:44:59,599 --> 00:45:01,760
is you just simply write code. You write simple

1253
00:45:01,760 --> 00:45:04,119
sequential code. Well, all code is sequential.

1254
00:45:04,530 --> 00:45:05,619
Uh, and

1255
00:45:05,929 --> 00:45:08,409
reliability is baked in reliability

1256
00:45:08,409 --> 00:45:09,389
retries

1257
00:45:09,728 --> 00:45:11,909
your workflow semantics are just baked in.

1258
00:45:12,250 --> 00:45:14,389
Um, right now we support Node and

1259
00:45:14,389 --> 00:45:16,409
Python. You know, more languages are coming, as I

1260
00:45:16,409 --> 00:45:18,449
said, the team pushed super hard to get this out for reinvent

1261
00:45:18,449 --> 00:45:20,489
more language languages support obviously is coming,

1262
00:45:20,878 --> 00:45:23,090
uh, but Python and, and Node are super popular

1263
00:45:23,090 --> 00:45:25,128
with Lambda, and we, we covered both the most common

1264
00:45:25,128 --> 00:45:25,909
languages there.

1265
00:45:26,250 --> 00:45:28,260
Yes, you can suspend and resume long running

1266
00:45:28,260 --> 00:45:30,239
operations, and while you're suspending the operation,

1267
00:45:30,610 --> 00:45:32,110
you're not paying for lambda at all,

1268
00:45:32,688 --> 00:45:33,829
um, and finally.

1269
00:45:34,148 --> 00:45:36,389
It's all the, the, the beauty of managing

1270
00:45:36,389 --> 00:45:38,599
the elities. It's still lambda. And so,

1271
00:45:38,869 --> 00:45:41,590
yes, you know, you, some of you might have heard of durable executions

1272
00:45:41,590 --> 00:45:43,320
or, or, or workflows before.

1273
00:45:43,989 --> 00:45:46,070
What, what this is super unique is that this

1274
00:45:46,070 --> 00:45:48,050
is a compute service lambda

1275
00:45:48,389 --> 00:45:50,750
with that reliable workflow stuff

1276
00:45:50,750 --> 00:45:52,789
built right in. There's nothing else. You're simply

1277
00:45:52,789 --> 00:45:54,800
going to write a lambda function and I'm gonna show you

1278
00:45:54,949 --> 00:45:55,668
what that looks like.

1279
00:45:56,119 --> 00:45:58,269
OK, so in a durable, what durable functions

1280
00:45:58,269 --> 00:46:00,289
really how what behind the scenes durable functions do

1281
00:46:00,289 --> 00:46:02,409
is they come up with, come with a very simple SDK. If

1282
00:46:02,409 --> 00:46:04,530
you choose to, and I'll show you how to do it, if you

1283
00:46:04,530 --> 00:46:06,289
choose a durable function in the lambda console,

1284
00:46:06,628 --> 00:46:08,949
the SDK is loaded as part of the runtime for you.

1285
00:46:09,329 --> 00:46:09,849
Um,

1286
00:46:10,119 --> 00:46:11,329
they have the ability to checkpoint.

1287
00:46:12,489 --> 00:46:14,769
Uh, you decide when to checkpoint. By the way, this

1288
00:46:14,769 --> 00:46:17,168
all the system is built on top of the same underlying

1289
00:46:17,168 --> 00:46:19,168
system that powers step functions as well. For those of you who

1290
00:46:19,168 --> 00:46:20,360
are familiar with step functions,

1291
00:46:20,648 --> 00:46:22,648
a lot of these things will make, make a lot of sense

1292
00:46:22,648 --> 00:46:23,869
to you immediately,

1293
00:46:24,208 --> 00:46:24,728
um.

1294
00:46:25,510 --> 00:46:27,789
The you can checkpoint and step functions. Every

1295
00:46:27,789 --> 00:46:29,789
state is checkpointed then in this particular case

1296
00:46:29,789 --> 00:46:32,309
you're writing the code and you decide when to checkpoint

1297
00:46:32,789 --> 00:46:33,648
and then replay.

1298
00:46:33,929 --> 00:46:35,989
The idea behind replay is if you're waiting

1299
00:46:35,989 --> 00:46:37,489
or you're resuming your function

1300
00:46:37,989 --> 00:46:40,128
or um you know there's a failure

1301
00:46:40,469 --> 00:46:42,579
and then you wanna retry and replay from failure because

1302
00:46:42,579 --> 00:46:43,938
that's where reliability comes in.

1303
00:46:44,429 --> 00:46:46,510
You do not have to replay all the stuff that

1304
00:46:46,510 --> 00:46:48,510
was already checkpointed. You simply get

1305
00:46:48,510 --> 00:46:50,668
those results back so you're not ever wasting

1306
00:46:50,668 --> 00:46:52,780
compute. And so tying it

1307
00:46:52,780 --> 00:46:54,809
back to what I was saying about long running workflows, we

1308
00:46:54,809 --> 00:46:56,809
really thought long and hard about LMI as well,

1309
00:46:56,869 --> 00:46:59,050
and we said, hey, should we allow customers, I mean they're

1310
00:46:59,050 --> 00:47:01,148
already paying for the full EC2 instance, should we just allow them

1311
00:47:01,148 --> 00:47:02,969
to run lambda functions for hours.

1312
00:47:03,918 --> 00:47:06,329
But the whole point of doing that is that you're building

1313
00:47:06,329 --> 00:47:08,519
inherently unreliable software

1314
00:47:08,668 --> 00:47:10,820
if you're gonna do that. So we said, hey, can we do something better?

1315
00:47:11,030 --> 00:47:13,030
And that's how we got, got, got together with

1316
00:47:13,030 --> 00:47:15,550
the step functions teams and the teams collaborated

1317
00:47:15,550 --> 00:47:17,829
together to build a, a joint capability inside lambda.

1318
00:47:17,989 --> 00:47:20,148
So look, these are the durable, these are the things that make something

1319
00:47:20,148 --> 00:47:21,159
durable execution.

1320
00:47:21,590 --> 00:47:22,849
So getting started is simple,

1321
00:47:23,510 --> 00:47:25,708
you know, you choose a function name, but you know you're providing

1322
00:47:25,708 --> 00:47:27,708
an optional durable configuration. That's how

1323
00:47:27,708 --> 00:47:28,438
you turn it on.

1324
00:47:28,909 --> 00:47:31,309
Uh, you mean execution timeout and the retention

1325
00:47:31,309 --> 00:47:33,340
periods are have defaults, so all you're doing

1326
00:47:33,340 --> 00:47:35,389
is basically saying I wanna do, I want this function

1327
00:47:35,389 --> 00:47:37,110
to be durably config configured.

1328
00:47:37,760 --> 00:47:39,878
And look, I'm gonna actually show you what a running

1329
00:47:39,878 --> 00:47:42,000
function will look like. So I've, I've already created one of these

1330
00:47:42,000 --> 00:47:44,110
functions. So what, what they come up with is,

1331
00:47:44,239 --> 00:47:46,599
is they have a new tab on the console called durable executions.

1332
00:47:46,639 --> 00:47:48,639
And again, for those of you familiar with step functions, you'll

1333
00:47:48,639 --> 00:47:50,719
be, you're used to the observability of

1334
00:47:50,719 --> 00:47:52,260
the workflow. We've taken a lot of things.

1335
00:47:52,639 --> 00:47:54,719
So I'm gonna kick off my durable, durable function.

1336
00:47:54,829 --> 00:47:56,539
Don't worry, I'll walk you through the code in a second.

1337
00:47:57,478 --> 00:47:58,179
And you'll see

1338
00:47:58,478 --> 00:48:00,590
that there's a new execution that has started,

1339
00:48:00,599 --> 00:48:02,179
and we'll click into that in a second.

1340
00:48:02,978 --> 00:48:04,978
Uh, and you'll, you'll see that the steps are

1341
00:48:04,978 --> 00:48:07,128
described where, where the, you know, the, the

1342
00:48:07,128 --> 00:48:09,340
system and the workflow has already fetched the,

1343
00:48:09,579 --> 00:48:10,329
the,

1344
00:48:10,599 --> 00:48:11,110
the note,

1345
00:48:11,619 --> 00:48:13,699
it's starting to process it. It's starting

1346
00:48:13,699 --> 00:48:15,869
to then send it to the LLM for a summarization,

1347
00:48:16,610 --> 00:48:18,688
and you can actually kind of see the progress. I mean, in, in

1348
00:48:18,688 --> 00:48:20,699
my demo here, obviously there's no failures, but if

1349
00:48:20,699 --> 00:48:22,739
anything was being retried, you'll be able to quickly

1350
00:48:22,739 --> 00:48:24,820
pinpoint where your asynchronous task.

1351
00:48:25,199 --> 00:48:26,619
Is not behaving the right way

1352
00:48:26,878 --> 00:48:27,889
and look there you go,

1353
00:48:28,360 --> 00:48:30,398
everything is done and so these workflows can run run up

1354
00:48:30,398 --> 00:48:32,438
to 1 year obviously the most canonical

1355
00:48:32,438 --> 00:48:34,599
use cases short lived transactions which are

1356
00:48:34,599 --> 00:48:36,739
probably under under sometimes under 1 2nd,

1357
00:48:37,360 --> 00:48:38,280
sometimes a few minutes,

1358
00:48:38,599 --> 00:48:40,679
but these you, you absolutely can build

1359
00:48:40,679 --> 00:48:42,878
human in the loop systems here as well which

1360
00:48:42,878 --> 00:48:44,878
cover which can which can last a long

1361
00:48:44,878 --> 00:48:46,898
time. So let's take a look at what the actual code was. Let's

1362
00:48:46,898 --> 00:48:48,938
zoom in. So the first thing I wanted to highlight

1363
00:48:49,199 --> 00:48:51,438
again for many of the developers who are familiar with lambda.

1364
00:48:51,820 --> 00:48:53,969
You'll see that you know lambda has a context object.

1365
00:48:54,070 --> 00:48:56,469
When you create a durable function, you get a durable context

1366
00:48:56,469 --> 00:48:58,250
object, and the durable context object has

1367
00:48:58,750 --> 00:49:00,789
those things I talk to you about which is enable you

1368
00:49:00,789 --> 00:49:03,179
to do waiting for for or checkpointing,

1369
00:49:03,188 --> 00:49:05,260
which is a step, and it has structured logging

1370
00:49:05,260 --> 00:49:07,340
as well for observability to see where you

1371
00:49:07,340 --> 00:49:09,159
are while the workflow is running.

1372
00:49:10,030 --> 00:49:10,809
Um,

1373
00:49:11,329 --> 00:49:13,750
the durability part, uh, is, is

1374
00:49:13,750 --> 00:49:15,869
again baked in, so I'm gonna actually show you this is the,

1375
00:49:15,989 --> 00:49:18,110
the, the step for actually retrieving

1376
00:49:18,300 --> 00:49:18,989
the note

1377
00:49:19,469 --> 00:49:21,469
from, from Dynamo DB in this particular

1378
00:49:21,469 --> 00:49:23,550
case. So the code you're writing is, is, is

1379
00:49:23,550 --> 00:49:25,628
basically the, the step which comes from the

1380
00:49:25,628 --> 00:49:26,469
context object.

1381
00:49:27,010 --> 00:49:27,668
Um,

1382
00:49:27,969 --> 00:49:30,010
the Dynamo DB cos we go to get item

1383
00:49:30,010 --> 00:49:30,989
command right there,

1384
00:49:31,409 --> 00:49:33,610
and then you have that structured logging to actually, you know, in

1385
00:49:33,610 --> 00:49:35,610
the console or any, any of of

1386
00:49:35,610 --> 00:49:37,728
your observability tools where you're sending your logs

1387
00:49:37,728 --> 00:49:38,889
to from your lambda functions,

1388
00:49:39,208 --> 00:49:41,628
you can actually see, hey, what was actually done right

1389
00:49:42,050 --> 00:49:44,128
now one of the coolest things about step

1390
00:49:44,128 --> 00:49:46,648
functions or workflows in general is is item potency.

1391
00:49:46,918 --> 00:49:49,510
Item potency is super important when you do transactions.

1392
00:49:50,228 --> 00:49:52,438
You item potency enables you to like basically have

1393
00:49:52,438 --> 00:49:54,510
one workflow, one unique workflow of a type,

1394
00:49:54,519 --> 00:49:56,679
and not allow a second version of instance of the workflow

1395
00:49:56,679 --> 00:49:57,389
to get started.

1396
00:49:57,719 --> 00:49:59,719
So that's through the name of the durable

1397
00:49:59,719 --> 00:50:01,019
context when you start the durable,

1398
00:50:01,510 --> 00:50:03,340
durable function, and you give it a name,

1399
00:50:03,878 --> 00:50:06,000
uh, or, or, or an ID when it gets

1400
00:50:06,000 --> 00:50:08,030
started, you're able to kind of

1401
00:50:08,030 --> 00:50:10,119
maintain that consistency. So no two objects

1402
00:50:10,119 --> 00:50:11,289
are working on the same thing.

1403
00:50:11,699 --> 00:50:13,648
Um, so super powerful

1404
00:50:13,989 --> 00:50:16,030
use case for, for a ton of, uh,

1405
00:50:16,228 --> 00:50:17,449
uh, a ton of applications.

1406
00:50:17,949 --> 00:50:20,110
And finally I wanted to highlight weight. Weighting is as simple

1407
00:50:20,110 --> 00:50:21,389
as just calling context of weight.

1408
00:50:22,539 --> 00:50:24,809
And while you're waiting we shut down the execution

1409
00:50:24,809 --> 00:50:26,398
environment so you're no longer paying for it

1410
00:50:26,938 --> 00:50:29,059
and once whatever you're waiting for either resumes

1411
00:50:29,059 --> 00:50:31,179
I'm I'm, I use a very simple code which which is

1412
00:50:31,179 --> 00:50:32,119
basically a wait

1413
00:50:32,378 --> 00:50:34,458
you can actually do call back you can do a

1414
00:50:34,458 --> 00:50:36,500
callback with condition where where you know

1415
00:50:36,500 --> 00:50:37,478
you are able to

1416
00:50:37,860 --> 00:50:40,418
wait for some condition to be true and then the execution

1417
00:50:40,418 --> 00:50:41,398
environment wakes up

1418
00:50:41,780 --> 00:50:43,918
all of these things basically allow you to save time

1419
00:50:44,300 --> 00:50:46,300
while while you're waiting and you're

1420
00:50:46,300 --> 00:50:48,579
not paying for any computer and you're not paying for any resources

1421
00:50:48,579 --> 00:50:49,139
at that time.

1422
00:50:49,869 --> 00:50:52,070
Um, and then the workflow starts

1423
00:50:52,070 --> 00:50:54,188
from exactly that, that same step

1424
00:50:54,188 --> 00:50:55,409
after the weight is complete

1425
00:50:55,909 --> 00:50:57,938
and look, in the previous example there was a

1426
00:50:57,938 --> 00:50:59,949
bunch of steps I, I gave you. I, I

1427
00:50:59,949 --> 00:51:01,949
kind of quickly walked through the code what would it take

1428
00:51:01,949 --> 00:51:03,989
to actually build such a workflow, but for

1429
00:51:03,989 --> 00:51:06,030
the developers here and the engineering managers who

1430
00:51:06,030 --> 00:51:07,699
review the architecture for the developers,

1431
00:51:07,989 --> 00:51:10,110
you can imagine with what, what would it take to

1432
00:51:10,110 --> 00:51:12,228
in a traditional architecture to build something like

1433
00:51:12,228 --> 00:51:14,389
this. You're using cues.

1434
00:51:14,840 --> 00:51:15,579
You're using,

1435
00:51:16,159 --> 00:51:18,478
you know, compute all over the place at different

1436
00:51:18,478 --> 00:51:20,478
steps between the queues because now you're not bundling

1437
00:51:20,478 --> 00:51:21,228
things properly.

1438
00:51:21,519 --> 00:51:23,800
Your deployments are more complex, complex. Debugging

1439
00:51:23,800 --> 00:51:26,300
is more complex. If anything goes wrong, replayability,

1440
00:51:26,840 --> 00:51:28,918
rehydration, all the some of the, some of the basic

1441
00:51:28,918 --> 00:51:31,539
challenges of a distributed event driven architecture

1442
00:51:31,739 --> 00:51:33,869
come in. But with a simple orchestration, a

1443
00:51:33,869 --> 00:51:35,820
simple deployment, a simple STLC,

1444
00:51:36,119 --> 00:51:38,320
you're able to basically build really, really

1445
00:51:38,320 --> 00:51:40,478
reliable workflows. And again, as I said, there

1446
00:51:40,478 --> 00:51:42,599
is no real comparison to this, this

1447
00:51:42,599 --> 00:51:45,079
technology. Uh, out there there's lots of workflow technologies

1448
00:51:45,079 --> 00:51:47,449
out there. This is actually a compute

1449
00:51:47,449 --> 00:51:49,750
technology with work workflows built into it. And

1450
00:51:49,750 --> 00:51:51,918
so look, we've got long running work of, uh, lambda

1451
00:51:51,918 --> 00:51:53,458
functions now that can run up to a year.

1452
00:51:54,429 --> 00:51:55,219
Um,

1453
00:51:55,590 --> 00:51:58,019
so anyway, I covered these points already, um,

1454
00:51:58,148 --> 00:51:59,409
and so we can get going,

1455
00:52:00,030 --> 00:52:02,269
all right, so we, we talked about our

1456
00:52:02,269 --> 00:52:04,309
MCP server and what we're doing with Gen AI

1457
00:52:04,309 --> 00:52:06,510
development. There was a whole bunch of things we've done like, uh,

1458
00:52:06,789 --> 00:52:09,059
how many of you, by the way, have installed our,

1459
00:52:09,070 --> 00:52:11,070
um, our actual dev tools

1460
00:52:11,070 --> 00:52:11,849
for VS code.

1461
00:52:12,860 --> 00:52:13,610
Few people

1462
00:52:14,449 --> 00:52:15,000
Awesome,

1463
00:52:15,340 --> 00:52:17,539
um, look, I would highly recommend

1464
00:52:17,539 --> 00:52:19,780
for the developers here to go try to check out our developer

1465
00:52:19,780 --> 00:52:21,780
tools or from the AWS tool kit. I'm assuming most

1466
00:52:21,780 --> 00:52:22,878
of you use VS code.

1467
00:52:23,530 --> 00:52:25,679
Um, one of the things you might have missed, for example,

1468
00:52:25,739 --> 00:52:28,110
is you're not able to remotely debug, uh,

1469
00:52:28,119 --> 00:52:30,179
lambda function. You can actually put a breakpoint into our

1470
00:52:30,179 --> 00:52:32,378
running lambda function through our tools as well. So we really,

1471
00:52:32,500 --> 00:52:34,360
really are focusing on developer experience.

1472
00:52:34,849 --> 00:52:35,889
But, um,

1473
00:52:36,260 --> 00:52:38,418
look, Jenna already talked about MCP and how that

1474
00:52:38,418 --> 00:52:40,750
makes developer experience super easy, especially on ISC

1475
00:52:40,750 --> 00:52:42,708
and our best practicetresses. We talked about LMI,

1476
00:52:43,340 --> 00:52:45,610
which lets you run long lived workflow, uh,

1477
00:52:45,619 --> 00:52:47,438
sorry, steady state,

1478
00:52:47,699 --> 00:52:50,519
large workloads at incredible, uh,

1479
00:52:50,579 --> 00:52:52,579
discounts and, uh, and choice

1480
00:52:52,579 --> 00:52:55,438
of EC2 instances, and I talked about, uh,

1481
00:52:55,458 --> 00:52:57,458
durable functions for you folks as well where you can now

1482
00:52:57,458 --> 00:52:59,809
run really reliable because reliability

1483
00:52:59,809 --> 00:53:02,179
and durability is super key for long run running workloads

1484
00:53:02,179 --> 00:53:03,119
because it's not a question of.

1485
00:53:03,889 --> 00:53:05,938
If you'll have an infrastructure issue, it's when you'll have

1486
00:53:05,938 --> 00:53:06,978
an infrastructure issue.

1487
00:53:07,300 --> 00:53:09,559
So, um, but we're not done.

1488
00:53:10,139 --> 00:53:12,148
I do. I wanna talk to you about one more thing we launched

1489
00:53:12,148 --> 00:53:13,519
a week or so before we invent

1490
00:53:13,860 --> 00:53:16,059
this is really around, uh, especially security

1491
00:53:16,059 --> 00:53:17,800
sensitive SAS applications.

1492
00:53:18,659 --> 00:53:21,000
So here's a, a scenario.

1493
00:53:21,059 --> 00:53:23,059
You have 3 customers or let's say 3

1494
00:53:23,059 --> 00:53:24,280
tenants of your SAS,

1495
00:53:24,860 --> 00:53:27,019
um, and you're using lambda. Lambda has,

1496
00:53:27,099 --> 00:53:29,340
uh, you know, maybe you're using a global variable in the lambda

1497
00:53:29,340 --> 00:53:31,070
function. Maybe,

1498
00:53:31,889 --> 00:53:33,929
maybe you have some, some, something in the temp file

1499
00:53:33,929 --> 00:53:35,188
you're using our temp storage.

1500
00:53:35,958 --> 00:53:36,699
Um,

1501
00:53:37,159 --> 00:53:39,510
maybe you wanna restrict and you wanna say, hey,

1502
00:53:39,869 --> 00:53:42,239
uh, an execution or invocation to this lambda

1503
00:53:42,239 --> 00:53:44,280
function should only talk to the Dynamo

1504
00:53:44,280 --> 00:53:45,179
DB table

1505
00:53:45,438 --> 00:53:49,840
and only fetch data from the Dynamo D table DB DB table row

1506
00:53:50,159 --> 00:53:52,478
for this customer who's calling or invoking this function.

1507
00:53:53,228 --> 00:53:55,668
Um, so in this case I have a blue tenant

1508
00:53:55,780 --> 00:53:57,869
and, you know, they created a lambda function, we

1509
00:53:57,869 --> 00:53:59,909
created an execution environment for them and maybe

1510
00:53:59,909 --> 00:54:02,059
there's something left over, maybe there's some global variables

1511
00:54:02,059 --> 00:54:02,728
left over,

1512
00:54:03,309 --> 00:54:05,280
and then the yellow tenant calls.

1513
00:54:06,039 --> 00:54:08,039
But the problem with the yellow tenant is they, they might have

1514
00:54:08,039 --> 00:54:10,159
some side effects that they leave in the lambda function as

1515
00:54:10,159 --> 00:54:12,409
well, um, or,

1516
00:54:12,530 --> 00:54:14,878
uh, you, you, uh, you're not, you're not not

1517
00:54:14,878 --> 00:54:16,239
able to isolate those iso uh,

1518
00:54:16,519 --> 00:54:18,719
those side effects, uh, if you've written code this way.

1519
00:54:18,878 --> 00:54:20,438
And finally, of course, you have a green tenant,

1520
00:54:20,800 --> 00:54:21,340
and again

1521
00:54:21,760 --> 00:54:23,840
the request is being, being sent to maybe the

1522
00:54:23,840 --> 00:54:26,099
same execution environment, and there's some side effects.

1523
00:54:26,478 --> 00:54:28,559
And look, this is nothing lambda specific here, right?

1524
00:54:28,599 --> 00:54:30,760
This is true for any computer you you

1525
00:54:30,760 --> 00:54:32,918
run. You can do you see two instances

1526
00:54:32,918 --> 00:54:33,659
containers.

1527
00:54:34,260 --> 00:54:36,260
Um, one of the hardest challenges is

1528
00:54:36,260 --> 00:54:38,579
how do I isolate my customers from each other

1529
00:54:38,579 --> 00:54:40,619
without actually creating individual infrastructure

1530
00:54:40,619 --> 00:54:41,429
for each customer.

1531
00:54:41,820 --> 00:54:43,949
So something pretty expensive to do, you can do it.

1532
00:54:44,179 --> 00:54:46,179
Uh, the way you do it on lambda traditionally before this

1533
00:54:46,179 --> 00:54:48,179
feature is you would create a lambda function per customer.

1534
00:54:48,539 --> 00:54:49,800
I know it sounds ridiculous, but

1535
00:54:50,458 --> 00:54:52,079
there's customers and use cases with that

1536
00:54:52,500 --> 00:54:53,780
where you have to do that. Well,

1537
00:54:54,099 --> 00:54:54,760
now you don't,

1538
00:54:55,418 --> 00:54:56,208
uh, so a coup,

1539
00:54:56,500 --> 00:54:58,619
a week or so ago we launched tenant isolation, and

1540
00:54:58,619 --> 00:55:00,699
what that does is that in the invocation, so it's

1541
00:55:00,699 --> 00:55:02,360
still the same lambda function you're writing,

1542
00:55:02,699 --> 00:55:03,820
you pass a tenant ID.

1543
00:55:04,208 --> 00:55:06,239
And then what we do is we create

1544
00:55:06,849 --> 00:55:08,898
individual execution environments which are not

1545
00:55:08,898 --> 00:55:10,929
shared by any of the tenants for

1546
00:55:10,929 --> 00:55:12,938
you. And the idea behind this is

1547
00:55:12,938 --> 00:55:14,978
that if you have sensitive software, if you have AI

1548
00:55:14,978 --> 00:55:17,139
generated software, you have, you're,

1549
00:55:17,260 --> 00:55:19,340
you're in an environment where you really

1550
00:55:19,340 --> 00:55:21,469
wanna even isolate your own customers from your

1551
00:55:21,619 --> 00:55:22,418
infrastructure

1552
00:55:22,739 --> 00:55:24,860
now you can do that and it's super, super

1553
00:55:24,860 --> 00:55:27,099
simple, no extra infrastructure to manage, no, not

1554
00:55:27,099 --> 00:55:28,679
even extra lambda functions to manage.

1555
00:55:29,510 --> 00:55:31,559
OK, so we're almost through,

1556
00:55:31,659 --> 00:55:33,750
and I know I, uh, we have a little bit of time, so

1557
00:55:33,750 --> 00:55:35,789
I'd love to, uh, invite Jonah up as well and take

1558
00:55:35,789 --> 00:55:37,019
some of your questions as well,

1559
00:55:37,349 --> 00:55:39,349
but I wanted to kind of share with you kind of what is our

1560
00:55:39,349 --> 00:55:41,500
strategy because we're not done yet. I, you know, I,

1561
00:55:41,590 --> 00:55:43,619
I'll, I always like leaking a few things,

1562
00:55:43,989 --> 00:55:46,070
and you know we've got some big things done by Reinvent.

1563
00:55:46,188 --> 00:55:48,590
I suspect in the next 6 months we have some other

1564
00:55:48,590 --> 00:55:50,719
big things we're working on that didn't quite make it,

1565
00:55:51,070 --> 00:55:53,309
so keep your ears and eyes peeled for more

1566
00:55:53,309 --> 00:55:55,309
information, I think, but all those things will be in the

1567
00:55:55,309 --> 00:55:56,188
same in this team.

1568
00:55:56,898 --> 00:55:59,019
Lambda has always been about developers. Lambda

1569
00:55:59,019 --> 00:56:01,260
has always been about, about speed, and we

1570
00:56:01,260 --> 00:56:02,719
really embrace that idea.

1571
00:56:03,179 --> 00:56:05,340
What we're trying to do is we're trying to get the objections

1572
00:56:05,340 --> 00:56:05,860
out of the way.

1573
00:56:06,860 --> 00:56:08,860
Like objections from platform teams that it can get

1574
00:56:08,860 --> 00:56:11,250
too expensive, objections from our ISC

1575
00:56:11,250 --> 00:56:12,438
is really hard to get right.

1576
00:56:12,878 --> 00:56:14,889
Um, are the fundamentals like, hey, can I

1577
00:56:14,889 --> 00:56:17,010
really do cost control with lambda really, really well?

1578
00:56:17,208 --> 00:56:19,208
All of those things are gonna be built in and

1579
00:56:19,208 --> 00:56:21,369
we're really, really laser focusing

1580
00:56:21,369 --> 00:56:23,438
on, on developers and how developers

1581
00:56:23,438 --> 00:56:25,530
can move fast with services. So like with this we

1582
00:56:25,530 --> 00:56:27,530
were, we over the last 18 months I talked about remote

1583
00:56:27,530 --> 00:56:29,800
debugging and, and some of the stuff we didn't even show you.

1584
00:56:30,289 --> 00:56:32,550
We are heavily involved in the dev tool space

1585
00:56:32,809 --> 00:56:34,860
to make sure that serverless development, you don't

1586
00:56:34,860 --> 00:56:37,000
have to be a serverless developer, you just have to be a

1587
00:56:37,000 --> 00:56:37,550
developer

1588
00:56:37,809 --> 00:56:39,289
to get the the benefits out of it.

1589
00:56:40,090 --> 00:56:42,099
Alright, so just to recap

1590
00:56:42,099 --> 00:56:42,789
the whole thing again,

1591
00:56:43,449 --> 00:56:45,449
we, we have a mirror road map that you can see

1592
00:56:45,449 --> 00:56:47,648
that's focusing on developer experience and then the fundamentals

1593
00:56:47,648 --> 00:56:48,228
are there.

1594
00:56:48,769 --> 00:56:51,110
What's coming up next is observability

1595
00:56:51,530 --> 00:56:53,409
hotel support. We've heard from customers.

1596
00:56:53,688 --> 00:56:55,769
We wanted to have like a native hotel support. We've

1597
00:56:55,769 --> 00:56:57,849
already done a bunch of launches over the last few years around

1598
00:56:57,849 --> 00:57:00,128
structured logging and getting lambda

1599
00:57:00,128 --> 00:57:02,039
to be ready for a hotel, but we wanna have full hotel support for customers.

1600
00:57:04,148 --> 00:57:06,188
Um, that's a key part. It's a key trade-off that

1601
00:57:06,188 --> 00:57:08,269
I mentioned in an evolutionary architecture, so

1602
00:57:08,269 --> 00:57:10,250
we wanna continue to make our observability better,

1603
00:57:10,949 --> 00:57:12,949
um, more runtime, uh, again you

1604
00:57:12,949 --> 00:57:15,188
might have missed this, but we just launched, uh, Rust

1605
00:57:15,188 --> 00:57:17,188
support in lambda as well now, uh, that was,

1606
00:57:17,269 --> 00:57:19,820
uh, I think a week or so ago as well, but more languages,

1607
00:57:20,188 --> 00:57:21,809
more frameworks, more runtime are coming.

1608
00:57:22,668 --> 00:57:23,329
Um,

1609
00:57:23,869 --> 00:57:26,139
look, with LMI, with durable functions,

1610
00:57:26,309 --> 00:57:28,349
we are able to now, uh, open up a

1611
00:57:28,349 --> 00:57:30,469
whole new class of applications that you just couldn't use

1612
00:57:30,469 --> 00:57:32,409
on, on lambda, but we're not again done.

1613
00:57:32,869 --> 00:57:34,909
There's so much more we wanna do because

1614
00:57:34,909 --> 00:57:37,128
we, we believe customers shouldn't have to choose

1615
00:57:37,590 --> 00:57:39,659
to, to manage a lot, a lot of those ilities that

1616
00:57:39,659 --> 00:57:41,708
I was talking about earlier simply because

1617
00:57:41,708 --> 00:57:43,369
they have a business need that doesn't fit,

1618
00:57:43,909 --> 00:57:46,159
um. And look, integrations

1619
00:57:46,159 --> 00:57:48,398
are bread and butter. The way lambda delivers that

1620
00:57:48,398 --> 00:57:50,599
speed is that so many things from

1621
00:57:50,599 --> 00:57:52,599
EventBridge to SNS to API gateway

1622
00:57:52,599 --> 00:57:55,039
to ALBs to SQS to Kafka,

1623
00:57:55,519 --> 00:57:57,599
they're all just built in. You're not trying to

1624
00:57:57,599 --> 00:57:59,679
figure out how do I make this technology work with my

1625
00:57:59,679 --> 00:58:01,760
code. They're all just built in and it's our

1626
00:58:01,760 --> 00:58:03,800
responsibility to make in. We're gonna continue to

1627
00:58:03,800 --> 00:58:05,840
do more both on the dev tool site and

1628
00:58:05,840 --> 00:58:08,070
an integration site so that your favorite, like,

1629
00:58:08,369 --> 00:58:09,438
you know, uh,

1630
00:58:09,760 --> 00:58:11,878
CICD tools, your favorite observability

1631
00:58:11,878 --> 00:58:13,559
tools just work with lambda.

1632
00:58:14,000 --> 00:58:16,260
And look, you might also not know this, but we just recently,

1633
00:58:16,478 --> 00:58:18,599
again just right before we invent, so Janek and the product team

1634
00:58:18,599 --> 00:58:19,219
were quite busy.

1635
00:58:19,840 --> 00:58:22,030
We, we launched our roadmap as well

1636
00:58:22,030 --> 00:58:24,159
publicly. So if you were to just to

1637
00:58:24,159 --> 00:58:26,280
take a look at the QR code, that would take you to the,

1638
00:58:26,360 --> 00:58:28,599
to the road map as well. Give us feedback. We

1639
00:58:28,599 --> 00:58:29,699
love to hear from you.

1640
00:58:30,119 --> 00:58:32,239
Uh, I'm gonna invite Jenna over. Janek, we have a

1641
00:58:32,250 --> 00:58:34,269
a few more minutes. Um, thank you

1642
00:58:34,269 --> 00:58:36,750
so much, folks for sticking around and coming out on Thursday.

1643
00:58:37,199 --> 00:58:39,239
If there's some questions, we'd love to take them. Thank you.

1644
00:58:41,699 --> 00:58:41,719
Thank you.

