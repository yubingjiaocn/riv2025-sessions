# AWS re:Invent 2025 会议总结：Octus Credit AI 迁移至 Amazon Bedrock

## 会议概述

本次会议主要介绍了金融科技公司 Octus 如何成功将其旗舰产品 Credit AI 从多云架构迁移到 AWS Amazon Bedrock 平台的完整历程。演讲者包括 AWS 高级解决方案架构师 Web Sabaral 和 Lavya Bandari，以及 Octus 首席技术官 Vishal Sakennena。

Octus 是信贷市场领域领先的数据、新闻、信息、分析和工作流产品提供商，被称为"信贷领域的彭博社"。其 Credit AI 产品是业内首个生成式 AI 应用，能够让用户通过自然语言查询数百万份金融文档、交易文档和情报数据。该产品最初部署在 Azure（使用 OpenAI 模型）和 AWS 的混合架构上，但多云运营带来了复杂性、高成本和可扩展性挑战。

通过迁移到 Amazon Bedrock 的完全托管 RAG（检索增强生成）架构，Octus 实现了显著的业务成果：基础设施成本降低 78%，每次查询成本降低 87%，文档同步时间从小时级缩短到分钟级，嵌入处理吞吐量提升 10 倍。更重要的是，简化的架构使团队能够更快地开发新功能，包括私有文档支持等关键能力，同时保持 SOC 2 合规性和零停机时间的严格要求。

## 详细时间线与关键要点

### 开场与背景介绍 (0:00 - 3:30)
- **0:00** - 会议开始，现场调查显示大多数参会者正在生产环境运行生成式 AI 工作负载，其中约半数的基础设施成本超出预算
- **1:15** - 介绍演讲团队：AWS 高级解决方案架构师 Web Sabaral、Octus CTO Vishal Sakennena 和 AWS 高级解决方案架构师 Lavya Bandari
- **1:45** - 会议议程：RAG 基础概念、Credit AI 迁移案例研究、经验教训和 AWS 加速迁移项目

### RAG 技术基础 (3:30 - 6:45)
- **3:30** - RAG（检索增强生成）概念讲解：使 LLM 能够查询专有数据的技术
- **4:15** - RAG 三个核心阶段：检索相关文档/片段、用上下文增强提示、模型生成响应
- **4:45** - 常见企业用例：改进内容交付、构建上下文聊天机器人、个性化搜索、大规模文档实时摘要
- **5:30** - Amazon Bedrock 知识库介绍：端到端托管 RAG 能力，包含文档摄取、检索、提示增强、响应生成、会话管理和自动引用
- **6:00** - RAG 工作流程详解：数据摄取、分块、向量嵌入、向量存储、查询嵌入、上下文检索、提示增强、LLM 生成响应

### 生产化挑战 (6:45 - 9:00)
- **6:45** - 生产化难题：90% 的生成式 AI 概念验证无法进入生产环境
- **7:15** - 规模化后的延迟问题导致糟糕的用户体验
- **7:30** - 74% 的生成式 AI 项目遇到性能或可靠性问题
- **7:45** - 52% 的公司报告工具碎片化和基于设备的评估问题，缺乏端到端可观测性
- **8:15** - 迁移生产环境工作负载的三大核心关注点：安全合规性、可扩展架构、投资回报率（ROI）

### Octus 公司与 Credit AI 产品介绍 (9:00 - 12:30)
- **9:00** - Vishal Sakennena 登台介绍 Octus：信贷市场数据、新闻、信息、分析和工作流产品的领先提供商
- **9:30** - Octus 成立 10 多年，最初专注于破产（困境资产），现已扩展到不良贷款、正常贷款、高收益贷款和私募信贷等整个信贷市场生命周期
- **10:00** - 客户群体：投资银行、投资管理公司、律师事务所、咨询公司等金融服务机构
- **10:30** - 播放 Credit AI Vault 产品演示视频（2 分钟）
- **12:30** - Credit AI 于 2023 年作为信贷市场首个生成式 AI 产品推出

### 初始架构挑战 (12:30 - 15:45)
- **12:30** - 最初选择 OpenAI 模型（当时 AWS 上不可用），导致部分产品托管在 Azure，其他产品在 AWS
- **13:15** - 多云架构带来的挑战：可扩展性问题、自行管理 RAG 架构所有组件（嵌入、分块、知识库、向量数据库、GPU 实例）
- **14:00** - 采用组件驱动架构以适应 AI 技术快速演进，但管理复杂性高
- **14:30** - 数据和服务在 AWS 和 Azure 之间频繁传输，导致运营复杂性
- **15:00** - 迁移目标：简化架构、将专业知识推给云提供商、统一云架构、专注于为客户构建高价值功能

### 不可妥协的需求 (15:45 - 18:00)
- **15:45** - 可扩展性：提高开发速度、减少管理复杂性时间、改善客户响应时间
- **16:15** - 成本最小化：简化多云运营以降低成本和优化基础设施
- **16:30** - 响应延迟：确保出色的用户体验，即使使用最佳 LLM 模型
- **16:45** - SOC 2 合规性：满足 SLA 义务，实现零停机时间
- **17:15** - 快速迭代：AI 领域和客户需求不断演进，需要更快的功能开发和迭代能力
- **17:45** - 多云简化：减少运营维护开销，提高可靠性

### 选择 Amazon Bedrock 的原因 (18:00 - 20:30)
- **18:00** - 简化 RAG 架构管理，将更多时间用于功能开发
- **18:30** - 访问多种最佳 LLM 模型（Anthropic Claude、Meta、Amazon Titan 等），支持模型灵活切换
- **19:00** - 降低成本并实现规模经济：利用 AWS 上已有的服务和数据支持其他产品
- **19:30** - 解决自托管 GPU 实例的扩展问题，支持实时问答的嵌入扩展
- **19:45** - 利用 AWS 已有的服务水平保障（SLA）经验
- **20:00** - AWS 整合带来的运营效率提升

### POC 验证 (20:30 - 22:00)
- **20:30** - 快速风险识别策略：尽早解决未知问题
- **20:45** - 与 AWS 解决方案专家合作进行 POC，仅用两周时间完成端到端工作原型
- **21:15** - POC 结果非常有前景，但尚未涉及基础设施自动化
- **21:30** - 强调 POC 与生产环境的巨大差异

### POC 与生产环境的差异 (22:00 - 24:30)
- **22:00** - 规模：POC 中数百份文档 vs 生产环境中数百万份文档
- **22:30** - 延迟：POC 中可接受任何延迟并计划后续优化 vs 生产环境需要亚秒级延迟
- **23:00** - 并发用户：POC 中最多 10 个用户 vs 生产环境中数千个并发用户
- **23:15** - 基础设施质量：POC 中不太关注 vs 生产环境需要高可用性、灾难恢复等 SOC 2 合规要求
- **23:45** - 准确性：POC 中"足够好"vs 生产环境需要 99%+ 准确率（金融服务客户要求）
- **24:00** - 合规性：生产环境必须考虑 SOC 2、法律合规、治理和安全问题
- **24:15** - 运营：POC 中手动操作 vs 生产环境需要全自动 CI/CD 管道、监控和可靠性工具

### 最终架构 - 数据摄取工作流 (24:30 - 27:30)
- **24:30** - 事件驱动架构：新文档到达时触发 Lambda 函数
- **25:00** - Lambda 执行初始验证：文档类型、文档大小，提取相关元数据
- **25:30** - 调用 Amazon Textract 提取文本和结构信息，同时保留文档布局和内容元素之间的关系
- **26:00** - 提取的内容存储在 Amazon S3 中，与源文档分开存储在不同前缀中
- **26:30** - 保持提取内容与源文档之间的数据血缘关系，包括时间戳和元数据
- **27:00** - Amazon Bedrock 对内容进行分块，调用 Cohere 嵌入模型获取向量，存储在 Amazon OpenSearch Service 中以实现高效检索

### 最终架构 - 查询与问答工作流 (27:30 - 29:30)
- **27:30** - Web 应用托管在 AWS Fargate 上，根据流量自动扩展，减少维护开销
- **28:00** - 在应用层进行用户初始验证
- **28:15** - 使用 Amazon MSK（托管 Kafka）作为流服务处理服务间通信，保持高吞吐量和效率
- **28:45** - 查询周期编排层：调用不同服务，与 RAG 管道直接集成
- **29:00** - 用户查询流程：调用 Cohere 嵌入模型 → 从 OpenSearch 检索相关片段 → Amazon Bedrock Guardrails 质量和安全控制 → 模型生成响应 → 返回用户

### 关键设计决策 - 分块策略 (29:30 - 32:30)
- **29:30** - 分块策略是关键设计决策之一：如何将文档划分为逻辑或较小的片段
- **30:00** - 固定大小分块：适用于小文档，但对长复杂文档效果不佳，可能在句子、段落或表格中间分块
- **30:45** - 层次分块：两层结构，子块用于精确匹配，父块提供上下文，效果很好但受嵌入模型 512 token 限制
- **31:30** - 语义分块（最终选择）：使用 LLM 识别文档中的自然断点，分析文档理解语义，在逻辑边界（章节结束、主题切换）处划分
- **32:00** - 语义分块有成本但效果最好，Octus 选择承担成本
- **32:15** - 关键教训：没有一刀切的方案，需根据文档类型选择分块策略

### 关键设计决策 - 嵌入模型 (32:30 - 35:00)
- **32:30** - 之前在专用 GPU 上自行管理嵌入模型，扩展困难且成本高
- **33:00** - 选择 Cohere 嵌入模型的原因：检索结果优异，能理解复杂金融文档和实体关系
- **33:30** - 多语言能力：支持美洲、欧洲、亚洲客户群
- **34:00** - 托管服务优势：嵌入模型实例不再是瓶颈，无需担心模型升级或 CUDA 错误
- **34:30** - 性能提升：吞吐量提高 10 倍，从瓶颈变为非问题
- **34:45** - 支持多租户架构扩展

### 关键设计决策 - 多租户隔离 (35:00 - 37:30)
- **35:00** - Octus 允许客户引入私有数据，需要租户隔离
- **35:30** - 设计决策：客户 A 和客户 B 的数据存储在独立的知识库中，实现物理隔离边界
- **36:00** - 不依赖文档上的客户 ID 进行隔离
- **36:15** - 物理边界简化安全合规性，满足客户和审计师要求
- **36:45** - 之前由于自托管嵌入模型无法为每个客户扩展专用 GPU 实例
- **37:00** - Octus 工程团队的创新支持：实时访问管理、细粒度文档访问控制、全局标识符服务（处理公司名称的不同表示形式）

### 关键设计决策 - Bedrock Guardrails (37:30 - 39:30)
- **37:30** - Amazon Bedrock Guardrails 提供内容安全和性能优化
- **38:00** - 基于规则的内置内容过滤：过滤主题、不当内容、特定查询
- **38:30** - 金融合规：防止 PII 泄露和不当内容
- **38:45** - 内置幻觉控制和相关性检查
- **39:00** - 之前使用第三方应用 TruLens 进行检查，增加延迟和成本
- **39:15** - Guardrails 集成在管道内，无需外部调用，降低 token 使用，提升响应性能

### RAG 管道优化迭代 (39:30 - 42:30)
- **39:30** - 搜索类型：从语义搜索升级到混合搜索（语义 + 文本搜索），合并结果
- **40:15** - 元数据过滤：利用丰富的文档元数据提高结果质量，系统自动识别相关元数据
- **41:00** - 重排序：之前自托管重排序模型，现使用 Bedrock 知识库的开箱即用集成，根据提示相关性对内容评分和排序
- **41:45** - 查询重构：将复杂查询分解为多个简单查询，并行运行，汇总结果，避免内容稀释
- **42:15** - 强调数据策略的重要性

### 数据策略 (42:30 - 45:30)
- **42:30** - Vishal 强调：AI 的好坏取决于其背后的数据，统一数据策略对统一 AI 体验至关重要
- **43:00** - 数据架构投资不仅针对生成式 AI，而是全面投资
- **43:30** - 数据生成和收集：第三方数据、内部准备的"原始报告"数据
- **44:00** - 数据标准化：统一多个数据集，建立标识符映射（CUSIP、ISIN 等）
- **44:30** - 主数据管理（MDM）：集中数据收集，通过参考数据服务统一标识符查找
- **45:00** - 文档摄取统一化和数据标准化

### 数据管道与 API 层 (45:30 - 47:00)
- **45:30** - 数据管道：主要使用 AWS Glue，根据复杂性使用其他技术
- **46:00** - ETL 流程：提取、转换、加载，将原始报告数据结构简化为适合应用的标准化数据结构
- **46:30** - API 层：所有应用通过一致的方式消费数据，实现规模经济、一致性、可靠性和更好的监控
- **46:45** - Credit AI 作为消费统一数据服务的应用之一

### 迁移实施 (47:00 - 49:30)
- **47:00** - 基础设施即代码（IaC）：全面使用 Terraform 实现基础设施自动化和扩展
- **47:45** - 统一集成的 CI/CD 管道：在 POC 阶段就确保到位
- **48:15** - 并行运行：Credit AI 在生产环境运行的同时，在新架构上并行运行，进行 A/B 测试，确保最小中断的切换
- **48:45** - 安全与合规：使用 Wiz 等云安全态势管理工具持续监控云工作负载
- **49:15** - 监控与告警：使用 Datadog 进行监控，PagerDuty 进行告警

### 迁移成果 (49:30 - 51:30)
- **49:30** - 成本降低 78%：不再管理自有 GPU，通过整合数据服务实现规模经济
- **50:00** - 每次查询成本降低 87%
- **50:15** - 更好的用户体验：私有文档功能得益于简化的架构和数据架构投资
- **50:45** - 功能交付速度更快，客户满意度提高
- **51:00** - 文档同步时间：从小时级缩短到分钟级，得益于 Amazon Bedrock 的嵌入扩展能力
- **51:15** - 开发速度提升：简化架构，不再自行管理所有步骤

### 额外成果 (51:30 - 52:30)
- **51:30** - 统一云架构：从 AWS + Azure 迁移到纯 AWS，减少维护开销
- **52:00** - 专注于单一基础设施的监控和告警，而非两个平台
- **52:15** - 强调：不反对多云，但如果能简化就应该简化；如果有业务原因需要多云，也完全可行

### 经验教训总结 (52:30 - 55:00)
- **52:30** - 成果总览回顾：成本降低、用户体验改善、开发速度提升、运营简化
- **53:00** - 关键经验教训开始
- **53:15** - 第一课：尽早进行 POC 以降低风险，快速验证假设
- **53:45** - 第二课：投资数据策略，AI 的质量取决于数据质量
- **54:15** - 第三课：选择合适的分块策略，没有一刀切的解决方案
- **54:30** - 第四课：利用托管服务减少运营开销，专注于业务价值

### AWS 支持项目介绍 (55:00 - 57:00)
- **55:00** - Lavya Bandari 介绍 AWS 加速迁移项目
- **55:30** - AWS 提供的支持：解决方案架构师、技术客户经理、专业服务团队
- **56:00** - 迁移加速计划（MAP）：提供资金支持和最佳实践指导
- **56:30** - AWS 合作伙伴网络：可提供额外的迁移支持和专业知识
- **56:45** - 强调 AWS 致力于帮助客户成功迁移和优化生成式 AI 工作负载

### 问答环节与总结 (57:00 - 结束)
- **57:00** - 开放问答环节
- **57:30** - 观众提问：关于多租户架构的安全性考虑
- **58:00** - Vishal 回答：物理隔离是关键，每个租户独立的知识库提供最强的安全保障
- **58:30** - 观众提问：迁移过程中最大的挑战是什么
- **59:00** - Vishal 回答：确保零停机时间和维持 99%+ 的准确率是最大挑战，通过并行运行和充分测试解决
- **59:30** - 会议总结：强调简化架构、利用托管服务、投资数据策略的重要性
- **60:00** - 感谢观众参与，会议结束