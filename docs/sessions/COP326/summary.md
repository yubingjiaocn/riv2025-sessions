# AWS re:Invent 2025 COP326 会议总结：提升应用程序和生成式AI可观测性

## 会议概述

本次会议（COP 326）由AWS云运维全球技术负责人Matzah和CloudWatch产品经理Peter Gang共同主讲，重点探讨了如何在现代复杂应用和AI驱动系统中实现全面的可观测性。

会议通过一个名为John的开发者角色，展示了从传统应用监控到生成式AI可观测性的完整演进过程。演讲者强调，在当今由AI驱动的复杂应用环境中，缺乏可见性就像在能见度极低的高速公路上驾驶一样危险。正如AWS CTO Werner Vogels所说："没有可见性，你只是在猜测。"会议承诺为参会者提供可操作的洞察，帮助他们在单一控制台中提升应用程序和生成式AI的可观测性。

第一部分由Matzah介绍了Amazon CloudWatch的应用程序监控能力，特别是Application Signals这一APM解决方案，它能够自动发现应用、提供预构建仪表板、快速定位根本原因，并通过SLO（服务级别目标）将技术指标与业务目标关联。第二部分由Peter深入讲解了AI工作负载的可观测性挑战，介绍了Amazon GenAI Observability的新功能，包括端到端提示追踪、数据保护、以及使用LLM作为评判者的质量评估功能。会议通过实际演示展示了如何使用CloudWatch监控从基础设施到用户体验的各个层面，以及如何追踪AI代理的行为和决策过程。

## 详细时间线与关键要点

### 开场与背景介绍
[00:00 - 02:30] 
- 演讲者自我介绍：Matzah（云运维全球技术负责人，来自达拉斯，第六次参加re:Invent）和Peter Gang（CloudWatch产品经理，首次参加re:Invent）
- 使用能见度有限的高速公路驾驶比喻，说明缺乏可观测性的危险性
- 引用Werner Vogels名言："没有可见性，你只是在猜测"

### 可观测性基础与挑战
[02:30 - 06:00]
- 介绍角色John（开发者）及其复杂的应用架构
- 展示应用的多层结构：网络层、基础设施层、应用层、数据库层、用户层
- John的需求：原生集成、快速问题解决、成本优化、单一控制台、可操作的智能洞察

### CloudWatch多层监控能力
[06:00 - 09:30]
- **网络层**：Internet Monitor分析互联网性能和ISP问题
- **基础设施层**：Container Insights、Lambda Insights监控系统级性能
- **数据库层**：Database Insights实时监控数据库性能和SQL查询
- **应用层**：自动检测KPI，使用SLO维护服务质量承诺
- **用户层**：Real User Monitoring (RUM)和Synthetics模拟用户行为

### 可观测性三大支柱
[09:30 - 12:00]
- **指标（Metrics）**：应用响应延迟增加35%等量化数据
- **日志（Logs）**：结构化数据，如用户认证信息
- **追踪（Traces）**：微服务间的分布式处理时间

### 微服务架构的挑战
[12:00 - 14:00]
- 需要持续的性能优化以满足最终用户
- 手动整合遥测数据以理解性能下降和高延迟
- 难以确定业务优先级和异常处理
- 关联指标、日志、追踪、RUM和Synthetics数据的复杂性

### 黄金信号（Golden Signals）
[14:00 - 16:30]
- **请求量（Volume）**：直接影响应用需求和延迟
- **延迟（Latency）**：请求响应速度，影响用户体验
- **故障（Faults）**：应用程序问题
- **错误（Errors）**：格式错误或应用问题
- 将技术指标与业务影响关联：每分钟收入、购物车放弃率、页面加载时间、API错误代码

### Application Signals介绍
[16:30 - 19:00]
- 自动发现应用（使用OpenTelemetry SDK）
- 预构建仪表板，包含黄金信号的标准指标
- 几次点击即可理解根本原因（HTTP错误、异常、代码行）
- **SLO（服务级别目标）**：与可靠性目标和业务目标关联

### SLO深度解析
[19:00 - 21:30]
- SLO示例：Pet Search API需要99.9%的正常运行时间
- **SLI（服务级别指标）**：用于衡量目标的具体指标
- **错误预算（Error Budget）**：0.1%允许在30天内有43分钟的停机时间
- 与SLA（服务级别协议）关联，确保客户满意度

### 实际演示 - SLO创建
[21:30 - 25:00]
- 展示多个SLO，部分处于不健康状态
- SLO创建流程：
  - 选择SLI（服务操作、CloudWatch指标或服务依赖）
  - 选择前端服务的POST操作
  - 选择计算方法（按请求或按周期）
  - 设置条件（延迟100毫秒或可用性）
  - 定义评估周期和达成目标
  - 配置告警（与SLI或SLO达成目标关联）

### Application Map功能
[25:00 - 27:30]
- 几周前推出的自动发现功能
- 支持已插桩和未插桩的应用
- 可按组过滤，自动显示账户中的所有应用
- 支持通过OpenTelemetry配置文件创建自定义属性
- 展示应用拓扑结构和服务间连接

### 服务详细监控
[27:30 - 31:00]
- 双击服务查看完整拓扑
- 查看前端与后端的所有微服务连接
- 识别高故障率和高延迟路径
- 右侧显示黄金信号：请求量、延迟、错误、故障
- 支持P90、P99、P50百分位数查看
- **运营审计**：自动标注性能波动和异常时段

### 仪表板与服务操作
[31:00 - 34:00]
- 综合指标仪表板显示所有黄金信号
- 使用OpenTelemetry识别所有POST、GET、PUT操作
- 显示不健康的SLI
- 双击故障峰值自动显示相关span的关联性

### 故障排查演示 - DynamoDB问题
[34:00 - 37:00]
- 展示追踪映射：从前端到后端的完整trace和span
- 时间线视图显示span的详细信息
- 发现Visit服务Java抛出异常
- 根本原因：DynamoDB吞吐量问题
- 显示具体错误消息和代码行号
- DynamoDB视图中也显示相关消息

### 容器级别监控
[37:00 - 39:00]
- EKS集群中识别问题节点
- 识别有故障的具体Pod
- 按节点和Pod优先级排序
- 点击Container Insights按钮跳转到容器性能控制台
- 单一控制台查看完整性能数据

### 依赖关系与延迟问题
[39:00 - 42:00]
- Dependencies标签显示所有应用依赖关系
- 第二个用例：延迟问题
- 识别特定时间的延迟峰值
- 使用相同方法追踪延迟问题
- 发现不同API服务（包括Bedrock）的高延迟

### Bedrock延迟问题排查
[42:00 - 44:30]
- 追踪映射和时间线视图显示所有span
- Bedrock运行时出现错误
- 根本原因：Bedrock基础模型已被弃用
- 导致响应时间过长，影响用户体验
- 事件视图显示详细错误信息

### 用户体验监控
[44:30 - 47:30]
- **Synthetics Canaries**：创建模拟用户行为的场景
- 模拟用户使用应用的步骤
- 自动截图功能
- **Real User Monitoring (RUM)**：理解页面加载和错误
- 时间轴显示错误趋势
- 识别有加载问题的具体页面

### RUM详细信息
[47:30 - 49:00]
- 点击错误查看完整信息
- 用户视角的详细数据
- 会话发生时间和浏览器类型
- CloudWatch模拟用户行为的详细信息
- 全面理解用户体验

### AI工作负载可观测性转变
[49:00 - 52:00]
- Peter接手讲解AI可观测性
- 现场调查：大多数参会者正在构建AI应用
- 2025年AI应用将改变业务和用户交互方式
- 三个重点：
  1. 可观测性如何变化及新工具
  2. 可观测性中不变的部分及现有工具
  3. 完整演示

### AI应用演进历程
[52:00 - 54:30]
- **2023年**：问答聊天机器人
- **当前**：AI助手（逐步引导用户完成业务流程）
- **现在**：AI代理（自主执行任务和决策）
- **未来**：完全代理系统（独立实现开放式目标）

### AWS AI构建全栈
[54:30 - 57:30]
- **底层**：SageMaker训练和部署AI模型
- **中间层**：
  - Amazon Bedrock：通过单一API访问多个基础模型的完全托管服务
  - Agent Core：构建和部署高度可扩展的AI代理
- **高层**：完全代理系统（Curo IDE、Q Business Intelligence、Amazon Connect）
- 每一层都有可观测性支持

### AI可观测性的新挑战
[57:30 - 60:30]
- **不确定性**：代理行为不可预测，像青少年一样
- **根因分析**：需要追踪代理调用序列，但难以大规模分析
- **系统健康评估**：新增"质量"维度
  - 为什么代理做出特定决策？
  - 代理如何路由自己？
  - 代理拥有什么上下文？
- 传统工具只能显示延迟和错误，无法解释AI决策过程
- **新现实**：观察推理和意图，而非仅仅观察系统运行状态

### 可观测性作为控制平面
[60:30 - 63:00]
- 可观测性将成为信任、安全和质量的控制平面
- AI工作负载位于整个技术栈顶层
- 可观测性在最高层运行
- 连接基础设施信号，贯穿整个技术栈
- 整合不同模型和代理操作的遥测数据
- 观察完整的端到端交互

### Amazon GenAI Observability功能
[63:00 - 66:00]
- **360度视图**：无论使用何种模型（Strands、Crew AI、LangChain等框架）
- **开箱即用仪表板**：显示性能参数
- **简单插桩**：只要使用OpenTelemetry格式
- **端到端提示追踪**：追踪LLM调用、代理操作、工具、内存调用
- **数据保护**：屏蔽日志中的PII内容
- **评估功能**：使用LLM作为评判者监控质量

### Agent Core架构
[66:00 - 69:30]
- 在AWS Agent Core上轻松构建代理
- 安全地大规模部署和运营高能力AI代理
- 专为动态代理工作负载构建的基础设施
- 整合多个组件：
  - Bedrock上的任何LLM模型
  - Agent Core Memory（上下文）
  - Identity（控制和安全）
  - Gateway（第三方API工具调用的中心位置）
- 所有组件向CloudWatch GenAI Observability发送遥测数据

### 灵活的托管选项
[69:30 - 71:30]
- **Agent Core Runtime托管**：开箱即用所有功能
- **其他位置托管**（EC2、EKS、本地、其他云）：
  - 只要数据采用OpenTelemetry格式
  - 也能获得类似的CloudWatch功能
- 提供灵活性以满足不同需求

### Agent Core Runtime详细配置
[71:30 - 74:30]
- 支持代理框架：Strands、Crew AI、LangChain
- 支持的插桩库（开源）：Open Inference、Trace Loop
- 使用Amazon Distro for OpenTelemetry (ADOT)收集插桩数据
- 发送到CloudWatch OTel端点
- 为Runtime托管的代理提供强大功能

### 遥测配置
[74:30 - 76:30]
- CloudWatch遥测配置：一键启用所有遥测
- 从Agent Core Memory、Agent Core Gateway等组件收集数据
- 整个账户级别的配置
- 数据流向CloudWatch并支持各种视图
- 其他位置托管的代理：使用ADOT，只要采用OpenTelemetry格式
- 启用CloudWatch Transactions Search整合操作和工具调用
- 提供快速入门指南

### AI工作负载的三大支柱
[76:30 - 79:00]
- 与传统可观测性相同：指标、日志、追踪
- **指标**：令牌消耗、AI完成的工作量
- **日志**：用户输入和LLM模型/代理输出的详细信息
- **追踪**：
  - 理解响应如何在整个系统中传播
  - 聚合级别分析
  - 深入到每个单独交互的能力

### AI指标详解
[79:00 - 82:00]
- 常见监控指标：
  - 调用次数
  - 调用完成速度
  - 限流情况
  - 工作量（输入令牌数、输出令牌数）
- 日志来源：
  - 模型调用日志
  - Span日志（包含每个步骤和工具调用/代理操作的内容）
- 追踪：只要包含相同的会话ID或追踪ID，就能整合并显示端到端交互

### AI黄金指标
[82:00 - 85:00]
- **令牌使用量**：AI完成的工作量，帮助预测需求和成本
- **延迟**：AI响应速度
- **限流**：追踪接近配额和限制的情况
- **错误**：请求中的问题
- 预构建自动仪表板，无需配置
- 支持按模型过滤
- 完全集成CloudWatch告警功能

### 质量评估 - 新概念
[85:00 - 88:30]
- AI可观测性的全新运营现实
- 关注AI响应和代理操作的质量
- LLM可能产生幻觉，代理可能采取非预期路径
- 传统方法：科学团队手动评估小样本，过程繁重且缺乏信任
- **新方法 - 评估功能**：
  - 使用LLM作为评判者
  - 评估代理的忠实度（是否遵循上下文）
  - 评估指令遵循情况
  - 评估帮助客户完成任务的有效性

### 持续自动评估
[88:30 - 90:00]
- 对整个AI工作负载流量进行持续自动评估
- 支持全量采样或比例采样
- 消除劳动密集型手动评估流程
- **评估指标功能**：昨天刚发布，现已在CloudWatch中可用
- 由Agent Core Evaluations提供支持

### 日志深度分析
[90:00 - 93:30]
- 调用日志来源：LLM模型和代理
- 可选择发送到CloudWatch和/或S3
- 存储在熟悉的CloudWatch日志组概念中
- 与现有工作流集成
- **CloudWatch Log Insights**：强大的查询工具
  - 支持SQL、OpenSearch PPL等查询语言
  - 模式分析：检测日志事件中的常见文本结构
  - 自动实时异常检测：识别代理行为和性能变化

### 数据保护功能
[93:30 - 95:30]
- 客户交互可能包含PII信息
- **CloudWatch数据保护功能**：
  - 识别和屏蔽敏感客户信息（信用卡、姓名、地址）
  - 自动编辑处理
  - 细粒度IAM基于角色的控制
  - 超级用户可查看内容，普通用户无法访问
  - 生成自动审计报告以满足合规要求

### 会议结束
[95:30 - 96:00]
- 演讲在讨论追踪功能时被截断
- 会议涵盖了从传统应用监控到AI代理可观测性的完整内容

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


关键要点总结：
- CloudWatch Application Signals提供自动化APM能力
- SLO将技术指标与业务目标关联
- AI可观测性需要新工具（GenAI Observability）但仍基于指标、日志、追踪三大支柱
- 质量评估成为AI时代的新运营维度
- OpenTelemetry是实现统一可观测性的关键标准