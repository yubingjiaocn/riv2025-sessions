1
00:00:01,879 --> 00:00:04,179
All right. Thanks everybody for joining,

2
00:00:04,599 --> 00:00:06,679
uh, kind of the holdouts for some of the last sessions, so

3
00:00:06,679 --> 00:00:08,759
I really appreciate it. I also know that I'm competing with a keynote,

4
00:00:08,880 --> 00:00:10,948
so I'm very happy to have you here.

5
00:00:11,319 --> 00:00:13,599
Uh, my name is Justin Rio, I'm deputy CTO

6
00:00:13,599 --> 00:00:15,599
at DX. Uh, DX is

7
00:00:15,599 --> 00:00:17,879
a productivity platform, an engineering intelligence

8
00:00:17,879 --> 00:00:18,458
platform,

9
00:00:18,789 --> 00:00:21,318
uh, and we're able to look at a lot of insights

10
00:00:21,318 --> 00:00:23,000
around how various things, tools,

11
00:00:23,478 --> 00:00:24,399
technology, and things like that

12
00:00:24,679 --> 00:00:27,138
are impacting productivity within an

13
00:00:27,138 --> 00:00:29,170
organization. Right. And so this is

14
00:00:29,170 --> 00:00:30,429
where the data

15
00:00:30,728 --> 00:00:32,789
that you're about to see kind of from this study

16
00:00:33,130 --> 00:00:33,789
came from.

17
00:00:34,270 --> 00:00:36,439
Uh, we're able to pull insights from

18
00:00:36,439 --> 00:00:38,969
over 135,000 developers

19
00:00:38,969 --> 00:00:41,048
who are tracking AI utilization within

20
00:00:41,048 --> 00:00:41,630
the platform

21
00:00:42,348 --> 00:00:44,469
across 435 companies.

22
00:00:44,889 --> 00:00:46,929
Uh, we've looked at engineering org sizes

23
00:00:46,929 --> 00:00:49,039
from less than 50 engineers to over

24
00:00:49,039 --> 00:00:51,060
10,000 engineers, and we'll break some

25
00:00:51,060 --> 00:00:52,509
of that data down in this study.

26
00:00:52,959 --> 00:00:55,009
And we're looking at regional global companies,

27
00:00:55,090 --> 00:00:56,969
so headquarters in North America, LATAM.

28
00:00:57,490 --> 00:00:59,340
Europe and Asia Pacific.

29
00:00:59,798 --> 00:01:01,798
So this is aggregated anonymized

30
00:01:01,798 --> 00:01:04,000
data, and we use

31
00:01:04,000 --> 00:01:06,079
various reporting mechanisms to get this data

32
00:01:06,079 --> 00:01:06,959
into the system.

33
00:01:07,680 --> 00:01:10,459
Part of what DX is really good at is marrying

34
00:01:10,638 --> 00:01:11,989
qualitative signals

35
00:01:12,480 --> 00:01:15,209
from high performing surveys, like 90%

36
00:01:15,209 --> 00:01:17,989
plus participation rate in these surveys,

37
00:01:18,000 --> 00:01:20,120
uh, the types of surveys that are engineered to

38
00:01:20,120 --> 00:01:22,198
kind of look at developer experience as a systems

39
00:01:22,198 --> 00:01:23,400
problem, not a people problem.

40
00:01:23,709 --> 00:01:25,859
So we tend to get very honest responses.

41
00:01:26,409 --> 00:01:28,540
Uh, so as far as I know, this is probably the the

42
00:01:28,540 --> 00:01:30,808
best data set that's kind of available right now,

43
00:01:31,019 --> 00:01:33,629
uh, in terms of how AI is truly

44
00:01:33,629 --> 00:01:35,629
impacting uh work across different

45
00:01:35,629 --> 00:01:37,709
cohorts and different kinds of companies.

46
00:01:37,829 --> 00:01:38,829
So that's what we'll share today.

47
00:01:39,120 --> 00:01:40,209
Now there's a full report

48
00:01:40,870 --> 00:01:43,028
that dives deeper into some of this,

49
00:01:43,308 --> 00:01:45,370
uh, which you are of course welcome to download.

50
00:01:45,709 --> 00:01:48,069
I'm gonna share a few resources with you

51
00:01:48,069 --> 00:01:49,808
throughout the course of this presentation,

52
00:01:50,409 --> 00:01:52,459
um. So, and we have plenty of time. I

53
00:01:52,459 --> 00:01:54,019
think this is like an hour long session.

54
00:01:54,558 --> 00:01:56,579
Uh, so I'll I'll linger a little bit on some

55
00:01:56,579 --> 00:01:57,519
of these slides.

56
00:01:58,019 --> 00:02:00,338
Uh, this is the result of compiling

57
00:02:00,338 --> 00:02:01,299
a lot of this data.

58
00:02:01,689 --> 00:02:03,079
Myself and my um

59
00:02:03,469 --> 00:02:05,528
CTO counterpart Laura Taco, who some of you

60
00:02:05,528 --> 00:02:07,620
may know, she, she's very prolific in the developer

61
00:02:07,620 --> 00:02:09,778
experience space, uh, worked together to

62
00:02:09,778 --> 00:02:11,909
put this, uh, to put this guide and these various

63
00:02:11,909 --> 00:02:12,939
kind of figures together.

64
00:02:13,270 --> 00:02:15,319
Um, so there's a lot in there, it's much more meaty

65
00:02:15,319 --> 00:02:16,469
than what we'll get into today,

66
00:02:16,750 --> 00:02:18,868
um, but we're gonna cover, uh, some of the trends

67
00:02:18,868 --> 00:02:19,849
and some of the interesting,

68
00:02:20,189 --> 00:02:21,849
uh, details that came out in this report.

69
00:02:22,349 --> 00:02:23,449
All right, so first of all,

70
00:02:23,990 --> 00:02:25,288
let's talk a little bit about

71
00:02:25,550 --> 00:02:27,028
the current impact of AI,

72
00:02:27,508 --> 00:02:28,508
right? Where are we?

73
00:02:28,830 --> 00:02:30,379
Uh, nobody knows.

74
00:02:31,399 --> 00:02:32,788
So, you know, on the one hand,

75
00:02:33,118 --> 00:02:35,199
we've got Google telling us like, oh, we're, you know,

76
00:02:35,360 --> 00:02:37,500
our engineers are 10% more productive

77
00:02:37,500 --> 00:02:39,558
as a result of of using AI. Now of

78
00:02:39,558 --> 00:02:41,500
course Google's already a highly productive company,

79
00:02:41,788 --> 00:02:43,819
focused a lot on developer productivity. They were

80
00:02:43,819 --> 00:02:46,258
pioneers in the study of developer experience.

81
00:02:46,879 --> 00:02:48,960
But on the other hand, we have this now I would say sort

82
00:02:48,960 --> 00:02:49,699
of infamous

83
00:02:50,129 --> 00:02:52,439
METR study, meter study, which had some flaws,

84
00:02:52,520 --> 00:02:53,399
you know, don't get me wrong.

85
00:02:53,729 --> 00:02:55,879
That showed that developers who took part in

86
00:02:55,879 --> 00:02:58,159
that study were 19%

87
00:02:58,159 --> 00:03:00,278
less productive as a result

88
00:03:00,278 --> 00:03:02,258
of using AI, and this is cursor. Now

89
00:03:02,719 --> 00:03:04,199
there were 16 people in this study.

90
00:03:04,508 --> 00:03:06,639
Some of them had never even touched cursor before, so

91
00:03:06,639 --> 00:03:08,679
that's flawed. But the one takeaway that I do

92
00:03:08,679 --> 00:03:10,740
think is really interesting from this study

93
00:03:10,919 --> 00:03:13,000
is that every engineer in that

94
00:03:13,000 --> 00:03:15,399
study qualitatively felt.

95
00:03:16,050 --> 00:03:18,088
That they were more productive using

96
00:03:18,088 --> 00:03:20,088
AI. So I think that there's something about

97
00:03:20,088 --> 00:03:21,308
the tooling that's kind of fun.

98
00:03:21,929 --> 00:03:24,199
It kind of initiates a bit of a flow state, makes

99
00:03:24,199 --> 00:03:26,258
us feel like we're doing more work, but in this

100
00:03:26,258 --> 00:03:27,389
case, in this study,

101
00:03:27,808 --> 00:03:29,210
it didn't really turn out that way.

102
00:03:30,219 --> 00:03:31,719
So we have a lot of data, uh, let me

103
00:03:32,050 --> 00:03:34,219
get ahead of myself here. Dora also, uh,

104
00:03:34,300 --> 00:03:36,300
you know, produces a lot of great reports. We work

105
00:03:36,300 --> 00:03:38,580
with Dora very closely. In fact, Nicole

106
00:03:38,580 --> 00:03:40,740
Forsgren, who invented the Dora metrics

107
00:03:40,740 --> 00:03:42,219
and wrote the book Accelerate,

108
00:03:42,490 --> 00:03:44,250
uh, is one of our chief researchers.

109
00:03:44,580 --> 00:03:46,919
Uh, she and my CEO Abby Noda

110
00:03:46,919 --> 00:03:49,139
just recently released a book called Frictionless,

111
00:03:49,429 --> 00:03:51,899
um, which talks about sort of a playbook for developer

112
00:03:51,899 --> 00:03:52,439
experience.

113
00:03:53,099 --> 00:03:55,139
So we work very, very closely with the Dora community. I

114
00:03:55,139 --> 00:03:57,038
have a lot of great friends there, they do a lot of great work.

115
00:03:57,639 --> 00:03:59,229
Uh, this data though,

116
00:03:59,679 --> 00:04:01,270
tended to like report

117
00:04:01,788 --> 00:04:02,308
impact

118
00:04:02,849 --> 00:04:04,159
on averages.

119
00:04:04,979 --> 00:04:06,439
So we're seeing these sort of like

120
00:04:07,099 --> 00:04:09,219
modest but positively leaning

121
00:04:09,219 --> 00:04:11,860
gains from this study. 7.5%

122
00:04:11,860 --> 00:04:13,528
increase in documentation quality,

123
00:04:13,860 --> 00:04:15,979
3.4% increase in code

124
00:04:15,979 --> 00:04:16,838
quality, so at least,

125
00:04:17,100 --> 00:04:19,178
you know, not a huge leap, but at least not leaning in the

126
00:04:19,178 --> 00:04:20,959
in the in the wrong direction, right?

127
00:04:21,259 --> 00:04:23,329
3.1% increase in overall code

128
00:04:23,329 --> 00:04:23,838
review speed.

129
00:04:24,259 --> 00:04:26,910
Uh, so again, like these modest,

130
00:04:27,139 --> 00:04:29,178
but at least positively leaning

131
00:04:29,500 --> 00:04:30,879
metrics that we're looking at

132
00:04:31,220 --> 00:04:32,480
across broad averages.

133
00:04:32,750 --> 00:04:34,819
So then we thought, well, why don't we correlate that data and see what we

134
00:04:34,819 --> 00:04:36,338
found, and we found largely the same thing.

135
00:04:36,889 --> 00:04:39,500
So this was a sample of close to 20,000

136
00:04:39,500 --> 00:04:40,160
developers,

137
00:04:40,819 --> 00:04:43,108
and this metric is

138
00:04:43,108 --> 00:04:44,338
called change confidence.

139
00:04:44,709 --> 00:04:46,160
It's a qualitative metric,

140
00:04:46,428 --> 00:04:48,829
and it's measured on a top box Leichhardt

141
00:04:48,829 --> 00:04:51,108
score. So what is that? If you're not familiar with survey

142
00:04:51,108 --> 00:04:53,189
engineering, a Leichhardt scale is when

143
00:04:53,189 --> 00:04:55,309
you say answer a question, like always, very often,

144
00:04:55,629 --> 00:04:56,338
sometimes, you know,

145
00:04:56,629 --> 00:04:58,629
and the top box scoring methodology means

146
00:04:58,629 --> 00:05:01,129
we want to see the percentage of people who answered always

147
00:05:01,319 --> 00:05:02,170
or very often,

148
00:05:02,509 --> 00:05:04,548
right? So the two like positive answers that

149
00:05:04,548 --> 00:05:06,588
you can put in that survey. So what you're seeing here

150
00:05:06,588 --> 00:05:08,910
is a percentage of developers that effectively

151
00:05:08,910 --> 00:05:10,910
answered a question saying that they feel like they can put

152
00:05:10,910 --> 00:05:12,428
stuff into production without breaking things.

153
00:05:13,119 --> 00:05:15,119
And uh what you're seeing here is AI users on

154
00:05:15,119 --> 00:05:15,699
the left

155
00:05:16,040 --> 00:05:18,579
and non-AI users on the right, in the platform.

156
00:05:19,040 --> 00:05:21,639
And there's a 2.6% gain

157
00:05:22,000 --> 00:05:24,399
from using AI. OK, yeah, great. Again,

158
00:05:24,639 --> 00:05:26,778
not huge, but at least positively

159
00:05:26,778 --> 00:05:28,959
leaning. We see the same thing with

160
00:05:28,959 --> 00:05:31,238
code maintainability, another quality metric,

161
00:05:31,350 --> 00:05:33,399
how much cognitive load do you feel like you have

162
00:05:33,399 --> 00:05:35,428
to expend to understand the code that's in

163
00:05:35,428 --> 00:05:37,439
front of you. Uh, and we found a

164
00:05:37,439 --> 00:05:39,829
2.2% gain amongst

165
00:05:39,829 --> 00:05:41,838
AI users that they felt, uh, you

166
00:05:41,838 --> 00:05:44,199
know, that they, that the code itself was maintainable.

167
00:05:44,600 --> 00:05:46,298
Easy to read. OK, cool.

168
00:05:46,600 --> 00:05:48,548
Then we looked at, uh, change failure rate,

169
00:05:48,920 --> 00:05:50,959
you know, who's familiar with Dora metrics and change

170
00:05:50,959 --> 00:05:53,079
failure rate and stuff like that. I got a few of you, so change

171
00:05:53,079 --> 00:05:55,170
failure rate is kind of what it sounds like, the percentage

172
00:05:55,170 --> 00:05:57,399
of value adding features, uh, that you

173
00:05:57,399 --> 00:05:59,480
release that then have to be reverted because they

174
00:05:59,480 --> 00:06:00,079
break something.

175
00:06:00,509 --> 00:06:03,088
And we saw a 0.11% reduction

176
00:06:03,230 --> 00:06:04,309
from using AI.

177
00:06:04,660 --> 00:06:05,588
OK, you know,

178
00:06:05,928 --> 00:06:07,850
the, the industry benchmark is 4%.

179
00:06:08,230 --> 00:06:10,230
So as sort of insignificant as that seems when

180
00:06:10,230 --> 00:06:12,278
you compare it to a 4% benchmark, it's a little

181
00:06:12,278 --> 00:06:13,488
bit more significant.

182
00:06:14,358 --> 00:06:15,309
So then we thought, well

183
00:06:16,309 --> 00:06:17,459
This can't be right,

184
00:06:17,988 --> 00:06:20,488
because we're talking to customers that are experiencing

185
00:06:20,488 --> 00:06:21,119
good things,

186
00:06:21,389 --> 00:06:23,548
and we're talking to customers that are experiencing bad

187
00:06:23,548 --> 00:06:25,629
things. So I thought, what if we ran the

188
00:06:25,629 --> 00:06:27,670
sample and we reported it company per

189
00:06:27,670 --> 00:06:28,629
company instead?

190
00:06:29,720 --> 00:06:30,738
Here's what we saw

191
00:06:31,819 --> 00:06:32,559
OK,

192
00:06:32,858 --> 00:06:33,689
every bar

193
00:06:34,269 --> 00:06:36,750
represents a single company on this graph.

194
00:06:36,988 --> 00:06:39,230
You want to be on the top line here. This means

195
00:06:39,230 --> 00:06:41,428
some companies experiencing more

196
00:06:41,428 --> 00:06:42,730
than a 20%

197
00:06:43,350 --> 00:06:44,699
increase in change confidence,

198
00:06:45,069 --> 00:06:47,769
but also companies experiencing a 20%

199
00:06:48,028 --> 00:06:48,709
decrease.

200
00:06:49,220 --> 00:06:51,259
So when we look at the averages, when we filter

201
00:06:51,259 --> 00:06:51,939
by average,

202
00:06:52,199 --> 00:06:54,298
the data, that's not telling us the story of what's really

203
00:06:54,298 --> 00:06:56,338
happening, right? We're actually living in quite

204
00:06:56,338 --> 00:06:58,459
volatile times. Now, there's

205
00:06:58,459 --> 00:07:00,500
a lot of factors that go into

206
00:07:00,500 --> 00:07:02,500
this. There's something that we're starting to

207
00:07:02,500 --> 00:07:04,619
refer to as agent X or agent

208
00:07:04,619 --> 00:07:06,660
experience, which is effectively that what's good for

209
00:07:06,660 --> 00:07:08,220
humans is also good for agents.

210
00:07:08,660 --> 00:07:10,750
And so companies that have already spent a lot of time.

211
00:07:11,449 --> 00:07:13,449
Like perfecting their automation and doing

212
00:07:13,449 --> 00:07:15,619
a lot of work on their SDLC and and getting

213
00:07:15,619 --> 00:07:17,619
all the right code hygiene things, they tend to

214
00:07:17,619 --> 00:07:19,379
be obviously on the top line of this graph.

215
00:07:20,220 --> 00:07:22,588
The irony is that all of this investment

216
00:07:22,588 --> 00:07:24,949
in AI and agents and everything might finally

217
00:07:24,949 --> 00:07:27,108
get companies unified about caring about the

218
00:07:27,108 --> 00:07:29,298
things that we should have been doing for developers

219
00:07:29,298 --> 00:07:30,329
er years ago.

220
00:07:30,790 --> 00:07:32,910
Um, so we looked at, we saw the same thing with

221
00:07:32,910 --> 00:07:33,769
code maintainability.

222
00:07:34,798 --> 00:07:36,059
Same volatility here.

223
00:07:36,559 --> 00:07:38,459
Uh, we saw the same thing with change failure rate.

224
00:07:38,959 --> 00:07:39,540
Um,

225
00:07:40,040 --> 00:07:41,858
so and this is a 2%

226
00:07:42,480 --> 00:07:44,480
increase, you wanna be on the bottom side of this

227
00:07:44,480 --> 00:07:46,509
graph here, you want to decrease your change failure

228
00:07:46,509 --> 00:07:48,678
rate. A 2% increase in

229
00:07:48,678 --> 00:07:49,738
change failure rate

230
00:07:50,079 --> 00:07:51,980
across a 4% benchmark

231
00:07:52,238 --> 00:07:54,480
means shipping 50% more

232
00:07:54,480 --> 00:07:55,259
defects

233
00:07:55,639 --> 00:07:56,670
than you were before.

234
00:07:56,959 --> 00:07:59,069
But then same here at the bottom, shipping 50%

235
00:07:59,069 --> 00:07:59,920
less, right?

236
00:08:00,619 --> 00:08:02,798
So, a big takeaway here

237
00:08:02,939 --> 00:08:04,939
is that especially as leaders, like we've got to

238
00:08:04,939 --> 00:08:07,250
measure, right? We need to

239
00:08:07,250 --> 00:08:09,298
understand where we are. And if we're on the

240
00:08:09,298 --> 00:08:11,298
wrong side of this graph, we need to be

241
00:08:11,298 --> 00:08:13,298
really strategic in thinking about how we get on the

242
00:08:13,298 --> 00:08:14,178
right side of it.

243
00:08:14,889 --> 00:08:17,358
Because as everyone knows, right, AI is an accelerant,

244
00:08:17,660 --> 00:08:18,920
it accelerates good

245
00:08:19,319 --> 00:08:21,129
and it accelerates bad, right?

246
00:08:21,509 --> 00:08:23,738
And we are seeing absolutely widespread

247
00:08:23,738 --> 00:08:26,540
adoption. One thing that is definitely consistent.

248
00:08:27,119 --> 00:08:29,420
Is that we're seeing now 90%

249
00:08:29,678 --> 00:08:32,000
overall adoption of AI

250
00:08:32,000 --> 00:08:34,158
across the companies that we sampled. This was a

251
00:08:34,158 --> 00:08:37,678
broad sample of 135,000

252
00:08:37,678 --> 00:08:38,418
developers,

253
00:08:39,178 --> 00:08:41,599
um, and we're getting from light utilization.

254
00:08:42,320 --> 00:08:43,849
On the lower end of the scale,

255
00:08:44,158 --> 00:08:46,460
uh, to more moderate and then high

256
00:08:46,460 --> 00:08:48,599
utilization. So this is basically

257
00:08:48,599 --> 00:08:49,239
monthly,

258
00:08:49,519 --> 00:08:51,719
weekly, daily, is kind of the scale

259
00:08:51,719 --> 00:08:53,840
there. All right. So this has all happened very

260
00:08:53,840 --> 00:08:54,379
quickly,

261
00:08:55,058 --> 00:08:57,190
uh, and we're going to talk about how this is

262
00:08:57,190 --> 00:08:59,229
like reported metrics,

263
00:08:59,599 --> 00:09:01,678
but that it's probably more like 100%,

264
00:09:01,719 --> 00:09:02,879
and I'll show you that in a minute.

265
00:09:03,719 --> 00:09:05,750
Um, we're finding that across again a

266
00:09:05,750 --> 00:09:07,798
broad sample of engineers, the regular

267
00:09:07,798 --> 00:09:10,239
AIs, uh, AI users are saving about 3.8

268
00:09:10,239 --> 00:09:10,940
hours a week,

269
00:09:11,279 --> 00:09:13,538
uh, from code completion and that sort of thing.

270
00:09:14,158 --> 00:09:16,538
This isn't, um, also talking about

271
00:09:17,038 --> 00:09:19,090
integrating agents throughout the SDLC, that's

272
00:09:19,090 --> 00:09:20,070
a whole other topic.

273
00:09:20,440 --> 00:09:22,019
I do have some data on that as well.

274
00:09:22,440 --> 00:09:24,580
But this is really like the code completion thing.

275
00:09:24,918 --> 00:09:27,029
So, OK, you know, 3.8 hours a week.

276
00:09:27,279 --> 00:09:29,399
I think it's also very important though to remember

277
00:09:29,399 --> 00:09:29,960
that like,

278
00:09:30,450 --> 00:09:32,719
You know, the, the Dora state of developer Experience

279
00:09:32,719 --> 00:09:34,750
report that just came out still reported that

280
00:09:34,750 --> 00:09:36,759
engineers on average, because of so many other

281
00:09:37,259 --> 00:09:38,840
time syncs and stuff, are lucky

282
00:09:39,298 --> 00:09:41,298
to get 5 to 6 hours a week

283
00:09:41,580 --> 00:09:43,200
of like focused time

284
00:09:43,500 --> 00:09:44,178
writing code.

285
00:09:44,928 --> 00:09:46,519
So as impressive as this is,

286
00:09:46,808 --> 00:09:49,440
it's not necessarily the bottleneck, I think for most

287
00:09:49,440 --> 00:09:51,519
organizations, right? But this is what we're seeing across a

288
00:09:51,519 --> 00:09:52,269
broad sample.

289
00:09:52,889 --> 00:09:53,529
Um,

290
00:09:54,048 --> 00:09:56,048
22% of code across

291
00:09:56,048 --> 00:09:58,129
this sample is now authored by

292
00:09:58,129 --> 00:09:58,690
AI,

293
00:09:59,129 --> 00:10:01,649
right? And when we looked at the sampling.

294
00:10:02,250 --> 00:10:04,779
Uh, we were very careful not to just look at telemetry

295
00:10:04,779 --> 00:10:05,558
metrics here,

296
00:10:05,979 --> 00:10:08,219
right, because telemetry metrics don't always tell the

297
00:10:08,219 --> 00:10:10,219
full story. When we get a little later in this

298
00:10:10,219 --> 00:10:11,719
presentation to measurement,

299
00:10:12,019 --> 00:10:14,019
I'll talk about sort of the three types of metrics

300
00:10:14,019 --> 00:10:16,178
that you want to correlate together to

301
00:10:16,178 --> 00:10:17,460
get a good picture about impact.

302
00:10:17,879 --> 00:10:19,739
Um, but in this case, like for instance,

303
00:10:20,080 --> 00:10:22,119
how do we know that if an engineer like

304
00:10:22,119 --> 00:10:24,298
accepted the code changes, that didn't just go and then

305
00:10:24,440 --> 00:10:26,440
rewrite every line of it afterwards, right?

306
00:10:26,509 --> 00:10:28,639
So that would mean like the code didn't actually

307
00:10:28,639 --> 00:10:30,639
make it from AI to production. This is

308
00:10:30,639 --> 00:10:32,489
code that made it from AI to production,

309
00:10:32,840 --> 00:10:34,960
right? And we have some technology that's coming out

310
00:10:34,960 --> 00:10:36,979
soon, uh, where we look at

311
00:10:37,119 --> 00:10:39,210
various hashes and things like that going on in the file

312
00:10:39,210 --> 00:10:40,658
system to be able to automate this.

313
00:10:41,000 --> 00:10:43,168
Um, but this is the data that we found

314
00:10:43,168 --> 00:10:43,820
right now.

315
00:10:44,239 --> 00:10:46,239
OK. Uh, daily

316
00:10:46,239 --> 00:10:48,609
AI users are shipping 60%

317
00:10:48,609 --> 00:10:49,450
more PRs.

318
00:10:49,729 --> 00:10:51,529
Now, what's in those PRs,

319
00:10:51,808 --> 00:10:52,408
right?

320
00:10:53,168 --> 00:10:54,940
We know that we have companies that are,

321
00:10:55,250 --> 00:10:57,369
uh, you know, mandating top-down

322
00:10:57,369 --> 00:10:58,288
use of AI

323
00:10:58,769 --> 00:11:00,849
just like we always sort of tell people not

324
00:11:00,849 --> 00:11:02,408
to focus on any single metric.

325
00:11:02,690 --> 00:11:04,928
100% utilization across the company

326
00:11:04,928 --> 00:11:06,269
doesn't really say anything,

327
00:11:06,649 --> 00:11:08,969
especially if there's a mandate to do it, and

328
00:11:08,969 --> 00:11:11,109
especially if that mandate is being weaponized

329
00:11:11,330 --> 00:11:12,450
or incentivized,

330
00:11:13,129 --> 00:11:15,219
because there's this little thing called Goodheart's law.

331
00:11:15,619 --> 00:11:16,639
Uh, I'm from the South,

332
00:11:17,019 --> 00:11:19,500
and we say, uh, when you're talking about developer

333
00:11:19,500 --> 00:11:21,538
experience, you can't swing a dead cat without coming across

334
00:11:21,538 --> 00:11:22,320
Goodheart's law.

335
00:11:22,700 --> 00:11:24,298
Uh, anybody familiar with that law?

336
00:11:25,000 --> 00:11:27,080
A couple of you. All right. It basically says that when a

337
00:11:27,080 --> 00:11:27,658
measure

338
00:11:28,000 --> 00:11:28,960
becomes a target,

339
00:11:29,359 --> 00:11:30,879
it ceases to be a good measure,

340
00:11:31,320 --> 00:11:33,519
right? And the reason for that is

341
00:11:33,519 --> 00:11:35,519
because we're humans, and especially as

342
00:11:35,519 --> 00:11:37,840
engineers, we're going to find a way to hit that metric,

343
00:11:38,048 --> 00:11:40,399
right? If, if we're told that we need 100%

344
00:11:40,399 --> 00:11:42,428
utilization across the company to to use

345
00:11:42,428 --> 00:11:44,479
AI, like, OK, we will

346
00:11:44,479 --> 00:11:46,658
update our read me file every morning, like using

347
00:11:46,658 --> 00:11:48,859
an assistant, and we will look like we've got 100%

348
00:11:48,859 --> 00:11:49,379
utilization.

349
00:11:50,000 --> 00:11:52,080
There's a great parable that goes alongside

350
00:11:52,080 --> 00:11:54,200
Goodheart's law called the Cobra effect. Anybody

351
00:11:54,200 --> 00:11:54,779
heard of that one?

352
00:11:55,538 --> 00:11:56,250
OK, so

353
00:11:56,629 --> 00:11:58,668
it's a good way to explain it. It's a silly

354
00:11:58,668 --> 00:12:00,450
story. Uh, you have an emperor

355
00:12:00,979 --> 00:12:02,989
who has a problem with venomous cobras

356
00:12:02,989 --> 00:12:03,779
in the kingdom,

357
00:12:04,269 --> 00:12:06,750
and so, uh, sets up an incentivization

358
00:12:06,750 --> 00:12:09,070
program, hey, bring me 100 dead cobras, and

359
00:12:09,070 --> 00:12:10,099
I'll give you some money.

360
00:12:10,469 --> 00:12:12,548
Alright, so I'm incentivizing now the number of dead

361
00:12:12,548 --> 00:12:13,629
cobras that you bring me.

362
00:12:14,029 --> 00:12:16,149
So some people got clever, what do you think they did? They started

363
00:12:16,149 --> 00:12:17,418
farming cobras

364
00:12:17,788 --> 00:12:19,788
and killing them and bringing them to the emperor, right,

365
00:12:19,908 --> 00:12:21,190
so we're gaming the system.

366
00:12:21,548 --> 00:12:23,820
Emperor gets wind of what's going on, the people are cheating,

367
00:12:24,178 --> 00:12:24,889
kills the program.

368
00:12:25,538 --> 00:12:27,700
And all those farmers release

369
00:12:27,700 --> 00:12:29,960
all those cobras, and the problem

370
00:12:29,960 --> 00:12:31,609
gets a lot worse, right?

371
00:12:32,058 --> 00:12:32,750
So, um,

372
00:12:33,019 --> 00:12:35,099
we do have to be careful about what's in these PRs, but

373
00:12:35,099 --> 00:12:37,099
we do know that it's definitely accelerating. So

374
00:12:37,099 --> 00:12:39,139
you're seeing it's going from daily to weekly to monthly

375
00:12:39,139 --> 00:12:39,960
to never, so

376
00:12:40,219 --> 00:12:41,298
very satisfying

377
00:12:41,658 --> 00:12:43,769
kind of graph there. And then an area that

378
00:12:43,769 --> 00:12:44,418
we have,

379
00:12:44,779 --> 00:12:45,340
uh,

380
00:12:45,859 --> 00:12:47,279
um, no data.

381
00:12:47,700 --> 00:12:49,739
I want to point out, because we're going to get back to this.

382
00:12:51,099 --> 00:12:53,288
That the metrics showed us that people who are never

383
00:12:53,288 --> 00:12:54,158
using AI

384
00:12:54,558 --> 00:12:57,489
are using AI to ship 1.3%

385
00:12:57,570 --> 00:12:59,649
or 1.3 extra PRs. Uh,

386
00:12:59,690 --> 00:13:00,928
so we'll get into that in a moment.

387
00:13:01,750 --> 00:13:03,908
Uh, OK, so that's just kind of what we've

388
00:13:03,908 --> 00:13:06,090
seen in terms of current impact. This is all very

389
00:13:06,090 --> 00:13:08,149
fresh data, by the way. Uh, we ran

390
00:13:08,149 --> 00:13:10,369
these samples back in mid-October.

391
00:13:10,629 --> 00:13:12,168
Now I know that things are moving very quickly,

392
00:13:12,619 --> 00:13:14,928
um, but this isn't like some study we did like a year ago.

393
00:13:15,239 --> 00:13:17,269
Uh, we'll continue to put out these types of reports

394
00:13:17,269 --> 00:13:18,168
at least quarterly.

395
00:13:18,469 --> 00:13:20,210
Uh, we've built sort of a mechanism to do that,

396
00:13:20,769 --> 00:13:22,788
uh, and it's pretty easy for us to, to glean this

397
00:13:22,788 --> 00:13:25,029
data. So keep an eye out on stuff that we continue to push.

398
00:13:25,918 --> 00:13:27,739
Alright, some interesting trends though.

399
00:13:28,808 --> 00:13:31,149
Junior engineers are actually using AI the most.

400
00:13:31,558 --> 00:13:33,830
So we're seeing junior engineers here on the left,

401
00:13:34,119 --> 00:13:36,139
mid-level senior and then staff plus.

402
00:13:36,469 --> 00:13:37,269
Um so,

403
00:13:37,558 --> 00:13:39,940
and then these, these darker areas are daily

404
00:13:40,279 --> 00:13:42,479
active use, right? So we see junior engineers

405
00:13:42,479 --> 00:13:44,599
actually making use of this technology.

406
00:13:44,889 --> 00:13:46,918
Now, I've been writing code professionally since the

407
00:13:46,918 --> 00:13:49,119
late 90s, OK. I, I was just

408
00:13:49,119 --> 00:13:51,538
as reticent, you know, I've been a staff engineer,

409
00:13:51,879 --> 00:13:53,879
and I've been through that whole like, oh, I can't

410
00:13:53,879 --> 00:13:56,119
do it better than me, I should write the code, or I like writing

411
00:13:56,119 --> 00:13:58,178
code and You know, I've, I've come around to

412
00:13:58,178 --> 00:13:59,359
the fact that like

413
00:13:59,739 --> 00:14:01,820
the optimization of developer experience and

414
00:14:01,820 --> 00:14:04,158
productivity has always been about reducing toil,

415
00:14:04,859 --> 00:14:06,779
right? And it, and in my opinion,

416
00:14:07,428 --> 00:14:09,668
It now sort of behooves us to rethink

417
00:14:09,668 --> 00:14:11,009
that definition of toil,

418
00:14:11,428 --> 00:14:13,788
right? Like if there is something like writing mid-loop

419
00:14:13,788 --> 00:14:15,830
code, like I, I know my function header, I know

420
00:14:15,830 --> 00:14:17,298
what my function's supposed to do.

421
00:14:17,750 --> 00:14:19,908
Do I really need to write the code in

422
00:14:19,908 --> 00:14:21,950
between? What if you like coding? Great. Work

423
00:14:21,950 --> 00:14:24,000
on an open source project, work on a passion

424
00:14:24,000 --> 00:14:25,408
project, but if somebody's paying you

425
00:14:25,830 --> 00:14:26,889
to write code efficiently.

426
00:14:27,178 --> 00:14:28,940
You know, we have to get to a point where,

427
00:14:29,219 --> 00:14:31,250
you know, we can at least trust some of these things that

428
00:14:31,250 --> 00:14:31,808
work well,

429
00:14:32,178 --> 00:14:33,609
much better than they did like a year ago,

430
00:14:33,899 --> 00:14:36,259
uh, over to some of these agents and these assistants.

431
00:14:36,460 --> 00:14:38,570
But I think with junior engineers, you don't have that much of a

432
00:14:38,570 --> 00:14:40,889
problem, right, because it's, they're still learning newer

433
00:14:40,889 --> 00:14:41,450
skill sets,

434
00:14:41,779 --> 00:14:43,849
right? So it's interesting to see, um,

435
00:14:43,859 --> 00:14:45,279
to see these adoption trends,

436
00:14:45,658 --> 00:14:47,889
uh, and I imagine that we'll see this change over time,

437
00:14:48,058 --> 00:14:50,259
you know, I mean, I was definitely one of a

438
00:14:50,259 --> 00:14:52,259
skeptic before I kind of became a believer, and

439
00:14:52,259 --> 00:14:54,440
I think a lot of people are kind of going through that journey right now.

440
00:14:55,759 --> 00:14:58,070
Uh, so staff engineers though,

441
00:14:58,639 --> 00:15:00,509
interestingly, save the most time.

442
00:15:01,048 --> 00:15:03,759
So even though they're lagging in overall adoption,

443
00:15:04,080 --> 00:15:06,519
they're generally going to be better at understanding

444
00:15:06,519 --> 00:15:08,269
when code is well written,

445
00:15:08,639 --> 00:15:09,739
when it's ready to ship,

446
00:15:10,000 --> 00:15:11,779
right, when there's issues with the code,

447
00:15:12,440 --> 00:15:14,700
and so they're going to be more efficient in these tools

448
00:15:15,000 --> 00:15:16,820
once they start getting better at them.

449
00:15:17,960 --> 00:15:20,099
We have definitely realized a trend

450
00:15:20,798 --> 00:15:22,940
across the board. This is like almost every company

451
00:15:23,119 --> 00:15:25,119
that we sampled, and it didn't matter whether you're a

452
00:15:25,119 --> 00:15:27,029
junior engineer or a senior engineer.

453
00:15:27,389 --> 00:15:29,399
There's absolutely this sort of J curve, that

454
00:15:29,399 --> 00:15:30,859
when we move from no adoption

455
00:15:31,239 --> 00:15:33,479
to light adoption, and if you're a leader in the audience,

456
00:15:33,759 --> 00:15:35,190
you kind of have to be ready for this.

457
00:15:35,599 --> 00:15:37,678
During that none to light adoption phase,

458
00:15:37,889 --> 00:15:40,038
productivity across the board went down,

459
00:15:40,320 --> 00:15:41,428
and so did quality.

460
00:15:41,960 --> 00:15:44,440
And then we moved into moderate and heavy adoption,

461
00:15:44,639 --> 00:15:46,460
it outpaced where we were before.

462
00:15:46,798 --> 00:15:48,899
But it was such a clear indicator

463
00:15:49,119 --> 00:15:51,320
of this like experimentation and learning

464
00:15:51,320 --> 00:15:53,519
period. Like it's really necessary to

465
00:15:53,519 --> 00:15:55,678
allow engineers to get

466
00:15:55,678 --> 00:15:58,080
the right type of education material, have

467
00:15:58,080 --> 00:16:00,119
time to implement that education, have

468
00:16:00,119 --> 00:16:01,190
time to experiment,

469
00:16:01,479 --> 00:16:03,479
and just, just expect that things might get a little bit

470
00:16:03,479 --> 00:16:05,418
worse before they do start getting better,

471
00:16:06,399 --> 00:16:06,928
right? Uh,

472
00:16:07,279 --> 00:16:09,359
so I do think it's interesting though that then when we see

473
00:16:09,359 --> 00:16:10,460
these heavy users

474
00:16:10,759 --> 00:16:11,619
of

475
00:16:11,918 --> 00:16:13,710
AI on the staff engineering side,

476
00:16:14,080 --> 00:16:17,149
we're outpacing senior and mid-levels

477
00:16:17,149 --> 00:16:19,519
with this, with this heavy adoption. So

478
00:16:19,519 --> 00:16:21,960
even though staff engineers might be slower

479
00:16:21,960 --> 00:16:24,119
to adopt the technology, when they

480
00:16:24,119 --> 00:16:26,200
do, they end up saving more time, they end up actually

481
00:16:26,200 --> 00:16:27,099
being better with it.

482
00:16:27,399 --> 00:16:29,418
So something to think about there too, if you're having

483
00:16:29,739 --> 00:16:32,408
Uh, still having some reticence in the

484
00:16:32,408 --> 00:16:34,619
organization, and you don't want to drive the top-down mandate

485
00:16:34,619 --> 00:16:36,019
for all those reasons that I just said,

486
00:16:36,298 --> 00:16:38,538
but you do want to encourage all of your engineers

487
00:16:38,538 --> 00:16:40,639
to be able to take advantage of great new

488
00:16:40,639 --> 00:16:42,658
technology and to be able to learn new skill sets that

489
00:16:42,658 --> 00:16:44,700
are in all likelihood going to benefit them from the rest of

490
00:16:44,700 --> 00:16:45,460
their careers,

491
00:16:45,940 --> 00:16:48,099
right? So here's some data to

492
00:16:48,099 --> 00:16:48,879
suggest that when

493
00:16:49,219 --> 00:16:51,259
us uh stodgy

494
00:16:51,259 --> 00:16:53,330
staff engineers actually do start using this stuff the

495
00:16:53,330 --> 00:16:55,558
right way, we, we actually have better results

496
00:16:55,700 --> 00:16:59,308
with it. Um,

497
00:16:59,440 --> 00:17:00,710
this is pretty interesting too.

498
00:17:01,038 --> 00:17:03,558
We saw that traditional enterprises actually

499
00:17:03,558 --> 00:17:04,539
have higher,

500
00:17:04,818 --> 00:17:06,269
uh, daily AI usage.

501
00:17:06,640 --> 00:17:08,680
We saw smaller companies, and I'll show that

502
00:17:08,680 --> 00:17:09,239
in a minute,

503
00:17:09,529 --> 00:17:12,019
start adopting the technology sort of faster.

504
00:17:12,559 --> 00:17:15,199
But, um, I just did a, a

505
00:17:15,199 --> 00:17:16,818
read out on another Dora report,

506
00:17:17,279 --> 00:17:19,449
uh, literally in a panel like like 3 hours

507
00:17:19,449 --> 00:17:21,489
ago. That talked about

508
00:17:21,500 --> 00:17:23,618
one of the biggest indicators for like the

509
00:17:23,618 --> 00:17:25,140
good use of AI

510
00:17:25,539 --> 00:17:27,680
and some of you I'm sure are starting to come across this,

511
00:17:27,979 --> 00:17:30,358
is like clear AI policies

512
00:17:30,660 --> 00:17:32,318
and basic change management.

513
00:17:32,699 --> 00:17:34,759
And this is something that a lot of enterprises have

514
00:17:34,759 --> 00:17:35,858
already sort of perfected.

515
00:17:36,219 --> 00:17:38,259
So even though they might be a little slower on the rollout

516
00:17:38,259 --> 00:17:39,219
and things like that,

517
00:17:39,568 --> 00:17:41,608
the by the time they roll it out, there's higher

518
00:17:41,608 --> 00:17:43,318
usage, and I think that that's because

519
00:17:43,578 --> 00:17:45,618
um of enterprises already having a lot of

520
00:17:45,618 --> 00:17:47,660
health around change management and

521
00:17:47,660 --> 00:17:49,338
around clear AI policies. Um.

522
00:17:49,880 --> 00:17:51,598
It's a really good report by Dora,

523
00:17:52,130 --> 00:17:54,318
that has like a, it's called a Bayesian

524
00:17:54,318 --> 00:17:55,989
posterior distribution graph,

525
00:17:56,279 --> 00:17:57,739
and it's like kind of like these

526
00:17:58,000 --> 00:18:00,400
hills with a dotted line in the middle. And

527
00:18:00,400 --> 00:18:02,318
the the graph kind of tells you

528
00:18:02,838 --> 00:18:05,039
where you're going to see positive or negative impact

529
00:18:05,039 --> 00:18:07,160
across certain things, in this case with the use of AI

530
00:18:07,439 --> 00:18:09,549
and you want to be like on the right side of the dotted

531
00:18:09,549 --> 00:18:11,588
line. And you want this sharp kind

532
00:18:11,588 --> 00:18:13,588
of peak, because that sharp peak means that we have a lot

533
00:18:13,588 --> 00:18:15,630
of confidence in the data in that part of the

534
00:18:15,630 --> 00:18:17,910
report. And like mandatory training,

535
00:18:18,390 --> 00:18:19,568
clear AI policies,

536
00:18:19,949 --> 00:18:22,289
and time to learn an experiment were by far

537
00:18:22,289 --> 00:18:24,328
the leading indicators of people having

538
00:18:24,328 --> 00:18:26,390
a lot of health in the implementation of this stuff.

539
00:18:26,670 --> 00:18:28,750
And I think that again, that's something that's easier for

540
00:18:28,750 --> 00:18:31,108
enterprises to be able to initiate

541
00:18:31,108 --> 00:18:33,180
because they already have that kind of stuff. Like they

542
00:18:33,180 --> 00:18:35,229
already have these kind of programs that are in place and

543
00:18:35,229 --> 00:18:36,269
being used at scale.

544
00:18:36,699 --> 00:18:38,719
So it was interesting to see this. We, we, um,

545
00:18:38,769 --> 00:18:40,809
when Laura and I first kind of found this data, we were like, nah,

546
00:18:40,858 --> 00:18:41,640
that can't be right.

547
00:18:42,219 --> 00:18:44,618
But then we really started, I mean we resampled and resampled

548
00:18:44,618 --> 00:18:46,779
and we're like this is what the data is showing. But

549
00:18:46,779 --> 00:18:48,858
then when we really started thinking about it, and we started

550
00:18:48,858 --> 00:18:50,930
thinking about these variables, it kind of

551
00:18:50,930 --> 00:18:52,660
did become, you know, started to make sense.

552
00:18:53,920 --> 00:18:56,078
However, small companies are the smaller

553
00:18:56,078 --> 00:18:58,400
AI companies are using AI more frequently, right?

554
00:18:58,509 --> 00:18:59,719
So we see like the uh

555
00:19:00,000 --> 00:19:01,140
uh the heavy adoption

556
00:19:02,039 --> 00:19:03,699
with uh companies that are less than

557
00:19:04,118 --> 00:19:06,299
50 employees or 50 engineers,

558
00:19:06,559 --> 00:19:08,568
uh, are the ones that are reaching that heavy

559
00:19:08,568 --> 00:19:10,578
adoption phase faster, right?

560
00:19:11,078 --> 00:19:13,279
Um, so again, I mean, that's also

561
00:19:13,279 --> 00:19:15,469
not too surprising, right? Small, scrappy, not

562
00:19:15,469 --> 00:19:16,709
a lot of clear AI policies,

563
00:19:17,000 --> 00:19:19,009
this may not even necessarily be a good thing,

564
00:19:19,519 --> 00:19:21,459
you know, I mean like the unregulated.

565
00:19:22,180 --> 00:19:24,539
And unmonitored use of AI at scale

566
00:19:24,759 --> 00:19:27,199
can really bite us, can get us on the bottom side of that graph

567
00:19:27,199 --> 00:19:28,539
that we showed earlier, OK?

568
00:19:28,799 --> 00:19:31,000
So I think there's something uh interesting to

569
00:19:31,000 --> 00:19:32,858
consider there. Uh,

570
00:19:33,650 --> 00:19:35,890
so again, kind of within that

571
00:19:35,890 --> 00:19:37,890
um like that use that we see

572
00:19:37,890 --> 00:19:40,439
coming out of enterprises, it was also very

573
00:19:40,439 --> 00:19:41,900
interesting that um

574
00:19:42,529 --> 00:19:44,650
enterprises were leading in actual time

575
00:19:44,650 --> 00:19:46,689
savings. So when we actually start looking at

576
00:19:46,689 --> 00:19:48,459
the output metrics themselves,

577
00:19:48,729 --> 00:19:49,848
and we figure out like,

578
00:19:50,209 --> 00:19:52,489
you know, what, what actually

579
00:19:52,489 --> 00:19:53,689
has been the impact.

580
00:19:54,170 --> 00:19:56,400
All of these things like clear policies,

581
00:19:56,489 --> 00:19:58,489
like education, like all this stuff means

582
00:19:58,489 --> 00:20:00,729
that there's more efficacious use of

583
00:20:00,729 --> 00:20:01,299
AI

584
00:20:01,608 --> 00:20:03,729
in enterprises. So we're seeing like

585
00:20:03,729 --> 00:20:05,108
companies below 50,

586
00:20:06,130 --> 00:20:07,088
this is

587
00:20:07,598 --> 00:20:09,930
effectively the amount of additional PRs

588
00:20:09,930 --> 00:20:10,689
that they're shipping.

589
00:20:11,699 --> 00:20:13,858
Uh, sorry, this is the hours that they're actually saving,

590
00:20:14,150 --> 00:20:16,150
and we see enterprises over here on the

591
00:20:16,150 --> 00:20:18,368
right, uh, with 1,000+ engineers

592
00:20:18,828 --> 00:20:20,900
actually saving the most hours per week once

593
00:20:20,900 --> 00:20:22,848
they reach that sort of heavy adoption phase.

594
00:20:23,229 --> 00:20:25,229
Um, you know, there's some interesting trends here

595
00:20:25,229 --> 00:20:27,709
too, where we see these, um, you know, 500

596
00:20:27,709 --> 00:20:29,709
to 1000 engineers with light

597
00:20:29,709 --> 00:20:31,949
usage, uh, actually kind

598
00:20:31,949 --> 00:20:33,328
of lagging, right?

599
00:20:33,640 --> 00:20:35,769
Um, but yeah, very interesting data here too.

600
00:20:36,189 --> 00:20:38,118
But I think again, more food for thought that like.

601
00:20:38,578 --> 00:20:41,059
Going back to the first principles, the code hygiene,

602
00:20:41,140 --> 00:20:43,140
the compliance, the change management, like all

603
00:20:43,140 --> 00:20:45,180
these things are incredibly important for getting the

604
00:20:45,180 --> 00:20:47,259
most ROI and the best

605
00:20:47,259 --> 00:20:48,219
impact out of AI.

606
00:20:49,150 --> 00:20:51,239
All right, so, back to that graph

607
00:20:51,239 --> 00:20:53,479
where we said people that were never using AI were

608
00:20:53,479 --> 00:20:55,900
shipping an additional PR week using

609
00:20:56,199 --> 00:20:57,858
AI, right?

610
00:20:58,118 --> 00:20:59,779
Um, I think what's going on here,

611
00:21:00,078 --> 00:21:02,699
uh, and you're probably seeing this within your own

612
00:21:02,699 --> 00:21:04,828
organization. What we were reporting

613
00:21:04,828 --> 00:21:07,549
on were like enterprise APIs

614
00:21:07,549 --> 00:21:10,049
and telemetry coming out from enterprise APIs,

615
00:21:10,348 --> 00:21:12,519
meaning enterprise licenses, right?

616
00:21:12,630 --> 00:21:13,289
So if you bought

617
00:21:13,588 --> 00:21:15,588
enterprise co-pilot or cursor or something

618
00:21:15,588 --> 00:21:17,789
like that, the only metrics, the only uh

619
00:21:18,108 --> 00:21:20,150
usage that we're really able to get from a systems

620
00:21:20,150 --> 00:21:22,630
perspective is the telemetry coming out of those APIs.

621
00:21:22,828 --> 00:21:24,910
But remember I said before that DX captures

622
00:21:24,910 --> 00:21:27,348
qualitative and quantitative metrics.

623
00:21:27,750 --> 00:21:29,858
So what this was, was saying that even though

624
00:21:30,239 --> 00:21:32,279
the licenses didn't show that

625
00:21:32,279 --> 00:21:33,959
there was utilization of AI,

626
00:21:34,279 --> 00:21:36,279
we still had qualitative signals coming

627
00:21:36,279 --> 00:21:38,858
from people who were not using AI, quote unquote,

628
00:21:39,680 --> 00:21:41,979
you know, talking about significant time savings

629
00:21:42,279 --> 00:21:43,180
in what they're doing.

630
00:21:43,799 --> 00:21:45,959
So this is like 11%

631
00:21:45,959 --> 00:21:46,880
merged code.

632
00:21:47,209 --> 00:21:49,289
That was qualitatively reported as

633
00:21:49,289 --> 00:21:50,890
being written by AI

634
00:21:51,328 --> 00:21:53,449
by people who, according to the API had

635
00:21:53,449 --> 00:21:54,029
never used

636
00:21:54,608 --> 00:21:56,920
AI, right? So these are personal

637
00:21:56,920 --> 00:21:59,009
licenses for a cursor or people

638
00:21:59,009 --> 00:22:00,568
pumping stuff into Chat GPT,

639
00:22:01,049 --> 00:22:03,299
um, but this is something that really like,

640
00:22:03,489 --> 00:22:05,689
we're gonna have to get a handle on this, right? I mean,

641
00:22:05,848 --> 00:22:07,848
I am by no means a proponent of

642
00:22:07,848 --> 00:22:10,068
a single solution, you know, I think we need to

643
00:22:10,250 --> 00:22:12,729
be using multiple solutions, especially in enterprises

644
00:22:12,729 --> 00:22:14,789
right now where some of these procurement cycles can take.

645
00:22:14,969 --> 00:22:17,209
You know, 9 months to a year to actually roll

646
00:22:17,209 --> 00:22:19,299
something out, and by the time you do, like 3

647
00:22:19,299 --> 00:22:21,449
other technologies have leapfrogged it, I mean, things are just moving

648
00:22:21,449 --> 00:22:22,630
too quickly for that right now.

649
00:22:23,088 --> 00:22:25,209
But we are going to have to kind of unify if

650
00:22:25,209 --> 00:22:27,449
we really want to understand utilization,

651
00:22:27,489 --> 00:22:29,519
when we get into measurement in a moment, I'll

652
00:22:29,519 --> 00:22:30,709
talk about why that's important.

653
00:22:31,578 --> 00:22:33,769
The best way to measure this stuff is

654
00:22:33,769 --> 00:22:36,140
to correlate utilization, daily

655
00:22:36,140 --> 00:22:38,400
active weekly use amongst cohorts

656
00:22:38,689 --> 00:22:40,890
to our core and foundational productivity

657
00:22:40,890 --> 00:22:43,088
metrics that we've been able to trust for a long time,

658
00:22:43,380 --> 00:22:45,459
right? So our Dora, our space, our DevEx, our core

659
00:22:45,459 --> 00:22:47,739
four metrics, right? We want to see how utilization

660
00:22:47,739 --> 00:22:49,380
in these cohorts impacts

661
00:22:49,640 --> 00:22:51,318
those, those other metrics, but we'll get into that

662
00:22:51,578 --> 00:22:52,400
in a little bit.

663
00:22:52,779 --> 00:22:54,279
I just think it's very interesting

664
00:22:54,539 --> 00:22:56,769
to kind of see this data play out. This is one of those

665
00:22:56,769 --> 00:22:57,479
areas where

666
00:22:58,059 --> 00:23:00,019
although system metrics are certainly important.

667
00:23:00,489 --> 00:23:02,729
We need context coming from qualitative

668
00:23:02,729 --> 00:23:04,890
metrics to really understand like the full

669
00:23:04,890 --> 00:23:07,209
picture. Uh, we like to use a lot of health metaphors

670
00:23:07,209 --> 00:23:08,969
at DX, so it's kind of akin to like,

671
00:23:09,289 --> 00:23:11,410
you go to the doctor and you don't feel well, and

672
00:23:11,410 --> 00:23:13,449
you tell them I don't feel well, and then they take your pulse and your

673
00:23:13,449 --> 00:23:15,559
blood pressure, and they're like, well, you're, you're fine, all your metrics

674
00:23:15,559 --> 00:23:17,969
are, yeah, but I don't feel well, right? Like the context

675
00:23:17,969 --> 00:23:19,189
is very. Important there.

676
00:23:19,588 --> 00:23:21,818
And this is one of those areas where we're able to kind of

677
00:23:22,229 --> 00:23:23,729
pinpoint pretty clear

678
00:23:24,059 --> 00:23:26,068
shadow AI usage as a result of

679
00:23:26,068 --> 00:23:28,160
marrying telemetry and API metrics

680
00:23:28,160 --> 00:23:30,390
with qualitative and self-reported metrics. And

681
00:23:30,390 --> 00:23:32,880
let me be clear too, we're talking about surveys with 90%

682
00:23:32,880 --> 00:23:35,189
plus participation rates. These are like

683
00:23:35,189 --> 00:23:36,229
strong signals.

684
00:23:37,789 --> 00:23:39,779
Uh, no big surprise here.

685
00:23:40,108 --> 00:23:42,390
AI is delivering bigger gains in modern

686
00:23:42,390 --> 00:23:44,509
languages, right? So we see like Golang,

687
00:23:44,670 --> 00:23:46,779
Python, Rust, JavaScript here

688
00:23:46,779 --> 00:23:47,289
on the left.

689
00:23:47,868 --> 00:23:49,809
On the right we see poor old Cobalt.

690
00:23:50,269 --> 00:23:52,269
I was actually just talking to a new friend

691
00:23:52,269 --> 00:23:54,509
of mine from Atlassian. DX was acquired

692
00:23:54,509 --> 00:23:56,549
by Atlassian back on the 10th of this

693
00:23:56,549 --> 00:23:58,828
month. Uh, and they needed

694
00:23:58,828 --> 00:23:59,769
somebody to ask them

695
00:24:00,430 --> 00:24:03,049
to, uh, effectively

696
00:24:03,049 --> 00:24:03,769
figure out

697
00:24:04,068 --> 00:24:06,750
whether, uh, in this case, RoboDev

698
00:24:07,029 --> 00:24:09,189
would be capable of an end to end conversion of

699
00:24:09,189 --> 00:24:10,049
cobalt code

700
00:24:10,338 --> 00:24:11,068
to Java code.

701
00:24:12,289 --> 00:24:13,799
So he needed a demo for this.

702
00:24:14,358 --> 00:24:16,828
Turns out, there's a Minecraft server

703
00:24:17,650 --> 00:24:18,608
coded in cobalt,

704
00:24:18,890 --> 00:24:19,880
an open source one.

705
00:24:20,170 --> 00:24:22,309
And so he used that to start doing it and, you know,

706
00:24:22,529 --> 00:24:25,150
uh it's much better at interpreting.

707
00:24:25,289 --> 00:24:25,900
Um,

708
00:24:26,410 --> 00:24:28,449
uh, Morgan Stanley has been very public

709
00:24:28,449 --> 00:24:30,689
about their creation of an AI agent called

710
00:24:30,689 --> 00:24:31,689
DevGen AI.

711
00:24:32,588 --> 00:24:34,809
Uh, and what DevGen AI does is reverse

712
00:24:34,809 --> 00:24:35,930
engineering of legacy code.

713
00:24:36,338 --> 00:24:38,459
So you can imagine Morgan Stanley has a bunch of legacy

714
00:24:38,459 --> 00:24:40,160
code laying around, they got mainframe natural,

715
00:24:40,500 --> 00:24:42,578
they have Cobalt. I hate to admit it because I used to

716
00:24:42,578 --> 00:24:44,199
write a lot of Perl, but Perl

717
00:24:44,618 --> 00:24:45,618
considered legacy now.

718
00:24:46,039 --> 00:24:48,209
Rather than a full end to end translation

719
00:24:48,209 --> 00:24:48,809
solution though,

720
00:24:49,098 --> 00:24:51,459
because it's difficult to get the full, you know, context

721
00:24:51,459 --> 00:24:52,689
and everything like that from Cobalt.

722
00:24:53,019 --> 00:24:55,059
They're just creating developer specs from all this

723
00:24:55,059 --> 00:24:57,088
legacy code, right? So the, the, the

724
00:24:57,088 --> 00:24:59,420
bots seem to be better at at least interpreting cobalt

725
00:24:59,420 --> 00:25:01,219
than necessarily transcribing it, right?

726
00:25:01,529 --> 00:25:04,078
Um, but yeah, this is across 23,500

727
00:25:04,078 --> 00:25:05,618
developers over 48 companies,

728
00:25:05,930 --> 00:25:07,959
and we again see that as the languages get

729
00:25:07,959 --> 00:25:08,750
a little bit older,

730
00:25:09,049 --> 00:25:11,150
um, the, the AI is just not as,

731
00:25:11,160 --> 00:25:13,170
as good, and that's because of the stuff that it was trained

732
00:25:13,170 --> 00:25:15,199
on. Um, also, some of it

733
00:25:15,199 --> 00:25:17,299
is like thinking about the domain specific

734
00:25:17,449 --> 00:25:19,449
specificity of some of these languages, like for

735
00:25:19,449 --> 00:25:21,549
instance, JavaScript, like of course React and

736
00:25:21,549 --> 00:25:23,029
TypeScript is like works pretty well

737
00:25:23,640 --> 00:25:24,489
with these assistants,

738
00:25:24,809 --> 00:25:27,049
because it's just code that's running in the browser, right? Even

739
00:25:27,049 --> 00:25:29,289
if you're writing like crazy JavaScript

740
00:25:29,289 --> 00:25:31,144
that's somewhat. Domain specific.

741
00:25:31,483 --> 00:25:33,884
The semantics of the code itself are still bounded

742
00:25:33,884 --> 00:25:36,005
and standardized by the

743
00:25:36,005 --> 00:25:37,993
DOM and the browser itself,

744
00:25:38,334 --> 00:25:40,473
right? So the AI doesn't, it's,

745
00:25:40,483 --> 00:25:42,555
it's much different than trying to interpret

746
00:25:42,555 --> 00:25:44,625
and understand a bunch of backend code that might

747
00:25:44,625 --> 00:25:46,644
have a lot of domain specific semantics and things like

748
00:25:46,644 --> 00:25:48,644
that. But yeah, pretty satisfying

749
00:25:48,644 --> 00:25:49,344
graph here too,

750
00:25:49,884 --> 00:25:51,364
but I wouldn't say terribly surprising.

751
00:25:52,630 --> 00:25:53,449
This one's big

752
00:25:54,118 --> 00:25:56,640
Uh, there's a significant

753
00:25:56,640 --> 00:25:58,459
impact on just overall

754
00:25:58,759 --> 00:25:59,509
onboarding,

755
00:25:59,838 --> 00:26:02,709
right? So what this is, is across 14,000

756
00:26:02,709 --> 00:26:04,949
developers, the number of days that it took to onboard

757
00:26:04,949 --> 00:26:07,318
a new resource either into a

758
00:26:07,318 --> 00:26:09,680
like an organization or a project.

759
00:26:10,078 --> 00:26:11,799
And I mean, look at this rampdown.

760
00:26:12,118 --> 00:26:14,299
Coming from back in Q1 of 2024,

761
00:26:14,880 --> 00:26:17,390
before AI has sort of like, you know, begun to proliferate,

762
00:26:17,640 --> 00:26:18,699
you know, we're looking at

763
00:26:19,000 --> 00:26:21,000
this 78 day ramp

764
00:26:21,000 --> 00:26:23,118
time. And we have more than cut that

765
00:26:23,118 --> 00:26:25,180
in half now, on average.

766
00:26:25,598 --> 00:26:27,750
Uh, Zapier, uh, is,

767
00:26:27,759 --> 00:26:29,818
in my opinion, doing really, really well

768
00:26:30,160 --> 00:26:32,318
with AI agents, which shouldn't like surprise

769
00:26:32,318 --> 00:26:34,029
anybody, they're like an automation first company.

770
00:26:34,400 --> 00:26:36,559
But I got a chance to speak to one of the folks who

771
00:26:36,559 --> 00:26:38,799
works on, you know, building agents and AI

772
00:26:38,799 --> 00:26:39,640
for Zapier,

773
00:26:40,160 --> 00:26:42,229
and um they've done all kinds of stuff. They, they

774
00:26:42,229 --> 00:26:44,479
love to joke that they've got more bots than humans at Zapier

775
00:26:44,479 --> 00:26:46,680
and everything like that. They have a really nice grassroots

776
00:26:46,680 --> 00:26:47,858
program for building agents.

777
00:26:48,259 --> 00:26:50,618
And one of the things that they've been able to do is move their onboarding

778
00:26:50,618 --> 00:26:52,900
time from 30 days down to 2 weeks,

779
00:26:53,219 --> 00:26:55,259
right, so effective time from an engineer now coming

780
00:26:55,259 --> 00:26:57,578
in uh less than half of what it was

781
00:26:57,578 --> 00:26:59,858
before. They're also able to get about 15%

782
00:26:59,858 --> 00:27:01,680
more productivity out of every engineer.

783
00:27:02,029 --> 00:27:04,328
So they're doing what I think everybody should be doing. They're

784
00:27:04,328 --> 00:27:05,479
hiring more,

785
00:27:05,939 --> 00:27:08,140
right? They know that they can make these resources

786
00:27:08,140 --> 00:27:09,078
more valuable,

787
00:27:09,338 --> 00:27:09,930
faster,

788
00:27:10,219 --> 00:27:12,279
and then they know that they can get more return on investment out

789
00:27:12,279 --> 00:27:13,209
of a single hire.

790
00:27:13,500 --> 00:27:15,519
So they're hiring faster than they ever have.

791
00:27:16,029 --> 00:27:18,140
Right? Now I mean I talk a lot, I have other workshops

792
00:27:18,140 --> 00:27:20,269
where I talk about the importance of psychological safety

793
00:27:20,269 --> 00:27:21,269
and the adoption of AI.

794
00:27:21,588 --> 00:27:23,608
And one big bit of uh psychological

795
00:27:23,608 --> 00:27:25,630
safety is making sure that as leaders, we are very clear,

796
00:27:25,670 --> 00:27:27,549
like we are augmenting

797
00:27:27,868 --> 00:27:29,019
with this technology,

798
00:27:29,430 --> 00:27:31,680
right? This technology is not ready to

799
00:27:31,680 --> 00:27:33,989
replace. And I can cite multiple examples

800
00:27:33,989 --> 00:27:35,989
of companies that have been very public about saying

801
00:27:35,989 --> 00:27:37,239
we're gonna fire half our engineers,

802
00:27:37,588 --> 00:27:38,818
and then we're gonna replace them with agents.

803
00:27:39,209 --> 00:27:41,358
And it doesn't work, and then they have to rehire

804
00:27:41,358 --> 00:27:43,529
those folks, but no one wants to work for them because they ruin

805
00:27:43,529 --> 00:27:45,568
their reputation by hire by firing everybody,

806
00:27:45,650 --> 00:27:47,689
right? We have to really remember now that this

807
00:27:47,689 --> 00:27:49,930
is about augmentation, but this is a perfect

808
00:27:49,930 --> 00:27:52,009
example of how we can really get more value, how we can make

809
00:27:52,009 --> 00:27:52,630
a resource

810
00:27:53,328 --> 00:27:55,670
by using agents and using various forms of AI

811
00:27:55,670 --> 00:27:57,719
more valuable to the company more quickly. And

812
00:27:57,719 --> 00:27:59,719
I think Zapier is an excellent example of that. I'll have

813
00:27:59,719 --> 00:28:01,769
a newsletter article coming about coming

814
00:28:01,769 --> 00:28:03,009
out about that interview pretty soon.

815
00:28:03,559 --> 00:28:05,838
Um, but I really do think that that's, it was very inspirational

816
00:28:05,838 --> 00:28:07,818
and even refreshing for me to kind of

817
00:28:08,078 --> 00:28:10,130
talk to that person and hear that coming from, from

818
00:28:10,130 --> 00:28:10,699
Zapier.

819
00:28:11,799 --> 00:28:12,318
OK.

820
00:28:13,059 --> 00:28:15,318
We're also having to redefine

821
00:28:15,529 --> 00:28:16,900
the notion of a builder

822
00:28:17,180 --> 00:28:19,660
in the organization, right? So traditional non-builders

823
00:28:19,660 --> 00:28:21,049
now are shipping much more code.

824
00:28:21,338 --> 00:28:23,500
We're seeing engineering managers actually shipping twice

825
00:28:23,500 --> 00:28:25,660
as much code uh as they were as a

826
00:28:25,660 --> 00:28:26,289
result of AI.

827
00:28:26,779 --> 00:28:28,858
Um, this is also being reflected

828
00:28:28,858 --> 00:28:30,900
as I look at a moment like project managers and stuff, but

829
00:28:30,900 --> 00:28:32,920
we have to start rethinking like who's a developer,

830
00:28:33,380 --> 00:28:34,598
right? Um,

831
00:28:34,939 --> 00:28:37,059
you know, when you have project managers that are able to crank

832
00:28:37,059 --> 00:28:38,420
out like decent prototypes.

833
00:28:38,868 --> 00:28:41,009
When you have engineering managers that can now like

834
00:28:41,009 --> 00:28:43,068
take on a player-coach role, but

835
00:28:43,068 --> 00:28:45,019
like not in a bad way where they're overwhelmed,

836
00:28:45,328 --> 00:28:47,390
you know, where they're actually getting a chance to contribute to code

837
00:28:47,390 --> 00:28:49,568
bases along with uh managing teams,

838
00:28:49,868 --> 00:28:51,848
that's, that's a fundamentally different world.

839
00:28:52,150 --> 00:28:53,709
And I think makes for a better manager,

840
00:28:54,068 --> 00:28:56,068
right? I mean somebody who's going to be able to kind of

841
00:28:56,068 --> 00:28:58,170
understand, you know, the weeds of what's going on

842
00:28:58,170 --> 00:28:59,848
and actually be able to contribute,

843
00:29:00,108 --> 00:29:01,729
uh, I think is gonna have better empathy

844
00:29:02,189 --> 00:29:04,009
uh and better managerial capabilities

845
00:29:04,469 --> 00:29:05,828
for uh for their engineers.

846
00:29:07,279 --> 00:29:08,078
Same with uh

847
00:29:08,410 --> 00:29:09,539
designers and PMs.

848
00:29:09,838 --> 00:29:10,979
Uh, we're seeing uh

849
00:29:11,318 --> 00:29:13,719
um uh, you know, 7.4%

850
00:29:13,719 --> 00:29:14,858
daily active use

851
00:29:15,160 --> 00:29:16,420
uh for designers

852
00:29:16,719 --> 00:29:18,259
and uh project managers.

853
00:29:18,680 --> 00:29:20,699
Uh, and I, I don't think that's too surprising.

854
00:29:20,729 --> 00:29:21,719
I mean like Figma.

855
00:29:22,160 --> 00:29:24,199
Has one of the most powerful MCP servers

856
00:29:24,199 --> 00:29:26,199
out there, like it's really, really good. And you

857
00:29:26,199 --> 00:29:28,269
know, you can have project managers now. Canva's been

858
00:29:28,269 --> 00:29:29,219
really public about

859
00:29:29,479 --> 00:29:31,380
having uh their project managers,

860
00:29:31,680 --> 00:29:33,880
uh, they've built a small agent that allows

861
00:29:33,880 --> 00:29:36,078
project managers to uh natural language

862
00:29:36,078 --> 00:29:37,500
what they want the product to do.

863
00:29:38,209 --> 00:29:40,449
And then it goes into MCP via Figma

864
00:29:40,449 --> 00:29:42,650
and it creates like a prototype, and it creates

865
00:29:42,650 --> 00:29:44,809
like nice developer

866
00:29:44,809 --> 00:29:45,868
friendly specifications.

867
00:29:46,529 --> 00:29:48,568
So not only is it easier for the p.m.s to put

868
00:29:48,568 --> 00:29:50,890
the PRDs together, but that translation

869
00:29:50,890 --> 00:29:51,449
layer

870
00:29:51,729 --> 00:29:53,838
of like what is this project requirement

871
00:29:53,838 --> 00:29:56,289
supposed to do, and the developer actually being able to

872
00:29:56,289 --> 00:29:58,489
understand that in their own vernacular is another

873
00:29:58,489 --> 00:30:00,789
friction point that's been fixed by that

874
00:30:00,930 --> 00:30:01,449
agent,

875
00:30:01,858 --> 00:30:04,229
right? So, yeah, we have to really start rethinking

876
00:30:04,650 --> 00:30:05,229
um.

877
00:30:06,209 --> 00:30:08,219
Who's a developer in the organization anymore when

878
00:30:08,219 --> 00:30:10,299
we're actually able to elevate traditional

879
00:30:10,299 --> 00:30:12,608
non-builders and have them make contributions

880
00:30:12,608 --> 00:30:14,670
like this. All right,

881
00:30:14,920 --> 00:30:15,920
so that's a lot of good news.

882
00:30:17,259 --> 00:30:19,410
But uh here is a very important point

883
00:30:19,789 --> 00:30:21,130
that I think we all need to remember

884
00:30:21,509 --> 00:30:22,229
is that

885
00:30:22,539 --> 00:30:24,969
there are still so many pain points

886
00:30:25,588 --> 00:30:26,400
for

887
00:30:26,670 --> 00:30:28,750
engineers that have nothing to do with the

888
00:30:28,750 --> 00:30:29,469
generation of code,

889
00:30:29,789 --> 00:30:32,009
that are absolutely eclipsing

890
00:30:32,309 --> 00:30:34,368
the time savings that we're seeing coming

891
00:30:34,368 --> 00:30:35,670
from, you know, AI.

892
00:30:36,150 --> 00:30:38,170
So when we annualize this, that pale

893
00:30:38,868 --> 00:30:41,108
bar there in the middle is overall annualized

894
00:30:41,108 --> 00:30:42,029
time savings

895
00:30:42,630 --> 00:30:43,439
across, uh,

896
00:30:43,709 --> 00:30:45,750
this is a sample of 134,000

897
00:30:45,750 --> 00:30:46,289
developers.

898
00:30:47,170 --> 00:30:49,189
Yeah, 134,000 developers.

899
00:30:50,219 --> 00:30:52,439
That AI time savings, it's not insignificant,

900
00:30:52,939 --> 00:30:55,618
but it is absolutely eclipsed by interruption, frequency,

901
00:30:56,180 --> 00:30:58,459
so context switching throughout the day

902
00:30:58,459 --> 00:30:59,759
from various sources,

903
00:31:00,130 --> 00:31:02,130
uh, and, uh, meeting heavy days,

904
00:31:02,338 --> 00:31:04,400
right? We, we all know that, right? What a

905
00:31:04,400 --> 00:31:06,118
developer's always I have too many meetings, right?

906
00:31:06,618 --> 00:31:08,739
There's some stuff that we can do around this that

907
00:31:08,750 --> 00:31:09,779
that AI can help with.

908
00:31:10,219 --> 00:31:12,259
You know, like going back to Zapier, they've reduced

909
00:31:12,259 --> 00:31:14,299
their daily stand-ups from 5 days a week to

910
00:31:14,299 --> 00:31:16,739
2 days a week, because they're doing like summary

911
00:31:16,739 --> 00:31:18,818
of meetings and and change logs and things like

912
00:31:18,818 --> 00:31:20,900
that, and using asynchronous updates instead

913
00:31:20,900 --> 00:31:21,809
of running stand-ups.

914
00:31:22,259 --> 00:31:24,289
But there's also some old school business stuff that

915
00:31:24,289 --> 00:31:25,439
we can apply here too.

916
00:31:25,739 --> 00:31:27,900
Like I'm a huge Ellie Goldrot theory of constraints

917
00:31:27,900 --> 00:31:29,989
fan. And one of the thinking

918
00:31:29,989 --> 00:31:32,059
models in the theory of constraints is something called

919
00:31:32,059 --> 00:31:34,140
the evaporating cloud. And if you've not

920
00:31:34,140 --> 00:31:36,489
heard about that before, it's definitely worth looking into.

921
00:31:37,019 --> 00:31:38,279
It's a way of reducing

922
00:31:38,660 --> 00:31:40,509
assumed dependencies

923
00:31:40,890 --> 00:31:42,049
within an organization,

924
00:31:42,338 --> 00:31:44,368
which can have the net effect of reducing the

925
00:31:44,368 --> 00:31:45,318
number of meetings

926
00:31:45,660 --> 00:31:47,739
in that organization. So there's non-AI

927
00:31:47,739 --> 00:31:49,779
stuff and AI stuff that we can do to deal with

928
00:31:49,779 --> 00:31:51,848
some of this. Interruption, frequency and

929
00:31:51,848 --> 00:31:54,500
context switching, like I can't emphasize

930
00:31:54,500 --> 00:31:55,039
enough

931
00:31:55,380 --> 00:31:57,848
how detrimental this is to

932
00:31:57,848 --> 00:31:58,680
organizational productivity.

933
00:31:59,019 --> 00:32:00,318
There have been a number of studies.

934
00:32:00,699 --> 00:32:02,818
One of them is called The Coding War Games. Anybody ever

935
00:32:02,818 --> 00:32:04,160
read the book PeopleSoft?

936
00:32:04,939 --> 00:32:06,239
Tom DeMarco, Timothy Lister,

937
00:32:06,578 --> 00:32:08,618
great book. Totally still, this is one that I keep

938
00:32:08,618 --> 00:32:10,739
in my desk, not even on my bookshelf, and I referenced

939
00:32:10,739 --> 00:32:11,500
it a fair amount.

940
00:32:11,818 --> 00:32:13,858
Um it was a series of studies that started in the, in

941
00:32:13,858 --> 00:32:14,838
the late 70s.

942
00:32:15,189 --> 00:32:17,568
And engineers took part

943
00:32:17,759 --> 00:32:20,068
across about 100 organizations in the first study,

944
00:32:20,289 --> 00:32:22,400
and there were about 700 engineers that

945
00:32:22,400 --> 00:32:23,479
took place in this first study.

946
00:32:23,838 --> 00:32:26,180
So you had engineers within a single organization

947
00:32:26,358 --> 00:32:27,039
competing

948
00:32:27,479 --> 00:32:29,989
in this study, and then you also had full

949
00:32:29,989 --> 00:32:31,489
organizations competing against each other.

950
00:32:31,838 --> 00:32:33,818
Now they found some really striking stuff.

951
00:32:34,828 --> 00:32:35,769
First off was that

952
00:32:36,118 --> 00:32:38,130
Across organizations, there was

953
00:32:38,130 --> 00:32:40,489
an 11x difference in productivity.

954
00:32:40,529 --> 00:32:42,670
You had some organizations that were 11 times

955
00:32:42,670 --> 00:32:45,279
as productive as the lowest performing

956
00:32:45,279 --> 00:32:46,130
organizations in the study.

957
00:32:47,348 --> 00:32:49,618
Within a single organization, there was only

958
00:32:49,618 --> 00:32:51,130
a 20% difference

959
00:32:51,420 --> 00:32:53,578
between top performers and lower performers. Now

960
00:32:53,578 --> 00:32:55,910
anybody familiar with systems thinking or profound knowledge

961
00:32:55,910 --> 00:32:57,390
or the work of W. Edwards Demming,

962
00:32:57,709 --> 00:32:58,979
this should not surprise you.

963
00:32:59,380 --> 00:33:01,469
90 to 95% of the productivity

964
00:33:01,469 --> 00:33:03,848
output of an organization is predicted by the system

965
00:33:04,229 --> 00:33:05,229
and not the worker,

966
00:33:05,588 --> 00:33:07,828
right? So what we see here is that even the most

967
00:33:07,828 --> 00:33:09,049
amazing developers

968
00:33:09,650 --> 00:33:11,660
are constrained by the systems and process and culture in

969
00:33:11,660 --> 00:33:12,328
which they're working.

970
00:33:13,309 --> 00:33:15,400
Some of the non-factors in the study were things

971
00:33:15,400 --> 00:33:16,140
like language.

972
00:33:16,549 --> 00:33:18,630
You know, people hypothesized, oh well, so they must be

973
00:33:18,630 --> 00:33:19,920
using some really high performance, no,

974
00:33:20,199 --> 00:33:22,239
the only, the the only lower performers really

975
00:33:22,239 --> 00:33:24,479
in that study that were significant were assembly

976
00:33:24,479 --> 00:33:25,578
developers.

977
00:33:26,000 --> 00:33:27,900
Um, they thought that maybe salary

978
00:33:28,199 --> 00:33:29,338
would be impacting this.

979
00:33:29,799 --> 00:33:32,160
Only a 10% difference in salary between the highest

980
00:33:32,160 --> 00:33:34,019
performers and the lowest performers in this study.

981
00:33:34,439 --> 00:33:36,469
What they did find was when they answered

982
00:33:36,469 --> 00:33:38,680
questions like, do people often interrupt

983
00:33:38,680 --> 00:33:39,479
you needlessly?

984
00:33:39,910 --> 00:33:42,029
The top performing organizations in that

985
00:33:42,029 --> 00:33:44,430
study overwhelmingly had people say

986
00:33:44,430 --> 00:33:46,578
no. So the

987
00:33:46,578 --> 00:33:48,618
things like divert your phone calls, this is back in the day, we

988
00:33:48,618 --> 00:33:50,670
had chunky conference phones and stuff like, but can

989
00:33:50,670 --> 00:33:52,699
you divert, the same thing as Slack, Teams, anything

990
00:33:52,699 --> 00:33:54,900
now. Like 5 times as many

991
00:33:54,900 --> 00:33:56,900
people in the top performing

992
00:33:56,900 --> 00:33:59,059
organizations answered positively that they could divert

993
00:33:59,059 --> 00:34:00,000
their calls,

994
00:34:00,420 --> 00:34:02,500
right? So this all came down to

995
00:34:02,500 --> 00:34:04,219
like encouraging flow state,

996
00:34:04,500 --> 00:34:06,660
minimizing context switching, like these

997
00:34:06,660 --> 00:34:08,820
were the biggest indicators, and, and I think we're we're

998
00:34:08,820 --> 00:34:10,820
still seeing this here, right? Where it's like, yeah, we're

999
00:34:10,820 --> 00:34:12,409
getting some good time savings from AI

1000
00:34:12,820 --> 00:34:14,800
but our time syncs are still eclipsing that.

1001
00:34:15,059 --> 00:34:17,128
And there's stuff that we have to do with our system and our process and

1002
00:34:17,128 --> 00:34:18,019
our culture to fix that.

1003
00:34:18,809 --> 00:34:20,809
There's a well defined

1004
00:34:20,809 --> 00:34:23,128
neuroscience in place here too, and I, this

1005
00:34:23,128 --> 00:34:25,168
is part of why I love focusing on developer

1006
00:34:25,168 --> 00:34:26,059
experience. Um,

1007
00:34:26,449 --> 00:34:28,570
I've spent the last 7 years of my career or so just

1008
00:34:28,570 --> 00:34:30,800
singularly focused on developer experience, study, and

1009
00:34:30,800 --> 00:34:31,309
productivity,

1010
00:34:31,639 --> 00:34:32,429
and it's this wonderful

1011
00:34:32,909 --> 00:34:34,110
sort of confluence of

1012
00:34:34,489 --> 00:34:36,909
engineering and psychology and cognitive science

1013
00:34:37,168 --> 00:34:38,079
and neuroscience.

1014
00:34:38,719 --> 00:34:40,760
And there's a lot of really good details out there. There's a great

1015
00:34:40,760 --> 00:34:42,659
Scientific American article that came out,

1016
00:34:43,000 --> 00:34:44,619
um, just a few months ago,

1017
00:34:44,878 --> 00:34:47,059
that studied flow state in

1018
00:34:47,059 --> 00:34:48,918
like improv jazz guitarists.

1019
00:34:49,378 --> 00:34:52,019
They can go into flow state almost immediately.

1020
00:34:52,519 --> 00:34:54,590
And so of course we did what we did, we put brain caps on them

1021
00:34:54,590 --> 00:34:56,590
while they were playing guitar, try to figure out what what was

1022
00:34:56,590 --> 00:34:58,889
happening with them. And it was fascinating, like

1023
00:34:58,889 --> 00:35:01,050
we've all experienced flow, and we

1024
00:35:01,050 --> 00:35:03,079
know how productive we are in that state. We know that that's

1025
00:35:03,079 --> 00:35:05,079
our most, the highest innovative capability

1026
00:35:05,079 --> 00:35:07,090
and most creative time when we're experiencing flow, and

1027
00:35:07,090 --> 00:35:09,010
it feels good and it's satisfying work.

1028
00:35:09,369 --> 00:35:10,429
And what's happening is

1029
00:35:10,688 --> 00:35:12,708
long-term knowledge from the back of the brain

1030
00:35:13,010 --> 00:35:15,139
is getting shuffled into the prefrontal cortex,

1031
00:35:15,449 --> 00:35:17,530
and it's going back and forth and taking over some of the

1032
00:35:17,530 --> 00:35:19,610
executive functioning, which is where that timelessness

1033
00:35:19,610 --> 00:35:21,530
sort of comes from that we feel when we're in that state.

1034
00:35:21,909 --> 00:35:23,989
And we're flaring off norepinephrine and

1035
00:35:23,989 --> 00:35:26,188
dopamine and serotonin and all the great feel-good

1036
00:35:26,188 --> 00:35:27,668
neurotransmitters when we're doing that.

1037
00:35:28,530 --> 00:35:31,128
So the brain quite intentionally separates

1038
00:35:31,128 --> 00:35:32,148
work throughout the day

1039
00:35:32,489 --> 00:35:34,610
into these sort of chemical chapters of

1040
00:35:34,610 --> 00:35:35,309
flow

1041
00:35:35,969 --> 00:35:37,269
and then context switch.

1042
00:35:38,250 --> 00:35:40,469
So something interesting happens in the prefrontal cortex

1043
00:35:40,648 --> 00:35:42,760
when we get out of flow or are pulled out of flow.

1044
00:35:43,090 --> 00:35:45,599
The brain releases the glutamate neurotoxin

1045
00:35:45,599 --> 00:35:47,039
into the prefrontal cortex.

1046
00:35:47,329 --> 00:35:49,320
And says, OK, we're done with this chapter of work,

1047
00:35:49,610 --> 00:35:51,648
here's some glutamate. Then we reach a point

1048
00:35:51,648 --> 00:35:53,809
where we reach a threshold where we experience cognitive

1049
00:35:53,809 --> 00:35:54,469
fatigue.

1050
00:35:54,889 --> 00:35:57,079
Right? We have too much uh glutamate going on in the

1051
00:35:57,079 --> 00:35:59,148
prefrontal cortex, and so it's time to stop working

1052
00:35:59,329 --> 00:36:01,329
and get some rest. Or if we're gonna keep

1053
00:36:01,329 --> 00:36:03,228
working, it's not gonna be our best work.

1054
00:36:03,809 --> 00:36:06,050
Right? That's the funny thing about cognitive uh

1055
00:36:06,159 --> 00:36:06,769
fatigue,

1056
00:36:07,300 --> 00:36:09,409
especially in Western culture, like we're very productivity

1057
00:36:09,409 --> 00:36:11,489
focused, and so even when we're tired, we sometimes

1058
00:36:11,489 --> 00:36:12,369
still have to do work.

1059
00:36:12,679 --> 00:36:14,728
Um, but the thing is that it's really hard to

1060
00:36:14,728 --> 00:36:16,969
elevate that work, it's really hard to innovate,

1061
00:36:17,010 --> 00:36:19,128
it's really hard to be our most creative selves when

1062
00:36:19,128 --> 00:36:20,409
we're in that state of cognitive fatigue.

1063
00:36:20,688 --> 00:36:22,918
So a lot of the study of developer experience is really focusing

1064
00:36:22,918 --> 00:36:23,869
on how do we extend

1065
00:36:24,449 --> 00:36:26,570
these flow state chapters as long as we can.

1066
00:36:27,050 --> 00:36:29,289
To minimize context switching throughout the day,

1067
00:36:29,458 --> 00:36:31,769
to minimize the overall amount of of cognitive fatigue,

1068
00:36:31,780 --> 00:36:33,878
and it's, it's, it's kind of,

1069
00:36:34,500 --> 00:36:36,530
it's kind of weird to think about, but there's absolutely

1070
00:36:36,530 --> 00:36:37,559
a relationship

1071
00:36:38,139 --> 00:36:40,260
between, you know, a software-driven culture like

1072
00:36:40,260 --> 00:36:40,780
ours,

1073
00:36:41,139 --> 00:36:43,260
and the capacity for global innovation,

1074
00:36:43,619 --> 00:36:45,820
and the amount of context switching that our

1075
00:36:45,820 --> 00:36:47,820
engineers are having to deal with, right?

1076
00:36:48,119 --> 00:36:50,199
So I, I spend a lot of time on this because I think it's really,

1077
00:36:50,239 --> 00:36:52,438
really important, like we often kind of blow off this notion

1078
00:36:52,438 --> 00:36:54,458
of like, oh well, I just get slacks all day

1079
00:36:54,458 --> 00:36:56,599
and or I'm in too many meetings and it's like this

1080
00:36:56,599 --> 00:36:58,320
is, this is a big problem.

1081
00:36:58,719 --> 00:37:00,719
And it's not something that we can fully solve with

1082
00:37:00,719 --> 00:37:02,860
AI. So AI is great for a lot of things,

1083
00:37:03,239 --> 00:37:05,280
not a silver bullet. And there's some other time things

1084
00:37:05,280 --> 00:37:07,519
here too, like build and and and and test

1085
00:37:07,519 --> 00:37:09,059
time, right? I used to work for Gradle.

1086
00:37:09,320 --> 00:37:11,639
It was my first real foray into developer productivity

1087
00:37:11,639 --> 00:37:14,219
engineering. We focused a lot on interloop optimization,

1088
00:37:14,429 --> 00:37:16,800
like reducing build times, reducing test cycle times,

1089
00:37:17,119 --> 00:37:18,320
failure rates and stuff like that.

1090
00:37:18,849 --> 00:37:20,878
Still, I mean like you start combining some of these

1091
00:37:20,878 --> 00:37:22,909
things like developer environment, toil,

1092
00:37:23,280 --> 00:37:24,228
review wait time,

1093
00:37:24,599 --> 00:37:26,958
build and test uh cycle time, you start compounding

1094
00:37:26,958 --> 00:37:29,159
these, and they also eclipse the savings

1095
00:37:29,159 --> 00:37:30,139
that we're getting from

1096
00:37:30,438 --> 00:37:32,500
AI. OK,

1097
00:37:32,800 --> 00:37:34,840
uh, what about some things that really do save us

1098
00:37:34,840 --> 00:37:36,898
some time? So here's another study that we did,

1099
00:37:37,320 --> 00:37:38,659
uh, you're welcome to download.

1100
00:37:39,079 --> 00:37:41,559
Um, this was a study that we put together

1101
00:37:41,559 --> 00:37:43,639
where we wanted, you know, we started capturing AI

1102
00:37:43,639 --> 00:37:45,938
and ROI metrics a while ago in our platform.

1103
00:37:46,360 --> 00:37:48,360
And we wanted to just help, we

1104
00:37:48,360 --> 00:37:49,820
wanted to create a resource

1105
00:37:50,119 --> 00:37:52,519
that could help our customers see better ROI.

1106
00:37:52,840 --> 00:37:54,878
And of course we found overwhelmingly that education

1107
00:37:54,878 --> 00:37:57,199
and enablement had a lot to do with like making this

1108
00:37:57,199 --> 00:37:58,019
technology work really well.

1109
00:37:58,809 --> 00:38:00,849
So we did a study where we came

1110
00:38:00,849 --> 00:38:02,889
across engineers who were reporting at least 1 hour a

1111
00:38:02,889 --> 00:38:04,929
week of time savings when we did this, and

1112
00:38:04,929 --> 00:38:07,010
we surveyed them. And it was a very simple survey, it was

1113
00:38:07,010 --> 00:38:09,128
just like, please stack rank what you think your top 5

1114
00:38:09,128 --> 00:38:10,849
most valuable use cases are for AI.

1115
00:38:11,708 --> 00:38:13,909
And we did similar stuff with uh S Levels

1116
00:38:13,909 --> 00:38:15,949
who had already rolled out AIs like successfully to

1117
00:38:15,949 --> 00:38:17,070
thousands of engineers,

1118
00:38:17,349 --> 00:38:19,510
and we asked them to talk about what best practices

1119
00:38:19,510 --> 00:38:20,530
they were encouraging

1120
00:38:20,789 --> 00:38:22,869
uh and uh and what they're trying to encourage

1121
00:38:22,869 --> 00:38:24,628
their engineers to kind of teach each other to do.

1122
00:38:24,949 --> 00:38:26,949
And where we found commonality, we

1123
00:38:26,949 --> 00:38:29,070
included those best practices in this study, and

1124
00:38:29,070 --> 00:38:31,148
then we turned that, uh, you know, stack rank

1125
00:38:31,148 --> 00:38:31,989
your top 5

1126
00:38:32,269 --> 00:38:34,769
into this sort of top 10 list of

1127
00:38:34,869 --> 00:38:35,989
time saving use cases.

1128
00:38:36,429 --> 00:38:38,510
I think it's really interesting that stack trace analysis

1129
00:38:38,510 --> 00:38:39,179
was number one.

1130
00:38:39,510 --> 00:38:41,628
I mean now, you know, of course, like, you know, put

1131
00:38:41,628 --> 00:38:43,668
anything in agent mode and it's already kinda gonna do this for

1132
00:38:43,668 --> 00:38:45,789
you. Um this is another one of those

1133
00:38:45,789 --> 00:38:47,829
like philosophical points though, where it's like, I mean when

1134
00:38:47,829 --> 00:38:48,719
I was you know,

1135
00:38:49,199 --> 00:38:51,269
still a developer, but when I was writing code professionally

1136
00:38:51,269 --> 00:38:53,550
like in in the late 90s, early 2000s, there was a lot of Java.

1137
00:38:54,119 --> 00:38:55,869
And became more JEE stuff.

1138
00:38:56,168 --> 00:38:58,199
And then some spraying and things like that, which we

1139
00:38:58,199 --> 00:38:58,849
all know,

1140
00:38:59,199 --> 00:39:01,550
spit out terribly long stack traces

1141
00:39:01,610 --> 00:39:03,648
that were then sort of like going line by line through to

1142
00:39:03,648 --> 00:39:05,769
try to figure out what's going on. But it can be a bit of a puzzle,

1143
00:39:05,809 --> 00:39:07,849
like I mean as an engineer, sometimes you like to solve that

1144
00:39:07,849 --> 00:39:09,849
stuff. But this is another one where

1145
00:39:09,849 --> 00:39:12,168
it's like, no, you gotta give this over to the AI.

1146
00:39:12,489 --> 00:39:14,570
It does a great job with stack trace analysis, but I

1147
00:39:14,570 --> 00:39:16,688
think it's interesting that it's an interpretive use case

1148
00:39:16,688 --> 00:39:17,909
and not a generative use case.

1149
00:39:18,409 --> 00:39:20,610
We saw some other things here like refactoring existing

1150
00:39:20,610 --> 00:39:21,809
code. Yeah, absolutely.

1151
00:39:22,269 --> 00:39:23,179
Uh, mid-loop generation,

1152
00:39:23,789 --> 00:39:25,909
in other words, I'm gonna write the function header, and

1153
00:39:25,909 --> 00:39:28,090
then maybe do a comment about what this function is supposed

1154
00:39:28,090 --> 00:39:30,119
to do, and I'm gonna let you just fill in the middle

1155
00:39:30,119 --> 00:39:32,369
for me, right? Cause I'm still using my higher order

1156
00:39:32,369 --> 00:39:34,570
thinking, understanding what this function is supposed to do. I

1157
00:39:34,570 --> 00:39:36,128
don't really need to write the code in the middle.

1158
00:39:36,438 --> 00:39:37,159
Test case generation,

1159
00:39:37,679 --> 00:39:38,510
no-brainer, right?

1160
00:39:38,829 --> 00:39:40,208
Uh, learning new techniques.

1161
00:39:40,708 --> 00:39:41,409
Um,

1162
00:39:41,869 --> 00:39:44,139
another philosophical point that I get when I give a workshop

1163
00:39:44,139 --> 00:39:46,478
that's kind of, uh, designed around this, uh, guide,

1164
00:39:47,030 --> 00:39:48,429
people ask me about Justin, are,

1165
00:39:48,708 --> 00:39:49,780
are we actually learning?

1166
00:39:50,148 --> 00:39:51,489
And I think it's like a really

1167
00:39:51,789 --> 00:39:53,909
good question, right? I mean, for,

1168
00:39:53,969 --> 00:39:56,208
you know, I, for one, I mean like I was always directionally

1169
00:39:56,208 --> 00:39:58,610
challenged, but I can't get anywhere with my GPS, it's like impossible,

1170
00:39:58,628 --> 00:40:00,168
even my hometown and everything, I get lost,

1171
00:40:00,668 --> 00:40:01,978
uh, because I'm, you know, just,

1172
00:40:02,269 --> 00:40:04,510
just blindly following what the GPS is telling me to do.

1173
00:40:05,159 --> 00:40:07,789
Uh, is that what's happening with cogeneration?

1174
00:40:08,039 --> 00:40:10,199
The answer is maybe, and it's up to you,

1175
00:40:10,320 --> 00:40:12,500
right? Like this is your personal responsibility.

1176
00:40:12,559 --> 00:40:14,579
This isn't any different than like when we used to

1177
00:40:14,840 --> 00:40:17,659
copy paste code from Stack Overflow,

1178
00:40:18,079 --> 00:40:20,139
right? Like it's up to you at that point, like.

1179
00:40:20,958 --> 00:40:23,000
Do I wanna understand what this code is actually

1180
00:40:23,000 --> 00:40:23,590
doing?

1181
00:40:23,878 --> 00:40:26,110
Do I wanna learn and become a better developer, or

1182
00:40:26,110 --> 00:40:27,958
am I just in a rush and I have to hit the easy button?

1183
00:40:28,320 --> 00:40:30,478
So you absolutely can learn new stuff if

1184
00:40:30,478 --> 00:40:32,500
you so choose, right? And uh

1185
00:40:32,500 --> 00:40:34,559
so, you know, letting the agent just do

1186
00:40:34,559 --> 00:40:36,668
stuff and then just sort of trusting it, no, you

1187
00:40:36,668 --> 00:40:37,550
probably won't be learning.

1188
00:40:37,840 --> 00:40:39,949
But taking that extra moment uh to see

1189
00:40:39,949 --> 00:40:42,059
what's happening and try to understand what's happening,

1190
00:40:42,119 --> 00:40:44,119
not only will you generate better code in the long run,

1191
00:40:44,320 --> 00:40:45,500
but you'll become a better developer.

1192
00:40:46,309 --> 00:40:47,929
Uh, complex query writing.

1193
00:40:48,668 --> 00:40:50,750
So I, uh, when I give this workshop, and

1194
00:40:50,750 --> 00:40:52,750
I happen to be home on Zoom or something like that, I point

1195
00:40:52,750 --> 00:40:54,829
over to my bookshelf where my mastering

1196
00:40:54,829 --> 00:40:57,070
regular expressions book lives and

1197
00:40:57,070 --> 00:40:59,269
has not been cracked in ages, right?

1198
00:40:59,320 --> 00:41:01,030
I don't write regular expressions every day.

1199
00:41:01,389 --> 00:41:03,429
So getting the agent to do something that you don't

1200
00:41:03,429 --> 00:41:04,958
do every day, like a Projects

1201
00:41:05,280 --> 00:41:07,478
or feeding it some context about your schema

1202
00:41:07,478 --> 00:41:09,590
and having it generate SQL queries. Another

1203
00:41:09,590 --> 00:41:10,500
really good use case.

1204
00:41:10,878 --> 00:41:12,918
Certainly code documentation in multiple forms,

1205
00:41:13,039 --> 00:41:15,280
right? So, I'm one of those weird engineers who actually

1206
00:41:15,280 --> 00:41:17,878
does like writing longer form documentation

1207
00:41:17,878 --> 00:41:20,159
when I write code, but I hate commenting.

1208
00:41:20,590 --> 00:41:22,878
I know how important it is, right, for posterity

1209
00:41:22,878 --> 00:41:24,619
and everything, but I just want to kind of flow my way through

1210
00:41:25,000 --> 00:41:27,030
and then not have to worry about writing comments. These

1211
00:41:27,030 --> 00:41:29,030
things are great at inserting comments,

1212
00:41:29,320 --> 00:41:31,559
right? So we tend to think in terms of it like generating markup

1213
00:41:31,559 --> 00:41:33,739
and things like that, which is a very valid use case,

1214
00:41:33,958 --> 00:41:36,378
but auto-coming the code is really good too.

1215
00:41:36,958 --> 00:41:39,139
Uh, yeah, brainstorming and planning, one of my favorite

1216
00:41:39,139 --> 00:41:41,199
uh recursive workflows. This is now

1217
00:41:41,199 --> 00:41:42,260
a first-class citizen

1218
00:41:42,760 --> 00:41:44,139
in like cursor plan.

1219
00:41:44,679 --> 00:41:46,800
Amazon Quiro was one of the first to bring this to market.

1220
00:41:46,878 --> 00:41:48,918
I think it was the first to bring it to market as a first-class

1221
00:41:48,918 --> 00:41:50,030
citizen inside the IDE.

1222
00:41:50,570 --> 00:41:52,809
This is basically where you just say, OK, I'm a, you

1223
00:41:52,809 --> 00:41:55,050
know, computer programmer and you're a project manager.

1224
00:41:55,389 --> 00:41:57,469
Ask me one question at a time

1225
00:41:57,728 --> 00:42:00,090
about this thing that I wanna do, and then

1226
00:42:00,090 --> 00:42:01,909
create a specification based on our

1227
00:42:02,840 --> 00:42:04,929
conversation that I can then use to maybe scaffold code

1228
00:42:04,929 --> 00:42:05,478
or whatever.

1229
00:42:05,929 --> 00:42:07,000
This is one of those ones,

1230
00:42:07,329 --> 00:42:09,489
even, you know, as as reticent as I was at first,

1231
00:42:09,688 --> 00:42:11,590
that has completely changed the way that I work.

1232
00:42:12,409 --> 00:42:14,449
Right, I mean, you know, back in the day when I, when I was

1233
00:42:14,449 --> 00:42:16,648
writing code, you, you always miss something in

1234
00:42:16,648 --> 00:42:18,728
that early planning phase, and then you sit down to

1235
00:42:18,728 --> 00:42:20,438
code, and it bites you later,

1236
00:42:20,849 --> 00:42:23,168
right? This is a really great way to get that comprehensive

1237
00:42:23,168 --> 00:42:25,289
plan kind of out first. I think about it as kind of like

1238
00:42:25,289 --> 00:42:26,769
rubber ducking 2.0,

1239
00:42:27,168 --> 00:42:29,369
because it's like I'm discussing what I wanna do, but

1240
00:42:29,369 --> 00:42:31,449
I'm actually getting feedback, and then that feedback

1241
00:42:31,449 --> 00:42:32,418
is turned into a plan.

1242
00:42:33,050 --> 00:42:35,159
Uh, so I was very, very pleased to see that come out

1243
00:42:35,159 --> 00:42:37,208
in Amazon Kiiro when I started using the public

1244
00:42:37,208 --> 00:42:39,250
preview for it. Now of course it's made its way, uh feature

1245
00:42:39,250 --> 00:42:40,389
parody and other tools.

1246
00:42:40,840 --> 00:42:42,239
But yeah, I totally like this one too.

1247
00:42:42,559 --> 00:42:44,929
And you know, then code explanation, initial code scaffolding.

1248
00:42:44,989 --> 00:42:47,159
So yeah, uh, the guide itself is

1249
00:42:47,159 --> 00:42:49,320
about 65 pages long. It gets into

1250
00:42:49,320 --> 00:42:51,099
more than just these top 10, it gets into

1251
00:42:51,458 --> 00:42:53,539
prompting techniques like metap-prompting and

1252
00:42:53,800 --> 00:42:55,918
uh recursive prompt chaining and things like

1253
00:42:55,918 --> 00:42:57,958
that. Um, and so, uh,

1254
00:42:58,000 --> 00:42:58,780
you know, you can,

1255
00:42:59,280 --> 00:43:01,280
you know, use this as a reference if it's helpful for

1256
00:43:01,280 --> 00:43:03,320
your engineers. We've definitely had some organizations that

1257
00:43:03,320 --> 00:43:04,570
they're calling it like recursive

1258
00:43:05,039 --> 00:43:06,510
required reading now for their engineers.

1259
00:43:06,869 --> 00:43:08,958
But it's a good way also to get more ROI out of these

1260
00:43:08,958 --> 00:43:11,208
tools. OK,

1261
00:43:11,579 --> 00:43:12,688
speaking of ROI.

1262
00:43:13,469 --> 00:43:15,208
How should we be measuring all this stuff?

1263
00:43:15,659 --> 00:43:16,409
Uh, well,

1264
00:43:18,159 --> 00:43:20,519
Measuring productivity and even defining productivity

1265
00:43:20,519 --> 00:43:21,610
was already difficult.

1266
00:43:22,000 --> 00:43:24,000
And the engineering like landscape, the

1267
00:43:24,000 --> 00:43:26,000
industry had not already sort of

1268
00:43:26,000 --> 00:43:26,860
landed on

1269
00:43:27,228 --> 00:43:29,659
and aligned against and commoditized

1270
00:43:29,918 --> 00:43:31,139
the best way to do it.

1271
00:43:31,679 --> 00:43:32,619
And then AI came out.

1272
00:43:33,289 --> 00:43:35,570
And now we're trying to solve for measuring ROI

1273
00:43:35,570 --> 00:43:37,309
and productivity because we have people in,

1274
00:43:37,610 --> 00:43:38,610
you know, on, on,

1275
00:43:38,889 --> 00:43:40,929
we have people on the board and we have CTOs and stuff

1276
00:43:40,929 --> 00:43:41,840
asking for,

1277
00:43:42,159 --> 00:43:44,800
you know, what's the ROI that we're getting on all these massive

1278
00:43:44,800 --> 00:43:46,489
AI AI investments that we're making.

1279
00:43:47,349 --> 00:43:49,469
And the unfortunate truth is that a lot of us weren't

1280
00:43:49,469 --> 00:43:51,228
even good at measuring this before AI

1281
00:43:51,539 --> 00:43:53,449
and now we have a whole new factor

1282
00:43:54,070 --> 00:43:56,148
that's come in. But what I hope that does is actually

1283
00:43:56,148 --> 00:43:58,289
accelerate our, our paying attention

1284
00:43:58,289 --> 00:44:00,250
to this different ways to measure.

1285
00:44:00,708 --> 00:44:01,239
Um,

1286
00:44:01,590 --> 00:44:03,668
so even what we do at DX is not perfect, but I think

1287
00:44:03,668 --> 00:44:05,668
it's the best model, right? Again, we've kind of

1288
00:44:05,668 --> 00:44:07,789
combined Dora metrics with space

1289
00:44:07,789 --> 00:44:09,789
framework, with a metric framework called

1290
00:44:09,789 --> 00:44:12,030
Dev X which focuses on cognitive load,

1291
00:44:12,110 --> 00:44:14,110
it focuses on context switching, feedback loops.

1292
00:44:14,389 --> 00:44:16,478
So if you're doing the core 4, you're doing all three of those metric

1293
00:44:16,478 --> 00:44:17,148
sets at once.

1294
00:44:17,728 --> 00:44:19,039
And then it was kind of on us

1295
00:44:19,300 --> 00:44:21,559
to say, well, look, all of our customers now

1296
00:44:21,739 --> 00:44:23,000
want to understand the impact

1297
00:44:23,418 --> 00:44:25,599
that AI is having on

1298
00:44:26,050 --> 00:44:27,000
our productivity.

1299
00:44:27,300 --> 00:44:29,300
And so we're like, I really, we, we studied with a couple

1300
00:44:29,300 --> 00:44:30,478
of companies for a couple of months,

1301
00:44:31,139 --> 00:44:33,300
and then in sort of a fever dream state over

1302
00:44:33,300 --> 00:44:34,079
a long weekend,

1303
00:44:34,739 --> 00:44:36,739
myself and Abby, our CEO co-founder and

1304
00:44:36,739 --> 00:44:38,739
other CTO Laura, just like banged

1305
00:44:38,739 --> 00:44:40,739
this thing out, right? But based on data that we'd

1306
00:44:40,739 --> 00:44:42,898
pulled from the system and based on interviews and

1307
00:44:42,898 --> 00:44:44,898
things with other companies, I'll show you a few of them in a

1308
00:44:44,898 --> 00:44:47,159
moment. So, we

1309
00:44:47,159 --> 00:44:49,159
found out a few things, like, as we were kind of putting

1310
00:44:49,159 --> 00:44:50,219
this framework together.

1311
00:44:50,719 --> 00:44:52,760
Um, we kind of thought about

1312
00:44:52,760 --> 00:44:54,619
three different types of metrics

1313
00:44:54,978 --> 00:44:57,000
and kind of their strengths and kind

1314
00:44:57,000 --> 00:44:58,329
of their challenges, right?

1315
00:44:58,800 --> 00:44:59,898
So the first of course,

1316
00:45:00,159 --> 00:45:01,739
is our telemetry metrics,

1317
00:45:02,199 --> 00:45:04,510
right? Uh, this is getting stuff from

1318
00:45:04,510 --> 00:45:05,599
co-pilot API

1319
00:45:06,079 --> 00:45:07,320
or cursor API.

1320
00:45:07,668 --> 00:45:09,949
Uh, Anthropic and Cloud didn't have an API,

1321
00:45:10,030 --> 00:45:12,070
but we had customers who wanted to get that data, so we

1322
00:45:12,070 --> 00:45:14,429
worked directly with Anthropic to build their API

1323
00:45:14,429 --> 00:45:16,750
for Cloud, which is now in my opinion, like a really

1324
00:45:16,750 --> 00:45:17,309
good API.

1325
00:45:17,869 --> 00:45:20,030
Um, but there's not always like a full story

1326
00:45:20,030 --> 00:45:21,228
that's gonna come out of this, right?

1327
00:45:21,628 --> 00:45:23,128
What does utilization really mean?

1328
00:45:23,869 --> 00:45:26,139
Right, what does daily active use, weekly active use,

1329
00:45:26,429 --> 00:45:27,958
monthly active use really mean?

1330
00:45:28,539 --> 00:45:30,668
Forget accept versus suggested lines of

1331
00:45:30,668 --> 00:45:32,898
code. Lines of code was never a good metric to begin with.

1332
00:45:33,148 --> 00:45:34,570
I don't know why we think it would be good now.

1333
00:45:35,188 --> 00:45:37,300
Um, but, uh, um,

1334
00:45:37,309 --> 00:45:39,438
especially when, when, when we look at the fact that the only

1335
00:45:39,438 --> 00:45:41,668
way that the API knows if the code has been accepted

1336
00:45:41,668 --> 00:45:43,860
is if a button was clicked at the IDE and

1337
00:45:43,860 --> 00:45:45,869
there's still no way to tell after the fact that the

1338
00:45:45,869 --> 00:45:48,030
engineer didn't just go and rewrite every line of

1339
00:45:48,030 --> 00:45:49,739
code, uh, that was generated, right?

1340
00:45:50,070 --> 00:45:52,090
But it's OK for like understanding

1341
00:45:52,668 --> 00:45:53,628
like what's happening.

1342
00:45:54,429 --> 00:45:56,458
You know, it's OK for saying like like who, who is

1343
00:45:56,458 --> 00:45:58,628
kind of using this stuff and who, who seems

1344
00:45:58,628 --> 00:46:00,329
to be like using it more than others.

1345
00:46:00,668 --> 00:46:01,269
Um,

1346
00:46:01,789 --> 00:46:03,829
but it's not until we start getting into what we

1347
00:46:03,829 --> 00:46:05,219
call our impact metrics,

1348
00:46:05,590 --> 00:46:07,659
right? How does this cohort, some of the trends

1349
00:46:07,659 --> 00:46:09,909
that I've already shown you, like, how does a cohort

1350
00:46:10,110 --> 00:46:12,228
or usage correlate to

1351
00:46:12,228 --> 00:46:14,019
PR throughput or PR merge rates,

1352
00:46:14,309 --> 00:46:16,699
or code confidence, uh change confidence,

1353
00:46:16,708 --> 00:46:18,789
or change failure rate. So speed and

1354
00:46:18,789 --> 00:46:21,269
quality metrics, right? Now we can actually start correlating

1355
00:46:21,269 --> 00:46:23,269
this stuff, right? And so it's, it's useful for

1356
00:46:23,269 --> 00:46:25,269
that. Experience sampling

1357
00:46:25,269 --> 00:46:27,289
can be great for collecting

1358
00:46:27,550 --> 00:46:28,969
small bits of data

1359
00:46:29,349 --> 00:46:31,389
and starting to quantify some ROI.

1360
00:46:31,789 --> 00:46:33,909
So this is, for instance, like interrupting a developer

1361
00:46:33,909 --> 00:46:36,148
as they're already in a workflow, but hopefully

1362
00:46:36,148 --> 00:46:38,389
not in a way that causes a context switch. So like for

1363
00:46:38,389 --> 00:46:40,389
instance, a great example, good textbook example

1364
00:46:40,389 --> 00:46:42,469
is adding one additional field to a PR

1365
00:46:42,469 --> 00:46:44,579
form, where they're already having to fill out a

1366
00:46:44,579 --> 00:46:46,610
PR that says, I used

1367
00:46:46,610 --> 00:46:48,429
AI to work on this PR.

1368
00:46:48,969 --> 00:46:50,469
Or I enjoyed

1369
00:46:50,750 --> 00:46:52,849
using AI to work on this PR,

1370
00:46:53,050 --> 00:46:54,550
right? We get that one little piece of data.

1371
00:46:55,090 --> 00:46:57,449
Uh, it can be a little difficult to set up though, and

1372
00:46:57,449 --> 00:47:00,239
we have to run this over a period of time, right? We wanna get longitudinal

1373
00:47:00,239 --> 00:47:02,250
data, uh, from this to kind of

1374
00:47:02,250 --> 00:47:03,188
understand that impact.

1375
00:47:03,648 --> 00:47:05,679
Then finally, self-reported data, surveys.

1376
00:47:05,769 --> 00:47:07,969
Um, again, we're a little biased, we've

1377
00:47:07,969 --> 00:47:10,039
done a great job of engineering our surveys and we get

1378
00:47:10,039 --> 00:47:11,750
great participation rates in our surveys.

1379
00:47:12,168 --> 00:47:14,489
Um, but when you do this, these signals

1380
00:47:14,489 --> 00:47:16,849
can be incredibly strong. I was just talking to, uh,

1381
00:47:17,128 --> 00:47:19,239
Uh, someone at Slack who gave a talk

1382
00:47:19,239 --> 00:47:21,409
at the same uh little event that I was doing a few hours

1383
00:47:21,409 --> 00:47:22,269
ago here in the Wynn,

1384
00:47:22,648 --> 00:47:24,809
and, uh, Slack relies mostly on

1385
00:47:24,809 --> 00:47:26,969
the qualitative signals that they get, because they get

1386
00:47:26,969 --> 00:47:29,329
like 92, 93% participation

1387
00:47:29,329 --> 00:47:30,800
rates in their engineering surveys.

1388
00:47:31,090 --> 00:47:33,280
When you get that high, and when it's a well engineered

1389
00:47:33,280 --> 00:47:35,769
survey, we even say like trust the qualitative

1390
00:47:35,769 --> 00:47:37,929
metrics over the system metrics. Like

1391
00:47:37,929 --> 00:47:40,039
you need both to understand what's fully happening,

1392
00:47:40,289 --> 00:47:41,610
but if there's like a deviation.

1393
00:47:42,019 --> 00:47:44,179
Where it's like the system metrics seem to

1394
00:47:44,179 --> 00:47:46,208
be telling you something that's different than the qualitative

1395
00:47:46,208 --> 00:47:48,500
metrics. When you have that good strong signal,

1396
00:47:48,619 --> 00:47:50,659
we're like, yeah, trust the qualitative metrics and figure out

1397
00:47:50,659 --> 00:47:52,570
what's wrong with the system metrics, right?

1398
00:47:52,898 --> 00:47:54,918
So that's where the self-reported data comes in, but we all know,

1399
00:47:55,099 --> 00:47:57,438
you know, they can't, they can only be run periodically.

1400
00:47:57,989 --> 00:48:00,309
We really don't wanna, we really don't want survey fatigue,

1401
00:48:00,389 --> 00:48:02,550
you know, we feel like quarterly is about right. The

1402
00:48:02,550 --> 00:48:03,369
real number

1403
00:48:03,789 --> 00:48:06,110
is how long it takes for improvements

1404
00:48:06,110 --> 00:48:08,148
to flow through your organization, and that's gonna

1405
00:48:08,148 --> 00:48:09,429
change based on your culture,

1406
00:48:09,829 --> 00:48:11,989
cause the last thing you wanna do is keep running these surveys

1407
00:48:11,989 --> 00:48:13,228
that just never change,

1408
00:48:13,590 --> 00:48:15,668
right? What you wanna be able to do to get engineers

1409
00:48:15,668 --> 00:48:18,010
excited about taking surveys and providing feedback

1410
00:48:18,228 --> 00:48:19,030
is showing

1411
00:48:19,309 --> 00:48:21,389
that the audience is looking at these signals

1412
00:48:21,389 --> 00:48:23,409
and saying, OK, great, thank you for this feedback.

1413
00:48:23,878 --> 00:48:25,929
Here's what we're gonna prioritize improving over

1414
00:48:25,929 --> 00:48:28,128
the next 3 months, 6 months, whatever

1415
00:48:28,128 --> 00:48:30,489
that is. Then we're gonna benchmark again and

1416
00:48:30,489 --> 00:48:32,728
say, OK, well did this actually move the needle. Then you have

1417
00:48:32,728 --> 00:48:34,809
engineers that figure out, OK, well actually this feedback is kind

1418
00:48:34,809 --> 00:48:36,429
of making my life better and I kinda like it.

1419
00:48:36,769 --> 00:48:39,329
So that's how we end up in these nice flywheels of of continuous

1420
00:48:39,329 --> 00:48:41,579
improvement. Uh, so yeah, telemetry

1421
00:48:41,579 --> 00:48:43,929
metrics, experience sampling and self-reported

1422
00:48:43,929 --> 00:48:46,039
data, and we really recommend that you do all three,

1423
00:48:46,418 --> 00:48:48,500
right? Cause each of them are gonna do different things and

1424
00:48:48,500 --> 00:48:49,239
give you a full picture.

1425
00:48:50,539 --> 00:48:52,320
This is the measurement framework itself.

1426
00:48:53,260 --> 00:48:55,398
So again, this was the result of working with a number of

1427
00:48:55,398 --> 00:48:57,579
companies, as well as what we already knew about

1428
00:48:57,579 --> 00:48:58,280
productivity.

1429
00:48:58,699 --> 00:49:00,800
You can use this measurement framework

1430
00:49:00,929 --> 00:49:01,860
in a few different ways.

1431
00:49:02,820 --> 00:49:04,860
Uh, in one way it's just like looking at

1432
00:49:04,860 --> 00:49:05,539
the raw metrics,

1433
00:49:05,820 --> 00:49:07,898
understanding what metrics are important. None of this was done

1434
00:49:07,898 --> 00:49:08,610
in a vacuum.

1435
00:49:08,898 --> 00:49:11,000
These all represent metrics that

1436
00:49:11,000 --> 00:49:13,260
across, uh, close to 40 different

1437
00:49:13,260 --> 00:49:15,320
companies that we ended up looking at what they were paying attention

1438
00:49:15,320 --> 00:49:17,418
to. We found commonality and we put them

1439
00:49:17,418 --> 00:49:18,119
in the framework.

1440
00:49:18,378 --> 00:49:20,500
But it's also inspired by the space

1441
00:49:20,500 --> 00:49:21,179
framework,

1442
00:49:21,539 --> 00:49:23,728
in that it's not just metrics,

1443
00:49:23,898 --> 00:49:26,418
it's dimensions, and more importantly, oppositional

1444
00:49:26,418 --> 00:49:27,099
dimensions.

1445
00:49:27,510 --> 00:49:29,789
Right? One good, great way to think about

1446
00:49:29,789 --> 00:49:31,309
um good metrics,

1447
00:49:31,590 --> 00:49:33,590
and this is not me, this is the author of the Space

1448
00:49:33,590 --> 00:49:35,590
Framework, Margaret Ann's story, Peggy's story's a good

1449
00:49:35,590 --> 00:49:37,688
friend, is to look at

1450
00:49:37,688 --> 00:49:39,989
a constellation of metrics

1451
00:49:39,989 --> 00:49:42,418
in tension with one another, right?

1452
00:49:42,628 --> 00:49:44,989
And so that's why we always map these uh these metrics

1453
00:49:44,989 --> 00:49:46,938
into these oppositional dimensions,

1454
00:49:47,228 --> 00:49:48,889
utilization, impact and cost.

1455
00:49:49,228 --> 00:49:51,449
You can also think about this as a maturity curve,

1456
00:49:51,909 --> 00:49:53,989
right? Most organizations are starting on

1457
00:49:53,989 --> 00:49:54,530
the left.

1458
00:49:55,010 --> 00:49:57,208
They're getting utilization like daily active use,

1459
00:49:57,360 --> 00:49:59,639
weekly active use, the percentage of PRs that are AI

1460
00:49:59,639 --> 00:50:01,809
assisted. And then as we start gathering

1461
00:50:01,809 --> 00:50:04,280
those, you know, what's going on metrics,

1462
00:50:04,559 --> 00:50:06,570
we move into the impact metrics, and some of these

1463
00:50:06,570 --> 00:50:08,648
should look familiar if you're already doing like Dora or

1464
00:50:08,648 --> 00:50:09,989
if you're familiar with the core 4.

1465
00:50:10,329 --> 00:50:12,369
So these are things like developer satisfaction,

1466
00:50:12,688 --> 00:50:15,188
PR throughput, perceived rate of delivery,

1467
00:50:15,449 --> 00:50:17,449
uh, changed confidence, change failer

1468
00:50:17,449 --> 00:50:18,030
percentage.

1469
00:50:18,519 --> 00:50:20,688
Um, so we want to start again being able to correlate

1470
00:50:20,688 --> 00:50:22,809
this. And then of course

1471
00:50:22,809 --> 00:50:24,869
cost. I mean, I do like to point out

1472
00:50:25,090 --> 00:50:27,168
that we're 15 years past the last major hype

1473
00:50:27,168 --> 00:50:29,168
cycle, and we're still figuring out how to

1474
00:50:29,168 --> 00:50:30,228
control our cloud costs

1475
00:50:30,489 --> 00:50:32,648
in a lot of cases, why a lot of us are here.

1476
00:50:32,949 --> 00:50:35,110
Um, but I'm also hearing horror stories

1477
00:50:35,110 --> 00:50:37,110
about engineers burning through like $3000 worth

1478
00:50:37,110 --> 00:50:37,909
of tokens a day,

1479
00:50:38,228 --> 00:50:40,269
so we are gonna have to get a handle on this. But what

1480
00:50:40,269 --> 00:50:42,500
we're finding is that in that maturity curve, it tends

1481
00:50:42,500 --> 00:50:44,550
to be like the utilization metrics first, followed by

1482
00:50:44,550 --> 00:50:46,869
the impact metrics, and then these cost metrics.

1483
00:50:47,030 --> 00:50:49,168
OK, so that's the framework. Lots of ways to gather

1484
00:50:49,168 --> 00:50:49,750
this data,

1485
00:50:50,079 --> 00:50:52,110
uh, just like space framework, we don't really prescribe

1486
00:50:52,110 --> 00:50:52,929
how to gather the data,

1487
00:50:53,429 --> 00:50:55,309
more that you normalize the data

1488
00:50:55,668 --> 00:50:57,110
into these dimensions.

1489
00:50:58,179 --> 00:50:59,789
So these are just a couple of the companies

1490
00:51:00,059 --> 00:51:02,378
that we worked with uh to um

1491
00:51:02,378 --> 00:51:03,280
put this framework together,

1492
00:51:03,820 --> 00:51:06,050
uh, and some of the metrics that were important to them.

1493
00:51:06,659 --> 00:51:07,659
So Microsoft,

1494
00:51:07,978 --> 00:51:10,099
looking at adoption just like Dropbox, just

1495
00:51:10,099 --> 00:51:12,179
like booking, so some commonality there for

1496
00:51:12,179 --> 00:51:13,208
adoption metrics.

1497
00:51:13,539 --> 00:51:15,800
Microsoft looking at things like system velocity, developer

1498
00:51:15,800 --> 00:51:17,179
satisfaction, change failure rate,

1499
00:51:17,449 --> 00:51:19,500
and one of my favorite metrics of all time.

1500
00:51:19,699 --> 00:51:21,168
We don't have time to go into this right now,

1501
00:51:21,489 --> 00:51:23,688
but it's called a bad developer day. Uh,

1502
00:51:23,739 --> 00:51:25,780
Microsoft is a great white paper on this if you look up

1503
00:51:25,780 --> 00:51:27,219
the Microsoft bad developer days.

1504
00:51:27,610 --> 00:51:30,228
Um, and it's basically like gathering telemetry

1505
00:51:30,228 --> 00:51:31,898
from a whole bunch of different areas,

1506
00:51:32,159 --> 00:51:33,570
uh, of the workflow,

1507
00:51:33,918 --> 00:51:35,989
and putting together signals that said, yeah, this developer

1508
00:51:35,989 --> 00:51:38,000
had a bad day, like too many meetings

1509
00:51:38,000 --> 00:51:40,110
or too many incidents, and there's a lot of

1510
00:51:40,110 --> 00:51:41,179
different metrics in there.

1511
00:51:41,438 --> 00:51:43,739
But then they're correlating this to AI utilization,

1512
00:51:43,878 --> 00:51:45,539
and look that one up, it really is kind of cool.

1513
00:51:45,898 --> 00:51:47,090
Um, Dropbox,

1514
00:51:47,458 --> 00:51:49,860
who has been hyperfocused on developer

1515
00:51:49,860 --> 00:51:50,639
experience

1516
00:51:50,898 --> 00:51:51,800
since the beginning.

1517
00:51:52,059 --> 00:51:54,059
Their CEO opens up the DX

1518
00:51:54,059 --> 00:51:55,219
platform every morning

1519
00:51:55,500 --> 00:51:57,500
to look at how developer productivity metrics

1520
00:51:57,500 --> 00:51:58,958
and experience metrics are going.

1521
00:51:59,300 --> 00:52:00,398
Uh, they're looking at adoption,

1522
00:52:00,938 --> 00:52:03,090
they're looking at developer sentiment, velocity as well,

1523
00:52:03,458 --> 00:52:05,458
percentage of uh AI code lines that were

1524
00:52:05,458 --> 00:52:07,119
added versus the total lines added.

1525
00:52:07,418 --> 00:52:09,489
Quality, they look at change failure percentage. Change failure

1526
00:52:09,489 --> 00:52:11,659
rate's a great metric, tells us so many different stories

1527
00:52:11,659 --> 00:52:13,539
about what's happening with quality in the organization.

1528
00:52:13,929 --> 00:52:16,119
And then Booking.com, yeah, daily active use, weekly

1529
00:52:16,119 --> 00:52:18,168
active use, overall time, say, PR throughput.

1530
00:52:18,250 --> 00:52:19,989
So you see some commonality here,

1531
00:52:20,289 --> 00:52:22,449
and where you see this overlap, this is how we put this metric

1532
00:52:22,449 --> 00:52:24,648
framework together. So this is pretty well trusted,

1533
00:52:24,688 --> 00:52:26,849
like these metrics have now been validated, not

1534
00:52:26,849 --> 00:52:29,079
just in our platform across millions of

1535
00:52:29,079 --> 00:52:31,250
developers and data points and things like this, but

1536
00:52:31,250 --> 00:52:32,329
across other companies too.

1537
00:52:33,719 --> 00:52:34,978
Uh, so,

1538
00:52:35,639 --> 00:52:36,739
there's no way you can read that.

1539
00:52:37,398 --> 00:52:38,559
That's, that's another set.

1540
00:52:38,878 --> 00:52:41,039
Uh, maybe you zoom in on your phone or rather look at it later. It's

1541
00:52:41,039 --> 00:52:43,219
also in that guide, uh, that I mentioned before.

1542
00:52:43,599 --> 00:52:44,179
Um,

1543
00:52:44,519 --> 00:52:46,679
but these are just some, what some other companies are looking at as

1544
00:52:46,679 --> 00:52:48,829
well. Uh, so GitHub, Toast,

1545
00:52:48,958 --> 00:52:49,860
uh, Grammarly.

1546
00:52:50,398 --> 00:52:52,019
But again, I really wanna stress here

1547
00:52:52,760 --> 00:52:54,099
that AI metrics again,

1548
00:52:54,559 --> 00:52:55,978
measure what's happening.

1549
00:52:56,780 --> 00:52:58,889
But core metrics measure whether

1550
00:52:58,889 --> 00:53:00,789
these investments are working,

1551
00:53:01,329 --> 00:53:03,228
right? And they're

1552
00:53:03,570 --> 00:53:05,688
really, those haven't really changed, right? I mean

1553
00:53:05,688 --> 00:53:08,000
we still are looking at speed, uh velocity,

1554
00:53:08,168 --> 00:53:09,090
but also quality.

1555
00:53:09,449 --> 00:53:11,489
But I think it's important that we understand that

1556
00:53:11,679 --> 00:53:13,728
hyperfocusing on any metric, like we said

1557
00:53:13,728 --> 00:53:15,789
before with Cobra effect and Goodheart's law is bad.

1558
00:53:16,208 --> 00:53:18,409
But um only looking at utilization

1559
00:53:18,409 --> 00:53:20,489
metrics are not going to tell you the full picture. They're

1560
00:53:20,489 --> 00:53:22,628
not gonna tell you whether the investments are actually

1561
00:53:22,728 --> 00:53:24,769
working. That's what the core foundation metrics are

1562
00:53:24,769 --> 00:53:26,820
for. All right,

1563
00:53:26,898 --> 00:53:27,679
so in summary,

1564
00:53:27,969 --> 00:53:30,179
um, you know, we do want to, as I mentioned

1565
00:53:30,179 --> 00:53:31,878
before, avoid venture lock-in, like, you know,

1566
00:53:32,179 --> 00:53:33,840
these tools are leapfrogging each other.

1567
00:53:34,179 --> 00:53:36,300
Uh, we want to expand the definition

1568
00:53:36,300 --> 00:53:37,099
of a developer.

1569
00:53:37,500 --> 00:53:39,059
We want to measure AI adoption.

1570
00:53:39,340 --> 00:53:41,340
Hopefully, uh, this framework was was

1571
00:53:41,340 --> 00:53:43,378
interesting, or at least some good food for thought about what you can be

1572
00:53:43,378 --> 00:53:45,389
measuring. But also remember that AI is not

1573
00:53:45,389 --> 00:53:46,010
a silver bullet,

1574
00:53:46,429 --> 00:53:48,550
right? That even though we're seeing these time savings in some

1575
00:53:48,550 --> 00:53:50,929
places, those time savings are often being

1576
00:53:51,030 --> 00:53:51,809
eclipsed

1577
00:53:52,110 --> 00:53:54,389
by uh other sources of friction, toil,

1578
00:53:54,550 --> 00:53:56,648
context switching and things like that from developers.

1579
00:53:56,949 --> 00:53:59,139
So final resource I'll share with you, uh,

1580
00:53:59,148 --> 00:54:01,300
a lot of this is summarized, the measurement

1581
00:54:01,300 --> 00:54:03,750
aspect is summarized in this uh strategy

1582
00:54:03,750 --> 00:54:05,139
playbook for senior executives.

1583
00:54:05,648 --> 00:54:07,668
Um, we get into a lot of stuff in

1584
00:54:07,668 --> 00:54:08,280
this guide.

1585
00:54:08,570 --> 00:54:10,849
We get into how to think about integrating

1586
00:54:10,849 --> 00:54:12,958
across the SDLC. I mentioned I love Ellie Goldrot,

1587
00:54:13,128 --> 00:54:14,958
means I also love value stream mapping.

1588
00:54:15,250 --> 00:54:16,360
So there's a lot of, uh,

1589
00:54:17,039 --> 00:54:19,079
information in here and how you can use your value stream maps to

1590
00:54:19,079 --> 00:54:21,079
determine where uh agentic AI is really

1591
00:54:21,079 --> 00:54:23,570
gonna help you. I dive a lot into psychological

1592
00:54:23,570 --> 00:54:26,168
safety. I talk about Google's Project Aristotle,

1593
00:54:26,958 --> 00:54:29,168
where they ran this study where they had this hypothesis

1594
00:54:29,168 --> 00:54:31,378
that the most performative, like highly. Forming teams

1595
00:54:31,378 --> 00:54:33,280
were going to be a result of like really good management

1596
00:54:33,619 --> 00:54:35,860
and really great developers and unlimited

1597
00:54:35,860 --> 00:54:37,918
compute resources, and they were totally wrong.

1598
00:54:38,219 --> 00:54:40,340
And what they actually found out was that psychological safety

1599
00:54:40,340 --> 00:54:42,409
was overwhelmingly the most important factor

1600
00:54:42,409 --> 00:54:44,458
in a high performing team. And I think that's more

1601
00:54:44,458 --> 00:54:46,059
important now than ever with AI.

1602
00:54:46,719 --> 00:54:49,179
Uh, we'll get into things like, you know, compliance, trust,

1603
00:54:49,329 --> 00:54:50,280
uh, security,

1604
00:54:50,619 --> 00:54:52,478
and we'll get into how we can sort of tie.

1605
00:54:52,860 --> 00:54:55,179
Um, you know, these skill sets

1606
00:54:55,179 --> 00:54:57,219
to employees' success, right?

1607
00:54:57,269 --> 00:54:59,280
And really try to remind employees that

1608
00:54:59,469 --> 00:55:01,000
you're, you're giving them an opportunity,

1609
00:55:01,500 --> 00:55:03,579
uh, to learn about something that again will

1610
00:55:03,579 --> 00:55:05,579
likely benefit them for the rest of their

1611
00:55:05,579 --> 00:55:07,659
career. And that's all I have for you today. Thank you

1612
00:55:07,659 --> 00:55:07,898
very much.

