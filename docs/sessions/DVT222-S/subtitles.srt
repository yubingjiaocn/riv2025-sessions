1
00:00:00,250 --> 00:00:01,229
Hey everybody.

2
00:00:02,278 --> 00:00:04,440
Thanks for sticking around. I think

3
00:00:04,440 --> 00:00:06,618
I might be one of the last few

4
00:00:06,618 --> 00:00:08,220
sessions that are

5
00:00:08,640 --> 00:00:10,819
happening. So thank you for uh

6
00:00:10,819 --> 00:00:11,698
for stopping by.

7
00:00:12,278 --> 00:00:14,349
So today I'm gonna talk a little

8
00:00:14,349 --> 00:00:16,478
bit about how Grepper's real-time machine

9
00:00:16,478 --> 00:00:19,138
learning can actually help you get 100%

10
00:00:19,138 --> 00:00:21,260
of the observability that you're seeing today

11
00:00:21,399 --> 00:00:22,699
at 10% of the cost.

12
00:00:24,750 --> 00:00:26,899
I'll start with a little bit of talking

13
00:00:26,899 --> 00:00:29,059
about the AI for telemetry problem because that's

14
00:00:29,059 --> 00:00:31,329
something that people always face,

15
00:00:31,350 --> 00:00:33,469
and I'll talk about extracting

16
00:00:33,469 --> 00:00:35,590
signal from that data so you can

17
00:00:35,590 --> 00:00:36,709
actually feed it into AI

18
00:00:37,109 --> 00:00:39,609
and I'll talk a bit about how Grupper works to get there.

19
00:00:41,289 --> 00:00:43,000
So if you think about how people have been

20
00:00:43,418 --> 00:00:45,439
working with observability for the past,

21
00:00:45,618 --> 00:00:47,618
I don't know, 1520 years,

22
00:00:47,929 --> 00:00:49,939
it all started with full stack observability

23
00:00:49,939 --> 00:00:52,219
where you would collect the data from

24
00:00:52,219 --> 00:00:52,978
the agents,

25
00:00:53,259 --> 00:00:54,880
send it into an application,

26
00:00:55,179 --> 00:00:57,418
um, and that application, that aggregator

27
00:00:57,418 --> 00:00:59,418
is a full stack aggregator, kind

28
00:00:59,418 --> 00:01:01,579
of a walled garden that defines

29
00:01:01,579 --> 00:01:03,740
what you can actually do with that application,

30
00:01:04,099 --> 00:01:05,260
not more with that data.

31
00:01:06,230 --> 00:01:08,829
And then over time we started seeing

32
00:01:08,829 --> 00:01:11,370
more openness in these observability platforms,

33
00:01:11,469 --> 00:01:12,750
more modularization,

34
00:01:13,069 --> 00:01:15,379
where Otel came in as a protocol

35
00:01:15,379 --> 00:01:17,469
to separate the data collection

36
00:01:17,469 --> 00:01:18,209
from the

37
00:01:18,469 --> 00:01:20,668
data aggregators, and then we started

38
00:01:20,668 --> 00:01:22,500
seeing telemetry pipelines as well.

39
00:01:22,870 --> 00:01:25,290
And so what happens after that is

40
00:01:25,439 --> 00:01:27,668
we want to enable AI powered ops

41
00:01:27,668 --> 00:01:29,730
and workflows, and this is what everybody's talking

42
00:01:29,730 --> 00:01:30,370
about today.

43
00:01:31,079 --> 00:01:33,120
We want to empower SREs and

44
00:01:33,120 --> 00:01:35,599
DevOps to be able to handle enormously

45
00:01:35,599 --> 00:01:36,778
more complex

46
00:01:38,069 --> 00:01:39,219
operations and systems.

47
00:01:40,939 --> 00:01:43,230
But the biggest problem with AI systems

48
00:01:43,230 --> 00:01:45,329
today is that the data

49
00:01:45,329 --> 00:01:47,388
is just enormous and it's mostly

50
00:01:47,388 --> 00:01:48,049
noise,

51
00:01:48,388 --> 00:01:50,888
so everything that you're collecting is maybe you'll

52
00:01:51,000 --> 00:01:52,829
ever need maybe 1% of it.

53
00:01:53,230 --> 00:01:55,308
And if you were to feed all that data

54
00:01:55,308 --> 00:01:57,069
into an AI model and tell it, hey,

55
00:01:57,430 --> 00:01:59,510
figure out what's actually in there, it's really

56
00:01:59,510 --> 00:02:01,028
garbage in and garbage out.

57
00:02:01,829 --> 00:02:03,989
And so the biggest problem with

58
00:02:03,989 --> 00:02:04,939
using AI

59
00:02:05,909 --> 00:02:08,330
for observability is the ability

60
00:02:08,330 --> 00:02:10,389
to de-noise the data and figure out how to

61
00:02:10,389 --> 00:02:12,469
concentrate it, so you can actually have

62
00:02:12,469 --> 00:02:13,969
clean data for these systems.

63
00:02:15,368 --> 00:02:17,349
And really that's what Grapper does.

64
00:02:19,659 --> 00:02:22,179
So the way Greppers works is you

65
00:02:22,179 --> 00:02:25,000
start, let's say, with your existing deployments,

66
00:02:25,538 --> 00:02:27,649
you're collecting data, logs, traces,

67
00:02:27,819 --> 00:02:28,460
metrics.

68
00:02:28,770 --> 00:02:30,860
That data is going into your observability

69
00:02:30,860 --> 00:02:32,860
vendor, you know, maybe Splunk,

70
00:02:32,979 --> 00:02:34,909
Data Dog, Grafana, whatever it is.

71
00:02:36,199 --> 00:02:37,538
And Grepper sits in the middle.

72
00:02:37,919 --> 00:02:40,020
We automatically figure out

73
00:02:40,319 --> 00:02:42,319
what is noisy, what's not noisy, what

74
00:02:42,319 --> 00:02:44,360
are all the patterns that are in your

75
00:02:44,360 --> 00:02:44,899
data,

76
00:02:45,240 --> 00:02:47,278
and we use that to figure out how

77
00:02:47,278 --> 00:02:49,439
much volume is actually passing

78
00:02:49,439 --> 00:02:51,639
through each of those patterns.

79
00:02:52,349 --> 00:02:54,788
And we can, we can use that pattern to

80
00:02:54,788 --> 00:02:57,069
understand, OK, what, how do we give you full

81
00:02:57,069 --> 00:02:58,528
coverage of your application.

82
00:02:59,750 --> 00:03:01,788
By passing through data for all of those

83
00:03:01,788 --> 00:03:04,149
patterns and making sure that we don't miss

84
00:03:04,149 --> 00:03:05,330
anything that might be useful.

85
00:03:06,270 --> 00:03:08,288
And so this is all automatic.

86
00:03:08,469 --> 00:03:09,528
It works out of the box.

87
00:03:09,788 --> 00:03:12,189
We automatically look at the data, we automatically

88
00:03:12,189 --> 00:03:13,500
figure out what are the patterns.

89
00:03:13,788 --> 00:03:15,909
We can operate on millions of patterns

90
00:03:15,909 --> 00:03:16,558
in the data.

91
00:03:16,909 --> 00:03:19,379
Today we're doing this for logs and traces,

92
00:03:19,710 --> 00:03:21,710
and we're building metrics next year.

93
00:03:23,629 --> 00:03:26,379
So the way that Grepper

94
00:03:26,379 --> 00:03:28,889
works for logs is as the data's passing

95
00:03:28,889 --> 00:03:31,008
through in real time, we're figuring

96
00:03:31,008 --> 00:03:33,710
out what are the patterns in those logs.

97
00:03:34,050 --> 00:03:36,088
And so here in this example, we're

98
00:03:36,088 --> 00:03:38,129
seeing that hey, there's two patterns in the

99
00:03:38,129 --> 00:03:40,360
data. There's these gets and then there's

100
00:03:40,360 --> 00:03:41,210
these posts.

101
00:03:41,569 --> 00:03:43,729
And what we do is we pass through those

102
00:03:43,729 --> 00:03:45,889
initial few samples for each

103
00:03:45,889 --> 00:03:46,960
of those patterns,

104
00:03:47,288 --> 00:03:49,490
and once we have enough samples, then we say, hey,

105
00:03:49,610 --> 00:03:51,838
we've seen enough of those log messages,

106
00:03:51,919 --> 00:03:52,830
let's actually start

107
00:03:53,159 --> 00:03:54,189
reducing them.

108
00:03:54,610 --> 00:03:56,689
And then at the end of a 2 minute window, we'll

109
00:03:56,689 --> 00:03:58,689
send you a summary saying, hey, we've seen this much

110
00:03:58,689 --> 00:04:00,969
of this pattern, we've seen that much of this pattern,

111
00:04:01,409 --> 00:04:03,409
and we can also aggregate data inside

112
00:04:03,409 --> 00:04:05,409
of those patterns so that we can say things

113
00:04:05,409 --> 00:04:06,028
like we've seen

114
00:04:06,528 --> 00:04:08,689
an average latency of this much or

115
00:04:08,689 --> 00:04:10,610
this many bytes actually passed through.

116
00:04:11,080 --> 00:04:12,538
So this allows you to get

117
00:04:13,338 --> 00:04:14,919
exactly the data that you need,

118
00:04:15,240 --> 00:04:16,338
high signal data

119
00:04:16,838 --> 00:04:18,920
passed through downstream, whether to AI

120
00:04:18,920 --> 00:04:20,920
models or down to your observability

121
00:04:20,920 --> 00:04:22,959
vendor. And all of

122
00:04:22,959 --> 00:04:25,059
this is super configurable, so you can make it

123
00:04:25,798 --> 00:04:27,959
be 1 minute instead of 2 minutes.

124
00:04:28,040 --> 00:04:30,040
You can change and decide, hey, I don't want

125
00:04:30,040 --> 00:04:32,000
to aggregate this pattern. I want to pass it through.

126
00:04:32,319 --> 00:04:34,358
We do things like automatically figure out

127
00:04:34,358 --> 00:04:37,079
what are the logs that are powering your dashboards

128
00:04:37,079 --> 00:04:39,189
and alerts, and we can

129
00:04:39,189 --> 00:04:41,278
automatically add them into Grepper so that we

130
00:04:41,278 --> 00:04:43,600
don't modify or we don't

131
00:04:43,600 --> 00:04:45,639
change your workflows and impact

132
00:04:45,639 --> 00:04:46,778
them if you roll it out.

133
00:04:48,819 --> 00:04:50,639
For traces, we do something similar.

134
00:04:51,028 --> 00:04:53,500
So if you're familiar with tail sampling,

135
00:04:53,540 --> 00:04:55,439
the way that it works is you

136
00:04:56,059 --> 00:04:58,338
look at the endpoints of

137
00:04:58,338 --> 00:05:00,420
the traces, like where they're hitting, where they're getting

138
00:05:00,420 --> 00:05:02,720
started, and then you start

139
00:05:02,778 --> 00:05:05,559
looking at the performance of each of those endpoints.

140
00:05:06,220 --> 00:05:07,920
But there's a problem here.

141
00:05:08,298 --> 00:05:10,639
What if that endpoint is sometimes cached

142
00:05:10,699 --> 00:05:12,119
and sometimes not cached?

143
00:05:12,738 --> 00:05:14,769
So that means that your data

144
00:05:14,769 --> 00:05:17,759
or your traces actually have different paths

145
00:05:17,769 --> 00:05:20,108
depending on whether the data is cached or not.

146
00:05:20,649 --> 00:05:22,889
So in this example, we're seeing all of the traces

147
00:05:22,889 --> 00:05:24,449
actually starting at a circle,

148
00:05:24,769 --> 00:05:26,790
and we have two red ones. One

149
00:05:26,790 --> 00:05:28,920
actually has only 2 hops,

150
00:05:28,928 --> 00:05:30,149
and the other one has

151
00:05:31,088 --> 00:05:32,600
4 hops, 3 hops,

152
00:05:32,980 --> 00:05:33,869
something like that.

153
00:05:34,449 --> 00:05:35,350
And so.

154
00:05:36,170 --> 00:05:38,488
You want to actually look at the performance

155
00:05:38,488 --> 00:05:40,608
of these two paths differently, even though

156
00:05:40,608 --> 00:05:42,910
they start at the same endpoint.

157
00:05:44,048 --> 00:05:46,329
And so what we do is we actually look at the full

158
00:05:46,329 --> 00:05:48,579
structure of every trace

159
00:05:48,850 --> 00:05:50,889
to map out your entire application

160
00:05:50,889 --> 00:05:53,250
and be able to understand, OK, here are all

161
00:05:53,250 --> 00:05:54,790
the things that we need to

162
00:05:55,048 --> 00:05:57,290
pass through and make sure that the end user

163
00:05:57,290 --> 00:05:58,100
is aware of.

164
00:05:59,009 --> 00:06:02,528
No Then

165
00:06:02,528 --> 00:06:04,649
we keep track of the performance

166
00:06:04,649 --> 00:06:06,689
of each of those different signatures of

167
00:06:06,689 --> 00:06:08,278
these full structures,

168
00:06:08,649 --> 00:06:11,838
which allows us to understand when is this

169
00:06:11,838 --> 00:06:13,889
particular path slow and when is that particular

170
00:06:13,889 --> 00:06:14,928
path fast.

171
00:06:15,329 --> 00:06:17,608
And then we can drop the noisy

172
00:06:17,608 --> 00:06:20,059
data, the stuff that's actually unnecessary,

173
00:06:20,170 --> 00:06:21,269
and give you full

174
00:06:21,889 --> 00:06:23,920
sampling across your entire

175
00:06:23,920 --> 00:06:25,470
application so we can cover everything.

176
00:06:27,970 --> 00:06:29,970
But ultimately no data is ever lost.

177
00:06:30,338 --> 00:06:32,338
So what we do is we put all the

178
00:06:32,338 --> 00:06:34,420
raw data into an observability data

179
00:06:34,420 --> 00:06:34,949
lake,

180
00:06:35,230 --> 00:06:37,678
which allows us to keep that data

181
00:06:37,678 --> 00:06:40,079
in at low cost

182
00:06:40,259 --> 00:06:41,488
for a very long time.

183
00:06:41,778 --> 00:06:43,600
You can keep it as long as you wanted it to.

184
00:06:44,189 --> 00:06:46,358
And it can always be queried.

185
00:06:46,600 --> 00:06:48,889
You can, if you ever wanted to go find a log

186
00:06:48,889 --> 00:06:49,709
message from

187
00:06:50,088 --> 00:06:52,088
6 months ago, you can go and look

188
00:06:52,088 --> 00:06:54,088
at it. You don't have to do a hydration,

189
00:06:54,369 --> 00:06:56,449
but if you wanted to, you could go and backfill that

190
00:06:56,449 --> 00:06:58,629
data back into your observability vendor,

191
00:06:59,048 --> 00:07:00,129
or you could

192
00:07:00,689 --> 00:07:01,250
have it

193
00:07:01,569 --> 00:07:04,048
be triggered to be manually

194
00:07:04,048 --> 00:07:06,309
backfilled or automatically backfilled.

195
00:07:06,689 --> 00:07:08,769
So you can hook up this backfill,

196
00:07:08,928 --> 00:07:10,730
let's say, to a ticketing system.

197
00:07:11,088 --> 00:07:11,910
If a customer

198
00:07:12,488 --> 00:07:14,569
opens a particular ticket, maybe you want to go

199
00:07:14,569 --> 00:07:16,608
and load all the logs that

200
00:07:16,608 --> 00:07:18,170
are relevant for that customer

201
00:07:18,528 --> 00:07:20,649
or all the traces that are relevant for that

202
00:07:20,649 --> 00:07:21,170
customer,

203
00:07:21,500 --> 00:07:23,569
or maybe you have some anomaly or

204
00:07:23,569 --> 00:07:25,730
fraud detection system that you want

205
00:07:25,730 --> 00:07:27,829
to hook up so that when an analyst

206
00:07:28,528 --> 00:07:30,108
finds that there's an anomaly, they're

207
00:07:31,160 --> 00:07:33,290
already all the logs are already there in your end

208
00:07:33,290 --> 00:07:35,069
system for them to go and troubleshoot.

209
00:07:38,040 --> 00:07:40,358
And what we've seen as results are

210
00:07:40,358 --> 00:07:42,660
very encouraging from our customers. We

211
00:07:42,660 --> 00:07:44,678
see over 90%

212
00:07:44,678 --> 00:07:46,838
reduction in many cases with very

213
00:07:46,838 --> 00:07:47,819
minimal impact

214
00:07:48,319 --> 00:07:50,259
to developer workflows.

215
00:07:50,819 --> 00:07:52,920
Grepper usually takes about 30 minutes to

216
00:07:52,920 --> 00:07:54,949
get started with. You just set it

217
00:07:54,949 --> 00:07:55,720
up. You get,

218
00:07:56,480 --> 00:07:58,548
you point your existing agents into

219
00:07:58,548 --> 00:08:00,588
Grepper, and Grepper automatically

220
00:08:00,588 --> 00:08:02,949
starts working to figure out what are all the patterns,

221
00:08:03,358 --> 00:08:04,420
do the compression,

222
00:08:04,759 --> 00:08:06,220
and send the data through.

223
00:08:06,790 --> 00:08:08,959
So this changes that

224
00:08:08,959 --> 00:08:10,959
conversation with your developers or your

225
00:08:10,959 --> 00:08:13,119
SREs who are trying to figure out, OK, well

226
00:08:13,119 --> 00:08:13,778
how do I,

227
00:08:14,079 --> 00:08:16,639
how do I even get started? I've got 100

228
00:08:16,639 --> 00:08:18,809
teams, they're all using logs or

229
00:08:18,809 --> 00:08:19,600
traces,

230
00:08:19,879 --> 00:08:22,220
and I need to really cut down this spend,

231
00:08:22,720 --> 00:08:24,459
but I'm not really sure where to start.

232
00:08:24,798 --> 00:08:27,000
Do I start looking at patterns one by

233
00:08:27,000 --> 00:08:29,278
one and adding drop filters and sampling

234
00:08:29,278 --> 00:08:30,619
rates for these patterns?

235
00:08:31,040 --> 00:08:33,259
What we do is we just set it up automatically

236
00:08:33,259 --> 00:08:35,898
for you. And that changes the

237
00:08:35,898 --> 00:08:38,188
conversation from being, hey, here's a blank slate, do

238
00:08:38,188 --> 00:08:39,609
something, learn this

239
00:08:39,869 --> 00:08:41,479
thing, get certified in it,

240
00:08:41,908 --> 00:08:43,908
to a place where it's actually more

241
00:08:43,908 --> 00:08:44,629
about tuning.

242
00:08:45,408 --> 00:08:47,489
So you set that, set it up, it starts

243
00:08:47,489 --> 00:08:48,029
working.

244
00:08:48,609 --> 00:08:50,690
You look at the data that's passing through.

245
00:08:50,769 --> 00:08:53,009
You can make decisions. Is this good? Is this

246
00:08:53,009 --> 00:08:54,269
enough? Do I need more?

247
00:08:54,690 --> 00:08:56,808
And you can do that as time moves on because

248
00:08:56,808 --> 00:08:58,250
ultimately there's no risk.

249
00:08:58,570 --> 00:09:00,808
The data's all in the data lake. So if you ever needed

250
00:09:00,808 --> 00:09:03,190
something that isn't actually forwarded,

251
00:09:03,408 --> 00:09:05,489
you can always go back into the data lake to fetch

252
00:09:05,489 --> 00:09:07,729
it. You'll always find everything there,

253
00:09:08,129 --> 00:09:10,210
but this makes it really easy to roll out

254
00:09:10,210 --> 00:09:10,908
Grepper

255
00:09:11,298 --> 00:09:12,690
with the assurance that.

256
00:09:13,239 --> 00:09:15,058
Your data is going to be there

257
00:09:15,399 --> 00:09:17,629
without impacting workflows and actually increasing

258
00:09:17,629 --> 00:09:18,239
MTTR.

259
00:09:21,509 --> 00:09:22,058
Thank you.

260
00:09:22,359 --> 00:09:24,678
This is a very quick talk because Grepper

261
00:09:24,678 --> 00:09:27,639
is actually very fast and easy to

262
00:09:27,639 --> 00:09:29,759
describe, but I'm happy to

263
00:09:29,759 --> 00:09:31,879
take any questions since we've got

264
00:09:31,879 --> 00:09:32,820
about 10 minutes left.

