# AWS DynamoDB 深度解析会议总结

## 会议概述

本次技术分享由 AWS DynamoDB 团队的高级首席工程师 Amrith 主讲，他在数据库领域拥有 35 年的从业经验，在 DynamoDB 团队工作了约 6 年。与以往不同，本次演讲没有采用传统的架构图和框图方式，而是通过两个真实客户案例来深入剖析 DynamoDB 的内部架构和工作原理。

DynamoDB 是一个文档和键值存储数据库，其核心目标是在任何规模下提供可预测的低延迟性能。该服务被广泛应用于基础性服务中，如登录系统、库存管理等，Amazon.com 的大部分业务以及 AWS 大多数服务的控制平面都运行在 DynamoDB 上。为了说明其规模，演讲者用了一个生动的比喻：如果将一个奥林匹克游泳池（17,000 个浴缸的容量）清空，每处理一个请求就放入一粒米，那么在 61 秒内就能填满整个游泳池。这展示了 DynamoDB 每天处理的惊人请求量。

## 详细时间线与关键要点

### **开场介绍 (0:00 - 2:30)**
- **0:00** - 演讲开始，感谢观众选择参加本次深度技术分享
- **0:30** - 介绍演讲目的：为客户服务，分享实际使用经验
- **1:00** - 说明本年度演讲形式的改变：通过真实客户案例而非传统架构图来讲解
- **1:30** - 演讲者自我介绍：Amrith，高级首席工程师，在 DynamoDB 团队工作 6 年，数据库行业 35 年经验
- **2:00** - 强调最喜欢与客户合作，欢迎会后交流

### **DynamoDB 核心特性介绍 (2:30 - 5:00)**
- **2:30** - DynamoDB 定义：文档和键值存储数据库
- **3:00** - 核心承诺：在任何规模下提供可预测的低延迟
- **3:30** - 典型应用场景：基础服务（登录、库存管理、Amazon.com 大部分业务）
- **4:00** - 性能指标：超过 5 个 9 的可用性（99.999%），大多数请求在个位数毫秒内完成
- **4:30** - 完全托管服务，无论 10 TPS 还是 50 万 RPS 都能保持相同延迟

### **规模演示：游泳池比喻 (5:00 - 7:00)**
- **5:00** - 展示奥林匹克游泳池图片（50m x 25m x 2m，2500 立方米）
- **5:30** - 换算：相当于 17,000 个浴缸的容量
- **6:00** - 比喻说明：每处理一个 DynamoDB 请求就放入一粒米
- **6:30** - 提问观众：需要多少天填满游泳池？答案：不到一天，实际上只需 61 秒
- **6:45** - 强调 DynamoDB 的处理规模：每分钟可以填满一个游泳池

### **案例一：全国投票系统的写入限流问题 (7:00 - 30:00)**

#### **问题描述 (7:00 - 10:00)**
- **7:00** - 引入第一个真实客户案例
- **7:30** - 客户报告：应用程序遇到意外的写入限流（throttling）
- **8:00** - 背景：这是一个全国性投票系统，如果不能正常工作将造成国家级危机
- **8:30** - 系统迁移：从传统 RDBMS 迁移到 DynamoDB
- **9:00** - 旧系统：仅需处理 600 TPS（人们到实体地点投票）
- **9:30** - COVID 影响：需要开发自助移动应用，要求处理 45,000 TPS

#### **初步调查 (10:00 - 15:00)**
- **10:00** - 客户反馈：在 800 TPS 时就出现写入限流
- **10:30** - 工程师困惑：800 TPS 对 DynamoDB 来说是极小的负载
- **11:00** - 应用架构说明：非常简单的应用，一次读取，三次写入
- **11:30** - 匿名性要求：这是应用设计的核心需求
- **12:00** - 工作流程：读取一个表，写入三个表
- **12:30** - 三个表：国家 ID 表、个人身份信息表（PII）、调查表
- **13:00** - 随机 ID 设计：使用 PID 和 SID 两个随机 ID 来分离数据
- **13:30** - 安全设计：通过低基数哈希确保无法反向追踪个人投票选择
- **14:00** - 应用流程：生成随机 ID → 记录 PII → 记录调查结果 → 存储单向哈希
- **14:30** - 困惑加深：如此简单的应用为何会限流？

#### **深入分析 (15:00 - 22:00)**
- **15:00** - 检查表配置：客户已正确扩展表，使用高基数键
- **15:30** - 检查模式：国家 ID 表和随机 ID 表都有全局二级索引（GSI）
- **16:00** - GSI 作用：提供另一种访问模式
- **16:30** - 检查项目大小：500 字节、2KB、400 字节，都很小
- **17:00** - 关键发现：随机 ID 不是运行时生成的
- **17:30** - 真相揭露：随机 ID 表是预先填充的，应用通过扫描获取随机 ID
- **18:00** - 随机数生成器机制：微服务批量读取行（如 1000 行），记录最后评估键
- **18:30** - 验证：确认 SID 的唯一性（法定要求）
- **19:00** - 定位问题：限流发生在 PII 表（500 字节的表），而非 2KB 的表
- **19:30** - 提问观众：是否有人知道问题所在？
- **20:00** - 团队同样困惑：无法理解为何会在 800 TPS 时限流

#### **DynamoDB 分区机制讲解 (22:00 - 27:00)**
- **22:00** - 解释 DynamoDB 扩展方式：水平扩展，基于哈希的分区
- **22:30** - 分区过程：计算分区键的哈希值 → 基于哈希值排序 → 创建连续范围的分区
- **23:00** - 哈希函数特性：快速、均匀分布
- **23:30** - 确定性哈希：无论哪个表、哪个用户，x = y 则 hash(x) = hash(y)
- **24:00** - 雪崩效应：输入的微小变化导致哈希值的巨大且不可预测的变化
- **24:30** - 展示随机 ID 表的实际存储：按哈希值排序存储在分区中
- **25:00** - 扫描操作：按哈希顺序遍历表
- **25:30** - 返回最后评估键：允许从相同位置继续扫描
- **26:00** - 随机数生成器的实际行为：扫描表，返回看似随机但实际按哈希顺序的数据
- **26:30** - 数据展示：对用户来说看起来完全随机

#### **问题根源与解决方案 (27:00 - 30:00)**
- **27:00** - 问题揭示：写入调查表时，SID 分布在所有分区（良好）
- **27:30** - 但写入 PII 表时，由于使用相同的 PID 键，写入按哈希顺序进行
- **28:00** - 结果：连续写入集中在单个分区，然后移到下一个分区
- **28:30** - 无法获得水平扩展的好处：一次只能使用一个分区的吞吐量
- **29:00** - 根本原因：确定性哈希的意外后果
- **29:30** - 解决方案：在写入 PII 表时，在 ID 前添加两个字符前缀（如 "TX"）
- **29:45** - 利用雪崩效应：小改变导致哈希值大变化，写入分布到所有分区

### **案例一总结与最佳实践 (30:00 - 35:00)**
- **30:00** - 实施结果：客户成功在 90,000 TPS 下进行基准测试（目标是 45,000 TPS）
- **30:30** - 投票顺利进行，没有任何问题
- **31:00** - 关键要点：DynamoDB 通过哈希分区扩展
- **31:30** - 警告：如果从一个表读取并写入另一个使用相同键的表，可能遇到此问题
- **32:00** - GSI 注意事项：大量具有相同 GSI 值的项目会导致性能下降
- **32:30** - 高基数和唯一性的重要性
- **33:00** - AWS 计划修复确定性哈希问题，但需要时间
- **33:30** - 建议：不要依赖当前的哈希行为
- **34:00** - 调试限流的工具：CloudWatch Contributor Insights
- **34:30** - 新功能：仅限流键模式，大幅降低成本

### **新功能介绍 (35:00 - 40:00)**
- **35:00** - 增强错误代码：向后兼容，标识确切的资源和原因
- **35:30** - 10 个新的 CloudWatch Contributor Insights 指标
- **36:00** - 历史限制：分区键和排序键只能是单个属性
- **36:30** - 常见 hack：使用分隔符连接多个值（如 "customerID#orderID"）
- **37:00** - 问题：数据冗余、存储成本翻倍、可能不同步
- **37:30** - 模式演化困难：需要回填数据
- **38:00** - 新功能发布（一周前）：分区键和排序键最多支持 4 个属性
- **38:30** - 当前仅支持 GSI，未来可能扩展到表
- **39:00** - 文档链接和 LinkedIn 帖子
- **39:30** - MCP 支持：模式建模顾问工具

### **案例二：批处理与交互式工作负载的延迟问题 (40:00 - 55:00)**

#### **问题描述 (40:00 - 43:00)**
- **40:00** - 引入第二个真实客户案例
- **40:30** - 展示内部工具 Hawkeye 的视图（支持团队使用）
- **41:00** - 7 天流量历史数据：峰值与谷值相差约 2000 倍
- **41:30** - 应用特点：每天运行一次批处理作业，产生高流量峰值
- **42:00** - 这是正常行为，不是异常
- **42:30** - 两种工作负载：持续交互式（低流量）和批处理（高流量峰值）
- **43:00** - 反直觉现象：低流量时延迟高且不稳定，高流量时延迟低且稳定

#### **数据分析 (43:00 - 46:00)**
- **43:00** - 平均延迟数据：高流量 = 低延迟，低流量 = 高延迟
- **43:30** - P90 数据：显示相同模式
- **44:00** - 构建模拟器：在实验室中重现问题
- **44:30** - 成功重现：高流量低延迟，低流量高延迟
- **45:00** - 请求类型：GetItem 和 PutItem
- **45:30** - 第二天数据：相同行为模式
- **46:00** - 提问观众：是否有人知道问题所在？

#### **应用架构分析 (46:00 - 48:00)**
- **46:00** - 应用描述：持续流量 + 批处理流量
- **46:30** - 模拟环境：150 个主机实例
- **47:00** - 架构简单：主机群 → DynamoDB
- **47:30** - 困惑：为何高流量好延迟，低流量差延迟？
- **48:00** - 决定深入研究 DynamoDB 架构

#### **DynamoDB 架构详解 (48:00 - 52:00)**
- **48:00** - 请求路径：应用 → SDK → 公共端点 → 负载均衡器
- **48:30** - 负载均衡器：跨多个可用区
- **49:00** - 请求路由器：每个请求都需要身份验证和授权
- **49:30** - 验证过程：检查 SigV4 签名、权限
- **50:00** - 元数据查找和速率限制
- **50:30** - 存储节点：实际数据存储位置
- **51:00** - 加密：所有数据静态加密，需要从 KMS 获取解密密钥
- **51:30** - 存储节点上的速率限制
- **52:00** - 关键点：为了性能，大量使用缓存

#### **缓存机制与问题根源 (52:00 - 54:00)**
- **52:00** - 请求路由器维护多种缓存：元数据、身份信息
- **52:30** - TCP 连接：从应用到请求路由器
- **53:00** - 关键：重用相同连接可获得缓存优势
- **53:30** - 频繁重连的代价：TCP 握手、TLS 建立、身份验证
- **54:00** - 建议：尽可能使用长连接

#### **解决方案 (54:00 - 56:00)**
- **54:00** - 问题诊断：客户有数千个容器
- **54:30** - 流量对比：批处理 20,000 TPS，持续流量 10 TPS（2000 倍差异）
- **55:00** - 静态稳定设计：始终按峰值容量配置，无需控制平面更改
- **55:30** - 模拟结果：高流量低延迟，低流量高且可变延迟
- **56:00** - 重新配置：将持续交互式流量仅路由到少量主机

#### **效果展示与建议 (56:00 - 58:00)**
- **56:00** - 重新配置后的结果：延迟立即变为平稳的低延迟
- **56:30** - 原因：现在能够充分利用所有缓存
- **57:00** - 两种可选方案：低流量时减少主机（节省成本但非静态稳定）
- **57:30** - 推荐方案：保持相同数量主机，但将低流量路由到少量主机
- **58:00** - 模拟验证：该方案有效

### **总结与结束 (58:00 - 60:00)**
- **58:00** - 核心观点：理解数据库内部工作原理至关重要
- **58:30** - 类比：任何人都能买油漆，但创作艺术需要思考和创造力
- **59:00** - 客户构建的是复杂应用，需要深思熟虑
- **59:30** - AWS 团队随时准备提供帮助
- **59:45** - 呼吁：请继续提供反馈
- **60:00** - 演讲结束，观众鼓掌

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


## 关键技术要点总结

1. 哈希分区机制：DynamoDB 使用确定性哈希和雪崩效应进行数据分区
2. 限流问题：扫描操作返回按哈希顺序排列的数据，可能导致写入集中在单个分区
3. 解决策略：通过添加前缀利用雪崩效应分散写入负载
4. 缓存优化：长连接和流量集中可显著提升性能
5. 新功能：复合键支持（最多 4 个属性）简化数据建模