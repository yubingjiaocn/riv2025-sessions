# AWS re:Invent 2025 会议总结：Netflix 数据库迁移实践

## 会议概述

本次技术分享由 Netflix 数据平台团队工程师 Ammar 主讲，详细介绍了 Netflix 如何将数十个运行在第三方 Postgres 兼容分布式数据库上的应用迁移到 Amazon Aurora Postgres 的完整实践过程。作为平台团队，他们需要为整个公司的应用团队执行这次大规模迁移，涉及超过 100 个不同规模和需求的应用程序。

演讲者重点强调了在真实生产环境中进行数据库迁移的复杂性，包括不同应用的数据访问模式差异、多种编程语言支持、不同的停机时间要求，以及与数据平台其他组件的集成挑战。Netflix 团队通过构建自动化工具链，结合 AWS DMS 服务，实现了高效的批量迁移，最终达到了超过 90% 的迁移完成率，且无需任何回滚操作。

## 详细时间线与关键要点

### 0:00-2:30 - 问题背景与迁移动机
- Netflix 数据平台团队管理着大量运行在第三方 Postgres 兼容分布式数据库上的应用
- 面临的挑战：自管理维护成本高、Postgres 兼容性问题、运营成本昂贵
- Aurora Postgres 在功能、可靠性和成本方面的改进促使迁移决策
- 平台团队主导迁移以减少应用团队工作量

### 2:30-5:00 - 迁移复杂性分析
- 超过 100 个应用，每个都有不同的数据形状和访问模式
- 支持多种编程语言的应用
- 不同应用的停机时间要求差异巨大（从 30 秒到 4 小时）
- 数据库与流处理、分析连接器等数据平台组件的集成依赖

### 5:00-8:30 - 预检查阶段（Pre-flight Checks）
- 使用 AWS DMS Schema Conversion Tool 生成兼容性报告
- 与 AWS 合作添加对第三方数据库的支持
- 对应用 SQL 语句进行采样测试，验证在 Postgres 上的兼容性
- 基于流量模式预先配置目标 Aurora 集群
- 创建临时集群供应用团队测试验证

### 8:30-12:00 - 模式和数据复制
- 构建基于 AWS DMS 的模式复制工具
- 发现并修复模式转换问题（如 VARCHAR 长度错误转换）
- 实施全量数据加载和 CDC（变更数据捕获）
- 构建监控工具及早发现复制任务失败

### 12:00-15:30 - 数据验证策略
- 批量验证：将源和目标数据导入数据仓库进行大规模 SQL 连接验证
- 实时验证：使用 Flink 作业比较源和目标数据流
- 双重验证机制确保历史数据和实时数据的准确性

### 15:30-19:00 - 切换过程（Cut-over）
- 利用代理层实现应用无感知切换
- 详细的切换步骤：
  - 测量复制延迟（通常 15-16 秒）
  - 运行批量和在线验证
  - 验证应用通过代理连接
  - 迁移流处理和批处理基础设施
  - 阻止源数据库写入
  - 同步序列值
  - 等待复制追赶
  - 切换代理指向目标数据库

### 19:00-21:30 - 项目成果与经验总结
- 项目历时近一年，从去年 12 月开始，4 月首次迁移
- 目前完成率超过 90%，剩余少量大数据集特殊处理
- 性能改善：部分应用延迟显著降低
- 发现并修复约 10 个数据损坏 bug
- 零回滚记录，仅有少量前向修复案例
- 关键成功因素：全量预检查、基于现有工具构建、专注最小公分母解决方案