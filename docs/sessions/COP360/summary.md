# AWS re:Invent 2025 会议总结:使用 Amazon Bedrock Guardrails 和 Amazon CloudWatch 构建负责任的 AI 应用

## 会议概述

本次技术分享会聚焦于如何构建负责任的 AI 应用程序,主讲人 Sashikan Maladi(AWS 首席技术客户经理和可观测性专家)提出了企业在 AI 应用部署中面临的三大核心问题:如何确保用户负责任地使用 AI 应用、如何防止敏感信息泄露给未授权用户、以及如何确保 AI 投资真正驱动业务价值而非制造混乱和风险。根据分析师数据,66% 的高管将数据隐私和安全视为首要 AI 风险,77% 的高管认为真正的 AI 系统必须建立在信任基础之上。

演讲通过两个真实场景展示了 AI 应用的风险:银行场景中 AI 产生幻觉(hallucination)提供虚假信息,以及客服中心场景中敏感个人信息(姓名、电话、社保号等)被暴露。主讲人详细介绍了一个实用框架,通过 Amazon Bedrock Guardrails 在运行时强制执行安全策略,通过 Amazon CloudWatch 将遥测数据转化为可操作的洞察,最终形成"预防-检测-行动"的完整闭环。该框架可以阻止高达 88% 的有害内容和 75% 的幻觉问题,同时提供端到端的可见性和治理能力。

演讲强调了构建定制化仪表板的重要性,使组织能够全面了解 AI 系统的使用情况、性能指标和安全事件,并通过 CloudWatch Alarms 实现实时告警和补救措施,最终建立持续监控和优化的生命周期管理机制。

## 详细时间线与关键要点

00:00:00 - 开场与核心问题提出
- 提出三个让决策者和开发者夜不能寐的问题:用户是否负责任使用 AI、敏感信息是否泄露、AI 投资是否创造价值
- 引用行业数据:66% 高管关注数据隐私安全,77% 高管认为信任是 AI 系统基础

00:02:00 - 真实场景案例一:幻觉问题
- 银行应用场景:用户询问储蓄账户开户费用,但企业数据中无此信息
- AI 自信地给出虚假答案,展示幻觉(hallucination)风险
- 强调幻觉会侵蚀客户信任并带来业务风险

00:03:00 - 真实场景案例二:敏感信息泄露
- 客服中心场景:客户重置密码时提供全名、用户名、邮箱、电话和社保号
- 进行呼叫中心分析时,敏感信息可能暴露给未授权用户
- 展示数据隐私保护的重要性

00:04:30 - 负责任 AI 概述
- 介绍负责任 AI 面临的挑战:无关话题、有害内容、数据隐私、幻觉问题
- 定义负责任 AI:安全、数据保护、透明度、公平性、端到端监控和治理

00:06:00 - 解决方案框架介绍
- 三大核心能力:Amazon Bedrock Guardrails(运行时安全)、Amazon CloudWatch(洞察分析)、告警与行动机制
- Guardrails 功能:阻止有害内容、过滤敏感信息、防止幻觉、确保语气一致性
- CloudWatch 功能:提供使用者、使用方式、干预原因等可见性

00:08:00 - Amazon Bedrock Guardrails 详解
- 提供灵活配置:内容过滤、敏感信息匿名化或阻止、自定义词汇/短语/主题限制
- 效果数据:阻止 88% 有害内容,防止 75% 幻觉(通过自动推理和基础检查)

00:09:30 - Guardrails 实战效果对比
- 案例一对比:无 Guardrails 时产生幻觉 vs 有 Guardrails 时识别并阻止不准确信息
- 案例二对比:无 Guardrails 时泄露敏感信息 vs 有 Guardrails 时自动匿名化处理
- 强调可自定义响应方式(匿名化或完全阻止)

00:11:00 - Amazon CloudWatch 能力介绍
- 提供端到端全栈可观测性(AWS、本地、其他云)
- 生成式 AI 可观测性、AI 驱动的运维、基础设施监控
- 核心能力:指标、日志、洞察和强大的仪表板

00:12:30 - Guardrails 遥测数据自动化
- 无需额外配置即可获取所有 Guardrails 遥测数据
- 可分析模型调用次数、Guardrails 干预频率等关键指标
- 提供开箱即用的自动化仪表板

00:13:30 - 自动化仪表板功能
- 显示总调用次数、Guardrails 干预次数、模型性能延迟
- 开箱即用,无需配置

00:14:00 - 定制化仪表板深度解析
- 单一视图展示完整 AI 应用的性能和安全状况
- 详细分解各个组件功能

00:15:00 - 模型使用洞察
- 跨账户、跨区域、跨模型的使用分析
- 识别最常用模型和调用频率
- 帮助理解模型使用如何驱动 AI 支出

00:16:00 - Guardrails 干预分析
- 区分用户提示词触发 vs 模型响应触发
- 按类别分析:内容问题 vs 敏感信息问题
- 所有数据均可从 Guardrails 遥测指标中获取

00:17:00 - 性能与调用统计
- 总调用次数 vs Guardrails 干预次数
- 评估 Guardrails 敏感度
- 延迟分析:是否增加额外延迟

00:18:00 - 敏感信息深度分析
- 识别泄露的信息类型:姓名、邮箱、电话、社保号、银行账号等
- 检测被拒绝的主题(如投资建议、安全相关话题)
- 识别被阻止的词汇和亵渎性语言

00:19:00 - 幻觉检测视图
- 基于基础检查和无关话题检测
- 识别用户提示或模型响应中的无关内容
- 内容分析:仇恨言论、侮辱性语言、提示词攻击(类似 DDoS)

00:20:00 - 账户与用户分析
- 识别哪些账户导致 Guardrails 干预
- 追踪"不良行为者"和违规用户
- 提供钻取能力定位具体违规来源

00:21:00 - 仪表板构建技术
- 使用 CloudWatch 指标和日志洞察构建
- 支持 SQL 风格查询和自然语言查询
- 可将查询结果作为仪表板组件

00:22:00 - CloudWatch Logs 数据保护
- 第二层保护:Guardrails 保护提示词层,Logs 数据保护保护日志层
- 应对模型日志启用或开发者打印语句场景
- 简单配置,100+ 托管数据标识符,支持自定义正则表达式

00:23:30 - 数据保护实战效果
- 自动检测敏感信息:姓名、邮箱、电话、社保号、驾照、银行账号等
- 自动编辑敏感信息(用星号替换)
- 实现端到端双层保护

00:24:30 - CloudWatch Alarms 告警机制
- 持续监控 Guardrails 遥测指标
- 阈值突破时触发告警
- 示例:设置 Guardrails 干预次数阈值,实时采取补救措施
- 适用场景:提示词攻击、敏感信息泄露等

00:25:30 - 补救行动建议
- 评估组织风险并制定优先级计划
- 具体措施:分配负责任 AI 培训、调整 Guardrails 敏感度
- 持续监控和审计控制措施
- 迭代优化:更新培训和 Guardrails 配置应对新威胁

00:26:30 - 总结与后续步骤
- 回顾实用框架:使用 Amazon Bedrock Guardrails 和 Amazon CloudWatch 构建负责任 AI
- 提供资源二维码:专家讨论、实践研讨会、最佳实践指南
- 鼓励构建定制化仪表板,了解 AI 系统真实使用情况

00:27:30 - 行动号召与结束
- 邀请参会者访问 CloudWatch 展位进行一对一专家交流
- 领取纪念品
- 致谢结束