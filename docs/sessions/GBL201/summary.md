# AWS re:Invent 2025 会议总结

## 会议概述

本次AWS re:Invent 2025分组会议重点介绍了如何在大规模环境中实现弹性架构并通过AI优化成本。会议展示了两个重要案例研究：三星电子和Kakao公司如何利用AWS服务构建智能化运维系统。

会议首先介绍了AWS在生成式AI领域的最新服务更新，包括基础设施层的Trainium 3芯片、NVIDIA Grace Blackwell GPU，以及SageMaker的新功能。在平台层，Bedrock增加了20多个模型，特别是Nova 2代系列和Nova Forge定制化功能。应用层推出了三个前沿自主代理：Kiro自主代理（开发者助手）、安全代理和DevOps代理，这些代理能够在无人工干预的情况下完成复杂任务。

三星电子MX部门分享了如何通过FinOps和AIOps两个项目实现成本优化和运维稳定性。他们定义了"单位成本"(Unicost)指标来衡量成本效率，并使用多代理架构（基于Agent Core和Strands SDK）构建了AI驱动的成本分析系统。Kakao则展示了如何革新日志系统，采用ClickHouse作为统一存储，每天处理超过20TB的日志数据，并通过AI实现智能化可观测性。

## 详细时间线

### 开场与AWS服务更新 (00:00 - 15:00)

00:00 - 02:30 - 会议开场，感谢参会者在晚间时段出席

02:30 - 05:00 - 介绍会议主题：两个关于大规模弹性实施和AI成本优化的案例研究

05:00 - 08:30 - AWS生成式AI基础设施层更新
- Trainium 3芯片发布，Ultra Server配备144个Trainium 3芯片
- NVIDIA Grace Blackwell 200/300 GPU更新至P3 EC2实例

08:30 - 12:00 - SageMaker平台更新
- 无服务器模式的模型定制功能
- Hyperpad新增无检查点训练功能，防止服务器故障导致训练重启

12:00 - 15:00 - Bedrock和Agent服务更新
- 超过20个模型可用，100,000+客户使用
- Agent Core和Strands SDK功能增强

### AWS前沿代理介绍 (15:00 - 25:00)

15:00 - 18:00 - 应用层服务介绍
- Amazon Kicks（AI网页开发工具）
- QuickSight更名并增强功能
- AWS Transform（遗留代码现代化服务）
- AWS Connect（联络中心AI增强）

18:00 - 22:00 - 三个前沿自主代理发布
- Kiro自主代理：可在数天至数十天内无人工干预完成开发任务
- 安全代理：自动进行安全检查、渗透测试模拟
- DevOps代理：连接CloudWatch、DynaTrace等监控服务，自动分析故障并采取行动

22:00 - 25:00 - Bedrock模型更新
- Mistral Large 3和3个轻量级模型
- Nova 2代系列：Lite、Pro、Sonic（语音）、Omni（多模态）
- Nova Forge：全新定制方法，可在模型训练的任意阶段插入检查点

### Strands SDK和Agent Core详解 (25:00 - 35:00)

25:00 - 28:00 - Strands SDK特性
- 开源Python SDK，现已支持TypeScript
- 新增边缘设备支持，可离线使用
- 仅需几行代码即可构建代理

28:00 - 32:00 - Agent Core功能模块
- Runtime（运行代理代码）
- Gateway（自动管理MCP等工具）
- Memory（会话短期内存）
- Identity（身份验证和授权）
- Agent Co-op（监控和调试）
- Self-browser和Code Interpreter（Python沙箱环境）

32:00 - 35:00 - Agent Core新增功能
- Policy（策略控制，如退款限额管理）
- Quality Management（结果评估和量化）
- Episode功能（长期记忆，基于过去经验）

### 三星电子案例：FinOps与AIOps (35:00 - 70:00)

35:00 - 38:00 - 三星电子背景介绍
- 2009年开始使用AWS（Galaxy系列）
- 目前超过150个服务运行在AWS上
- 成本和使用量每年增长超过10%
- Galaxy AI在2024年显著增加成本和使用量

38:00 - 42:00 - 面临的挑战
- 开发组织优先考虑开发进度，较少关注系统故障和成本
- 运维组织优先考虑稳定性
- 财务部门质疑成本增长与Galaxy销售/服务激活的关系
- 需要同时满足稳定性和成本效率

42:00 - 48:00 - FinOps项目：Unicost指标定义
- Unicost = 总成本 / 交易数量（每笔交易的成本）
- 理想状态：成本增加但Unicost下降，表明服务激活良好
- 通过Bixby项目进行POC验证

48:00 - 53:00 - Bixby成本优化实践
- 项目启动时Unicost处于峰值，成本增长但交易量未同步增长
- 应用Graviton、删除未使用资源、扩展RI/SP比例
- 首月成本下降但Unicost上升（发现季节性因素导致交易量下降）
- 后续月份根据交易量进行扩缩容，Unicost呈下降趋势
- 2024年实现年度成本降低10.4%

53:00 - 58:00 - AI驱动的成本分析架构
- 多代理架构，使用Agent Core和Strands SDK
- 四个代理：数据收集器、编排器、研究代理、协调器
- 数据源：Redshift中的AWS CUR数据、Unicost数据、设备信息
- 元数据管理：Amazon OpenSearch Vector DB存储常用查询
- 通过MCP协议连接Agent Gateway

58:00 - 65:00 - FinOps Chatbot演示
- 演示1：查询特定服务的月度AWS成本、资源使用模式、成本效率
  - 显示7月份月度成本、使用的AWS服务数量、各服务使用成本和比例
  - 按天显示使用模式、按区域显示数据
  - 详细说明低效使用部分及问题
  - 提供短中期战略计划和优化后的成本节省预测
- 演示2：比较两个服务的RI/SP覆盖率
  - B服务RI/SP覆盖率93.5%，C服务98.6%
  - 显示主要工作负载资源
  - 提供各资源的服务优化计划建议
  - 预测各服务的节省金额
  - 综合推荐成本效率实施顺序

65:00 - 70:00 - AIOps项目：四个AI应用方向
- 异常检测：在故障前快速检测异常，预防故障
- 云架构审查：检查云资源配置变化，发现安全漏洞
- 根因分析：快速分析故障原因，推荐恢复方案，判断故障级别
- 故障恢复建议：在无法快速恢复时推荐DR等方案

### 三星电子AIOps异常检测案例 (70:00 - 80:00)

70:00 - 73:00 - 异常检测场景
- Samsung Cloud有多个客户端
- 某些客户端因错误的新应用部署导致服务器流量过大
- 基础监控可快速检测，但渐进式异常行为（一周或一个月后才出现问题）难以发现

73:00 - 76:00 - 自建AI/ML模型解决方案
- 构建自有AI/ML模型进行异常检测
- 新应用分发时，如果模式与现有模式不同（如图表上升），快速检测并通知应用开发者
- 开发者询问问题后，修复外部部分并进行发布前修复
- 实际案例显示问题得到改善

76:00 - 80:00 - 未来AI扩展计划
- 云架构管理、云故障原因分析、云故障恢复建议三个方向
- 在FinOps中构建Amazon Bedrock代理
- 将多代理架构扩展到AI领域
- 考虑应用主题演讲中发布的安全代理和DevOps代理
- 多代理架构作为基础框架持续推进

### 三星电子经验总结与2026计划 (80:00 - 90:00)

80:00 - 83:00 - 四点经验教训
1. 领导层需要明确定义和沟通：领导层对FinOps和AIOps表现出浓厚兴趣，设定明确期望，认可过去成就，避免过度期望或低估
2. AI应用策略：不应仅在必要时使用AI，而应在业务流程中分析并完全用AI替代某些部分，使运维人员和用户必须持续使用，从而真正持续提高工作效率
3. 数据质量至关重要：80%的AI工作是准备数据和创建数据管道，错误数据导致错误响应，需要建立数据治理和数据质量管理系统
4. 技术选择要适配问题：最优技术不一定是最新技术，简单数据分析可获得洞察，大量实时数据可能使用代理AI成本更高，需根据问题性质、数据量和数据性质适当应用AI

83:00 - 87:00 - 2026年计划：智能云运维
- AI领域：继续异常检测、云变更审查、漏洞分析、基于AI的故障恢复、DR推荐、故障级别判断
- 安全领域：引入云AI安全解决方案，实时检测AI恶意行为，构建自动化合规
- 成本领域：继续使用FinOps，提高成本效率建议的稳定性和准确性
- 多云成本管理：构建集成管理多云成本的系统
- 成本分配自动化：150个服务的成本分配目前几乎完全手动，计划通过AI或自动化实现

87:00 - 90:00 - 三星电子演讲结束，过渡到Kakao案例

### Kakao案例：AI原生可观测性 (90:00 - 130:00)

90:00 - 93:00 - Kakao背景介绍
- KakaoTalk月活跃用户约4900万，几乎所有韩国公民使用
- 部分系统每天生成超过20TB日志
- 存储3个月约1.4 PB
- 2025年是KakaoTalk服务推出15周年，功能多、微服务复杂度高

93:00 - 98:00 - 现有日志系统面临的困难
1. 大规模问题：
   - 日志规模太大，难以构建集成日志系统
   - 并行使用Elasticsearch和Loki
   - ES性能好但大规模环境下可扩展性有限，扩容成本呈指数增长，每个集群节点数有限制，需要不断增加集群，重新索引和重新平衡任务难度大
   - Loki相对易于操作且轻量，但大规模日志环境下查询性能显著下降，特别是高基数字段查询速度急剧下降，无法快速分析日志以响应CS或错误

2. 可观测性碎片化：
   - 开发者响应故障时需要打开Loki或Kibana查看日志
   - 还需检查指标，打开时间序列数据库仪表板
   - 开发者必须浏览多个工具并在脑海中整理数据
   - 响应障碍的速度不可避免地变慢

98:00 - 103:00 - 新可观测性策略
1. 统一存储库：创建能够有效容纳各种遥测数据的统一存储库
   - 选择ClickHouse（OLAP分析数据库）
   - Netflix案例：每天存储PB级日志，构建日志系统
   - 可观测性生态系统中的解决方案（Signose、HyperDx等）大多使用ClickHouse作为存储

2. 分层存储降低成本：
   - EBS比S3更贵
   - 仅在EBS中存储3天日志（主要搜索场景）
   - 3天以上的日志移至S3
   - 通过分层存储降低成本

103:00 - 108:00 - 新可观测性策略（续）
3. 标准化：
   - 各种服务和系统使用不同代理和协议收集遥测数据
   - 管理碎片化的代理和协议需要大量工作
   - 决定标准化公司内部可观测性标准
   - 采用CNCF的OpenTelemetry标准

4. 引入AI：
   - 开发者手动响应故障，速度和质量因开发者技能水平而异
   - 引入AI标准化这些领域
   - 目标：检测故障、识别故障区域、识别故障原因

108:00 - 113:00 - 现有架构回顾
- 部分系统将日志存储在Loki，部分存储在ES
- ES管道中有Kafka防止日志丢失
- AWS和本地环境混合配置

113:00 - 118:00 - 新架构设计
- AWS和本地环境混合配置
- Kafka作为AWS和本地环境之间的连接链路
- Kafka同时具有日志丢失防止功能，存储约3天日志
- 日志通过Kafka被AWS上的Otel收集器消费
- 消费的日志存储在AWS EKS上的ClickHouse集群
- ClickHouse存储：热存储使用EBS，冷存储使用S3
- 遵循OpenTelemetry标准的管道
- 统一存储库可存储日志、指标、跟踪等各种遥测数据

118:00 - 125:00 - 独特的可用性策略
- 不使用副本（replica）确保可用性
- 使用ClickHouse的备份和恢复功能
- Kafka存储约3天日志也是保障轴之一
- 原因：日志规模大，存储副本会使存储成本翻倍，成本显著
- ClickHouse的备份和恢复功能足够有用

125:00 - 130:00 - 备份恢复性能测试数据
- 现有ES（60TB数据）：备份和恢复各需超过1天，难以日常使用
- ClickHouse案例1（195TB，S3+EBS）：备份和恢复各约2小时20分钟
- ClickHouse案例2（40TB）：备份约30分钟，恢复约40分钟
- 该性能水平可以进行日常备份，出现问题时恢复

### 会议结束 (130:00+)

130:00+ - 演讲内容在此处被截断

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


注： 本总结基于提供的字幕文本，部分内容可能因字幕质量或演讲连贯性而存在理解偏差。