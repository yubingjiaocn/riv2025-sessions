1
00:00:00,000 --> 00:00:02,040
- People who have put a
headset, can you hear me fine?

2
00:00:02,040 --> 00:00:03,750
Can you raise your hand
if you can hear me fine?

3
00:00:03,750 --> 00:00:05,100
Awesome. Perfect.

4
00:00:05,100 --> 00:00:06,420
First of all, thank you so much

5
00:00:06,420 --> 00:00:10,110
for being here on a Wednesday
morning in Vegas at 8:30,

6
00:00:10,110 --> 00:00:12,693
and choosing us versus
Swami, I appreciate it.

7
00:00:13,530 --> 00:00:15,960
So this is IND 3303,

8
00:00:15,960 --> 00:00:20,010
Moody's: Architecting a
multi-agent system on AWS.

9
00:00:20,010 --> 00:00:20,843
My name is Samuel Baruffi,

10
00:00:20,843 --> 00:00:24,060
and I'm Principal
Solutions Architect at AWS.

11
00:00:24,060 --> 00:00:26,730
And I have the pleasure to
have with me Dennis Climent.

12
00:00:26,730 --> 00:00:29,670
Dennis is a managing director,
Engineering and Architecture

13
00:00:29,670 --> 00:00:32,820
for Moody's Digital
Content and Innovation.

14
00:00:32,820 --> 00:00:36,960
So in the next 60 minutes or so, me

15
00:00:36,960 --> 00:00:38,400
and Dennis are gonna
go through the journey

16
00:00:38,400 --> 00:00:39,660
that we've been working together

17
00:00:39,660 --> 00:00:42,960
on how Moody's have revolutionized
their way of thinking

18
00:00:42,960 --> 00:00:45,873
and serving their customers
through an agentic system.

19
00:00:48,090 --> 00:00:48,990
Before I get started, maybe

20
00:00:48,990 --> 00:00:50,340
can I ask a question for the audience?

21
00:00:50,340 --> 00:00:51,540
And you can just raise your hand.

22
00:00:51,540 --> 00:00:54,183
How many of you are
currently building agents?

23
00:00:55,350 --> 00:00:56,850
Okay. A majority.

24
00:00:56,850 --> 00:01:00,030
How many of you are in the
financial service industry?

25
00:01:00,030 --> 00:01:01,590
Okay, awesome. The
majority of you as well.

26
00:01:01,590 --> 00:01:04,410
So hopefully this will
be very useful for you.

27
00:01:04,410 --> 00:01:08,100
A quick look at the agenda on
what we're gonna cover today.

28
00:01:08,100 --> 00:01:10,680
We're gonna start with Dennis taking us

29
00:01:10,680 --> 00:01:14,610
through their journey from
almost three years ago

30
00:01:14,610 --> 00:01:16,710
on how they saw a opportunity

31
00:01:16,710 --> 00:01:18,690
of revolutionizing their business

32
00:01:18,690 --> 00:01:20,790
through the lens of generative AI.

33
00:01:20,790 --> 00:01:24,300
What was the vision? What
was the challenges they face?

34
00:01:24,300 --> 00:01:25,950
After that, we're gonna go through some

35
00:01:25,950 --> 00:01:28,290
of the technical foundational services

36
00:01:28,290 --> 00:01:30,480
that they're currently using on AWS

37
00:01:30,480 --> 00:01:35,480
to implement and deliver those
services through agentic AI.

38
00:01:35,580 --> 00:01:39,270
And of course, this is a
technical session, Dennis is

39
00:01:39,270 --> 00:01:42,270
gonna take us through the
architecture they decided

40
00:01:42,270 --> 00:01:44,520
on taking, some of the
challenges they face,

41
00:01:44,520 --> 00:01:46,290
how they solved those challenges,

42
00:01:46,290 --> 00:01:49,650
and how they actually
evolve from a simple chatbot

43
00:01:49,650 --> 00:01:52,443
through a multi-agent system on AWS.

44
00:01:53,310 --> 00:01:56,130
And a very important,
I think, lesson learned

45
00:01:56,130 --> 00:01:58,740
that Dennis is gonna share with us is,

46
00:01:58,740 --> 00:02:02,220
financial services have a
lot of unstructured data.

47
00:02:02,220 --> 00:02:04,920
How do you actually retrieve insights

48
00:02:04,920 --> 00:02:09,920
for those financial documents
into a structured ability

49
00:02:10,170 --> 00:02:12,570
to use that into agents, right?

50
00:02:12,570 --> 00:02:15,390
And then Dennis and I also
gonna share a little bit more,

51
00:02:15,390 --> 00:02:17,160
looking forward, what is the vision

52
00:02:17,160 --> 00:02:19,350
and what the future entitles.

53
00:02:19,350 --> 00:02:21,933
So I'm gonna pass it over
to Dennis to kick us off.

54
00:02:24,630 --> 00:02:29,630
- Thanks Sam. So good morning,
so I'm Dennis Climent.

55
00:02:30,990 --> 00:02:35,220
I'm a managing director at
Moody's Analytics, and I lead one

56
00:02:35,220 --> 00:02:39,420
of the largest engineering
teams focused on generative AI.

57
00:02:39,420 --> 00:02:40,800
Now, this is a team that has been

58
00:02:40,800 --> 00:02:45,800
producing actual production-grade
generative AI products

59
00:02:45,870 --> 00:02:47,970
since about 2023.

60
00:02:47,970 --> 00:02:48,803
So I'm gonna show you

61
00:02:48,803 --> 00:02:52,260
how a 100-year old
financial institution is

62
00:02:52,260 --> 00:02:54,360
redefining what is possible

63
00:02:54,360 --> 00:02:57,963
with a multi-agentic system on AWS.

64
00:03:01,650 --> 00:03:04,080
So I need to start with who we are,

65
00:03:04,080 --> 00:03:05,430
because I think it's really important

66
00:03:05,430 --> 00:03:07,620
to understand who we are

67
00:03:07,620 --> 00:03:10,230
so that you know why
we built what we built.

68
00:03:10,230 --> 00:03:13,800
So yes, Moody's is a 100-year
old credit rating agency,

69
00:03:13,800 --> 00:03:18,150
right, but that's what's actually
really interesting, right?

70
00:03:18,150 --> 00:03:21,450
That hundred years of
domain knowledge is actually

71
00:03:21,450 --> 00:03:23,730
what makes us really, really dangerous

72
00:03:23,730 --> 00:03:25,560
in the gen AI space, right?

73
00:03:25,560 --> 00:03:27,990
We are not a tech company trying

74
00:03:27,990 --> 00:03:31,260
to understand financial institutions.

75
00:03:31,260 --> 00:03:35,970
We are the, like, preemptive service

76
00:03:35,970 --> 00:03:38,040
that financial institutions need

77
00:03:38,040 --> 00:03:40,680
to solve their problems, right?

78
00:03:40,680 --> 00:03:45,680
We serve over 1,500 customers
across 165 countries,

79
00:03:46,920 --> 00:03:49,440
97% of the Fortune 100.

80
00:03:49,440 --> 00:03:53,310
And this is all not just ratings anymore.

81
00:03:53,310 --> 00:03:56,070
We are doing risk intelligence

82
00:03:56,070 --> 00:03:59,160
across a bunch of
different domains, right?

83
00:03:59,160 --> 00:04:02,520
We are doing credit, climate, economics,

84
00:04:02,520 --> 00:04:04,563
compliance, right, you name it.

85
00:04:05,400 --> 00:04:09,120
And folks aren't coming to
Moody's, right, just to browse.

86
00:04:09,120 --> 00:04:12,750
They are making billion
dollar decisions, right,

87
00:04:12,750 --> 00:04:17,160
across a ton of their own
internal systems, right,

88
00:04:17,160 --> 00:04:21,570
and we need a strategic
AI strategy, right,

89
00:04:21,570 --> 00:04:24,570
for customers to actually
make a difference

90
00:04:24,570 --> 00:04:27,030
on a day-to-day basis, right?

91
00:04:27,030 --> 00:04:30,480
So one of the big challenges
that we have is the fact

92
00:04:30,480 --> 00:04:33,360
that we have a lot of
different types of customers

93
00:04:33,360 --> 00:04:35,010
that are coming into our systems.

94
00:04:35,010 --> 00:04:37,650
We have commercial banks
running loan origination,

95
00:04:37,650 --> 00:04:39,900
and they need a multitude
of different data sets

96
00:04:39,900 --> 00:04:41,580
to solve some of their problems.

97
00:04:41,580 --> 00:04:43,740
We have asset managers, right,

98
00:04:43,740 --> 00:04:48,300
that need climate risk models
to do portfolio analysis.

99
00:04:48,300 --> 00:04:49,770
We have insurance companies

100
00:04:49,770 --> 00:04:52,650
that need regulatory
compliance validation.

101
00:04:52,650 --> 00:04:54,960
So it's the same platform,

102
00:04:54,960 --> 00:04:57,843
but very, very different
problems to solve.

103
00:04:59,850 --> 00:05:04,140
So this is our, like, one
pager of our data universe,

104
00:05:04,140 --> 00:05:07,860
because understanding this
complexity is key, right,

105
00:05:07,860 --> 00:05:09,903
to understanding what we built.

106
00:05:10,800 --> 00:05:15,180
So we have about four core
pillars in our data universe.

107
00:05:15,180 --> 00:05:19,470
Ratings, research and
insights, data and information,

108
00:05:19,470 --> 00:05:20,883
and decision solutions.

109
00:05:22,290 --> 00:05:25,920
And we create our own
authoritative data sets

110
00:05:25,920 --> 00:05:27,510
through our ratings agencies.

111
00:05:27,510 --> 00:05:31,710
So this is decades of research
documents, credit opinions,

112
00:05:31,710 --> 00:05:35,130
sector outlooks, right, you name it.

113
00:05:35,130 --> 00:05:38,070
Now we also operate Orbis, which is one

114
00:05:38,070 --> 00:05:43,070
of the largest databases of
company or an entity data

115
00:05:43,380 --> 00:05:46,650
in the world, this is
600 million entities.

116
00:05:46,650 --> 00:05:51,060
And we are creating climate risk analysis,

117
00:05:51,060 --> 00:05:53,670
we are doing economic forecasts,

118
00:05:53,670 --> 00:05:58,170
we do know your customer
screening, we do regulatory filing.

119
00:05:58,170 --> 00:06:03,030
So as you can see, the
scale is pretty incredible.

120
00:06:03,030 --> 00:06:06,330
So with all of this,
we have to truly focus

121
00:06:06,330 --> 00:06:11,130
on being accessible, accurate, and fast.

122
00:06:11,130 --> 00:06:14,250
So the question is, how do
you build an AI system, right,

123
00:06:14,250 --> 00:06:16,050
that takes all of this into account.

124
00:06:18,600 --> 00:06:22,890
So our customer diversity,
right, is what really

125
00:06:22,890 --> 00:06:27,090
drives, you know, why we cannot compromise

126
00:06:27,090 --> 00:06:28,950
on accuracy, right?

127
00:06:28,950 --> 00:06:31,050
You gotta look at who relies on us?

128
00:06:31,050 --> 00:06:34,890
2,600 commercial banks
processing loan originations,

129
00:06:34,890 --> 00:06:39,540
1,900 asset managers making
portfolio allocation decisions,

130
00:06:39,540 --> 00:06:42,180
and 800 plus insurance companies, right,

131
00:06:42,180 --> 00:06:44,910
running regulatory stress tests.

132
00:06:44,910 --> 00:06:49,080
These aren't, like, low
stakes, right, use cases.

133
00:06:49,080 --> 00:06:52,110
And that's why, right, we're
introducing generative AI

134
00:06:52,110 --> 00:06:54,303
into our system was challenging.

135
00:06:56,821 --> 00:07:00,030
And so this is just a list
of industry awards, right?

136
00:07:00,030 --> 00:07:04,470
This right here really is our
accountability markers, right?

137
00:07:04,470 --> 00:07:07,650
This is what, why we
deliver precision, right?

138
00:07:07,650 --> 00:07:11,010
Our SaaS products, right,
carry the Moody's name.

139
00:07:11,010 --> 00:07:15,780
And when our company makes,
like, certain credit decisions,

140
00:07:15,780 --> 00:07:20,130
and certain risk profiles,
the market moves, right?

141
00:07:20,130 --> 00:07:22,950
So this is why, right, we really needed

142
00:07:22,950 --> 00:07:25,200
to think through why our AI systems need

143
00:07:25,200 --> 00:07:28,803
to work for high-stake
financial environments.

144
00:07:30,480 --> 00:07:33,930
So this is where our journey
though really begins,

145
00:07:33,930 --> 00:07:35,370
not truly technical, right,

146
00:07:35,370 --> 00:07:38,253
but what forced us to kind
of rethink everything.

147
00:07:40,320 --> 00:07:45,320
And this is the big
fundamental tension, right,

148
00:07:45,390 --> 00:07:46,980
that we faced, right?

149
00:07:46,980 --> 00:07:51,540
When a commercial bank is making
$500 million loan decisions

150
00:07:51,540 --> 00:07:52,650
or an asset manager is

151
00:07:52,650 --> 00:07:55,920
rebalancing a $2 billion portfolio, right,

152
00:07:55,920 --> 00:07:59,820
99% accuracy just isn't good enough.

153
00:07:59,820 --> 00:08:03,600
That missing 1%, right,
could be catastrophic, right?

154
00:08:03,600 --> 00:08:08,600
So let me paint a little picture, right,

155
00:08:09,810 --> 00:08:12,090
of why this is so hard, right?

156
00:08:12,090 --> 00:08:14,310
Look at the complexity we're dealing with.

157
00:08:14,310 --> 00:08:18,363
A single customer, right,
comes to us needing expertise

158
00:08:19,590 --> 00:08:23,070
across all of our different
domains: credit ratings,

159
00:08:23,070 --> 00:08:26,070
sector analysis, economic comparisons,

160
00:08:26,070 --> 00:08:30,720
and regulatory compliance,
all of this simultaneously.

161
00:08:30,720 --> 00:08:33,120
And they just aren't adjacent domains,

162
00:08:33,120 --> 00:08:36,210
these are different
knowledge universes, right?

163
00:08:36,210 --> 00:08:41,210
And they require separate
analyst teams, right?

164
00:08:41,370 --> 00:08:45,750
Now, not only that, we are also
in a regulated space, right?

165
00:08:45,750 --> 00:08:47,910
So we have to think about compliance.

166
00:08:47,910 --> 00:08:51,420
We think we have to think
about data separation.

167
00:08:51,420 --> 00:08:55,110
When users actually input
their data into our systems,

168
00:08:55,110 --> 00:08:58,230
we have to think about
true data isolation, right?

169
00:08:58,230 --> 00:09:01,470
And so all of this, right, means

170
00:09:01,470 --> 00:09:06,000
that we needed to make really,
really specific decisions

171
00:09:06,000 --> 00:09:09,360
about how we were producing
our products, right?

172
00:09:09,360 --> 00:09:11,130
And what makes it even harder is,

173
00:09:11,130 --> 00:09:14,070
our customers aren't just
querying Moody's data,

174
00:09:14,070 --> 00:09:16,440
they want their own data as well, right?

175
00:09:16,440 --> 00:09:18,600
And so they are uploading
financial documents,

176
00:09:18,600 --> 00:09:21,330
they're uploading PDFs into
our system, and we have

177
00:09:21,330 --> 00:09:26,330
to seamlessly kind of merge
not only our expertise, right,

178
00:09:28,530 --> 00:09:30,480
but also with their data sets, right,

179
00:09:30,480 --> 00:09:33,570
to solve real world problems, right?

180
00:09:33,570 --> 00:09:36,330
And let me tell you the PDF reality

181
00:09:36,330 --> 00:09:39,840
and that unstructured
data, that is difficult,

182
00:09:39,840 --> 00:09:41,460
and we are still tackling it,

183
00:09:41,460 --> 00:09:43,950
and we're still fighting that fight,

184
00:09:43,950 --> 00:09:45,723
but hopefully a winning fight.

185
00:09:47,820 --> 00:09:51,360
So now we'll give you a little
bit of how we evolved, right?

186
00:09:51,360 --> 00:09:53,280
Now this timeline tells our story.

187
00:09:53,280 --> 00:09:56,160
We started like most people did, right,

188
00:09:56,160 --> 00:09:58,470
with a RAG application, right?

189
00:09:58,470 --> 00:10:01,170
So we deployed our research assistant

190
00:10:01,170 --> 00:10:06,170
about December of 2023,
and users loved it.

191
00:10:06,750 --> 00:10:10,800
They got answers grounded
in real research, right?

192
00:10:10,800 --> 00:10:14,523
And it was able to truly
solve a lot of their problems.

193
00:10:15,480 --> 00:10:20,100
But the moment somebody asks
something truly complex, right,

194
00:10:20,100 --> 00:10:23,730
where you're comparing risk,
right, for multiple companies,

195
00:10:23,730 --> 00:10:27,510
their financial metrics,
right, across your portfolio,

196
00:10:27,510 --> 00:10:30,690
analyzing news, all of
that, is when it started

197
00:10:30,690 --> 00:10:31,860
to kind of crumble.

198
00:10:31,860 --> 00:10:33,660
These scenarios were very difficult

199
00:10:33,660 --> 00:10:36,483
for a basic RAG application to solve.

200
00:10:38,010 --> 00:10:40,890
Then in August, 2024,
we got the understanding

201
00:10:40,890 --> 00:10:42,600
that people wanted to introduce their data

202
00:10:42,600 --> 00:10:44,100
into our world, right?

203
00:10:44,100 --> 00:10:47,850
So we released our first
PDF upload capability.

204
00:10:47,850 --> 00:10:49,953
And that is where a
customer adds their data

205
00:10:49,953 --> 00:10:54,090
into our systems to solve
real world problems, right?

206
00:10:54,090 --> 00:10:56,490
And that is where, I would say,

207
00:10:56,490 --> 00:10:59,820
that's where our unstructured data story

208
00:10:59,820 --> 00:11:02,760
kind of even begins, 'cause
that's where we really started

209
00:11:02,760 --> 00:11:05,130
to realize where we needed

210
00:11:05,130 --> 00:11:08,190
to upskill ourselves and our systems.

211
00:11:08,190 --> 00:11:10,290
And now in the end of
2025, it's the culmination

212
00:11:10,290 --> 00:11:11,610
of all of that, right?

213
00:11:11,610 --> 00:11:13,410
We have learned from our customers,

214
00:11:13,410 --> 00:11:15,840
we have created custom orchestrators

215
00:11:15,840 --> 00:11:18,000
with specialized workflows,

216
00:11:18,000 --> 00:11:21,420
with specific task agents
all sitting there trying

217
00:11:21,420 --> 00:11:25,710
to solve a designated
task, right, for our users.

218
00:11:25,710 --> 00:11:28,680
And all of this powered
by AWS's infrastructure,

219
00:11:28,680 --> 00:11:32,640
operating agentic loops, and
all the sorts of evaluations

220
00:11:32,640 --> 00:11:35,373
that we need for our systems.

221
00:11:36,750 --> 00:11:41,580
So here is how this kind of
works in practice, right?

222
00:11:41,580 --> 00:11:43,740
This is Moody's research assistant.

223
00:11:43,740 --> 00:11:46,440
And this was our first gen AI chatbot

224
00:11:46,440 --> 00:11:48,930
released, again, in 2023.

225
00:11:48,930 --> 00:11:51,750
And you'll see it's a
simple interface, right?

226
00:11:51,750 --> 00:11:54,240
But behind the scenes,
there's so much complexity.

227
00:11:54,240 --> 00:11:56,970
This is a specialized
intent engine, right,

228
00:11:56,970 --> 00:12:00,180
routing to the right expertise,
routing to the right data

229
00:12:00,180 --> 00:12:02,070
that is necessary.

230
00:12:02,070 --> 00:12:04,830
It quickly provides context, right?

231
00:12:04,830 --> 00:12:07,860
And it delivers really fast
and reliable answers, right?

232
00:12:07,860 --> 00:12:10,770
And it's all grounded in real data.

233
00:12:10,770 --> 00:12:14,910
And let me tell you, we
painstakingly cite everything

234
00:12:14,910 --> 00:12:16,230
that we can do, right?

235
00:12:16,230 --> 00:12:18,870
Because when we do that, right,

236
00:12:18,870 --> 00:12:23,870
this is what gives our customers,
right, the continued trust

237
00:12:23,880 --> 00:12:27,273
in what we are doing and how
we are serving our clients.

238
00:12:29,940 --> 00:12:33,720
But this is where kind of
our vision really went.

239
00:12:33,720 --> 00:12:36,240
And this is what changed
everything for us, right?

240
00:12:36,240 --> 00:12:38,730
We spent much of our times
in research assistant,

241
00:12:38,730 --> 00:12:42,510
tweaking prompts, tweaking
the intent engine,

242
00:12:42,510 --> 00:12:46,560
and all of these for really small gains.

243
00:12:46,560 --> 00:12:48,930
And we realized early
that the future, right,

244
00:12:48,930 --> 00:12:53,700
isn't better prompts, it's
better context, right?

245
00:12:53,700 --> 00:12:56,220
Research assistant,
right, was proven though.

246
00:12:56,220 --> 00:12:58,380
It was saving people 60%,

247
00:12:58,380 --> 00:13:01,140
it was giving people 60%
faster insights, right?

248
00:13:01,140 --> 00:13:04,560
It was 30% reduction in task completions.

249
00:13:04,560 --> 00:13:06,570
And we were processing decades

250
00:13:06,570 --> 00:13:08,760
of Moody's proprietary research, right?

251
00:13:08,760 --> 00:13:11,280
All to serve our clients.

252
00:13:11,280 --> 00:13:13,650
But we realized that we can do even more.

253
00:13:13,650 --> 00:13:15,450
And we realized that
there were certain things

254
00:13:15,450 --> 00:13:18,570
that this chatbot was
just not doing for us.

255
00:13:18,570 --> 00:13:22,290
So we moved from, let's ask
a question and get an answer

256
00:13:22,290 --> 00:13:26,550
to let's orchestrate
specialist intelligence, right?

257
00:13:26,550 --> 00:13:30,150
And this is how we were
going to move forward.

258
00:13:30,150 --> 00:13:31,710
So now I'm gonna let Sam

259
00:13:31,710 --> 00:13:33,600
kind of show you what the foundations

260
00:13:33,600 --> 00:13:35,793
kind of helped build all of these systems.

261
00:13:36,900 --> 00:13:37,900
- Thank you, Dennis.

262
00:13:39,300 --> 00:13:42,360
So before Dennis takes us to the journey

263
00:13:42,360 --> 00:13:44,820
on how they've implemented AWS services

264
00:13:44,820 --> 00:13:48,300
and AWS infrastructure
into their agentic system,

265
00:13:48,300 --> 00:13:50,730
let's just quickly go
through some of the services

266
00:13:50,730 --> 00:13:53,373
and high level idea on how they work.

267
00:13:55,680 --> 00:13:58,710
The journey that Dennis
just took us through

268
00:13:58,710 --> 00:14:01,830
is what we've seen in
financial service industries

269
00:14:01,830 --> 00:14:03,810
and other industries as well.

270
00:14:03,810 --> 00:14:05,100
And I really like this slide,

271
00:14:05,100 --> 00:14:07,770
because it kind of demonstrate
exactly the journey

272
00:14:07,770 --> 00:14:09,000
that they've taken.

273
00:14:09,000 --> 00:14:10,830
They've started with research assistant

274
00:14:10,830 --> 00:14:14,760
as a generative AI assistant back in 2023.

275
00:14:14,760 --> 00:14:18,300
They started creating specialized
agents as the next step.

276
00:14:18,300 --> 00:14:20,580
Then as mentioned, the PDF upload.

277
00:14:20,580 --> 00:14:22,140
And of course, they're now working

278
00:14:22,140 --> 00:14:25,680
and have released agentic
AI systems as part

279
00:14:25,680 --> 00:14:29,820
of a more autonomous
multi-agent system collaboration

280
00:14:29,820 --> 00:14:32,220
that he's gonna spend
a little bit more time

281
00:14:32,220 --> 00:14:34,380
dive deeping in a moment.

282
00:14:34,380 --> 00:14:37,920
But how do you achieve
that with AWS services?

283
00:14:37,920 --> 00:14:40,530
Well, there are multiple services.

284
00:14:40,530 --> 00:14:43,140
We start of course, with Amazon Bedrock.

285
00:14:43,140 --> 00:14:45,810
If you watch the keynote
from Matt yesterday,

286
00:14:45,810 --> 00:14:49,140
Amazon Bedrock is not just a
service, it is a full ecosystem

287
00:14:49,140 --> 00:14:52,590
of services that allow companies
across different industries

288
00:14:52,590 --> 00:14:55,560
to build-production grade workloads

289
00:14:55,560 --> 00:14:58,290
through agents and foundational models.

290
00:14:58,290 --> 00:15:01,155
The most important aspect
of this is the ability

291
00:15:01,155 --> 00:15:03,480
to choose models from different providers

292
00:15:03,480 --> 00:15:05,190
in a true serverless fashion,

293
00:15:05,190 --> 00:15:07,710
which Moody's is currently doing.

294
00:15:07,710 --> 00:15:09,330
But if you have different use cases

295
00:15:09,330 --> 00:15:11,880
such as you require a RAG database

296
00:15:11,880 --> 00:15:14,640
and you need a managed ingestion pipeline,

297
00:15:14,640 --> 00:15:17,733
Bedrock has also capabilities
which allow you to do that.

298
00:15:18,570 --> 00:15:20,430
Now, one of the challenges

299
00:15:20,430 --> 00:15:24,750
of moving agentic systems
from a simple chatbot

300
00:15:24,750 --> 00:15:28,590
through a multi-agent
orchestration that requires a lot

301
00:15:28,590 --> 00:15:31,290
of tokens from foundational models,

302
00:15:31,290 --> 00:15:34,770
is how do you achieve that capacity?

303
00:15:34,770 --> 00:15:36,450
So this year,

304
00:15:36,450 --> 00:15:41,310
Bedrock was very heavy at
work on helping customers

305
00:15:41,310 --> 00:15:44,940
with more capacity and
the capability of expand.

306
00:15:44,940 --> 00:15:48,690
There are two features
within the Bedrock inference

307
00:15:48,690 --> 00:15:51,840
of foundation models that
I wanna touch base first.

308
00:15:51,840 --> 00:15:52,860
The first one is what we

309
00:15:52,860 --> 00:15:55,860
call the global cross-region inference.

310
00:15:55,860 --> 00:15:59,040
The way it work is previous one, Bedrock,

311
00:15:59,040 --> 00:16:01,560
was released two and a half years ago,

312
00:16:01,560 --> 00:16:05,070
you could call a model
within a single region.

313
00:16:05,070 --> 00:16:06,840
So on this slide here, I'm showing

314
00:16:06,840 --> 00:16:10,200
if I have a specific application
running on a container

315
00:16:10,200 --> 00:16:14,610
on a Lambda, you could call
Bedrock within the region

316
00:16:14,610 --> 00:16:16,500
and that region will have a specific limit

317
00:16:16,500 --> 00:16:18,633
and capacity for a specific model.

318
00:16:19,560 --> 00:16:22,140
What Bedrock now allows you to do is

319
00:16:22,140 --> 00:16:24,960
if you enable the global
cross-region inference endpoint,

320
00:16:24,960 --> 00:16:27,000
and if you see at the
bottom of this screen,

321
00:16:27,000 --> 00:16:28,800
this is the inference profile ID

322
00:16:28,800 --> 00:16:31,263
that you can pick when
building applications,

323
00:16:31,263 --> 00:16:33,330
what that allows you to do is

324
00:16:33,330 --> 00:16:36,960
if the region that you are
located doesn't have capacity

325
00:16:36,960 --> 00:16:39,540
or you have achieved
the limits of the region

326
00:16:39,540 --> 00:16:41,580
for your specific account,

327
00:16:41,580 --> 00:16:44,100
it can automatically have a routing

328
00:16:44,100 --> 00:16:47,520
using the internal backbone of AWS network

329
00:16:47,520 --> 00:16:51,120
and ask the question, where
is there available capacity

330
00:16:51,120 --> 00:16:54,570
that is closer to my user
across commercial regions

331
00:16:54,570 --> 00:16:56,820
that Bedrock and that model is available.

332
00:16:56,820 --> 00:16:59,880
This model of course,
is Claude Sonnet 4.5.

333
00:16:59,880 --> 00:17:00,810
There are multiple models

334
00:17:00,810 --> 00:17:04,260
that support a global
cross-region inference endpoint.

335
00:17:04,260 --> 00:17:08,000
So in that case, Bedrock behind
the scenes will route you

336
00:17:08,000 --> 00:17:11,190
to a specific region that has capacity.

337
00:17:11,190 --> 00:17:14,910
In this slide, we've chosen
ap-southeast-1, keep in mind

338
00:17:14,910 --> 00:17:16,260
that everything behind the scenes is

339
00:17:16,260 --> 00:17:18,600
using the AWS network backbone.

340
00:17:18,600 --> 00:17:20,820
So nothing is going through the internet.

341
00:17:20,820 --> 00:17:23,730
And if you also go and hit the limits

342
00:17:23,730 --> 00:17:26,910
of that specific region, Bedrock can then

343
00:17:26,910 --> 00:17:30,330
redirect the traffic across
any commercial available region

344
00:17:30,330 --> 00:17:32,100
that that model is available.

345
00:17:32,100 --> 00:17:33,420
So what that allows you to do,

346
00:17:33,420 --> 00:17:36,600
of course, increases your
resiliency, increases the limits

347
00:17:36,600 --> 00:17:39,570
that you can actually
call that specific model

348
00:17:39,570 --> 00:17:41,820
for your specific application.

349
00:17:41,820 --> 00:17:44,970
Now, a very common challenge,

350
00:17:44,970 --> 00:17:48,780
the financial services
companies face, are you need

351
00:17:48,780 --> 00:17:52,200
to be bound at a specific
geographic location.

352
00:17:52,200 --> 00:17:54,450
Maybe you have some data
residency requirements,

353
00:17:54,450 --> 00:17:58,020
maybe you have some regulatory
compliance that you need

354
00:17:58,020 --> 00:18:01,533
to obey that it can only serve
a specific geographic region.

355
00:18:02,460 --> 00:18:05,850
Now you can still call
just a specific region,

356
00:18:05,850 --> 00:18:08,850
and that is fine, but you have
the limits of the capacity

357
00:18:08,850 --> 00:18:12,600
of Bedrock and that model
within that specific region.

358
00:18:12,600 --> 00:18:13,770
What we introduced as well,

359
00:18:13,770 --> 00:18:16,950
we call geographic cross-region inference.

360
00:18:16,950 --> 00:18:18,060
It works very similar

361
00:18:18,060 --> 00:18:21,000
to a global cross-region
inference endpoint.

362
00:18:21,000 --> 00:18:24,270
The difference is, rather than
picking a global endpoint,

363
00:18:24,270 --> 00:18:26,730
you choose a specific geographic location.

364
00:18:26,730 --> 00:18:30,390
For example, Europe, US, Asia.

365
00:18:30,390 --> 00:18:32,520
And what happens behind the scenes is

366
00:18:32,520 --> 00:18:36,510
if the capacity, in
this case for eu-west-1,

367
00:18:36,510 --> 00:18:39,300
have been hit, breached, from your account

368
00:18:39,300 --> 00:18:40,770
and you need more capacity,

369
00:18:40,770 --> 00:18:42,960
behind the scenes working the same way

370
00:18:42,960 --> 00:18:45,180
that I explained on global endpoint,

371
00:18:45,180 --> 00:18:48,960
we'll find another region
within Europe specifically

372
00:18:48,960 --> 00:18:51,960
and we redirect the traffic
to that specific endpoint

373
00:18:51,960 --> 00:18:53,250
for that specific model.

374
00:18:53,250 --> 00:18:56,670
And of course, there are more
regions that support Bedrock

375
00:18:56,670 --> 00:19:00,810
within the European regions,
and that allows you to do that.

376
00:19:00,810 --> 00:19:02,040
Now why is that important?

377
00:19:02,040 --> 00:19:04,830
If you are in within a regulated industry,

378
00:19:04,830 --> 00:19:08,010
you can still keep the data
within the geographic region

379
00:19:08,010 --> 00:19:09,930
while you increasing the capacity

380
00:19:09,930 --> 00:19:12,060
and the ability for you
to serve multiple agents

381
00:19:12,060 --> 00:19:14,973
that requires a higher
throughput of tokens.

382
00:19:16,050 --> 00:19:18,300
So that is definitely
something Moody's is using

383
00:19:18,300 --> 00:19:20,010
to help them orchestrate it

384
00:19:20,010 --> 00:19:22,953
across multiple regions, their system.

385
00:19:24,690 --> 00:19:27,990
Now Dennis mentioned multiple
times about the challenge

386
00:19:27,990 --> 00:19:32,990
of embedding unstructured data
into a RAG vector database.

387
00:19:34,170 --> 00:19:37,380
And part of the Bedrock service ecosystem,

388
00:19:37,380 --> 00:19:40,713
we have something called
Knowledge Base for Amazon Bedrock.

389
00:19:42,540 --> 00:19:43,523
What this allows you to do is

390
00:19:43,523 --> 00:19:48,240
to have a fully managed
end-to-end RAG workflow.

391
00:19:48,240 --> 00:19:50,460
So it just not only gives you the ability

392
00:19:50,460 --> 00:19:53,700
to embed documents into a vector database,

393
00:19:53,700 --> 00:19:56,490
it focus on the whole ingestion pipeline

394
00:19:56,490 --> 00:20:01,410
for a broad document, a PDF sitting on S3,

395
00:20:01,410 --> 00:20:04,500
for parsing the document,
to creating chunks

396
00:20:04,500 --> 00:20:07,230
for the document, embedding the document,

397
00:20:07,230 --> 00:20:10,230
and saving a vector database,
and giving you the ability

398
00:20:10,230 --> 00:20:13,650
to choose multiple ways you
wanna retrieve that document.

399
00:20:13,650 --> 00:20:17,100
So it's a completely fully
managed solution that allows you

400
00:20:17,100 --> 00:20:20,220
to have a peace of mind rather than trying

401
00:20:20,220 --> 00:20:22,680
to manage every single
component of the stack.

402
00:20:22,680 --> 00:20:26,460
You can just rely on AWS
with Bedrock Knowledge Base.

403
00:20:26,460 --> 00:20:29,010
So how does that work?

404
00:20:29,010 --> 00:20:31,410
If you look at the data
ingestion workflow,

405
00:20:31,410 --> 00:20:34,740
let's assume you have
different file formats.

406
00:20:34,740 --> 00:20:38,310
You have text documents,
you have PDF documents,

407
00:20:38,310 --> 00:20:40,920
you might even have some
multimodality documents,

408
00:20:40,920 --> 00:20:44,130
maybe some audio files,
maybe some video files.

409
00:20:44,130 --> 00:20:47,340
And you want that, that
insight from that data

410
00:20:47,340 --> 00:20:48,810
to be by the end of the day

411
00:20:48,810 --> 00:20:51,510
in a vector store that you can retrieve.

412
00:20:51,510 --> 00:20:56,460
So the way Knowledge Base
works is you choose a S3 bucket

413
00:20:56,460 --> 00:20:59,223
where you save those files
within that S3 bucket.

414
00:21:01,110 --> 00:21:04,560
That S3 bucket will, you
know, evolve with time,

415
00:21:04,560 --> 00:21:06,360
maybe you're gonna have updated documents,

416
00:21:06,360 --> 00:21:08,040
you're gonna have new documents.

417
00:21:08,040 --> 00:21:09,660
Knowledge base can keep an eye

418
00:21:09,660 --> 00:21:12,873
and update the ingestion pipeline for you.

419
00:21:14,100 --> 00:21:16,830
Once, if it realizes
there is a new document,

420
00:21:16,830 --> 00:21:19,650
there is an updated document,
it can do the parsing.

421
00:21:19,650 --> 00:21:22,050
There are multiple ways you
can choose to do the parsing.

422
00:21:22,050 --> 00:21:25,140
You can use the default way
for Bedrock Knowledge Base.

423
00:21:25,140 --> 00:21:28,530
You can use a large language
model to parse the document.

424
00:21:28,530 --> 00:21:31,590
And you can also use what we
call Bedrock Data Automation,

425
00:21:31,590 --> 00:21:34,410
which is the last service
I'm gonna mention today.

426
00:21:34,410 --> 00:21:35,243
Once it does that,

427
00:21:35,243 --> 00:21:37,830
you decide what chunking
strategy you wanna use,

428
00:21:37,830 --> 00:21:40,140
you might wanna use a
fixed chunking strategy,

429
00:21:40,140 --> 00:21:42,240
you might wanna do your chunking strategy

430
00:21:42,240 --> 00:21:44,880
with the Lambda function,
which allows you to do that.

431
00:21:44,880 --> 00:21:47,760
And Moody's is actually
using the capability.

432
00:21:47,760 --> 00:21:50,340
And after that you can
choose an embedding model.

433
00:21:50,340 --> 00:21:53,430
So the embedding models are
available within Bedrock.

434
00:21:53,430 --> 00:21:58,430
We have Amazon Titan, Amazon
Nova multimodal embedding model

435
00:21:58,830 --> 00:22:01,890
that we just released about
three weeks or so ago,

436
00:22:01,890 --> 00:22:04,140
and also the Cohere embedding models.

437
00:22:04,140 --> 00:22:06,030
Now, if you don't wanna
use some of these models

438
00:22:06,030 --> 00:22:08,250
and you wanna use maybe some open source,

439
00:22:08,250 --> 00:22:10,170
open weight models, you can also

440
00:22:10,170 --> 00:22:12,690
host those embedding models on SageMaker

441
00:22:12,690 --> 00:22:15,630
and point Knowledge Base into SageMaker.

442
00:22:15,630 --> 00:22:17,940
And finally, because Bedrock wants

443
00:22:17,940 --> 00:22:20,130
to provide you with flexibility, you can

444
00:22:20,130 --> 00:22:24,240
choose the vector database you
wanna use behind the scenes.

445
00:22:24,240 --> 00:22:25,830
You can use OpenSearch Serverless

446
00:22:25,830 --> 00:22:28,050
where you don't need to
manage any infrastructure.

447
00:22:28,050 --> 00:22:31,277
You can use some partners as
well, such as Pinecone, Redis.

448
00:22:32,130 --> 00:22:34,200
If you are into more relational databases,

449
00:22:34,200 --> 00:22:38,490
and you're very familiar with
Postgres, you can do pgvector

450
00:22:38,490 --> 00:22:41,550
and use either Aurora
pgvector or RDS pgvector.

451
00:22:41,550 --> 00:22:44,130
And the list is bigger as well.

452
00:22:44,130 --> 00:22:47,220
We've just announced yesterday
the general availability

453
00:22:47,220 --> 00:22:49,410
of S3 Vectors, which
is the ability for you

454
00:22:49,410 --> 00:22:51,570
to store vectors into S3

455
00:22:51,570 --> 00:22:54,930
with 90% price performance comparing

456
00:22:54,930 --> 00:22:57,393
to traditional vector databases.

457
00:22:58,590 --> 00:23:02,070
Now Dennis is gonna talk to us

458
00:23:02,070 --> 00:23:06,600
about how they've taken the
very, very fundamental challenge

459
00:23:06,600 --> 00:23:08,760
of unstructured data.

460
00:23:08,760 --> 00:23:10,140
So you have these PDFs.

461
00:23:10,140 --> 00:23:14,700
These PDFs are full of complex
financial tables, graphs.

462
00:23:14,700 --> 00:23:18,510
How do we extract not only
the text from those PDFs,

463
00:23:18,510 --> 00:23:21,633
but the insights, the
tables, in the proper format?

464
00:23:23,730 --> 00:23:27,590
Actually, there was a study
that was done by Amazon that 80%

465
00:23:27,590 --> 00:23:31,680
of the data in financial
service is unstructured, right?

466
00:23:31,680 --> 00:23:35,970
It could be in maybe 10-Q
documents, maybe can be an audio

467
00:23:35,970 --> 00:23:38,490
or a video from a financial reporting

468
00:23:38,490 --> 00:23:40,740
that the company has, the earning reported

469
00:23:40,740 --> 00:23:42,750
that the company published.

470
00:23:42,750 --> 00:23:46,200
But only 20% of organizations
are actually currently able

471
00:23:46,200 --> 00:23:48,753
to take an advantage of
this unstructured data.

472
00:23:49,890 --> 00:23:54,780
So we've introduced, a year or so ago,

473
00:23:54,780 --> 00:23:56,700
another capability on Bedrock.

474
00:23:56,700 --> 00:23:59,670
It's called Bedrock Data Automation.

475
00:23:59,670 --> 00:24:03,570
So for those specific
challenging documents

476
00:24:03,570 --> 00:24:07,140
that you have a lot of different
data, unstructured data,

477
00:24:07,140 --> 00:24:09,690
how can you actually choose, just

478
00:24:09,690 --> 00:24:12,810
put all the unstructured document into S3,

479
00:24:12,810 --> 00:24:16,980
and how can you actually
extract the insights from that?

480
00:24:16,980 --> 00:24:20,010
Well, you can use Bedrock Data Automation.

481
00:24:20,010 --> 00:24:24,120
And the way Bedrock Data
Automation works are two ways.

482
00:24:24,120 --> 00:24:26,490
The first way you can call
Bedrock Data Automation

483
00:24:26,490 --> 00:24:28,440
as a traditional API.

484
00:24:28,440 --> 00:24:30,930
And you can pass the document, it can be,

485
00:24:30,930 --> 00:24:35,280
so it supports multimodality,
so it supports audio, video,

486
00:24:35,280 --> 00:24:37,500
image, and documents.

487
00:24:37,500 --> 00:24:39,660
Dennis gonna go through how they've

488
00:24:39,660 --> 00:24:43,110
used Bedrock Data Automation
for financial documents,

489
00:24:43,110 --> 00:24:46,290
like very complex, long financial PDFs.

490
00:24:46,290 --> 00:24:47,880
So you put the document,

491
00:24:47,880 --> 00:24:51,240
you choose the capability of extraction.

492
00:24:51,240 --> 00:24:55,110
So you can do summary, you can
do text, you can do fields.

493
00:24:55,110 --> 00:24:58,380
And we've actually seen a weight increase

494
00:24:58,380 --> 00:25:00,480
of performance and accuracy

495
00:25:00,480 --> 00:25:03,720
when using Bedrock data automation

496
00:25:03,720 --> 00:25:06,120
instead of traditional
large language model.

497
00:25:06,120 --> 00:25:07,980
The hallucination distraction

498
00:25:07,980 --> 00:25:12,630
of a foundational model versus
Bedrock Data Automation,

499
00:25:12,630 --> 00:25:15,630
you can actually gain
advantage both from price

500
00:25:15,630 --> 00:25:19,500
and also accuracy performance
with Bedrock Data Automation.

501
00:25:19,500 --> 00:25:22,230
So with that said, I'll
pass it back to Dennis,

502
00:25:22,230 --> 00:25:24,450
whence he's gonna go through
the architecture deep dive

503
00:25:24,450 --> 00:25:27,450
on how they've implemented their
agentic system of database.

504
00:25:28,440 --> 00:25:29,560
Over to you, Dennis.

505
00:25:32,687 --> 00:25:35,550
- All right, now the fun
part, let's get technical.

506
00:25:35,550 --> 00:25:38,880
So I'm gonna walk you through
how we actually built this,

507
00:25:38,880 --> 00:25:41,880
and the architectural
decisions that we've made,

508
00:25:41,880 --> 00:25:45,600
and the theory, right,
around how we put our theory

509
00:25:45,600 --> 00:25:46,893
into production reality.

510
00:25:48,870 --> 00:25:51,720
So again, the evolution, right?

511
00:25:51,720 --> 00:25:53,700
So everybody raise your hand here

512
00:25:53,700 --> 00:25:57,120
if you've built a RAG
application, all right?

513
00:25:57,120 --> 00:25:59,790
So all of us have started with that.

514
00:25:59,790 --> 00:26:01,860
It's the initial
deployment that we all do.

515
00:26:01,860 --> 00:26:05,310
It's a RAG system, one model,
one context window, right?

516
00:26:05,310 --> 00:26:08,400
Trying to solve everything, right?

517
00:26:08,400 --> 00:26:09,450
And so users started

518
00:26:09,450 --> 00:26:11,760
to ask about credit risk, sector analysis,

519
00:26:11,760 --> 00:26:13,050
all of that fun stuff.

520
00:26:13,050 --> 00:26:17,190
And this one system had to be
an expert in all of it, right?

521
00:26:17,190 --> 00:26:19,200
And the cracks appeared
immediately, right?

522
00:26:19,200 --> 00:26:21,180
So context window limitations,

523
00:26:21,180 --> 00:26:23,100
performance degradations, right?

524
00:26:23,100 --> 00:26:26,040
And just shallow expertise, right?

525
00:26:26,040 --> 00:26:28,800
And so we were really
asking the impossible.

526
00:26:28,800 --> 00:26:33,450
So we kind of made a few series

527
00:26:33,450 --> 00:26:34,920
of realizations, right?

528
00:26:34,920 --> 00:26:38,580
The first one is financial
intelligence, right?

529
00:26:38,580 --> 00:26:42,090
That should mirror how
we as humans, right,

530
00:26:42,090 --> 00:26:44,190
and expert teams actually view some

531
00:26:44,190 --> 00:26:45,510
of these problems, right?

532
00:26:45,510 --> 00:26:49,890
And it requires specialized
expertise, right?

533
00:26:49,890 --> 00:26:52,740
Second, we noticed that
our users were asking,

534
00:26:52,740 --> 00:26:54,510
now we're not asking
just random questions,

535
00:26:54,510 --> 00:26:58,647
they were orchestrating
repeatable workflows, right?

536
00:26:58,647 --> 00:27:01,080
And then third, it's
context switching, right?

537
00:27:01,080 --> 00:27:03,060
Just like a human context switching,

538
00:27:03,060 --> 00:27:05,280
switching kills performance, right?

539
00:27:05,280 --> 00:27:09,150
Even similar expertise
benefits from true isolation,

540
00:27:09,150 --> 00:27:13,320
and agentic systems need
that focused context, right?

541
00:27:13,320 --> 00:27:15,900
So the answer we came up
with was deep specialists,

542
00:27:15,900 --> 00:27:19,533
intelligent coordination,
right, and repeatable patterns.

543
00:27:21,960 --> 00:27:24,570
So this was the fundamental shift, right?

544
00:27:24,570 --> 00:27:26,640
No more prompt engineering, right?

545
00:27:26,640 --> 00:27:29,430
But true context engineering, right?

546
00:27:29,430 --> 00:27:31,170
So before we dive into this, right?

547
00:27:31,170 --> 00:27:34,473
Raise your hand if you spent
hours tweaking a prompt.

548
00:27:35,370 --> 00:27:36,510
Yeah. All right?

549
00:27:36,510 --> 00:27:40,080
And I bet you a bunch of you
also hit a really brick wall

550
00:27:40,080 --> 00:27:42,480
and at some point no
tweaking was ever going

551
00:27:42,480 --> 00:27:44,820
to solve that problem, right?

552
00:27:44,820 --> 00:27:46,650
And that's the reality of the systems

553
00:27:46,650 --> 00:27:47,820
that we've built, right?

554
00:27:47,820 --> 00:27:52,263
We have to move away from
prompt engineering, right,

555
00:27:53,610 --> 00:27:55,690
that optimizes little instructions

556
00:27:56,547 --> 00:27:58,650
and little parameters here and there.

557
00:27:58,650 --> 00:28:00,810
And we pray to the LLM gods

558
00:28:00,810 --> 00:28:04,770
and voila, we probably fall short, right?

559
00:28:04,770 --> 00:28:07,110
So here's what we learned, right?

560
00:28:07,110 --> 00:28:09,660
The breakthrough wasn't
about better prompts, right?

561
00:28:09,660 --> 00:28:13,020
It was about better
context boundaries, right?

562
00:28:13,020 --> 00:28:15,390
These multi-agentic architectures,

563
00:28:15,390 --> 00:28:17,970
these multi-agentic workflows, right,

564
00:28:17,970 --> 00:28:21,330
they own precise context
boundaries, right,

565
00:28:21,330 --> 00:28:23,280
about their specific domain.

566
00:28:23,280 --> 00:28:25,620
No cross-domain interference.

567
00:28:25,620 --> 00:28:30,000
There's no diluted expertise, all right?

568
00:28:30,000 --> 00:28:34,470
So here I'm gonna give
you a little context

569
00:28:34,470 --> 00:28:38,700
into our workflow system.

570
00:28:38,700 --> 00:28:40,400
Do I have to?
- Just click, yeah.

571
00:28:41,700 --> 00:28:46,140
- Nice. So in late 2023,
around 2024, right?

572
00:28:46,140 --> 00:28:48,780
We're running research assistant
and customers loved it,

573
00:28:48,780 --> 00:28:52,560
but we started to see a real
specific pattern, right?

574
00:28:52,560 --> 00:28:55,830
Users were asking questions
like pull credit ratings

575
00:28:55,830 --> 00:28:57,780
for these five companies, right?

576
00:28:57,780 --> 00:29:01,560
Now, do an analysis of their
financial metrics, right?

577
00:29:01,560 --> 00:29:03,210
Compare it to news,

578
00:29:03,210 --> 00:29:06,150
and cross reference it
with some sector research.

579
00:29:06,150 --> 00:29:10,203
They were forcing chain of
thought, right, through our chat.

580
00:29:11,550 --> 00:29:13,020
So that's when we realized.

581
00:29:13,020 --> 00:29:15,020
They don't want smarter chatbots, right?

582
00:29:16,236 --> 00:29:18,420
They want the orchestration power, right?

583
00:29:18,420 --> 00:29:19,500
They want to visually

584
00:29:19,500 --> 00:29:23,370
stitch together Moody's expertise, right?

585
00:29:23,370 --> 00:29:25,500
Into repeatable workflows.

586
00:29:25,500 --> 00:29:29,580
And so to create, like, really
specialized outputs, right?

587
00:29:29,580 --> 00:29:34,580
Which this means charts,
graphs, tables, you name it.

588
00:29:34,680 --> 00:29:37,020
So we built this. This
is our workflow designer.

589
00:29:37,020 --> 00:29:39,900
This is before OpenAI's Agent Builder.

590
00:29:39,900 --> 00:29:43,950
This is before most orchestration
platforms existed, right?

591
00:29:43,950 --> 00:29:46,350
We built it, because
our customers needed it.

592
00:29:46,350 --> 00:29:49,563
This was true customer empowerment.

593
00:29:51,150 --> 00:29:54,270
And so our system here, right, has gone

594
00:29:54,270 --> 00:29:57,750
from, you know, a 20-step workflow

595
00:29:57,750 --> 00:30:01,470
to 400-step workflows, right?

596
00:30:01,470 --> 00:30:04,860
It will take anything from
a couple minutes, right,

597
00:30:04,860 --> 00:30:07,620
to 15 plus, right?

598
00:30:07,620 --> 00:30:11,640
But what you get is a
structured output, right,

599
00:30:11,640 --> 00:30:15,360
of our expertise, right, that ourselves

600
00:30:15,360 --> 00:30:18,480
and our customers were able
to stitch together, right,

601
00:30:18,480 --> 00:30:21,213
to solve real world problems.

602
00:30:22,320 --> 00:30:26,790
And I will say this is
probably one of those systems

603
00:30:26,790 --> 00:30:30,450
that we realized that we needed to create.

604
00:30:30,450 --> 00:30:34,470
This wasn't about something
that our users, like, came to us

605
00:30:34,470 --> 00:30:36,000
and like theorized, right?

606
00:30:36,000 --> 00:30:39,240
This was us understanding
what users wanted,

607
00:30:39,240 --> 00:30:40,860
why they needed it, right,

608
00:30:40,860 --> 00:30:43,410
and how we were gonna solve
some of their problems.

609
00:30:45,660 --> 00:30:50,070
But we're very proud of this.
So now the fun stuff, right?

610
00:30:50,070 --> 00:30:54,060
So I wanna dive deep into,
like, the architecture, right,

611
00:30:54,060 --> 00:30:55,200
and go through this,

612
00:30:55,200 --> 00:30:59,313
but first I wanna align
on terminology, right?

613
00:31:00,330 --> 00:31:03,150
So I'd be really interested
to ask this, right?

614
00:31:03,150 --> 00:31:05,550
So how many times have
any of you been asked

615
00:31:05,550 --> 00:31:09,180
by some executive inside of
your company to say, "Hey,

616
00:31:09,180 --> 00:31:11,850
I want you to ingest all of our documents.

617
00:31:11,850 --> 00:31:14,760
I want it to be able to
ask any question you want.

618
00:31:14,760 --> 00:31:18,720
And I want it to be a hundred
percent accurate?" 100%.

619
00:31:18,720 --> 00:31:20,640
And then they also ask you that they need

620
00:31:20,640 --> 00:31:23,310
that probably tomorrow
or next month, right?

621
00:31:23,310 --> 00:31:25,740
That's just not realistic.

622
00:31:25,740 --> 00:31:27,480
And they also say, "Hey,

623
00:31:27,480 --> 00:31:29,820
can't you just throw some agents at this?"

624
00:31:29,820 --> 00:31:33,600
Now I think it's really,
really, really important

625
00:31:33,600 --> 00:31:36,720
for us to understand,
right, the terminology.

626
00:31:36,720 --> 00:31:38,340
If we align on the terminology,

627
00:31:38,340 --> 00:31:40,740
we can have a lot better
of a conversation, right?

628
00:31:40,740 --> 00:31:44,340
So here I'm gonna talk
through what we, in our team,

629
00:31:44,340 --> 00:31:46,830
have aligned on what are tools,

630
00:31:46,830 --> 00:31:50,250
what are agents, and what
are workflows, right?

631
00:31:50,250 --> 00:31:52,350
So tool, right, is a system

632
00:31:52,350 --> 00:31:54,960
that performs a very specific task.

633
00:31:54,960 --> 00:31:59,250
It is a process, it returns
context back to an LLM, right?

634
00:31:59,250 --> 00:32:03,840
Think of it as a discreet process.

635
00:32:03,840 --> 00:32:06,270
So you are fetching data, right?

636
00:32:06,270 --> 00:32:09,270
You are doing calculations, right?

637
00:32:09,270 --> 00:32:12,870
And it is isolated, right?

638
00:32:12,870 --> 00:32:17,870
So an agent for us, right,
is again, an LLM, right?

639
00:32:18,630 --> 00:32:21,600
It's autonomously choosing tools.

640
00:32:21,600 --> 00:32:24,600
It's operating in some
form of loop, right?

641
00:32:24,600 --> 00:32:27,930
And it determines when
it's task is complete.

642
00:32:27,930 --> 00:32:32,220
Now, yes, I know that
sounds smart, all right?

643
00:32:32,220 --> 00:32:33,570
But it's not Skynet, right?

644
00:32:35,160 --> 00:32:36,840
We all know what it truly is, right?

645
00:32:36,840 --> 00:32:40,530
Which is a, honestly, it's a for loop

646
00:32:40,530 --> 00:32:41,733
with kind of better PR.

647
00:32:43,290 --> 00:32:45,090
Now a workflow, right?

648
00:32:45,090 --> 00:32:48,690
That is a deterministic
orchestration, right?

649
00:32:48,690 --> 00:32:53,430
This is a predefined
sequence of steps, right?

650
00:32:53,430 --> 00:32:56,280
That we are coordinating tools, right,

651
00:32:56,280 --> 00:32:59,160
agents, something along those lines

652
00:32:59,160 --> 00:33:03,480
to get a very consistent output, right?

653
00:33:03,480 --> 00:33:08,480
So, but fundamentally, right,
tools can also be agents,

654
00:33:09,720 --> 00:33:12,180
agents can also be tools, right?

655
00:33:12,180 --> 00:33:14,730
But the real reality here is

656
00:33:14,730 --> 00:33:17,610
these are just the building blocks, right,

657
00:33:17,610 --> 00:33:19,533
that we have built this system on.

658
00:33:20,760 --> 00:33:23,940
So with this, right, I want to talk

659
00:33:23,940 --> 00:33:28,940
through kind of like the five
pillars that changed, right?

660
00:33:29,010 --> 00:33:32,310
Or the five pillars that
we've thought through, right,

661
00:33:32,310 --> 00:33:34,020
in orchestrating the system.

662
00:33:34,020 --> 00:33:37,500
And so the first is we strive
to be serverless, right?

663
00:33:37,500 --> 00:33:38,490
The financial world

664
00:33:38,490 --> 00:33:42,090
that we live in is
incredibly spiky, right?

665
00:33:42,090 --> 00:33:46,560
So at any moment, credit
risk, a credit change happens,

666
00:33:46,560 --> 00:33:51,560
and we go from baseline users
on our site to 50x, right?

667
00:33:52,440 --> 00:33:54,270
And that is just the way we work.

668
00:33:54,270 --> 00:33:57,270
So we built our agentic systems
in that kind of same way,

669
00:33:57,270 --> 00:33:59,790
truly understanding that we
were gonna use the foundations

670
00:33:59,790 --> 00:34:02,310
of our serverless architecture, right,

671
00:34:02,310 --> 00:34:06,810
to perform the agentic tasks
that we also need, right?

672
00:34:06,810 --> 00:34:10,620
And so second is we learned that tools,

673
00:34:10,620 --> 00:34:13,890
the tools that perform, like, operations,

674
00:34:13,890 --> 00:34:16,380
those are the essential building blocks.

675
00:34:16,380 --> 00:34:20,910
So we wanted to focus on how
do we surface those tools

676
00:34:20,910 --> 00:34:24,300
to agentic systems and to the
company as a whole, right?

677
00:34:24,300 --> 00:34:27,510
And that we chose to do in Lambdas, right?

678
00:34:27,510 --> 00:34:29,400
So the reason for this is,

679
00:34:29,400 --> 00:34:34,400
because they are single
purpose, they are fast, right?

680
00:34:35,190 --> 00:34:37,620
And they are stateless, right?

681
00:34:37,620 --> 00:34:39,120
And so this allows us

682
00:34:39,120 --> 00:34:42,360
to, again, have a ton of different sets

683
00:34:42,360 --> 00:34:44,970
of workflows or agents
utilizing the same tools,

684
00:34:44,970 --> 00:34:46,820
and it will be able to scale with us.

685
00:34:49,320 --> 00:34:53,700
So third is our agents, right?

686
00:34:53,700 --> 00:34:57,420
And we build kind of
like two types of agents.

687
00:34:57,420 --> 00:34:59,970
There are simple agents, right?

688
00:34:59,970 --> 00:35:04,230
And these are some form
of system prompt, right?

689
00:35:04,230 --> 00:35:08,340
A set of curated tools, some
validation steps, right?

690
00:35:08,340 --> 00:35:11,520
We serve those all in some
form of a JSON object, right?

691
00:35:11,520 --> 00:35:14,370
So that we can just run
them at will, right?

692
00:35:14,370 --> 00:35:16,350
And then they get orchestrated

693
00:35:16,350 --> 00:35:19,770
by our orchestrating systems right?

694
00:35:19,770 --> 00:35:23,370
Now then we have complex agents, right?

695
00:35:23,370 --> 00:35:25,170
And these are, honestly,

696
00:35:25,170 --> 00:35:27,630
it's just custom built software, right?

697
00:35:27,630 --> 00:35:32,580
It is again, Lambda's, I'm
sorry, it is tools, right?

698
00:35:32,580 --> 00:35:37,137
It is our data sets,
and it is code, right?

699
00:35:37,137 --> 00:35:40,410
And all of that kind of
stitched together, right,

700
00:35:40,410 --> 00:35:43,440
in our world as an ECS.

701
00:35:43,440 --> 00:35:46,650
Why? Because a lot of times
those require state, right?

702
00:35:46,650 --> 00:35:50,190
They are long running in nature, right?

703
00:35:50,190 --> 00:35:51,060
One of the caveats

704
00:35:51,060 --> 00:35:53,730
to using Lambdas always
is you have to remember,

705
00:35:53,730 --> 00:35:56,030
they're not great for
giant amount of compute.

706
00:35:57,333 --> 00:36:00,150
They have a limit to I
think 15 minutes or so

707
00:36:00,150 --> 00:36:03,243
before they will crap out on us.

708
00:36:04,200 --> 00:36:06,600
So ECSs on the other hand,

709
00:36:06,600 --> 00:36:09,300
give us that stateful information, right?

710
00:36:09,300 --> 00:36:12,210
They allow us to have
long running tasks, right?

711
00:36:12,210 --> 00:36:15,990
And that is kind of how we
push those things forward.

712
00:36:15,990 --> 00:36:19,560
And then fourth here is going
to be our orchestrator, right?

713
00:36:19,560 --> 00:36:24,090
And that is the brains to
this whole operation, right?

714
00:36:24,090 --> 00:36:27,990
So our custom built
orchestration system, right, will

715
00:36:27,990 --> 00:36:31,320
take, again, in JSON
format, your list of tools,

716
00:36:31,320 --> 00:36:34,350
your list of agents, your
list of prompts, right?

717
00:36:34,350 --> 00:36:38,730
All were orchestrated
together, right, in an ECS.

718
00:36:38,730 --> 00:36:40,560
But the complexity there

719
00:36:40,560 --> 00:36:43,080
that we've built into our orchestrator is

720
00:36:43,080 --> 00:36:44,490
behind the scenes, right?

721
00:36:44,490 --> 00:36:47,190
So inside of this, we are juggling the act

722
00:36:47,190 --> 00:36:50,490
of it being performant, right?

723
00:36:50,490 --> 00:36:52,797
It being cost effective, right?

724
00:36:52,797 --> 00:36:55,710
And so we are paralleling
as many of these steps

725
00:36:55,710 --> 00:36:57,300
as humanly possible, right?

726
00:36:57,300 --> 00:37:00,930
But we're also understanding
that, you know, you need

727
00:37:00,930 --> 00:37:03,540
to have x amount of these
steps finished, right,

728
00:37:03,540 --> 00:37:05,820
before the next step is allowed to go.

729
00:37:05,820 --> 00:37:09,420
And we kind of, we do all the magic there.

730
00:37:09,420 --> 00:37:12,030
Now, the concerted effort here, right,

731
00:37:12,030 --> 00:37:17,030
has been to save costs,
right, to handle our errors,

732
00:37:18,690 --> 00:37:21,990
anytime we get throttled by
our LLM providers, right?

733
00:37:21,990 --> 00:37:24,750
That's the real power in our orchestrator.

734
00:37:24,750 --> 00:37:27,960
And so our lead engineer,
when he created this,

735
00:37:27,960 --> 00:37:32,190
he set a max limit to about
20 or so steps, right?

736
00:37:32,190 --> 00:37:34,560
Because none of us thought
in any way, shape, or form

737
00:37:34,560 --> 00:37:36,660
that you would need more than 20 tools

738
00:37:36,660 --> 00:37:38,523
or 20 steps to ever solve a problem.

739
00:37:39,600 --> 00:37:41,730
Now, some of our customer workflows are

740
00:37:41,730 --> 00:37:43,287
over 400 steps, right?

741
00:37:43,287 --> 00:37:46,080
And so that really blows your
mind about understanding,

742
00:37:46,080 --> 00:37:49,440
like, what people are trying
to do inside of our systems.

743
00:37:49,440 --> 00:37:54,030
And last kind of like
architectural decision

744
00:37:54,030 --> 00:37:57,870
that we needed to make was,
you know, what LLMs to choose.

745
00:37:57,870 --> 00:38:00,630
And we made a concerted
effort not to be pigeonholed

746
00:38:00,630 --> 00:38:05,400
into a specific model,
right, for our systems.

747
00:38:05,400 --> 00:38:10,400
So every agent, every step,
every tool has the ability

748
00:38:10,680 --> 00:38:15,060
to choose a very specific
LLM for its needs, right?

749
00:38:15,060 --> 00:38:17,730
And so these are things
that we can then test,

750
00:38:17,730 --> 00:38:22,730
validate, right, and push forward
as small isolated systems.

751
00:38:24,300 --> 00:38:29,160
So one of our agents could
use a reasoning model

752
00:38:29,160 --> 00:38:33,090
and another one could use
even a small language model

753
00:38:33,090 --> 00:38:36,570
for small computational pieces, right?

754
00:38:36,570 --> 00:38:39,990
So let's take a step back, right?

755
00:38:39,990 --> 00:38:41,910
And we can talk through
the numbers, right?

756
00:38:41,910 --> 00:38:45,060
So we have about 80 or so tools.

757
00:38:45,060 --> 00:38:48,240
We have a hundred plus workflows, right?

758
00:38:48,240 --> 00:38:51,720
We have many specialized
task agents themselves,

759
00:38:51,720 --> 00:38:55,410
and we're processing over a
million tokens a day, right?

760
00:38:55,410 --> 00:38:59,130
And I just want you to know,
like, this isn't a demo,

761
00:38:59,130 --> 00:39:02,220
this is in production today, right,

762
00:39:02,220 --> 00:39:04,323
satisfying our customer's needs.

763
00:39:09,810 --> 00:39:14,370
All right, so I wanna
take a moment here though

764
00:39:14,370 --> 00:39:18,840
and talk about something
that is truly near

765
00:39:18,840 --> 00:39:20,610
and dear to all of our hearts, right?

766
00:39:20,610 --> 00:39:23,010
So we spent some time talking
about the sophistication

767
00:39:23,010 --> 00:39:25,890
around our orchestration systems, right,

768
00:39:25,890 --> 00:39:28,350
our workflows, our agents, right?

769
00:39:28,350 --> 00:39:31,320
But none of that works, right,

770
00:39:31,320 --> 00:39:33,780
if you do not have the context, right,

771
00:39:33,780 --> 00:39:36,150
to give our agents, right?

772
00:39:36,150 --> 00:39:41,040
So this is our fundamental PDF processing

773
00:39:41,040 --> 00:39:43,323
and retrieval challenge.

774
00:39:45,120 --> 00:39:49,380
Now, in our industry, like Sam said,

775
00:39:49,380 --> 00:39:51,830
everything is a PDF, right?

776
00:39:51,830 --> 00:39:55,350
10-Qs have hundreds of pages.

777
00:39:55,350 --> 00:39:59,460
Annual reports, again,
are hundreds of pages,

778
00:39:59,460 --> 00:40:02,040
earnings reports as well.

779
00:40:02,040 --> 00:40:05,040
There are regulatory filings, right?

780
00:40:05,040 --> 00:40:08,220
And all of this is a challenge, right?

781
00:40:08,220 --> 00:40:12,210
And LLMs are brilliant
at reasoning, right?

782
00:40:12,210 --> 00:40:14,220
But without the right context,

783
00:40:14,220 --> 00:40:16,200
what is it actually going to do?

784
00:40:16,200 --> 00:40:17,130
So we actually call this,

785
00:40:17,130 --> 00:40:21,900
like, an archeological dig problem, right?

786
00:40:21,900 --> 00:40:26,880
You are trying to excavate
layers of buried information

787
00:40:26,880 --> 00:40:29,730
across hundreds of different pages, right?

788
00:40:29,730 --> 00:40:32,430
A table header can be on one page, right?

789
00:40:32,430 --> 00:40:33,690
But the actual table can

790
00:40:33,690 --> 00:40:37,080
span two, three pages afterwards, right?

791
00:40:37,080 --> 00:40:40,980
There are charts, there are
images, there are infographics,

792
00:40:40,980 --> 00:40:42,870
there's text all over the place.

793
00:40:42,870 --> 00:40:45,000
There are footnotes that
aren't always attached

794
00:40:45,000 --> 00:40:47,910
to what you think they
should be attached to, right?

795
00:40:47,910 --> 00:40:52,910
And, you know, that was
kind of a fundamental issue.

796
00:40:52,980 --> 00:40:55,440
All of these PDFs are always,

797
00:40:55,440 --> 00:40:57,420
the layouts are different, right?

798
00:40:57,420 --> 00:41:01,080
And so they needed a very unique way

799
00:41:01,080 --> 00:41:03,060
of trying to solve all of our problems.

800
00:41:03,060 --> 00:41:05,520
And the reality is, in a
financial world, right,

801
00:41:05,520 --> 00:41:08,160
one decimal, right, that's off

802
00:41:08,160 --> 00:41:11,940
could represent a catastrophic change

803
00:41:11,940 --> 00:41:15,270
to a customer and what they need, right?

804
00:41:15,270 --> 00:41:16,920
So I think one of the biggest bottlenecks

805
00:41:16,920 --> 00:41:20,370
in our financial AI, right,
continues to be this,

806
00:41:20,370 --> 00:41:23,100
the complexity around trying to deal

807
00:41:23,100 --> 00:41:24,633
with this unstructured data.

808
00:41:26,280 --> 00:41:29,640
So how do we tackle this, right?

809
00:41:29,640 --> 00:41:33,090
And I wanna say like a good
engineering team, right,

810
00:41:33,090 --> 00:41:37,500
we tried everything
that seemed reasonable,

811
00:41:37,500 --> 00:41:40,890
some things that seemed unreasonable.

812
00:41:40,890 --> 00:41:43,320
We over-engineered a bunch of things,

813
00:41:43,320 --> 00:41:46,320
and we also under engineered
a bunch of things.

814
00:41:46,320 --> 00:41:50,280
So I'm gonna go through all
the ways that we failed, right?

815
00:41:50,280 --> 00:41:51,390
And this is how we can

816
00:41:51,390 --> 00:41:54,180
be an honest engineering team together.

817
00:41:54,180 --> 00:41:56,880
Because I think in noticing
what, where we have failed,

818
00:41:56,880 --> 00:41:59,400
hopefully that can help
you as you are reaching

819
00:41:59,400 --> 00:42:01,830
for your solutions, right?

820
00:42:01,830 --> 00:42:03,480
So first, like a lot of us, right,

821
00:42:03,480 --> 00:42:06,420
we started with basic
Python libraries, right?

822
00:42:06,420 --> 00:42:10,140
It goes, it extracts a
bunch of the text, right?

823
00:42:10,140 --> 00:42:13,203
And it does it pretty decently
well, and fast and cheap.

824
00:42:14,550 --> 00:42:17,520
But the problem there is
you lose all context, right?

825
00:42:17,520 --> 00:42:20,340
I think about it as
throwing a 200-page document

826
00:42:20,340 --> 00:42:21,570
into a blender, right?

827
00:42:21,570 --> 00:42:23,160
You're gonna get all the parts back out,

828
00:42:23,160 --> 00:42:24,870
but it might not have all the context

829
00:42:24,870 --> 00:42:26,550
that you truly need, right?

830
00:42:26,550 --> 00:42:30,360
So honestly, the verdict
here was it failed.

831
00:42:30,360 --> 00:42:33,780
It did not provide us the
type of context needed

832
00:42:33,780 --> 00:42:37,260
to solve financial problems, right?

833
00:42:37,260 --> 00:42:41,010
So verdict number two, right?
Custom parsing algorithm.

834
00:42:41,010 --> 00:42:43,320
And this is where we
realized that we wanted

835
00:42:43,320 --> 00:42:46,380
to understand the true hierarchy, right,

836
00:42:46,380 --> 00:42:48,660
of a PDF document, right?

837
00:42:48,660 --> 00:42:50,370
So we would go through, we would try

838
00:42:50,370 --> 00:42:53,130
to do some bounding boxes
around certain sections

839
00:42:53,130 --> 00:42:55,560
so that we could group some
of these things together.

840
00:42:55,560 --> 00:42:58,200
This screenshot that
you're seeing on the right

841
00:42:58,200 --> 00:43:00,093
is what that looks like, right?

842
00:43:02,042 --> 00:43:03,960
And that's complex, right?

843
00:43:03,960 --> 00:43:08,370
And it is a little bit
of a crapshoot, right?

844
00:43:08,370 --> 00:43:11,100
It's not always gonna be able
to work, it's not always going

845
00:43:11,100 --> 00:43:12,765
to be able to scale
with the different types

846
00:43:12,765 --> 00:43:14,490
of documents that get thrown at it.

847
00:43:14,490 --> 00:43:17,820
So the reality there,
it also failed, right?

848
00:43:17,820 --> 00:43:21,090
It wasn't able to scale for us, right?

849
00:43:21,090 --> 00:43:23,130
And then approach number three, right,

850
00:43:23,130 --> 00:43:27,930
was like our multimodal
foundational models, right?

851
00:43:27,930 --> 00:43:30,690
And that makes sense, right?
We now have vision models.

852
00:43:30,690 --> 00:43:33,420
We should be able to look
at these PDFs, right,

853
00:43:33,420 --> 00:43:34,860
just like as a human would,

854
00:43:34,860 --> 00:43:37,113
an LLM should be able
to do the same thing.

855
00:43:38,130 --> 00:43:41,133
And honestly it did pretty well, right?

856
00:43:42,030 --> 00:43:46,260
But we definitely found that
certain complex tables, right,

857
00:43:46,260 --> 00:43:48,690
definitely certain complex layouts, right,

858
00:43:48,690 --> 00:43:50,850
it would just struggle, right?

859
00:43:50,850 --> 00:43:54,930
And it wasn't able to be
as accurate as we wanted.

860
00:43:54,930 --> 00:43:58,740
And the reality? That was
very, very costly, right?

861
00:43:58,740 --> 00:44:00,630
So thinking about how to do that at scale

862
00:44:00,630 --> 00:44:02,640
was gonna be very, very difficult, right?

863
00:44:02,640 --> 00:44:05,520
So the verdict here as well, failed.

864
00:44:05,520 --> 00:44:07,680
It's gonna be too pricey, right?

865
00:44:07,680 --> 00:44:10,410
And it just got just enough things wrong

866
00:44:10,410 --> 00:44:12,843
to make it not usable in production.

867
00:44:14,250 --> 00:44:15,630
And last, right?

868
00:44:15,630 --> 00:44:19,680
So this is our 1 million context windows.

869
00:44:19,680 --> 00:44:22,380
Once those babies came out,
we were like, ah, look,

870
00:44:22,380 --> 00:44:24,930
this is gonna solve all
of our problems, right?

871
00:44:24,930 --> 00:44:29,040
We can just throw these entire
giant documents in there

872
00:44:29,040 --> 00:44:31,233
and it will be able to
understand them all.

873
00:44:32,280 --> 00:44:36,600
And also, did really,
really, really well, right?

874
00:44:36,600 --> 00:44:39,120
Of course, though the problem is here,

875
00:44:39,120 --> 00:44:40,380
larger the documents,

876
00:44:40,380 --> 00:44:42,330
the more you stuff into a context window,

877
00:44:42,330 --> 00:44:44,910
the more you are going to start

878
00:44:44,910 --> 00:44:47,670
to degrade what comes out.

879
00:44:47,670 --> 00:44:51,840
And the reality here too is
this is expensive, right?

880
00:44:51,840 --> 00:44:56,840
This is incredibly hard to scale, right?

881
00:44:56,910 --> 00:44:59,880
So here we have it, four approaches,

882
00:44:59,880 --> 00:45:01,680
all of them failed, right,

883
00:45:01,680 --> 00:45:03,330
to reach the kind of requirements

884
00:45:03,330 --> 00:45:06,030
that we need in the financial industry.

885
00:45:06,030 --> 00:45:09,870
But the reality is we learned
so much from this, right?

886
00:45:09,870 --> 00:45:11,820
And we weren't going to just stop.

887
00:45:11,820 --> 00:45:14,850
Our clients need this,
need this solved, right?

888
00:45:14,850 --> 00:45:17,943
So we needed to learn from our failures.

889
00:45:19,350 --> 00:45:22,530
So that led us here, right?

890
00:45:22,530 --> 00:45:26,610
This is the concept of not
trying to find one solution

891
00:45:26,610 --> 00:45:28,350
to solve our problem, right?

892
00:45:28,350 --> 00:45:30,300
But we would start building pipelines

893
00:45:30,300 --> 00:45:32,940
that could route different content types

894
00:45:32,940 --> 00:45:37,230
to specialized processes,
processors, right?

895
00:45:37,230 --> 00:45:40,020
So the insights were this, right?

896
00:45:40,020 --> 00:45:42,600
Not all pages are created equal, right?

897
00:45:42,600 --> 00:45:46,890
A text heavy narrative page
needs far different processing

898
00:45:46,890 --> 00:45:50,100
than a page dominated by
complex tables, right?

899
00:45:50,100 --> 00:45:52,950
Or charts or graphs, right?

900
00:45:52,950 --> 00:45:57,360
So we built an intelligent
page classification system.

901
00:45:57,360 --> 00:45:59,700
Right? It's an upfront analysis step.

902
00:45:59,700 --> 00:46:02,970
And it could categorize
a page that is dominant,

903
00:46:02,970 --> 00:46:05,220
that is text heavy dominant, right?

904
00:46:05,220 --> 00:46:07,920
And that would go to a Bedrock LLM

905
00:46:07,920 --> 00:46:10,260
that could do OCR for us, right?

906
00:46:10,260 --> 00:46:13,260
And that would then convert
that into markdown, right?

907
00:46:13,260 --> 00:46:16,530
And we have something that
is a lot easier to query.

908
00:46:16,530 --> 00:46:19,830
Now for table dominated pages, this is

909
00:46:19,830 --> 00:46:23,007
where AWS' Bedrock Data
Automation came in,

910
00:46:23,007 --> 00:46:27,240
and BDA became absolutely
essential, right?

911
00:46:27,240 --> 00:46:29,490
BDA is purpose built

912
00:46:29,490 --> 00:46:32,550
for these kind of complex
table extractions.

913
00:46:32,550 --> 00:46:34,380
And honestly it was a
game changer from us.

914
00:46:34,380 --> 00:46:36,810
Traditional table extractors just couldn't

915
00:46:36,810 --> 00:46:41,810
handle the complexity around
these financial documents.

916
00:46:41,880 --> 00:46:44,790
The reality is, even myself,
I look at some of these tables

917
00:46:44,790 --> 00:46:46,020
and I'm even confused, right?

918
00:46:46,020 --> 00:46:49,320
So cheers to anything that
can kind of look at those,

919
00:46:49,320 --> 00:46:51,570
and handle them, right?

920
00:46:51,570 --> 00:46:55,620
So last there is gonna be our
charts and our images, right?

921
00:46:55,620 --> 00:46:58,620
And so those, then we would
go into a vision model, right?

922
00:46:58,620 --> 00:47:01,170
A vision model is able
to look at those, right?

923
00:47:01,170 --> 00:47:03,180
Create some kind of metadata for it

924
00:47:03,180 --> 00:47:05,250
and create something that allows us

925
00:47:05,250 --> 00:47:09,480
to query them in some
form of vector database.

926
00:47:09,480 --> 00:47:11,850
So this multimodal approach is

927
00:47:11,850 --> 00:47:14,130
what finally kind of unlocked the fact

928
00:47:14,130 --> 00:47:18,870
that we have a scalable PDF
processing system, right?

929
00:47:18,870 --> 00:47:22,080
So different modalities, different tools,

930
00:47:22,080 --> 00:47:23,910
intelligent routing, right?

931
00:47:23,910 --> 00:47:27,270
That's kind of the architecture
that solves some of this.

932
00:47:27,270 --> 00:47:29,400
But here's the thing.

933
00:47:29,400 --> 00:47:31,380
This is like maybe half the battle,

934
00:47:31,380 --> 00:47:33,270
maybe even less than
half the battle, right?

935
00:47:33,270 --> 00:47:34,740
The real battle comes

936
00:47:34,740 --> 00:47:37,290
in how do you get this
information then back out

937
00:47:37,290 --> 00:47:39,810
of our systems, right?

938
00:47:39,810 --> 00:47:44,810
So this is where we went into
a kind of different approach

939
00:47:46,770 --> 00:47:50,220
to get our stuff back out, right?

940
00:47:50,220 --> 00:47:55,220
This is about moving away from
a traditional keyword search,

941
00:47:55,830 --> 00:47:57,840
from semantic search, right,

942
00:47:57,840 --> 00:48:01,410
because that all fails to
understand the complexity

943
00:48:01,410 --> 00:48:03,870
around these documents, right?

944
00:48:03,870 --> 00:48:08,160
And here's where like traditional
single shop vector search,

945
00:48:08,160 --> 00:48:12,090
Which then just returns
the top-k chunks, right?

946
00:48:12,090 --> 00:48:16,350
Or combining that with some
form of keyword search.

947
00:48:16,350 --> 00:48:18,270
You run a reranker, right?

948
00:48:18,270 --> 00:48:19,977
You get that information into an LLM,

949
00:48:19,977 --> 00:48:22,677
and you're like, "Ha,
I'm done, this works."

950
00:48:23,647 --> 00:48:25,680
And then you realize it doesn't.

951
00:48:25,680 --> 00:48:28,380
So what we needed to
do, right, is we found

952
00:48:28,380 --> 00:48:31,800
that there were very specific
types of questions, right,

953
00:48:31,800 --> 00:48:33,090
that people were asking us

954
00:48:33,090 --> 00:48:35,520
where the information is
just scattered, right,

955
00:48:35,520 --> 00:48:38,850
across these documents, right?

956
00:48:38,850 --> 00:48:40,590
Think of a use case
where somebody's trying

957
00:48:40,590 --> 00:48:44,740
to find, in an annual
report, the business units

958
00:48:45,600 --> 00:48:47,940
of the entity, right?

959
00:48:47,940 --> 00:48:49,740
Cross reference that with the revenue

960
00:48:49,740 --> 00:48:51,510
that it may have, right?

961
00:48:51,510 --> 00:48:55,290
And then also analyze maybe
its sector information, right?

962
00:48:55,290 --> 00:48:58,410
So this kind of search query, right,

963
00:48:58,410 --> 00:49:00,900
on a document is incredibly complex.

964
00:49:00,900 --> 00:49:03,900
Business units, right,
that exists in one table,

965
00:49:03,900 --> 00:49:08,340
probably stretched around a
couple different pages, right?

966
00:49:08,340 --> 00:49:11,820
The revenue and other kind
of financial metrics are

967
00:49:11,820 --> 00:49:12,900
in another table.

968
00:49:12,900 --> 00:49:15,120
Maybe some of that
information is in a footnote

969
00:49:15,120 --> 00:49:16,860
for some table, right?

970
00:49:16,860 --> 00:49:19,650
And so how do you, how
are you able to pull all

971
00:49:19,650 --> 00:49:23,190
of that stuff together
in a single shot search?

972
00:49:23,190 --> 00:49:25,140
It's just not gonna happen, right?

973
00:49:25,140 --> 00:49:29,520
So this is where we went into
a agentic retrieval, right?

974
00:49:29,520 --> 00:49:34,050
And so we built agentic
retrieval, right, to be,

975
00:49:34,050 --> 00:49:37,950
to look at a document like a
human would look at it, right?

976
00:49:37,950 --> 00:49:41,640
So an agentic retrieval, we
get the user's query, right?

977
00:49:41,640 --> 00:49:44,430
We create a plan off of that, right?

978
00:49:44,430 --> 00:49:49,430
So this means decompose
the queries, right?

979
00:49:49,680 --> 00:49:54,300
Create a search strategy, we
then execute that strategy

980
00:49:54,300 --> 00:49:57,300
that could be multiple different
searches across it, right?

981
00:49:57,300 --> 00:49:59,850
Then it will reflect, right?

982
00:49:59,850 --> 00:50:02,370
Did it actually answer that question?

983
00:50:02,370 --> 00:50:04,710
Was it able to pull down that information?

984
00:50:04,710 --> 00:50:06,930
If not, continue the loop, right?

985
00:50:06,930 --> 00:50:08,610
And then finalize this

986
00:50:08,610 --> 00:50:11,670
by providing the individual chunks, right,

987
00:50:11,670 --> 00:50:13,980
with its proper citations, right?

988
00:50:13,980 --> 00:50:18,980
And so this is truly
intelligent document navigation.

989
00:50:19,140 --> 00:50:21,900
It's not just search, right?

990
00:50:21,900 --> 00:50:24,300
And so to take a step back, right,

991
00:50:24,300 --> 00:50:26,220
into the kind of conversation
that we're having today

992
00:50:26,220 --> 00:50:28,080
about this multi-agentic system is

993
00:50:28,080 --> 00:50:32,130
that this now becomes
one of the tools, right,

994
00:50:32,130 --> 00:50:34,200
inside of our tool belt, right?

995
00:50:34,200 --> 00:50:37,350
This is a tool that now any workflow,

996
00:50:37,350 --> 00:50:40,590
any agent is able to utilize, right?

997
00:50:40,590 --> 00:50:43,440
So that it can pull the right information

998
00:50:43,440 --> 00:50:46,443
at the right time, right,
to solve its needs.

999
00:50:47,400 --> 00:50:50,040
So this as a whole kind of, like,

1000
00:50:50,040 --> 00:50:53,040
brings together our
complete solution, right?

1001
00:50:53,040 --> 00:50:54,900
We have a bunch of different tools.

1002
00:50:54,900 --> 00:50:58,350
We have specific task agents, right?

1003
00:50:58,350 --> 00:51:02,460
That work inside of their known
domains, right, orchestrated

1004
00:51:02,460 --> 00:51:05,670
across a really complex
orchestration system, right?

1005
00:51:05,670 --> 00:51:09,633
All there, right, to solve
a specific customer need.

1006
00:51:10,860 --> 00:51:15,420
Now we need to talk
about what's next, right?

1007
00:51:15,420 --> 00:51:18,720
And so we're evolving at all times, right?

1008
00:51:18,720 --> 00:51:20,970
And our customers realize

1009
00:51:20,970 --> 00:51:23,310
that they need our intelligence, right?

1010
00:51:23,310 --> 00:51:26,850
But they want to not only just
consume with it, they want

1011
00:51:26,850 --> 00:51:30,510
to build with it, and this
led us into MCPs, right,

1012
00:51:30,510 --> 00:51:31,950
and our smart APIs.

1013
00:51:31,950 --> 00:51:33,840
And a lot of the tools that we have built

1014
00:51:33,840 --> 00:51:36,780
and we utilize inside of our
orchestration systems, right,

1015
00:51:36,780 --> 00:51:41,370
we are now able to expose
to our customers directly.

1016
00:51:41,370 --> 00:51:46,370
Now I think, we were incredibly
fast to the market, right?

1017
00:51:47,760 --> 00:51:51,240
And we have been custom
building a lot of our solutions,

1018
00:51:51,240 --> 00:51:53,790
because there just weren't
solutions available

1019
00:51:53,790 --> 00:51:55,980
to us already.

1020
00:51:55,980 --> 00:51:57,780
So I think one of the
next steps that we have

1021
00:51:57,780 --> 00:51:59,430
to take internally is really

1022
00:51:59,430 --> 00:52:02,550
figure out the, like,
buy versus build, right?

1023
00:52:02,550 --> 00:52:03,930
And honestly,

1024
00:52:03,930 --> 00:52:07,170
after being on in re:Invent
for the last few days,

1025
00:52:07,170 --> 00:52:09,600
we have realized that a lot of the things

1026
00:52:09,600 --> 00:52:14,400
that have come out, right, in
Bedrock, in AgentCore are all

1027
00:52:14,400 --> 00:52:16,290
going to be things that
we are going to be able

1028
00:52:16,290 --> 00:52:19,530
to replace a lot of our
custom code width, right?

1029
00:52:19,530 --> 00:52:21,390
And it's gonna be able
to solve our problems.

1030
00:52:21,390 --> 00:52:26,250
And all of these utilizing
of these managed services is

1031
00:52:26,250 --> 00:52:29,100
gonna reduce a little
bit of our own tech debt.

1032
00:52:29,100 --> 00:52:34,100
So speaking of your primitives, right?

1033
00:52:34,320 --> 00:52:36,720
Sam's gonna work, go
through AgentCore, right?

1034
00:52:36,720 --> 00:52:39,960
And teach you how AWS is
trying to build this, right,

1035
00:52:39,960 --> 00:52:41,130
so that you guys can also

1036
00:52:41,130 --> 00:52:43,030
have production ready things at scale.

1037
00:52:45,060 --> 00:52:46,650
- Thank you, Dennis.

1038
00:52:46,650 --> 00:52:50,040
So I'd expect the
majority of you have heard

1039
00:52:50,040 --> 00:52:51,870
through re:Invent or
before about AgentCore.

1040
00:52:51,870 --> 00:52:53,490
This is not gonna be a deep dive.

1041
00:52:53,490 --> 00:52:56,130
This is gonna be a very
high level introduction

1042
00:52:56,130 --> 00:52:57,420
of AgentCore.

1043
00:52:57,420 --> 00:53:01,230
So AgentCore is an addition
of our Bedrock ecosystem

1044
00:53:01,230 --> 00:53:02,970
that gives you primitives

1045
00:53:02,970 --> 00:53:06,843
to build production-grade
agents at scale on AWS.

1046
00:53:08,160 --> 00:53:09,930
There are eight primitives.

1047
00:53:09,930 --> 00:53:12,990
We just announced one, a new
one yesterday that is not here,

1048
00:53:12,990 --> 00:53:14,220
because it was an embargo

1049
00:53:14,220 --> 00:53:16,440
and I couldn't add it to this slide.

1050
00:53:16,440 --> 00:53:18,090
But some of these primitives

1051
00:53:18,090 --> 00:53:22,620
that I strongly believe Moody's
will be able to actually use

1052
00:53:22,620 --> 00:53:25,860
and benefit from that, are the runtime.

1053
00:53:25,860 --> 00:53:28,080
So we start with the
Runtime, which is the ability

1054
00:53:28,080 --> 00:53:30,600
for you to have a serverless
compute environment

1055
00:53:30,600 --> 00:53:32,040
where you can run agents

1056
00:53:32,040 --> 00:53:35,250
with session isolation at the VM level

1057
00:53:35,250 --> 00:53:39,210
with the pay-as-you-go
serverless scenario, right?

1058
00:53:39,210 --> 00:53:41,550
It supports any framework.

1059
00:53:41,550 --> 00:53:43,200
Moody's have built their own framework,

1060
00:53:43,200 --> 00:53:45,030
so they can bring their own framework,

1061
00:53:45,030 --> 00:53:47,070
they can call whatever model they're using

1062
00:53:47,070 --> 00:53:49,710
for specialized agents at any point.

1063
00:53:49,710 --> 00:53:53,340
The whole idea of AgentCore
is to give flexibility

1064
00:53:53,340 --> 00:53:55,260
and options for users.

1065
00:53:55,260 --> 00:53:58,980
You can pick and choose any of
these primitives at any point

1066
00:53:58,980 --> 00:54:01,290
and combine with your own solution.

1067
00:54:01,290 --> 00:54:04,770
So Runtime is definitely a
big candidate for helping

1068
00:54:04,770 --> 00:54:06,570
with the compute power.

1069
00:54:06,570 --> 00:54:10,440
But then, Dennis mentioned,
they currently have 80 tools

1070
00:54:10,440 --> 00:54:13,830
just for that specific
multi-agentic system.

1071
00:54:13,830 --> 00:54:17,400
And I could imagine that tool
list will keep increasing.

1072
00:54:17,400 --> 00:54:20,100
We have released AgentCore
Gateway, which allows you

1073
00:54:20,100 --> 00:54:23,640
to create a virtual remote MCP server

1074
00:54:23,640 --> 00:54:27,360
that has a complete managed
service solution for you

1075
00:54:27,360 --> 00:54:30,960
to manage your tools that
maybe can call directly APIs.

1076
00:54:30,960 --> 00:54:33,960
You can have Lambda behind the
scenes to add your own logic.

1077
00:54:33,960 --> 00:54:35,310
You can even actually call

1078
00:54:35,310 --> 00:54:38,310
behind the scenes your
own existing MCP servers

1079
00:54:38,310 --> 00:54:40,590
in a centralized platform.

1080
00:54:40,590 --> 00:54:43,230
Now, everything that you do, especially

1081
00:54:43,230 --> 00:54:46,470
on a such a regulated industry
as financial services,

1082
00:54:46,470 --> 00:54:49,890
you wanna make sure you have
proper identity authentication

1083
00:54:49,890 --> 00:54:51,810
and authorization, right?

1084
00:54:51,810 --> 00:54:54,180
And you separate, when
you think about an agent,

1085
00:54:54,180 --> 00:54:56,670
you can think about two types
of authorization, right?

1086
00:54:56,670 --> 00:54:59,310
You can think about inbound
authorization, meaning

1087
00:54:59,310 --> 00:55:01,770
who is the user accessing the agent

1088
00:55:01,770 --> 00:55:04,320
and what are the permissions
that that user have

1089
00:55:04,320 --> 00:55:06,330
in order to call that agent.

1090
00:55:06,330 --> 00:55:09,570
But then, you know, agentic
systems brings a new challenge

1091
00:55:09,570 --> 00:55:11,760
into authentication, authorization.

1092
00:55:11,760 --> 00:55:14,760
What are the tools, and what tools,

1093
00:55:14,760 --> 00:55:17,460
and what type of calls those agents can do

1094
00:55:17,460 --> 00:55:19,080
on behalf of the user?

1095
00:55:19,080 --> 00:55:20,700
And how can you do the metadata,

1096
00:55:20,700 --> 00:55:23,910
the federation propagation
from the user identity

1097
00:55:23,910 --> 00:55:27,060
into what we call the
outbound authentication.

1098
00:55:27,060 --> 00:55:29,610
So we have introduced AgentCore Identity

1099
00:55:29,610 --> 00:55:32,310
that can help you with all this complexity

1100
00:55:32,310 --> 00:55:35,160
of managing the authentication
and authorization.

1101
00:55:35,160 --> 00:55:38,160
Great news about AgentCore
Identity, you can integrate

1102
00:55:38,160 --> 00:55:39,870
with your existing IdPs.

1103
00:55:39,870 --> 00:55:42,420
So if you're using
Cognito, you're using Okta,

1104
00:55:42,420 --> 00:55:45,930
or any custom provider
that supports OAuth,

1105
00:55:45,930 --> 00:55:48,360
you can just connect
to AgentCore Identity.

1106
00:55:48,360 --> 00:55:50,070
And AgentCore Identity will actually

1107
00:55:50,070 --> 00:55:54,360
call, on your behalf, those
providers to validate the token

1108
00:55:54,360 --> 00:55:56,730
and validate the credentials of your user.

1109
00:55:56,730 --> 00:55:59,340
So you're not trying to replace
your identity providers,

1110
00:55:59,340 --> 00:56:01,170
we're just trying to give you flexibility

1111
00:56:01,170 --> 00:56:05,100
to support both inbound and
outbound authentication.

1112
00:56:05,100 --> 00:56:07,770
And of course, everything you do here,

1113
00:56:07,770 --> 00:56:10,050
you wanna make sure
you have observability.

1114
00:56:10,050 --> 00:56:13,590
How do you make sure you
know what the agent is doing

1115
00:56:13,590 --> 00:56:15,000
if you need to troubleshoot?

1116
00:56:15,000 --> 00:56:15,870
Or you wanna make sure

1117
00:56:15,870 --> 00:56:17,940
you have regulatory, you know, compliance,

1118
00:56:17,940 --> 00:56:20,580
you're saving every single
step that, you know,

1119
00:56:20,580 --> 00:56:23,220
Dennis showed us a very complex workflow

1120
00:56:23,220 --> 00:56:26,400
that had dozens and dozens of steps?

1121
00:56:26,400 --> 00:56:29,580
How do you actually
collect every single step

1122
00:56:29,580 --> 00:56:32,580
that every single agent
took behind the scenes?

1123
00:56:32,580 --> 00:56:34,380
Every single large language model call,

1124
00:56:34,380 --> 00:56:35,760
every single tool call,

1125
00:56:35,760 --> 00:56:38,220
every single reasoning
chain of thought, prompt.

1126
00:56:38,220 --> 00:56:39,690
With AgentCore Observability,

1127
00:56:39,690 --> 00:56:42,870
you can either use Runtime
on AgentCore Gateway,

1128
00:56:42,870 --> 00:56:45,240
or you can even use outside AgentCore.

1129
00:56:45,240 --> 00:56:49,260
You can extract all that
information and ship to CloudWatch

1130
00:56:49,260 --> 00:56:51,840
or a third party observability provider

1131
00:56:51,840 --> 00:56:54,480
of your preference using OpenTelemetry.

1132
00:56:54,480 --> 00:56:57,150
And you have all the capability there.

1133
00:56:57,150 --> 00:56:59,010
And then finally, which I
think is a very important one,

1134
00:56:59,010 --> 00:57:00,153
is AgentCore Memory.

1135
00:57:01,350 --> 00:57:06,150
Let's say I'm a bank using
Moody's agentic AI systems,

1136
00:57:06,150 --> 00:57:08,910
and I would like the system to know

1137
00:57:08,910 --> 00:57:11,190
that, you know, I am from this bank

1138
00:57:11,190 --> 00:57:14,910
and I am a maybe part
of the investment bank

1139
00:57:14,910 --> 00:57:18,120
and I have these stocks on my portfolio.

1140
00:57:18,120 --> 00:57:20,430
Wouldn't it be awesome if
the system could actually

1141
00:57:20,430 --> 00:57:23,460
collect that data as I'm
interacting with the agent

1142
00:57:23,460 --> 00:57:25,800
and save for long-term purposes?

1143
00:57:25,800 --> 00:57:28,470
With AgentCore Memory, you have
this fully managed solution

1144
00:57:28,470 --> 00:57:30,600
that you can collect
both short-term memory,

1145
00:57:30,600 --> 00:57:33,240
which is just a
user-assistant interaction,

1146
00:57:33,240 --> 00:57:36,510
and automatically
extract insights for you,

1147
00:57:36,510 --> 00:57:38,400
preferences, summarizations,

1148
00:57:38,400 --> 00:57:41,970
or even your own custom
semantic information.

1149
00:57:41,970 --> 00:57:43,980
If you're interested in
AgentCore, there are a lot

1150
00:57:43,980 --> 00:57:45,870
of sessions available in re:Invent.

1151
00:57:45,870 --> 00:57:48,000
Highly recommend you checking it out.

1152
00:57:48,000 --> 00:57:50,370
But that is pretty much
it for our session.

1153
00:57:50,370 --> 00:57:52,560
Just wanna say thank you
so much for joining us.

1154
00:57:52,560 --> 00:57:56,130
And the last thing, please
rate us on the AWS Events app.

1155
00:57:56,130 --> 00:58:00,188
Our session ID is IND3303. And
thank you so much everyone.

1156
00:58:00,188 --> 00:58:03,188
(audience clapping)

