# AWS re:Invent 2025 技术会议总结：Autodesk Bernini 模型在 AWS Neuron 上的优化

## 会议概述

本次会议由 AWS 生成式 AI 创新中心的 Anila Jooshi 主持，与 Autodesk 的首席机器学习工程师 Kamal 以及 AWS 高级工程师 Mund 共同分享了 Autodesk 如何通过 AWS Neuron 芯片优化其 3D 生成式 AI 模型 Bernini 的推理性能。会议重点讨论了 AI 基础设施成本不断上升的挑战，以及如何通过专用 AI 加速器实现成本优化。

会议展示了 Autodesk 在建筑、制造、娱乐等领域的 AI 应用案例，包括环境因素分析、自动化任务处理、3D 运动生成等。Autodesk 在过去两年中深度学习计算需求增长了 200%，这促使他们寻求更高效的计算解决方案。通过与 AWS 合作，将 Bernini 模型迁移到 Neuron 芯片上，实现了显著的性能提升和成本节约。

## 详细时间线与关键要点

### 开场介绍 (00:00-05:30)
- **00:00-01:30**: Anila Jooshi 开场，询问观众 AI 基础设施成本是否翻倍，大多数人举手确认
- **01:30-03:00**: 介绍 AWS 生成式 AI 创新中心团队，包括深度科学、工程、策略和架构师
- **03:00-05:30**: 概述会议议程：AI 计算的未来、Autodesk 的 AI 之旅、Bernini 模型优化

### AI 基础设施现状分析 (05:30-08:00)
- **05:30-06:30**: 根据 Gartner 数据，今年 AI 基础设施支出将达到 180 亿美元，预计明年翻倍
- **06:30-08:00**: 客户反馈显示灵活性是关键，更大的模型和更多 GPU 并非总是答案，性能收益在某点后会递减

### AWS AI 实例组合介绍 (08:00-10:00)
- **08:00-09:00**: AWS 构建了包括 Graviton CPU、GPU、AI 加速器 Inferentia 和 FPGA 的实例组合
- **09:00-10:00**: 三天前发布了 Trainium 3，为客户提供基于工作负载选择合适资源的灵活性

### Autodesk 使命与应用场景 (10:00-15:00)
- **10:00-11:30**: Kamal 介绍 Autodesk 使命：赋能创新者设计和制造任何东西，从体育场到赛道再到 VFX 超级英雄
- **11:30-13:00**: 在建筑领域分析风、噪音、洪水风险等环境因素，生成优化的建筑布局
- **13:00-15:00**: 在制造业生成 3D 模型和设计替代方案，支持使用简单提示快速探索概念

### Autodesk 计算需求增长 (15:00-18:00)
- **15:00-16:00**: 为支持生成式 AI 工作规模，计算需求显著增加，过去两年深度学习计算需求增长 200%
- **16:00-18:00**: 展示深度学习工作流程示例：数据摄取（300TB）、处理、模型训练实验（300+ 次）、部署（10 个模型）

### 基础设施架构 (18:00-20:00)
- **18:00-19:00**: 基于 AWS EKS 构建训练和推理基础设施，使用 Ray 进行可扩展分布式计算
- **19:00-20:00**: 包含开发者友好的模型训练界面、Ray Serve、GitOps 模型部署和可观测性工具

### Bernini 模型介绍 (20:00-25:00)
- **20:00-22:00**: Autodesk 多年来推动 3D 生成模型研究，在 CVPR 和 ICML 等顶级会议发表论文
- **22:00-25:00**: Bernini 能够从图像、点云或自然语言等多种输入生成 3D 对象，包含扩散模型和多种数据表示

### AWS Neuron 技术原理 (25:00-35:00)
- **25:00-27:00**: Mund 解释为什么需要 AI 加速器：深度学习需要大量矩阵乘法运算（GPT 可达千万亿次浮点运算）
- **27:00-30:00**: 展示矩阵乘法中元素重用的概念，4x4 矩阵中 A1 元素被重用 4 次
- **30:00-35:00**: 介绍脉动阵列架构，通过乘法累加操作减少内存 IO，实现更便宜、更简单的芯片设计

### Neuron 芯片架构 (35:00-40:00)
- **35:00-37:00**: Neuron 芯片包含多个 Neuron 核心，具有不同类型的引擎（HBM 等）支持核心间通信
- **37:00-40:00**: 详细介绍 Neuron 核心内部：张量引擎（主要脉动阵列）、向量引擎、标量引擎、通用 SIMD 引擎

### PyTorch 与 Neuron 集成 (40:00-43:00)
- **40:00-42:00**: PyTorch 代码转换为 XLA C++ 中间表示，Neuron SDK 编译图形、融合操作、调度引擎
- **42:00-43:00**: 新发布的 Torch Neuron 允许更原生地使用 Neuron，类似于 CUDA 的 .to() 方法

### Neuron 适用场景 (43:00-47:00)
- **43:00-45:00**: Neuron 专为矩阵乘法优化，适合 Transformer 和嵌入模型，在需要亚 5 毫秒延迟的工作负载中表现出色
- **45:00-47:00**: 实验显示在较低批次大小和序列长度下，Neuron 性能至少提升 2 倍，价格性能提升 3-4 倍

### Bernini 在 Neuron 上的实现 (47:00-52:00)
- **47:00-49:00**: 将 Bernini 管道分解为组件：编码器、反向扩散、小波变换器、三角化
- **49:00-52:00**: 使用 Neuron Trace API 分别编译各组件，将编译产物保存到 S3，通过 Ray Serve 部署

### 性能结果 (52:00-55:00)
- **52:00-54:00**: 实现每次预测成本降低 28%，在不同并发级别下都获得更好的价格性能
- **54:00-55:00**: 展示 Inferentia 与 G5 实例在 100 万次推理成本对比图表

### 总结与经验分享 (55:00-58:00)
- **55:00-56:30**: 强调没有一刀切的解决方案，模型架构很重要，灵活性是长期成功的关键
- **56:30-58:00**: 专用硬件将在摩尔定律放缓后继续扩展，生产环境设置对延迟影响巨大