{
  "title": "AWS re:Invent 2025 - Tracing the Untraceable: Full-Stack Observability for LLMs and Agents (AIM212)",
  "title_cn": "AWS re:Invent 2025 - 追踪不可追踪的：LLM 和 Agent 的全栈可观测性 (AIM212)",
  "abstract": "In just a few years, LLMs have gone from research curiosities to the backbone of new software experiences. Organizations are rushing to productionize LLM workflows because of their immense value, but are doing so without any observability guardrails, introducing new layers of fragility and complexity such as performance volatility, quality drift, and security risks.\nIn this talk, we’ll discover how to instantly monitor and troubleshoot LLM applications with zero-instrumentation. Whether on commercial LLM stacks or AWS Bedrock - we’ll break out of the LLM blackbox and learn how to monitor token usage, response latency, data exposure prompts, and model execution failures. This presentation is brought to you by groundcover, an AWS Partner.",
  "abstract_cn": "短短几年间，大语言模型（LLM）已从研究领域的新奇事物发展成为新型软件体验的支柱。各类组织正争相将LLM工作流投入生产环境，因为它们具有巨大价值，但在此过程中却没有任何可观测性护栏，引入了新的脆弱性和复杂性层面，例如性能波动、质量漂移和安全风险。\n\n在本次演讲中，我们将探讨如何通过零插桩方式即时监控和排查LLM应用程序故障。无论是在商业LLM技术栈还是AWS Bedrock上，我们都将突破LLM黑盒，学习如何监控令牌使用量、响应延迟、数据暴露提示以及模型执行失败。本演示由AWS合作伙伴groundcover为您呈现。",
  "presenter": [
    {
      "name": "Shahar Azulay",
      "title": "CEO",
      "company": "groundcover"
    }
  ],
  "attributes": {
    "topic": "Artificial Intelligence",
    "area_of_interest": [
      "Cost Optimization",
      "Agentic AI",
      "Kubernetes"
    ],
    "services": [],
    "type": "Lightning talk"
  },
  "video_url": "https://www.youtube.com/watch?v=nCsdKZgwYO8",
  "session_code": "AIM212-S"
}