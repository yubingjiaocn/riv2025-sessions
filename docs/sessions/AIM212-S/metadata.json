{
  "title": "AWS re:Invent 2025 - Tracing the Untraceable: Full-Stack Observability for LLMs and Agents (AIM212)",
  "title_cn": "AWS re:Invent 2025 - 追踪不可追踪的：LLM和智能体的全栈可观测性 (AIM212)",
  "abstract": "In just a few years, LLMs have gone from research curiosities to the backbone of new software experiences. Organizations are rushing to productionize LLM workflows because of their immense value, but are doing so without any observability guardrails, introducing new layers of fragility and complexity such as performance volatility, quality drift, and security risks.\nIn this talk, we’ll discover how to instantly monitor and troubleshoot LLM applications with zero-instrumentation. Whether on commercial LLM stacks or AWS Bedrock - we’ll break out of the LLM blackbox and learn how to monitor token usage, response latency, data exposure prompts, and model execution failures. This presentation is brought to you by groundcover, an AWS Partner.",
  "abstract_cn": "在短短几年内，大语言模型已从研究好奇心发展为新软件体验的支柱。各组织正急于将LLM工作流投入生产，因为它们具有巨大价值，但在没有任何可观测性防护措施的情况下进行，引入了新的脆弱性和复杂性层面，如性能波动、质量漂移和安全风险。\n\n在本次演讲中，我们将探索如何通过零仪器化即时监控和故障排除LLM应用程序。无论是在商业LLM堆栈还是AWS Bedrock上 - 我们将突破LLM黑盒，学习如何监控令牌使用量、响应延迟、数据暴露提示和模型执行失败。本演示由AWS合作伙伴groundcover为您呈现。",
  "presenter": [
    {
      "name": "Shahar Azulay",
      "title": "CEO",
      "company": "groundcover"
    }
  ],
  "attributes": {
    "topic": "Artificial Intelligence",
    "area_of_interest": [
      "Cost Optimization",
      "Agentic AI",
      "Kubernetes"
    ],
    "services": [],
    "type": "Lightning talk"
  },
  "video_url": "https://www.youtube.com/watch?v=nCsdKZgwYO8",
  "session_code": "AIM212-S",
  "duration_seconds": 1077,
  "duration_minutes": 17.9
}