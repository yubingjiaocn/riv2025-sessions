1
00:00:00,045 --> 00:00:00,878
(audience applauding)

2
00:00:00,878 --> 00:00:02,760
- Hi everyone, my name is Ruslan Kusov.

3
00:00:02,760 --> 00:00:06,000
I'm cloud COE director at
SoftServe, an AWS Ambassador,

4
00:00:06,000 --> 00:00:08,010
and currently I'm losing my voice.

5
00:00:08,010 --> 00:00:09,300
I have one more presentation today,

6
00:00:09,300 --> 00:00:10,710
but hope everything will be fine,

7
00:00:10,710 --> 00:00:12,690
at least for this presentation.

8
00:00:12,690 --> 00:00:14,630
So today I'm gonna tell you about new era

9
00:00:14,630 --> 00:00:15,832
of platform engineering,

10
00:00:15,832 --> 00:00:19,861
particularly platform
engineering powered by agentic AI

11
00:00:19,861 --> 00:00:22,830
and self-service with agentic AI.

12
00:00:22,830 --> 00:00:24,183
Let me grab my clicker.

13
00:00:25,740 --> 00:00:27,750
First, let me start
with the concept itself,

14
00:00:27,750 --> 00:00:29,190
concept of platform engineering.

15
00:00:29,190 --> 00:00:32,130
I believe most of you may
be familiar with this,

16
00:00:32,130 --> 00:00:34,590
but if not, it all started with DevOps.

17
00:00:34,590 --> 00:00:35,850
Remember this, DevOps,

18
00:00:35,850 --> 00:00:37,710
tools, people, processes,

19
00:00:37,710 --> 00:00:39,570
how we connect those things together,

20
00:00:39,570 --> 00:00:40,530
how we build something

21
00:00:40,530 --> 00:00:43,620
that will be useful for our developers.

22
00:00:43,620 --> 00:00:46,080
And it evolved at some point of time.

23
00:00:46,080 --> 00:00:48,000
It evolves to platform engineering.

24
00:00:48,000 --> 00:00:50,190
So people, they started building

25
00:00:50,190 --> 00:00:52,260
what they call internal
development platform

26
00:00:52,260 --> 00:00:53,850
or self-service platform.

27
00:00:53,850 --> 00:00:56,636
The idea is that if you
have large development team

28
00:00:56,636 --> 00:00:59,190
or teams, like 10 different teams,

29
00:00:59,190 --> 00:01:01,230
you would like to introduce
some set of standards.

30
00:01:01,230 --> 00:01:04,950
Otherwise, you will end up
with a situation when one team,

31
00:01:04,950 --> 00:01:08,370
they are developing their
application using ECS.

32
00:01:08,370 --> 00:01:10,770
Another team, they'll be using EKS.

33
00:01:10,770 --> 00:01:12,180
One team will be using Datadog,

34
00:01:12,180 --> 00:01:14,880
another team will be using
CloudWatch and so on,

35
00:01:14,880 --> 00:01:17,410
and that will introduce
additional operational overheads,

36
00:01:17,410 --> 00:01:19,560
additional costs and so on.

37
00:01:19,560 --> 00:01:22,470
And in order to avoid that,
you would like to standardize.

38
00:01:22,470 --> 00:01:24,870
You would like to build some
sort of like abstraction layer,

39
00:01:24,870 --> 00:01:27,360
the platform that can be
used as a self-service.

40
00:01:27,360 --> 00:01:28,860
So you just follow the standard,

41
00:01:28,860 --> 00:01:30,510
and you just write your code.

42
00:01:30,510 --> 00:01:32,400
Functions well for the developers,

43
00:01:32,400 --> 00:01:35,010
and that's why concept became popular.

44
00:01:35,010 --> 00:01:36,390
And they really mean it,

45
00:01:36,390 --> 00:01:40,230
because we researched different sources.

46
00:01:40,230 --> 00:01:42,000
We worked with multiple customers

47
00:01:42,000 --> 00:01:44,730
of SoftServe's regional
data system integrator.

48
00:01:44,730 --> 00:01:47,790
And we compared our data
with the data from Red Hat.

49
00:01:47,790 --> 00:01:51,150
As you can see on this
slide, 85% of customers,

50
00:01:51,150 --> 00:01:52,860
they are moving towards
platform engineering.

51
00:01:52,860 --> 00:01:56,310
So organizations, they
would like to discover

52
00:01:56,310 --> 00:01:59,040
or they're already using
this platform engineering.

53
00:01:59,040 --> 00:02:02,040
As you can see, 18%, they're advanced,

54
00:02:02,040 --> 00:02:03,930
14, they're just exploring,

55
00:02:03,930 --> 00:02:07,833
and 27, 41, that's like number in between.

56
00:02:09,000 --> 00:02:12,120
Process itself, from our
experience, takes about two years.

57
00:02:12,120 --> 00:02:15,090
So if you're right now
at this exploring stage,

58
00:02:15,090 --> 00:02:17,970
you need about two years to
introduce mature practices

59
00:02:17,970 --> 00:02:20,433
of platform engineering
in your organization.

60
00:02:21,540 --> 00:02:25,470
The problem is that there is
no one-size-fits-all approach.

61
00:02:25,470 --> 00:02:29,130
So simply meaning that
it is a complex product.

62
00:02:29,130 --> 00:02:31,260
It depends on your organizational culture.

63
00:02:31,260 --> 00:02:33,060
It depends on the way

64
00:02:33,060 --> 00:02:35,970
how you are organizing processes
within your organization,

65
00:02:35,970 --> 00:02:38,580
what tools you're already
using in your organization.

66
00:02:38,580 --> 00:02:41,250
As I mentioned previously, it's
the way how to set standards

67
00:02:41,250 --> 00:02:44,100
and not to introduce any new
tools, unnecessary tools.

68
00:02:44,100 --> 00:02:48,420
So how we can approach at that case.

69
00:02:48,420 --> 00:02:51,570
And at SoftServe, we
decided that it makes sense

70
00:02:51,570 --> 00:02:53,430
to build some sort of like framework.

71
00:02:53,430 --> 00:02:55,170
So instead of telling

72
00:02:55,170 --> 00:02:57,870
that you should buy platform
engineering solution,

73
00:02:57,870 --> 00:02:59,910
you should build platform
engineering solution

74
00:02:59,910 --> 00:03:01,770
that will follow all your needs.

75
00:03:01,770 --> 00:03:04,890
So we introduced our own
framework based on experience,

76
00:03:04,890 --> 00:03:07,980
based on our interaction with our clients,

77
00:03:07,980 --> 00:03:10,680
based on feedback that we received

78
00:03:10,680 --> 00:03:13,320
and, of course, in collaboration with AWS.

79
00:03:13,320 --> 00:03:15,450
And that ended up with this concept

80
00:03:15,450 --> 00:03:16,710
that you can see on the screen,

81
00:03:16,710 --> 00:03:18,873
a concept where we have core components,

82
00:03:18,873 --> 00:03:20,670
EKS, ECS, and Lambda,

83
00:03:20,670 --> 00:03:23,460
because we are talking about
microservices architecture

84
00:03:23,460 --> 00:03:24,960
and all other components

85
00:03:24,960 --> 00:03:28,800
that will complement this
microservices architecture

86
00:03:28,800 --> 00:03:32,790
like microservices runtime,
observability components,

87
00:03:32,790 --> 00:03:34,440
security components, CI/CD,

88
00:03:34,440 --> 00:03:36,240
because we need to build continuous,

89
00:03:36,240 --> 00:03:37,073
we need to test them,

90
00:03:37,073 --> 00:03:38,220
we need to deploy.

91
00:03:38,220 --> 00:03:41,160
The storage is databases,
third-party services.

92
00:03:41,160 --> 00:03:44,580
And of course we have this IDP,
Internal Development Portal,

93
00:03:44,580 --> 00:03:46,380
the tool, that will be your interface,

94
00:03:46,380 --> 00:03:49,500
the developer's interface to
interact with this platform.

95
00:03:49,500 --> 00:03:52,710
So again, the idea is that
all what you need to do

96
00:03:52,710 --> 00:03:55,380
is just to design integration interfaces

97
00:03:55,380 --> 00:03:57,390
and understand that in case,

98
00:03:57,390 --> 00:03:59,130
today, you're gonna use HashiCorp Vault

99
00:03:59,130 --> 00:04:01,470
and tomorrow we are gonna
switch to Secrets Manager,

100
00:04:01,470 --> 00:04:03,210
you're not gonna do
anything with your code.

101
00:04:03,210 --> 00:04:05,970
So you just update this
integration interface,

102
00:04:05,970 --> 00:04:07,620
CSI driver for example.

103
00:04:07,620 --> 00:04:10,500
And you will get new
tool securely connected

104
00:04:10,500 --> 00:04:12,753
to your environments,
to your applications.

105
00:04:13,650 --> 00:04:14,880
Pretty cool idea.

106
00:04:14,880 --> 00:04:16,410
As I said,

107
00:04:16,410 --> 00:04:18,987
we call it SoftServe's Adaptive
Modernization Platform,

108
00:04:18,987 --> 00:04:20,790
but it's not a platform, it's framework.

109
00:04:20,790 --> 00:04:23,340
I know things sometimes confuse people,

110
00:04:23,340 --> 00:04:25,590
but we are trying to follow AWS

111
00:04:25,590 --> 00:04:27,600
in naming our services.

112
00:04:27,600 --> 00:04:32,340
So this platform, we
started with blueprint.

113
00:04:32,340 --> 00:04:33,840
So as you can see,

114
00:04:33,840 --> 00:04:37,440
it's all Kubernetes reference architecture

115
00:04:37,440 --> 00:04:40,860
related to EKS blueprints
released a couple of years ago.

116
00:04:40,860 --> 00:04:42,570
We have multi availability zones.

117
00:04:42,570 --> 00:04:44,070
We have cluster components

118
00:04:44,070 --> 00:04:46,950
split by critical components
and worker components.

119
00:04:46,950 --> 00:04:49,530
We have those environments insulated.

120
00:04:49,530 --> 00:04:53,100
We have best practices like
Karpenter instead of Autoscaler

121
00:04:53,100 --> 00:04:54,450
to better manage efficiency

122
00:04:54,450 --> 00:04:57,090
and scaling capabilities of the cluster.

123
00:04:57,090 --> 00:04:59,640
And if we dive deeper,

124
00:04:59,640 --> 00:05:01,950
we'll also introduce
some default components

125
00:05:01,950 --> 00:05:04,500
because again, remember that
not everything can be solved

126
00:05:04,500 --> 00:05:05,820
with a Kubernetes alone.

127
00:05:05,820 --> 00:05:08,911
You should think about
observability, security,

128
00:05:08,911 --> 00:05:11,340
CI/CD and other things.

129
00:05:11,340 --> 00:05:12,480
And as you can see,

130
00:05:12,480 --> 00:05:15,840
we build this framework
considering those other components,

131
00:05:15,840 --> 00:05:17,490
but they are built in the way

132
00:05:17,490 --> 00:05:19,830
that these components can
be easily substituted.

133
00:05:19,830 --> 00:05:21,330
So again, if for example,

134
00:05:21,330 --> 00:05:24,030
you don't want to use
Argo CD for deployments

135
00:05:24,030 --> 00:05:25,560
because currently using Jenkins

136
00:05:25,560 --> 00:05:28,080
and you are absolutely
fine with that Jenkins,

137
00:05:28,080 --> 00:05:29,490
you can proceed with the Jenkins.

138
00:05:29,490 --> 00:05:32,220
But we'll give you a
framework that will tell you

139
00:05:32,220 --> 00:05:34,710
what gaps you have in
platform engineering,

140
00:05:34,710 --> 00:05:35,880
how you can fill these gaps

141
00:05:35,880 --> 00:05:37,920
with our default solution
and also framework

142
00:05:37,920 --> 00:05:39,630
that will show you how to apply

143
00:05:39,630 --> 00:05:41,970
these platform engineering
processes and practices

144
00:05:41,970 --> 00:05:43,143
for your organization.

145
00:05:45,480 --> 00:05:49,083
It worked really well till 2023,

146
00:05:50,040 --> 00:05:54,900
the year when people started
experimenting with AI.

147
00:05:54,900 --> 00:05:58,500
The funny thing in 2023,

148
00:05:58,500 --> 00:06:00,990
that's the fact that
people, a lot of people,

149
00:06:00,990 --> 00:06:03,720
they did not realize that
AI was not something new.

150
00:06:03,720 --> 00:06:07,680
AI was born like 1956
with a small workshop.

151
00:06:07,680 --> 00:06:09,360
It evolved over the years.

152
00:06:09,360 --> 00:06:11,700
And 2023, that was the year of experiments

153
00:06:11,700 --> 00:06:13,950
and year of Gen AI, generative AI.

154
00:06:13,950 --> 00:06:16,590
I believe everyone had
experiments with the ChatGPT,

155
00:06:16,590 --> 00:06:18,330
with chatbots, whatever.

156
00:06:18,330 --> 00:06:20,070
That's like common use cases.

157
00:06:20,070 --> 00:06:22,950
However, that was hype that
distracted people a lot,

158
00:06:22,950 --> 00:06:26,280
and it distracted our
platform engineering practices

159
00:06:26,280 --> 00:06:27,113
as well.

160
00:06:28,050 --> 00:06:30,930
Next year, that was year after hype

161
00:06:30,930 --> 00:06:32,347
when people realized that,

162
00:06:32,347 --> 00:06:35,010
"Okay, so we created a lot of chatbots,

163
00:06:35,010 --> 00:06:36,870
a lot of experiments with Gen AI,

164
00:06:36,870 --> 00:06:39,033
but how we move that to production.

165
00:06:40,410 --> 00:06:43,230
And 2025, we're still not in production.

166
00:06:43,230 --> 00:06:45,240
And you can join my second session

167
00:06:45,240 --> 00:06:48,450
where I will show you some
specific numbers about that.

168
00:06:48,450 --> 00:06:50,940
But 2025, that's a year when we are trying

169
00:06:50,940 --> 00:06:54,330
to identify business value
of AI, Gen AI, Agentic AI,

170
00:06:54,330 --> 00:06:56,850
But we are trying to build a
business case for our customers

171
00:06:56,850 --> 00:06:59,613
in order to move them to this AI era.

172
00:07:01,440 --> 00:07:04,770
Suddenly, we figured it out
that it's very well connected

173
00:07:04,770 --> 00:07:06,720
with the platform engineering use cases.

174
00:07:06,720 --> 00:07:11,720
So SDLC, to be honest, I
was not like surprised,

175
00:07:12,390 --> 00:07:15,930
but that was an honor for me this morning

176
00:07:15,930 --> 00:07:19,680
to participate in this
keynote note from Matt Garman.

177
00:07:19,680 --> 00:07:24,680
And he shared the same idea
that, in terms of SDLC,

178
00:07:25,290 --> 00:07:26,700
it is end-to-end process.

179
00:07:26,700 --> 00:07:29,700
So you cannot just take
an agent for testing,

180
00:07:29,700 --> 00:07:34,700
agent for business, for
planning, for UI design,

181
00:07:34,770 --> 00:07:37,380
because if you take just a single agent

182
00:07:37,380 --> 00:07:40,920
and not going to care about
end-to-end SDLC process,

183
00:07:40,920 --> 00:07:41,753
you will fail.

184
00:07:41,753 --> 00:07:43,860
You will introduce yet another bottleneck.

185
00:07:43,860 --> 00:07:44,700
How it works.

186
00:07:44,700 --> 00:07:47,820
So let's imagine that you
have a life cycle, SDLC cycle,

187
00:07:47,820 --> 00:07:48,653
every two weeks.

188
00:07:48,653 --> 00:07:51,120
You have new release every two weeks.

189
00:07:51,120 --> 00:07:52,470
You introduce testing agents.

190
00:07:52,470 --> 00:07:54,990
So now you don't need two
weeks to test all your code.

191
00:07:54,990 --> 00:07:57,180
You can test it within hours.

192
00:07:57,180 --> 00:08:00,360
But your developers cannot
develop the code within hours.

193
00:08:00,360 --> 00:08:02,430
They still need two weeks
to develop new code.

194
00:08:02,430 --> 00:08:04,980
So you'll be waiting, sitting and waiting

195
00:08:04,980 --> 00:08:07,410
on the code that should be tested.

196
00:08:07,410 --> 00:08:09,900
Deployments, environments
cannot be prepared

197
00:08:09,900 --> 00:08:12,900
in hours or days.

198
00:08:12,900 --> 00:08:15,240
We still need two weeks to
prepare those environments.

199
00:08:15,240 --> 00:08:17,430
So it's instead of improving the process,

200
00:08:17,430 --> 00:08:20,160
you will introduce yet another
bottleneck to that process.

201
00:08:20,160 --> 00:08:21,450
And in order to avoid that,

202
00:08:21,450 --> 00:08:23,970
you need to have this end-to-end solution.

203
00:08:23,970 --> 00:08:27,780
So again, we connected that
with platform engineering.

204
00:08:27,780 --> 00:08:32,010
What if considering this
SDLC as a common case

205
00:08:32,010 --> 00:08:34,440
or one of the best business
cases for organizations

206
00:08:34,440 --> 00:08:37,373
to step up into this era of AI,

207
00:08:37,373 --> 00:08:39,750
Agentic AI, Gen AI and so on,

208
00:08:39,750 --> 00:08:42,690
what if we connect that
with a platform engineering,

209
00:08:42,690 --> 00:08:46,080
one of the most mature cases
that we had previously?

210
00:08:46,080 --> 00:08:48,480
And we decided to extend the idea

211
00:08:48,480 --> 00:08:51,090
of self-service portal with AI.

212
00:08:51,090 --> 00:08:53,670
So that's how we released AIDEEQ,

213
00:08:53,670 --> 00:08:57,810
or AI Driven Enhanced
Engineering with Amazon Queue.

214
00:08:57,810 --> 00:08:59,640
Again, don't pay attention to the names.

215
00:08:59,640 --> 00:09:03,030
We are following AWS best
practices in naming our services.

216
00:09:03,030 --> 00:09:06,630
So we released this idea of
self-service powered by AI.

217
00:09:06,630 --> 00:09:10,080
And as you can see, it all
based on the components

218
00:09:10,080 --> 00:09:13,800
that either available, like
first party agents from Amazon,

219
00:09:13,800 --> 00:09:17,670
Amazon Queue, Amazon Bedrock
agents, AWS Transform.

220
00:09:17,670 --> 00:09:20,460
Pay attention to agents
that AWS releases today,

221
00:09:20,460 --> 00:09:22,560
especially security agent, DevOps agent.

222
00:09:22,560 --> 00:09:25,200
That's something that we
tested in a preview mode,

223
00:09:25,200 --> 00:09:27,237
worked really well as
an extension to this.

224
00:09:27,237 --> 00:09:28,906
The MCP servers,

225
00:09:28,906 --> 00:09:32,220
custom agents, reusable prompts, LLMs.

226
00:09:32,220 --> 00:09:35,190
With LLM, it is the same
situation as with engineers, yes?

227
00:09:35,190 --> 00:09:37,020
So you have two different engineers

228
00:09:37,020 --> 00:09:38,550
with their background,
with their experience.

229
00:09:38,550 --> 00:09:42,000
And if you ask them to do
the same thing for you,

230
00:09:42,000 --> 00:09:43,590
one engineer can spend one hour,

231
00:09:43,590 --> 00:09:45,480
another engineer can spend two hours.

232
00:09:45,480 --> 00:09:47,370
You can get different results.

233
00:09:47,370 --> 00:09:48,203
They will work.

234
00:09:48,203 --> 00:09:49,920
They both will work these results,

235
00:09:49,920 --> 00:09:52,770
but one result will be more
cost effective and scalable,

236
00:09:52,770 --> 00:09:55,290
another one less secure, for example.

237
00:09:55,290 --> 00:09:56,730
And the same with LLM.

238
00:09:56,730 --> 00:09:58,680
That's why it's important
to choose the right LLM

239
00:09:58,680 --> 00:10:01,653
and provide this power
of choice to developers.

240
00:10:02,880 --> 00:10:05,640
So to highlight,

241
00:10:05,640 --> 00:10:08,640
it is yet another iteration
of platform engineering.

242
00:10:08,640 --> 00:10:11,700
So we just introduced
enhancement for the self-service

243
00:10:11,700 --> 00:10:15,270
that brings this AI
capabilities for the developers.

244
00:10:15,270 --> 00:10:17,040
This self-service,

245
00:10:17,040 --> 00:10:21,150
the idea of the self-service
is to introduce a nail gun.

246
00:10:21,150 --> 00:10:23,520
So if you're a constructor,
you build a new house,

247
00:10:23,520 --> 00:10:24,810
of course you can build new house

248
00:10:24,810 --> 00:10:27,300
with just nails and hammer,

249
00:10:27,300 --> 00:10:29,250
that will take like months,

250
00:10:29,250 --> 00:10:32,430
or you can take a nail gun
and use that for the purpose,

251
00:10:32,430 --> 00:10:34,080
for the same purpose of building new house

252
00:10:34,080 --> 00:10:36,210
within a week or less.

253
00:10:36,210 --> 00:10:38,010
The same with the platform engineering.

254
00:10:38,010 --> 00:10:40,050
And a couple of cases,

255
00:10:40,050 --> 00:10:43,200
so real cases before I jump to live demo.

256
00:10:43,200 --> 00:10:44,033
The first case,

257
00:10:44,033 --> 00:10:45,270
that's the case that we implemented

258
00:10:45,270 --> 00:10:46,560
for one of our customers.

259
00:10:46,560 --> 00:10:50,637
That's the case where we
orchestrated this deployment

260
00:10:50,637 --> 00:10:53,610
CI/CD flow with the help of AI,

261
00:10:53,610 --> 00:10:55,740
with the help of MCP servers.

262
00:10:55,740 --> 00:10:56,790
Pretty simple case.

263
00:10:56,790 --> 00:10:59,550
So developer in this case

264
00:10:59,550 --> 00:11:02,370
needs to know only about
programming language.

265
00:11:02,370 --> 00:11:03,960
So I know Java.

266
00:11:03,960 --> 00:11:06,780
I'm gonna run or create
my application in Java,

267
00:11:06,780 --> 00:11:07,620
and that's it.

268
00:11:07,620 --> 00:11:12,210
After that, I will put
commit to repository

269
00:11:12,210 --> 00:11:14,340
and everything else will be done by AI.

270
00:11:14,340 --> 00:11:16,350
So it will detect programming language,

271
00:11:16,350 --> 00:11:18,270
it will create a Dockerfile,

272
00:11:18,270 --> 00:11:20,190
build a container from that Dockerfile,

273
00:11:20,190 --> 00:11:22,440
deploy it to Amazon EKS

274
00:11:22,440 --> 00:11:25,170
using manifest generated by another agent

275
00:11:25,170 --> 00:11:27,690
and will return me a status of deployment.

276
00:11:27,690 --> 00:11:30,723
If everything is okay, I'll
get notification in Slack

277
00:11:30,723 --> 00:11:32,490
that it was successful deployment.

278
00:11:32,490 --> 00:11:34,020
If something is wrong,

279
00:11:34,020 --> 00:11:36,630
I will get notification that it is wrong

280
00:11:36,630 --> 00:11:40,290
and analysis from MCP
servers to CloudWatch and EKS

281
00:11:40,290 --> 00:11:44,373
about potential root cause for
problem with my deployment.

282
00:11:45,420 --> 00:11:46,905
The second use case is pretty similar.

283
00:11:46,905 --> 00:11:50,600
So we here you can see an
example of model that we used.

284
00:11:50,600 --> 00:11:53,781
We use Claude 3.7 Sonnet for that.

285
00:11:53,781 --> 00:11:56,550
The idea is that we build a tool

286
00:11:56,550 --> 00:11:59,190
for validation of
deployments to Kubernetes.

287
00:11:59,190 --> 00:12:01,590
It includes validation of
application components,

288
00:12:01,590 --> 00:12:04,004
it includes validation
of cluster components,

289
00:12:04,004 --> 00:12:05,640
Kubernetes cluster components.

290
00:12:05,640 --> 00:12:07,980
But by the end of that,

291
00:12:07,980 --> 00:12:11,280
customer receives validated
Kubernetes deployments.

292
00:12:11,280 --> 00:12:13,380
And after a production release,

293
00:12:13,380 --> 00:12:15,720
the customer can be sure
that everything was fine

294
00:12:15,720 --> 00:12:17,640
and no issues happened during deployment.

295
00:12:17,640 --> 00:12:19,620
Or, in case of any issues,

296
00:12:19,620 --> 00:12:21,360
that would be a rollback process

297
00:12:21,360 --> 00:12:24,270
with notification of
root cause for that fail.

298
00:12:24,270 --> 00:12:26,370
Well, it works really well
in production environments

299
00:12:26,370 --> 00:12:29,850
and we saved about three
months of time for the customer

300
00:12:29,850 --> 00:12:32,250
by implementing that instead
of rewriting the tool

301
00:12:32,250 --> 00:12:34,250
that they built originally using Golang.

302
00:12:35,130 --> 00:12:38,460
So again, to highlight, we're
not gonna build a product.

303
00:12:38,460 --> 00:12:40,110
It doesn't make any sense.

304
00:12:40,110 --> 00:12:41,640
We built framework.

305
00:12:41,640 --> 00:12:43,920
We don't have any software,

306
00:12:43,920 --> 00:12:46,650
proprietary software,
intellectual property here,

307
00:12:46,650 --> 00:12:47,940
but we do have a framework

308
00:12:47,940 --> 00:12:51,900
that helps to accelerate deployments,

309
00:12:51,900 --> 00:12:53,460
accelerate application development,

310
00:12:53,460 --> 00:12:55,620
application modernization, migration,

311
00:12:55,620 --> 00:12:57,720
increase development productivity.

312
00:12:57,720 --> 00:13:00,390
And this framework follows
all the best practices

313
00:13:00,390 --> 00:13:02,340
for the security, high reliability,

314
00:13:02,340 --> 00:13:03,930
scalability, cost efficiency.

315
00:13:03,930 --> 00:13:05,130
So it's very well aligned

316
00:13:05,130 --> 00:13:07,560
with the well-architected framework.

317
00:13:07,560 --> 00:13:10,170
Now it's time for the demo.

318
00:13:10,170 --> 00:13:14,100
So it's live demo, so apologize
if it's not gonna work,

319
00:13:14,100 --> 00:13:15,543
but I'll do my best.

320
00:13:16,590 --> 00:13:18,480
And this demo about migration,

321
00:13:18,480 --> 00:13:20,253
that's an example of self-service.

322
00:13:21,690 --> 00:13:24,630
Yes, that's an example of self-service

323
00:13:24,630 --> 00:13:26,100
that can be done for a migration.

324
00:13:26,100 --> 00:13:28,980
So let's imagine that I'm
running my data center.

325
00:13:28,980 --> 00:13:31,980
And in this data center, as you can see,

326
00:13:31,980 --> 00:13:33,510
it's connected through VPN.

327
00:13:33,510 --> 00:13:36,360
I have my internal IP address for that.

328
00:13:36,360 --> 00:13:40,233
I can create some stuff here,

329
00:13:41,790 --> 00:13:44,160
add to my to-do list, it'll be added.

330
00:13:44,160 --> 00:13:47,010
So it's well-functioning application.

331
00:13:47,010 --> 00:13:48,270
Pretty simple architecture.

332
00:13:48,270 --> 00:13:50,790
So I have virtual machine
with load balancer,

333
00:13:50,790 --> 00:13:52,590
two virtual machines with application,

334
00:13:52,590 --> 00:13:55,830
and one virtual machine
with a Postgres database.

335
00:13:55,830 --> 00:13:58,290
And I'm gonna move it to AWS Cloud.

336
00:13:58,290 --> 00:14:01,350
So I'm gonna use benefits
of AWS Transform service.

337
00:14:01,350 --> 00:14:03,556
That's a service that
allows me to run assessment,

338
00:14:03,556 --> 00:14:07,590
gets dependency mapping,
verify my service,

339
00:14:07,590 --> 00:14:10,470
runs through right-sizing exercise.

340
00:14:10,470 --> 00:14:13,350
But Transform works
well for lift and shift.

341
00:14:13,350 --> 00:14:14,670
Unfortunately lift and shift,

342
00:14:14,670 --> 00:14:16,830
that's a strategy for lazy migration.

343
00:14:16,830 --> 00:14:19,470
So that's the best strategy
to introduce technical debt,

344
00:14:19,470 --> 00:14:21,960
but not the best strategy
to run in the long term

345
00:14:21,960 --> 00:14:24,990
or in a long time.

346
00:14:24,990 --> 00:14:26,460
With that customers,

347
00:14:26,460 --> 00:14:29,280
they prefer to find a
way how to modernize,

348
00:14:29,280 --> 00:14:30,840
how to introduce replatforming

349
00:14:30,840 --> 00:14:33,030
and re-architecture at the beginning.

350
00:14:33,030 --> 00:14:38,030
So is it possible to perform
replatforming, re-architecture,

351
00:14:38,670 --> 00:14:40,140
with the cost of lift and shift?

352
00:14:40,140 --> 00:14:41,970
And with this demo, I will show you that,

353
00:14:41,970 --> 00:14:42,990
yes, it's possible.

354
00:14:42,990 --> 00:14:44,550
And that's because of the self-service

355
00:14:44,550 --> 00:14:47,970
that we provided to our developers.

356
00:14:47,970 --> 00:14:49,320
So again, on the left hand side,

357
00:14:49,320 --> 00:14:51,240
that's architecture that I have right now.

358
00:14:51,240 --> 00:14:52,230
On the right hand side,

359
00:14:52,230 --> 00:14:54,150
that's something that I'm gonna build.

360
00:14:54,150 --> 00:14:56,010
Load balancer instead of virtual machine.

361
00:14:56,010 --> 00:14:58,535
I'm gonna use managed service RDS

362
00:14:58,535 --> 00:15:03,450
with the primary and replica
set up, multi-AZ deployment,

363
00:15:03,450 --> 00:15:07,024
and my application
converted to containers,

364
00:15:07,024 --> 00:15:09,093
containerized and deployed to EKS.

365
00:15:09,960 --> 00:15:11,372
So application itself,

366
00:15:11,372 --> 00:15:14,550
that's Java application, as you can see.

367
00:15:14,550 --> 00:15:18,150
And what we built, we built this agent.

368
00:15:18,150 --> 00:15:20,070
This is a fancy web UI that I added

369
00:15:20,070 --> 00:15:21,150
for the purpose of this demo.

370
00:15:21,150 --> 00:15:22,590
But this is the agent

371
00:15:22,590 --> 00:15:25,080
that can be integrated
to ID of your choice.

372
00:15:25,080 --> 00:15:28,740
So Visual Code Studio, whatever
else that you're gonna use,

373
00:15:28,740 --> 00:15:30,840
it can be easily integrated.

374
00:15:30,840 --> 00:15:35,777
And what I'm gonna do, I'm
gonna show you that I have my,

375
00:15:35,777 --> 00:15:37,983
and that's what I'm talking about.

376
00:15:38,970 --> 00:15:42,840
So I have my servers,

377
00:15:42,840 --> 00:15:45,780
and I have my servers
discovered by Transform.

378
00:15:45,780 --> 00:15:47,640
Thanks god I saved this file earlier,

379
00:15:47,640 --> 00:15:50,580
so probably I'll skip this
part with AWS Console,

380
00:15:50,580 --> 00:15:53,190
so you should trust me.

381
00:15:53,190 --> 00:15:56,160
But that's a file generated
by AWS Transform agent.

382
00:15:56,160 --> 00:15:59,430
So with AWS Transform, what I did,

383
00:15:59,430 --> 00:16:01,230
I used Discovery tool.

384
00:16:01,230 --> 00:16:03,240
So we can read about this Discovery tool

385
00:16:03,240 --> 00:16:04,500
to get this CSV file.

386
00:16:04,500 --> 00:16:07,500
So this CSV file identified instances,

387
00:16:07,500 --> 00:16:09,960
their IP addresses, and roles,

388
00:16:09,960 --> 00:16:12,450
client database, client load balancer.

389
00:16:12,450 --> 00:16:14,733
According to that, according to that,

390
00:16:16,530 --> 00:16:19,710
again, I'm sorry, but I need
to log in again to my console

391
00:16:19,710 --> 00:16:21,510
so I'm not gonna show you visualization,

392
00:16:21,510 --> 00:16:24,993
but we can chat offline
after this presentation.

393
00:16:27,810 --> 00:16:30,210
Back to this tool that we built,

394
00:16:30,210 --> 00:16:32,670
this agent that we built
for the modernization.

395
00:16:32,670 --> 00:16:33,960
And all of what we need to do

396
00:16:33,960 --> 00:16:36,990
is just download our files,

397
00:16:36,990 --> 00:16:40,560
the CSV file and WAR artifacts
for this Java application

398
00:16:40,560 --> 00:16:41,940
to S3 bucket.

399
00:16:41,940 --> 00:16:43,260
That's pretty much it.

400
00:16:43,260 --> 00:16:47,676
Everything else is just to push
this button, Start Analysis.

401
00:16:47,676 --> 00:16:49,920
And under the hood,

402
00:16:49,920 --> 00:16:51,960
that's implementation
of this self-service.

403
00:16:51,960 --> 00:16:54,150
So particular version,

404
00:16:54,150 --> 00:16:57,000
Java Containerization
Agent of that self-service,

405
00:16:57,000 --> 00:16:59,760
the use case, developer
who is operating on-prem,

406
00:16:59,760 --> 00:17:01,230
but going to migrate to the cloud

407
00:17:01,230 --> 00:17:02,490
with zero knowledge of the cloud itself,

408
00:17:02,490 --> 00:17:04,950
with zero knowledge of cloud services.

409
00:17:04,950 --> 00:17:06,870
But I'm gonna migrate my application

410
00:17:06,870 --> 00:17:08,760
to reference architecture
with the containers,

411
00:17:08,760 --> 00:17:11,430
with the load balancer,
with RDS managed service,

412
00:17:11,430 --> 00:17:13,320
and I'm gonna use AI for that.

413
00:17:13,320 --> 00:17:15,990
I'm gonna use these
capabilities of self-service

414
00:17:15,990 --> 00:17:18,180
connected with AWS Transform.

415
00:17:18,180 --> 00:17:21,780
So we're gonna wait
for a couple of seconds

416
00:17:21,780 --> 00:17:23,403
just to have it fully generated.

417
00:17:26,541 --> 00:17:29,640
And I will show you what
this tool actually creates

418
00:17:29,640 --> 00:17:32,403
and how it can be used for the next steps.

419
00:17:34,590 --> 00:17:36,330
So meanwhile, just a reminder

420
00:17:36,330 --> 00:17:39,210
that we are going from
this legacy lift and shift

421
00:17:39,210 --> 00:17:40,833
to this modernized environment.

422
00:17:42,000 --> 00:17:43,623
Yeah, still no access.

423
00:17:45,900 --> 00:17:48,540
I actually like this fact of live demo,

424
00:17:48,540 --> 00:17:52,140
because it shows you
real time that is needed

425
00:17:52,140 --> 00:17:54,840
to create this conversion,
to generate all the files,

426
00:17:54,840 --> 00:17:57,510
generate all the manifest,
deployment Dockerfile,

427
00:17:57,510 --> 00:17:59,640
and actually have something
that can be easily deployed

428
00:17:59,640 --> 00:18:01,350
to a live environment.

429
00:18:01,350 --> 00:18:04,620
So technically, within this live demo,

430
00:18:04,620 --> 00:18:07,050
you are just watching the
process of real migration

431
00:18:07,050 --> 00:18:08,580
for this simple application.

432
00:18:08,580 --> 00:18:11,220
And in order to understand
what does it mean for you,

433
00:18:11,220 --> 00:18:12,053
for your cases,

434
00:18:12,053 --> 00:18:13,560
if you have large migration,

435
00:18:13,560 --> 00:18:15,240
planning to migrate 1000 VMs,

436
00:18:15,240 --> 00:18:17,130
all what you need to do
is just multiply that

437
00:18:17,130 --> 00:18:18,510
by 100 or 1000

438
00:18:18,510 --> 00:18:22,500
to understand how much time you
need for that modernization.

439
00:18:22,500 --> 00:18:24,210
Okay? So generating recommendations.

440
00:18:24,210 --> 00:18:26,223
I hope it will be here soon.

441
00:18:29,250 --> 00:18:31,320
Yeah, so meanwhile, again,

442
00:18:31,320 --> 00:18:33,480
unfortunately I cannot
show you what's going on,

443
00:18:33,480 --> 00:18:38,480
but AWS Transform has
integration with Migration Hub.

444
00:18:38,490 --> 00:18:39,600
It will be deprecated,

445
00:18:39,600 --> 00:18:41,430
service itself will be deprecated.

446
00:18:41,430 --> 00:18:43,560
However, right now through
this Migration Hub,

447
00:18:43,560 --> 00:18:46,140
you can see the list of servers,
you can see dependencies.

448
00:18:46,140 --> 00:18:48,360
So this network map dependencies,

449
00:18:48,360 --> 00:18:50,220
and this file that's actually exports

450
00:18:50,220 --> 00:18:52,530
from that Transform Discovery tool.

451
00:18:52,530 --> 00:18:55,110
So that's pretty much what you can use.

452
00:18:55,110 --> 00:18:58,200
And you can see in a Migration
Hub planning your migration.

453
00:18:58,200 --> 00:19:01,110
But again, reminder
that Transform supports

454
00:19:01,110 --> 00:19:03,990
just lift and shift
migration, nothing else.

455
00:19:03,990 --> 00:19:05,370
Okay, live demo.

456
00:19:05,370 --> 00:19:06,900
Yeah, running a bit late.

457
00:19:06,900 --> 00:19:09,570
Probably like people
using Bedrock proactively,

458
00:19:09,570 --> 00:19:11,640
because under the hoods,

459
00:19:11,640 --> 00:19:13,517
we are using Bedrock, we are using API.

460
00:19:13,517 --> 00:19:17,340
We are using connection to
Bedrock and predefined prompts.

461
00:19:17,340 --> 00:19:18,870
So we defined LLM.

462
00:19:18,870 --> 00:19:20,070
We build this custom agents,

463
00:19:20,070 --> 00:19:22,628
custom entities, and we predefined prompts

464
00:19:22,628 --> 00:19:27,030
that can be used in
order to run this request

465
00:19:27,030 --> 00:19:28,050
and create results

466
00:19:28,050 --> 00:19:30,513
that will help me to
modernize my application.

467
00:19:31,950 --> 00:19:33,030
Wrapping up.

468
00:19:33,030 --> 00:19:34,890
So by the end of this demo,

469
00:19:34,890 --> 00:19:36,990
I hope, once I'm done
with my presentation,

470
00:19:36,990 --> 00:19:38,490
we can chat offline.

471
00:19:38,490 --> 00:19:42,866
By the end of this demo, you
will have generated YAML file,

472
00:19:42,866 --> 00:19:43,699
Dockerfile,

473
00:19:43,699 --> 00:19:46,020
Dockerfile, that will help
you to deploy application,

474
00:19:46,020 --> 00:19:47,730
YAML file, that will help you

475
00:19:47,730 --> 00:19:51,840
to apply and deploy this
application to Kubernetes cluster.

476
00:19:51,840 --> 00:19:53,910
And you will have step-by-step instruction

477
00:19:53,910 --> 00:19:55,140
how to move your database.

478
00:19:55,140 --> 00:19:57,300
So snapshot, that should be taken first.

479
00:19:57,300 --> 00:19:58,650
Oh yeah, finally.

480
00:19:58,650 --> 00:20:00,210
So as I said, it took more time.

481
00:20:00,210 --> 00:20:02,040
So it's like results of the analysis

482
00:20:02,040 --> 00:20:04,613
with a old deployment
roadmap, preparation step,

483
00:20:04,613 --> 00:20:07,590
application containerization
step, Kubernetes deployments,

484
00:20:07,590 --> 00:20:10,050
load balancer configuration,
database migration,

485
00:20:10,050 --> 00:20:12,600
validation testing and details.

486
00:20:12,600 --> 00:20:15,600
So as you can see, Dockerfile
for your application,

487
00:20:15,600 --> 00:20:17,370
build command for that Dockerfile.

488
00:20:17,370 --> 00:20:20,070
Kubernetes deployments,
Kubernetes services,

489
00:20:20,070 --> 00:20:21,900
ConfigMap, variables,

490
00:20:21,900 --> 00:20:23,610
and configuration for other resources,

491
00:20:23,610 --> 00:20:26,220
including CDK code for infrastructure,

492
00:20:26,220 --> 00:20:27,413
the code for load balancer

493
00:20:27,413 --> 00:20:29,760
and CDK for database service.

494
00:20:29,760 --> 00:20:33,273
With that, coming back to my presentation,

495
00:20:34,710 --> 00:20:36,900
that was an example of self-service

496
00:20:36,900 --> 00:20:39,030
that we introduced for our customers.

497
00:20:39,030 --> 00:20:40,770
And for our developers,

498
00:20:40,770 --> 00:20:43,260
it accelerated a lot
our migration practices

499
00:20:43,260 --> 00:20:44,730
and modernization practices.

500
00:20:44,730 --> 00:20:45,780
So in average,

501
00:20:45,780 --> 00:20:48,450
we can see two to three times improvements

502
00:20:48,450 --> 00:20:51,690
in terms of time needed for
migration and modernization.

503
00:20:51,690 --> 00:20:55,000
And last but not least, it
is the way to do migration

504
00:20:56,040 --> 00:20:58,770
with replatforming and
re-architecture strategy

505
00:20:58,770 --> 00:20:59,880
instead of lift and shift

506
00:20:59,880 --> 00:21:02,040
and instead of introducing
this technical debt,

507
00:21:02,040 --> 00:21:04,260
and with a almost zero cloud knowledge,

508
00:21:04,260 --> 00:21:08,130
so the way of proper use or
use case for self-service.

509
00:21:08,130 --> 00:21:11,933
Thank you very much.
(audience applauding)

