# AWS re:Invent 2025 - AI M 380: 定制化Amazon Nova模型增强工具调用能力

## 会议概述

本次技术会议由AWS全球AI专家Hirsha Asnani和Nova团队高级解决方案架构师Anupam主讲，重点介绍了如何使用Amazon Nova模型进行定制化以增强工具调用能力。会议采用代码演示的形式，展示了从数据准备到模型部署的完整流程，包括监督微调(SFT)和强化微调(RFT)技术。演讲者通过一个法律助手代理的实际用例，演示了如何生成合成数据、训练模型并最终部署到Bedrock平台进行推理。

会议强调了模型定制化的重要性，特别是在工具调用场景中的应用。通过结合SageMaker的完全托管训练作业和Nova Forge的开放训练概念，用户可以获得更好的模型性能和更精确的工具选择能力。整个演示过程展现了从基础模型44%的准确率提升到RFT后90%准确率的显著改进。

## 详细时间线与关键要点

### 0:00-5:00 会议开场与议程介绍
- 介绍演讲者：Hirsha Asnani（AWS全球AI专家）和Anupam（Nova团队高级解决方案架构师）
- 概述会议议程：模型定制化概念、关键考虑因素、Nova最新发布功能、代码演示
- 强调这是一个教育性和互动性的代码演示会议

### 5:00-10:00 模型定制化技术谱系
- 介绍从轻量级到重量级的定制化技术：提示工程、RAG、后训练、预训练
- 解释权重修改与非权重修改方法的区别
- 介绍AWS提供的两种解决方案：SageMaker完全托管训练作业和SageMaker Hyperpod

### 10:00-15:00 Nova模型系列发布
- 第一代模型：Nova Micro、Light、Pro
- 第二代模型：Nova Light 2（改进的多语言能力、代理用例、编程能力）
- 早期访问模型：Nova 2 Pro、Nova Omni（多模态）
- Nova Forge功能：中间检查点、数据混合、强化学习、预设配方、负责任AI工具包

### 15:00-20:00 技术对比与用例介绍
- 对比1.0和2.0版本的不同微调技术：参数高效微调、全秩微调、DPO、PPO、RFT
- 介绍演示用例：证券协议法律助手代理
- 涵盖模块：合成数据生成、基础模型评估、监督微调、强化微调、部署

### 20:00-25:00 SFT和RFT技术原理
- SFT适配器训练：使用LoRA技术，仅训练1-2%的模型权重
- RFT架构：包含rollout模块、trainer模块和Lambda奖励函数
- 解释RFT的循环训练过程：生成预测→计算奖励→更新权重→重复循环

### 25:00-35:00 数据准备与合成数据生成
- 使用三个数据源：EDGAR文件、SEC正式语言规定、司法解释
- 合成数据生成工具包：数据分块、重叠字符处理、语义连续性维护
- 使用Nova Premium作为教师模型生成训练数据
- JSON格式数据结构：系统提示、用户查询、模型回答

### 35:00-40:00 监督微调(SFT)实现
- 使用SageMaker PyTorch估算器进行分布式训练
- LoRA适配器训练：参数高效，资源需求低
- 训练监控：损失曲线从70收敛到10
- 评估指标：工具选择准确率从44%提升到75%

### 40:00-45:00 强化微调(RFT)与部署
- RFT数据格式：系统、用户、参考答案
- Lambda奖励函数设计：避免偏见和可被利用的漏洞
- 训练结果：准确率从75%进一步提升到90%
- Bedrock部署：使用create_custom_model和create_custom_model_deployment API

### 45:00-46:30 总结与问答
- 展示最终推理效果：结构化输出和正确的工具调用
- 强调端到端流程的完整性
- 开放问答环节，讨论实际用例应用