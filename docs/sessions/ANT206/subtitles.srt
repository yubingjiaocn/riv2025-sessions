1
00:00:05,520 --> 00:00:06,353
- Hello, everyone.

2
00:00:06,353 --> 00:00:07,920
We're gonna get started.

3
00:00:07,920 --> 00:00:10,980
Quick reminder to please
put your headphones on.

4
00:00:10,980 --> 00:00:13,260
Hope everyone is having a great re:Invent.

5
00:00:13,260 --> 00:00:16,320
Welcome to What's new in Amazon Redshift

6
00:00:16,320 --> 00:00:18,030
and Amazon Athena session.

7
00:00:18,030 --> 00:00:19,560
My name is Imran Moin.

8
00:00:19,560 --> 00:00:21,570
I'm a senior manager of product management

9
00:00:21,570 --> 00:00:23,640
within the Amazon Redshift team,

10
00:00:23,640 --> 00:00:26,520
and I'm delighted to have
my co-speakers with me.

11
00:00:26,520 --> 00:00:28,830
Scott Rigney, who is a
principal product manager

12
00:00:28,830 --> 00:00:31,350
with Amazon Athena, and Sean McKibben,

13
00:00:31,350 --> 00:00:34,113
who is a principal software
engineer with Twilio.

14
00:00:36,930 --> 00:00:40,320
In this session today,
I'm gonna kick things off,

15
00:00:40,320 --> 00:00:43,200
talk about what's new in Amazon Redshift.

16
00:00:43,200 --> 00:00:44,670
Then I'm gonna hand it over to Sean,

17
00:00:44,670 --> 00:00:47,580
who will talk about how
Twilio is using Redshift

18
00:00:47,580 --> 00:00:51,090
and Athena to transform
billing and analytics at scale.

19
00:00:51,090 --> 00:00:53,160
And then finally, Scott
will come up on stage

20
00:00:53,160 --> 00:00:56,043
and talk about what's
new in Amazon Athena.

21
00:00:59,010 --> 00:01:02,190
When we look at customer
needs for analytics,

22
00:01:02,190 --> 00:01:06,630
we see that, broadly, things
fall into three main use cases.

23
00:01:06,630 --> 00:01:10,350
On one hand, you have
customers that want to store

24
00:01:10,350 --> 00:01:13,530
and analyze vast amounts
of structured data

25
00:01:13,530 --> 00:01:17,190
from their business systems,
run SQL queries on them,

26
00:01:17,190 --> 00:01:19,980
and get insights on that
data by visualizing it

27
00:01:19,980 --> 00:01:22,740
in BI dashboards like Tableau, QuickSight,

28
00:01:22,740 --> 00:01:24,540
Looker, et cetera.

29
00:01:24,540 --> 00:01:28,710
These use cases are well suited
for a cloud data warehouse.

30
00:01:28,710 --> 00:01:30,780
On the other hand, we have customers

31
00:01:30,780 --> 00:01:34,050
that have vast amount
of raw, unstructured,

32
00:01:34,050 --> 00:01:36,030
or semi-structured data,

33
00:01:36,030 --> 00:01:39,150
and this data is often
used for advanced analytics

34
00:01:39,150 --> 00:01:41,460
or machine learning types of use cases.

35
00:01:41,460 --> 00:01:45,990
These use cases are well
suited for a cloud data lake.

36
00:01:45,990 --> 00:01:48,210
And then you have customers that want

37
00:01:48,210 --> 00:01:51,780
to bring data warehouse
and data lake together.

38
00:01:51,780 --> 00:01:54,540
They want to combine the
structured business data

39
00:01:54,540 --> 00:01:57,960
with the unstructured
or semi-structured data,

40
00:01:57,960 --> 00:02:00,000
so that their teams can work off

41
00:02:00,000 --> 00:02:01,980
of a unified data foundation

42
00:02:01,980 --> 00:02:04,170
and they're able to get richer insights

43
00:02:04,170 --> 00:02:06,720
into all of their available data.

44
00:02:06,720 --> 00:02:11,010
The industry typically refers
to this as a lakehouse.

45
00:02:11,010 --> 00:02:14,310
At AWS, we have built
a portfolio of services

46
00:02:14,310 --> 00:02:16,230
that are geared towards meeting

47
00:02:16,230 --> 00:02:18,420
all these different use cases.

48
00:02:18,420 --> 00:02:23,070
Amazon Redshift is our
purpose-built cloud data warehouse

49
00:02:23,070 --> 00:02:26,760
that provides high
performance SQL analytics

50
00:02:26,760 --> 00:02:28,113
on your structured data.

51
00:02:29,208 --> 00:02:32,190
Amazon Athena is a serverless way

52
00:02:32,190 --> 00:02:34,950
for customers to query their unstructured

53
00:02:34,950 --> 00:02:37,560
or semi-structured data stored in S3,

54
00:02:37,560 --> 00:02:39,753
using a familiar SQL interface.

55
00:02:41,040 --> 00:02:44,100
And then Amazon SageMaker
brings it all together,

56
00:02:44,100 --> 00:02:47,310
where you can analyze
your data warehouse data

57
00:02:47,310 --> 00:02:50,640
and data lake data together in one place,

58
00:02:50,640 --> 00:02:53,940
so that your teams can
get richer insights,

59
00:02:53,940 --> 00:02:55,620
mostly for advanced analytics

60
00:02:55,620 --> 00:02:57,660
and machine learning types of use cases,

61
00:02:57,660 --> 00:02:59,310
and all your teams can work off

62
00:02:59,310 --> 00:03:01,023
of a unified data foundation.

63
00:03:03,930 --> 00:03:05,823
Let's begin with Amazon Redshift.

64
00:03:08,250 --> 00:03:10,830
Amazon Redshift has had
a history of innovation

65
00:03:10,830 --> 00:03:13,500
over the last 12 or 13 years.

66
00:03:13,500 --> 00:03:16,590
When we first launched Redshift in 2013,

67
00:03:16,590 --> 00:03:20,760
it was a first ever cloud data warehouse,

68
00:03:20,760 --> 00:03:25,500
providing massively parallel
processing, columnar storage,

69
00:03:25,500 --> 00:03:28,830
and a familiar SQL interface
at a fraction of the cost

70
00:03:28,830 --> 00:03:31,023
of your traditional on-premises system.

71
00:03:32,340 --> 00:03:35,760
When we launched Redshift
Spectrum in 2017,

72
00:03:35,760 --> 00:03:38,640
customers had a way to
query their data lake data

73
00:03:38,640 --> 00:03:42,240
stored in S3, bridging the
worlds of data warehouse

74
00:03:42,240 --> 00:03:43,473
and data lake together.

75
00:03:44,340 --> 00:03:48,180
More recently in 2022, we
launched support for Zero-ETL,

76
00:03:48,180 --> 00:03:49,740
where you could bring your data

77
00:03:49,740 --> 00:03:51,570
from your operational databases

78
00:03:51,570 --> 00:03:54,930
and business systems
directly into Redshift

79
00:03:54,930 --> 00:03:56,010
without having to worry

80
00:03:56,010 --> 00:03:58,770
about managing complex ingestion pipelines

81
00:03:58,770 --> 00:04:01,020
and data processing workloads.

82
00:04:01,020 --> 00:04:03,150
Last year, we launched AI-driven scaling

83
00:04:03,150 --> 00:04:06,210
and optimization for Redshift Serverless,

84
00:04:06,210 --> 00:04:09,420
where Redshift would
automatically scale up

85
00:04:09,420 --> 00:04:12,690
your compute clusters if
there is a certain spike

86
00:04:12,690 --> 00:04:14,640
in demand or query volumes,

87
00:04:14,640 --> 00:04:17,040
so that you continue to
get the best performance

88
00:04:17,040 --> 00:04:19,743
out of your underlying
Redshift infrastructure.

89
00:04:20,970 --> 00:04:24,180
Along the way, Redshift
has also invested heavily

90
00:04:24,180 --> 00:04:28,320
in optimizing the
performance of your queries,

91
00:04:28,320 --> 00:04:32,250
which is why Redshift has 2.2 times

92
00:04:32,250 --> 00:04:35,820
better price performance
than its nearest competitors,

93
00:04:35,820 --> 00:04:39,210
enabling you to get faster
insights on your data

94
00:04:39,210 --> 00:04:40,563
at a fraction of the cost.

95
00:04:43,650 --> 00:04:46,590
Each of these first
two market capabilities

96
00:04:46,590 --> 00:04:49,020
demonstrate that Redshift
continues to evolve

97
00:04:49,020 --> 00:04:52,560
with the changing customer
needs, which is why, today,

98
00:04:52,560 --> 00:04:55,890
it is used by tens of
thousands of customers globally

99
00:04:55,890 --> 00:04:58,500
for their business critical applications.

100
00:04:58,500 --> 00:05:00,990
It processes billions of queries

101
00:05:00,990 --> 00:05:03,723
and exabytes of data every single day.

102
00:05:06,061 --> 00:05:10,290
As we look at 2025, Amazon
Redshift has delivered a number

103
00:05:10,290 --> 00:05:12,390
of key features and innovations

104
00:05:12,390 --> 00:05:14,070
that can be broadly categorized

105
00:05:14,070 --> 00:05:16,830
into three broad investment pillars.

106
00:05:16,830 --> 00:05:20,460
The first one is cloud data
warehouse fundamentals.

107
00:05:20,460 --> 00:05:22,950
Second one is distributed warehouse,

108
00:05:22,950 --> 00:05:25,500
and the third one is
Apache Iceberg support.

109
00:05:25,500 --> 00:05:26,790
And I'm gonna talk about each

110
00:05:26,790 --> 00:05:29,613
of these three investment areas.

111
00:05:31,373 --> 00:05:35,040
Cloud data warehouse
fundamentals remain at the core

112
00:05:35,040 --> 00:05:37,140
of Amazon Redshift innovation

113
00:05:37,140 --> 00:05:40,560
because they underpin
every customer's trust

114
00:05:40,560 --> 00:05:42,063
and success in the platform.

115
00:05:42,960 --> 00:05:46,740
This includes areas such
as security, performance,

116
00:05:46,740 --> 00:05:49,110
global region availability, et cetera.

117
00:05:49,110 --> 00:05:52,140
Areas that are crucial for
any cloud data warehouse

118
00:05:52,140 --> 00:05:52,973
to work well.

119
00:05:55,230 --> 00:05:56,680
Let's start with performance.

120
00:05:57,570 --> 00:06:00,733
Historically, Amazon
Redshift has invested heavily

121
00:06:00,733 --> 00:06:03,510
in query performance, delivering up

122
00:06:03,510 --> 00:06:05,850
to 2.2x better price performance

123
00:06:05,850 --> 00:06:07,800
than its nearest competitor.

124
00:06:07,800 --> 00:06:11,700
In fact, for specific workloads
such as BI dashboarding,

125
00:06:11,700 --> 00:06:14,070
Redshift actually offers seven times

126
00:06:14,070 --> 00:06:17,370
better price performance
than its nearest competitors,

127
00:06:17,370 --> 00:06:19,950
which is one of the
hallmarks of its leadership

128
00:06:19,950 --> 00:06:21,333
in cloud data warehousing.

129
00:06:22,200 --> 00:06:25,050
This performance is an area
where we continue to invest

130
00:06:25,050 --> 00:06:26,670
and we are not done yet.

131
00:06:26,670 --> 00:06:28,170
You can expect further improvements

132
00:06:28,170 --> 00:06:30,483
from Redshift in 2026 and beyond.

133
00:06:31,530 --> 00:06:35,310
Let me dive into some specific
areas under performance.

134
00:06:35,310 --> 00:06:37,110
First one is materialized views.

135
00:06:37,110 --> 00:06:39,870
Materialized view is an
area of ongoing innovation

136
00:06:39,870 --> 00:06:43,890
for Redshift, where we provide
you pre-computed results,

137
00:06:43,890 --> 00:06:46,321
query results stored in a database

138
00:06:46,321 --> 00:06:49,680
designed to provide you
the best performance

139
00:06:49,680 --> 00:06:52,410
for your commonly used queries.

140
00:06:52,410 --> 00:06:54,270
This year, we have delivered a number

141
00:06:54,270 --> 00:06:56,910
of key capabilities for materialized view.

142
00:06:56,910 --> 00:07:00,810
Starting with in June, we
delivered incremental auto refresh

143
00:07:00,810 --> 00:07:04,710
of materialized views
triggered by DML commits,

144
00:07:04,710 --> 00:07:06,930
where anytime there is a change

145
00:07:06,930 --> 00:07:09,270
in the underlying base tables,

146
00:07:09,270 --> 00:07:12,120
Redshift automatically triggers a refresh

147
00:07:12,120 --> 00:07:13,890
of materialized view.

148
00:07:13,890 --> 00:07:17,790
This provides you with near
real-time updates on your data

149
00:07:17,790 --> 00:07:20,670
without having to go
through manual tuning.

150
00:07:20,670 --> 00:07:23,820
In July, we also release
cascading refreshes

151
00:07:23,820 --> 00:07:25,860
across nested materialized views,

152
00:07:25,860 --> 00:07:27,360
so that you don't have to go

153
00:07:27,360 --> 00:07:30,360
through complete refreshes
every single time.

154
00:07:30,360 --> 00:07:33,360
And in September, we
delivered materialized views

155
00:07:33,360 --> 00:07:38,070
that are built on top of
materialized views on shared data,

156
00:07:38,070 --> 00:07:41,850
providing you the ability to optimize

157
00:07:41,850 --> 00:07:43,620
and pre-compute queries

158
00:07:43,620 --> 00:07:46,293
on shared data sets between clusters.

159
00:07:48,270 --> 00:07:51,592
Each of these advanced
materialized view capabilities

160
00:07:51,592 --> 00:07:55,170
are designed to provide you
with near real time access

161
00:07:55,170 --> 00:07:58,893
and insights into your data
with minimal manual effort.

162
00:08:02,130 --> 00:08:05,460
I'm also happy to share
that in September this year,

163
00:08:05,460 --> 00:08:07,050
we announced general availability

164
00:08:07,050 --> 00:08:10,440
of a feature called
multi-dimensional data layouts,

165
00:08:10,440 --> 00:08:14,640
or MDDL, which is a query
aware sorting mechanisms,

166
00:08:14,640 --> 00:08:17,910
where Redshift automatically
sorts your tables

167
00:08:17,910 --> 00:08:21,543
based on your query
patterns and query volumes.

168
00:08:24,240 --> 00:08:26,670
Unlike fixed column sorting,

169
00:08:26,670 --> 00:08:31,380
MDDL provides up to 10x
better price performance

170
00:08:31,380 --> 00:08:34,620
for selective repetitive queries,

171
00:08:34,620 --> 00:08:37,803
and it far outperforms tables

172
00:08:37,803 --> 00:08:41,013
that are sorted based on single columns.

173
00:08:43,020 --> 00:08:46,200
What's even better is that
once Redshift determines

174
00:08:46,200 --> 00:08:48,300
the right layout for your table,

175
00:08:48,300 --> 00:08:50,400
it automatically applies that layout

176
00:08:50,400 --> 00:08:53,520
using automatic table optimization,

177
00:08:53,520 --> 00:08:54,960
thereby minimizing the amount

178
00:08:54,960 --> 00:08:57,420
of manual tuning you
need to do on your tables

179
00:08:57,420 --> 00:08:58,743
on an ongoing basis.

180
00:09:03,150 --> 00:09:07,260
Security has always been
job zero for Amazon.

181
00:09:07,260 --> 00:09:09,510
It is our highest priority

182
00:09:09,510 --> 00:09:12,690
and it is the foundation
of our customer trust.

183
00:09:12,690 --> 00:09:17,370
This year in January, we
enhanced the security defaults

184
00:09:17,370 --> 00:09:19,560
of Amazon Redshift.

185
00:09:19,560 --> 00:09:24,300
Now your Redshift clusters
are private by default.

186
00:09:24,300 --> 00:09:27,990
They are fully encrypted,
and they require SSL

187
00:09:27,990 --> 00:09:31,143
for every client connections
coming into Redshift.

188
00:09:32,880 --> 00:09:36,240
With these new settings,
it's easy for you to adhere

189
00:09:36,240 --> 00:09:38,814
to the best practices in data protection,

190
00:09:38,814 --> 00:09:42,000
and also minimizes the
chances of misconfiguration

191
00:09:42,000 --> 00:09:43,563
that might happen on your part.

192
00:09:47,010 --> 00:09:49,590
Let's take a look at the
second big investment pillar

193
00:09:49,590 --> 00:09:53,703
for Redshift in 2025, which
is distributed warehouse.

194
00:09:55,800 --> 00:09:58,050
As big enterprise customers continue

195
00:09:58,050 --> 00:09:59,850
to scale their Redshift environment,

196
00:10:00,750 --> 00:10:02,850
we had to reimagine what the future

197
00:10:02,850 --> 00:10:05,550
of cloud data warehouses would look like.

198
00:10:05,550 --> 00:10:07,620
Last year, we outlined a vision,

199
00:10:07,620 --> 00:10:11,280
where customers would have
different analytics workloads,

200
00:10:11,280 --> 00:10:16,280
such as BI dashboarding,
ETL/ELT ingestion,

201
00:10:16,710 --> 00:10:18,630
real-time analytics, et cetera,

202
00:10:18,630 --> 00:10:19,860
where customers would run all

203
00:10:19,860 --> 00:10:22,200
of these different analytics workloads

204
00:10:22,200 --> 00:10:25,110
on their own dedicated clusters optimized

205
00:10:25,110 --> 00:10:28,743
to provide the best performance
for each of those workloads.

206
00:10:30,840 --> 00:10:33,630
All of these clusters also
were designed in such a way

207
00:10:33,630 --> 00:10:36,210
that they can share one common data set.

208
00:10:36,210 --> 00:10:39,303
They could either read or
write to a single copy of data.

209
00:10:40,140 --> 00:10:43,830
This year, we have enhanced
this architecture even more

210
00:10:43,830 --> 00:10:46,833
and added a bunch of new
features and capabilities.

211
00:10:48,780 --> 00:10:51,900
This architecture is available
in two different flavors.

212
00:10:51,900 --> 00:10:53,940
First one is hub and spoke,

213
00:10:53,940 --> 00:10:58,170
where different workloads run
on their dedicated clusters,

214
00:10:58,170 --> 00:11:01,410
but they read and write
from a single copy of data

215
00:11:01,410 --> 00:11:05,190
that is tied to a main
cluster or producer cluster.

216
00:11:05,190 --> 00:11:08,250
The second architecture is
a data mesh architecture,

217
00:11:08,250 --> 00:11:11,760
where each cluster has
its own copy of data,

218
00:11:11,760 --> 00:11:14,130
but it securely shares that data

219
00:11:14,130 --> 00:11:15,720
with all other remote clusters

220
00:11:15,720 --> 00:11:17,523
that might need access to that data.

221
00:11:18,810 --> 00:11:21,430
This distributed warehouse architecture

222
00:11:21,430 --> 00:11:24,090
is designed to provide best performance

223
00:11:24,090 --> 00:11:26,520
for each of your analytics workload.

224
00:11:26,520 --> 00:11:29,190
It provides workload isolation,

225
00:11:29,190 --> 00:11:32,940
and it also provides more
granular cost visibility

226
00:11:32,940 --> 00:11:36,600
and chargeback capabilities
so that enterprise customers

227
00:11:36,600 --> 00:11:40,245
that have different business
units or different teams

228
00:11:40,245 --> 00:11:44,073
can deploy this in a
secure and scalable manner.

229
00:11:47,970 --> 00:11:52,260
Next, I'll talk about
Amazon Redshift Serverless.

230
00:11:52,260 --> 00:11:55,260
Ever since we launched Serverless in 2021,

231
00:11:55,260 --> 00:11:59,760
we have seen many enterprise
customers adopt serverless

232
00:11:59,760 --> 00:12:02,040
for their business critical needs.

233
00:12:02,040 --> 00:12:04,770
This year, we have made
Redshift Serverless

234
00:12:04,770 --> 00:12:09,453
more cost effective, more
flexible, and more easy to use.

235
00:12:10,740 --> 00:12:14,610
In March, we launched
support for trailing tracks,

236
00:12:14,610 --> 00:12:17,520
where customers that
required more stability

237
00:12:17,520 --> 00:12:20,220
and more time to test new releases

238
00:12:20,220 --> 00:12:24,420
before they are deployed in
production are able to do that.

239
00:12:24,420 --> 00:12:27,360
All you have to do is simply
set your serverless clusters

240
00:12:27,360 --> 00:12:29,280
to be on trailing track,

241
00:12:29,280 --> 00:12:31,200
take your time testing those features out,

242
00:12:31,200 --> 00:12:32,280
and when you are ready,

243
00:12:32,280 --> 00:12:34,780
you can deploy those new
versions into production.

244
00:12:36,840 --> 00:12:40,440
We knew that a lot of the
government and federal agencies

245
00:12:40,440 --> 00:12:44,010
required high degree of security
and compliance standards,

246
00:12:44,010 --> 00:12:47,160
so I'm very happy to share
that in May this year,

247
00:12:47,160 --> 00:12:50,580
Redshift Serverless achieved
FedRAMP authorization,

248
00:12:50,580 --> 00:12:54,480
so that your federal
contractors, government agencies,

249
00:12:54,480 --> 00:12:57,570
and regulated industry customers

250
00:12:57,570 --> 00:12:59,460
can now deploy Redshift Serverless

251
00:12:59,460 --> 00:13:01,893
in their production
environment with confidence.

252
00:13:02,970 --> 00:13:07,970
In June this year, we deployed
support for four RPUs,

253
00:13:08,970 --> 00:13:11,100
which is a very small form factor

254
00:13:11,100 --> 00:13:13,920
down from eight RPUs,
which we used to have.

255
00:13:13,920 --> 00:13:16,530
So customers that have smaller workloads

256
00:13:16,530 --> 00:13:19,890
can easily get started
with Redshift Serverless

257
00:13:19,890 --> 00:13:23,460
with lower cost, and
still get the benefits

258
00:13:23,460 --> 00:13:24,873
that serverless offers.

259
00:13:26,370 --> 00:13:30,330
Four RPU costs as little
as $1.50 per hour,

260
00:13:30,330 --> 00:13:33,693
so it's easy for you to get
started for smaller workloads.

261
00:13:34,740 --> 00:13:38,040
And then in July this year,
we also made serverless

262
00:13:38,040 --> 00:13:39,870
easy to use in environments

263
00:13:39,870 --> 00:13:42,150
that have constrained networking.

264
00:13:42,150 --> 00:13:44,730
So Serverless now requires
only three IP addresses

265
00:13:44,730 --> 00:13:46,890
to get started and you can deploy it

266
00:13:46,890 --> 00:13:48,960
with only two availability zones.

267
00:13:48,960 --> 00:13:51,810
It is fully compatible with IPv6.

268
00:13:51,810 --> 00:13:53,940
So if you have regulated

269
00:13:53,940 --> 00:13:55,800
or constrained networking environments,

270
00:13:55,800 --> 00:13:58,250
it's easy for you to get
started with Serverless.

271
00:14:00,540 --> 00:14:02,940
Now, while Redshift Serverless
has seen tremendous growth

272
00:14:02,940 --> 00:14:05,040
since we launched it in 2021,

273
00:14:05,040 --> 00:14:08,430
we heard from a lot of our
large enterprise customers

274
00:14:08,430 --> 00:14:10,590
that had predictable usage.

275
00:14:10,590 --> 00:14:13,800
They were asking us a way to get discounts

276
00:14:13,800 --> 00:14:16,680
and lower their overall cost of Redshift.

277
00:14:16,680 --> 00:14:19,650
So I'm very happy to share
that in April this year,

278
00:14:19,650 --> 00:14:23,310
we launched support for Redshift
Serverless reservations,

279
00:14:23,310 --> 00:14:28,310
where you can commit to a
certain number of RPUs every year

280
00:14:29,610 --> 00:14:33,720
and get up to 24% discount
off of your list price

281
00:14:33,720 --> 00:14:35,163
for Redshift Serverless.

282
00:14:36,360 --> 00:14:38,640
This option is available
in two different flavors.

283
00:14:38,640 --> 00:14:41,523
You can pay all upfront or
you can pay partial upfronts.

284
00:14:42,360 --> 00:14:44,610
What's even better is
that these reservations

285
00:14:44,610 --> 00:14:46,800
are applied at the payer account level

286
00:14:46,800 --> 00:14:49,170
and can be shared across your multiple

287
00:14:49,170 --> 00:14:50,970
different AWS accounts.

288
00:14:50,970 --> 00:14:53,560
Thereby, giving you a lot of flexibility

289
00:14:55,983 --> 00:14:59,160
if you're running a large
enterprise architecture,

290
00:14:59,160 --> 00:15:00,480
where you have different business unit

291
00:15:00,480 --> 00:15:02,850
or different teams that
might want to benefit

292
00:15:02,850 --> 00:15:04,593
from the serverless reservations.

293
00:15:08,790 --> 00:15:12,060
Centralized identity
and unified governance,

294
00:15:12,060 --> 00:15:13,830
we knew as customers continue

295
00:15:13,830 --> 00:15:15,570
to scale the Redshift environment,

296
00:15:15,570 --> 00:15:17,880
centralized identity
and unified governance

297
00:15:17,880 --> 00:15:19,200
are very important.

298
00:15:19,200 --> 00:15:22,260
So I'm very happy to share
that only a few days back,

299
00:15:22,260 --> 00:15:25,200
Redshift launched support
for centralized identity

300
00:15:25,200 --> 00:15:27,690
and unified governance by integrating

301
00:15:27,690 --> 00:15:31,953
with AWS Lake Formation
and AWS Glue Data Catalog.

302
00:15:32,790 --> 00:15:37,200
Now, you can log into any Redshift cluster

303
00:15:37,200 --> 00:15:40,260
using your IAM Identity
Center credentials,

304
00:15:40,260 --> 00:15:42,810
or simply your IAM credentials,

305
00:15:42,810 --> 00:15:45,600
defined fine grain access
control permissions,

306
00:15:45,600 --> 00:15:49,650
like role level security,
column level permissions,

307
00:15:49,650 --> 00:15:51,210
or dynamic data masking,

308
00:15:51,210 --> 00:15:53,700
and have those permissions
apply to any cluster

309
00:15:53,700 --> 00:15:57,153
or any warehouse across your
entire Redshift environment.

310
00:15:58,290 --> 00:15:59,553
With these features,

311
00:16:01,890 --> 00:16:04,620
your users can log into
any Redshift cluster,

312
00:16:04,620 --> 00:16:07,020
define permissions,
and have the confidence

313
00:16:07,020 --> 00:16:09,030
that those permissions
and identities would apply

314
00:16:09,030 --> 00:16:11,710
to any cluster and any warehouse

315
00:16:11,710 --> 00:16:13,833
across your Redshift environment.

316
00:16:18,180 --> 00:16:19,920
Another area of investment for us

317
00:16:19,920 --> 00:16:23,190
as we build out the vision
for distributed warehouse

318
00:16:23,190 --> 00:16:25,560
was concurrency scaling.

319
00:16:25,560 --> 00:16:28,590
Ever since we launched
concurrency scaling in 2019,

320
00:16:28,590 --> 00:16:31,230
customers told us how
much they value the fact

321
00:16:31,230 --> 00:16:33,780
that their Redshift
clusters can automatically

322
00:16:33,780 --> 00:16:35,580
and dynamically scale up

323
00:16:35,580 --> 00:16:39,270
anytime there is a spike
in query volume or demand.

324
00:16:39,270 --> 00:16:43,230
This year, we have enhanced
the concurrency scaling feature

325
00:16:43,230 --> 00:16:46,808
so that all of your
ingestion, transformation,

326
00:16:46,808 --> 00:16:50,220
and consumption workloads can easily burst

327
00:16:50,220 --> 00:16:53,700
across different clusters
using concurrency scaling.

328
00:16:53,700 --> 00:16:55,710
I'm happy to share that very soon,

329
00:16:55,710 --> 00:16:58,410
you will have support for
additional workload types

330
00:16:58,410 --> 00:17:03,410
on concurrency scaling,
such as autocopy from S3,

331
00:17:03,480 --> 00:17:08,480
Zero-ETL, materialized view
creation, spectrum queries,

332
00:17:09,090 --> 00:17:11,880
refreshes of streaming materialized views,

333
00:17:11,880 --> 00:17:14,220
all of these different workloads can scale

334
00:17:14,220 --> 00:17:16,830
across clusters using concurrency scaling.

335
00:17:16,830 --> 00:17:20,280
In fact, these features are
already available to you

336
00:17:20,280 --> 00:17:22,560
in all the regions except IAD,

337
00:17:22,560 --> 00:17:25,860
and we are rolling our support
for IAD very, very soon here.

338
00:17:25,860 --> 00:17:28,810
After which, we will make public
announcements around this.

339
00:17:30,360 --> 00:17:32,040
Related to concurrency scaling,

340
00:17:32,040 --> 00:17:34,380
also happy to share that
in October this year,

341
00:17:34,380 --> 00:17:38,010
we launched support for
DML and DDL commands.

342
00:17:38,010 --> 00:17:41,130
So you can now use create table like

343
00:17:41,130 --> 00:17:44,760
and alter table commands on
concurrency scaling clusters,

344
00:17:44,760 --> 00:17:47,220
which makes it very easy for customers

345
00:17:47,220 --> 00:17:49,380
to do complex table operations

346
00:17:49,380 --> 00:17:52,593
and manage ingestion
pipelines across clusters.

347
00:17:55,950 --> 00:17:59,790
The third big pillar
for Redshift this year

348
00:17:59,790 --> 00:18:02,583
has been around Iceberg Apache support.

349
00:18:05,010 --> 00:18:06,690
We are seeing increasing number

350
00:18:06,690 --> 00:18:10,020
of analytic customers adopt Apache Iceberg

351
00:18:10,020 --> 00:18:12,330
as their open table format

352
00:18:12,330 --> 00:18:15,780
as it provides a high
performance, open source solution

353
00:18:15,780 --> 00:18:18,543
for customers to build their
analytics architecture.

354
00:18:19,410 --> 00:18:23,190
Across AWS, we are fully
behind Apache Iceberg

355
00:18:23,190 --> 00:18:25,590
and we are adding support
for Apache Iceberg

356
00:18:25,590 --> 00:18:28,200
across a variety of different data

357
00:18:28,200 --> 00:18:30,513
and analytics services at AWS.

358
00:18:31,350 --> 00:18:34,740
In Redshift, we have also
added support for Iceberg,

359
00:18:34,740 --> 00:18:38,070
and I'm very happy to
share that Redshift now

360
00:18:38,070 --> 00:18:40,860
has support for Iceberg table rights,

361
00:18:40,860 --> 00:18:43,860
where you can create and
insert Iceberg tables

362
00:18:43,860 --> 00:18:45,603
directly from within Redshift.

363
00:18:47,100 --> 00:18:48,990
And last year, if you remember,

364
00:18:48,990 --> 00:18:51,450
we added support for
Iceberg read capability.

365
00:18:51,450 --> 00:18:54,060
So building up on that,
now Redshift has support

366
00:18:54,060 --> 00:18:57,240
for both Iceberg read
and write capabilities,

367
00:18:57,240 --> 00:18:59,430
giving customers maximum flexibility

368
00:18:59,430 --> 00:19:03,093
to build their analytics
architectures on top of Iceberg.

369
00:19:04,350 --> 00:19:06,720
We have also made a number of enhancements

370
00:19:06,720 --> 00:19:08,820
in terms of improving the performance

371
00:19:08,820 --> 00:19:11,820
of data lake queries from Redshift,

372
00:19:11,820 --> 00:19:14,760
and I'm happy to share
that based on a series

373
00:19:14,760 --> 00:19:17,070
of query optimization techniques,

374
00:19:17,070 --> 00:19:21,060
Redshift now delivers two
times better price performance

375
00:19:21,060 --> 00:19:23,680
on data lake queries that are run

376
00:19:25,808 --> 00:19:28,443
on data lake tables
built on top of Iceberg.

377
00:19:29,910 --> 00:19:31,170
The last thing I'll mention on this

378
00:19:31,170 --> 00:19:33,690
is that we have added
support for auto refresh

379
00:19:33,690 --> 00:19:38,430
of materialized views built
on top of Iceberg data.

380
00:19:38,430 --> 00:19:41,460
The way this feature works
is that it periodically pulls

381
00:19:41,460 --> 00:19:45,690
Iceberg buckets to see,
it pulls S3 buckets to see

382
00:19:45,690 --> 00:19:47,760
if there are any new Iceberg files.

383
00:19:47,760 --> 00:19:50,460
And anytime it detects a new Iceberg file,

384
00:19:50,460 --> 00:19:54,060
it auto triggers a refresh
of materialized views.

385
00:19:54,060 --> 00:19:57,840
The benefit of this is that
U.S. customers get access

386
00:19:57,840 --> 00:19:59,340
to near real time updates,

387
00:19:59,340 --> 00:20:01,470
near real time insights into your data

388
00:20:01,470 --> 00:20:04,533
without having to do this
work manually yourself.

389
00:20:07,800 --> 00:20:11,130
So, so far, we have
discussed why it is important

390
00:20:11,130 --> 00:20:14,850
for customers to have a platform

391
00:20:14,850 --> 00:20:16,230
that has very, very strong

392
00:20:16,230 --> 00:20:18,060
cloud data warehouse fundamentals, right?

393
00:20:18,060 --> 00:20:21,780
We've talked about performance,
we talked about security,

394
00:20:21,780 --> 00:20:24,300
we talked about distributed warehouses,

395
00:20:24,300 --> 00:20:27,150
we talked about global region
availability, et cetera.

396
00:20:27,150 --> 00:20:29,520
But what about the end customer use cases?

397
00:20:29,520 --> 00:20:31,150
So when I look at the landscape

398
00:20:32,094 --> 00:20:35,580
of what customers are
doing with Amazon Redshift,

399
00:20:35,580 --> 00:20:40,580
I see that these use cases
fall into a variety of buckets.

400
00:20:40,710 --> 00:20:43,217
If you look at the left-hand
side of this slide,

401
00:20:43,217 --> 00:20:45,900
Redshift has historically been very strong

402
00:20:45,900 --> 00:20:47,580
on batch analytics.

403
00:20:47,580 --> 00:20:50,340
So when customers want to
run end-of-day sales report

404
00:20:50,340 --> 00:20:53,670
or end-of-quarter
regulatory reporting, right?

405
00:20:53,670 --> 00:20:55,650
Lot of customers are
using Redshift for that

406
00:20:55,650 --> 00:20:58,950
and it's very, very sort of tailored

407
00:20:58,950 --> 00:21:00,720
for that particular use case.

408
00:21:00,720 --> 00:21:02,310
Another strong use case we see

409
00:21:02,310 --> 00:21:05,640
customers using Redshift
for is BI dashboarding,

410
00:21:05,640 --> 00:21:09,060
where they want to visualize
their structured data

411
00:21:09,060 --> 00:21:13,260
inside of BI dashboards,
whether it's AWS QuickSight,

412
00:21:13,260 --> 00:21:17,103
or Tableau, or Looker, or
any BI tool of your choice.

413
00:21:18,300 --> 00:21:19,710
We are also seeing increasing number

414
00:21:19,710 --> 00:21:22,980
of customers use Redshift
for complex decision support

415
00:21:22,980 --> 00:21:24,540
or ad hoc analytics.

416
00:21:24,540 --> 00:21:27,330
This includes things like,
you know, market forecasting,

417
00:21:27,330 --> 00:21:30,300
customer segmentation, you
know, those kind of use cases.

418
00:21:30,300 --> 00:21:31,350
And if you remember all

419
00:21:31,350 --> 00:21:33,270
of the performance
enhancements I talked about

420
00:21:33,270 --> 00:21:35,850
that we focused on this
year are basically geared

421
00:21:35,850 --> 00:21:37,830
towards reducing your latency

422
00:21:37,830 --> 00:21:40,950
for first time queries as
well as repeat queries.

423
00:21:40,950 --> 00:21:43,770
And as we continue to make
improvements in that area,

424
00:21:43,770 --> 00:21:46,770
this use case is gonna
get even more stronger.

425
00:21:46,770 --> 00:21:49,980
Moving on, we also see Redshift
play a very critical role

426
00:21:49,980 --> 00:21:54,900
in data processing workloads
for ETL and ELT pipelines,

427
00:21:54,900 --> 00:21:57,060
where customers want to ingest this data

428
00:21:57,060 --> 00:22:00,270
from their operational databases
directly into Redshift,

429
00:22:00,270 --> 00:22:02,130
and they want to transform this data,

430
00:22:02,130 --> 00:22:06,720
either using AWS Glue or custom
SQL commands within Redshift

431
00:22:06,720 --> 00:22:09,210
or use a third party tool like DBT.

432
00:22:09,210 --> 00:22:11,190
Redshift plays a very critical role

433
00:22:11,190 --> 00:22:13,770
in the entire data processing pipeline.

434
00:22:13,770 --> 00:22:16,530
And all the enhancements
we've made around Zero-ETL

435
00:22:16,530 --> 00:22:18,360
and the distributed warehouse architecture

436
00:22:18,360 --> 00:22:19,710
that I talked about earlier

437
00:22:19,710 --> 00:22:22,440
makes this use case even, even stronger.

438
00:22:22,440 --> 00:22:24,120
And then last use case I'll talk about

439
00:22:24,120 --> 00:22:27,120
is near real-time interactive analytics.

440
00:22:27,120 --> 00:22:29,580
We're seeing increasing number
of customers use Redshift

441
00:22:29,580 --> 00:22:31,260
for this particular use case.

442
00:22:31,260 --> 00:22:34,680
And for this use case, both
your ingestion latency,

443
00:22:34,680 --> 00:22:37,590
as well as query latency,
becomes very important.

444
00:22:37,590 --> 00:22:40,200
And so on the ingestion
side, we have made a lot

445
00:22:40,200 --> 00:22:41,817
of improvements on Zero-ETL.

446
00:22:41,817 --> 00:22:44,820
And as a result, we can
bring the ingestion latency

447
00:22:44,820 --> 00:22:47,370
down to single digit seconds.

448
00:22:47,370 --> 00:22:49,590
And on the query performance front,

449
00:22:49,590 --> 00:22:51,360
we continue to improve query performance

450
00:22:51,360 --> 00:22:54,240
for both first time and
repeat queries, right?

451
00:22:54,240 --> 00:22:56,430
So all of these enhancements
will make this use case

452
00:22:56,430 --> 00:22:59,220
even, even stronger,
and customers can use it

453
00:22:59,220 --> 00:23:01,530
for things like clickstream analytics,

454
00:23:01,530 --> 00:23:03,603
IoT monitoring, et cetera.

455
00:23:08,160 --> 00:23:10,740
Now we have thousands
of enterprise customers

456
00:23:10,740 --> 00:23:12,060
that use Redshift daily

457
00:23:12,060 --> 00:23:14,340
for their business-critical applications.

458
00:23:14,340 --> 00:23:16,740
One of those customers is Twilio

459
00:23:16,740 --> 00:23:19,200
that provides a cloud
communication platform

460
00:23:19,200 --> 00:23:21,240
for you to embed your email, voice,

461
00:23:21,240 --> 00:23:24,090
and video directly into your applications.

462
00:23:24,090 --> 00:23:26,970
To learn more about how
Twilio is using Redshift

463
00:23:26,970 --> 00:23:29,370
to transform billing
and analytics at scale,

464
00:23:29,370 --> 00:23:31,740
please welcome principal software engineer

465
00:23:31,740 --> 00:23:33,363
of Twilio, Sean Mckibben.

466
00:23:34,643 --> 00:23:36,120
(audience applauding)

467
00:23:36,120 --> 00:23:36,953
- Thanks, Imran.

468
00:23:41,970 --> 00:23:43,920
About a year ago, my leadership

469
00:23:43,920 --> 00:23:46,800
on Twilio's commerce platform charged us

470
00:23:46,800 --> 00:23:49,440
with reimagining our billing engine.

471
00:23:49,440 --> 00:23:51,540
The business needed new ways to deal

472
00:23:51,540 --> 00:23:54,030
with challenges of scale and flexibility,

473
00:23:54,030 --> 00:23:56,670
and our finance teams needed
to have analytical views

474
00:23:56,670 --> 00:23:58,770
of our data that were not possible

475
00:23:58,770 --> 00:24:01,200
with our classic architecture.

476
00:24:01,200 --> 00:24:03,600
What came out of this
project helped us modernize

477
00:24:03,600 --> 00:24:05,260
and streamline how we process

478
00:24:05,260 --> 00:24:07,890
analytical customer financial data

479
00:24:07,890 --> 00:24:10,350
to empower the business
to imagine new ways

480
00:24:10,350 --> 00:24:12,350
of delivering our products to customers.

481
00:24:14,730 --> 00:24:16,890
Twilio's billing engine processes billions

482
00:24:16,890 --> 00:24:20,160
of usage events every
day, every text message,

483
00:24:20,160 --> 00:24:22,320
every voice call, every video session

484
00:24:22,320 --> 00:24:24,870
from customers like Toyota, Salesforce,

485
00:24:24,870 --> 00:24:28,860
and Shopify needs to be
accurately priced and billed.

486
00:24:28,860 --> 00:24:30,840
Our legacy billing engine was built

487
00:24:30,840 --> 00:24:32,610
when Twilio was much smaller.

488
00:24:32,610 --> 00:24:35,430
It was laser-focused on operational speed,

489
00:24:35,430 --> 00:24:38,850
ingest an event, price it, and move on.

490
00:24:38,850 --> 00:24:41,400
But that architecture
created two critical gaps.

491
00:24:41,400 --> 00:24:43,920
The first was flexibility.

492
00:24:43,920 --> 00:24:46,080
The business wanted
innovative pricing models,

493
00:24:46,080 --> 00:24:48,480
like package deals,
committed use discounts

494
00:24:48,480 --> 00:24:50,100
with overage pricing.

495
00:24:50,100 --> 00:24:53,460
But our system couldn't adapt
without major re-architecture.

496
00:24:53,460 --> 00:24:55,410
Unwinding pricing misconfigurations

497
00:24:55,410 --> 00:24:57,900
was a multi-day engineering effort,

498
00:24:57,900 --> 00:24:59,280
and backdating a discount

499
00:24:59,280 --> 00:25:02,070
was a bespoke time-consuming process.

500
00:25:02,070 --> 00:25:04,770
The second gap was with analytics.

501
00:25:04,770 --> 00:25:06,630
Finance couldn't answer basic questions,

502
00:25:06,630 --> 00:25:08,190
like what would revenue look like

503
00:25:08,190 --> 00:25:09,790
if we changed this pricing tier?

504
00:25:11,010 --> 00:25:13,500
Our BI teams couldn't build dashboards

505
00:25:13,500 --> 00:25:15,300
showing customer usage trends

506
00:25:15,300 --> 00:25:18,450
without impacting the
production billing system.

507
00:25:18,450 --> 00:25:20,790
The operational system
and the analytical needs

508
00:25:20,790 --> 00:25:22,320
were stepping on each other's toes

509
00:25:22,320 --> 00:25:25,023
and neither served our
business use cases very well.

510
00:25:26,070 --> 00:25:28,530
We needed a distributed
data warehouse architecture

511
00:25:28,530 --> 00:25:31,590
that could handle both
transactional billing integrity

512
00:25:31,590 --> 00:25:33,303
and analytical flexibility.

513
00:25:34,890 --> 00:25:36,810
We evaluated several platforms,

514
00:25:36,810 --> 00:25:40,740
traditional data warehouses,
data lakes with query engines,

515
00:25:40,740 --> 00:25:43,830
even a split architecture
with separate operational

516
00:25:43,830 --> 00:25:47,250
and analytical systems, but
our workload is unusual.

517
00:25:47,250 --> 00:25:49,860
This system generates invoice line items,

518
00:25:49,860 --> 00:25:52,620
so we needed financial grade consistency,

519
00:25:52,620 --> 00:25:56,430
guarantees against duplicate
charges or missing events,

520
00:25:56,430 --> 00:25:58,230
but we also needed analytical speed.

521
00:26:02,340 --> 00:26:06,630
Most data warehouses
optimize for analytics

522
00:26:06,630 --> 00:26:08,670
at the expense of consistency.

523
00:26:08,670 --> 00:26:10,470
Most operational databases

524
00:26:10,470 --> 00:26:13,320
can't handle analytical queries at scale.

525
00:26:13,320 --> 00:26:15,660
Redshift bridges that gap for us

526
00:26:15,660 --> 00:26:17,790
as an operational data warehouse.

527
00:26:17,790 --> 00:26:20,940
We get serializable
transactional isolation,

528
00:26:20,940 --> 00:26:23,400
the strongest consistency
guarantees possible,

529
00:26:23,400 --> 00:26:25,593
while maintaining analytical performance.

530
00:26:26,760 --> 00:26:27,810
That's the unlock.

531
00:26:27,810 --> 00:26:29,250
We can ingest events,

532
00:26:29,250 --> 00:26:31,170
aggregate with transactional correctness,

533
00:26:31,170 --> 00:26:34,350
and serve BI queries all in one system.

534
00:26:34,350 --> 00:26:36,120
Plus, Redshift Serverless gives us this

535
00:26:36,120 --> 00:26:39,510
without infrastructure
overhead, no provisioning,

536
00:26:39,510 --> 00:26:43,200
no capacity planning,
no failover management,

537
00:26:43,200 --> 00:26:45,990
and price performance
scaling gives us this means

538
00:26:45,990 --> 00:26:48,840
that our compute adjusts automatically

539
00:26:48,840 --> 00:26:50,340
as our workload changes.

540
00:26:50,340 --> 00:26:53,250
We pay for usage and not for capacity.

541
00:26:53,250 --> 00:26:57,030
The result is that Redshift
Serverless cost us 75% less

542
00:26:57,030 --> 00:26:58,860
than what our previous system did,

543
00:26:58,860 --> 00:27:00,780
all while processing more data

544
00:27:00,780 --> 00:27:02,902
with stronger consistency guarantees,

545
00:27:02,902 --> 00:27:06,093
and enabling analytics that
were impossible before.

546
00:27:07,650 --> 00:27:09,450
Let's look at the ingestion layer.

547
00:27:09,450 --> 00:27:11,220
Billions of events daily

548
00:27:11,220 --> 00:27:14,250
flow from MSK into Redshift Serverless.

549
00:27:14,250 --> 00:27:18,000
Every usage event across
Twilio's platform lands here.

550
00:27:18,000 --> 00:27:20,896
Two architectural decisions
make this work at scale.

551
00:27:20,896 --> 00:27:24,903
First, serializable transaction
isolation for item potency.

552
00:27:25,830 --> 00:27:28,170
Events can arrive multiple times,

553
00:27:28,170 --> 00:27:31,440
whether it's from network
retries or system resubmissions.

554
00:27:31,440 --> 00:27:33,540
But Redshift's consistency
guarantees ensure

555
00:27:33,540 --> 00:27:35,790
that we only count each event once.

556
00:27:35,790 --> 00:27:39,000
No duplicate charges, no
custom deduplication logic,

557
00:27:39,000 --> 00:27:41,400
the transaction model handles it.

558
00:27:41,400 --> 00:27:43,890
Second, auto refreshing materialized views

559
00:27:43,890 --> 00:27:45,660
for real-time aggregation.

560
00:27:45,660 --> 00:27:47,700
We're not batch processing overnight.

561
00:27:47,700 --> 00:27:50,190
As events land, they're
incrementally aggregated

562
00:27:50,190 --> 00:27:52,530
by customer, product, and day,

563
00:27:52,530 --> 00:27:55,623
and our rating system downstream
gets near real-time data.

564
00:27:56,760 --> 00:28:00,570
We stored over half a trillion
events in Redshift so far,

565
00:28:00,570 --> 00:28:03,870
all de-duplicated and
immediately queryable.

566
00:28:03,870 --> 00:28:05,100
That's the foundation.

567
00:28:05,100 --> 00:28:08,190
Now let me show you how
we built on top of it.

568
00:28:08,190 --> 00:28:10,800
We didn't build just one big cluster.

569
00:28:10,800 --> 00:28:13,740
We built what ended up being
a distributed data warehouse.

570
00:28:13,740 --> 00:28:15,630
Multiple Redshift work groups

571
00:28:15,630 --> 00:28:17,940
sharing data through data shares.

572
00:28:17,940 --> 00:28:21,000
Our AWS folks called this
the golden architecture.

573
00:28:21,000 --> 00:28:22,740
And honestly, once we understood it,

574
00:28:22,740 --> 00:28:25,710
we couldn't imagine building
the system any other way.

575
00:28:25,710 --> 00:28:27,300
So we have multiple work groups,

576
00:28:27,300 --> 00:28:29,910
all working off of the same data set,

577
00:28:29,910 --> 00:28:32,220
ingesting writing billions of events.

578
00:28:32,220 --> 00:28:34,680
The pricing engine is
running transformations

579
00:28:34,680 --> 00:28:36,630
and aggregations on those events.

580
00:28:36,630 --> 00:28:38,670
Analytics is querying the results,

581
00:28:38,670 --> 00:28:41,100
but they're all looking at the same tables

582
00:28:41,100 --> 00:28:42,360
through data shares.

583
00:28:42,360 --> 00:28:45,810
We're not making copies or
ETL-ing data between them.

584
00:28:45,810 --> 00:28:49,410
This gave us workload
isolation and cost visibility.

585
00:28:49,410 --> 00:28:52,980
Heavy analytical queries don't
slow down invoice processing.

586
00:28:52,980 --> 00:28:56,160
When we need to reprocess data,
it doesn't impact dashboards

587
00:28:56,160 --> 00:28:59,250
and we can actually see
what each workload costs.

588
00:28:59,250 --> 00:29:02,310
For a financial system, live
data shares are critical.

589
00:29:02,310 --> 00:29:05,193
Everyone sees the same version
of the data in real time.

590
00:29:07,260 --> 00:29:09,270
So let's talk about
what's actually happening

591
00:29:09,270 --> 00:29:10,740
in that pricing engine work group

592
00:29:10,740 --> 00:29:13,080
because this is where it gets complicated.

593
00:29:13,080 --> 00:29:14,760
How complex are we talking?

594
00:29:14,760 --> 00:29:17,910
Our dbt pipeline manages
over 200 million price points

595
00:29:17,910 --> 00:29:20,280
across Twilio's product catalog.

596
00:29:20,280 --> 00:29:23,040
We're dealing with
multi-tiered volume discounts,

597
00:29:23,040 --> 00:29:26,460
promotional discounts that
stack in specific orders,

598
00:29:26,460 --> 00:29:29,220
multi-product bundles where
one thing affects the pricing

599
00:29:29,220 --> 00:29:31,620
of another, bifurcated taxes.

600
00:29:31,620 --> 00:29:33,750
It's genuinely intricate.

601
00:29:33,750 --> 00:29:37,200
We use dbt Core to break this
down into manageable pieces.

602
00:29:37,200 --> 00:29:40,410
Each pricing rule is a discreet SQL model

603
00:29:40,410 --> 00:29:42,780
and dbt orchestrates how they run.

604
00:29:42,780 --> 00:29:44,940
Redshift paralyzes what it can,

605
00:29:44,940 --> 00:29:46,800
serializes what it needs to,

606
00:29:46,800 --> 00:29:49,503
and dbt manages the
dependency graph between them.

607
00:29:50,370 --> 00:29:53,700
The bonus here is that dbt
auto generates documentation

608
00:29:53,700 --> 00:29:55,680
as the pipeline evolves.

609
00:29:55,680 --> 00:29:57,240
We can actually trace the lineage to see

610
00:29:57,240 --> 00:30:00,540
exactly how an invoice
line item was calculated.

611
00:30:00,540 --> 00:30:02,310
That kind of transparency was impossible

612
00:30:02,310 --> 00:30:03,720
with our old system,

613
00:30:03,720 --> 00:30:07,020
but it's critical for
customer trust and compliance.

614
00:30:07,020 --> 00:30:08,520
And here's what surprised us.

615
00:30:08,520 --> 00:30:10,470
Redshift handled these complex joins

616
00:30:10,470 --> 00:30:13,740
and window functions with
very little optimization.

617
00:30:13,740 --> 00:30:15,540
We budgeted weeks for performance tuning

618
00:30:15,540 --> 00:30:17,040
and barely needed it.

619
00:30:17,040 --> 00:30:20,460
We can recalculate an entire
month of billing in 30 minutes

620
00:30:20,460 --> 00:30:22,773
where our old system
took six hours or more.

621
00:30:24,900 --> 00:30:27,960
Midway through this process,
we hit a bit of a snag.

622
00:30:27,960 --> 00:30:30,480
Our product catalog and
pricing configuration data

623
00:30:30,480 --> 00:30:35,043
lived spread across about seven
or eight Aurora databases,

624
00:30:36,120 --> 00:30:37,980
and we only had the current state

625
00:30:37,980 --> 00:30:40,260
of our configuration stored in them.

626
00:30:40,260 --> 00:30:42,780
The old system just priced everything

627
00:30:42,780 --> 00:30:45,540
with whatever was current
at the time of processing.

628
00:30:45,540 --> 00:30:47,550
That's fine if you only
want to go forward,

629
00:30:47,550 --> 00:30:50,520
but we needed the flexibility
to reprice historical usage

630
00:30:50,520 --> 00:30:54,900
for corrections, promotional
adjustments, contract changes.

631
00:30:54,900 --> 00:30:58,260
To do that accurately, we needed
to know when prices changed

632
00:30:58,260 --> 00:31:00,975
and what they were at any point in time.

633
00:31:00,975 --> 00:31:03,480
Zero-ETL with history mode,

634
00:31:03,480 --> 00:31:05,430
which launched in April of this year,

635
00:31:05,430 --> 00:31:07,050
fixed this for us.

636
00:31:07,050 --> 00:31:09,390
We integrated that with Aurora databases

637
00:31:09,390 --> 00:31:11,250
and got full change history

638
00:31:11,250 --> 00:31:13,680
flowing automatically into Redshift.

639
00:31:13,680 --> 00:31:16,410
Every price update, every
configuration change,

640
00:31:16,410 --> 00:31:19,683
timestamped and captured,
no custom CDC to manage.

641
00:31:20,580 --> 00:31:22,650
The result is that we
can reconstruct any bill

642
00:31:22,650 --> 00:31:23,910
from any point in time,

643
00:31:23,910 --> 00:31:27,360
we can reprice historical
usage with exact configuration

644
00:31:27,360 --> 00:31:30,240
that should have applied, or
we can model what invoices

645
00:31:30,240 --> 00:31:32,640
would look like under different scenarios.

646
00:31:32,640 --> 00:31:35,140
That's only possible with
complete change history.

647
00:31:36,270 --> 00:31:38,940
Let's talk about outcomes,
starting with cost.

648
00:31:38,940 --> 00:31:43,080
We're running at a 75% lower
cost than the previous system

649
00:31:43,080 --> 00:31:46,530
while processing more data
with stronger guarantees.

650
00:31:46,530 --> 00:31:48,450
Four people on my team are managing

651
00:31:48,450 --> 00:31:50,823
almost a hundred billion events a month.

652
00:31:52,770 --> 00:31:54,150
Speed.

653
00:31:54,150 --> 00:31:58,500
Six hours down to 30 minutes
for full month recalculations.

654
00:31:58,500 --> 00:32:01,290
Finance dashboards went
from daily batch updates

655
00:32:01,290 --> 00:32:02,763
to sub minute response times.

656
00:32:03,990 --> 00:32:06,330
But the real win is flexibility.

657
00:32:06,330 --> 00:32:08,550
We can now do retroactive pricing changes,

658
00:32:08,550 --> 00:32:10,500
accurately recalculate last month's usage

659
00:32:10,500 --> 00:32:12,810
with today's promotional rules,

660
00:32:12,810 --> 00:32:15,900
product managers can model
new pricing strategies

661
00:32:15,900 --> 00:32:18,060
against real-time usage,
answering questions,

662
00:32:18,060 --> 00:32:21,330
like what if we change this
pricing tier structure?

663
00:32:21,330 --> 00:32:23,610
Billing ops can audit any invoice

664
00:32:23,610 --> 00:32:26,910
and see the complete
calculation lineage in minutes.

665
00:32:26,910 --> 00:32:30,060
We're also auto generating
new data products,

666
00:32:30,060 --> 00:32:32,820
like an effective pricing
model that represents

667
00:32:32,820 --> 00:32:36,810
what any customer will pay
for any product at any time.

668
00:32:36,810 --> 00:32:40,200
Direct rights to S3 and
soon to Iceberg tables

669
00:32:40,200 --> 00:32:43,953
eliminate Spark ETL jobs
for data lake delivery.

670
00:32:44,820 --> 00:32:46,320
The previous system served us well,

671
00:32:46,320 --> 00:32:49,920
but it wasn't built for this
kind of scale or flexibility.

672
00:32:49,920 --> 00:32:51,930
This architecture fundamentally changed

673
00:32:51,930 --> 00:32:53,580
what's possible for the business.

674
00:32:55,740 --> 00:32:57,240
The power of this architecture

675
00:32:57,240 --> 00:32:59,250
is that it doesn't end
with the billing engine.

676
00:32:59,250 --> 00:33:02,400
We're about to start writing
our curated financial data sets

677
00:33:02,400 --> 00:33:07,290
to Iceberg tables, indexed
with AWS Glue Data Catalog.

678
00:33:07,290 --> 00:33:09,870
This opens up the data to
broader organizational use

679
00:33:09,870 --> 00:33:13,020
without having to give everyone
direct access to Redshift,

680
00:33:13,020 --> 00:33:15,840
which brings me to the next
part of our data story.

681
00:33:15,840 --> 00:33:19,603
Teams at Twilio have built
what we call the Odin system,

682
00:33:19,603 --> 00:33:23,340
a query infrastructure layer
on top of these Iceberg tables

683
00:33:23,340 --> 00:33:25,980
and the Glue Data Catalog using Athena.

684
00:33:25,980 --> 00:33:27,390
Scott's gonna walk you through

685
00:33:27,390 --> 00:33:29,550
how you can leverage
Athena's latest features

686
00:33:29,550 --> 00:33:33,090
to democratize data access
across your organization.

687
00:33:33,090 --> 00:33:33,923
Scott?

688
00:33:35,610 --> 00:33:36,780
- Hey, man, thanks.
- Good luck, man.

689
00:33:36,780 --> 00:33:38,850
Appreciate it, oops, sorry.

690
00:33:38,850 --> 00:33:40,953
All right, thank you, Sean.

691
00:33:42,330 --> 00:33:43,163
Thanks again, Sean.

692
00:33:43,163 --> 00:33:46,350
Really loved to hear the
outcomes that Twilio has had,

693
00:33:46,350 --> 00:33:48,810
especially the 75% cost savings,

694
00:33:48,810 --> 00:33:51,810
which is really impressive
at Twilio's scale.

695
00:33:51,810 --> 00:33:53,340
So as Imran mentioned, I'm Scott.

696
00:33:53,340 --> 00:33:54,750
I lead the product management function

697
00:33:54,750 --> 00:33:55,890
for the Athena Service.

698
00:33:55,890 --> 00:33:57,810
Delighted to be with you today.

699
00:33:57,810 --> 00:33:59,790
Like many of you, I'm a data nerd

700
00:33:59,790 --> 00:34:00,900
and I love working with data,

701
00:34:00,900 --> 00:34:03,810
so I wanted to gather
some data from you all.

702
00:34:03,810 --> 00:34:06,360
So raise your hand if this
is your first re:Invent.

703
00:34:07,380 --> 00:34:08,490
All right, cool.

704
00:34:08,490 --> 00:34:09,900
And raise your hand if this is your first

705
00:34:09,900 --> 00:34:11,553
What's New in Athena session?

706
00:34:12,870 --> 00:34:15,240
All right, great to see
some friendly new faces

707
00:34:15,240 --> 00:34:17,700
and previous ones alike.

708
00:34:17,700 --> 00:34:20,790
So as a refresher,
Athena is our serverless

709
00:34:20,790 --> 00:34:22,830
interactive query service that's designed

710
00:34:22,830 --> 00:34:26,820
to make it dead simple to
run SQL on your data lakes.

711
00:34:26,820 --> 00:34:28,830
Customers love Athena's ease of use.

712
00:34:28,830 --> 00:34:29,790
We talk about it often.

713
00:34:29,790 --> 00:34:31,800
It's kind of what we really focus on

714
00:34:31,800 --> 00:34:34,710
on the product team in
every feature that we build.

715
00:34:34,710 --> 00:34:37,110
There's no infrastructure
to set up or manage.

716
00:34:37,110 --> 00:34:40,260
It just works with the
tools that you have today.

717
00:34:40,260 --> 00:34:43,200
Customers love how Athena's
optimized for interactivity.

718
00:34:43,200 --> 00:34:45,990
Meaning, you get queries that
started in under a second

719
00:34:45,990 --> 00:34:47,640
and a fast engine on top

720
00:34:47,640 --> 00:34:50,730
of great out-of-the-box performance.

721
00:34:50,730 --> 00:34:52,650
Last but not least, our engine just works

722
00:34:52,650 --> 00:34:53,760
with the data that you have.

723
00:34:53,760 --> 00:34:56,940
So you can bring your
Parquet, JSON, Iceberg, CSV,

724
00:34:56,940 --> 00:34:59,250
and other data and bring that to Athena,

725
00:34:59,250 --> 00:35:01,530
and start querying right away.

726
00:35:01,530 --> 00:35:03,630
And best yet, we're able to pair

727
00:35:03,630 --> 00:35:05,670
Athena's query engine capabilities

728
00:35:05,670 --> 00:35:08,648
with really deep fine
grain access capabilities

729
00:35:08,648 --> 00:35:11,253
through our lake formation sister service.

730
00:35:12,300 --> 00:35:14,220
So we launched in 2016, and today,

731
00:35:14,220 --> 00:35:16,800
we have customers from every industry,

732
00:35:16,800 --> 00:35:18,540
from startups to large enterprises,

733
00:35:18,540 --> 00:35:20,340
who are running lots of queries per week.

734
00:35:20,340 --> 00:35:23,370
In fact, over billions of queries a week

735
00:35:23,370 --> 00:35:25,980
in our most recent kind
of, you know, metrics.

736
00:35:25,980 --> 00:35:27,960
And so customers are kind
of getting a lot of insights

737
00:35:27,960 --> 00:35:30,380
and value out of their S3 data lake.

738
00:35:30,380 --> 00:35:33,120
So let's talk about the
customer journey with Athena

739
00:35:33,120 --> 00:35:35,853
and how that often starts with Amazon S3.

740
00:35:36,780 --> 00:35:40,260
So customers choose S3 for
its unmatched durability,

741
00:35:40,260 --> 00:35:43,500
scalability, and availability.

742
00:35:43,500 --> 00:35:45,990
Because of those foundational capabilities

743
00:35:45,990 --> 00:35:47,640
and unique differentiators,

744
00:35:47,640 --> 00:35:49,590
customers have been able to build millions

745
00:35:49,590 --> 00:35:51,723
of data lakes on top of S3.

746
00:35:53,430 --> 00:35:55,260
But as Imran mentioned earlier,

747
00:35:55,260 --> 00:35:57,060
there's a big shift
happening in data lakes

748
00:35:57,060 --> 00:35:59,580
and that's open table formats.

749
00:35:59,580 --> 00:36:01,470
Folks love how these open table formats

750
00:36:01,470 --> 00:36:03,510
brings familiar SQL functionality

751
00:36:03,510 --> 00:36:05,670
to kind of where we're all working today,

752
00:36:05,670 --> 00:36:09,360
which is in our S3 based data lake stores.

753
00:36:09,360 --> 00:36:11,670
Athena actually launched its
open table format support

754
00:36:11,670 --> 00:36:13,620
back in 2021, and since then,

755
00:36:13,620 --> 00:36:16,020
we've seen Iceberg emerge
as a leading choice

756
00:36:16,020 --> 00:36:18,783
amongst the open table
formats that we support.

757
00:36:19,860 --> 00:36:22,680
Iceberg is unique amongst
OTFs for its ability

758
00:36:22,680 --> 00:36:24,450
to handle massive scale data sets

759
00:36:24,450 --> 00:36:26,430
while maintaining simplicity,

760
00:36:26,430 --> 00:36:30,060
supporting multiple query
engines like Athena and Spark,

761
00:36:30,060 --> 00:36:31,920
and providing you transactional features

762
00:36:31,920 --> 00:36:35,040
that allow you to write into
your data lakes with ease.

763
00:36:35,040 --> 00:36:36,900
And it does that all without locking you

764
00:36:36,900 --> 00:36:38,913
into a single vendor ecosystem.

765
00:36:40,770 --> 00:36:43,290
So excited to share today
that Athena, this year,

766
00:36:43,290 --> 00:36:46,020
is 1.5 times faster on
Iceberg with Parquet,

767
00:36:46,020 --> 00:36:48,690
based on TIP CDS one terabyte compared

768
00:36:48,690 --> 00:36:50,610
to this time last year.

769
00:36:50,610 --> 00:36:51,810
And we've been able to achieve that

770
00:36:51,810 --> 00:36:53,760
through a number of changes,
starting with our engine,

771
00:36:53,760 --> 00:36:55,800
but kind of kind of cascading out

772
00:36:55,800 --> 00:36:57,390
to our catalog experiences as well.

773
00:36:57,390 --> 00:36:59,550
But wanted to touch on a few of those.

774
00:36:59,550 --> 00:37:01,770
The first is Iceberg Statistics,

775
00:37:01,770 --> 00:37:03,810
which is an existing feature of Athena,

776
00:37:03,810 --> 00:37:06,330
but two weeks ago, we
launched a new update,

777
00:37:06,330 --> 00:37:07,920
where we've actually enhanced the behavior

778
00:37:07,920 --> 00:37:09,510
of the Athena service when it interacts

779
00:37:09,510 --> 00:37:14,340
with statistics files to
ultimately make queries run faster.

780
00:37:14,340 --> 00:37:16,230
So to use Iceberg Statistics,

781
00:37:16,230 --> 00:37:19,593
basically what you'll do
is you'll fire up AWS Glue

782
00:37:19,593 --> 00:37:23,190
and ask Glue to collect
statistics on your Iceberg tables.

783
00:37:23,190 --> 00:37:24,270
And then when you come to Athena

784
00:37:24,270 --> 00:37:25,560
and you query those tables,

785
00:37:25,560 --> 00:37:28,020
Athena will automatically
apply the statistics

786
00:37:28,020 --> 00:37:30,660
to make more intelligent
query planning decisions.

787
00:37:30,660 --> 00:37:32,640
So automatically accelerating your queries

788
00:37:32,640 --> 00:37:34,050
without a ton of work to do.

789
00:37:34,050 --> 00:37:35,250
So it's a great feature.

790
00:37:36,286 --> 00:37:37,890
And so, that's an awesome
feature we launched

791
00:37:37,890 --> 00:37:40,680
just a couple weeks ago
is an updated experience

792
00:37:40,680 --> 00:37:41,850
for Iceberg Stats.

793
00:37:41,850 --> 00:37:45,600
We also launched a net new
feature, Parquet column indexing,

794
00:37:45,600 --> 00:37:49,530
which allows queries to skip
irrelevant blocks of data,

795
00:37:49,530 --> 00:37:51,900
which reduces unnecessary IOL operations

796
00:37:51,900 --> 00:37:53,520
when reading from S3.

797
00:37:53,520 --> 00:37:56,220
So this is like really
beneficial, especially on queries

798
00:37:56,220 --> 00:37:59,880
that have selective filter
predicates on sorted data.

799
00:37:59,880 --> 00:38:01,500
So that's fairly common in, you know,

800
00:38:01,500 --> 00:38:03,300
a lot of enterprise reporting scenarios

801
00:38:03,300 --> 00:38:04,533
is to have sorted data.

802
00:38:05,432 --> 00:38:06,690
So great feature to try out.

803
00:38:06,690 --> 00:38:09,000
And for our customers who are
using lake formation today

804
00:38:09,000 --> 00:38:12,090
to secure their and govern
their Iceberg tables,

805
00:38:12,090 --> 00:38:12,923
just a couple weeks ago,

806
00:38:12,923 --> 00:38:15,540
we announced new partition
pruning behaviors

807
00:38:15,540 --> 00:38:19,200
for lake formation tables with
row filters and column masks,

808
00:38:19,200 --> 00:38:21,060
and additional predicate
push down behaviors,

809
00:38:21,060 --> 00:38:24,000
which altogether will help
improve query performance,

810
00:38:24,000 --> 00:38:25,860
reduce cost, and does that

811
00:38:25,860 --> 00:38:27,723
without sacrificing data governance.

812
00:38:30,360 --> 00:38:32,520
So on Sunday, we launched
a new feature for Iceberg,

813
00:38:32,520 --> 00:38:34,590
which is called materialized views.

814
00:38:34,590 --> 00:38:35,883
This is a really cool feature.

815
00:38:35,883 --> 00:38:39,060
This is essentially a
managed Iceberg table

816
00:38:39,060 --> 00:38:42,030
that stores pre-computed
query results for you,

817
00:38:42,030 --> 00:38:44,890
and then always ready to query S3 Table

818
00:38:44,890 --> 00:38:48,000
that you can or Iceberg
table that you can query

819
00:38:48,000 --> 00:38:50,100
through Athena and other engines.

820
00:38:50,100 --> 00:38:52,140
Super easy to use, they're
automatically updated

821
00:38:52,140 --> 00:38:53,490
when source data changes.

822
00:38:53,490 --> 00:38:56,820
So your kind of data is flowing
through materialized views,

823
00:38:56,820 --> 00:38:58,590
and again, always
available for you to query.

824
00:38:58,590 --> 00:39:00,720
So you're always seeing
the latest and greatest.

825
00:39:00,720 --> 00:39:01,620
And it does all of that

826
00:39:01,620 --> 00:39:03,960
without any infrastructure to manage.

827
00:39:03,960 --> 00:39:06,210
So today, we support
read support on Athena,

828
00:39:06,210 --> 00:39:10,200
but you can also go out to
Redshift, Spark on EMR, and Glue,

829
00:39:10,200 --> 00:39:13,260
and perform additional
operations over there.

830
00:39:13,260 --> 00:39:15,180
What we like to talk about with this one

831
00:39:15,180 --> 00:39:16,710
is like what are some good use cases

832
00:39:16,710 --> 00:39:18,720
for materialized views with Athena?

833
00:39:18,720 --> 00:39:20,340
And a lot of customers come to Athena

834
00:39:20,340 --> 00:39:23,160
and sort of build these
decomposed SQL pipelines

835
00:39:23,160 --> 00:39:24,720
on top of this service.

836
00:39:24,720 --> 00:39:26,490
So imagine if you have a complex

837
00:39:26,490 --> 00:39:29,010
data transformation pipeline
today that's joining

838
00:39:29,010 --> 00:39:31,020
and manipulating a
bunch of tables together

839
00:39:31,020 --> 00:39:33,540
to produce one single output table,

840
00:39:33,540 --> 00:39:36,360
that's now something
you can kind of reflect

841
00:39:36,360 --> 00:39:39,420
as a materialized view
in Glue Data Catalog

842
00:39:39,420 --> 00:39:41,220
and express that as SQL,

843
00:39:41,220 --> 00:39:43,140
and get the always updated benefits

844
00:39:43,140 --> 00:39:45,960
that we now provide
through materialized views.

845
00:39:45,960 --> 00:39:48,030
So really easy to get started
with this one as well.

846
00:39:48,030 --> 00:39:52,110
You'll fire up one of our Spark
experiences in EMR or Glue,

847
00:39:52,110 --> 00:39:55,500
or use those Glue APIs to launch

848
00:39:55,500 --> 00:39:57,390
or create your materialized view.

849
00:39:57,390 --> 00:39:59,730
And when you're creating
one, you'll get to choose

850
00:39:59,730 --> 00:40:01,980
whether you store your materialized view

851
00:40:01,980 --> 00:40:04,170
in a self-managed Iceberg table

852
00:40:04,170 --> 00:40:07,260
or an Amazon S3 Table,
which is a great segue

853
00:40:07,260 --> 00:40:10,890
to all the good work we've
been doing with S3 Tables.

854
00:40:10,890 --> 00:40:12,840
So if you remember back
to this time last year

855
00:40:12,840 --> 00:40:14,010
at re:Invent, we talked about

856
00:40:14,010 --> 00:40:16,770
and announced preview for Amazon S3 Tables

857
00:40:16,770 --> 00:40:21,480
as the first fully managed
Iceberg offering in the cloud.

858
00:40:21,480 --> 00:40:22,620
S3 Tables is really great

859
00:40:22,620 --> 00:40:24,480
because it simplifies the tedious stuff

860
00:40:24,480 --> 00:40:27,000
of running a Iceberg data lake.

861
00:40:27,000 --> 00:40:31,230
Things like table compaction
and expiring old snapshots,

862
00:40:31,230 --> 00:40:33,130
S3 tables handles all of that for you.

863
00:40:34,680 --> 00:40:36,570
So this year, we've been really busy

864
00:40:36,570 --> 00:40:38,670
taking S3 tables to GA,

865
00:40:38,670 --> 00:40:40,890
which we did on Pi Day in March.

866
00:40:40,890 --> 00:40:44,310
And in that launch, we added
expanded DDL operations.

867
00:40:44,310 --> 00:40:47,940
So gave you create database
and create table operators,

868
00:40:47,940 --> 00:40:49,530
plus a bunch of others.

869
00:40:49,530 --> 00:40:52,320
That made it possible
to work with S3 Tables

870
00:40:52,320 --> 00:40:54,210
end-to-end through Athena SQL.

871
00:40:54,210 --> 00:40:56,910
So really excited about what
that allows customers to do.

872
00:40:56,910 --> 00:40:59,340
And in that launch, we also
added a new console wizard

873
00:40:59,340 --> 00:41:01,710
to help you get started quickly.

874
00:41:01,710 --> 00:41:04,680
In August, we launched
Create Tables as Select,

875
00:41:04,680 --> 00:41:07,290
which is a very popular feature in Athena.

876
00:41:07,290 --> 00:41:08,370
We call it CTAS.

877
00:41:08,370 --> 00:41:10,620
What CTAs lets you do is convert data

878
00:41:10,620 --> 00:41:12,330
from one format to another.

879
00:41:12,330 --> 00:41:14,040
And so it's a really
no-brainer feature to have

880
00:41:14,040 --> 00:41:14,970
with S3 Tables.

881
00:41:14,970 --> 00:41:16,830
So imagine what you can do with this one,

882
00:41:16,830 --> 00:41:19,650
is just to give you an example use case.

883
00:41:19,650 --> 00:41:21,210
Let's assume you have an application

884
00:41:21,210 --> 00:41:23,940
that's writing JSON data out to S3

885
00:41:23,940 --> 00:41:25,770
and you want to query that JSON data,

886
00:41:25,770 --> 00:41:29,070
but you need a columnar level performance

887
00:41:29,070 --> 00:41:31,950
to meet the latency
requirements of your use case.

888
00:41:31,950 --> 00:41:35,250
What you can now do is a
CTAS on that JSON data,

889
00:41:35,250 --> 00:41:37,590
convert that into an S3 Table,

890
00:41:37,590 --> 00:41:39,930
and then tomorrow when new records show up

891
00:41:39,930 --> 00:41:41,490
from your JSON data stream,

892
00:41:41,490 --> 00:41:43,890
you can run an insert
operation on top of that table

893
00:41:43,890 --> 00:41:47,100
to bring your new records
over to your S3 Table,

894
00:41:47,100 --> 00:41:49,590
and drive your queries off of the S3 Table

895
00:41:49,590 --> 00:41:51,000
instead of your JSON data.

896
00:41:51,000 --> 00:41:53,310
So that's a really cool feature.

897
00:41:53,310 --> 00:41:55,390
So in kind of the back half of the year,

898
00:41:55,390 --> 00:41:56,790
what we've been doing
is optimizing the rest

899
00:41:56,790 --> 00:41:58,740
of the S3 Tables experience.

900
00:41:58,740 --> 00:42:01,080
And what's really great
about how we're working

901
00:42:01,080 --> 00:42:03,990
with the S3 team and the
work we're doing over there

902
00:42:03,990 --> 00:42:05,790
is that all of the
features that I mentioned

903
00:42:05,790 --> 00:42:07,620
for Iceberg on the previous slides,

904
00:42:07,620 --> 00:42:09,540
you also get with S3 Tables.

905
00:42:09,540 --> 00:42:12,510
So Parquet column indexing,
updated statistics,

906
00:42:12,510 --> 00:42:15,450
all of that good stuff
applies to S3 Tables,

907
00:42:15,450 --> 00:42:17,550
but you're also getting
the performance features

908
00:42:17,550 --> 00:42:20,070
that our partner teams and
S3 and Glue Data Catalog

909
00:42:20,070 --> 00:42:21,540
have also been delivering,

910
00:42:21,540 --> 00:42:23,670
like Z order and sort compaction,

911
00:42:23,670 --> 00:42:25,260
plus a bunch of operational tweaks

912
00:42:25,260 --> 00:42:27,030
that they've been
delivering to reduce latency

913
00:42:27,030 --> 00:42:28,263
across the experience.

914
00:42:30,090 --> 00:42:31,890
So now we recognize that Iceberg

915
00:42:31,890 --> 00:42:34,350
is not the only data format out there.

916
00:42:34,350 --> 00:42:37,260
And when we look at
the data that customers

917
00:42:37,260 --> 00:42:40,830
are querying today, we see lots of JSON,

918
00:42:40,830 --> 00:42:44,490
we see lots of text, CSV,
and other data formats,

919
00:42:44,490 --> 00:42:46,170
and we're proud to share that the majority

920
00:42:46,170 --> 00:42:48,870
of those queries are quite fast indeed,

921
00:42:48,870 --> 00:42:51,240
completing in under two seconds.

922
00:42:51,240 --> 00:42:53,850
We're able to achieve this
through how Athena's engine

923
00:42:53,850 --> 00:42:55,380
is designed and tuned,

924
00:42:55,380 --> 00:42:57,390
but also because of how Athena provides

925
00:42:57,390 --> 00:42:59,100
the serverless compute infrastructure

926
00:42:59,100 --> 00:43:02,520
that automatically scales
based on query complexity

927
00:43:02,520 --> 00:43:05,103
and is able to run multiple
queries in parallel.

928
00:43:06,600 --> 00:43:08,190
So this year, as we kind
of looked at this data,

929
00:43:08,190 --> 00:43:10,560
we asked, you know,
howelse can we accelerate

930
00:43:10,560 --> 00:43:12,900
or bring the performance bar higher

931
00:43:12,900 --> 00:43:14,880
for some of these additional data formats

932
00:43:14,880 --> 00:43:17,100
that customers are querying today?

933
00:43:17,100 --> 00:43:18,870
And that took us down a
pretty interesting path

934
00:43:18,870 --> 00:43:21,150
of actually redesigning our file system,

935
00:43:21,150 --> 00:43:23,190
and our readers and writers for a bunch

936
00:43:23,190 --> 00:43:26,280
of different file formats
to bring faster experience

937
00:43:26,280 --> 00:43:29,910
when interacting with those
files through the Athena engine.

938
00:43:29,910 --> 00:43:31,590
So we're seeing some really
awesome results there

939
00:43:31,590 --> 00:43:33,150
as this slide highlights.

940
00:43:33,150 --> 00:43:34,410
And just to highlight a few,

941
00:43:34,410 --> 00:43:37,860
Parquet, as I mentioned,
is a super popular format,

942
00:43:37,860 --> 00:43:41,220
is now 1.2 times faster
when used with Hive.

943
00:43:41,220 --> 00:43:44,880
Then this time last year, JSON, 2x faster.

944
00:43:44,880 --> 00:43:48,720
CSV, yeah, folks are
still passing CSVs around.

945
00:43:48,720 --> 00:43:50,490
I'm definitely guilty of that.

946
00:43:50,490 --> 00:43:53,340
It's now 1.8x faster
compared to last year.

947
00:43:53,340 --> 00:43:55,410
And then Iceberg, we talked
a little bit about already,

948
00:43:55,410 --> 00:43:59,313
but Delta Lake is seeing a
good boost this year as well.

949
00:44:00,540 --> 00:44:03,510
So when we talk about these
features kind of rolling out,

950
00:44:03,510 --> 00:44:04,920
normally, what you kind of hear is,

951
00:44:04,920 --> 00:44:07,320
well, now I have to
upgrade to this new thing,

952
00:44:07,320 --> 00:44:08,760
and that's a lot of work.

953
00:44:08,760 --> 00:44:11,340
But where we try to do
things differently on Athena

954
00:44:11,340 --> 00:44:14,310
is kind of work ahead of you
and figure out better ways

955
00:44:14,310 --> 00:44:15,960
to migrate our customers

956
00:44:15,960 --> 00:44:18,210
and bring them along for these journeys.

957
00:44:18,210 --> 00:44:20,460
So what we've been doing with this rollout

958
00:44:20,460 --> 00:44:21,720
is over the course of this year,

959
00:44:21,720 --> 00:44:23,820
we've been moving customers automatically

960
00:44:23,820 --> 00:44:27,090
to these new formats
and our new file system

961
00:44:27,090 --> 00:44:28,470
based on compatibility checks

962
00:44:28,470 --> 00:44:30,450
that we've run in the background.

963
00:44:30,450 --> 00:44:32,550
So chances are you're already
getting these benefits

964
00:44:32,550 --> 00:44:34,080
or you'll be getting these very soon

965
00:44:34,080 --> 00:44:35,640
in your production applications.

966
00:44:35,640 --> 00:44:37,950
So I'm really excited about that.

967
00:44:37,950 --> 00:44:40,110
Now we've also been shipping
performance features

968
00:44:40,110 --> 00:44:41,430
kind of elsewhere in the service,

969
00:44:41,430 --> 00:44:44,880
so I wanted to highlight a
few of those today as well.

970
00:44:44,880 --> 00:44:47,220
Query result reuse or what we call QRR

971
00:44:47,220 --> 00:44:50,280
is a caching feature that Athena has.

972
00:44:50,280 --> 00:44:51,113
What's really neat about this

973
00:44:51,113 --> 00:44:54,870
is it can bypass query execution
under certain conditions.

974
00:44:54,870 --> 00:44:56,190
And what means in that case

975
00:44:56,190 --> 00:44:58,380
is you're bypassing the actual latency

976
00:44:58,380 --> 00:44:59,700
from the query engine itself,

977
00:44:59,700 --> 00:45:03,390
but you're also getting a
query that ran in, you know,

978
00:45:03,390 --> 00:45:04,830
sub-hundred milliseconds

979
00:45:04,830 --> 00:45:06,690
as you're sort of bypassing the execution

980
00:45:06,690 --> 00:45:09,630
and picking up the previous query results.

981
00:45:09,630 --> 00:45:12,060
So here, we actually changed
how our hashing function works

982
00:45:12,060 --> 00:45:14,760
to ignore small variations

983
00:45:14,760 --> 00:45:16,680
in how different people write queries.

984
00:45:16,680 --> 00:45:18,780
So a good example is code comments

985
00:45:18,780 --> 00:45:22,650
or use of white space
characters in your queries.

986
00:45:22,650 --> 00:45:24,390
And we've done all of
that to actually increase

987
00:45:24,390 --> 00:45:28,113
the cache hit ratio when you're
using query result reuse.

988
00:45:29,109 --> 00:45:30,960
So that's a really sweet
feature to turn on.

989
00:45:30,960 --> 00:45:33,360
You just toggle a switch
within the Athena console

990
00:45:33,360 --> 00:45:35,160
or our APIs to activate it,

991
00:45:35,160 --> 00:45:37,230
and if a result is found,

992
00:45:37,230 --> 00:45:39,150
Athena will again bypass execution

993
00:45:39,150 --> 00:45:41,250
and give you the previous matching result.

994
00:45:42,090 --> 00:45:44,610
We also rewrote some of our memory logic

995
00:45:44,610 --> 00:45:49,610
way down in the engine with
the goal of reducing failures

996
00:45:50,760 --> 00:45:53,220
and making queries that have heavy shuffle

997
00:45:53,220 --> 00:45:56,880
and joint operators more stable at scale.

998
00:45:56,880 --> 00:45:58,770
So what we've done there is, again,

999
00:45:58,770 --> 00:46:02,340
kind of tweak a lot of the
very deep kind of behaviors

1000
00:46:02,340 --> 00:46:05,430
of the engine internals to
get better memory stability

1001
00:46:05,430 --> 00:46:08,460
and efficiency out of the engine.

1002
00:46:08,460 --> 00:46:10,470
So you should get fewer
failures on queries

1003
00:46:10,470 --> 00:46:13,473
that have a lot of process
a lot of data in memory.

1004
00:46:15,390 --> 00:46:16,770
So we'll switch gears a little bit

1005
00:46:16,770 --> 00:46:19,138
and talk about some
administrator features.

1006
00:46:19,138 --> 00:46:21,990
One of those is capacity reservations.

1007
00:46:21,990 --> 00:46:22,823
This is not too different

1008
00:46:22,823 --> 00:46:25,317
from Redshift Serverless reservations,

1009
00:46:25,317 --> 00:46:26,790
and this is Athena's feature

1010
00:46:26,790 --> 00:46:29,100
for guaranteed serverless compute

1011
00:46:29,100 --> 00:46:32,760
on top of our kind of managed
compute infrastructure.

1012
00:46:32,760 --> 00:46:35,670
It's really ideal for mission
critical applications,

1013
00:46:35,670 --> 00:46:40,170
dashboards, any SLA-sensitive
reporting jobs you may have,

1014
00:46:40,170 --> 00:46:42,150
as well as user-facing applications

1015
00:46:42,150 --> 00:46:45,990
that have a requirement for
significant concurrency.

1016
00:46:45,990 --> 00:46:47,550
To use it, pretty straightforward,

1017
00:46:47,550 --> 00:46:50,985
you create a reservation
and then you choose a number

1018
00:46:50,985 --> 00:46:53,760
of compute units, which
would be called DPUs.

1019
00:46:53,760 --> 00:46:57,420
And then you assign this
reservation to your work groups,

1020
00:46:57,420 --> 00:46:59,790
which allows your
reservation to share capacity

1021
00:46:59,790 --> 00:47:01,230
across your work groups.

1022
00:47:01,230 --> 00:47:03,180
And what's really great
about how this feature works

1023
00:47:03,180 --> 00:47:04,650
is there's no SQL changes needed.

1024
00:47:04,650 --> 00:47:08,250
You basically just configured
this setup here on the screen

1025
00:47:08,250 --> 00:47:09,990
and Athena automatically knows what to do

1026
00:47:09,990 --> 00:47:11,760
and routes queries from those work groups

1027
00:47:11,760 --> 00:47:14,700
to your reserved capacity units.

1028
00:47:14,700 --> 00:47:16,680
So last week, we
announced two new features

1029
00:47:16,680 --> 00:47:18,420
for capacity reservations.

1030
00:47:18,420 --> 00:47:21,480
The first is capacity and cost controls.

1031
00:47:21,480 --> 00:47:24,570
This is a new setting that influences

1032
00:47:24,570 --> 00:47:27,540
how Athena assigns data processing units

1033
00:47:27,540 --> 00:47:31,020
or DPUs to each of your queries.

1034
00:47:31,020 --> 00:47:33,060
You can set it at the work group level.

1035
00:47:33,060 --> 00:47:37,050
That gives you a centralized
kind of way to apply defaults,

1036
00:47:37,050 --> 00:47:39,870
kind of min and max range
for each of your queries.

1037
00:47:39,870 --> 00:47:44,310
But you can also control DPU
allocation at the query level

1038
00:47:44,310 --> 00:47:47,460
through new features in our
start query execution API

1039
00:47:47,460 --> 00:47:51,000
that now now allowed
this property to be set.

1040
00:47:51,000 --> 00:47:54,180
And that gives you precise
task level performance control

1041
00:47:54,180 --> 00:47:57,150
that customers who've used
our preview of this feature

1042
00:47:57,150 --> 00:48:00,630
have been able to get very low latency

1043
00:48:00,630 --> 00:48:02,910
out of their queries
through experimentation

1044
00:48:02,910 --> 00:48:05,490
and get very high levels of utilization

1045
00:48:05,490 --> 00:48:06,600
on their reserved capacity.

1046
00:48:06,600 --> 00:48:09,210
So really great feature.

1047
00:48:09,210 --> 00:48:10,380
Last but not least on that one

1048
00:48:10,380 --> 00:48:12,570
is we now have new observability data

1049
00:48:12,570 --> 00:48:14,460
in our get query results API.

1050
00:48:14,460 --> 00:48:17,124
So after you run a query
on capacity reservation,

1051
00:48:17,124 --> 00:48:19,920
we now tell you exactly how
many DPU it would consume.

1052
00:48:19,920 --> 00:48:21,990
So you can use that new
data to help you plan

1053
00:48:21,990 --> 00:48:25,440
for maybe future queries
that have a similar shape

1054
00:48:25,440 --> 00:48:26,700
and may have a difference

1055
00:48:26,700 --> 00:48:29,493
or a slightly different capacity need.

1056
00:48:30,357 --> 00:48:33,840
So we also launched an
auto scaling solution.

1057
00:48:33,840 --> 00:48:34,920
This is really neat.

1058
00:48:34,920 --> 00:48:37,770
This works as a step
function state machine.

1059
00:48:37,770 --> 00:48:39,270
So it's completely serverless

1060
00:48:39,270 --> 00:48:42,510
and it's entire logic is
kind of presented to you

1061
00:48:42,510 --> 00:48:43,980
as the state machine.

1062
00:48:43,980 --> 00:48:46,380
So you can go into the
step functions console

1063
00:48:46,380 --> 00:48:48,840
and kind of explore and
look at how it works.

1064
00:48:48,840 --> 00:48:50,520
But that also means it's highly open

1065
00:48:50,520 --> 00:48:52,650
and flexible to customization

1066
00:48:52,650 --> 00:48:55,140
for different requirements
that you may have.

1067
00:48:55,140 --> 00:48:57,150
The way it works is it basically monitors

1068
00:48:57,150 --> 00:48:58,950
the utilization of a reservation

1069
00:48:58,950 --> 00:49:00,870
and it'll make capacity adjustments based

1070
00:49:00,870 --> 00:49:04,050
on the parameters that
you set for look back

1071
00:49:04,050 --> 00:49:06,420
and how frequently and by
how much you should scale

1072
00:49:06,420 --> 00:49:07,570
based on your workload.

1073
00:49:08,550 --> 00:49:09,780
To launch it or to get started,

1074
00:49:09,780 --> 00:49:12,810
you have a console click-through
button that we've provided,

1075
00:49:12,810 --> 00:49:15,630
as well as documentation
that provides you a link

1076
00:49:15,630 --> 00:49:17,673
into the cloud formation experience.

1077
00:49:18,870 --> 00:49:21,060
Managed query results
is another admin feature

1078
00:49:21,060 --> 00:49:22,650
that we launched earlier this year.

1079
00:49:22,650 --> 00:49:24,120
This is a really great feature

1080
00:49:24,120 --> 00:49:25,770
if you're an administrator out there

1081
00:49:25,770 --> 00:49:27,660
because it simplifies your experience

1082
00:49:27,660 --> 00:49:30,090
by allowing the Athena service

1083
00:49:30,090 --> 00:49:33,900
to automatically store query
results in our own storage

1084
00:49:33,900 --> 00:49:35,250
rather than your S3 bucket.

1085
00:49:35,250 --> 00:49:39,420
So we're kind of taking over the headache

1086
00:49:39,420 --> 00:49:42,720
of having to manage query
result files for you.

1087
00:49:42,720 --> 00:49:45,960
And what's neat about this
is we store results for a day

1088
00:49:45,960 --> 00:49:49,380
at no cost to you and
automatically expire them

1089
00:49:49,380 --> 00:49:52,380
and delete them after that one-day period

1090
00:49:52,380 --> 00:49:54,720
with no action needed on your part.

1091
00:49:54,720 --> 00:49:57,000
So no longer you need to take action

1092
00:49:57,000 --> 00:50:00,480
to manage query's old
files or their lifecycle.

1093
00:50:00,480 --> 00:50:01,640
And what we also did with this feature

1094
00:50:01,640 --> 00:50:03,840
is we actually elevated the permissions

1095
00:50:03,840 --> 00:50:06,270
for query results to
be tied to work groups

1096
00:50:06,270 --> 00:50:07,590
instead of an S3 bucket.

1097
00:50:07,590 --> 00:50:10,150
So it should simplify permissions

1098
00:50:11,010 --> 00:50:13,140
for folks who are accessing Athena

1099
00:50:13,140 --> 00:50:14,640
through different work groups.

1100
00:50:16,350 --> 00:50:18,240
So it's been a really
busy year of launches

1101
00:50:18,240 --> 00:50:20,070
and we couldn't get to everything today,

1102
00:50:20,070 --> 00:50:22,320
but we wanted to make sure
there's some key launches

1103
00:50:22,320 --> 00:50:24,330
that you had kind of
at least visibility on

1104
00:50:24,330 --> 00:50:27,930
to check out while
you're here at re:Invent.

1105
00:50:27,930 --> 00:50:30,120
The first is Amazon SageMaker notebooks.

1106
00:50:30,120 --> 00:50:31,830
I don't know if you've seen the keynotes

1107
00:50:31,830 --> 00:50:33,570
or some of the other
announcements on this one.

1108
00:50:33,570 --> 00:50:35,040
This is a really cool feature.

1109
00:50:35,040 --> 00:50:37,530
I'm glad we had a chance
to talk about it today.

1110
00:50:37,530 --> 00:50:40,170
This is a brand new native notebook UI

1111
00:50:40,170 --> 00:50:42,510
in SageMaker Unified Studio.

1112
00:50:42,510 --> 00:50:45,930
It's integrated with Athena
SQL and Athena Spark Engines,

1113
00:50:45,930 --> 00:50:48,390
and deliver it to you as a single canvas,

1114
00:50:48,390 --> 00:50:49,890
providing you a data analysis

1115
00:50:49,890 --> 00:50:53,280
and development experience in one spot.

1116
00:50:53,280 --> 00:50:54,810
It's also multi-dialect.

1117
00:50:54,810 --> 00:50:57,600
So in one cell, you can
run a SQL query on Athena,

1118
00:50:57,600 --> 00:50:59,250
then you can run some Python code,

1119
00:50:59,250 --> 00:51:03,030
then you can run some Spark
code, all in one canvas,

1120
00:51:03,030 --> 00:51:06,060
with data frame access kind
of in between each cell.

1121
00:51:06,060 --> 00:51:08,460
So you kind of work with data in memory

1122
00:51:08,460 --> 00:51:10,170
and in a really snappy experience.

1123
00:51:10,170 --> 00:51:11,170
So it's really cool.

1124
00:51:12,240 --> 00:51:14,970
Best yet is you can work
alongside our data agents,

1125
00:51:14,970 --> 00:51:16,320
which is a built-in AI agent

1126
00:51:16,320 --> 00:51:17,910
that helps you do data analysis.

1127
00:51:17,910 --> 00:51:19,140
So it's a really great feature

1128
00:51:19,140 --> 00:51:21,300
if you're getting started
to learn some new data set

1129
00:51:21,300 --> 00:51:22,770
and want to extract some insights from it,

1130
00:51:22,770 --> 00:51:24,480
you can kind of task data agent

1131
00:51:24,480 --> 00:51:26,610
with helping you with some of that work.

1132
00:51:26,610 --> 00:51:29,280
And kind of behind the
scenes here, underneath,

1133
00:51:29,280 --> 00:51:32,250
we've upgraded the Athena
Spark engine to a 3.5.6,

1134
00:51:32,250 --> 00:51:34,410
and we've also given Spark Connect support

1135
00:51:34,410 --> 00:51:37,653
and Spark Live UI support to
the Athena Spark experience.

1136
00:51:39,810 --> 00:51:42,120
SMUS, as I mentioned,
SageMaker Unified Studio,

1137
00:51:42,120 --> 00:51:44,040
we've kind of continued on
the notebook experience.

1138
00:51:44,040 --> 00:51:46,380
We've also added a one-click onboarding

1139
00:51:46,380 --> 00:51:48,630
with IAM permission experience,

1140
00:51:48,630 --> 00:51:51,600
brought new AI power
column and metadata rules

1141
00:51:51,600 --> 00:51:53,550
and many other features
on our unified studio.

1142
00:51:53,550 --> 00:51:56,460
So if you get a chance to,
while you're here at re:Invent,

1143
00:51:56,460 --> 00:51:58,140
drop by some of the SageMaker sessions

1144
00:51:58,140 --> 00:51:59,590
to see what that's all about.

1145
00:52:00,750 --> 00:52:02,580
At re:Invent this year, you'll
probably also hear a lot

1146
00:52:02,580 --> 00:52:06,510
about trusted identity
propagation, also known as TIP.

1147
00:52:06,510 --> 00:52:08,520
This gets you a way to
authenticate end users

1148
00:52:08,520 --> 00:52:10,590
based on their corporate identities,

1149
00:52:10,590 --> 00:52:12,180
and have that identity propagate

1150
00:52:12,180 --> 00:52:15,030
to all of the AWS services
that they're using

1151
00:52:15,030 --> 00:52:16,950
when they're querying and analyzing data.

1152
00:52:16,950 --> 00:52:21,480
So that's Athena, S3, Glue, Lambda, KMS,

1153
00:52:21,480 --> 00:52:24,210
all the services that Athena will talk to

1154
00:52:24,210 --> 00:52:25,977
and querying your data.

1155
00:52:25,977 --> 00:52:28,200
And that gives you end-to-end auditability

1156
00:52:28,200 --> 00:52:30,810
on user actions tied to identity.

1157
00:52:30,810 --> 00:52:32,310
It also plugs into lake formation.

1158
00:52:32,310 --> 00:52:34,170
So you can define fine
grade access controls

1159
00:52:34,170 --> 00:52:36,060
based on corporate identity
and have those enforced

1160
00:52:36,060 --> 00:52:38,460
by engines like Athena and Spark.

1161
00:52:38,460 --> 00:52:40,500
And from a Redshift
and Athena perspective,

1162
00:52:40,500 --> 00:52:42,750
we've also carried TIP
support out to our drivers.

1163
00:52:42,750 --> 00:52:43,680
So if you're logging in

1164
00:52:43,680 --> 00:52:46,020
through third party
clients, like DataGrip,

1165
00:52:46,020 --> 00:52:49,027
you now have a browser-based
authentication flows

1166
00:52:49,027 --> 00:52:51,600
that use TIP to, again, authenticate

1167
00:52:51,600 --> 00:52:53,460
with your corporate identity.

1168
00:52:53,460 --> 00:52:55,680
And on MCP, you know a
growing number of customers

1169
00:52:55,680 --> 00:52:57,240
are developing AI agents,

1170
00:52:57,240 --> 00:53:00,180
and doing new and interesting
things with agents

1171
00:53:00,180 --> 00:53:01,590
to perform different tasks.

1172
00:53:01,590 --> 00:53:05,587
So we launched earlier this
year, several MCP servers,

1173
00:53:05,587 --> 00:53:09,870
Redshift, Athena, EMR, and
Glue just to name a few.

1174
00:53:09,870 --> 00:53:11,820
And we're seeing customers
build really cool things

1175
00:53:11,820 --> 00:53:12,653
on top of that.

1176
00:53:12,653 --> 00:53:14,880
For example, you know,
building agents to query

1177
00:53:14,880 --> 00:53:16,440
and analyze and extract insights

1178
00:53:16,440 --> 00:53:18,900
from your data lakes all autonomously.

1179
00:53:18,900 --> 00:53:21,093
So really cool progress on MCP.

1180
00:53:22,470 --> 00:53:24,420
So as we wrap up, if you wanna learn more

1181
00:53:24,420 --> 00:53:25,710
about what we shared today,

1182
00:53:25,710 --> 00:53:28,935
definitely scan these QR
codes, get your phones out.

1183
00:53:28,935 --> 00:53:31,650
A lot of really awesome blogs here.

1184
00:53:31,650 --> 00:53:34,470
One on Redshift Serverless
reservations and Iceberg Rights.

1185
00:53:34,470 --> 00:53:36,300
You should definitely check out.

1186
00:53:36,300 --> 00:53:38,130
There's one on data transformation

1187
00:53:38,130 --> 00:53:39,690
with Athena and S3 Tables.

1188
00:53:39,690 --> 00:53:40,523
So as you think

1189
00:53:40,523 --> 00:53:42,890
about that Create Table
as Select experience

1190
00:53:42,890 --> 00:53:44,430
we talked about earlier,

1191
00:53:44,430 --> 00:53:45,780
that's a great blog to check out

1192
00:53:45,780 --> 00:53:47,940
with a lot of practical takeaways.

1193
00:53:47,940 --> 00:53:50,100
And we've also included
the Odin deep dive deck.

1194
00:53:50,100 --> 00:53:52,620
So our folks at Twilio and
our customers at Twilio,

1195
00:53:52,620 --> 00:53:55,200
who've built and support
the Odin platform,

1196
00:53:55,200 --> 00:53:58,200
they've got a really neat blog
that describes their journey

1197
00:53:58,200 --> 00:54:00,950
and building that on top of
Athena, which we recommend.

1198
00:54:01,800 --> 00:54:03,420
And then we hope that you've, you know,

1199
00:54:03,420 --> 00:54:06,750
taken the learnings like from
our session today further

1200
00:54:06,750 --> 00:54:09,660
and that you can kind of leverage other,

1201
00:54:09,660 --> 00:54:12,330
you know, learning and
knowledge capabilities

1202
00:54:12,330 --> 00:54:15,300
and resources that we have here at AWS.

1203
00:54:15,300 --> 00:54:17,100
For that, we have AWS Skill Builder,

1204
00:54:17,100 --> 00:54:18,780
tons of great resources for you to learn,

1205
00:54:18,780 --> 00:54:20,610
practice, and get AWS-certified.

1206
00:54:20,610 --> 00:54:21,447
So definitely check that out

1207
00:54:21,447 --> 00:54:23,730
and share that with your teammates.

1208
00:54:23,730 --> 00:54:26,760
And so that about wraps
up the 206 session,

1209
00:54:26,760 --> 00:54:28,440
What's New in Redshift and Athena.

1210
00:54:28,440 --> 00:54:30,510
Definitely on behalf of the AWS team,

1211
00:54:30,510 --> 00:54:32,040
I wanna send a thank you to Sean at Twilio

1212
00:54:32,040 --> 00:54:33,720
for sharing his journey with us,

1213
00:54:33,720 --> 00:54:35,340
and Imran for sharing the insights

1214
00:54:35,340 --> 00:54:37,140
on the exciting Redshift launches.

1215
00:54:37,140 --> 00:54:39,510
So last but not least,
thank you for attending

1216
00:54:39,510 --> 00:54:40,920
and spending the hour with us today.

1217
00:54:40,920 --> 00:54:42,120
We'd love to hear your feedback,

1218
00:54:42,120 --> 00:54:44,610
so pop into the events app
and give us your rating,

1219
00:54:44,610 --> 00:54:46,350
and have a great rest of the re:Invent.

1220
00:54:46,350 --> 00:54:47,491
Thanks.

1221
00:54:47,491 --> 00:54:49,881
(audience applauds)

