1
00:00:01,470 --> 00:00:04,383
- Here's the paradox we're facing in 2025.

2
00:00:05,250 --> 00:00:06,330
We are building AI agents

3
00:00:06,330 --> 00:00:09,047
that can reason, act,
and plan autonomously.

4
00:00:09,047 --> 00:00:10,980
Agents that should be able to achieve

5
00:00:10,980 --> 00:00:13,102
your business outcomes,
optimize business operations,

6
00:00:13,102 --> 00:00:15,540
and also make real time decisions.

7
00:00:15,540 --> 00:00:17,578
Yet most organizations
are sitting on petabytes,

8
00:00:17,578 --> 00:00:19,680
sometimes exabytes of data,

9
00:00:19,680 --> 00:00:22,311
that their agent simply
can't use effectively.

10
00:00:22,311 --> 00:00:26,100
Your customer service logs
in S3, product documentation,

11
00:00:26,100 --> 00:00:27,701
some sort of a distributed file system,

12
00:00:27,701 --> 00:00:30,498
years of transaction history in S3,

13
00:00:30,498 --> 00:00:32,407
data that has been perfectly stored,

14
00:00:32,407 --> 00:00:35,430
governed, and backed up.

15
00:00:35,430 --> 00:00:36,864
But there's a gap, a critical gap,

16
00:00:36,864 --> 00:00:39,300
in terms of where the data sits

17
00:00:39,300 --> 00:00:41,253
and how your agent needs to access it.

18
00:00:42,300 --> 00:00:43,500
Here's the irony.

19
00:00:43,500 --> 00:00:44,957
The data is already there.

20
00:00:44,957 --> 00:00:47,220
You've invested in terms of storing it,

21
00:00:47,220 --> 00:00:49,470
backing it up, and protecting it.

22
00:00:49,470 --> 00:00:50,880
But when the agent needs to recall

23
00:00:50,880 --> 00:00:52,856
a customer interaction from years ago,

24
00:00:52,856 --> 00:00:56,460
or find a pattern across
millions of transaction history,

25
00:00:56,460 --> 00:00:57,960
or tap into institution knowledge

26
00:00:57,960 --> 00:01:00,609
when it needs to make a
decision, it hits a wall

27
00:01:00,609 --> 00:01:04,050
because agents don't just need data.

28
00:01:04,050 --> 00:01:06,018
They need memory, they need context,

29
00:01:06,018 --> 00:01:09,510
they need to be able
to learn, collaborate,

30
00:01:09,510 --> 00:01:10,683
and adapt in real time.

31
00:01:11,790 --> 00:01:13,260
The breakthrough everyone's chasing

32
00:01:13,260 --> 00:01:15,270
isn't about building smarter models.

33
00:01:15,270 --> 00:01:16,636
We are already getting
pretty good at that.

34
00:01:16,636 --> 00:01:18,354
The real breakthrough lies

35
00:01:18,354 --> 00:01:20,793
when your existing data
becomes agent-ready.

36
00:01:22,350 --> 00:01:24,991
So turning passive storage
into active memory,

37
00:01:24,991 --> 00:01:26,813
transforming archived information

38
00:01:26,813 --> 00:01:28,756
into accessible intelligence

39
00:01:28,756 --> 00:01:31,233
that your agents can actually work with,

40
00:01:32,400 --> 00:01:35,199
and that's exactly what we're here today

41
00:01:35,199 --> 00:01:37,140
because the most powerful agent

42
00:01:37,140 --> 00:01:40,500
is only as good as the data
architecture behind it.

43
00:01:40,500 --> 00:01:42,750
So let's talk about
putting your data to work,

44
00:01:42,750 --> 00:01:45,600
but not just for analytical or compliance,

45
00:01:45,600 --> 00:01:47,790
but for AI agents that are shaping up

46
00:01:47,790 --> 00:01:50,670
the next generation of
applications in enterprises.

47
00:01:50,670 --> 00:01:51,720
I'm Venkata Sistla.

48
00:01:51,720 --> 00:01:54,529
I'm a senior worldwide
specialist solutions architect

49
00:01:54,529 --> 00:01:55,362
here at AWS.

50
00:01:57,000 --> 00:01:58,650
So from today's agenda perspective,

51
00:01:58,650 --> 00:01:59,700
we'll cover these topics.

52
00:01:59,700 --> 00:02:01,290
So first of all, we'll start off

53
00:02:01,290 --> 00:02:02,509
with covering a few fundamentals

54
00:02:02,509 --> 00:02:05,970
in terms of what makes
an agent truly agentic

55
00:02:05,970 --> 00:02:07,981
versus just another simple chat bot.

56
00:02:07,981 --> 00:02:10,074
Then we'll dive deep into what it takes

57
00:02:10,074 --> 00:02:12,420
to build context-aware agents.

58
00:02:12,420 --> 00:02:15,550
We'll also explore
building scalable agents

59
00:02:16,475 --> 00:02:18,390
using managed versus
self-managed approach.

60
00:02:18,390 --> 00:02:20,760
Then we'll dive deeper
into how AWS storage

61
00:02:20,760 --> 00:02:23,523
becomes the external
brain for your AI agents.

62
00:02:24,630 --> 00:02:25,530
Finally, we'll leave you

63
00:02:25,530 --> 00:02:27,439
with a few architectural
examples and references

64
00:02:27,439 --> 00:02:30,301
and a few resources that you
can take away after the session

65
00:02:30,301 --> 00:02:32,193
so you can learn and dive deeper.

66
00:02:35,556 --> 00:02:38,280
These numbers should grab your attention

67
00:02:38,280 --> 00:02:39,780
'cause we are looking at
a massive transformation

68
00:02:39,780 --> 00:02:41,700
that's happening right now.

69
00:02:41,700 --> 00:02:43,269
Gartner predicts by 2028

70
00:02:43,269 --> 00:02:45,330
that one in three enterprise applications

71
00:02:45,330 --> 00:02:46,758
will have agentic AI.

72
00:02:46,758 --> 00:02:50,013
That's nearly up from
less than 1% from 2024,

73
00:02:51,114 --> 00:02:54,240
and we are also talking about
$120 million transformation

74
00:02:54,240 --> 00:02:55,740
that's happening right now.

75
00:02:55,740 --> 00:02:58,414
Sorry, $120 billion market by 2030,

76
00:02:58,414 --> 00:03:00,765
which tells you that
this isn't just a hype

77
00:03:00,765 --> 00:03:03,558
and enterprises are making
serious investments,

78
00:03:03,558 --> 00:03:06,525
and I'm also seeing this
firsthand from my customers

79
00:03:06,525 --> 00:03:09,210
where they're transitioning from building

80
00:03:09,210 --> 00:03:12,690
simple Q and H ad bots to
really complex multi-agents

81
00:03:12,690 --> 00:03:16,290
as part of their enterprises
to solve complex problems.

82
00:03:16,290 --> 00:03:17,925
The question isn't
whether this will happen,

83
00:03:17,925 --> 00:03:20,823
rather would you be ready when it happens?

84
00:03:21,754 --> 00:03:23,730
And some of the customers
that I've worked with

85
00:03:23,730 --> 00:03:27,300
include Ericsson, Thomson
Reuters, Experian, so on,

86
00:03:27,300 --> 00:03:29,550
who are actually going really deep in

87
00:03:29,550 --> 00:03:31,740
in terms of deploying
agentic architectures

88
00:03:31,740 --> 00:03:33,790
as part of their enterprise applications.

89
00:03:36,130 --> 00:03:40,650
Agentic AI promises to enhance
productivity and efficiency.

90
00:03:40,650 --> 00:03:41,506
You know, taking on problems

91
00:03:41,506 --> 00:03:45,644
that were difficult to be
solved by traditional software,

92
00:03:45,644 --> 00:03:49,500
simplifying integration, and
also finding answers and data

93
00:03:49,500 --> 00:03:51,050
that were previously invisible.

94
00:03:51,990 --> 00:03:54,540
Agentic AI systems autonomously decide

95
00:03:54,540 --> 00:03:56,220
how to accomplish a task,

96
00:03:56,220 --> 00:03:58,710
taking on prompts in the
form of a natural language,

97
00:03:58,710 --> 00:03:59,860
and adapting their plan

98
00:04:01,050 --> 00:04:02,550
as they're learning more new information.

99
00:04:02,550 --> 00:04:04,450
But there is still a human in the mix.

100
00:04:05,490 --> 00:04:08,790
So human essentially gives
the overall sets the goal

101
00:04:08,790 --> 00:04:09,930
in the form of natural language

102
00:04:09,930 --> 00:04:12,138
and exercises supervisory control.

103
00:04:12,138 --> 00:04:14,265
So what makes it truly special

104
00:04:14,265 --> 00:04:18,150
is their ability to sort of
learn and improve over time.

105
00:04:18,150 --> 00:04:20,431
So every interaction, every new

106
00:04:20,431 --> 00:04:23,280
I guess piece of information
that you give it to the agent,

107
00:04:23,280 --> 00:04:24,698
it essentially stores it in memory

108
00:04:24,698 --> 00:04:27,363
and then adapts for its
future conversation.

109
00:04:30,960 --> 00:04:32,070
This diagram illustrates

110
00:04:32,070 --> 00:04:35,422
what transforms a simple LLM
into an autonomous agent,

111
00:04:35,422 --> 00:04:38,013
which is capable of
solving complex problems.

112
00:04:38,880 --> 00:04:41,130
The key difference here is autonomy

113
00:04:41,130 --> 00:04:43,710
because these systems don't
just respond to prompts,

114
00:04:43,710 --> 00:04:45,150
but they're actively working

115
00:04:45,150 --> 00:04:48,720
towards accomplishing towards
a specific objective or goal

116
00:04:48,720 --> 00:04:49,623
set by the human.

117
00:04:50,833 --> 00:04:52,980
So going with the components,

118
00:04:52,980 --> 00:04:54,360
the first we have is LLM.

119
00:04:54,360 --> 00:04:56,610
LLM's more capable or responsible

120
00:04:56,610 --> 00:05:00,330
for reasoning capabilities.

121
00:05:00,330 --> 00:05:02,429
So it'll give you the
understanding of the intent,

122
00:05:02,429 --> 00:05:05,910
as well as making
decisions about next steps.

123
00:05:05,910 --> 00:05:07,084
Second, you have tools.

124
00:05:07,084 --> 00:05:08,824
Tools give ability the agent

125
00:05:08,824 --> 00:05:11,439
to interact with internal
and external environment,

126
00:05:11,439 --> 00:05:15,600
whether that's extracting data,
executing certain functions,

127
00:05:15,600 --> 00:05:17,940
or also interacting with systems.

128
00:05:17,940 --> 00:05:19,290
Third, memory.

129
00:05:19,290 --> 00:05:21,510
Memory ensures continuity.

130
00:05:21,510 --> 00:05:24,480
Agent doesn't need to start
from scratch all the time.

131
00:05:24,480 --> 00:05:27,333
It essentially builds or
resumes from where it left off.

132
00:05:28,170 --> 00:05:30,282
Third is context awareness.

133
00:05:30,282 --> 00:05:33,120
Essentially allows the agent
to understand its environment

134
00:05:33,120 --> 00:05:35,340
so that it can adapt its behavior

135
00:05:35,340 --> 00:05:37,860
based on who it's interacting with.

136
00:05:37,860 --> 00:05:39,930
Finally, prompt engineering.

137
00:05:39,930 --> 00:05:43,320
Prompt engineering defines
agent's role, capabilities,

138
00:05:43,320 --> 00:05:46,533
and constraints that it
needs to operate with.

139
00:05:46,533 --> 00:05:48,120
What makes this powerful

140
00:05:48,120 --> 00:05:51,300
is the shift in how we interact with AI

141
00:05:51,300 --> 00:05:53,010
'cause instead of
step-by-step instructions

142
00:05:53,010 --> 00:05:55,818
that we are used to or over
the last couple of years ago,

143
00:05:55,818 --> 00:05:57,540
you're now providing the oral goal

144
00:05:57,540 --> 00:05:59,160
in the form of natural language,

145
00:05:59,160 --> 00:06:02,490
and the agent then autonomously
plans the required steps

146
00:06:02,490 --> 00:06:05,343
to achieve that goal, and
continues to deliver so.

147
00:06:09,466 --> 00:06:11,766
This is the million dollar question

148
00:06:11,766 --> 00:06:14,700
that every organization's
grappling with right now.

149
00:06:14,700 --> 00:06:18,180
Most context-aware agents
don't just need a good LLM.

150
00:06:18,180 --> 00:06:20,280
That's just table stakes.

151
00:06:20,280 --> 00:06:22,962
You need persistent memory,
real time data access,

152
00:06:22,962 --> 00:06:25,893
and the ability to learn
and adapt over time.

153
00:06:26,730 --> 00:06:28,620
Most importantly, you need all of this

154
00:06:28,620 --> 00:06:31,620
with enterprise scale,
enterprise grade scale,

155
00:06:31,620 --> 00:06:32,973
security and governance.

156
00:06:33,960 --> 00:06:36,860
Let's dive into what this
actually looks like in practice.

157
00:06:40,239 --> 00:06:44,887
Agent memory is a computational
exo cortex for AI agents,

158
00:06:44,887 --> 00:06:47,010
which means it's a system

159
00:06:47,010 --> 00:06:50,750
that combines LLM's built-in
memory with persistent storage

160
00:06:50,750 --> 00:06:55,750
so that it's able to remember,
retrieve, and adapt over time

161
00:06:55,830 --> 00:06:57,990
with past experiences
and the new information

162
00:06:57,990 --> 00:06:59,706
that it's trying to learn.

163
00:06:59,706 --> 00:07:01,200
Just like human memory,

164
00:07:01,200 --> 00:07:04,140
it helps agents to build
knowledge over time,

165
00:07:04,140 --> 00:07:06,270
maintain context across conversations,

166
00:07:06,270 --> 00:07:10,565
also learn behavior adaptations
based on interactions.

167
00:07:10,565 --> 00:07:12,765
Transforming from one-off responders

168
00:07:12,765 --> 00:07:15,093
to reliable and truly intelligent systems.

169
00:07:16,650 --> 00:07:19,185
Our customer conversations
show that one-off interactions

170
00:07:19,185 --> 00:07:22,830
are really good at capturing

171
00:07:22,830 --> 00:07:24,411
the initial or the first of impression,

172
00:07:24,411 --> 00:07:26,869
but the real value comes from the agents

173
00:07:26,869 --> 00:07:30,440
having ability to remember the
context, learn from history,

174
00:07:30,440 --> 00:07:33,900
and also adapt the overall experience.

175
00:07:33,900 --> 00:07:36,210
So memory management isn't just a feature.

176
00:07:36,210 --> 00:07:37,380
It's the core infrastructure

177
00:07:37,380 --> 00:07:40,081
that turns reactive agents
into truly intelligent systems

178
00:07:40,081 --> 00:07:43,113
that deliver sustained
value for your enterprises.

179
00:07:47,190 --> 00:07:48,860
Let me show you a real world example

180
00:07:48,860 --> 00:07:52,680
that perfectly illustrate
why memory matters.

181
00:07:52,680 --> 00:07:54,706
So the difference in user
experience is really dramatic,

182
00:07:54,706 --> 00:07:58,023
and that actually translates
directly to the business value.

183
00:07:58,860 --> 00:08:00,930
Pay attention to how the
customer conversation...

184
00:08:00,930 --> 00:08:02,460
Sorry, how this particular
conversation flow

185
00:08:02,460 --> 00:08:05,010
changes completely when the
agent's able to remember

186
00:08:05,010 --> 00:08:07,353
the past conversation and build upon.

187
00:08:08,911 --> 00:08:10,380
Without agent memory,

188
00:08:10,380 --> 00:08:12,240
there are several critical limitations

189
00:08:12,240 --> 00:08:14,010
that we will end up hitting.

190
00:08:14,010 --> 00:08:17,490
First, inability to maintain
conversation continuity.

191
00:08:17,490 --> 00:08:21,003
It cannot really build upon or
reference previous dialogue.

192
00:08:21,960 --> 00:08:24,030
No behavioral adaptation.

193
00:08:24,030 --> 00:08:26,312
So essentially, it cannot
learn user feedback

194
00:08:26,312 --> 00:08:30,300
or adjust approaches
based on your preferences.

195
00:08:30,300 --> 00:08:32,730
Third, lack of personal objectives.

196
00:08:32,730 --> 00:08:35,040
So without personal objectives,

197
00:08:35,040 --> 00:08:38,081
then it cannot really
sustain the overall session

198
00:08:38,081 --> 00:08:40,413
or achieve the goal set by you.

199
00:08:41,251 --> 00:08:43,950
And lastly, missing personalization.

200
00:08:43,950 --> 00:08:46,500
So it cannot really develop
user specific preferences,

201
00:08:46,500 --> 00:08:48,330
and I've got some examples
in the future slides

202
00:08:48,330 --> 00:08:51,510
that will demonstrate
why your personalization

203
00:08:51,510 --> 00:08:54,243
is very important trait for AI agents.

204
00:08:55,200 --> 00:08:58,380
There's a research that was
done by Microsoft and Salesforce

205
00:08:58,380 --> 00:09:00,270
and the study's called, LLMs get lost

206
00:09:00,270 --> 00:09:02,823
in multi-turn conversations.

207
00:09:03,763 --> 00:09:06,690
So the study found that most of the LLMs

208
00:09:06,690 --> 00:09:08,907
experience significant performance drop

209
00:09:08,907 --> 00:09:13,783
in extended conversations
primarily because those LLMs

210
00:09:13,783 --> 00:09:17,040
make premature assumptions very early on,

211
00:09:17,040 --> 00:09:19,530
and they essentially fail to recover

212
00:09:19,530 --> 00:09:22,017
when they're proved wrong
on those assumptions.

213
00:09:22,017 --> 00:09:23,580
That exactly goes back

214
00:09:23,580 --> 00:09:25,650
to the conversation continuity limitation

215
00:09:25,650 --> 00:09:27,100
that we just discussed above.

216
00:09:32,250 --> 00:09:33,840
Here's another frustrating example

217
00:09:33,840 --> 00:09:35,733
of, you know, agents without memory.

218
00:09:36,570 --> 00:09:38,583
Every conversation starts from scratch.

219
00:09:39,422 --> 00:09:42,270
Notice how the agent asked
for the iPhone model twice

220
00:09:42,270 --> 00:09:43,620
within just two days apart.

221
00:09:45,150 --> 00:09:46,740
This creates a terrible user experience

222
00:09:46,740 --> 00:09:49,190
and feels the agent really
robotic and unhelpful.

223
00:09:50,055 --> 00:09:52,297
I love this quote which says, you know,

224
00:09:52,297 --> 00:09:54,554
"AI agent without memory
is like a goldfish.

225
00:09:54,554 --> 00:09:56,907
Everything's new every three seconds."

226
00:10:00,934 --> 00:10:02,910
When we implement proper memory,

227
00:10:02,910 --> 00:10:05,037
we unlock three key capabilities

228
00:10:05,037 --> 00:10:07,383
that transform the user experience.

229
00:10:08,310 --> 00:10:10,107
First, contextual intelligence,

230
00:10:10,107 --> 00:10:14,760
meaning the agent not just
understands what you're asking,

231
00:10:14,760 --> 00:10:16,010
but why you're asking it.

232
00:10:17,280 --> 00:10:19,410
Second, user preferences.

233
00:10:19,410 --> 00:10:21,702
It truly personalizes interactions.

234
00:10:21,702 --> 00:10:24,409
The agent's able to remember or adapt

235
00:10:24,409 --> 00:10:26,853
based on how you work and communicate.

236
00:10:27,948 --> 00:10:30,300
Third is knowledge retention.

237
00:10:30,300 --> 00:10:32,670
So with the continued interactions,

238
00:10:32,670 --> 00:10:35,730
agent builds its own knowledge
base about the world,

239
00:10:35,730 --> 00:10:37,896
the facts, the things, the participants,

240
00:10:37,896 --> 00:10:41,430
and it gets essentially
smarter with every interaction.

241
00:10:41,430 --> 00:10:43,140
So these are nice to have features.

242
00:10:43,140 --> 00:10:45,890
They're really essential for
enterprise level adoption.

243
00:10:49,015 --> 00:10:51,813
So now let's dive a little
deeper into agentic memory.

244
00:10:52,920 --> 00:10:53,969
Understanding these core concepts

245
00:10:53,969 --> 00:10:57,569
will help you design AI
systems to work at scale,

246
00:10:57,569 --> 00:10:59,370
and think of it also

247
00:10:59,370 --> 00:11:01,560
you're building neural
pathways for your AI

248
00:11:01,560 --> 00:11:03,720
'cause if you get this right,

249
00:11:03,720 --> 00:11:06,330
everything else from an
AI agentic deployment

250
00:11:06,330 --> 00:11:07,330
becomes much easier.

251
00:11:08,393 --> 00:11:11,130
Agentic memory is really critical,

252
00:11:11,130 --> 00:11:14,340
especially when you're building
personalized AI systems

253
00:11:14,340 --> 00:11:16,124
'cause it enables adaptive learning

254
00:11:16,124 --> 00:11:18,582
through, you know, each interaction,

255
00:11:18,582 --> 00:11:21,480
allows agents to understand
individual preferences,

256
00:11:21,480 --> 00:11:24,543
communication styles, and
also behavioral patterns.

257
00:11:25,440 --> 00:11:27,492
Without access to persistent memory,

258
00:11:27,492 --> 00:11:29,489
even the most sophisticated agents

259
00:11:29,489 --> 00:11:33,134
or chat bots cannot really provide

260
00:11:33,134 --> 00:11:34,950
the personalized user experience

261
00:11:34,950 --> 00:11:36,900
that we are demanding
from this day and age

262
00:11:36,900 --> 00:11:38,223
of AI applications.

263
00:11:40,290 --> 00:11:42,502
This is probably a personal reflection

264
00:11:42,502 --> 00:11:46,500
of me looking at the last couple of years.

265
00:11:46,500 --> 00:11:48,300
You know, GPT models have provided

266
00:11:48,300 --> 00:11:50,880
broad general knowledge to begin with.

267
00:11:50,880 --> 00:11:53,662
So we quickly introduced RAG
to ground those GPT models

268
00:11:53,662 --> 00:11:56,133
to our proprietary data.

269
00:11:57,060 --> 00:11:58,680
But what we quickly realized was

270
00:11:58,680 --> 00:12:00,450
as RAG architecture scaled,

271
00:12:00,450 --> 00:12:02,160
we encountered that there is a limitation

272
00:12:02,160 --> 00:12:04,020
with finite context windows,

273
00:12:04,020 --> 00:12:06,900
which limited us with the
conversation continuity problem

274
00:12:06,900 --> 00:12:09,720
that we, you know, tried
to uncover previously,

275
00:12:09,720 --> 00:12:12,150
as well as personalization
in the oral experience

276
00:12:12,150 --> 00:12:14,280
of how we interact with AI.

277
00:12:14,280 --> 00:12:17,294
So agent memory essentially
extends the rack capabilities

278
00:12:17,294 --> 00:12:21,180
by providing persistent
memory across sessions,

279
00:12:21,180 --> 00:12:25,140
enabling agents to build context
over multiple interactions,

280
00:12:25,140 --> 00:12:26,760
and delivering really relevant

281
00:12:26,760 --> 00:12:28,920
and personalized experience to users.

282
00:12:28,920 --> 00:12:33,120
So the RAG concept doesn't go away,

283
00:12:33,120 --> 00:12:34,770
it is essentially getting extended

284
00:12:34,770 --> 00:12:36,720
into the concept of agent memory

285
00:12:36,720 --> 00:12:39,573
where it's trying to give
us multiple benefits.

286
00:12:40,876 --> 00:12:43,859
Data retrieval becomes a fundamental

287
00:12:43,859 --> 00:12:45,723
to agent's memory architecture.

288
00:12:46,903 --> 00:12:50,310
Effective systems must
intelligently surface

289
00:12:50,310 --> 00:12:52,980
the relevant context from
vast stores of user stories

290
00:12:52,980 --> 00:12:54,644
and past interaction data.

291
00:12:54,644 --> 00:12:56,970
So this requires sophisticated algorithms

292
00:12:56,970 --> 00:13:00,358
to precisely identify which
elements of past conversation

293
00:13:00,358 --> 00:13:03,098
would really supplement
the current context

294
00:13:03,098 --> 00:13:05,337
of existing interaction,

295
00:13:05,337 --> 00:13:09,333
enabling truly adaptive learning
that compounds over time.

296
00:13:11,006 --> 00:13:15,420
And advanced systems still
require higher order form

297
00:13:15,420 --> 00:13:19,031
of information retrieval
organization and retention

298
00:13:19,031 --> 00:13:21,390
that mirrors human cognitive process,

299
00:13:21,390 --> 00:13:23,433
which we now define as agent's memory.

300
00:13:28,379 --> 00:13:30,802
So there are two
fundamental types of memory

301
00:13:30,802 --> 00:13:32,523
that every agent needs.

302
00:13:33,360 --> 00:13:37,710
Short term memory it's
like a RAM in a computer

303
00:13:37,710 --> 00:13:40,500
which is mostly temporary
and session based.

304
00:13:40,500 --> 00:13:42,030
Long term memory is like a hard drive,

305
00:13:42,030 --> 00:13:43,230
which is more persistent

306
00:13:43,230 --> 00:13:45,130
and supplements evolutionary learning.

307
00:13:46,230 --> 00:13:47,850
So this dual memory architecture

308
00:13:47,850 --> 00:13:50,010
enables both immediate responsiveness

309
00:13:50,010 --> 00:13:52,060
and also sustained improvement over time.

310
00:13:54,480 --> 00:13:55,980
Long term memory is also crucial

311
00:13:55,980 --> 00:13:58,620
for enabling AI self-evolution

312
00:13:58,620 --> 00:14:00,780
where agents automatically learn, adapt,

313
00:14:00,780 --> 00:14:01,890
and refine their reasoning

314
00:14:01,890 --> 00:14:06,093
based on accumulated examples
and interactions of data.

315
00:14:07,080 --> 00:14:09,300
So by incorporating long-term memory,

316
00:14:09,300 --> 00:14:11,257
AI agents becomes like adaptive teammates

317
00:14:11,257 --> 00:14:13,320
where they're really getting specialized

318
00:14:13,320 --> 00:14:15,567
in their skill and the knowledge over time

319
00:14:15,567 --> 00:14:17,640
as a subject matter experts

320
00:14:17,640 --> 00:14:19,690
just like humans as we would evolve into.

321
00:14:23,076 --> 00:14:24,750
So let's dive a little deeper

322
00:14:24,750 --> 00:14:26,500
into the short term memory concept.

323
00:14:27,450 --> 00:14:28,283
So short term memory

324
00:14:28,283 --> 00:14:30,630
is all about maintaining
the conversation flow

325
00:14:30,630 --> 00:14:32,223
and immediate context.

326
00:14:33,390 --> 00:14:35,572
So in this particular example,

327
00:14:35,572 --> 00:14:37,980
see how the agent's able to
remember the iPhone model

328
00:14:38,856 --> 00:14:40,620
from the earlier conversation

329
00:14:40,620 --> 00:14:42,908
and provide really
specific help to the user.

330
00:14:42,908 --> 00:14:44,340
So this requires storing

331
00:14:44,340 --> 00:14:47,610
and retrieving conversation
history in real time.

332
00:14:47,610 --> 00:14:51,630
The agent needs to quickly
access recent messages

333
00:14:51,630 --> 00:14:54,001
and understand the current context,

334
00:14:54,001 --> 00:14:57,213
and maintain that state
across multiple interactions.

335
00:14:58,387 --> 00:14:59,430
From a storage perspective,

336
00:14:59,430 --> 00:15:01,620
this means that we require really fast

337
00:15:01,620 --> 00:15:03,483
and low latency access to the data.

338
00:15:05,377 --> 00:15:08,283
Think of this as agents working memory.

339
00:15:09,390 --> 00:15:11,808
It needs immediately accessible

340
00:15:11,808 --> 00:15:14,793
but also doesn't necessarily
need to persist forever.

341
00:15:15,930 --> 00:15:17,880
Short-term memory units last anywhere

342
00:15:17,880 --> 00:15:22,382
from seconds to days depending
upon the application needs.

343
00:15:22,382 --> 00:15:24,570
So there are two terminologies

344
00:15:24,570 --> 00:15:26,680
when we mention short-term memory.

345
00:15:26,680 --> 00:15:30,870
There is working memory and
there is short-term memory.

346
00:15:30,870 --> 00:15:33,850
Often the terms short-term
memory and working memory,

347
00:15:33,850 --> 00:15:36,656
sorry, working memory
are interchangeably used,

348
00:15:36,656 --> 00:15:38,553
but there is a clear distinction.

349
00:15:40,230 --> 00:15:43,020
Working memory is a special
type of short-term memory

350
00:15:43,020 --> 00:15:44,160
that is used specifically

351
00:15:44,160 --> 00:15:48,183
for actively processing
information for that specific task.

352
00:15:49,230 --> 00:15:51,720
Short term memory is a
broader temporary storage

353
00:15:51,720 --> 00:15:52,893
for the oral session.

354
00:15:54,090 --> 00:15:56,823
So not all working memory
is short-term memory,

355
00:15:57,818 --> 00:16:00,543
but all short term
memory is working memory.

356
00:16:01,674 --> 00:16:04,500
So working memory is the doing part.

357
00:16:04,500 --> 00:16:05,880
On the other hand, short term memory

358
00:16:05,880 --> 00:16:07,730
is the holding part for that session.

359
00:16:14,160 --> 00:16:16,050
Episodic memory is the agent's record

360
00:16:16,050 --> 00:16:18,780
of specific events and interactions,

361
00:16:18,780 --> 00:16:20,370
just like human's personal memory

362
00:16:20,370 --> 00:16:22,893
of our own life experiences.

363
00:16:23,820 --> 00:16:25,500
It stores conversation history,

364
00:16:25,500 --> 00:16:26,841
summaries of important events,

365
00:16:26,841 --> 00:16:28,770
and individual occurrences

366
00:16:28,770 --> 00:16:30,510
with specifically attached metadata

367
00:16:30,510 --> 00:16:32,523
such as timestamps and participants.

368
00:16:33,780 --> 00:16:36,583
Conversation memory is a
specific type of episodic memory

369
00:16:36,583 --> 00:16:39,297
that is essentially
focused on chat history

370
00:16:39,297 --> 00:16:41,403
or user preferences that you see here.

371
00:16:42,870 --> 00:16:45,120
It keeps a complete
record of conversations,

372
00:16:45,120 --> 00:16:47,832
who said what and when,
and also helping agents

373
00:16:47,832 --> 00:16:51,690
staying consistent
throughout interactions,

374
00:16:51,690 --> 00:16:53,070
and it is also able to refer back

375
00:16:53,070 --> 00:16:54,900
to the earlier parts of the conversation

376
00:16:54,900 --> 00:16:59,023
and really, you know, provide
the contextualized responses

377
00:16:59,023 --> 00:17:01,503
as part of the interaction.

378
00:17:02,340 --> 00:17:05,140
So the system continuously
updates its memory blocks

379
00:17:06,030 --> 00:17:07,773
as the conversation progresses.

380
00:17:09,330 --> 00:17:13,680
So in short, episodic memory
is the what happened storage

381
00:17:13,680 --> 00:17:15,510
and the conversational memory

382
00:17:15,510 --> 00:17:17,583
is the what we talked about storage.

383
00:17:24,330 --> 00:17:25,347
So long term memories

384
00:17:25,347 --> 00:17:27,540
are where things get really interesting,

385
00:17:27,540 --> 00:17:30,887
and this is about learning
and personalization over time.

386
00:17:30,887 --> 00:17:32,730
Notice how the agent's able to remember

387
00:17:32,730 --> 00:17:35,130
the specific preferences
from few days ago?

388
00:17:35,130 --> 00:17:39,272
It is able to remember the
brand, the employee discount,

389
00:17:39,272 --> 00:17:42,210
and also the color of the headphones.

390
00:17:42,210 --> 00:17:44,130
So this isn't just storing data.

391
00:17:44,130 --> 00:17:47,250
It's about extracting and
organizing those insights

392
00:17:47,250 --> 00:17:49,778
that can be applied to
the future interactions.

393
00:17:49,778 --> 00:17:51,960
So essentially, agent builds up

394
00:17:51,960 --> 00:17:54,210
a profile of user preferences

395
00:17:54,210 --> 00:17:56,640
that gets richer and
more accurate over time

396
00:17:56,640 --> 00:17:58,620
with every interaction.

397
00:17:58,620 --> 00:18:00,330
So from a technical standpoint,

398
00:18:00,330 --> 00:18:02,904
this requires a very sophisticated

399
00:18:02,904 --> 00:18:06,630
storage and retrieval
system that can quickly find

400
00:18:06,630 --> 00:18:10,753
relevant preferences based
upon the given context.

401
00:18:10,753 --> 00:18:14,190
So this is where the vector
databases and semantic search

402
00:18:14,190 --> 00:18:17,343
becomes really crucial for
the oral agentic performance.

403
00:18:20,096 --> 00:18:22,293
Next we have semantic memory.

404
00:18:23,340 --> 00:18:27,120
So semantic memory is an agent's
organized knowledge base.

405
00:18:27,120 --> 00:18:29,298
Everything the agent
knows about the world,

406
00:18:29,298 --> 00:18:31,898
including the facts, the concepts,

407
00:18:31,898 --> 00:18:34,203
how things relate to each other.

408
00:18:35,220 --> 00:18:38,100
This includes knowledge bases.

409
00:18:38,100 --> 00:18:40,980
Essentially, that's a collection
of factual information.

410
00:18:40,980 --> 00:18:43,650
Entity memory, which is specific details

411
00:18:43,650 --> 00:18:46,230
about people's, facts, and things.

412
00:18:46,230 --> 00:18:49,470
Third is persona memory,
which is role-based knowledge

413
00:18:49,470 --> 00:18:51,000
that essentially guides the agent

414
00:18:51,000 --> 00:18:54,510
in terms of how it should
behave with every interaction.

415
00:18:54,510 --> 00:18:56,031
So semantic memory is essentially

416
00:18:56,031 --> 00:18:58,237
agent-structured world knowledge

417
00:18:58,237 --> 00:19:01,053
that enables consistent reasoning.

418
00:19:02,220 --> 00:19:05,280
So the most common real
world example is RAG.

419
00:19:05,280 --> 00:19:07,197
So we've used RAG over
the last couple of years,

420
00:19:07,197 --> 00:19:08,922
which is able to take
the factual documents

421
00:19:08,922 --> 00:19:10,917
or the proprietary data that we supplied,

422
00:19:10,917 --> 00:19:13,217
and able to provide
contextualized responses

423
00:19:13,217 --> 00:19:16,380
only from the given factual information.

424
00:19:16,380 --> 00:19:17,700
So in simple terms,

425
00:19:17,700 --> 00:19:20,040
semantic memory is agent's encyclopedia

426
00:19:20,040 --> 00:19:23,931
of facts and concepts that
it can further reference back

427
00:19:23,931 --> 00:19:26,722
to be able to answer any
questions or future interactions,

428
00:19:26,722 --> 00:19:29,397
also make decisions, and separate memories

429
00:19:29,397 --> 00:19:31,740
from, you know, each other memories.

430
00:19:31,740 --> 00:19:33,930
So it is able to, through this mechanism,

431
00:19:33,930 --> 00:19:36,060
the agent's able to sort of
separate out the memories

432
00:19:36,060 --> 00:19:37,563
for each every user profile.

433
00:19:39,377 --> 00:19:40,383
Sorry.

434
00:19:42,390 --> 00:19:43,710
In this particular example,

435
00:19:43,710 --> 00:19:44,730
the agent has learned

436
00:19:44,730 --> 00:19:47,040
the specific business
values or business rules.

437
00:19:47,040 --> 00:19:50,367
So it's learned the return
policy, the employee discount,

438
00:19:50,367 --> 00:19:54,363
and also the overall
product specification.

439
00:19:55,530 --> 00:20:00,530
So this type of memory is
really particularly powerful

440
00:20:00,578 --> 00:20:03,390
in the context of enterprises

441
00:20:03,390 --> 00:20:04,830
because especially when
you have, you know,

442
00:20:04,830 --> 00:20:07,740
company policies, factual documentation,

443
00:20:07,740 --> 00:20:09,450
or various product catalogs,

444
00:20:09,450 --> 00:20:12,597
when you have different
dimensions of information,

445
00:20:12,597 --> 00:20:15,060
when you want agent to
find semantic meaning

446
00:20:15,060 --> 00:20:17,880
or context across different dimensions,

447
00:20:17,880 --> 00:20:20,080
semantic memory is where
it comes into play.

448
00:20:20,970 --> 00:20:24,240
So rather than just storing
the raw conversation data,

449
00:20:24,240 --> 00:20:26,280
the agent essentially
builds up a knowledge base

450
00:20:26,280 --> 00:20:28,155
as you're seeing on the
right hand side as an example

451
00:20:28,155 --> 00:20:31,080
with full of facts and relationships.

452
00:20:31,080 --> 00:20:32,670
So this is where the integration

453
00:20:32,670 --> 00:20:34,350
between your agent's memory

454
00:20:34,350 --> 00:20:36,630
and your existing data
sources with your organization

455
00:20:36,630 --> 00:20:37,803
becomes really crucial.

456
00:20:41,705 --> 00:20:43,890
Third, summary memory.

457
00:20:43,890 --> 00:20:47,460
Essentially shortly known as
distilling for key insights.

458
00:20:47,460 --> 00:20:50,700
So summary memory is another
type of episodic memory

459
00:20:50,700 --> 00:20:54,240
that distills keen insights
from longer interactions.

460
00:20:54,240 --> 00:20:56,565
So practically, we can store

461
00:20:56,565 --> 00:20:58,080
every single interaction in the storage,

462
00:20:58,080 --> 00:21:00,450
but when we are looking to scale

463
00:21:00,450 --> 00:21:01,950
the overall agentic performance,

464
00:21:01,950 --> 00:21:04,410
retrieving every single
interaction from the storage

465
00:21:04,410 --> 00:21:06,630
and then extracting the insights out of it

466
00:21:06,630 --> 00:21:09,270
will be a very laborious task,

467
00:21:09,270 --> 00:21:12,000
or it would be very performance intensive.

468
00:21:12,000 --> 00:21:14,346
So which is why the
agent essentially stores

469
00:21:14,346 --> 00:21:17,790
a summary of the very long conversation

470
00:21:17,790 --> 00:21:19,410
with really key messages,

471
00:21:19,410 --> 00:21:23,310
or the storyline of what
was the interaction about.

472
00:21:23,310 --> 00:21:24,720
So in this particular example,

473
00:21:24,720 --> 00:21:26,310
you can see it's talking about

474
00:21:26,310 --> 00:21:29,229
the user bought the headphones,
there's a price match,

475
00:21:29,229 --> 00:21:31,304
or, you know, found a cheaper price

476
00:21:31,304 --> 00:21:33,090
and it was able to, you know,

477
00:21:33,090 --> 00:21:35,730
do the price match as a result of it.

478
00:21:35,730 --> 00:21:38,810
So it is also where you start
to see the value of agents,

479
00:21:38,810 --> 00:21:41,311
you know, having the ability
to sort of learn and adapt,

480
00:21:41,311 --> 00:21:43,461
you know, with the
summarization over time.

481
00:21:44,550 --> 00:21:45,870
- Okay, thanks.

482
00:21:45,870 --> 00:21:47,190
I'm John Mallory.

483
00:21:47,190 --> 00:21:50,400
I'm a go to market specialist here at AWS,

484
00:21:50,400 --> 00:21:52,300
and so I wanna switch gears now

485
00:21:52,300 --> 00:21:55,020
and, you know, Venkata
just walked us through

486
00:21:55,020 --> 00:21:58,260
the importance of both short
term and persistent memory

487
00:21:58,260 --> 00:21:59,940
for building agents.

488
00:21:59,940 --> 00:22:02,243
What I'd like to do is double click

489
00:22:02,243 --> 00:22:04,110
into some common approaches
of how you do this,

490
00:22:04,110 --> 00:22:08,823
and then layer in how
storage supports all of that.

491
00:22:09,660 --> 00:22:13,350
So let's get started with
how you're going to build,

492
00:22:13,350 --> 00:22:15,790
and deploy, and host agents.

493
00:22:15,790 --> 00:22:18,660
You know, a very common design pattern

494
00:22:18,660 --> 00:22:21,900
is a lot of AI builders wanna start off

495
00:22:21,900 --> 00:22:24,093
using open source frameworks.

496
00:22:24,093 --> 00:22:26,730
You know, like Strands Agent,

497
00:22:26,730 --> 00:22:29,964
LangChain Llama agent, AutoGen.

498
00:22:29,964 --> 00:22:31,754
There's a whole host of them out there

499
00:22:31,754 --> 00:22:34,710
and they're really good because, you know,

500
00:22:34,710 --> 00:22:37,830
they can accelerate experimentation,

501
00:22:37,830 --> 00:22:40,371
and building, and learning.

502
00:22:40,371 --> 00:22:43,788
They're, you know, have a lot
of packaged tools built in,

503
00:22:43,788 --> 00:22:47,972
and, you know, they really can simplify

504
00:22:47,972 --> 00:22:51,120
particularly using
interfaces and protocols

505
00:22:51,120 --> 00:22:53,948
like MCP and agent to agent,

506
00:22:53,948 --> 00:22:56,834
stitching all the components together.

507
00:22:56,834 --> 00:22:58,860
But the challenge lies

508
00:22:58,860 --> 00:23:02,004
in how do you start to
move this into production

509
00:23:02,004 --> 00:23:03,870
because then you have to start to worry

510
00:23:03,870 --> 00:23:07,260
about scaling infrastructure,
managing security,

511
00:23:07,260 --> 00:23:10,050
managing the various types of memory

512
00:23:10,050 --> 00:23:13,263
that Venkata talked about, and, you know,

513
00:23:13,263 --> 00:23:16,478
gluing all these pieces
together, you know,

514
00:23:16,478 --> 00:23:20,471
as you wanna scale to
hundreds or thousands of users

515
00:23:20,471 --> 00:23:24,750
have very complex orchestrated
agentic workflows.

516
00:23:24,750 --> 00:23:26,850
Make sure you've got the right guardrails

517
00:23:26,850 --> 00:23:29,010
and safety and security around it.

518
00:23:29,010 --> 00:23:31,591
It can quickly get very complicated.

519
00:23:31,591 --> 00:23:35,040
You know, so this is
evidenced by a Gartner study

520
00:23:35,040 --> 00:23:39,775
that over 40% of Agentic AI projects

521
00:23:39,775 --> 00:23:42,960
will be canceled in 2027,

522
00:23:42,960 --> 00:23:47,960
you know, due to unclear
business value, increasing cost,

523
00:23:48,060 --> 00:23:53,060
and, you know, questionable
security and governance policies

524
00:23:53,310 --> 00:23:56,340
that aren't going to meet
enterprise requirements.

525
00:23:56,340 --> 00:23:57,960
So, but that being said,

526
00:23:57,960 --> 00:24:00,946
we do see a lot of sophisticated customers

527
00:24:00,946 --> 00:24:03,707
using self-managed frameworks.

528
00:24:03,707 --> 00:24:06,210
There are a couple of other approaches.

529
00:24:06,210 --> 00:24:07,471
You know, down on the left,

530
00:24:07,471 --> 00:24:09,846
if you're just starting out your journey,

531
00:24:09,846 --> 00:24:12,726
you wanna leverage the power of agents.

532
00:24:12,726 --> 00:24:17,400
We have Amazon Queue in our quick suite,

533
00:24:17,400 --> 00:24:19,710
which has agents packaged in

534
00:24:19,710 --> 00:24:22,362
for common enterprise workloads.

535
00:24:22,362 --> 00:24:26,160
You know, so you can really
leverage the power of agentic AI

536
00:24:26,160 --> 00:24:28,110
without needing to build anything.

537
00:24:28,110 --> 00:24:30,630
Next stop is the fully managed approach

538
00:24:30,630 --> 00:24:35,460
using Amazon Bedrock
agents, which, you know,

539
00:24:35,460 --> 00:24:38,513
really starts to stitch
all these pieces together,

540
00:24:38,513 --> 00:24:42,150
handle key parts of the infrastructure

541
00:24:42,150 --> 00:24:46,076
like hosting the LLMs, building
knowledge bases in RAG,

542
00:24:46,076 --> 00:24:49,800
and orchestrating
multi-step agent workflow.

543
00:24:49,800 --> 00:24:54,800
So that gives you a lot of
flexibility and, you know,

544
00:24:54,840 --> 00:24:56,733
can help you get started quickly.

545
00:24:58,020 --> 00:25:01,848
But the key thing is you
don't really have to choose

546
00:25:01,848 --> 00:25:03,874
between a do-it-yourself approach

547
00:25:03,874 --> 00:25:06,960
using these open source frameworks,

548
00:25:06,960 --> 00:25:10,394
and some of the features
and capabilities of Bedrock.

549
00:25:10,394 --> 00:25:12,900
You know, what we released back in July

550
00:25:12,900 --> 00:25:17,900
and went GA in October
was a Bedrock AgentCore,

551
00:25:19,329 --> 00:25:23,580
which removes a lot of the
undifferentiated heavy lifting

552
00:25:23,580 --> 00:25:25,980
of building agents
where you can kinda take

553
00:25:25,980 --> 00:25:27,510
a mix and match approach.

554
00:25:27,510 --> 00:25:29,365
You can use your open source frameworks

555
00:25:29,365 --> 00:25:33,925
and, you know, choose the
framework of your choice,

556
00:25:33,925 --> 00:25:36,120
have your choice of models

557
00:25:36,120 --> 00:25:38,383
both inside and outside of Bedrock,

558
00:25:38,383 --> 00:25:41,253
but then to have these
AgentCore components

559
00:25:41,253 --> 00:25:45,630
that really start to make
it a managed experience.

560
00:25:45,630 --> 00:25:50,630
You know, so if you take like
runtime that handles compute

561
00:25:50,760 --> 00:25:52,590
where you don't have to
worry about provisioning,

562
00:25:52,590 --> 00:25:55,530
scaling, compute up
and down, it does that.

563
00:25:55,530 --> 00:25:57,484
AgentCore memory reduces a lot

564
00:25:57,484 --> 00:26:02,010
of the work you have to do to build

565
00:26:02,010 --> 00:26:04,560
both the short term and
the long term memory

566
00:26:04,560 --> 00:26:06,510
that Venkata talked about.

567
00:26:06,510 --> 00:26:07,860
It automates a lot of that.

568
00:26:07,860 --> 00:26:10,759
And then, you know, identity helps

569
00:26:10,759 --> 00:26:13,039
with all the security and permissions,

570
00:26:13,039 --> 00:26:15,990
and gateway can help orchestrate

571
00:26:15,990 --> 00:26:17,911
between all the tools you're gonna use.

572
00:26:17,911 --> 00:26:22,911
You know, so really this is
a great way to get started,

573
00:26:23,220 --> 00:26:24,919
but even if you take this approach

574
00:26:24,919 --> 00:26:27,476
and you use AgentCore memory,

575
00:26:27,476 --> 00:26:29,756
you still need to think about storage

576
00:26:29,756 --> 00:26:32,763
when it comes to building agents.

577
00:26:34,830 --> 00:26:38,340
So before we dive into
the various components,

578
00:26:38,340 --> 00:26:40,740
let's talk about a few of the challenges

579
00:26:40,740 --> 00:26:43,710
you need to be mindful of
as you start this journey,

580
00:26:43,710 --> 00:26:47,190
or, you know, even as you
evolve in this journey.

581
00:26:47,190 --> 00:26:51,991
The first is you've gotta
make all of your data

582
00:26:51,991 --> 00:26:55,470
accessible, discoverable, and actionable.

583
00:26:55,470 --> 00:26:57,339
You know, agents that
create business value

584
00:26:57,339 --> 00:26:59,730
are going to need to access

585
00:26:59,730 --> 00:27:01,671
all forms of your data that you have

586
00:27:01,671 --> 00:27:05,399
in your organization, or your
company, or your enterprise,

587
00:27:05,399 --> 00:27:08,485
and this is everything
from structured data

588
00:27:08,485 --> 00:27:12,439
that may live in data
warehouses, databases,

589
00:27:12,439 --> 00:27:16,380
you know, transactional
data that, you know,

590
00:27:16,380 --> 00:27:19,710
drives all of your business
transactions and billing,

591
00:27:19,710 --> 00:27:22,061
and, you know, key use cases

592
00:27:22,061 --> 00:27:24,840
that are gonna power the business daily

593
00:27:24,840 --> 00:27:27,480
all the way to depending
on what industry you're in,

594
00:27:27,480 --> 00:27:29,910
unstructured data of all forms.

595
00:27:29,910 --> 00:27:33,150
You know, things like images,
video, call record logs,

596
00:27:33,150 --> 00:27:35,790
if you're in specific
industries like healthcare,

597
00:27:35,790 --> 00:27:39,491
medical records,
pathology reports, images.

598
00:27:39,491 --> 00:27:42,960
Agents really need to
be able to understand

599
00:27:42,960 --> 00:27:46,336
and choose from all of these data sets.

600
00:27:46,336 --> 00:27:48,111
The second key challenge

601
00:27:48,111 --> 00:27:52,122
is really privacy, and
security, and governance

602
00:27:52,122 --> 00:27:55,530
because ultimately, you want the agents

603
00:27:55,530 --> 00:27:58,402
to access as much data as they need

604
00:27:58,402 --> 00:28:00,527
to be effective and to add value,

605
00:28:00,527 --> 00:28:02,640
but you need to put guardrails on that

606
00:28:02,640 --> 00:28:05,461
because God forbid you build an agent

607
00:28:05,461 --> 00:28:09,212
that exposes sensitive,
let's say, patient data

608
00:28:09,212 --> 00:28:11,442
to, you know, the world.

609
00:28:11,442 --> 00:28:12,750
That can't happen.

610
00:28:12,750 --> 00:28:16,500
So you've gotta have proper
governance and guardrails.

611
00:28:16,500 --> 00:28:18,666
And then as Venkata discussed,

612
00:28:18,666 --> 00:28:21,600
agents are gonna act if they're built

613
00:28:21,600 --> 00:28:24,465
and really adding value autonomously

614
00:28:24,465 --> 00:28:28,470
without human intervention
and achieve complex goals.

615
00:28:28,470 --> 00:28:32,100
So you really need to monitor
this both to make sure

616
00:28:32,100 --> 00:28:34,080
you don't have any data leakage

617
00:28:34,080 --> 00:28:35,578
or, you know, governance breaches,

618
00:28:35,578 --> 00:28:38,864
but also to collect data
on how to improve accuracy

619
00:28:38,864 --> 00:28:43,864
and iterate as your
agents learn and evolve.

620
00:28:44,040 --> 00:28:46,500
So you need to think about governance.

621
00:28:46,500 --> 00:28:51,270
And finally, semantic search and storage

622
00:28:51,270 --> 00:28:56,270
is key both for grounding
agents with data via RAG,

623
00:28:56,698 --> 00:28:59,460
as well as the long-term memory.

624
00:28:59,460 --> 00:29:01,020
And this isn't just theoretical.

625
00:29:01,020 --> 00:29:02,580
I had a customer meeting this morning

626
00:29:02,580 --> 00:29:05,164
with a large enterprise software customer

627
00:29:05,164 --> 00:29:08,070
who they built some agents,

628
00:29:08,070 --> 00:29:09,629
they've seen some business value,

629
00:29:09,629 --> 00:29:11,790
and so they really wanna scale it,

630
00:29:11,790 --> 00:29:13,012
but now they're thinking about

631
00:29:13,012 --> 00:29:16,680
how do we build the data
foundation to do this.

632
00:29:16,680 --> 00:29:18,549
Essentially they want an agentic layer

633
00:29:18,549 --> 00:29:21,060
that they can bring the agents to the data

634
00:29:21,060 --> 00:29:24,853
because if you start to
bring data to the agents,

635
00:29:24,853 --> 00:29:27,150
now you're back with data sprawl

636
00:29:27,150 --> 00:29:31,140
and trying to maintain data
fidelity across multiple copies.

637
00:29:31,140 --> 00:29:33,652
So it really kind of brought
all these challenges to life

638
00:29:33,652 --> 00:29:36,990
and they've got multiple data warehouses,

639
00:29:36,990 --> 00:29:41,190
Snowflake, Databricks, Redshift, Athena,

640
00:29:41,190 --> 00:29:42,660
you know, all these different pieces,

641
00:29:42,660 --> 00:29:44,400
and so they're trying to figure out

642
00:29:44,400 --> 00:29:46,110
how to stitch this all together

643
00:29:46,110 --> 00:29:47,621
into a common data foundation

644
00:29:47,621 --> 00:29:49,923
before they can even start their journey.

645
00:29:50,940 --> 00:29:52,860
So let's switch gears now

646
00:29:52,860 --> 00:29:55,277
and talk about some of
our storage services

647
00:29:55,277 --> 00:29:57,903
and how it can help with all this.

648
00:29:59,166 --> 00:30:04,126
This is a map I like to
use to start to layer in

649
00:30:04,126 --> 00:30:08,220
how storage interacts with agents

650
00:30:08,220 --> 00:30:10,590
and the memory requirements.

651
00:30:10,590 --> 00:30:13,860
And really, no matter
if you're going to use

652
00:30:13,860 --> 00:30:15,880
Bedrock AgentCore memory,

653
00:30:19,016 --> 00:30:23,040
which manages the short
term and long term memory,

654
00:30:23,040 --> 00:30:25,770
you've still gotta think
about that data foundation

655
00:30:25,770 --> 00:30:26,901
back to this, you know,

656
00:30:26,901 --> 00:30:30,000
enterprise software provider challenge.

657
00:30:30,000 --> 00:30:33,960
So you wanna start with a data lake,

658
00:30:33,960 --> 00:30:37,110
ideally built on S3 if
you're building in Amazon,

659
00:30:37,110 --> 00:30:40,380
and then using services like S3 Tables.

660
00:30:40,380 --> 00:30:43,440
You know, that's really
going to aggregate your data,

661
00:30:43,440 --> 00:30:47,340
allow you to provide common
security and governance,

662
00:30:47,340 --> 00:30:50,104
and then make the data cataloged,

663
00:30:50,104 --> 00:30:54,721
and discoverable, and
usable by the agents.

664
00:30:54,721 --> 00:30:58,770
So that, you know, is why we use S3

665
00:30:58,770 --> 00:31:01,692
because of the durability, scalability.

666
00:31:01,692 --> 00:31:05,333
Both the AWS first party
services that integrate with it,

667
00:31:05,333 --> 00:31:08,070
but then all these third
party providers as well

668
00:31:08,070 --> 00:31:10,261
that use it as a common data hub.

669
00:31:10,261 --> 00:31:13,383
Building on that, as Venkata discussed,

670
00:31:14,726 --> 00:31:16,830
short term memory is really
the temporary storage

671
00:31:16,830 --> 00:31:18,750
or working memory for information

672
00:31:18,750 --> 00:31:21,060
that the agents are processing.

673
00:31:21,060 --> 00:31:23,040
You know, so it's going to be stored

674
00:31:23,040 --> 00:31:25,391
typically in raw data formats,

675
00:31:25,391 --> 00:31:29,280
and if you have multiple agents

676
00:31:29,280 --> 00:31:31,381
coordinating with each other,

677
00:31:31,381 --> 00:31:34,412
they're going to need exchange
information with each other

678
00:31:34,412 --> 00:31:37,802
so they're going to need to
have a shared storage layer.

679
00:31:37,802 --> 00:31:42,303
Like, if you think of, you
know, a research agent workflow,

680
00:31:43,200 --> 00:31:44,850
you're probably gonna have an agent

681
00:31:44,850 --> 00:31:48,471
that's, you know, discovering
data, you know, maybe looking,

682
00:31:48,471 --> 00:31:50,751
searching through academic papers,

683
00:31:50,751 --> 00:31:53,258
another one that's verifying citations

684
00:31:53,258 --> 00:31:55,181
and rights to use that data,

685
00:31:55,181 --> 00:31:57,750
and then another one that's summarizing,

686
00:31:57,750 --> 00:31:59,250
and this is all gonna be iterative

687
00:31:59,250 --> 00:32:01,230
so they have to communicate.

688
00:32:01,230 --> 00:32:02,773
So given this, we typically recommend

689
00:32:02,773 --> 00:32:07,773
starting with our FSX
family of file services.

690
00:32:07,800 --> 00:32:09,870
There's a whole family to choose from.

691
00:32:09,870 --> 00:32:13,560
They're low latency, scalable, you know,

692
00:32:13,560 --> 00:32:15,540
have a lot of options to save costs

693
00:32:15,540 --> 00:32:18,379
and make it easy to
manage for scratch space

694
00:32:18,379 --> 00:32:21,720
and for this shared memory access.

695
00:32:21,720 --> 00:32:24,686
S3 does play a part
here because ultimately,

696
00:32:24,686 --> 00:32:29,686
you're going to wanna snapshot
that state so that, you know,

697
00:32:29,700 --> 00:32:32,104
if things crash you can quickly recover,

698
00:32:32,104 --> 00:32:34,920
but then you're also going to wanna start

699
00:32:34,920 --> 00:32:38,640
to stage and consolidate
all that short-term memory

700
00:32:38,640 --> 00:32:40,800
and run it through a processing pipeline

701
00:32:40,800 --> 00:32:43,890
to start to create the longer term memory,

702
00:32:43,890 --> 00:32:47,790
the semantic memory that
Venkata talked about.

703
00:32:47,790 --> 00:32:51,810
And so, you know, really
you can use S3 for that.

704
00:32:51,810 --> 00:32:54,881
A couple of other components
of short term memory

705
00:32:54,881 --> 00:32:58,770
are a lot of these agents
can be highly transactional.

706
00:32:58,770 --> 00:33:02,490
So people may want to use a
high performance key value store

707
00:33:02,490 --> 00:33:05,062
to capture state like Dynamo DB.

708
00:33:05,062 --> 00:33:08,399
And then another layer you
wanna build at that level

709
00:33:08,399 --> 00:33:13,399
is a semantic cash layer
oftentimes, which, you know,

710
00:33:14,340 --> 00:33:18,720
might be something like ElastiCache,

711
00:33:18,720 --> 00:33:21,120
which recently introduced vector search

712
00:33:21,120 --> 00:33:22,218
because if you put caching

713
00:33:22,218 --> 00:33:27,218
in front of your LLM, and
your RAG, and your prompting,

714
00:33:27,691 --> 00:33:29,520
even though those storage layers

715
00:33:29,520 --> 00:33:33,180
can be expensive on a dollar basis,

716
00:33:33,180 --> 00:33:35,010
if you reduce the interaction

717
00:33:35,010 --> 00:33:38,430
back and forth with the
LLM and cash responses,

718
00:33:38,430 --> 00:33:40,269
you know, you're quickly driving down cost

719
00:33:40,269 --> 00:33:43,890
and making it a much more
cost effective architecture.

720
00:33:43,890 --> 00:33:47,324
And then finally, you know,
as Venkata also indicated,

721
00:33:47,324 --> 00:33:51,960
you need to think about
semantic memory and RAG

722
00:33:51,960 --> 00:33:55,275
to ground, you know, the LLMs

723
00:33:55,275 --> 00:33:57,180
and get the most accurate results.

724
00:33:57,180 --> 00:34:00,330
And so, you know, we recommend S3 vectors,

725
00:34:00,330 --> 00:34:02,970
which, you know, just went GA today

726
00:34:02,970 --> 00:34:06,759
and Garmin's keynote is
a very cost effective,

727
00:34:06,759 --> 00:34:11,403
highly durable, you know, very
scalable approach for that.

728
00:34:13,230 --> 00:34:15,900
So what do you wanna consider

729
00:34:15,900 --> 00:34:18,690
when you're building that
Data Lake Foundation?

730
00:34:18,690 --> 00:34:21,734
I talked about this enterprise customer

731
00:34:21,734 --> 00:34:23,400
who has all these different platforms

732
00:34:23,400 --> 00:34:25,050
that they're trying to
integrate, you know,

733
00:34:25,050 --> 00:34:27,390
with their own formats,
their own catalogs,

734
00:34:27,390 --> 00:34:29,629
their own security and governance.

735
00:34:29,629 --> 00:34:34,110
The industry has built
a open source solution

736
00:34:34,110 --> 00:34:37,163
to start to address these
challenges called Iceberg.

737
00:34:37,163 --> 00:34:40,620
So if you're building a new data lake,

738
00:34:40,620 --> 00:34:42,660
or even if you have an existing one,

739
00:34:42,660 --> 00:34:46,050
you probably wanna to think
about how to adopt Iceberg

740
00:34:46,050 --> 00:34:48,080
as your data lake foundation

741
00:34:48,080 --> 00:34:50,160
'cause a couple key advantages of it

742
00:34:50,160 --> 00:34:55,160
are it brings a lot of the
data warehouse capabilities

743
00:34:55,613 --> 00:35:00,300
like acid transactions, rollback,

744
00:35:00,300 --> 00:35:04,082
and a number of other
transactional integrity fields

745
00:35:04,082 --> 00:35:08,310
into an object-based data lake.

746
00:35:08,310 --> 00:35:13,310
Secondly, it has Iceberg
rest catalog endpoints,

747
00:35:15,270 --> 00:35:20,190
which start to make it easy to
integrate different catalogs,

748
00:35:20,190 --> 00:35:23,230
data catalogs, that
different provider solutions

749
00:35:24,322 --> 00:35:25,440
have together with each other.

750
00:35:25,440 --> 00:35:26,820
So now you can start to get

751
00:35:26,820 --> 00:35:30,480
better interoperability
between multiple data engines,

752
00:35:30,480 --> 00:35:34,047
both AWS native ones, as
well as a lot of third party

753
00:35:34,047 --> 00:35:36,270
and even open source ones.

754
00:35:36,270 --> 00:35:38,850
So, you know, definitely
consider building Iceberg

755
00:35:38,850 --> 00:35:40,502
as your data foundation.

756
00:35:40,502 --> 00:35:45,480
And to help with that,
we launched S3 tables,

757
00:35:45,480 --> 00:35:49,260
which is a native
Iceberg-managed table within S3.

758
00:35:49,260 --> 00:35:52,752
We launched that back a
year ago here at re:Invent

759
00:35:52,752 --> 00:35:56,645
and have continued to iterate
on it to the point where today

760
00:35:56,645 --> 00:36:00,390
we just announced
intelligent tiering for it.

761
00:36:00,390 --> 00:36:03,510
So really help you
optimize cost for Iceberg,

762
00:36:03,510 --> 00:36:07,500
and native Iceberg
replication across regions

763
00:36:07,500 --> 00:36:09,765
so you can really, if you're
an enterprise, start to build,

764
00:36:09,765 --> 00:36:14,433
you know, highly resilient,
highly available Iceberg.

765
00:36:16,013 --> 00:36:18,180
I wanna divert a minute

766
00:36:18,180 --> 00:36:20,580
and talk about model context protocol

767
00:36:20,580 --> 00:36:22,440
because that's really the key

768
00:36:22,440 --> 00:36:25,140
to stitching all these
components together.

769
00:36:25,140 --> 00:36:26,430
It's an open source standard

770
00:36:26,430 --> 00:36:29,799
that allows AI agents via MCP clients

771
00:36:29,799 --> 00:36:34,680
to communicate with external
tools, data, and services

772
00:36:34,680 --> 00:36:36,630
in a structured way, you know,

773
00:36:36,630 --> 00:36:39,770
so it allows agentic
AI vendors and builders

774
00:36:39,770 --> 00:36:44,770
to start to have access to
potentially thousands of tools

775
00:36:45,021 --> 00:36:47,135
that your agents can call upon

776
00:36:47,135 --> 00:36:50,430
without having to learn all
those individual interfaces.

777
00:36:50,430 --> 00:36:52,815
You just need to know how to speak MCP,

778
00:36:52,815 --> 00:36:57,570
pick the right MCP servers
from a catalog of tools,

779
00:36:57,570 --> 00:36:58,906
and now you can start to build

780
00:36:58,906 --> 00:37:01,836
and if you have data over
all these different devices,

781
00:37:01,836 --> 00:37:06,450
you can start to, you know,
quickly stitch it all together.

782
00:37:06,450 --> 00:37:09,780
Your agents can start to
understand how to access

783
00:37:09,780 --> 00:37:12,390
without knowing how to speak individually

784
00:37:12,390 --> 00:37:14,220
to each one of these devices.

785
00:37:14,220 --> 00:37:16,280
So it's like a USB port for agents

786
00:37:16,280 --> 00:37:17,930
is the way I like to think of it.

787
00:37:18,898 --> 00:37:23,815
And we've started to adopt that
into storage family as well.

788
00:37:23,815 --> 00:37:27,026
You know, we released an
MCP server for S3 tables

789
00:37:27,026 --> 00:37:30,660
so that, you know now, you know,

790
00:37:30,660 --> 00:37:33,360
agents that wanna use tabular data,

791
00:37:33,360 --> 00:37:34,917
store it in Iceberg format,

792
00:37:34,917 --> 00:37:38,230
can speak to and understand

793
00:37:39,300 --> 00:37:43,590
and access data in S3 tables.

794
00:37:43,590 --> 00:37:45,510
You know, one tip I would recommend

795
00:37:45,510 --> 00:37:47,850
when you're thinking about MCP,

796
00:37:47,850 --> 00:37:49,950
particularly if you're just starting out,

797
00:37:49,950 --> 00:37:53,400
is you should really consider

798
00:37:53,400 --> 00:37:56,730
only using it with a read-only capability

799
00:37:56,730 --> 00:37:58,770
and scoping down, you know,

800
00:37:58,770 --> 00:38:03,300
to the least needed
access privileges via IAM,

801
00:38:03,300 --> 00:38:07,163
and these MCP servers,
like the 1-4 S3 tables,

802
00:38:07,163 --> 00:38:09,450
support all that through IAM.

803
00:38:09,450 --> 00:38:13,260
But, you know, really be
deliberate about, you know,

804
00:38:13,260 --> 00:38:16,186
not doing an allow write type capability

805
00:38:16,186 --> 00:38:17,920
unless you're absolutely sure

806
00:38:17,920 --> 00:38:20,643
you have a specific use
case that needs that.

807
00:38:21,885 --> 00:38:24,870
Another key is data discovery.

808
00:38:24,870 --> 00:38:26,520
I mean, you're gonna build this data lake,

809
00:38:26,520 --> 00:38:29,130
you're gonna have all
your data aggregated.

810
00:38:29,130 --> 00:38:32,479
How are agents going to discover this?

811
00:38:32,479 --> 00:38:36,210
Structured data catalogs
have been the foundation

812
00:38:36,210 --> 00:38:39,060
of analytics and data lakes for decades,

813
00:38:39,060 --> 00:38:42,814
but a lot of the data that
AI agents are going to use

814
00:38:42,814 --> 00:38:47,159
is unstructured data of
a lot of different types,

815
00:38:47,159 --> 00:38:50,040
and traditional analytic catalogs

816
00:38:50,040 --> 00:38:52,170
don't really deal with that well.

817
00:38:52,170 --> 00:38:56,026
So you really need to think
about a metadata strategy,

818
00:38:56,026 --> 00:38:58,581
and then, you know, having that metadata

819
00:38:58,581 --> 00:39:02,386
really be discoverable
and consumable by agents

820
00:39:02,386 --> 00:39:05,190
so that they can kind of self-discover

821
00:39:05,190 --> 00:39:08,340
and, you know,
self-describe and understand

822
00:39:08,340 --> 00:39:10,980
the data that they're drawing upon.

823
00:39:10,980 --> 00:39:13,953
So, you know, metadata's really
what makes it actionable.

824
00:39:15,000 --> 00:39:18,781
And to help with that,
we released S3 metadata,

825
00:39:18,781 --> 00:39:22,656
which is a built-in metadata service in S3

826
00:39:22,656 --> 00:39:27,390
that will take system collected metadata,

827
00:39:27,390 --> 00:39:30,458
allow you to augment it with
user-generated metadata,

828
00:39:30,458 --> 00:39:34,920
and then query it
through an iceberg table.

829
00:39:34,920 --> 00:39:39,920
So you can actually use the
MCP server for S3 tables

830
00:39:40,680 --> 00:39:43,595
to also let agents start to discover

831
00:39:43,595 --> 00:39:46,053
metadata and the data itself.

832
00:39:47,100 --> 00:39:50,628
And so the way it works essentially
is you turn it on in S3,

833
00:39:50,628 --> 00:39:55,530
and S3 will populate a metadata table

834
00:39:55,530 --> 00:39:58,380
both with inventory of all the objects,

835
00:39:58,380 --> 00:40:01,470
but also with lineage and, you know,

836
00:40:01,470 --> 00:40:03,360
essentially mutations of the objects.

837
00:40:03,360 --> 00:40:06,090
So you can also start to
use it for governance,

838
00:40:06,090 --> 00:40:09,840
and so when you combine
all these pieces together,

839
00:40:09,840 --> 00:40:13,380
you know, with S3 tables MCP, you know,

840
00:40:13,380 --> 00:40:17,616
AI agents can now really
have true data discovery,

841
00:40:17,616 --> 00:40:19,770
particularly if they have MCP servers

842
00:40:19,770 --> 00:40:22,713
that also speak to things
like iceberg catalogs.

843
00:40:25,140 --> 00:40:27,728
Another key thing we just introduced

844
00:40:27,728 --> 00:40:31,680
in the keynote today for NetApp

845
00:40:31,680 --> 00:40:35,100
was S3 access points for FSX

846
00:40:35,100 --> 00:40:36,850
because one of the challenges

847
00:40:37,698 --> 00:40:40,980
is it's well and good to
say build a data lake,

848
00:40:40,980 --> 00:40:44,130
but a lot of people's data
still lives on premises

849
00:40:44,130 --> 00:40:46,050
in traditional file systems.

850
00:40:46,050 --> 00:40:47,520
So what do you do about that?

851
00:40:47,520 --> 00:40:50,580
Because there are a lot of
legacy applications out there

852
00:40:50,580 --> 00:40:53,070
that don't know how to
speak to object storage.

853
00:40:53,070 --> 00:40:54,630
They, you know, were built to speak

854
00:40:54,630 --> 00:40:57,510
to traditional file systems.

855
00:40:57,510 --> 00:41:00,570
I mean, IDC indicated a
study they did, you know,

856
00:41:00,570 --> 00:41:04,560
that while things are moving
to the cloud, you know,

857
00:41:04,560 --> 00:41:06,962
48% of data still lives on premises

858
00:41:06,962 --> 00:41:11,310
and 29% in the cloud by the end of 2028.

859
00:41:11,310 --> 00:41:16,050
So it is a gradual transition,
and really you need to start

860
00:41:16,050 --> 00:41:19,418
to bring all this data
together in a coherent way.

861
00:41:19,418 --> 00:41:23,322
You know, because while you
could bring the agents to data,

862
00:41:23,322 --> 00:41:26,982
now back to this customer I talked about,

863
00:41:26,982 --> 00:41:30,690
you start to run into
data fidelity issues,

864
00:41:30,690 --> 00:41:35,690
and so this is where FSX access
points for S3 really help

865
00:41:36,037 --> 00:41:37,120
is because you can take data

866
00:41:37,120 --> 00:41:40,950
that lives in traditional file systems,

867
00:41:40,950 --> 00:41:43,050
and if it's in NetApp file systems,

868
00:41:43,050 --> 00:41:46,140
which has been, you know, a
standard on-prem for decades,

869
00:41:46,140 --> 00:41:49,320
you can start to use their
replication capabilities,

870
00:41:49,320 --> 00:41:52,560
snap a copy, maintain a
coherent copy with the cloud

871
00:41:52,560 --> 00:41:54,390
even if you're running on premises,

872
00:41:54,390 --> 00:41:58,920
expose that into S3 as if the
data's living there natively,

873
00:41:58,920 --> 00:42:01,020
and now when you're building
that data foundation,

874
00:42:01,020 --> 00:42:03,000
you've integrated your file data

875
00:42:03,000 --> 00:42:05,550
without having to
maintain a separate copy,

876
00:42:05,550 --> 00:42:06,630
and this is really important

877
00:42:06,630 --> 00:42:11,630
because the same Gartner IDC
study indicated that today,

878
00:42:12,870 --> 00:42:16,980
an enterprise has 6.4 data silos per org

879
00:42:16,980 --> 00:42:19,320
and has to manage 13 copies of data.

880
00:42:19,320 --> 00:42:22,500
So anything you can do to simplify that

881
00:42:22,500 --> 00:42:24,808
is really going to help with, you know,

882
00:42:24,808 --> 00:42:27,649
making your agents have access to data

883
00:42:27,649 --> 00:42:29,643
in a more simplified way.

884
00:42:31,230 --> 00:42:33,120
And then finally, vectors.

885
00:42:33,120 --> 00:42:36,030
Vectors really are the language
of AI because, you know,

886
00:42:36,030 --> 00:42:39,838
you can take increasingly
sophisticated embedding models,

887
00:42:39,838 --> 00:42:42,999
create vectors of any data type,

888
00:42:42,999 --> 00:42:46,590
and then find things that
are semantically similar

889
00:42:46,590 --> 00:42:50,520
both in context, meaning,
and if it's agents,

890
00:42:50,520 --> 00:42:52,410
you know, things that even look the same.

891
00:42:52,410 --> 00:42:54,870
So they really power a lot of this,

892
00:42:54,870 --> 00:42:57,632
everything from RAG to, you
know, intelligence search,

893
00:42:57,632 --> 00:43:00,903
to long-term memory.

894
00:43:02,010 --> 00:43:06,780
And so we launched S3 vectors this summer,

895
00:43:06,780 --> 00:43:09,949
it went GA today, and
it really is designed

896
00:43:09,949 --> 00:43:12,450
to have good enough performance

897
00:43:12,450 --> 00:43:15,706
for a lot of agentic
workflows and RAG workflows.

898
00:43:15,706 --> 00:43:20,045
Lower cost of similarity
search and semantic search

899
00:43:20,045 --> 00:43:23,878
by up to 90% when you look at TCO,

900
00:43:23,878 --> 00:43:26,400
and scale to billions of vectors.

901
00:43:26,400 --> 00:43:28,500
In fact, with the limits
we introduced today,

902
00:43:28,500 --> 00:43:30,849
2 billion vectors per index,

903
00:43:30,849 --> 00:43:34,156
10 billion in 10,000 indexes per bucket,

904
00:43:34,156 --> 00:43:37,290
you can scale to 20 trillion vectors

905
00:43:37,290 --> 00:43:39,600
in a single S3 vector bucket.

906
00:43:39,600 --> 00:43:42,393
So you're not gonna run
into scalability challenges.

907
00:43:43,560 --> 00:43:46,410
And so starting to stitch
all these pieces together,

908
00:43:46,410 --> 00:43:50,280
you can start to do things
like agentic search, you know,

909
00:43:50,280 --> 00:43:52,110
where agents can start to use

910
00:43:52,110 --> 00:43:55,577
conversational information
and choose strategies.

911
00:43:55,577 --> 00:44:00,000
You know, so Venkata
talked about, you know,

912
00:44:00,000 --> 00:44:01,980
a shopping assistant and mapping that

913
00:44:01,980 --> 00:44:03,428
to short and long-term memory.

914
00:44:03,428 --> 00:44:06,533
You can really start
that shopping assistant

915
00:44:06,533 --> 00:44:11,533
can start to pull in, you
know, image data, you know,

916
00:44:12,060 --> 00:44:13,698
and user preference data

917
00:44:13,698 --> 00:44:16,732
and make intelligent
recommendations to buyers

918
00:44:16,732 --> 00:44:19,922
and even start to create images, you know,

919
00:44:19,922 --> 00:44:24,090
using a multimodal model so
that they can start to visualize

920
00:44:24,090 --> 00:44:27,082
what that dress that they
found this one dress,

921
00:44:27,082 --> 00:44:31,258
they want another one like
it, might look like on them.

922
00:44:31,258 --> 00:44:33,540
So, you know, super powerful.

923
00:44:33,540 --> 00:44:36,962
And then just to ground it in
a real world customer example,

924
00:44:36,962 --> 00:44:40,917
BMW group has a 20 petabyte data lake,

925
00:44:40,917 --> 00:44:43,320
they call it their cloud data hub,

926
00:44:43,320 --> 00:44:46,830
of all of their data about their vehicles,

927
00:44:46,830 --> 00:44:51,420
their manufacturing processes,
their warranty information,

928
00:44:51,420 --> 00:44:54,250
and really they wanted to make it simple

929
00:44:55,294 --> 00:44:56,127
for all of their users

930
00:44:56,127 --> 00:44:58,200
to access all these different data types

931
00:44:58,200 --> 00:45:00,060
without being data experts.

932
00:45:00,060 --> 00:45:01,066
And so they built

933
00:45:01,066 --> 00:45:04,434
an agent-powered search
capability for this,

934
00:45:04,434 --> 00:45:09,194
which really can provide
three modes of search,

935
00:45:09,194 --> 00:45:11,910
including direct structured search,

936
00:45:11,910 --> 00:45:14,573
hybrid search across
structured and semantic data,

937
00:45:14,573 --> 00:45:16,343
and pure similarity search

938
00:45:16,343 --> 00:45:20,104
based on the context of the, you know,

939
00:45:20,104 --> 00:45:23,773
natural language query
the user's trying to do.

940
00:45:23,773 --> 00:45:27,870
You know, so it really does
democratize access to data

941
00:45:27,870 --> 00:45:29,943
for all of their users.

942
00:45:29,943 --> 00:45:33,270
So with that, I'm gonna
turn it back to Venkata.

943
00:45:33,270 --> 00:45:34,170
- Thank you, John.

944
00:45:35,190 --> 00:45:36,870
So this is probably my favorite slide

945
00:45:36,870 --> 00:45:38,020
of the overall content.

946
00:45:39,090 --> 00:45:39,966
So we are gonna talk about

947
00:45:39,966 --> 00:45:42,120
when does data actually become memory?

948
00:45:42,120 --> 00:45:43,470
So we saw the first part,

949
00:45:43,470 --> 00:45:45,760
we understood the memory
constructs, right?

950
00:45:45,760 --> 00:45:48,240
And then John covered what
are the building blocks

951
00:45:48,240 --> 00:45:51,090
that facilitate the overall
memory building process?

952
00:45:51,090 --> 00:45:52,621
So now we're bringing both together.

953
00:45:52,621 --> 00:45:56,940
So essentially how when
data becomes memory.

954
00:45:56,940 --> 00:46:00,900
So I guess in AI agentic development,

955
00:46:00,900 --> 00:46:03,780
data and memory are interchangeably used.

956
00:46:03,780 --> 00:46:06,510
But that's fair because
memory is actually data,

957
00:46:06,510 --> 00:46:10,320
but there is a clear distinction
between both the terms.

958
00:46:10,320 --> 00:46:11,911
Data actually becomes memory

959
00:46:11,911 --> 00:46:15,180
when it transforms a passive information

960
00:46:15,180 --> 00:46:16,410
into active component

961
00:46:16,410 --> 00:46:19,173
that informs agent's
behavior and reasoning.

962
00:46:20,280 --> 00:46:22,775
So it's a five stage
transformation process.

963
00:46:22,775 --> 00:46:27,420
So to understand the overall
transformation in a easier way,

964
00:46:27,420 --> 00:46:28,740
let's understand there's a use case.

965
00:46:28,740 --> 00:46:29,573
Let's pick a use case,

966
00:46:29,573 --> 00:46:33,660
which is a customer chat bot
on an e-commerce website.

967
00:46:33,660 --> 00:46:35,790
So that we will pick the overall flow

968
00:46:35,790 --> 00:46:37,440
and then build the overall
transformation pipeline.

969
00:46:37,440 --> 00:46:39,600
So let's say you got
your source data stream.

970
00:46:39,600 --> 00:46:41,494
So on the e-commerce website

971
00:46:41,494 --> 00:46:42,327
you got different channels,

972
00:46:42,327 --> 00:46:43,160
you're getting the order information,

973
00:46:43,160 --> 00:46:46,920
you're getting the like supply
chain merchandise, right?

974
00:46:46,920 --> 00:46:49,410
Whole sorts of information
coming through the sources.

975
00:46:49,410 --> 00:46:51,300
So the first step is to aggregate them.

976
00:46:51,300 --> 00:46:55,020
So you consolidate them into
one single structure, right?

977
00:46:55,020 --> 00:46:57,061
So you bring them all together
typically in a data lake

978
00:46:57,061 --> 00:47:01,121
and you aggregate them at the first stage.

979
00:47:01,121 --> 00:47:04,410
The second step is
encoding or structuring.

980
00:47:04,410 --> 00:47:05,460
So we then take

981
00:47:05,460 --> 00:47:09,090
the structured and unstructured
data that we've aggregated,

982
00:47:09,090 --> 00:47:10,951
and then create vector
embeddings out of them

983
00:47:10,951 --> 00:47:12,780
with enhanced metadata.

984
00:47:12,780 --> 00:47:14,959
So not just creating vector
embeddings would be helpful,

985
00:47:14,959 --> 00:47:18,720
but adding more extensive
metadata to it takes a long way.

986
00:47:18,720 --> 00:47:20,169
So the second step of structuring

987
00:47:20,169 --> 00:47:24,240
is creating vector embeddings
using your preferred model.

988
00:47:24,240 --> 00:47:26,619
All the models available out of Bedrock.

989
00:47:26,619 --> 00:47:29,130
So the third step is storage.

990
00:47:29,130 --> 00:47:32,280
So which is where the
persistent encoded data,

991
00:47:32,280 --> 00:47:33,510
like the data that we have.

992
00:47:33,510 --> 00:47:35,070
So the embeddings that we've created

993
00:47:35,070 --> 00:47:38,190
as part of the stage two, we
create them in stage three.

994
00:47:38,190 --> 00:47:40,410
So this is where S3 vector shines

995
00:47:40,410 --> 00:47:42,450
as a long-term persistent memory store

996
00:47:42,450 --> 00:47:44,659
because it has the scalability attributes

997
00:47:44,659 --> 00:47:48,750
from a latency perspective,
storage, and the performance.

998
00:47:48,750 --> 00:47:51,510
So S3 vectors becomes the preferred

999
00:47:51,510 --> 00:47:54,822
long-term memory store for AI agents.

1000
00:47:54,822 --> 00:47:57,450
Fourth is organization.

1001
00:47:57,450 --> 00:47:59,340
So essentially, we structure the data

1002
00:47:59,340 --> 00:48:03,210
through modeling, indexing,
and relationships.

1003
00:48:03,210 --> 00:48:05,655
So conversations are
organized chronologically,

1004
00:48:05,655 --> 00:48:09,026
product information is
organized hierarchically,

1005
00:48:09,026 --> 00:48:11,310
and order data is, you know,

1006
00:48:11,310 --> 00:48:13,902
spread across multiple conversations.

1007
00:48:13,902 --> 00:48:15,510
So it's mostly structured

1008
00:48:15,510 --> 00:48:17,516
across either time-based, topic-based

1009
00:48:17,516 --> 00:48:20,283
from this particular use case perspective.

1010
00:48:21,210 --> 00:48:24,150
The last stage is activation or retrieval.

1011
00:48:24,150 --> 00:48:25,410
So this is a crucial stage

1012
00:48:25,410 --> 00:48:28,070
where information becomes
actionable memory.

1013
00:48:28,070 --> 00:48:31,470
Through text search for
exact message matches,

1014
00:48:31,470 --> 00:48:34,260
vector search for semantic similarity,

1015
00:48:34,260 --> 00:48:37,713
and also graph reversal
for complex relationships.

1016
00:48:39,600 --> 00:48:41,190
And then we have the LLM.

1017
00:48:41,190 --> 00:48:44,850
So we then utilize the
LLM's built-in capabilities

1018
00:48:44,850 --> 00:48:47,190
and go through an iterative process.

1019
00:48:47,190 --> 00:48:51,630
So as we are interacting with
the chat bot more iteratively,

1020
00:48:51,630 --> 00:48:55,470
it's able to take the
learnings from the interaction,

1021
00:48:55,470 --> 00:48:58,705
put it in the storage, again,
goes through a reorganization,

1022
00:48:58,705 --> 00:49:02,220
it then gets activated and
then sent back to the LLM.

1023
00:49:02,220 --> 00:49:04,050
So this is the iterative process

1024
00:49:04,050 --> 00:49:07,140
which essentially gives
the ability for AI agents

1025
00:49:07,140 --> 00:49:10,383
to become truly intelligent
and adaptive systems.

1026
00:49:12,750 --> 00:49:15,780
So a memory unit is a structured container

1027
00:49:15,780 --> 00:49:19,080
that holds information plus
metadata and also relationships

1028
00:49:19,080 --> 00:49:20,940
about the information it's learned.

1029
00:49:20,940 --> 00:49:23,671
So that essentially makes it
useful for agent reasoning.

1030
00:49:23,671 --> 00:49:25,637
So unlike traditional data storage

1031
00:49:25,637 --> 00:49:28,050
which essentially treats
all information as equal,

1032
00:49:28,050 --> 00:49:29,760
there is a little bit of distinction

1033
00:49:29,760 --> 00:49:31,496
that we are trying to form here.

1034
00:49:31,496 --> 00:49:36,180
So essentially, memory units
carry several entities.

1035
00:49:36,180 --> 00:49:39,030
So first one being the temporal context,

1036
00:49:39,030 --> 00:49:41,730
which is when the information was learned.

1037
00:49:41,730 --> 00:49:44,040
The second one is a strength indicator,

1038
00:49:44,040 --> 00:49:46,290
which means how relevant
the information is

1039
00:49:46,290 --> 00:49:47,841
and how reliable it is.

1040
00:49:47,841 --> 00:49:50,670
The third is the associative links,

1041
00:49:50,670 --> 00:49:54,090
how it connects to other
memories that it has stored.

1042
00:49:54,090 --> 00:49:56,010
Fourth, the semantic context,

1043
00:49:56,010 --> 00:49:59,400
which is the overall meaning
captured with the interaction.

1044
00:49:59,400 --> 00:50:01,410
The last retrieval metadata,

1045
00:50:01,410 --> 00:50:03,183
how and when it should be accessed.

1046
00:50:04,140 --> 00:50:07,140
So data essentially becomes
memory at the point of storage,

1047
00:50:07,140 --> 00:50:08,880
which is step number three.

1048
00:50:08,880 --> 00:50:10,148
So when it's collected and stored

1049
00:50:10,148 --> 00:50:13,052
with the intent of enabling adaptation

1050
00:50:13,052 --> 00:50:15,960
and coherent interaction over time.

1051
00:50:15,960 --> 00:50:18,780
So this transformation is
what enables, you know,

1052
00:50:18,780 --> 00:50:22,893
the stateless applications
into truly intelligent agents.

1053
00:50:27,827 --> 00:50:29,880
So here's a comprehensive architecture

1054
00:50:29,880 --> 00:50:32,790
of, you know, deploying
agents using Amazon EKS.

1055
00:50:32,790 --> 00:50:36,690
So this is more of a self-managed
approach I would call.

1056
00:50:36,690 --> 00:50:38,010
So this essentially highlights

1057
00:50:38,010 --> 00:50:40,020
all the components working together.

1058
00:50:40,020 --> 00:50:42,990
So you have authentication, model serving,

1059
00:50:42,990 --> 00:50:44,690
memory management, and monitoring.

1060
00:50:45,960 --> 00:50:48,810
So notice how S3 vectors is integrated

1061
00:50:48,810 --> 00:50:49,830
within the memory construct.

1062
00:50:49,830 --> 00:50:51,570
So you have the ElastiCache and DynamoDB

1063
00:50:51,570 --> 00:50:53,490
as the short-term memory offerings

1064
00:50:53,490 --> 00:50:55,550
and then you've got S3
as the working memory

1065
00:50:55,550 --> 00:50:57,630
or the scratch pad as John covered.

1066
00:50:57,630 --> 00:51:00,584
And then we have S3 vectors
covering the long-term memory.

1067
00:51:00,584 --> 00:51:03,664
So this architecture also
includes proper security

1068
00:51:03,664 --> 00:51:05,310
with cognitive authentication

1069
00:51:05,310 --> 00:51:08,824
and monitoring built in
using Amazon CloudWatch.

1070
00:51:08,824 --> 00:51:12,270
So this is a production
ready pattern that can scale

1071
00:51:12,270 --> 00:51:15,003
to support multiple agents
and high user volumes.

1072
00:51:18,920 --> 00:51:21,734
So now let's look at a weather agent

1073
00:51:21,734 --> 00:51:25,590
on how it handles a simple query workflow.

1074
00:51:25,590 --> 00:51:28,080
So the agent maintains the session state

1075
00:51:28,080 --> 00:51:30,423
or its session state
in S3, as you can see.

1076
00:51:31,260 --> 00:51:34,557
It accesses its long term
memory through S3 vectors

1077
00:51:34,557 --> 00:51:36,630
and also stores its user content

1078
00:51:36,630 --> 00:51:38,523
in Amazon S3 data lake house.

1079
00:51:40,133 --> 00:51:43,530
So the MCP server essentially
enables the standardized

1080
00:51:43,530 --> 00:51:45,360
integration with external APIs.

1081
00:51:45,360 --> 00:51:47,750
So John covered the
MCP, the concept of MCP

1082
00:51:47,750 --> 00:51:50,370
and the MCP offering for S3 tables.

1083
00:51:50,370 --> 00:51:52,350
So we are essentially
leveraging an MCP server

1084
00:51:52,350 --> 00:51:54,450
in this particular example here.

1085
00:51:54,450 --> 00:51:56,820
So even the simple example
demonstrates the power

1086
00:51:56,820 --> 00:51:59,640
of having a persistent memory and context.

1087
00:51:59,640 --> 00:52:00,960
So notice how the agent

1088
00:52:00,960 --> 00:52:03,000
just doesn't answer the weather question,

1089
00:52:03,000 --> 00:52:04,962
it actually remembers the
use of location preferences

1090
00:52:04,962 --> 00:52:06,810
and also able to provide

1091
00:52:06,810 --> 00:52:08,860
personalized recommendations as a result.

1092
00:52:14,010 --> 00:52:14,910
The cognitive now.

1093
00:52:17,580 --> 00:52:21,414
- Okay, so I know you've
all got places to be.

1094
00:52:21,414 --> 00:52:23,490
So to wrap this up, you know,

1095
00:52:23,490 --> 00:52:27,240
I won't belabor this slide
other than to say, you know,

1096
00:52:27,240 --> 00:52:31,988
Rocket Companies is a home
financing organization

1097
00:52:31,988 --> 00:52:35,340
that helps people, you know,
through the whole process

1098
00:52:35,340 --> 00:52:36,810
of home ownership.

1099
00:52:36,810 --> 00:52:37,643
There's a good blog out there

1100
00:52:37,643 --> 00:52:40,281
if you search Rocket Companies, AWS,

1101
00:52:40,281 --> 00:52:44,333
and agents that'll go
into a lot more depth

1102
00:52:44,333 --> 00:52:47,310
of how they did this, their architecture.

1103
00:52:47,310 --> 00:52:50,190
But, you know, they used
Amazon Bedrock agents

1104
00:52:50,190 --> 00:52:53,567
to build an agent-powered
engagement platform

1105
00:52:53,567 --> 00:52:57,674
for their customers that
really helped their customers

1106
00:52:57,674 --> 00:53:00,613
resolve their queries in
their ask much more quickly

1107
00:53:00,613 --> 00:53:05,100
and gave much improved
guidance, which really helped

1108
00:53:05,100 --> 00:53:06,780
with their customer satisfaction.

1109
00:53:06,780 --> 00:53:09,180
So look up the Rocket Mortgages blog

1110
00:53:09,180 --> 00:53:10,241
if you wanna learn more.

1111
00:53:10,241 --> 00:53:13,993
So closing out with a
couple of key learnings

1112
00:53:13,993 --> 00:53:16,920
to hopefully tie all this together.

1113
00:53:16,920 --> 00:53:19,380
You know, the first is no matter

1114
00:53:19,380 --> 00:53:22,237
where you're gonna go
in your agentic journey,

1115
00:53:22,237 --> 00:53:23,953
make your data actionable

1116
00:53:23,953 --> 00:53:26,640
by building a modern data foundation,

1117
00:53:26,640 --> 00:53:31,410
ideally Iceberg-based, on Amazon S3.

1118
00:53:31,410 --> 00:53:34,302
And then use cataloging and metadata,

1119
00:53:34,302 --> 00:53:38,671
particularly in combination
with MCP servers and tools

1120
00:53:38,671 --> 00:53:41,850
so that agents can discover data

1121
00:53:41,850 --> 00:53:45,480
and use it and learn and evolve from it.

1122
00:53:45,480 --> 00:53:47,940
Second is scale cost effectively

1123
00:53:47,940 --> 00:53:51,295
because your data is going
to grow if you're successful,

1124
00:53:51,295 --> 00:53:55,529
and so use Amazon S3 as your
data foundation if it works,

1125
00:53:55,529 --> 00:54:00,529
and use S3 vectors as your
semantic data foundation

1126
00:54:01,020 --> 00:54:03,000
if that meets your needs.

1127
00:54:03,000 --> 00:54:05,910
Secondly, you want to iterate rapidly.

1128
00:54:05,910 --> 00:54:08,517
So this means you're going
to implement observability

1129
00:54:08,517 --> 00:54:11,575
and look at things like your
accuracy, your retrieving,

1130
00:54:11,575 --> 00:54:14,610
how your agents are
interacting with each other

1131
00:54:14,610 --> 00:54:16,212
and how they're evolving over time.

1132
00:54:16,212 --> 00:54:20,970
So you need to have a good
observability story in place.

1133
00:54:20,970 --> 00:54:24,960
And then second is make
your agents quickly move

1134
00:54:24,960 --> 00:54:28,470
from POC to production
and drive business value

1135
00:54:28,470 --> 00:54:30,690
so you're not one of those 40% companies

1136
00:54:30,690 --> 00:54:34,065
that's going to fail in your AI project.

1137
00:54:34,065 --> 00:54:38,070
You know, which means
consider using AgentCore

1138
00:54:38,070 --> 00:54:40,338
even if you want to take
an open source framework

1139
00:54:40,338 --> 00:54:43,440
just to reduce the
undifferentiated heavy lifting

1140
00:54:43,440 --> 00:54:45,630
you have to do on the security,

1141
00:54:45,630 --> 00:54:47,943
the infrastructure, the storage side.

1142
00:54:49,380 --> 00:54:52,114
So to wrap up with a few
actions and resources,

1143
00:54:52,114 --> 00:54:55,680
you know, we've got a
couple of blogs here.

1144
00:54:55,680 --> 00:54:59,400
There's the second one is the
Rocket Story that I mentioned,

1145
00:54:59,400 --> 00:55:02,988
and then the third one per
that EKS design pattern

1146
00:55:02,988 --> 00:55:07,590
is how to build a
self-managed RAG using EKS

1147
00:55:07,590 --> 00:55:11,160
and Amazon S3 vectors that Venkata wrote.

1148
00:55:11,160 --> 00:55:13,620
So thank you so much for your time.

1149
00:55:13,620 --> 00:55:15,183
We're happy to take questions.

