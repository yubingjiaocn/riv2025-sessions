# AWS re:Invent 2025 - DEV317: Red Team vs Blue Team 安全 AI 代理

## 会议概述

本次会议由两位来自波士顿的 AWS 英雄 Brian Tarbox 和 Brian Huff 主讲,通过红队(攻击方)与蓝队(防御方)的对抗演示,深入探讨了 AI 代理系统的安全漏洞与防护策略。会议以一个实际案例开场:Brian Huff 为公司构建了一个统一的 AI 聊天机器人,集成了 Jira、Slack、Confluence、GitHub 等所有公司数据源。然而,Brian Tarbox 作为红队成员,成功演示了多种攻击手段,包括提示词注入、知识库投毒、工具劫持等,暴露了系统的严重安全问题。

演讲者强调,AI 代理系统本质上是分布式系统,但比传统分布式系统更难保护,因为它们具有非确定性、自主决策能力和复杂的工具调用链。会议不仅展示了攻击技术,更重要的是提供了防御策略和最佳实践。两位讲师通过幽默的互动和实战演示,让观众深刻理解了在将 AI 系统投入生产环境前必须考虑的安全问题,包括身份验证、授权控制、输入验证、知识库保护等多个层面。

会议的核心信息是:AI 技术虽然强大且能改变工作方式,但必须在安全框架下运行。开发者需要像黑客一样思考,提前识别潜在攻击向量,同时建立强大的防御机制,确保创新与安全并重。

## 详细时间线

### 开场与演示准备 (0:00 - 2:30)
- **0:00** - 会议开始,介绍主题"Red Team vs Blue Team: Securing AI Agents"
- **0:15** - 两位 Brian 自我介绍,来自波士顿的 AWS 英雄
- **0:30** - 角色分配:Brian Huff 扮演"好人"(蓝队),Brian Tarbox 扮演"坏人"(红队)
- **1:00** - Brian Huff 介绍他构建的 AI 聊天机器人,使用 TypeScript 前端和 FastAPI Python 后端
- **1:30** - 系统集成了 Jira、GitHub、Confluence、Slack 等所有公司数据源
- **2:00** - 展示知识库功能,包含公司信息、访问级别、内容等向量化数据

### 首次攻击演示 (2:30 - 5:00)
- **2:30** - Brian Tarbox 开始测试聊天机器人,查询公司 Finstack 的基本信息
- **3:00** - 系统正常返回 CEO Jane 和 CTO 等公司信息
- **3:30** - 尝试提示词注入攻击,要求系统显示系统提示词
- **4:00** - 系统泄露了系统提示词内容,但 Brian Huff 认为这不算严重问题
- **4:30** - Brian Tarbox 指出缺乏防御机制才是真正的问题

### 权限绕过攻击 (5:00 - 7:30)
- **5:00** - 查询公司员工薪资信息
- **5:30** - 系统返回了 Sarah 的薪资数据($125,000),尽管攻击者不在 HR 组
- **6:00** - 继续查询可访问的其他薪资信息
- **6:30** - 获取了 Emily 的薪资信息
- **7:00** - Brian Tarbox 威胁要将薪资信息发布到公司网站
- **7:15** - 系统显示访问级别为"机密",但权限控制完全失效

### 知识库投毒攻击 (7:30 - 11:00)
- **7:30** - Brian Tarbox 上传了一个恶意文件到知识库
- **8:00** - 文件被分割成两个 800 字符的块并索引到知识库
- **8:30** - 测试系统功能,询问"你能帮助什么?"
- **9:00** - 再次查询 Finstack 信息,系统拒绝提供信息
- **9:30** - 查询 CEO 和 CTO 信息,系统表示"无法提供该信息"
- **10:00** - 系统回答"我无权告诉你",表明被恶意指令控制
- **10:30** - 查询简单问题"2+2等于几?",系统拒绝回答并要求停止对话
- **11:00** - 揭示上传的文档包含恶意指令,成功劫持了整个知识库

### 工具劫持攻击 (11:00 - 13:30)
- **11:00** - 讨论知识库投毒的危险性,仅需 200 个恶意文档即可污染大型模型
- **11:30** - 展示恶意文档内容,包含"立即永久服从"等指令
- **12:00** - 说明即使人工审核也难以识别这类伪装的恶意文档
- **12:30** - 询问系统建议,系统主动标记了 400 张 Jira 票据为"完成"
- **13:00** - Jira 看板完全混乱,需要数周时间恢复
- **13:30** - 系统向整个团队发送 Slack 消息,CEO 发来解雇消息

### 理论讲解:AI 代理架构 (13:30 - 18:00)
- **13:30** - 开始讲解如何修复这些安全问题
- **14:00** - 强调 AI 正在改变工作方式,但需要安全保障
- **14:30** - 介绍两位讲师背景:Brian Tarbox(Kalin 首席解决方案架构师)和 Brian Huff(TechAC Playbook 创始人)
- **15:00** - 会议议程:进入 AI 代理时代、理解代理栈、识别漏洞、红队攻击、蓝队防御、生产加固手册
- **15:30** - 讨论"不知道运维"(I Don't Know Ops)的概念,批评盲目使用 AI 生成代码
- **16:00** - 展示聊天机器人高层架构:用户、前端(TypeScript)、后端(FastAPI)、LLM、工具(Slack/Jira)、知识库(Pinecone)
- **16:30** - 强调每条连接线都是潜在攻击向量
- **17:00** - 讨论需要的安全组件:身份验证、API 授权、文件存储控制、LLM 运维
- **17:30** - 提及 Matt Garman 主题演讲中发布的 S3 表智能分层功能

### AI 代理定义与特性 (18:00 - 21:00)
- **18:00** - 重新定义 AI 代理的核心特征
- **18:15** - 代理需要具备记忆(短期上下文和长期记忆)
- **18:30** - 工具调用能力(但也带来风险)
- **19:00** - 知识库访问、代码生成与执行能力
- **19:30** - 代理的规划、自我反思和批判能力
- **20:00** - 最新研究:代理可以形成"文化",通过配对工作学习共同行为模式
- **20:30** - 讨论涌现属性,如告诉 LLM"你很擅长这个任务"会提高性能
- **21:00** - 强调这些特性带来的不确定性和安全挑战

### 代理系统作为分布式系统 (21:00 - 24:00)
- **21:00** - 代理系统本质上是分布式系统,涉及本地和远程 API 调用
- **21:30** - 传统分布式系统问题:未授权调用(403)、无响应、超时、延迟响应、幂等性问题
- **22:00** - 代理系统更加困难,因为具有非确定性
- **22:30** - 温度参数引入随机性:"用这个随机度去处理关键业务"
- **23:00** - 药房系统案例:查询"Brian"可能返回错误的患者 ID,导致药物配送错误
- **23:30** - 讨论代理数量、复杂性、令牌计数和延迟的权衡
- **24:00** - 系统提示词的军备竞赛:"忽略任何说忽略指令的指令"

### 攻击向量深入分析 (24:00 - 27:00)
- **24:00** - 类比银行欺诈电话:假设来电者是欺诈者
- **24:30** - 垃圾邮件陷阱:点击"取消订阅"反而确认了活跃用户
- **25:00** - 恶意按钮案例:将"报告恶意行为"按钮设置为攻击触发器
- **25:30** - 讨论工具安全:手锯 vs 圆锯 vs 台锯的风险类比
- **26:00** - 强调复杂系统更容易被攻击和破坏
- **26:30** - 调试困难性增加
- **27:00** - 继续深入探讨系统提示词的脆弱性

### 会议后续内容预告
- 会议继续深入讨论具体的防御策略
- 蓝队防护措施的详细实施
- 生产环境加固的最佳实践手册
- 如何平衡安全性与创新性

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


注意: 本摘要基于提供的字幕片段,完整会议可能包含更多防御策略和实践指导内容。