1
00:00:00,900 --> 00:00:01,920
- Hi everyone.

2
00:00:01,920 --> 00:00:03,150
Thanks for taking some time

3
00:00:03,150 --> 00:00:05,520
from your busy re:Invent schedule

4
00:00:05,520 --> 00:00:08,070
to come and listen to this session.

5
00:00:08,070 --> 00:00:10,770
We're gonna talk today
about grounding GenAI

6
00:00:10,770 --> 00:00:14,670
with enterprise data, working
with AgentCore and Coveo.

7
00:00:14,670 --> 00:00:16,635
I'm Nick Bordeleau, I work at Coveo.

8
00:00:16,635 --> 00:00:19,443
I work in the product relation team.

9
00:00:20,430 --> 00:00:23,070
Looking forward to give
you some information

10
00:00:23,070 --> 00:00:24,933
around grounding on enterprise data.

11
00:00:26,640 --> 00:00:29,370
So the agenda for today,
we're gonna be work,

12
00:00:29,370 --> 00:00:32,070
talking about why
grounding is so important.

13
00:00:32,070 --> 00:00:34,350
A couple of notion to cover there.

14
00:00:34,350 --> 00:00:35,940
Also, a bit of architecture about how

15
00:00:35,940 --> 00:00:38,130
to integrate Coveo with Bedrock.

16
00:00:38,130 --> 00:00:41,520
The secret sauce, no spoiler alert,

17
00:00:41,520 --> 00:00:42,690
is gonna be prompting.

18
00:00:42,690 --> 00:00:45,960
Everything is about
prompting in the LLM world.

19
00:00:45,960 --> 00:00:48,713
And a few next step after
that, if you wanna learn more.

20
00:00:49,650 --> 00:00:52,290
I wanted to start by not bragging,

21
00:00:52,290 --> 00:00:54,060
but I wanna set the stage a bit

22
00:00:54,060 --> 00:00:56,190
so that you understand
who we are, what we do.

23
00:00:56,190 --> 00:00:57,840
Also, give some credibility

24
00:00:57,840 --> 00:01:00,030
so that you should listen
to what I have to say.

25
00:01:00,030 --> 00:01:02,310
We are an enterprise search company.

26
00:01:02,310 --> 00:01:03,990
We've been working with many customers,

27
00:01:03,990 --> 00:01:06,360
helping them get GenAI to production.

28
00:01:06,360 --> 00:01:08,340
This is an example of Dell.

29
00:01:08,340 --> 00:01:11,070
Dell using Coveo to power
multiple of their portal.

30
00:01:11,070 --> 00:01:12,540
If you want to buy a laptop,

31
00:01:12,540 --> 00:01:13,830
if you wanna buy material from them,

32
00:01:13,830 --> 00:01:14,880
it's gonna be powered by Coveo.

33
00:01:14,880 --> 00:01:16,560
If you go and look at the support section,

34
00:01:16,560 --> 00:01:18,690
also it's gonna be also powered by Coveo.

35
00:01:18,690 --> 00:01:19,950
They have real complex product

36
00:01:19,950 --> 00:01:22,470
and they use us to provide answer

37
00:01:22,470 --> 00:01:25,170
to their user when they
try to solve their issues.

38
00:01:25,170 --> 00:01:26,400
Same thing with Nvidia.

39
00:01:26,400 --> 00:01:28,320
Nvidia has all the money in the world.

40
00:01:28,320 --> 00:01:29,700
They could be building that solution.

41
00:01:29,700 --> 00:01:32,700
They decide to partner with Coveo to offer

42
00:01:32,700 --> 00:01:35,250
question answering to their customer

43
00:01:35,250 --> 00:01:36,603
through the Coveo solution.

44
00:01:37,770 --> 00:01:39,450
Intuit decided to integrate Coveo

45
00:01:39,450 --> 00:01:40,680
inside their own application.

46
00:01:40,680 --> 00:01:43,290
So if you're into Intuit, if
you're looking to find how

47
00:01:43,290 --> 00:01:45,750
to work with the product,
if you have questions,

48
00:01:45,750 --> 00:01:47,400
also gonna be Coveo there.

49
00:01:47,400 --> 00:01:49,500
And Vanguard in the financial

50
00:01:49,500 --> 00:01:53,100
and financial services area
is also a big customer.

51
00:01:53,100 --> 00:01:55,500
Coveo, they use Coveo
like all across the board,

52
00:01:55,500 --> 00:01:57,150
internal, external, and that's an example

53
00:01:57,150 --> 00:01:59,160
of their personal investor portal.

54
00:01:59,160 --> 00:02:01,620
If you're looking to get
information around their product,

55
00:02:01,620 --> 00:02:03,150
not investing information,

56
00:02:03,150 --> 00:02:04,260
but information around their product,

57
00:02:04,260 --> 00:02:05,700
that's gonna be provided by Coveo.

58
00:02:05,700 --> 00:02:08,940
So we help our customer go
to production with GenAI,

59
00:02:08,940 --> 00:02:10,440
we build a whole solution,

60
00:02:10,440 --> 00:02:12,930
but we also have option for our customers

61
00:02:12,930 --> 00:02:14,970
if they wanna integrate with a solution

62
00:02:14,970 --> 00:02:19,110
from AWS to be able to
build their own solution.

63
00:02:19,110 --> 00:02:22,740
So what I've been talking
about so far is the left side.

64
00:02:22,740 --> 00:02:25,830
Yeah, left side of that
slide where we do everything.

65
00:02:25,830 --> 00:02:29,370
Basically, we index your
content, we build an index,

66
00:02:29,370 --> 00:02:30,840
we ground the prompt, we build a prompt,

67
00:02:30,840 --> 00:02:32,640
and then we also provide the UI component

68
00:02:32,640 --> 00:02:34,140
for you to be able to deliver that

69
00:02:34,140 --> 00:02:36,900
on whatever portal you wanna deploy it.

70
00:02:36,900 --> 00:02:39,960
We decided to help our customers to offer

71
00:02:39,960 --> 00:02:42,210
the rest of the platform as a retriever

72
00:02:42,210 --> 00:02:44,190
and then offer integration
point with Bedrock,

73
00:02:44,190 --> 00:02:46,713
AgentCore, Q Business,
and also Quick Suite.

74
00:02:48,270 --> 00:02:50,700
And that's what we're gonna
be covering today basically.

75
00:02:50,700 --> 00:02:54,420
How to integrate Coveo into
the second one, into AgentCore.

76
00:02:54,420 --> 00:02:56,100
But it's gonna be pretty
similar if you wanna work

77
00:02:56,100 --> 00:02:58,743
with Quick Suite or
other solution from AWS.

78
00:03:02,760 --> 00:03:04,310
That's a slide I stole from AWS

79
00:03:05,790 --> 00:03:07,290
that they presented a couple of weeks ago.

80
00:03:07,290 --> 00:03:08,490
I thought it was interesting.

81
00:03:08,490 --> 00:03:10,260
I fully agree with what's in there.

82
00:03:10,260 --> 00:03:12,360
Agentic is probably the future

83
00:03:12,360 --> 00:03:15,150
that's gonna be enabled
the LLMs to be fully used

84
00:03:15,150 --> 00:03:16,650
to their full potential.

85
00:03:16,650 --> 00:03:19,890
I was really interested to
see that there's, in any case,

86
00:03:19,890 --> 00:03:21,870
there's always a dependency on data.

87
00:03:21,870 --> 00:03:23,430
If you are working with GenAI,

88
00:03:23,430 --> 00:03:27,150
you need to ground the LLM
based on enterprise data.

89
00:03:27,150 --> 00:03:28,860
You need to ground them so
that they don't hallucinate.

90
00:03:28,860 --> 00:03:30,510
So there's a strong dependency on data.

91
00:03:30,510 --> 00:03:32,040
This is where we come into play.

92
00:03:32,040 --> 00:03:33,780
Same thing for Agentic AI.

93
00:03:33,780 --> 00:03:35,580
There's always a strong
dependency on tools

94
00:03:35,580 --> 00:03:37,860
and data so that these agents

95
00:03:37,860 --> 00:03:39,840
or those model know how to behave

96
00:03:39,840 --> 00:03:42,363
and know where to get fresh information.

97
00:03:44,520 --> 00:03:47,910
So let's jump into the
meat of this presentation.

98
00:03:47,910 --> 00:03:50,370
Why LLM needs to be grounded?

99
00:03:50,370 --> 00:03:51,750
They need to be factually accurate.

100
00:03:51,750 --> 00:03:53,910
So for an LLM to be factually accurate,

101
00:03:53,910 --> 00:03:55,440
you need to provide them some information.

102
00:03:55,440 --> 00:03:58,320
They've been trained on
data that is basically dated

103
00:03:58,320 --> 00:03:59,760
and they don't know
what's true, what's not.

104
00:03:59,760 --> 00:04:02,010
If you're ask them question,
they're gonna answer

105
00:04:02,010 --> 00:04:03,900
and they're gonna basically give them,

106
00:04:03,900 --> 00:04:05,550
give you back the
information that they got in.

107
00:04:05,550 --> 00:04:07,350
If it's not what your brand thinks about,

108
00:04:07,350 --> 00:04:09,870
what should be told to your
customer, they don't care.

109
00:04:09,870 --> 00:04:12,300
They're just gonna give back
the information to the user

110
00:04:12,300 --> 00:04:14,280
on the other side trying
to get information.

111
00:04:14,280 --> 00:04:16,680
If you ground them, it's
now a source of truth

112
00:04:16,680 --> 00:04:18,420
that you're giving to the LLM

113
00:04:18,420 --> 00:04:19,950
and they're gonna be able to provide more,

114
00:04:19,950 --> 00:04:22,623
most accurate information
and be factually accurate.

115
00:04:23,700 --> 00:04:25,920
If you want your LLM to be
also contextually relevant,

116
00:04:25,920 --> 00:04:27,240
you need to ground them.

117
00:04:27,240 --> 00:04:29,610
LLM don't know much about
the users on the other side

118
00:04:29,610 --> 00:04:31,920
of asking the question.

119
00:04:31,920 --> 00:04:34,590
You want to be able to
provide project information,

120
00:04:34,590 --> 00:04:36,240
user history, those kind of things needs

121
00:04:36,240 --> 00:04:37,980
to be added into the prompt.

122
00:04:37,980 --> 00:04:39,177
That can be done by grounding

123
00:04:39,177 --> 00:04:41,553
the LLM to make it easier for you.

124
00:04:43,200 --> 00:04:44,430
Traceability and trust.

125
00:04:44,430 --> 00:04:48,270
When you ground an LLM, you
can now do source attribution.

126
00:04:48,270 --> 00:04:51,900
If you want your users to be
able to trust what they read,

127
00:04:51,900 --> 00:04:53,370
you want them to be able to see

128
00:04:53,370 --> 00:04:55,080
where that information is coming from.

129
00:04:55,080 --> 00:04:56,340
If you don't ground an LLM,

130
00:04:56,340 --> 00:04:58,020
the information is coming
from the LLM itself

131
00:04:58,020 --> 00:04:59,400
and there's no way to trace back

132
00:04:59,400 --> 00:05:00,900
where this information is coming from.

133
00:05:00,900 --> 00:05:02,910
When you are grounding an LLM,

134
00:05:02,910 --> 00:05:04,320
you're basically providing
them the information

135
00:05:04,320 --> 00:05:07,620
that they should be using
to give back an answer.

136
00:05:07,620 --> 00:05:09,600
This is where you can
do source attribution

137
00:05:09,600 --> 00:05:12,300
and then the users can
then navigate those links

138
00:05:12,300 --> 00:05:14,403
and they can validate if
the information is accurate,

139
00:05:14,403 --> 00:05:16,953
that they can gain
confidence on the system.

140
00:05:18,180 --> 00:05:19,200
Dynamic knowledge update.

141
00:05:19,200 --> 00:05:20,520
Another important one.

142
00:05:20,520 --> 00:05:22,920
Basically, LLMs have been trained

143
00:05:22,920 --> 00:05:25,470
on set of data that is fixed on time.

144
00:05:25,470 --> 00:05:27,420
If you wanna be able to
provide them update on data,

145
00:05:27,420 --> 00:05:29,550
you need to provide that
as grounding information.

146
00:05:29,550 --> 00:05:32,790
So maybe the information
that you wanna expose

147
00:05:32,790 --> 00:05:34,410
in that LLM is already
available out there,

148
00:05:34,410 --> 00:05:35,670
is already public, yes,

149
00:05:35,670 --> 00:05:37,110
but it's dated on the last time

150
00:05:37,110 --> 00:05:38,370
the model has been trained.

151
00:05:38,370 --> 00:05:40,410
So you need to be able to
provide grounding information

152
00:05:40,410 --> 00:05:42,750
to those model or for those reasons.

153
00:05:42,750 --> 00:05:45,570
The holy grail of grounding
is to reduce hallucination.

154
00:05:45,570 --> 00:05:49,170
You want LLM to be able to
answer factually with information

155
00:05:49,170 --> 00:05:52,410
that you trust so that it
don't provide false answer

156
00:05:52,410 --> 00:05:53,733
to your customers.

157
00:05:55,080 --> 00:05:57,180
LLMs are really good at lying

158
00:05:57,180 --> 00:05:58,380
and having us believe that,

159
00:05:58,380 --> 00:05:59,970
that the information that
they provide is true.

160
00:05:59,970 --> 00:06:01,950
So by grounding them,
you're able to reduce

161
00:06:01,950 --> 00:06:04,320
the amount of hallucination
that they are doing.

162
00:06:04,320 --> 00:06:07,350
And an enterprise is
just, it's just mandatory.

163
00:06:07,350 --> 00:06:09,780
There's not enough information
about your enterprise

164
00:06:09,780 --> 00:06:11,310
available out there so that the models

165
00:06:11,310 --> 00:06:12,600
don't know about your data.

166
00:06:12,600 --> 00:06:15,963
You need to ground them so
that they are fully accurate.

167
00:06:17,760 --> 00:06:20,193
Now a bit more on what
makes a good retriever.

168
00:06:21,870 --> 00:06:24,810
So a good retriever need to
have a good depth of knowledge.

169
00:06:24,810 --> 00:06:27,780
You need to be able to look
at a large amount of data.

170
00:06:27,780 --> 00:06:30,240
It's fairly easy to build
a VectorDB to be able

171
00:06:30,240 --> 00:06:31,770
to get a small set of data to be able

172
00:06:31,770 --> 00:06:34,770
to ground your model based
on a small set of data.

173
00:06:34,770 --> 00:06:37,680
But what we see is, when
end users these days

174
00:06:37,680 --> 00:06:40,620
is that they go and talk with an LLM,

175
00:06:40,620 --> 00:06:41,730
they ask first question

176
00:06:41,730 --> 00:06:43,440
and then they don't go back to,

177
00:06:43,440 --> 00:06:45,420
in the Google day you were
looking at the results

178
00:06:45,420 --> 00:06:46,830
and then you were navigating that result

179
00:06:46,830 --> 00:06:48,300
and then you were now, you were gone,

180
00:06:48,300 --> 00:06:50,220
you are on your own trying
to find the information.

181
00:06:50,220 --> 00:06:51,900
Within LLM, people go there

182
00:06:51,900 --> 00:06:53,580
and they ask one question, they refine,

183
00:06:53,580 --> 00:06:54,960
they ask a second question.

184
00:06:54,960 --> 00:06:56,910
So you don't know exactly what's the scope

185
00:06:56,910 --> 00:06:58,530
of what they're gonna be looking for.

186
00:06:58,530 --> 00:07:00,810
So you wanna be able
to provide a larger set

187
00:07:00,810 --> 00:07:03,240
of information so that when
you talk with that LLM,

188
00:07:03,240 --> 00:07:05,610
they're always able to get
an answer out of that LLM.

189
00:07:05,610 --> 00:07:08,940
They don't end up in a data dead end

190
00:07:08,940 --> 00:07:11,190
where there's no
information to be retrieved.

191
00:07:14,670 --> 00:07:17,130
Just like the LLM needs to be grounded,

192
00:07:17,130 --> 00:07:19,770
good retriever needs to
be contextually aware.

193
00:07:19,770 --> 00:07:23,010
You want LLM, you want
the retriever to be able

194
00:07:23,010 --> 00:07:24,840
to know about the users in front of you.

195
00:07:24,840 --> 00:07:26,130
You need that information to be able

196
00:07:26,130 --> 00:07:29,130
to personalize the
information being returned

197
00:07:29,130 --> 00:07:31,380
based on who you are, based
on what you have access to,

198
00:07:31,380 --> 00:07:32,760
based on what you've done before.

199
00:07:32,760 --> 00:07:34,560
Retriever need to be able to take

200
00:07:34,560 --> 00:07:35,880
that information into account

201
00:07:35,880 --> 00:07:37,350
and retrieve a set of information

202
00:07:37,350 --> 00:07:39,240
that's gonna be used to ground the LLM

203
00:07:39,240 --> 00:07:40,650
based on who you are, based on

204
00:07:40,650 --> 00:07:42,090
what you're currently trying to do.

205
00:07:42,090 --> 00:07:43,440
But that's extremely important that

206
00:07:43,440 --> 00:07:45,933
that retriever are able
to be contextually aware.

207
00:07:47,310 --> 00:07:51,330
Relevance quality is probably
the most important one here

208
00:07:51,330 --> 00:07:53,910
because you are providing information,

209
00:07:53,910 --> 00:07:56,010
in fact, to the LLM
before the inference time,

210
00:07:56,010 --> 00:07:58,200
the LLM, you're basically telling LLM

211
00:07:58,200 --> 00:08:00,043
just to use his linguistic capacity.

212
00:08:00,043 --> 00:08:02,520
You don't him to use his own information.

213
00:08:02,520 --> 00:08:05,040
You're basically telling
him, answer user question

214
00:08:05,040 --> 00:08:07,230
or decide course of action
based on the information

215
00:08:07,230 --> 00:08:08,850
that I'm providing you at the bottom.

216
00:08:08,850 --> 00:08:09,960
Don't choose anything else.

217
00:08:09,960 --> 00:08:11,640
Use what I'm providing you here.

218
00:08:11,640 --> 00:08:13,620
So if what you're
providing is not relevant,

219
00:08:13,620 --> 00:08:16,380
is not accurate, then you're
gonna provide false sensor

220
00:08:16,380 --> 00:08:17,730
and that's by design.

221
00:08:17,730 --> 00:08:20,640
So relevance quality
is extremely important

222
00:08:20,640 --> 00:08:22,953
when you are working with a retriever.

223
00:08:26,730 --> 00:08:28,593
Execution speed is also important.

224
00:08:30,030 --> 00:08:31,410
Retrieval, the retrieval part

225
00:08:31,410 --> 00:08:34,830
of a RAG pipeline happened
at the first stage basically.

226
00:08:34,830 --> 00:08:36,600
So when you talk with the LLM these days,

227
00:08:36,600 --> 00:08:37,950
if they're not grounded,

228
00:08:37,950 --> 00:08:39,420
the answers are gonna be coming fast.

229
00:08:39,420 --> 00:08:41,790
And then you're used to see
the answer being streamed.

230
00:08:41,790 --> 00:08:44,250
So as the answer is generated,
it's being returned to you

231
00:08:44,250 --> 00:08:46,260
and you can consume that information.

232
00:08:46,260 --> 00:08:47,940
When you are grounding in LLM,

233
00:08:47,940 --> 00:08:50,010
that information is retrieved at first.

234
00:08:50,010 --> 00:08:51,270
So there's a first step

235
00:08:51,270 --> 00:08:53,460
that's gonna be the user basically waiting

236
00:08:53,460 --> 00:08:55,860
on the LLM to start to generate an answer.

237
00:08:55,860 --> 00:08:57,600
So you need that retriever
to be really fast

238
00:08:57,600 --> 00:08:59,340
so that user can start to see the answer

239
00:08:59,340 --> 00:09:00,483
as soon as possible.

240
00:09:02,070 --> 00:09:05,490
Format supported, you
can do multiple thing

241
00:09:05,490 --> 00:09:07,530
with the retriever, you can
do multiple thing with an LLM,

242
00:09:07,530 --> 00:09:09,930
you can do deep research,
you can ask them question

243
00:09:09,930 --> 00:09:11,790
to guide you toward exploration.

244
00:09:11,790 --> 00:09:13,230
You can do multiple things.

245
00:09:13,230 --> 00:09:15,510
The classic way retriever work these days

246
00:09:15,510 --> 00:09:17,160
is by returning chunks of information.

247
00:09:17,160 --> 00:09:21,360
Passages of information
basically are parts

248
00:09:21,360 --> 00:09:22,830
of information that are useful for the LLM

249
00:09:22,830 --> 00:09:27,030
to able to answer the
question is being asked.

250
00:09:27,030 --> 00:09:28,680
But sometime you just want to have links

251
00:09:28,680 --> 00:09:30,870
so that people can go and
can navigate those links

252
00:09:30,870 --> 00:09:32,430
to do further exploration.

253
00:09:32,430 --> 00:09:34,020
Sometime you wanna do deep research

254
00:09:34,020 --> 00:09:36,120
or you want to answer a
really complex question

255
00:09:36,120 --> 00:09:38,790
and you don't need some
passages of a document.

256
00:09:38,790 --> 00:09:40,020
You need the whole document

257
00:09:40,020 --> 00:09:42,270
so that the LLM can look
at the whole information

258
00:09:42,270 --> 00:09:44,700
and make a mind of itself
and answer the full question.

259
00:09:44,700 --> 00:09:46,380
So I think the retriever it that is able

260
00:09:46,380 --> 00:09:48,660
to provide you various
format of information.

261
00:09:48,660 --> 00:09:50,310
It's extremely important as well.

262
00:09:51,840 --> 00:09:54,000
And concise, being concise and precise,

263
00:09:54,000 --> 00:09:55,770
returning the right information

264
00:09:55,770 --> 00:09:58,320
in as the shortest format as possible

265
00:09:58,320 --> 00:10:00,720
will make the job of the LLM easier

266
00:10:00,720 --> 00:10:02,160
because it's easier to consume

267
00:10:02,160 --> 00:10:03,450
smaller more portion of information.

268
00:10:03,450 --> 00:10:05,640
You don't have to decipher
what you've returned.

269
00:10:05,640 --> 00:10:07,410
They already get the right
passage of information

270
00:10:07,410 --> 00:10:09,510
to answer the the questions

271
00:10:09,510 --> 00:10:11,190
and it's also gonna be cheaper for you.

272
00:10:11,190 --> 00:10:12,900
The more information
you put in that prompt,

273
00:10:12,900 --> 00:10:15,060
the more you're gonna have
to pay for those input token.

274
00:10:15,060 --> 00:10:18,450
So if you have a retriever
that is concise and precise,

275
00:10:18,450 --> 00:10:20,130
in the end you're gonna be paying less

276
00:10:20,130 --> 00:10:22,080
for that LLM inference,

277
00:10:22,080 --> 00:10:24,570
although input token are
not the most expensive one.

278
00:10:24,570 --> 00:10:26,133
In the end, it shows up anyway.

279
00:10:28,110 --> 00:10:30,780
We offer a tool set of retriever,

280
00:10:30,780 --> 00:10:34,500
retrieval tool, sorry, we
offer that to MCP quickly.

281
00:10:34,500 --> 00:10:37,740
We have, in that tool set,
we have a passage retrieval.

282
00:10:37,740 --> 00:10:40,260
So we're able to extract
passages from your documents

283
00:10:40,260 --> 00:10:41,910
and retrieve those documents
so you can use them

284
00:10:41,910 --> 00:10:44,100
to ground whatever tools you're trying

285
00:10:44,100 --> 00:10:45,420
to build within that LLM.

286
00:10:45,420 --> 00:10:47,160
We also have an answer generation tool

287
00:10:47,160 --> 00:10:50,070
in that MCP server where if you're looking

288
00:10:50,070 --> 00:10:53,670
to get an answer and use
Coveo more as an agent,

289
00:10:53,670 --> 00:10:56,040
basically, in the
question answering agent,

290
00:10:56,040 --> 00:10:58,110
you can decide to leave out the prompt,

291
00:10:58,110 --> 00:11:01,020
but simply get answer from Coveo as an API

292
00:11:01,020 --> 00:11:03,000
and then provide those answer to your LLM

293
00:11:03,000 --> 00:11:04,650
when you decide that might be specific

294
00:11:04,650 --> 00:11:06,450
to do something a bit more simple

295
00:11:06,450 --> 00:11:08,610
than answering complex question.

296
00:11:08,610 --> 00:11:10,590
We also have search
and document retrieval.

297
00:11:10,590 --> 00:11:12,390
So if you just want to
get a list of results

298
00:11:12,390 --> 00:11:15,000
for users to explore
and do their own things

299
00:11:15,000 --> 00:11:16,860
with the data, we can also offer that.

300
00:11:16,860 --> 00:11:18,450
And also full document retrieval,

301
00:11:18,450 --> 00:11:20,670
as I was saying before,
for a deeper research

302
00:11:20,670 --> 00:11:22,170
and for more complex question,

303
00:11:22,170 --> 00:11:24,690
getting access to full
document, not just passages,

304
00:11:24,690 --> 00:11:26,670
not just stacking passages one to another,

305
00:11:26,670 --> 00:11:30,045
getting the full document,
let's say procedure

306
00:11:30,045 --> 00:11:33,477
to rebuild a complex
engine or stuff like that.

307
00:11:33,477 --> 00:11:34,980
You can get built from Coveo,

308
00:11:34,980 --> 00:11:37,383
making the job of the LLM much easier.

309
00:11:38,790 --> 00:11:40,740
This is a, an architecture that we suggest

310
00:11:40,740 --> 00:11:42,480
to our customer when
they want to get started

311
00:11:42,480 --> 00:11:44,190
to build an agent.

312
00:11:44,190 --> 00:11:47,370
Pretty simple, nothing
groundbreaking in there.

313
00:11:47,370 --> 00:11:48,870
In the middle you have an agent.

314
00:11:48,870 --> 00:11:50,910
That agent obviously use an LLM.

315
00:11:50,910 --> 00:11:52,890
There is long-term and
short-term memory at the top.

316
00:11:52,890 --> 00:11:54,990
So they can know, they can have a session,

317
00:11:54,990 --> 00:11:57,390
they can work in the context
of a few interaction.

318
00:11:57,390 --> 00:11:59,850
You basically have a
conversation with that agent.

319
00:11:59,850 --> 00:12:01,950
That agent is connected via Gateway.

320
00:12:01,950 --> 00:12:04,169
That's a service from AgentCore

321
00:12:04,169 --> 00:12:05,610
to the Coveo MCP server.

322
00:12:05,610 --> 00:12:06,923
And other side, you have all the tools

323
00:12:06,923 --> 00:12:09,270
that've been talking
about are offered there

324
00:12:09,270 --> 00:12:12,510
on the side via an MCP server.

325
00:12:12,510 --> 00:12:16,110
So the Gateway is gonna be
registering those tools.

326
00:12:16,110 --> 00:12:19,230
Now the agent has a set
of tools that he can use

327
00:12:19,230 --> 00:12:22,260
to do whatever job you wanted him to do.

328
00:12:22,260 --> 00:12:25,050
And we're also leveraging
the identity provider

329
00:12:25,050 --> 00:12:28,530
from AgentCore so that actions

330
00:12:28,530 --> 00:12:30,690
that are performed on Coveo are performed

331
00:12:30,690 --> 00:12:33,210
as the user who's dedicated
on the other side.

332
00:12:33,210 --> 00:12:36,090
So if I go, if I try to
ask question to an agent,

333
00:12:36,090 --> 00:12:38,040
if I don't have access
to some specific part

334
00:12:38,040 --> 00:12:40,740
of the information that
is under Coveo index,

335
00:12:40,740 --> 00:12:42,270
those information won't gonna

336
00:12:42,270 --> 00:12:43,830
be coming true to the agent.

337
00:12:43,830 --> 00:12:45,600
So there's no leakage or information.

338
00:12:45,600 --> 00:12:49,440
So that's also an important
part to add in there,

339
00:12:49,440 --> 00:12:51,600
to have some more contextual information

340
00:12:51,600 --> 00:12:53,200
based on who you are, basically.

341
00:12:55,770 --> 00:12:56,793
Secret sauce.

342
00:12:57,630 --> 00:13:00,150
It's a combination of prompt

343
00:13:00,150 --> 00:13:02,220
and MCP description, basically.

344
00:13:02,220 --> 00:13:04,440
You are building an agent,

345
00:13:04,440 --> 00:13:05,940
you are giving him a set of tools.

346
00:13:05,940 --> 00:13:08,100
So you need to be
extremely explicit around

347
00:13:08,100 --> 00:13:10,860
what those tools are,
when to use those tools,

348
00:13:10,860 --> 00:13:13,230
what they're for, how they
work and all these things.

349
00:13:13,230 --> 00:13:16,080
In the end, it's a model
that's gonna be using

350
00:13:16,080 --> 00:13:17,940
those description to decide what to do

351
00:13:17,940 --> 00:13:19,680
and how to use your tools.

352
00:13:19,680 --> 00:13:23,160
So this is a kind of a
meta prompt that we work

353
00:13:23,160 --> 00:13:24,423
with a few customers.

354
00:13:25,470 --> 00:13:26,940
Global directive, who you are,

355
00:13:26,940 --> 00:13:28,560
what's the main job of the agent?

356
00:13:28,560 --> 00:13:31,410
So that's up to you to
decide what you do with it.

357
00:13:31,410 --> 00:13:32,670
But you wanna talk about grounding,

358
00:13:32,670 --> 00:13:34,860
you wanna talk about memory,
you wanna talk about sources.

359
00:13:34,860 --> 00:13:37,680
So there's gonna be grounding available

360
00:13:37,680 --> 00:13:40,200
that's gonna be done with XYZ tools.

361
00:13:40,200 --> 00:13:42,540
So you need to be explicit with that.

362
00:13:42,540 --> 00:13:44,400
Make it clear distinction
also between memory

363
00:13:44,400 --> 00:13:47,160
and fresh information from the retriever.

364
00:13:47,160 --> 00:13:49,050
So it's another source of information.

365
00:13:49,050 --> 00:13:51,990
Memory is also information
much more limited,

366
00:13:51,990 --> 00:13:52,823
but it's another source.

367
00:13:52,823 --> 00:13:55,380
So you need to be
explicit when to use both.

368
00:13:55,380 --> 00:13:57,720
If you want your source to be cited,

369
00:13:57,720 --> 00:13:59,460
you also need to be explicit around that.

370
00:13:59,460 --> 00:14:02,823
So it's a bit like taking
something by the end,

371
00:14:04,225 --> 00:14:05,760
a young child by the end,

372
00:14:05,760 --> 00:14:07,405
but in the end you do it once.

373
00:14:07,405 --> 00:14:10,320
You test it multiple
times, but you do it once

374
00:14:10,320 --> 00:14:12,360
and at some point the agent
become into autonomous

375
00:14:12,360 --> 00:14:16,890
and be able to use those
tools autonomously.

376
00:14:16,890 --> 00:14:18,480
We have some question that go as far

377
00:14:18,480 --> 00:14:21,030
as defining some types of question.

378
00:14:21,030 --> 00:14:22,080
What is coming from memory,

379
00:14:22,080 --> 00:14:23,160
what is coming from retrieval?

380
00:14:23,160 --> 00:14:24,870
So you can go much further,

381
00:14:24,870 --> 00:14:26,640
but if you build
something good at the top,

382
00:14:26,640 --> 00:14:28,290
that's a really good
starting point to be able

383
00:14:28,290 --> 00:14:30,963
to use a retriever in a good way.

384
00:14:32,160 --> 00:14:35,310
The other part is the MCP description.

385
00:14:35,310 --> 00:14:38,280
So you have an agent,
you told 'em how to use,

386
00:14:38,280 --> 00:14:40,530
not how, but you told them
basically when to use the tools,

387
00:14:40,530 --> 00:14:42,120
what to do with these tools.

388
00:14:42,120 --> 00:14:43,980
On the other side, you have an MCP server

389
00:14:43,980 --> 00:14:45,480
that count these tools.

390
00:14:45,480 --> 00:14:47,670
What we provide by
default is pretty simple.

391
00:14:47,670 --> 00:14:49,200
There's a retriever agent that,

392
00:14:49,200 --> 00:14:50,340
which is not a retriever,

393
00:14:50,340 --> 00:14:52,530
but there's a retriever, which is Coveo.

394
00:14:52,530 --> 00:14:54,750
You have tools for search for retrieval,

395
00:14:54,750 --> 00:14:56,880
you have tools for the full document,

396
00:14:56,880 --> 00:14:59,040
but we don't know what you're exposing

397
00:14:59,040 --> 00:15:00,270
in your index on the other side.

398
00:15:00,270 --> 00:15:01,620
So you need to be explicit around

399
00:15:01,620 --> 00:15:04,620
what's gonna be available
through these tools.

400
00:15:04,620 --> 00:15:05,950
So you want to

401
00:15:09,030 --> 00:15:11,580
first use the tool naming standard.

402
00:15:11,580 --> 00:15:12,690
We've see so many confusion

403
00:15:12,690 --> 00:15:14,850
with customer using dot
in the name of the tools.

404
00:15:14,850 --> 00:15:19,590
So avoid dots go with
snake caves, maybe dashes,

405
00:15:19,590 --> 00:15:22,170
but tool naming is quite important.

406
00:15:22,170 --> 00:15:23,370
The most important one is probably

407
00:15:23,370 --> 00:15:25,890
having good description for your tools.

408
00:15:25,890 --> 00:15:27,300
Stick to concise description.

409
00:15:27,300 --> 00:15:29,850
Once again, that's gonna be used

410
00:15:29,850 --> 00:15:30,840
by an LLM on your side.

411
00:15:30,840 --> 00:15:33,210
So the more precise your
tool descriptions are,

412
00:15:33,210 --> 00:15:35,610
the more, the easier
it's gonna be for the LLM

413
00:15:35,610 --> 00:15:37,290
to use those tools properly.

414
00:15:37,290 --> 00:15:40,830
Stick to one two sentence,
front load the information.

415
00:15:40,830 --> 00:15:43,230
If you are, if the tool
is to create a case,

416
00:15:43,230 --> 00:15:45,570
requires authentication,
start with creating a case,

417
00:15:45,570 --> 00:15:48,100
requires authentication
signal, put that secondary

418
00:15:48,990 --> 00:15:52,230
verbs and type of object
that's gonna be retrieving.

419
00:15:52,230 --> 00:15:54,720
So lots of guideline we can provide,

420
00:15:54,720 --> 00:15:55,890
more information around that.

421
00:15:55,890 --> 00:15:58,410
But defining your tool the right way

422
00:15:58,410 --> 00:16:01,920
is gonna make a mile for the difference

423
00:16:01,920 --> 00:16:04,023
for your LLM agent to use them.

424
00:16:05,070 --> 00:16:07,440
And also schema versus description.

425
00:16:07,440 --> 00:16:11,130
When you use an MCP server,
you get a whole schema,

426
00:16:11,130 --> 00:16:14,370
a JSON schema for that MCP server,

427
00:16:14,370 --> 00:16:16,050
which counting description for the tools.

428
00:16:16,050 --> 00:16:18,660
The whole schema is what's
gonna be used at runtime

429
00:16:18,660 --> 00:16:21,090
for the agent on the other
side to call your tools.

430
00:16:21,090 --> 00:16:25,530
So procedure description,
arguments, all the things,

431
00:16:25,530 --> 00:16:26,910
the all the things that are required

432
00:16:26,910 --> 00:16:29,310
to call your tools are gonna be in there

433
00:16:29,310 --> 00:16:31,440
but the only part that
the LLM is gonna use

434
00:16:31,440 --> 00:16:33,360
to basically decide when to use

435
00:16:33,360 --> 00:16:35,220
and what to use as of tools

436
00:16:35,220 --> 00:16:36,180
are gonna be the description.

437
00:16:36,180 --> 00:16:38,370
So they are part of the same bundle,

438
00:16:38,370 --> 00:16:39,660
but they're used for different things.

439
00:16:39,660 --> 00:16:41,850
So make sure that you
provide good description

440
00:16:41,850 --> 00:16:43,863
for your tools.

441
00:16:45,780 --> 00:16:48,720
That's basically what I
had planned for today.

442
00:16:48,720 --> 00:16:51,360
We have a booth around
the Atlassian booth.

443
00:16:51,360 --> 00:16:53,010
If you make the tour
of the Atlassian booth,

444
00:16:53,010 --> 00:16:53,843
you'll find Coveo.

445
00:16:53,843 --> 00:16:56,220
It's a booth 1529.

446
00:16:56,220 --> 00:16:58,890
We also have a AI masterclass series that,

447
00:16:58,890 --> 00:16:59,723
those are webinar, I think.

448
00:16:59,723 --> 00:17:01,170
There's probably one around every

449
00:17:01,170 --> 00:17:02,463
two weeks or every month.

450
00:17:03,360 --> 00:17:04,440
It can be used.

451
00:17:04,440 --> 00:17:05,550
You can use the QR code here

452
00:17:05,550 --> 00:17:07,830
or you can go on coveo.com to find

453
00:17:07,830 --> 00:17:11,040
the latest AI masterclass.

454
00:17:11,040 --> 00:17:13,530
And I have to tell you to go to the app

455
00:17:13,530 --> 00:17:16,530
and fill the survey, actually,

456
00:17:16,530 --> 00:17:19,080
it'll be appreciated if you fill a survey

457
00:17:19,080 --> 00:17:20,880
to know how to improve.

458
00:17:20,880 --> 00:17:23,280
And there's a few more minutes

459
00:17:23,280 --> 00:17:24,690
if people have question,

460
00:17:24,690 --> 00:17:26,970
happy to answer question or
if you want to come talk,

461
00:17:26,970 --> 00:17:27,803
I'm also available.

462
00:17:27,803 --> 00:17:31,110
I'll be at the booth for
the rest of the day as well.

463
00:17:31,110 --> 00:17:31,943
Thank you.

