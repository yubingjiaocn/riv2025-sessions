# AWS re:Invent 2025 - IND 3325 会议总结

## 会议概述

本次会议主题为"零停机时间大规模迁移：Peacock全球流媒体平台迁移至Amazon EKS"。会议由AWS首席解决方案架构师Ian、NBC Universal Sky全球平台工程总监Mans、平台基础设施负责人Pete以及AWS高级技术客户经理Manish共同主讲。

NBC Universal和Sky的全球流媒体技术团队管理着包括Peacock（美国市场超过4000万用户）、Sky Showtime（欧洲）、Showmax（非洲）以及Now/Wow品牌（英国、德国、意大利等）在内的多个流媒体平台。这些平台使用单一代码库和同构基础设施层，支持NBA、NFL、英超等重大体育赛事直播。团队面临的核心挑战是：平台工程团队70%的时间用于开发任务，30%用于运维工作（如Kubernetes升级、安全补丁等），而每日部署量持续增长。为了释放更多工程时间并减少运维负担，团队决定从自管理Kubernetes集群迁移到Amazon EKS，同时必须确保零停机、不影响开发团队的日常工作。

迁移项目涉及1600个应用、数百个业务单元、超过1000名开发人员，且平台历史可追溯至2014年（Kubernetes 1.0之前）。团队制定了严格的目标：开发团队无需采取任何行动、实时迁移、零停机时间、12个月内完成，最理想状态是"团队甚至不知道迁移发生了"。通过与AWS的紧密合作，团队开发了六阶段自动化迁移流程，利用Velero、Route 53、Amazon S3等服务，最终在12个月内成功完成迁移，其中前6个月用于构建自动化工具和测试框架，后4个月完成了所有集群的实际迁移。

## 详细时间线与关键要点

### 00:00 - 会议开场与背景介绍
- **00:00** - 会议开始，介绍主题：IND 3325 - 零停机时间大规模迁移Peacock全球流媒体至Amazon EKS
- **00:15** - 演讲嘉宾介绍：AWS首席解决方案架构师Ian、NBC Universal Sky工程总监Mans、平台基础设施负责人Pete、AWS技术客户经理Manish
- **00:30** - 强调大规模Kubernetes集群迁移至EKS的挑战性

### 01:00 - Peacock宣传视频
- **01:00** - 播放NBA在Peacock平台上的流媒体服务宣传片
- **01:30** - 展示Peacock的体育内容优势（140场NBA比赛、每周赛事等）

### 02:00 - 全球流媒体技术团队概况
- **02:00** - Mans介绍全球流媒体技术（GST）团队的组织架构
- **02:15** - Peacock在美国拥有超过4000万用户
- **02:30** - 团队在欧洲和非洲也有其他流媒体业务
- **02:45** - 强调在体育直播领域的领先地位（NBA、NFL、英超、MLB等）
- **03:00** - 提及一年半前的NFL外卡赛事占美国带宽30%以上
- **03:15** - 团队分布在美国、英国、捷克、葡萄牙和印度

### 03:30 - 多租户架构介绍
- **03:30** - 多租户是核心工作方式，涵盖前端和基础设施
- **03:45** - 展示四个流媒体品牌：Peacock（美国）、Sky Showtime（欧洲）、Showmax（非洲）、Now/Wow（欧洲多国）
- **04:00** - 单一代码库支持所有前端和同构基础设施层
- **04:15** - 强调跨开发团队保持一致性的重要性，以提高开发速度
- **04:30** - 中央平台团队由Pete管理

### 04:45 - 问题陈述
- **04:45** - 当前平台工程团队70%时间用于开发任务，30%用于运维工作（Kubernetes升级、安全补丁等）
- **05:00** - 目标是减少运维负担，释放更多工程时间
- **05:15** - 每日部署量持续增长，涉及数百个跨时区的开发团队
- **05:30** - 关键挑战：如何在不干扰开发团队的情况下释放工程时间

### 05:45 - 平台工程原则
- **05:45** - Pete介绍平台工程部门的四大核心原则
- **06:00** - 原则1：工程师是我们的客户 - 开发团队应该主动想要使用平台产品
- **06:15** - 原则2：保护客户接口 - 限制接口变更次数，避免影响已集成的开发者
- **06:30** - 原则3：交付能力而非技术 - 从客户使用角度反向设计，而非单纯追求最新技术
- **06:45** - 原则4：可靠性设计 - 支持全球领先流媒体服务，几秒钟的停机都不可接受

### 07:00 - 迁移历史背景
- **07:00** - 解释为何2025年才讨论EKS迁移
- **07:15** - 团队从2014-2015年开始使用Kubernetes（1.0版本之前）
- **07:30** - 早期团队规模小，遇到大量bug，积极贡献给Kubernetes社区
- **07:45** - 学到的关键经验：控制器模式和最终一致性的价值
- **08:00** - EKS于2017-2018年发布，但Peacock的推出改变了规模
- **08:15** - 用户基数、开发者数量、平台关注度都呈数量级增长
- **08:30** - 2024年底推出首个基于EKS的流媒体平台Showmax
- **08:45** - 面临挑战：如何将过去10年构建的成熟平台迁移到EKS

### 09:00 - 增长曲线展示
- **09:00** - 展示图表：前几年增长平稳，EKS发布后使用量激增
- **09:15** - 说明迁移的紧迫性

### 09:30 - 迁移规模
- **09:30** - 展示迁移范围：自管理Kubernetes（使用Terraform、Ansible、EC2、NLB/ELB等）
- **09:45** - 超过1000名开发者使用平台
- **10:00** - 数百个业务单元，不同组织结构和工作方式
- **10:15** - 关键数字：1600个应用需要迁移
- **10:30** - 这是技术层面的核心挑战

### 10:45 - 传统迁移方案的问题
- **10:45** - 分析传统方案：构建新平台并要求所有人迁移
- **11:00** - 计算：假设每个应用平均2周，需要61名全职工程师工作一整年
- **11:15** - 这是巨大的投资，且开发团队并不关心迁移（他们只想开发功能）
- **11:30** - 这种方案不符合"为团队做重活"的原则

### 11:45 - 五大迁移目标
- **11:45** - 目标1：开发团队无需采取任何行动 - 保持kubectl和Kubernetes API接口一致
- **12:00** - 目标2：必须实时迁移 - 流媒体平台无法停机
- **12:15** - 目标3：零停机时间 - 即使几秒钟的停机也不可接受
- **12:30** - 目标4：12个月内完成 - 这是平台工程团队自我设定的目标
- **12:45** - 团队希望利用Karpenter、自动模式等EKS新特性
- **13:00** - 目标5（黄金标准）：团队甚至不知道迁移发生了 - 在保持能力一致的同时革新技术

### 13:15 - AWS合作伙伴关系
- **13:15** - Ian介绍AWS解决方案架构师在复杂迁移规划中的角色
- **13:30** - 过去8年建立的信任关系帮助实现客户目标
- **13:45** - 讨论迁移工具和AWS服务
- **14:00** - 分享跨行业的大规模迁移架构模式
- **14:15** - 引入解决方案架构专家和服务团队验证方案
- **14:30** - 使用AWS Well-Architected Framework验证架构
- **14:45** - 关注规模、冗余、弹性、可靠性和成本
- **15:00** - 建立了跨业务和AWS的关系网络

### 15:15 - 迁移阶段工具和服务
- **15:15** - 深入研究迁移工具和AWS服务
- **15:30** - 完全验证迁移方法
- **15:45** - Pete团队构建了六阶段迁移流程
- **16:00** - 每个步骤都向前推进、验证和测试
- **16:15** - 关键：能够回退并恢复运营状态
- **16:30** - 核心服务：Velero + Amazon S3（Kubernetes备份恢复）
- **16:45** - Amazon EKS（管理Kubernetes集群）
- **17:00** - Kafka（消息处理）、Route 53（DNS）
- **17:15** - 可观测性至关重要 - 观察现有基础设施和EKS过渡过程
- **17:30** - 确保客户体验不受影响

### 17:45 - 迁移架构详解
- **17:45** - Pete展示自管理集群的详细架构图
- **18:00** - 集成点：CI/CD工具、开发者kubectl、CDN、第三方
- **18:15** - 关键：平台团队控制路由入口
- **18:30** - 平台对应用部署方式有明确规范

### 18:45 - 六阶段迁移流程
- **18:45** - 阶段1：启动新EKS集群
  - 在同一VPC中
  - 使用相同的出口NAT（流量看起来来自同一集群）
  - 简化防火墙配置
  - 创建新Route 53区域（但不委托）

- **19:15** - 阶段2：使用Velero迁移核心服务
  - 与AWS合作确认Velero是事实标准
  - 需要围绕Velero构建大量自动化
  - 迁移CoreDNS、Ingress、监控等核心服务
  - 当时还没有EKS插件，需要手动操作

- **19:45** - 阶段3：迁移应用工作负载
  - 平台团队进入应用空间（通常由开发团队管理）
  - 需要深入理解每个应用
  - 承担服务可靠性和可用性的责任

- **20:15** - 阶段4：委托DNS
  - 这是大爆炸式迁移，必须全栈迁移
  - 由于Kubernetes服务发现和路由，无法逐个服务迁移
  - 需要整个堆栈在新集群中运行

- **20:45** - 阶段5和6：清理旧集群
  - 删除2014年以来的旧集群
  - 虽然有些不舍，但为了未来更好

### 21:00 - 自动化和控制器的重要性
- **21:00** - 强调依赖自动化和控制器进行迁移
- **21:15** - 在这种规模下无法依赖人工操作
- **21:30** - 人工操作不安全且无法在12个月内完成

### 21:45 - 六阶段详细流程
- **21:45** - 阶段1：预检验证
  - 检查Route 53区域TTL
  - 大幅降低TTL以提高切换灵活性
  - 提前数周完成，确保所有客户端获得新TTL

- **22:15** - 阶段2：构建EKS集群
  - 部署专用端到端测试套件
  - 设置Velero机制（与S3集成）
  - 在自管理和EKS集群中都进行设置

- **22:45** - 阶段3：使用Velero快照
  - 停止集群的传入变更
  - 由于平台规范化，可以集中禁用所有开发团队的管道
  - 这是开发者可能首次意识到迁移的时刻
  - 实际收到的消息很少，大多数人没有察觉

- **23:15** - 阶段4：工作负载迁移
  - 采用50/50扩展策略
  - 缩减自管理集群，扩展EKS集群
  - 部分出于成本考虑
  - 避免两个大规模应用同时访问持久层可能出现的问题

- **23:45** - 阶段5：流量切换
  - 进行区域委托
  - 流量开始转移到新集群
  - EKS集群扩展到100%
  - 自管理集群缩减

- **24:00** - 阶段6：重新启用管道
  - 阶段3-6是开发团队可能察觉的时期
  - 整个过程在数小时内完成（单日活动）
  - 快速执行以避免长时间阻塞开发团队

### 24:30 - 测试套件详解
- **24:30** - 测试是项目成功的关键
- **24:45** - 合成负载测试
  - 持续监控延迟和可用性（P99、P99.5）
  - 在负载下测试整个平台
  - 不是功能测试，而是持续注入负载
  - 平台团队拥有的服务，可以管理从请求到响应的整个过程

- **25:15** - 双区域验证
  - 为EKS创建新区域但不委托
  - 平台团队负责确保服务运行
  - 开发团队无法访问（不知道如何访问EKS中的新pod）
  - 进行低级功能测试（不是全规模负载测试）
  - 检查pod状态、健康检查、延迟、HTTP状态码分布

- **25:45** - 持续比较
  - 对比自管理集群和EKS集群的指标
  - 查看两个集群之间的差异
  - 即使应用有大量204或404响应，也能验证两边没有差异

- **26:15** - 节点和集群级检查
  - 确保所有节点健康
  - 持续运行节点和集群级检查

- **26:30** - 第三方防火墙监控
  - 这是最令人担心的部分
  - 无法管理不属于团队的防火墙
  - 最可能导致事故的原因不是自己的防火墙，而是其他团队的防火墙
  - 使用VPC Flow Logs和CloudWatch
  - 查找异常和连接丢弃的峰值
  - 对比自管理和EKS的差异
  - 确实发现了一些问题（大量数据包被丢弃，表明防火墙问题）

- **27:00** - Victoria Metrics作为基础
  - 在这种规模下无法依赖Prometheus甚至Thanos
  - 需要更分布式、可扩展的解决方案
  - 对于这种分析至关重要

### 27:30 - 复杂工作负载迁移
- **27:30** - 大多数应用是无状态的，迁移相对简单
- **27:45** - 有状态工作负载挑战
  - 示例：使用Kafka进行队列的服务
  - 生产者-消费者架构
  - 问题：Kafka集群配置了固定数量的生产者和消费者

- **28:00** - Kafka迁移策略
  - 如果突然将消费者和生产者数量翻倍，会严重影响Kafka性能
  - 可能导致Kafka集群降级
  - 采用精细调整方法
  - 增量迁移：±1的增量
  - 在EKS中增加一对消费者-生产者，在自管理集群中减少一对
  - 构建自动化处理多个用例
  - 与Kafka专家密切合作

- **28:45** - 多区域策略
  - 将流量从正在迁移的环境转移
  - 等待队列清空到零
  - 对于没有多区域的平台，选择一天中最安静的时段
  - 确保队列尽可能接近零
  - 没有遇到重大问题

### 29:15 - 迁移时间线成果
- **29:15** - 12个月目标在开始时相当雄心勃勃
- **29:30** - 前6个月：零集群迁移
  - 每次汇报都说"还没有迁移任何集群"
  - 向Mans等领导汇报时压力很大
  - 但获得了Mans和团队的信任和支持
  - 这段时间在开发工具和自动化

- **30:00** - Q2末：首个集群迁移
  - 达到内部目标
  - 完成六阶段流程的构建

- **30:15** - 后4个月：完成所有迁移
  - 在接下来的6个月中（实际上是4个月）迁移了全球流媒体的所有集群
  - 完全依赖于构建的自动化和测试
  - 对自动化和测试充满信心

### 30:30 - 会议结束
- 会议在此处字幕截断，但已涵盖迁移项目的核心内容

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


关键成功因素总结：
1. 6个月构建自动化和测试框架
2. 六阶段可重复迁移流程
3. 全面的测试套件（合成负载、双区域验证、节点检查、防火墙监控）
4. 与AWS的紧密合作
5. 平台工程原则的坚持
6. 对开发团队透明的迁移过程