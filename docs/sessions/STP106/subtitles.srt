1
00:00:00,708 --> 00:00:02,869
Hello everyone, my name's Dan and I

2
00:00:02,869 --> 00:00:05,030
am the CEO and co-founder of Mary

3
00:00:05,030 --> 00:00:05,769
Technology.

4
00:00:06,299 --> 00:00:08,630
Um, so we're a legal tech

5
00:00:08,630 --> 00:00:10,909
firm based in Sydney, but now with a global

6
00:00:10,909 --> 00:00:12,909
presence, and we help law

7
00:00:12,909 --> 00:00:15,169
firms automate, uh, document

8
00:00:15,169 --> 00:00:17,429
review. That's a

9
00:00:17,429 --> 00:00:19,429
major challenge for large language

10
00:00:19,429 --> 00:00:21,708
models, and I wanna talk to you today about

11
00:00:21,708 --> 00:00:23,870
how Mary's trying to solve that.

12
00:00:24,899 --> 00:00:27,059
Just before we start, can I ask how many

13
00:00:27,059 --> 00:00:28,079
people here are

14
00:00:28,379 --> 00:00:30,420
uh heads of legal operations

15
00:00:30,420 --> 00:00:32,978
inside of uh large enterprises

16
00:00:32,978 --> 00:00:33,560
or

17
00:00:33,819 --> 00:00:35,609
uh have your own law firm? Yeah,

18
00:00:35,899 --> 00:00:37,240
OK, great, cool.

19
00:00:38,060 --> 00:00:39,848
Hello? You can't do those.

20
00:00:40,899 --> 00:00:42,978
Um, so here's the problem, uh,

21
00:00:43,109 --> 00:00:44,250
large language models,

22
00:00:44,509 --> 00:00:46,509
uh, even with retrieval augmented generation

23
00:00:46,509 --> 00:00:47,658
or agentic frameworks,

24
00:00:47,950 --> 00:00:50,228
are not fit for purpose for legal dispute

25
00:00:50,228 --> 00:00:51,408
resolution workloads.

26
00:00:53,429 --> 00:00:55,509
There's a number of problems. I'm gonna talk about 4

27
00:00:55,509 --> 00:00:57,509
today, the first one being the

28
00:00:57,509 --> 00:00:58,149
training problem.

29
00:00:59,219 --> 00:01:01,459
So what do I mean by the availability of training data,

30
00:01:01,658 --> 00:01:03,700
so The sorts of

31
00:01:03,700 --> 00:01:05,819
data that we work on every day

32
00:01:05,819 --> 00:01:08,049
for law firms and legal teams

33
00:01:08,049 --> 00:01:09,480
that deal with disputes,

34
00:01:10,219 --> 00:01:12,278
they're very sensitive, and so

35
00:01:12,459 --> 00:01:14,879
this sort of information isn't available publicly,

36
00:01:15,180 --> 00:01:17,260
and you certainly can't collect and train on

37
00:01:17,260 --> 00:01:19,299
that data when it contains sensitive

38
00:01:19,299 --> 00:01:21,918
information from law firms' customers

39
00:01:22,099 --> 00:01:23,980
or your internal employees.

40
00:01:25,129 --> 00:01:27,448
The second challenge is that there isn't a single

41
00:01:27,448 --> 00:01:29,930
right answer to tell a

42
00:01:30,290 --> 00:01:32,528
large language model to sort of trend

43
00:01:32,528 --> 00:01:34,609
towards, because there's always at least

44
00:01:34,609 --> 00:01:35,549
two sides

45
00:01:35,808 --> 00:01:37,189
of a matter.

46
00:01:37,448 --> 00:01:39,668
And so you can't just say, hey, here's the right answer

47
00:01:39,668 --> 00:01:41,168
and try and move and

48
00:01:41,689 --> 00:01:43,489
probe towards that. You have to

49
00:01:43,849 --> 00:01:46,189
include and understand all of the potential

50
00:01:47,579 --> 00:01:49,849
available narratives and correct answers depending on

51
00:01:49,849 --> 00:01:51,189
which side you're representing.

52
00:01:52,418 --> 00:01:53,379
The second problem,

53
00:01:53,698 --> 00:01:55,939
and maybe the biggest one, is that large language

54
00:01:55,939 --> 00:01:57,969
models are compression machines.

55
00:01:58,219 --> 00:02:00,219
That's what they do really well, and I'm just

56
00:02:00,219 --> 00:02:02,418
going to talk to you a little bit about some of these

57
00:02:02,418 --> 00:02:03,629
stages of compression.

58
00:02:04,260 --> 00:02:06,418
So. The first thing

59
00:02:06,418 --> 00:02:09,008
that a large language model does when it receives a document

60
00:02:09,270 --> 00:02:10,250
is it turns,

61
00:02:10,508 --> 00:02:12,838
ultimately turns that page into an image.

62
00:02:13,149 --> 00:02:15,368
And then if that image has words on it,

63
00:02:15,669 --> 00:02:17,838
or an image, even if it's actually

64
00:02:17,838 --> 00:02:20,028
just a picture, it will still ultimately convert

65
00:02:20,028 --> 00:02:20,929
that into text.

66
00:02:21,490 --> 00:02:23,659
But particularly in legal documents where you actually have

67
00:02:23,659 --> 00:02:24,599
lots of words there,

68
00:02:24,899 --> 00:02:26,979
it's gonna take away and remove

69
00:02:26,979 --> 00:02:28,179
some of that nuance,

70
00:02:28,580 --> 00:02:30,860
legal nuance and important meaning that

71
00:02:30,860 --> 00:02:33,139
may be present there, so things like handwriting

72
00:02:33,139 --> 00:02:34,719
or a small note on the side.

73
00:02:35,179 --> 00:02:36,808
Once it's turned that

74
00:02:37,258 --> 00:02:38,330
document into text,

75
00:02:38,659 --> 00:02:40,699
it then ultimately turns into tokens and then

76
00:02:40,699 --> 00:02:42,699
into embeddings, then a contextual

77
00:02:42,699 --> 00:02:44,778
compression, and ultimately something

78
00:02:44,778 --> 00:02:47,139
that's capable of uh chunking

79
00:02:47,139 --> 00:02:48,020
and summarization.

80
00:02:49,038 --> 00:02:51,199
Each layer of that compression

81
00:02:51,569 --> 00:02:52,319
removes meaning,

82
00:02:52,639 --> 00:02:54,899
and it's that meaning and nuance that's so important

83
00:02:54,899 --> 00:02:55,419
to

84
00:02:55,679 --> 00:02:57,960
law firms and anybody trying to understand a dispute

85
00:02:57,960 --> 00:03:00,028
or facts, which is sort of

86
00:03:00,028 --> 00:03:01,179
the core of a dispute,

87
00:03:01,639 --> 00:03:04,189
well. Here's

88
00:03:04,189 --> 00:03:06,349
what they're really good at though, we're not saying large language models

89
00:03:06,349 --> 00:03:08,308
are bad, we're actually saying they're really, really good,

90
00:03:08,629 --> 00:03:11,129
but they're particularly good at being

91
00:03:11,429 --> 00:03:13,550
generally capable. So they handle

92
00:03:13,550 --> 00:03:15,129
a massive range of tasks,

93
00:03:15,588 --> 00:03:17,699
they scale across massive corpuses

94
00:03:17,699 --> 00:03:18,508
of documents,

95
00:03:18,819 --> 00:03:21,149
and they generate fluent, plausible

96
00:03:21,149 --> 00:03:21,929
text without.

97
00:03:22,679 --> 00:03:23,689
Deep preprocessing.

98
00:03:24,588 --> 00:03:26,669
So they're generalists and they're really

99
00:03:26,669 --> 00:03:28,710
good at that, and so you can, as you can probably tell,

100
00:03:29,069 --> 00:03:31,000
uh, this slide was written by an LLM

101
00:03:31,300 --> 00:03:32,889
it's done its lovely emojis

102
00:03:33,490 --> 00:03:35,550
and done a very good job of, of telling me what

103
00:03:35,550 --> 00:03:36,469
the slide should say.

104
00:03:37,838 --> 00:03:39,028
The third problem,

105
00:03:39,399 --> 00:03:41,520
facts are not in the uploaded

106
00:03:41,520 --> 00:03:43,599
data. This is a bit of a strange

107
00:03:43,599 --> 00:03:45,599
one and something that

108
00:03:45,599 --> 00:03:47,740
might take a small amount of

109
00:03:47,960 --> 00:03:48,800
explanation,

110
00:03:49,069 --> 00:03:51,558
but the facts are what is at the core of

111
00:03:51,558 --> 00:03:53,258
a legal matter or a dispute.

112
00:03:53,800 --> 00:03:55,360
So I'm just going to give you an example.

113
00:03:56,349 --> 00:03:58,349
Here's a fact that might be present

114
00:03:58,349 --> 00:03:58,969
inside of a document.

115
00:03:59,819 --> 00:04:01,719
It gives the date, which is wonderful,

116
00:04:02,258 --> 00:04:04,659
and then it says A. Smith

117
00:04:04,659 --> 00:04:05,710
reported an error.

118
00:04:06,469 --> 00:04:08,508
So here's a few of those challenges about

119
00:04:08,508 --> 00:04:10,610
why you can't just extract this piece of data

120
00:04:10,750 --> 00:04:12,490
and assume that it's ready

121
00:04:12,909 --> 00:04:15,008
uh in its current state to be used

122
00:04:15,008 --> 00:04:16,170
for downstream

123
00:04:16,750 --> 00:04:17,899
processing using AI.

124
00:04:19,259 --> 00:04:21,338
What if there's multiple people within

125
00:04:21,338 --> 00:04:23,338
that corpus of documents called

126
00:04:23,338 --> 00:04:25,699
A Smith? One could be Alice,

127
00:04:25,819 --> 00:04:27,059
one could be Andrew,

128
00:04:27,338 --> 00:04:29,600
but. In order to make this a

129
00:04:29,600 --> 00:04:31,879
useful or meaningful act, you actually

130
00:04:31,879 --> 00:04:34,298
have to understand which A Smith that is.

131
00:04:34,759 --> 00:04:36,798
Uh, and by just using a large language model, you can't do

132
00:04:36,798 --> 00:04:38,899
that. Uh, we're in the US

133
00:04:38,899 --> 00:04:40,399
today, so

134
00:04:40,838 --> 00:04:41,389
where we're from,

135
00:04:41,720 --> 00:04:42,670
Australia, um,

136
00:04:42,959 --> 00:04:44,959
these two dates are completely separate, so

137
00:04:44,959 --> 00:04:46,449
this could be the 5th of,

138
00:04:46,759 --> 00:04:48,798
uh, January, February, March, or, yeah, there

139
00:04:48,798 --> 00:04:49,829
we go, 3rd of May.

140
00:04:50,189 --> 00:04:52,199
So you've gotta try and

141
00:04:52,199 --> 00:04:54,199
understand what is the context of this matter, so that

142
00:04:54,199 --> 00:04:56,278
you can actually say, great, it's probably this date.

143
00:04:57,009 --> 00:04:59,100
In this matter, is a reported error on this date

144
00:04:59,100 --> 00:05:00,119
even important?

145
00:05:00,738 --> 00:05:03,088
That's obviously more to do with context,

146
00:05:03,329 --> 00:05:05,519
and so maybe this isn't a relevant fact

147
00:05:05,519 --> 00:05:07,639
for you to understand and dig into more.

148
00:05:08,139 --> 00:05:09,879
It's also fragmented.

149
00:05:10,459 --> 00:05:12,699
How many times is this particular fact

150
00:05:12,699 --> 00:05:13,358
mentioned

151
00:05:13,660 --> 00:05:15,838
throughout all of these documents, and do they

152
00:05:16,199 --> 00:05:18,338
potentially conflict with this fact or support

153
00:05:18,338 --> 00:05:20,428
it? And finally, provenance,

154
00:05:20,750 --> 00:05:22,608
what kind of document did it come from?

155
00:05:23,028 --> 00:05:25,059
If this is, for example, a primary

156
00:05:25,059 --> 00:05:25,730
document,

157
00:05:26,069 --> 00:05:27,738
um maybe it's come from.

158
00:05:28,838 --> 00:05:31,160
Somebody detailing what a CCTV camera

159
00:05:31,160 --> 00:05:31,899
saw or

160
00:05:32,678 --> 00:05:34,759
or if it's from hearsay from somebody's statement that

161
00:05:34,759 --> 00:05:35,660
was given to

162
00:05:36,358 --> 00:05:37,790
a police officer, for example,

163
00:05:38,079 --> 00:05:40,100
all of those have different meanings as to how

164
00:05:40,639 --> 00:05:42,420
relevant and meaningful they are when

165
00:05:43,079 --> 00:05:45,470
related in court or in a litigation

166
00:05:45,480 --> 00:05:48,319
process. Here's

167
00:05:48,319 --> 00:05:50,639
another example, this is actually from my co-founder

168
00:05:50,639 --> 00:05:52,119
Rowan's medical documents,

169
00:05:52,439 --> 00:05:54,519
and there's a couple of challenges in here

170
00:05:54,519 --> 00:05:56,829
that I'll actually hopefully show you how Mary,

171
00:05:57,048 --> 00:05:59,319
our, our, our platform deals with it just a little

172
00:05:59,319 --> 00:06:01,350
later. But the one thing I'm gonna point

173
00:06:01,350 --> 00:06:03,439
out here is, and this is incredibly common,

174
00:06:03,838 --> 00:06:04,379
PT.

175
00:06:04,678 --> 00:06:06,420
What it actually means here is patient.

176
00:06:07,000 --> 00:06:09,278
Now, what would happen if you put this fact into

177
00:06:09,278 --> 00:06:10,459
a large language model?

178
00:06:11,000 --> 00:06:13,199
Well, it wouldn't understand that it's talking

179
00:06:13,199 --> 00:06:13,798
about Rowan.

180
00:06:14,939 --> 00:06:16,939
Who is the person it's actually referring to,

181
00:06:17,019 --> 00:06:19,059
or rather the patient itself, so you need

182
00:06:19,059 --> 00:06:20,358
to actually converge and

183
00:06:21,379 --> 00:06:23,600
correct things like this piece of information

184
00:06:23,858 --> 00:06:25,858
so that you can actually leverage that information

185
00:06:25,858 --> 00:06:27,778
later when you're trying to use it

186
00:06:28,220 --> 00:06:30,298
within a fact or rather

187
00:06:30,298 --> 00:06:31,500
document review process.

188
00:06:33,480 --> 00:06:34,858
This is a more

189
00:06:35,639 --> 00:06:37,178
drawn out example of

190
00:06:37,480 --> 00:06:39,608
something that a large language model

191
00:06:39,608 --> 00:06:41,338
would do incredibly poorly

192
00:06:41,959 --> 00:06:44,059
in comparison to, to a system that is

193
00:06:44,519 --> 00:06:46,619
designed and built to support

194
00:06:46,619 --> 00:06:48,670
litigation workflows and the

195
00:06:48,670 --> 00:06:50,678
document review that's as low

196
00:06:50,678 --> 00:06:52,220
fault tolerance as law.

197
00:06:52,678 --> 00:06:54,259
So imagine I've written a letter,

198
00:06:55,000 --> 00:06:57,079
um, within it, I don't

199
00:06:57,079 --> 00:06:59,119
write my name, and I don't say who

200
00:06:59,119 --> 00:07:00,269
I'm writing it to.

201
00:07:00,548 --> 00:07:02,108
And I detail out

202
00:07:02,588 --> 00:07:04,709
a crime I've committed, uh, but

203
00:07:04,709 --> 00:07:06,829
I don't necessarily say it in the simple

204
00:07:06,829 --> 00:07:08,910
fact that, say, you know, I didn't, I

205
00:07:08,910 --> 00:07:10,910
didn't, don't put that I stole that car, I say it

206
00:07:10,910 --> 00:07:12,428
in some colloquial way,

207
00:07:12,829 --> 00:07:14,910
um. The challenge for a large language

208
00:07:14,910 --> 00:07:17,259
model, if that document is placed in between

209
00:07:17,399 --> 00:07:19,139
4000 other documents,

210
00:07:19,470 --> 00:07:20,959
if you were to ask a large language model,

211
00:07:21,238 --> 00:07:23,459
did Daniel steal a car,

212
00:07:23,720 --> 00:07:25,790
well, it wouldn't ever be able to say yes,

213
00:07:26,119 --> 00:07:28,278
because Daniel's not mentioned, and I didn't

214
00:07:28,278 --> 00:07:30,278
say that I stole a car, and

215
00:07:30,278 --> 00:07:32,028
I also don't say who I've written it to.

216
00:07:32,439 --> 00:07:34,139
What Mary, or rather what

217
00:07:34,639 --> 00:07:37,059
any tool that's going to do this type of work.

218
00:07:37,600 --> 00:07:40,009
In a document review process in law

219
00:07:40,009 --> 00:07:42,170
needs to be able to do is

220
00:07:42,170 --> 00:07:44,350
do things like look at the handwriting of that letter.

221
00:07:45,319 --> 00:07:47,449
Is that handwriting present in any of the other

222
00:07:47,449 --> 00:07:49,488
documents? Can we understand who actually

223
00:07:49,488 --> 00:07:50,040
wrote that?

224
00:07:50,488 --> 00:07:52,649
Also, maybe I wrote on it a date

225
00:07:52,649 --> 00:07:53,869
when I went to the park.

226
00:07:54,129 --> 00:07:56,129
We need to be able to understand that in this other document over

227
00:07:56,129 --> 00:07:58,250
here, Daniel said that he went to

228
00:07:58,250 --> 00:08:00,250
the park on that date and then try and

229
00:08:00,250 --> 00:08:02,769
understand that, hey, actually, maybe we can draw a conclusion

230
00:08:02,769 --> 00:08:04,889
here and say, brilliant,

231
00:08:05,290 --> 00:08:07,309
maybe you should review whether or not

232
00:08:07,449 --> 00:08:09,670
this is Daniel, because we've got some supporting evidence.

233
00:08:10,488 --> 00:08:13,199
So that's an example of where large language models

234
00:08:13,199 --> 00:08:14,428
just fall short

235
00:08:15,189 --> 00:08:16,088
in this type of work.

236
00:08:17,920 --> 00:08:19,079
And the last problem

237
00:08:19,399 --> 00:08:21,639
is that even if I did all of that fact

238
00:08:21,639 --> 00:08:23,199
extraction perfectly.

239
00:08:24,189 --> 00:08:26,389
That's not really what lawyers and legal

240
00:08:26,389 --> 00:08:28,428
teams need when undertaking

241
00:08:28,428 --> 00:08:29,449
an investigation.

242
00:08:29,790 --> 00:08:32,469
They actually need to feel really confident uh

243
00:08:32,700 --> 00:08:34,788
about those facts and the narrative that

244
00:08:34,788 --> 00:08:35,729
they're going to present

245
00:08:36,469 --> 00:08:37,668
on their client's behalf.

246
00:08:38,690 --> 00:08:39,668
Or for their company.

247
00:08:40,158 --> 00:08:41,460
So here's an example.

248
00:08:41,840 --> 00:08:43,590
Is anybody a lawyer?

249
00:08:45,308 --> 00:08:45,840
OK,

250
00:08:46,200 --> 00:08:48,658
well, We've got one, brilliant.

251
00:08:49,019 --> 00:08:51,139
So this is just a, a, an example,

252
00:08:51,219 --> 00:08:53,460
hopefully that gets you thinking as to why this is so

253
00:08:53,460 --> 00:08:55,619
important, but that it's uh an

254
00:08:55,619 --> 00:08:57,418
exercise, the perfect letter of demand.

255
00:08:58,139 --> 00:09:00,379
So imagine a large language model spits

256
00:09:00,379 --> 00:09:02,798
out to you and says, here's a perfect

257
00:09:03,139 --> 00:09:03,950
legal document,

258
00:09:04,379 --> 00:09:06,489
whatever it is, and I've done the work for you,

259
00:09:06,639 --> 00:09:08,739
I've gone through this entirely massive corpus

260
00:09:08,739 --> 00:09:10,820
of documents. I've extracted all

261
00:09:10,820 --> 00:09:12,859
of the facts, I've reviewed what's

262
00:09:12,859 --> 00:09:15,139
relevant in the context of the case, and

263
00:09:15,139 --> 00:09:17,139
I'm now going to give you the perfect document, in

264
00:09:17,139 --> 00:09:17,678
this case,

265
00:09:18,178 --> 00:09:19,058
a letter of demand.

266
00:09:19,609 --> 00:09:21,279
I can assure you it's the ideal

267
00:09:21,658 --> 00:09:23,979
uh letter to file, it's supported with the perfect

268
00:09:23,979 --> 00:09:25,259
evidence, it's in your

269
00:09:25,570 --> 00:09:27,710
template that you normally use, all of that good

270
00:09:27,710 --> 00:09:29,779
stuff, please now go and file it with the other

271
00:09:29,779 --> 00:09:30,908
side or with the court.

272
00:09:31,739 --> 00:09:33,460
Would you, would you go and file that?

273
00:09:34,428 --> 00:09:36,009
That's the correct answer, good.

274
00:09:36,450 --> 00:09:38,538
Uh, you can't because you need to ultimately

275
00:09:38,538 --> 00:09:40,590
you have an obligation to whoever it is that

276
00:09:40,590 --> 00:09:43,168
you're representing, but more importantly, you, you

277
00:09:43,168 --> 00:09:45,349
have a responsibility to make sure that you're confident

278
00:09:45,349 --> 00:09:46,029
about doing that,

279
00:09:46,538 --> 00:09:47,788
uh, with the action that you're taking.

280
00:09:48,580 --> 00:09:50,739
And so, unlike a large language

281
00:09:50,739 --> 00:09:53,058
model that is perfectly built

282
00:09:53,259 --> 00:09:55,580
to receive a question

283
00:09:55,940 --> 00:09:58,389
and then deliver a correct answer,

284
00:09:58,779 --> 00:10:00,279
what's required in

285
00:10:00,538 --> 00:10:01,479
this type of work,

286
00:10:01,739 --> 00:10:02,399
in this

287
00:10:02,779 --> 00:10:04,940
document review and litigation

288
00:10:04,940 --> 00:10:07,019
workflow, is something that, that doesn't

289
00:10:07,019 --> 00:10:08,639
know what the question's going to be,

290
00:10:09,178 --> 00:10:11,259
yet can understand all of the facts and

291
00:10:11,259 --> 00:10:13,379
give you all of the potential narratives

292
00:10:13,379 --> 00:10:15,500
for you yourself to review and

293
00:10:15,500 --> 00:10:17,340
verify and become confident in.

294
00:10:18,700 --> 00:10:20,859
So how do you fix all of these

295
00:10:20,859 --> 00:10:21,558
problems?

296
00:10:22,469 --> 00:10:24,509
Well, in a way that large language

297
00:10:24,509 --> 00:10:26,019
models simply don't like,

298
00:10:26,389 --> 00:10:28,019
because it's incredibly uh

299
00:10:28,428 --> 00:10:30,548
process heavy and it's not a

300
00:10:30,548 --> 00:10:32,548
generalized task, it's very specific. And

301
00:10:32,548 --> 00:10:34,710
the first thing you've got to do is treat facts

302
00:10:34,710 --> 00:10:36,109
as first-class citizens.

303
00:10:36,389 --> 00:10:38,690
So in the same way that a large language model says,

304
00:10:38,788 --> 00:10:40,820
the most important thing to us is

305
00:10:40,820 --> 00:10:42,609
having an incredibly efficient

306
00:10:42,989 --> 00:10:44,129
embeddings model.

307
00:10:45,469 --> 00:10:47,820
A fact review platform needs to have

308
00:10:48,038 --> 00:10:50,038
the best fact model and say,

309
00:10:50,119 --> 00:10:52,200
right, great, we're gonna take those facts and we're gonna process

310
00:10:52,200 --> 00:10:52,960
them and make them,

311
00:10:54,070 --> 00:10:56,119
uh put them through this manufacturing pipeline that's

312
00:10:56,119 --> 00:10:58,479
incredibly heavy and deliver to you something

313
00:10:58,639 --> 00:11:01,019
that you can rely on, and then ultimately,

314
00:11:01,479 --> 00:11:04,038
verify, which is why you need a world-class

315
00:11:04,038 --> 00:11:05,899
review and verification experience.

316
00:11:06,928 --> 00:11:09,489
This is where the lawyer or the,

317
00:11:09,629 --> 00:11:12,009
the team representing or trying to undertake this

318
00:11:12,009 --> 00:11:14,048
investigation, this is where they go to review the

319
00:11:14,048 --> 00:11:16,269
facts that have come out, build their narratives,

320
00:11:16,330 --> 00:11:16,989
and more.

321
00:11:17,450 --> 00:11:19,450
And finally, and this is maybe

322
00:11:19,450 --> 00:11:21,210
the one piece that I think is

323
00:11:21,529 --> 00:11:22,658
missing uh

324
00:11:22,928 --> 00:11:25,408
from what I've spoken about before, is

325
00:11:25,590 --> 00:11:27,609
you need to then take this layer

326
00:11:27,609 --> 00:11:28,389
of facts.

327
00:11:28,788 --> 00:11:31,119
That you can feel confident about and

328
00:11:31,119 --> 00:11:33,200
pipe it through to these downstream

329
00:11:33,200 --> 00:11:34,428
AI applications,

330
00:11:34,719 --> 00:11:37,178
so things like OpenAI or

331
00:11:37,320 --> 00:11:39,428
any other unified interface,

332
00:11:39,678 --> 00:11:41,678
you can just pipe them in there and and have them

333
00:11:41,678 --> 00:11:43,719
working. OK, so I've

334
00:11:43,719 --> 00:11:45,719
got a short video to show you how we've solved

335
00:11:45,719 --> 00:11:46,820
some of these problems.

336
00:11:47,200 --> 00:11:49,259
As a lawyer, when you receive a case.

337
00:11:50,590 --> 00:11:52,428
Your first goal is to get the facts straight.

338
00:11:53,428 --> 00:11:54,969
But this is never straightforward.

339
00:11:58,379 --> 00:12:00,619
It means digging through endless emails,

340
00:12:00,779 --> 00:12:02,779
PDFs and records, splitting

341
00:12:02,779 --> 00:12:04,840
documents, cross-checking dates,

342
00:12:05,058 --> 00:12:07,019
piecing together a clear timeline.

343
00:12:07,418 --> 00:12:09,460
It's slow, it's manual, and

344
00:12:09,460 --> 00:12:11,519
it can take anywhere from hours to days

345
00:12:11,739 --> 00:12:13,750
before you've even started the legal work.

346
00:12:14,139 --> 00:12:16,000
We call this fact chaos.

347
00:12:17,729 --> 00:12:19,158
But what if

348
00:12:19,519 --> 00:12:21,340
the moment a case landed in your inbox,

349
00:12:22,158 --> 00:12:23,200
everything was set in motion?

350
00:12:24,750 --> 00:12:27,129
We could take the attached documents in the email

351
00:12:27,269 --> 00:12:29,349
or find uploaded documents in the tools you

352
00:12:29,349 --> 00:12:30,090
already use,

353
00:12:30,349 --> 00:12:32,190
then scan and process them.

354
00:12:32,558 --> 00:12:34,820
The messy bundled files could be split

355
00:12:34,820 --> 00:12:35,489
into clear,

356
00:12:35,830 --> 00:12:37,109
structured documents.

357
00:12:37,469 --> 00:12:39,509
They could be categorized, renamed,

358
00:12:39,710 --> 00:12:42,529
and seamlessly organized back into your workflow,

359
00:12:42,989 --> 00:12:44,070
exactly where you need them.

360
00:12:44,899 --> 00:12:47,288
But what if organizing documents was just the start?

361
00:12:47,538 --> 00:12:49,349
What if we could unblock you completely,

362
00:12:50,019 --> 00:12:52,009
so you can get started on the real legal work?

363
00:12:54,619 --> 00:12:56,899
We can pull key entities from every document,

364
00:12:57,178 --> 00:12:59,178
names, businesses, and their role in the

365
00:12:59,178 --> 00:12:59,759
case,

366
00:13:00,139 --> 00:13:02,298
giving you instant insight into exactly

367
00:13:02,298 --> 00:13:03,080
who matters.

368
00:13:04,029 --> 00:13:06,029
Find and capture significant dates

369
00:13:06,029 --> 00:13:07,029
when events occurred.

370
00:13:07,308 --> 00:13:09,469
Get a concise case summary, distilling

371
00:13:09,469 --> 00:13:12,139
the entire matter into a few clear paragraphs.

372
00:13:12,369 --> 00:13:14,908
Identify gaps that need assessing, detect

373
00:13:14,908 --> 00:13:17,029
possible data leaks, build a timeline

374
00:13:17,029 --> 00:13:19,058
of events, and extract any other key

375
00:13:19,058 --> 00:13:20,928
details relevant to your case.

376
00:13:21,269 --> 00:13:23,509
Then bring all these insights together

377
00:13:23,509 --> 00:13:25,629
in a single dashboard, so anyone

378
00:13:25,629 --> 00:13:27,908
can get a firm grip on a case in minutes,

379
00:13:28,090 --> 00:13:29,788
even if they've never seen it before.

380
00:13:31,229 --> 00:13:33,469
Delve deeper with generated chronologies,

381
00:13:33,629 --> 00:13:35,668
surfacing only what's most relevant to

382
00:13:35,668 --> 00:13:37,830
your case. Invite experts to work

383
00:13:37,830 --> 00:13:40,168
alongside you and your colleagues in real time

384
00:13:40,229 --> 00:13:42,308
and draft directly into the tools you

385
00:13:42,308 --> 00:13:43,038
already use.

386
00:13:43,548 --> 00:13:45,700
Because MRI connects with your existing systems,

387
00:13:45,869 --> 00:13:47,428
it adapts as new evidence,

388
00:13:47,750 --> 00:13:50,070
events, and documents emerge, keeping

389
00:13:50,070 --> 00:13:52,070
your case aligned every step of the way.

390
00:13:54,178 --> 00:13:55,399
When the facts are clear,

391
00:13:55,899 --> 00:13:57,158
decisions are faster.

392
00:13:57,619 --> 00:13:58,580
Back to chaos.

393
00:13:59,359 --> 00:14:00,070
Solved

394
00:14:05,989 --> 00:14:06,529
Um,

395
00:14:06,908 --> 00:14:09,469
OK, so just to, just to conclude

396
00:14:09,469 --> 00:14:11,509
what I'm trying to get at there and hopefully

397
00:14:11,509 --> 00:14:12,950
that you could see in the video,

398
00:14:13,349 --> 00:14:14,928
it requires a novel approach.

399
00:14:15,320 --> 00:14:15,879
And

400
00:14:16,379 --> 00:14:18,808
interestingly, we couldn't use what most

401
00:14:19,070 --> 00:14:19,609
people

402
00:14:20,070 --> 00:14:22,700
can, which is retrieval, augmented

403
00:14:22,700 --> 00:14:24,788
generation, or agentic workflows to

404
00:14:24,788 --> 00:14:26,788
just go into the documents and extract the

405
00:14:26,788 --> 00:14:28,830
facts that are meaningful and present them

406
00:14:28,830 --> 00:14:29,928
to a user.

407
00:14:30,469 --> 00:14:32,788
So that's what I'm sort of

408
00:14:32,788 --> 00:14:34,830
saying up here, we can't just use good enough, it

409
00:14:34,830 --> 00:14:35,408
has to be.

410
00:14:36,349 --> 00:14:36,989
Brilliant.

411
00:14:37,269 --> 00:14:39,658
And so we built a fact manufacturing,

412
00:14:39,668 --> 00:14:40,830
processing pipeline,

413
00:14:41,340 --> 00:14:43,668
where, where we extract every event, entity,

414
00:14:43,750 --> 00:14:44,269
actor,

415
00:14:44,788 --> 00:14:46,908
issue, loads of other stuff. Ultimately imagine a

416
00:14:46,908 --> 00:14:48,369
fact as like an object,

417
00:14:48,668 --> 00:14:50,830
where it has lots of metadata underneath it that

418
00:14:50,830 --> 00:14:52,869
allows you to build relationships and

419
00:14:52,869 --> 00:14:54,908
construct a case, almost as a

420
00:14:54,908 --> 00:14:55,849
digital

421
00:14:56,668 --> 00:14:58,229
case as a an object.

422
00:14:59,500 --> 00:15:01,440
So it will then do things like

423
00:15:01,779 --> 00:15:03,798
tell you whether or not a fact contradicts with another.

424
00:15:04,500 --> 00:15:06,739
And then the important part here is that

425
00:15:06,739 --> 00:15:07,279
every

426
00:15:07,619 --> 00:15:09,899
piece of that metadata underneath that object

427
00:15:10,019 --> 00:15:11,239
has to be explainable.

428
00:15:11,700 --> 00:15:13,779
So we'll surface and expose any

429
00:15:13,779 --> 00:15:14,639
rationale

430
00:15:15,139 --> 00:15:17,250
if we make a single decision. If we make a decision, we

431
00:15:17,250 --> 00:15:19,418
tell you a date, we're going to tell you how we got to that date.

432
00:15:19,570 --> 00:15:21,678
If we're going to tell you something that's relevant, we're going to tell you how

433
00:15:21,678 --> 00:15:22,418
it's relevant.

434
00:15:23,450 --> 00:15:25,489
Only after producing that high quality fat

435
00:15:25,489 --> 00:15:27,729
layer do we then use these

436
00:15:27,729 --> 00:15:29,830
more traditional or or not traditional,

437
00:15:30,408 --> 00:15:32,529
very new technologies, but the more

438
00:15:32,529 --> 00:15:34,700
standard technologies such as RAG and ergentic

439
00:15:34,700 --> 00:15:35,519
frameworks,

440
00:15:35,808 --> 00:15:38,058
and the result is a persistent

441
00:15:38,250 --> 00:15:40,250
auditable fat layer that you can rely

442
00:15:40,250 --> 00:15:42,548
on both in the platform itself when you're

443
00:15:42,729 --> 00:15:44,019
doing that investigation

444
00:15:44,369 --> 00:15:46,729
or downstream when you want to pipe that

445
00:15:46,729 --> 00:15:48,899
information down and use it when you're drafting

446
00:15:48,899 --> 00:15:50,769
or other associated legal tasks.

447
00:15:52,048 --> 00:15:54,408
So I'm just gonna show you just very briefly what the platform

448
00:15:54,408 --> 00:15:56,558
looks like for a single fact, just to

449
00:15:56,558 --> 00:15:58,609
highlight that challenge before when I spoke

450
00:15:58,609 --> 00:15:59,149
to you about

451
00:15:59,570 --> 00:16:00,190
patient.

452
00:16:00,769 --> 00:16:02,798
So you can see here, there's a fact

453
00:16:02,798 --> 00:16:03,548
at the top.

454
00:16:03,969 --> 00:16:06,048
So you can see that there's a date with a time, and

455
00:16:06,048 --> 00:16:08,139
it's talking about a chap called Rowan McNamee

456
00:16:08,450 --> 00:16:10,599
is reassessed, swelling to right bicep

457
00:16:10,599 --> 00:16:13,168
remains. You'll notice that that's an incredibly summarized

458
00:16:13,168 --> 00:16:14,330
and concise fact.

459
00:16:14,649 --> 00:16:16,690
That's because that's what lawyers need, they need to be able to have a

460
00:16:16,690 --> 00:16:19,090
look at all of these facts because the majority

461
00:16:19,090 --> 00:16:20,330
of them won't be relevant.

462
00:16:21,149 --> 00:16:22,090
So if we just

463
00:16:22,548 --> 00:16:24,788
zoom in on, I've, imagine I've pushed my mouse

464
00:16:24,788 --> 00:16:26,969
over to the right-hand side and I've hovered over

465
00:16:26,969 --> 00:16:29,070
that relevance, and it's gonna tell me, the

466
00:16:29,070 --> 00:16:31,070
entry focuses on a separate medical

467
00:16:31,070 --> 00:16:33,259
issue. Now bear in mind, I know a lot of my examples

468
00:16:33,259 --> 00:16:35,308
have been in personal injury, but this is

469
00:16:35,308 --> 00:16:37,369
for employment, or any type of

470
00:16:37,629 --> 00:16:38,979
law you can do this with.

471
00:16:39,308 --> 00:16:41,469
But in this particular case, personal injury. So it's gonna

472
00:16:41,469 --> 00:16:42,928
tell me why this isn't relevant.

473
00:16:43,369 --> 00:16:45,538
But then I'm able to dive deeper

474
00:16:45,538 --> 00:16:47,250
if I think it might have some relevance.

475
00:16:47,538 --> 00:16:49,538
You can see I can pull up the actual

476
00:16:49,538 --> 00:16:50,879
document on the exact page

477
00:16:51,219 --> 00:16:53,500
and space where that fact has come from, and

478
00:16:53,500 --> 00:16:55,580
I can also rely on Mary to give

479
00:16:55,580 --> 00:16:57,619
me more rationale as to how it came up with this

480
00:16:57,619 --> 00:16:59,779
fact and where there's more uh details

481
00:16:59,779 --> 00:17:00,759
that I can replace

482
00:17:01,058 --> 00:17:03,178
the fact with if I want more information. But you'll

483
00:17:03,178 --> 00:17:05,219
notice that this handwriting's terrible. I mean, well, it's

484
00:17:05,219 --> 00:17:07,189
pretty good handwriting, um, but

485
00:17:07,539 --> 00:17:10,160
yeah. It works on unstructured

486
00:17:10,160 --> 00:17:12,380
data primarily rather than things like

487
00:17:12,380 --> 00:17:13,880
contracts, where all of the

488
00:17:14,469 --> 00:17:16,640
information is very easy to get out, we have to focus on the documents

489
00:17:16,640 --> 00:17:17,439
that are really difficult.

490
00:17:17,759 --> 00:17:19,910
But the reason I bring this up is because if we have a look in that

491
00:17:19,910 --> 00:17:22,118
document, that's where it's from, PT

492
00:17:22,118 --> 00:17:22,828
or patient.

493
00:17:23,279 --> 00:17:25,479
Well, we don't just rely on that, and this is just one of those

494
00:17:25,479 --> 00:17:27,519
elements where we correct the fact as we

495
00:17:27,519 --> 00:17:28,588
go through that pipeline.

496
00:17:28,920 --> 00:17:30,920
We say, Rowan McNamee, so that

497
00:17:31,068 --> 00:17:33,500
ultimately when we pipe this fact down into another

498
00:17:33,759 --> 00:17:35,880
downstream AI capability, it

499
00:17:35,880 --> 00:17:37,900
knows it's looking for Rowan McNamee, so when you say,

500
00:17:38,118 --> 00:17:40,118
hey, did Rowan ever go into a hospital

501
00:17:40,118 --> 00:17:42,160
with this, it can say yes and be

502
00:17:42,160 --> 00:17:44,160
confident, and you can go directly back to where

503
00:17:44,160 --> 00:17:44,799
that was found.

504
00:17:45,588 --> 00:17:47,750
So, just, just quickly on

505
00:17:47,900 --> 00:17:50,250
on where we, where we're at in our journey, um,

506
00:17:50,588 --> 00:17:52,709
we work with many of the largest firms now in

507
00:17:52,709 --> 00:17:54,949
Australia, and including ANO

508
00:17:54,949 --> 00:17:57,150
Sherman, who's one of the largest law firms in the world,

509
00:17:57,229 --> 00:17:59,229
both here and over in the UK and everywhere

510
00:17:59,229 --> 00:18:01,390
else. But we're, we're bringing on more firms

511
00:18:01,390 --> 00:18:02,189
every single week.

512
00:18:03,088 --> 00:18:05,088
Across all of our customers, we

513
00:18:05,088 --> 00:18:07,239
have achieved a 75 to 85%

514
00:18:07,239 --> 00:18:09,568
reduction in time spent on this, probably

515
00:18:09,568 --> 00:18:11,769
the biggest bottleneck in litigation, which

516
00:18:11,769 --> 00:18:13,779
is document review. It's where so much of the

517
00:18:13,779 --> 00:18:16,118
time is spent, it's where so much of the cost is accrued,

518
00:18:16,250 --> 00:18:17,949
and we're reducing it significantly.

519
00:18:18,328 --> 00:18:20,880
And overall, we've achieved a 96 out of 100

520
00:18:20,880 --> 00:18:21,858
MPS score.

521
00:18:22,160 --> 00:18:24,209
People really love using Mary because

522
00:18:24,209 --> 00:18:26,559
this is one of the most difficult, annoying, frustrating

523
00:18:26,559 --> 00:18:28,930
jobs that you can do as part of this

524
00:18:28,930 --> 00:18:30,289
process, and so people love it.

525
00:18:31,118 --> 00:18:33,118
Um, here's just, I'm just gonna leave this up on

526
00:18:33,118 --> 00:18:34,078
the screen briefly.

527
00:18:34,400 --> 00:18:36,469
Uh, it is a little bit Aussie, um,

528
00:18:36,640 --> 00:18:38,680
but this is, and I, I've had to redact the name, which

529
00:18:38,680 --> 00:18:39,920
is why there's a little dot here,

530
00:18:40,199 --> 00:18:42,318
um, but that's what one of our customers has

531
00:18:42,318 --> 00:18:44,500
said, uh, about how they use Mary.

532
00:18:45,118 --> 00:18:47,160
So, I'm, I'm, I, I'm open it up to questions

533
00:18:47,160 --> 00:18:49,318
if anybody's got any, but, um, that's

534
00:18:49,318 --> 00:18:51,559
Mary technology and, and how we're building this

535
00:18:51,559 --> 00:18:52,098
fact layer.

536
00:18:54,880 --> 00:18:55,828
Any questions?

537
00:18:56,568 --> 00:18:57,078
No?

538
00:18:57,489 --> 00:18:59,328
Cool. Thank you

