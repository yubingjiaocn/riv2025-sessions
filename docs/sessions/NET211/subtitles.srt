1
00:00:00,480 --> 00:00:04,140
- Hello everyone. My name's Etienne.

2
00:00:04,140 --> 00:00:08,370
I'm an Edge specialist essay
based from Sydney, Australia.

3
00:00:08,370 --> 00:00:10,230
It's good to be with you here today.

4
00:00:10,230 --> 00:00:11,700
We've traveled a long way to be here.

5
00:00:11,700 --> 00:00:16,146
I'm here with my colleague Nishit

6
00:00:16,146 --> 00:00:19,170
and with my customer Ambrose.

7
00:00:19,170 --> 00:00:21,210
- Thank you. Good morning everyone.

8
00:00:21,210 --> 00:00:24,120
My name's Ambrose Phey and
I'm a cloud network engineer

9
00:00:24,120 --> 00:00:26,820
at Atlassian in our Edge services team.

10
00:00:26,820 --> 00:00:28,140
Today I've flown in from Australia

11
00:00:28,140 --> 00:00:30,510
and I'm excited to share
in our story, use case

12
00:00:30,510 --> 00:00:32,400
and outcomes of the work we've been doing

13
00:00:32,400 --> 00:00:35,610
over the past year with
Amazon's Edge products.

14
00:00:35,610 --> 00:00:37,890
But for now, I'll pass it over to Nishit.

15
00:00:37,890 --> 00:00:40,410
- Hello everyone. I'm Nishit Sawhney.

16
00:00:40,410 --> 00:00:42,210
I'm the director and general manager

17
00:00:42,210 --> 00:00:45,480
for network services at Amazon.

18
00:00:45,480 --> 00:00:47,760
These include Amazon CloudFront,

19
00:00:47,760 --> 00:00:49,890
our Perimeter Protection Services

20
00:00:49,890 --> 00:00:52,533
and Application Load Balancing, ALBs.

21
00:00:53,561 --> 00:00:55,170
- Thank you Nishit.

22
00:00:55,170 --> 00:00:58,983
So you're in session net
211, the state of Edge.

23
00:01:00,027 --> 00:01:02,548
We are excited to share
some insights today

24
00:01:02,548 --> 00:01:05,700
and we glad to bring you along with some

25
00:01:05,700 --> 00:01:07,950
of the journey that
we've been involved with.

26
00:01:09,900 --> 00:01:13,380
We are excited to make sure
that you take away some

27
00:01:13,380 --> 00:01:17,010
of the learnings that Ambrose
and his team have worked

28
00:01:17,010 --> 00:01:19,863
through and we hope you enjoy it today.

29
00:01:20,820 --> 00:01:23,595
This is a 200 level talk.

30
00:01:23,595 --> 00:01:25,230
We expect you to notice something

31
00:01:25,230 --> 00:01:27,660
about CloudFront, WAF and Shield.

32
00:01:27,660 --> 00:01:29,790
However, if you don't
stress, we'll take you along

33
00:01:29,790 --> 00:01:31,020
for the ride.

34
00:01:31,020 --> 00:01:33,030
I'm gonna hand it to Nishit.

35
00:01:33,030 --> 00:01:37,020
- Thank you. All right.

36
00:01:37,020 --> 00:01:41,610
So let's start by defining
what an Edge service is

37
00:01:41,610 --> 00:01:43,953
and what is at the AWS Edge?

38
00:01:44,790 --> 00:01:48,990
Well, an Edge service is a
distributed computing service

39
00:01:48,990 --> 00:01:51,330
that brings network, storage,

40
00:01:51,330 --> 00:01:54,720
compute, capabilities physically closer

41
00:01:54,720 --> 00:01:59,720
to your users, thereby reducing
latency for your users.

42
00:01:59,730 --> 00:02:03,990
Now at AWS, there are
several Edge services

43
00:02:03,990 --> 00:02:08,070
that run either partially
or fully at the Edge.

44
00:02:08,070 --> 00:02:10,320
For the purposes of this
session, we are going

45
00:02:10,320 --> 00:02:14,047
to focus on Amazon
CloudFront, Shield and WAF.

46
00:02:15,510 --> 00:02:17,550
Just as a refresher, CloudFront

47
00:02:17,550 --> 00:02:20,520
is a global content delivery network.

48
00:02:20,520 --> 00:02:23,580
Shield and WAF are security services

49
00:02:23,580 --> 00:02:26,790
that protect your
applications against Layer 3/4

50
00:02:26,790 --> 00:02:28,683
and Layer 7 attacks.

51
00:02:31,410 --> 00:02:34,620
Our mission really is to
protect your applications,

52
00:02:34,620 --> 00:02:37,653
make them fast, secure, and resilient.

53
00:02:38,670 --> 00:02:42,060
If you think about it,
our mission really is

54
00:02:42,060 --> 00:02:44,910
to make the internet fun and engaging

55
00:02:44,910 --> 00:02:47,730
for billions of users across the world.

56
00:02:47,730 --> 00:02:50,583
This is what drives me and my team at AWS.

57
00:02:54,240 --> 00:02:59,240
Now, we've evolved our services
over the last 17 years.

58
00:02:59,580 --> 00:03:02,073
As per the evolution of the internet.

59
00:03:03,090 --> 00:03:04,320
The internet has gone

60
00:03:04,320 --> 00:03:07,484
through massive shifts,
each one redefining

61
00:03:07,484 --> 00:03:11,670
how users interact, what
applications you build,

62
00:03:11,670 --> 00:03:15,603
and what infrastructure services
like ours need to deliver.

63
00:03:16,560 --> 00:03:19,110
Let's start with how it all began.

64
00:03:19,110 --> 00:03:22,080
The web was simple static web,

65
00:03:22,080 --> 00:03:24,810
a browser made a request for a file.

66
00:03:24,810 --> 00:03:28,050
The server responded simple, get requests.

67
00:03:28,050 --> 00:03:31,833
Security was simple, merely IP blocks.

68
00:03:33,060 --> 00:03:35,820
Caching rules were pretty simple.

69
00:03:35,820 --> 00:03:39,510
Along came the transactional
and the e-commerce web.

70
00:03:39,510 --> 00:03:44,510
That's where APIs became
prevalent. Put post requests.

71
00:03:44,940 --> 00:03:48,750
We in CloudFront, launched
dynamic content acceleration

72
00:03:48,750 --> 00:03:51,690
for handing these kind of requests.

73
00:03:51,690 --> 00:03:54,360
Security became more complicated.

74
00:03:54,360 --> 00:03:56,460
DDoS attacks at Layer 3/4

75
00:03:56,460 --> 00:03:58,533
and Layer 7 became prevalent.

76
00:04:00,270 --> 00:04:04,290
Then came the next big shift,
which was social and mobile.

77
00:04:04,290 --> 00:04:05,123
If you think about it,

78
00:04:05,123 --> 00:04:08,820
that really democratized the
internet bringing millions

79
00:04:08,820 --> 00:04:13,323
and millions of users
and scale on the network.

80
00:04:14,340 --> 00:04:17,820
Security then became even more complicated

81
00:04:17,820 --> 00:04:19,950
with bot activity.

82
00:04:19,950 --> 00:04:24,480
These bots acted as humans
and tried to conduct

83
00:04:24,480 --> 00:04:27,183
or steal information from your websites.

84
00:04:28,380 --> 00:04:32,853
Latency also became even more complicated.

85
00:04:34,080 --> 00:04:38,580
Then the next step was really social media

86
00:04:38,580 --> 00:04:42,480
and short form video live streams.

87
00:04:42,480 --> 00:04:46,590
Here, latency attachments
became emotional.

88
00:04:46,590 --> 00:04:50,310
It wasn't just a number it
hundred millisecond latency

89
00:04:50,310 --> 00:04:53,490
difference could be
really the differentiator

90
00:04:53,490 --> 00:04:57,452
between user engagement and
abandonment on a platform

91
00:04:57,452 --> 00:05:00,063
like TikTok or Reels.

92
00:05:01,410 --> 00:05:05,867
Along the right came Internet
of Things here we saw

93
00:05:05,867 --> 00:05:08,400
a lot more devices and a lot more requests

94
00:05:08,400 --> 00:05:11,820
with different traffic
profiles on the internet.

95
00:05:11,820 --> 00:05:15,570
But what came along with
that was opportunities

96
00:05:15,570 --> 00:05:19,500
for those devices to be
compromised by malicious actors

97
00:05:19,500 --> 00:05:24,270
and that created these
massive pool of devices

98
00:05:24,270 --> 00:05:27,390
on endpoints on the
internet that would launch

99
00:05:27,390 --> 00:05:30,843
DDoS attacks and other web
attacks against the applications.

100
00:05:31,890 --> 00:05:35,550
We've evolved our services
along these evolutions

101
00:05:35,550 --> 00:05:37,260
and one such thing

102
00:05:37,260 --> 00:05:41,640
that we did was security
was no longer reactive.

103
00:05:41,640 --> 00:05:43,470
It had to become proactive.

104
00:05:43,470 --> 00:05:47,160
So we launched threat
intelligence built based

105
00:05:47,160 --> 00:05:52,160
on a global set of sensors,
which we call honeypot network.

106
00:05:53,160 --> 00:05:56,670
That Honey Pot Network allows
us to collect intelligence

107
00:05:56,670 --> 00:06:00,330
from the entire web and
feed that intelligence

108
00:06:00,330 --> 00:06:04,980
into our services at AWS and
protect your applications.

109
00:06:04,980 --> 00:06:07,380
So what really happened here was

110
00:06:07,380 --> 00:06:11,730
the perceived latency tolerance
for our users went down.

111
00:06:11,730 --> 00:06:15,720
The security and resiliency
expectations has increased

112
00:06:15,720 --> 00:06:20,720
exponentially, but we are
now entering the next era,

113
00:06:21,990 --> 00:06:25,350
which is the Agentic Web or the AI web.

114
00:06:25,350 --> 00:06:27,480
I'm gonna ask a question, how many

115
00:06:27,480 --> 00:06:31,200
of you have observed requests
on your web applications

116
00:06:31,200 --> 00:06:35,253
that are originating from
AI bots or chat bots?

117
00:06:36,420 --> 00:06:37,253
Quite a few.

118
00:06:40,680 --> 00:06:44,010
This is the data that we see
on websites that are hosted

119
00:06:44,010 --> 00:06:45,397
on CloudFront and AWS WAF.

120
00:06:48,270 --> 00:06:50,309
On a daily basis, billions

121
00:06:50,309 --> 00:06:53,820
of requests are originating from AI bots

122
00:06:53,820 --> 00:06:57,210
like Chatbot, GPT, Claude,

123
00:06:57,210 --> 00:07:00,630
Perplexity, Nova, Bedrock, et cetera.

124
00:07:00,630 --> 00:07:03,690
And this is not just
for certain industries

125
00:07:03,690 --> 00:07:05,640
like retail and e-commerce.

126
00:07:05,640 --> 00:07:08,790
Every possible industry
and customers to the

127
00:07:08,790 --> 00:07:11,463
in those industries are experiencing this.

128
00:07:12,660 --> 00:07:16,050
And you might be wondering,
well, don't we have a way

129
00:07:16,050 --> 00:07:20,220
to solve this with
something called robots.txt?

130
00:07:20,220 --> 00:07:22,590
Well, that really is the challenge.

131
00:07:22,590 --> 00:07:27,000
Robots.txt was built for
an entirely different era.

132
00:07:27,000 --> 00:07:30,993
It was when bots were
well-behaved and respecting,

133
00:07:32,160 --> 00:07:33,483
but the bots have evolved.

134
00:07:35,520 --> 00:07:37,980
The bots used to be traditional bots

135
00:07:37,980 --> 00:07:41,730
for crawl and refer search bots.

136
00:07:41,730 --> 00:07:45,570
They've now increasingly
become AI training bots used

137
00:07:45,570 --> 00:07:48,000
for training massive amounts of data

138
00:07:48,000 --> 00:07:50,763
and models they crawl and consume.

139
00:07:51,660 --> 00:07:55,170
And increasingly we are
seeing agentic AI bots

140
00:07:55,170 --> 00:07:57,390
that are conducting transactions

141
00:07:57,390 --> 00:07:59,643
and actions on behalf of the users.

142
00:08:00,780 --> 00:08:02,940
I hear from a lot of customers, especially

143
00:08:02,940 --> 00:08:05,760
in publishing space, where they're asking

144
00:08:05,760 --> 00:08:08,373
for help to deal with this bot activity.

145
00:08:09,330 --> 00:08:13,170
First of all to understand
what bot activity is

146
00:08:13,170 --> 00:08:17,558
on their websites, to
apply rules that apply

147
00:08:17,558 --> 00:08:19,290
with their business logic,

148
00:08:19,290 --> 00:08:22,230
like allowing those bots denying

149
00:08:22,230 --> 00:08:26,373
or even in some cases monetizing
in a sophisticated manner.

150
00:08:28,740 --> 00:08:31,560
So really the the Agentic
Web era is defined

151
00:08:31,560 --> 00:08:34,710
by three defining trends.

152
00:08:34,710 --> 00:08:39,030
The first one is the
traffic profile is changing.

153
00:08:39,030 --> 00:08:42,420
We see a lot of burst
traffic on our network.

154
00:08:42,420 --> 00:08:46,080
We see a whole bunch of duplex connections

155
00:08:46,080 --> 00:08:48,510
to chat applications.

156
00:08:48,510 --> 00:08:52,380
We see not just large
objects for live streams

157
00:08:52,380 --> 00:08:57,380
and video, but also
tokens that used for LLMs.

158
00:08:57,660 --> 00:08:59,913
Our network needs to evolve for that.

159
00:09:01,290 --> 00:09:03,813
The second big trend is security.

160
00:09:04,830 --> 00:09:07,320
Now customers are asking for security

161
00:09:07,320 --> 00:09:09,540
of their AI based applications,

162
00:09:09,540 --> 00:09:13,353
but also from AI powered attacks.

163
00:09:14,940 --> 00:09:19,800
And lastly, you all developers are going

164
00:09:19,800 --> 00:09:21,390
through an unprecedented era

165
00:09:21,390 --> 00:09:25,560
where the development cycles are so fast.

166
00:09:25,560 --> 00:09:29,250
You can now build applications
with AI coding assistance

167
00:09:29,250 --> 00:09:33,240
or agent systems like Bedrock AgentCore,

168
00:09:33,240 --> 00:09:34,940
or even why coding platforms

169
00:09:34,940 --> 00:09:37,833
like Lovable and Cursor and Kiro.

170
00:09:38,790 --> 00:09:42,270
And you all do not want to be hindered

171
00:09:42,270 --> 00:09:45,030
by infrastructure complexity.

172
00:09:45,030 --> 00:09:48,120
Our customers want the
infrastructure services

173
00:09:48,120 --> 00:09:52,920
to evolve with the pace of
these new development cycles.

174
00:09:52,920 --> 00:09:55,220
We don't want infrastructure
to be in the way.

175
00:09:56,910 --> 00:09:59,820
These three trends are what
are driving our investments

176
00:09:59,820 --> 00:10:02,163
and roadmap at head services.

177
00:10:03,480 --> 00:10:05,760
In the next part of the session, I'm going

178
00:10:05,760 --> 00:10:08,460
to talk about these three trends

179
00:10:08,460 --> 00:10:10,290
and some of the enhancements we've made

180
00:10:10,290 --> 00:10:11,640
and how we've helped customers

181
00:10:11,640 --> 00:10:13,233
as well as where we are going.

182
00:10:16,450 --> 00:10:19,863
Okay, so let's start with
performance and resiliency.

183
00:10:22,530 --> 00:10:26,490
The underpinnings of great
performance, resiliency

184
00:10:26,490 --> 00:10:30,453
and security is the massive AWS network.

185
00:10:31,590 --> 00:10:36,590
This comprises of AWS regions
as well as distributed PoPs

186
00:10:38,280 --> 00:10:40,830
that belong to Amazon CloudFront.

187
00:10:40,830 --> 00:10:45,333
This network has been growing
over 50% year over year.

188
00:10:46,260 --> 00:10:51,260
We've added 750 plus PoPs
and 1,140 embedded PoPs

189
00:10:52,530 --> 00:10:56,610
that are deployed deeply
inside ISP networks.

190
00:10:56,610 --> 00:10:59,340
We are now in 200 plus cities

191
00:10:59,340 --> 00:11:02,160
and 50 plus countries connecting

192
00:11:02,160 --> 00:11:04,383
to millions of users around the world.

193
00:11:06,030 --> 00:11:10,620
This network handles trillions
of requests on a given day

194
00:11:10,620 --> 00:11:13,443
and hundreds and hundreds of
terabytes per second peak.

195
00:11:14,640 --> 00:11:18,270
But that's not just all, even
from a security standpoint,

196
00:11:18,270 --> 00:11:22,081
this network allows us
tremendous amount of data

197
00:11:22,081 --> 00:11:25,050
for threat intelligence purposes.

198
00:11:25,050 --> 00:11:28,237
We analyze exabytes of
data every minute and just

199
00:11:28,237 --> 00:11:33,237
in the last year, we handled
6.2 million DDoS attacks,

200
00:11:34,170 --> 00:11:37,053
which was a growth of 150% year over year.

201
00:11:38,550 --> 00:11:41,313
The largest one being
25 terabytes per second.

202
00:11:44,880 --> 00:11:49,350
Okay, on this network,
we just recently launched

203
00:11:49,350 --> 00:11:52,203
a Global Anycast bring your own IP.

204
00:11:53,130 --> 00:11:56,610
Up until now, when you
put your application

205
00:11:56,610 --> 00:12:00,900
on CloudFront, you would
get dynamically assigned IPs

206
00:12:00,900 --> 00:12:02,760
to your applications.

207
00:12:02,760 --> 00:12:06,090
Last year, we launched
the Anycast capability

208
00:12:06,090 --> 00:12:09,540
with static IPs and
customers could use that

209
00:12:09,540 --> 00:12:12,013
to put their applications allow listed

210
00:12:12,013 --> 00:12:16,260
for enterprise firewalls or
even zero rating agreements

211
00:12:16,260 --> 00:12:18,213
with relation with ISPs.

212
00:12:20,520 --> 00:12:24,030
With the recent launch, you
can now bring your own IP

213
00:12:24,030 --> 00:12:26,430
and enhance that experience.

214
00:12:26,430 --> 00:12:31,230
This BYOIP capability comes
integrated with VPC IPAM

215
00:12:31,230 --> 00:12:34,443
as the unified way in
which you bring IPs to AWS.

216
00:12:36,990 --> 00:12:38,310
Think about what this does.

217
00:12:38,310 --> 00:12:41,833
You now have a global front door, Anycast

218
00:12:41,833 --> 00:12:43,473
on the AWS network.

219
00:12:46,620 --> 00:12:48,810
So let's go into under the hood

220
00:12:48,810 --> 00:12:52,263
of what happens when a
request comes to this network?

221
00:12:53,340 --> 00:12:56,100
Your users are trying
to access applications,

222
00:12:56,100 --> 00:12:59,280
which might be in database
regions or other clouds

223
00:12:59,280 --> 00:13:00,873
or on-premise networks.

224
00:13:02,700 --> 00:13:06,570
When request hits the database
Edge, the CloudFront PoP,

225
00:13:06,570 --> 00:13:08,040
there's TLS termination

226
00:13:08,040 --> 00:13:10,893
and the TLS optimizations
that happen through there.

227
00:13:11,820 --> 00:13:16,110
We optimize routing to the best PoP

228
00:13:16,110 --> 00:13:19,500
from a latency point of
view, and we get millions

229
00:13:19,500 --> 00:13:22,650
of measurements on real time latency data

230
00:13:22,650 --> 00:13:26,340
from web bugs that are
deployed across the world.

231
00:13:26,340 --> 00:13:30,300
That allows us to route your
requests to the best PoP.

232
00:13:30,300 --> 00:13:32,130
And we handle congestion on the network

233
00:13:32,130 --> 00:13:33,330
as part of this routing.

234
00:13:34,500 --> 00:13:37,740
Your dynamic content or APIs go

235
00:13:37,740 --> 00:13:40,950
over the privately managed backbone,

236
00:13:40,950 --> 00:13:45,420
the database backbone,
straight to your regions,

237
00:13:45,420 --> 00:13:46,713
to your applications.

238
00:13:47,820 --> 00:13:50,760
For cacheable content,
it goes through a series

239
00:13:50,760 --> 00:13:54,780
of tiered caches on the AWS network.

240
00:13:54,780 --> 00:13:57,690
These caches are on the AWS PoPs

241
00:13:57,690 --> 00:14:00,723
as well as in regions in AWS.

242
00:14:02,700 --> 00:14:06,360
Optionally, customers
configure Origin Shield, which

243
00:14:06,360 --> 00:14:11,160
is yet another layer of caching
that allows better offload

244
00:14:11,160 --> 00:14:13,740
and better performance through
persistent connections back

245
00:14:13,740 --> 00:14:14,913
to your origins.

246
00:14:16,080 --> 00:14:19,998
Now as we've seen, a lot
of our customers want

247
00:14:19,998 --> 00:14:23,970
to customize and
personalize their delivery.

248
00:14:23,970 --> 00:14:26,670
We've added capabilities
like CloudFront functions

249
00:14:26,670 --> 00:14:28,920
and Lambda Edge over the years, along

250
00:14:28,920 --> 00:14:31,260
with a global key value store

251
00:14:31,260 --> 00:14:33,510
that allows you to do AB testing

252
00:14:33,510 --> 00:14:37,230
or manipulate request
response capabilities

253
00:14:37,230 --> 00:14:38,640
on your requests.

254
00:14:38,640 --> 00:14:42,210
This again allows you
to put compute closer

255
00:14:42,210 --> 00:14:45,600
to where your users are
and reduce the latency

256
00:14:45,600 --> 00:14:46,953
that they experience.

257
00:14:51,690 --> 00:14:54,101
Over the years, we've added a lot

258
00:14:54,101 --> 00:14:56,640
of performance enhancements
to different parts

259
00:14:56,640 --> 00:14:58,410
of the request flow.

260
00:14:58,410 --> 00:15:03,410
One such enhancement was
QUIC/HTTP3 launched in 2023.

261
00:15:04,830 --> 00:15:09,830
QUIC/HTTP3 originally from
Google allows faster time

262
00:15:10,858 --> 00:15:15,271
to First Byte and leads to TCP head

263
00:15:15,271 --> 00:15:18,270
of line blocking removal.

264
00:15:18,270 --> 00:15:21,537
What it does is it combines the TLS

265
00:15:21,537 --> 00:15:24,633
and the HGTP Handshake
into single connection.

266
00:15:27,540 --> 00:15:32,540
Over 25% of requests on
platform today are on QUIC,

267
00:15:32,700 --> 00:15:35,500
and this is something that
is available just by default.

268
00:15:39,138 --> 00:15:42,600
Last week, we added another capability

269
00:15:42,600 --> 00:15:47,013
for enhancing the
performance of QUIC/HTTP3.

270
00:15:48,450 --> 00:15:51,810
We added support for HTTPS DNS records.

271
00:15:51,810 --> 00:15:55,680
Now this is a DNS record
type that allows us

272
00:15:55,680 --> 00:15:59,460
to send hints about
supported HTTP protocols

273
00:15:59,460 --> 00:16:02,370
as part of DNS query itself.

274
00:16:02,370 --> 00:16:04,593
Let's understand what that means.

275
00:16:06,360 --> 00:16:07,530
When your client

276
00:16:07,530 --> 00:16:11,580
or browser session requests an IP address

277
00:16:11,580 --> 00:16:13,980
for your application hosted on CloudFront,

278
00:16:13,980 --> 00:16:17,670
it makes the DNS query and
that's where it gets the A

279
00:16:17,670 --> 00:16:21,030
or quad, a address of the CloudFront PoP.

280
00:16:21,030 --> 00:16:24,727
Your browser then establishes a TCP TLS

281
00:16:24,727 --> 00:16:27,560
and a CTP connection with CloudFront.

282
00:16:28,650 --> 00:16:31,653
That connection happens
over HTP 1.1 or 1.2.

283
00:16:33,420 --> 00:16:38,420
Then CloudFront provides a
clue to your browser saying

284
00:16:38,670 --> 00:16:42,570
We support HTTP3 as part
of all service headers.

285
00:16:42,570 --> 00:16:46,020
That leads to an additional handshake

286
00:16:46,020 --> 00:16:49,533
and round trip time when
connecting to the optimal protocol.

287
00:16:50,850 --> 00:16:54,190
What with the launch of HTTPS DNS records

288
00:16:55,080 --> 00:16:58,320
in the query itself, the
DNS query itself you,

289
00:16:58,320 --> 00:17:02,170
we will pass support for HTTP3 as a signal

290
00:17:03,270 --> 00:17:05,550
when you now make the
connection to CloudFront.

291
00:17:05,550 --> 00:17:09,960
It comes with already the
optimal protocol selection

292
00:17:09,960 --> 00:17:11,073
of HTTP3.

293
00:17:12,120 --> 00:17:14,460
This has been a huge
hit as it leads not just

294
00:17:14,460 --> 00:17:16,110
to performance benefit,

295
00:17:16,110 --> 00:17:20,340
but also DNS query cost reduction

296
00:17:20,340 --> 00:17:24,873
because alias records on
Route 53 are free of charge.

297
00:17:30,510 --> 00:17:31,590
There's some other enhancement

298
00:17:31,590 --> 00:17:34,653
that we made on round trip reduction.

299
00:17:35,730 --> 00:17:37,560
Let me walk through two of those.

300
00:17:37,560 --> 00:17:41,610
The first one is TLS 1.3 to Origin.

301
00:17:41,610 --> 00:17:44,842
We just launched this
capability that allows you

302
00:17:44,842 --> 00:17:49,110
to establish TLS 1.3 origins connections

303
00:17:49,110 --> 00:17:52,260
between CloudFront and
your supported origins.

304
00:17:52,260 --> 00:17:53,993
So if you have your origins

305
00:17:53,993 --> 00:17:57,990
that support TLS 1.3, this just works.

306
00:17:57,990 --> 00:18:02,430
We've seen almost 36%
improvement in handshake time.

307
00:18:02,430 --> 00:18:04,931
As with TLS 1.3, it cuts

308
00:18:04,931 --> 00:18:08,763
the round trip connections
for TLS exchange.

309
00:18:10,200 --> 00:18:12,700
The second one is TCP Fast open

310
00:18:14,160 --> 00:18:16,560
TCP Fast Open allows data to be sent

311
00:18:16,560 --> 00:18:19,053
as part of HTCP SYN exchange.

312
00:18:19,890 --> 00:18:21,240
We've added support for this

313
00:18:21,240 --> 00:18:25,680
and observed 50% improvement
in TCP Connect times.

314
00:18:25,680 --> 00:18:28,440
This is available between CloudFront PoPs

315
00:18:28,440 --> 00:18:31,440
and our internal caching layers.

316
00:18:31,440 --> 00:18:33,123
Again, works by default.

317
00:18:35,190 --> 00:18:38,250
The best part about these
performance enhancements are

318
00:18:38,250 --> 00:18:40,800
that they are enabled by default.

319
00:18:40,800 --> 00:18:43,170
They just work and they're free.

320
00:18:43,170 --> 00:18:46,560
So I would recommend
that you look at these

321
00:18:46,560 --> 00:18:48,685
and see if these apply to you, especially

322
00:18:48,685 --> 00:18:52,980
as TLS 1.3 and HTTP DNS records

323
00:18:52,980 --> 00:18:57,153
and take advantage of these
with your application delivery.

324
00:18:59,160 --> 00:19:01,560
Okay, we are now going to switch

325
00:19:01,560 --> 00:19:05,040
to this next part, which
is building a secure Edge.

326
00:19:05,040 --> 00:19:07,983
I'm gonna invite Etienne
to walk you through that.

327
00:19:09,990 --> 00:19:11,963
- Thank you Nishit, for
all the work that you

328
00:19:11,963 --> 00:19:14,280
and your team put together
to improve the performance

329
00:19:14,280 --> 00:19:15,180
for our customers.

330
00:19:16,440 --> 00:19:18,180
So I'd like to talk a little bit about

331
00:19:18,180 --> 00:19:22,770
how we provide Security Edge,
what you can do and what is

332
00:19:22,770 --> 00:19:25,320
provided to you by default
when you use CloudFront.

333
00:19:27,099 --> 00:19:29,370
So Nishit described a little bit about

334
00:19:29,370 --> 00:19:32,670
how the request path happens
through our infrastructure

335
00:19:32,670 --> 00:19:35,100
and I'm going to talk in
a little bit more detail

336
00:19:35,100 --> 00:19:36,603
about what we do at the Edge.

337
00:19:38,040 --> 00:19:41,605
So typically at an Edge
Location, we provide connection

338
00:19:41,605 --> 00:19:45,565
from there back to an
AWS origin, which may be

339
00:19:45,565 --> 00:19:49,533
a load balancer or it could be
to your on-premise location.

340
00:19:51,630 --> 00:19:54,630
With that type of
connection, we can provide

341
00:19:54,630 --> 00:19:56,758
to AWS origins using VPC Origins

342
00:19:56,758 --> 00:20:01,260
where we can ingress traffic
into a private subnet,

343
00:20:01,260 --> 00:20:04,650
thereby reducing the the tax
surface, reducing the need

344
00:20:04,650 --> 00:20:08,190
for public load balances
and recently just launched

345
00:20:08,190 --> 00:20:11,280
is cross account VPC origin support.

346
00:20:11,280 --> 00:20:13,980
So you can actually use
almost a hub and spoke model

347
00:20:13,980 --> 00:20:17,190
for using CloudFront to
route into private subnets

348
00:20:17,190 --> 00:20:18,603
across multiple accounts.

349
00:20:20,070 --> 00:20:21,750
Again, we have origin access control

350
00:20:21,750 --> 00:20:24,870
to help protect your
access from CloudFront

351
00:20:24,870 --> 00:20:27,480
to something like Lambda
URLs or your buckets

352
00:20:27,480 --> 00:20:29,133
and some of our media services.

353
00:20:30,870 --> 00:20:34,203
So when traffic come comes to
your CloudFront distribution,

354
00:20:35,107 --> 00:20:37,620
CloudFront will provide a TLS certificate

355
00:20:37,620 --> 00:20:39,540
for someone to connect to.

356
00:20:39,540 --> 00:20:42,390
Right now we've actually
just launched MTLS support,

357
00:20:42,390 --> 00:20:45,660
so a client can provide a certificate

358
00:20:45,660 --> 00:20:47,360
and authenticate that way as well.

359
00:20:48,720 --> 00:20:53,106
On top of that, the team
have enabled post quantum

360
00:20:53,106 --> 00:20:56,370
cryptography support or cipher supports.

361
00:20:56,370 --> 00:20:58,180
And so what this means is that

362
00:20:59,070 --> 00:21:03,930
by default, when you use
CloudFront, you're future proofed

363
00:21:03,930 --> 00:21:06,573
for that type of attack risk.

364
00:21:09,420 --> 00:21:11,490
On top of that, CloudFront
provides the ability

365
00:21:11,490 --> 00:21:14,820
to protect against Layer 3

366
00:21:14,820 --> 00:21:17,763
and layer of war attack
vectors by using Shield.

367
00:21:19,920 --> 00:21:23,910
This helps you protect against
issues on known offenders

368
00:21:23,910 --> 00:21:25,233
and provides a SIM proxy.

369
00:21:27,270 --> 00:21:29,610
There's continuous inspection at the Edge

370
00:21:29,610 --> 00:21:32,310
and there's protocol validation
and packet validation.

371
00:21:34,020 --> 00:21:35,670
There are automated routing policies

372
00:21:35,670 --> 00:21:38,460
for particular large attacks so

373
00:21:38,460 --> 00:21:42,573
that it helps mitigate the risk
away from your applications.

374
00:21:46,320 --> 00:21:50,940
CloudFront also provides
the ability to monitor

375
00:21:50,940 --> 00:21:54,210
and check the resource application usage

376
00:21:54,210 --> 00:21:58,350
at the Edge so that we can
make sure that attack surfaces

377
00:21:58,350 --> 00:22:01,486
that would be vulnerable to Solaris

378
00:22:01,486 --> 00:22:04,473
and HTTP/2 Rapid Reset are negated.

379
00:22:06,120 --> 00:22:07,230
There's further protections

380
00:22:07,230 --> 00:22:10,470
that you could have with using AWS WAF.

381
00:22:10,470 --> 00:22:14,129
You can elect to turn this on
on your platform distribution.

382
00:22:14,129 --> 00:22:17,020
Here you can use controls
such as rate limiting

383
00:22:17,880 --> 00:22:21,540
by aggregate key employ
Amazon managed rules such

384
00:22:21,540 --> 00:22:23,220
as the anti-DDoS rules

385
00:22:23,220 --> 00:22:26,010
and our Amazon partner Edge
and managed rules as well.

386
00:22:26,010 --> 00:22:28,518
You can build your own custom
rules and use bot control

387
00:22:28,518 --> 00:22:30,933
and fraud control rule sets at the Edge.

388
00:22:35,160 --> 00:22:38,250
So let's talk a little
bit about bot control

389
00:22:38,250 --> 00:22:39,393
and fraud control.

390
00:22:40,950 --> 00:22:42,570
Our Anti-DDoS rule set allows you

391
00:22:42,570 --> 00:22:45,130
to very quickly turn on protections

392
00:22:46,080 --> 00:22:49,950
to protect your application
against volumetric attacks.

393
00:22:49,950 --> 00:22:51,150
This is something that you can tune

394
00:22:51,150 --> 00:22:53,633
and we'll talk a little bit
more detail about this later.

395
00:22:56,190 --> 00:22:58,113
With AWS WAF bot control,

396
00:22:58,980 --> 00:23:01,530
you can choose two different
types of modes of operation

397
00:23:01,530 --> 00:23:04,590
to protect against common
bots that are easily detected

398
00:23:04,590 --> 00:23:07,170
through common signatures
and then looking at behavior

399
00:23:07,170 --> 00:23:10,290
and machine learning
capability with targeted bots.

400
00:23:10,290 --> 00:23:11,973
These are for sophisticated bots.

401
00:23:12,810 --> 00:23:14,550
We'll talk a little bit more
about some of the innovations

402
00:23:14,550 --> 00:23:16,263
that the team have introduced.

403
00:23:20,520 --> 00:23:21,353
On top of that,

404
00:23:21,353 --> 00:23:25,500
we have our account takeover
fraud prevention rule sets

405
00:23:25,500 --> 00:23:28,313
and our account creation
fraud prevention rule sets.

406
00:23:28,313 --> 00:23:30,690
These are particularly
helpful when you want to deal

407
00:23:30,690 --> 00:23:32,700
with credential stuffing attacks or

408
00:23:32,700 --> 00:23:35,310
if you have a particular
benefit when someone wants

409
00:23:35,310 --> 00:23:36,570
to sign up an account,

410
00:23:36,570 --> 00:23:40,286
but there's a financial
benefit or a scraping benefit

411
00:23:40,286 --> 00:23:42,993
that someone would want
to take advantage of

412
00:23:42,993 --> 00:23:45,930
and these would help
provide you the controls

413
00:23:45,930 --> 00:23:48,330
at the Edge of the network
to prevent that risk.

414
00:23:51,390 --> 00:23:53,070
So let's talk about anti-DDoS rules

415
00:23:53,070 --> 00:23:56,583
and how these rules reduce
their attack surface.

416
00:23:57,690 --> 00:24:00,277
DDoS attacks When I've
helped customers mitigate

417
00:24:00,277 --> 00:24:04,030
these DDoS attacks, rate
controls alone are not sufficient

418
00:24:05,790 --> 00:24:08,215
and so you would want
to not spend time going

419
00:24:08,215 --> 00:24:10,200
through your logs and
trying to figure out how

420
00:24:10,200 --> 00:24:12,030
to put these protections at the Edge just

421
00:24:12,030 --> 00:24:13,473
with simple IP controls.

422
00:24:14,820 --> 00:24:17,490
What you can do is use
the anti-DDoS rule set

423
00:24:17,490 --> 00:24:19,095
and which is quite quick to deploy

424
00:24:19,095 --> 00:24:22,260
and within a few minutes you
can have an effective control.

425
00:24:22,260 --> 00:24:23,970
What's really neat about this is

426
00:24:23,970 --> 00:24:26,793
that you can tune this
rule set based on the type

427
00:24:26,793 --> 00:24:29,280
of workload you have and your appetite

428
00:24:29,280 --> 00:24:31,653
for absorbing a certain amount of traffic.

429
00:24:33,060 --> 00:24:34,290
Typically, you would want to make sure

430
00:24:34,290 --> 00:24:37,335
that this rule set sits in the top part

431
00:24:37,335 --> 00:24:40,050
of your rules so that
it's exposed to as much

432
00:24:40,050 --> 00:24:41,900
of the traffic signature as possible.

433
00:24:43,860 --> 00:24:46,170
This allows you to tune the rule sets,

434
00:24:46,170 --> 00:24:47,850
decide which path you want to protect.

435
00:24:47,850 --> 00:24:49,450
You can scope these protections,

436
00:24:50,370 --> 00:24:51,510
you can add exclusion lists.

437
00:24:51,510 --> 00:24:53,160
There may be parts of your own application

438
00:24:53,160 --> 00:24:55,373
that you don't want this
control in place for.

439
00:24:57,720 --> 00:24:59,550
And then there's a rich set of metrics

440
00:24:59,550 --> 00:25:02,013
that are emitted into
CloudWatch that you can then use

441
00:25:02,013 --> 00:25:05,970
to drive alarms and to be
able to build some dashboards

442
00:25:05,970 --> 00:25:09,183
to understand the type of
DDoS risk that you're facing.

443
00:25:14,280 --> 00:25:18,240
This helps you make sure that
you can more quickly adapt

444
00:25:18,240 --> 00:25:20,650
and mitigate for your volumetric attacks

445
00:25:21,570 --> 00:25:24,070
and improve the accuracy
of your DDoS mitigations.

446
00:25:25,020 --> 00:25:27,960
There's a challenge capability
in the anti DDoS rules

447
00:25:27,960 --> 00:25:29,856
that allow you to have
a conditional action

448
00:25:29,856 --> 00:25:33,243
to help prove out that someone
is a valid user or not.

449
00:25:35,160 --> 00:25:37,110
And the granular controls allow you

450
00:25:37,110 --> 00:25:40,830
to change your rule sets based on the risk

451
00:25:40,830 --> 00:25:42,930
that you're facing at
any one point in time.

452
00:25:42,930 --> 00:25:45,600
You may have an appetite
that you would have

453
00:25:45,600 --> 00:25:49,290
a lower risk profile during a large event

454
00:25:49,290 --> 00:25:54,290
and you may have a more,
less of an appetite

455
00:25:57,630 --> 00:25:58,470
during a large event.

456
00:25:58,470 --> 00:26:03,470
Yeah. Alright, pivoting to
what we've recently released,

457
00:26:04,920 --> 00:26:09,920
which is mutual TLS or mutual
transport layer security

458
00:26:11,460 --> 00:26:13,800
authentication, which
is a security protocol

459
00:26:13,800 --> 00:26:17,065
that extends the standard
TLS authentication into a

460
00:26:17,065 --> 00:26:20,730
bidirectional certificate
based authentication.

461
00:26:20,730 --> 00:26:23,400
If you've not yet used this,
what this simply means is

462
00:26:23,400 --> 00:26:26,171
that a client provides a
certificate to help prove

463
00:26:26,171 --> 00:26:29,980
that it's who it's and
CloudFront has two modes

464
00:26:29,980 --> 00:26:34,980
of operation where you can
allow for both standard traffic

465
00:26:36,180 --> 00:26:39,420
with a normal certificate
and out of mutual TLS

466
00:26:39,420 --> 00:26:41,760
and TLS mutual TLS only.

467
00:26:41,760 --> 00:26:44,613
This allows you to migrate
between the two models.

468
00:26:46,590 --> 00:26:49,170
We're quite excited to see
what our customers do with us

469
00:26:49,170 --> 00:26:51,783
and please have a look at this capability.

470
00:26:55,980 --> 00:26:58,620
I'm personally quite excited
about what we we are doing

471
00:26:58,620 --> 00:27:03,420
in the space with Agentic
in the agentic internet era,

472
00:27:03,420 --> 00:27:04,800
and this is an additional capability.

473
00:27:04,800 --> 00:27:06,050
It was recently launched.

474
00:27:09,600 --> 00:27:11,250
What we have found is that businesses

475
00:27:11,250 --> 00:27:16,250
are facing an onslaught
of traffic via agents.

476
00:27:18,900 --> 00:27:21,870
And what this means is
that you potentially need

477
00:27:21,870 --> 00:27:24,630
to be able to have not only
just a control at the Edge,

478
00:27:24,630 --> 00:27:27,780
but you also need to have
a rich set of metrics.

479
00:27:27,780 --> 00:27:30,180
Bot control's at the center of this.

480
00:27:30,180 --> 00:27:31,770
And this allows you to make sure

481
00:27:31,770 --> 00:27:35,470
that legitimate AI agents
can access your distribution

482
00:27:36,690 --> 00:27:39,843
through a process of a
cryptographic control.

483
00:27:40,770 --> 00:27:45,562
And this allows you to then
to create fine tune controls

484
00:27:45,562 --> 00:27:48,554
for your AI agents to
access specific parts

485
00:27:48,554 --> 00:27:52,863
of your application whilst
denying access to others.

486
00:27:54,060 --> 00:27:56,526
It of us have these managed rules

487
00:27:56,526 --> 00:27:57,480
that allowed that automatically

488
00:27:57,480 --> 00:28:02,043
allow verified bots plus
blocking unverified traffic.

489
00:28:04,230 --> 00:28:08,070
So the first step is to make sure

490
00:28:08,070 --> 00:28:11,100
that you can identify the risk

491
00:28:11,100 --> 00:28:13,800
and then decide what you want to mitigate.

492
00:28:13,800 --> 00:28:16,330
This is done through both categorization

493
00:28:17,250 --> 00:28:21,789
or through the simple AI
label that you can choose

494
00:28:21,789 --> 00:28:24,573
which specific bot you want to block.

495
00:28:26,760 --> 00:28:30,714
With web bot authentication,
you'll be able

496
00:28:30,714 --> 00:28:34,378
to allow your application
to be more deeply integrated

497
00:28:34,378 --> 00:28:38,850
into your WAV to make sure that
those parts can be monetized

498
00:28:38,850 --> 00:28:40,080
if you choose to.

499
00:28:40,080 --> 00:28:42,530
So there's an additional
level of capability that

500
00:28:43,440 --> 00:28:45,060
is continuously being built on

501
00:28:45,060 --> 00:28:47,483
and will keep adding to
this capability and time.

502
00:28:49,647 --> 00:28:51,350
Now I'd like to hand back to Nishit

503
00:28:51,350 --> 00:28:52,940
to talk a little bit about some

504
00:28:52,940 --> 00:28:54,390
of the work the team are doing

505
00:28:54,390 --> 00:28:56,700
to help improve our develops lives.

506
00:28:56,700 --> 00:28:57,533
- Thank you.

507
00:28:59,760 --> 00:29:02,913
As part, this is my favorite part,

508
00:29:04,590 --> 00:29:08,340
so let's talk about security.

509
00:29:08,340 --> 00:29:12,570
Now, lots of customers tell
us that configuring security

510
00:29:12,570 --> 00:29:16,860
in this ever evolving landscape is hard,

511
00:29:16,860 --> 00:29:19,050
but it does not need to be hard.

512
00:29:19,050 --> 00:29:21,524
This is an area that we
are massively investing

513
00:29:21,524 --> 00:29:23,553
in solving this challenge.

514
00:29:24,600 --> 00:29:28,757
Earlier this year, we re-imagined
a developer experience

515
00:29:28,757 --> 00:29:33,757
for configuring security rules
with CloudFront and ALBs.

516
00:29:34,260 --> 00:29:37,290
Here you can add WAF capabilities

517
00:29:37,290 --> 00:29:39,420
as part of protection packs.

518
00:29:39,420 --> 00:29:42,900
These are tailored rules and rule sets

519
00:29:42,900 --> 00:29:45,633
that are designed for
your traffic profile.

520
00:29:46,500 --> 00:29:49,843
It comes with vis improved
visibility as well

521
00:29:49,843 --> 00:29:54,243
as easier, more intuitive
configuration controls.

522
00:29:55,110 --> 00:29:56,940
We are adding more capabilities here

523
00:29:56,940 --> 00:29:59,130
to bring smarter recommendations

524
00:29:59,130 --> 00:30:03,123
and automated traffic analysis
on these rollbacks in future.

525
00:30:04,710 --> 00:30:08,010
Already with these enhancements we've seen

526
00:30:08,010 --> 00:30:12,210
about 80% reduction in the
initial configuration steps

527
00:30:12,210 --> 00:30:15,210
and a dramatic improvement
in the success rate

528
00:30:15,210 --> 00:30:18,300
for customers configuring
their security rules

529
00:30:18,300 --> 00:30:20,313
on the front doors.

530
00:30:24,810 --> 00:30:27,723
Now here's another favorite part of mine.

531
00:30:28,950 --> 00:30:32,670
Developer complexity is not
just technical complexity,

532
00:30:32,670 --> 00:30:34,833
it is also pricing complexity.

533
00:30:36,480 --> 00:30:38,370
When CloudFront was launched back

534
00:30:38,370 --> 00:30:43,370
in 2008, we disrupted
the CDN pricing industry

535
00:30:43,500 --> 00:30:46,080
with pay as you go pricing.

536
00:30:46,080 --> 00:30:49,830
Customers could simply use the CDN

537
00:30:49,830 --> 00:30:52,440
and pay as their traffic grew

538
00:30:52,440 --> 00:30:54,663
and the pricing scaled accordingly.

539
00:30:55,590 --> 00:30:58,080
But over the years, customers have told us

540
00:30:58,080 --> 00:31:01,353
that while they like the
pay as you go pricing model,

541
00:31:02,490 --> 00:31:05,010
they're worried about bill shocks.

542
00:31:05,010 --> 00:31:09,810
They might see their websites
either getting really popular

543
00:31:09,810 --> 00:31:13,511
and viral and it would lead
to sudden increase in bills

544
00:31:13,511 --> 00:31:17,340
or they might get hot
linked or even suffer

545
00:31:17,340 --> 00:31:18,840
from DDoS attacks that might lead

546
00:31:18,840 --> 00:31:22,080
to exponential request charges.

547
00:31:22,080 --> 00:31:24,360
We've solved that problem with

548
00:31:24,360 --> 00:31:26,700
what we call flat-rate pricing plans,

549
00:31:26,700 --> 00:31:28,683
and this was launched two weeks ago.

550
00:31:29,700 --> 00:31:33,390
It basically starts with $0 pricing plans

551
00:31:33,390 --> 00:31:36,780
that include not just CloudFront,

552
00:31:36,780 --> 00:31:41,473
but security services,
Amazon S3, Route 53,

553
00:31:42,480 --> 00:31:47,130
CloudWatch Ingestion, ACM,
and a bunch of other services.

554
00:31:47,130 --> 00:31:50,880
These pricing plans come
with no overages whatsoever.

555
00:31:50,880 --> 00:31:51,713
You pay a fixed monthly price

556
00:31:51,713 --> 00:31:55,893
or you start with $0 free plan.

557
00:31:57,150 --> 00:32:00,300
And then you upgrade to these
according to your growth

558
00:32:00,300 --> 00:32:03,870
of your business, but you
never would see overage

559
00:32:03,870 --> 00:32:06,333
or unpredictable pricing anymore.

560
00:32:07,500 --> 00:32:09,960
There's no long term commitments either.

561
00:32:09,960 --> 00:32:13,950
In just a week or so since
launch, tens of thousands

562
00:32:13,950 --> 00:32:16,800
of customers are using,
taking benefit of these plans

563
00:32:16,800 --> 00:32:18,690
and serving their applications.

564
00:32:18,690 --> 00:32:21,120
Something that if you haven't looked at,

565
00:32:21,120 --> 00:32:22,970
I would encourage you to take a look.

566
00:32:25,320 --> 00:32:27,930
Right, another great simplification

567
00:32:27,930 --> 00:32:29,973
is CloudFront SaaS Manager.

568
00:32:31,230 --> 00:32:34,500
Lots of our customers
host millions of domains

569
00:32:34,500 --> 00:32:36,330
or hundreds of thousands of domains in

570
00:32:36,330 --> 00:32:38,850
multi-tenant applications.

571
00:32:38,850 --> 00:32:42,600
The vibe coding platforms like
Cursor, Lovable, et cetera,

572
00:32:42,600 --> 00:32:45,440
also allow customers to
build applications with lots

573
00:32:45,440 --> 00:32:49,323
of multi-tenant domains and and tenants.

574
00:32:50,910 --> 00:32:53,040
Up until this time, you would have

575
00:32:53,040 --> 00:32:55,980
to create individual distributions

576
00:32:55,980 --> 00:32:58,083
and apply policies such as cash policies

577
00:32:58,083 --> 00:33:02,970
or security policies individually
on those distributions.

578
00:33:02,970 --> 00:33:06,867
With CloudFront SaaS Manager,
it provides a unified way

579
00:33:06,867 --> 00:33:09,060
and a dramatically simpler experience

580
00:33:09,060 --> 00:33:12,360
in which you can handle
multi-tenant applications

581
00:33:12,360 --> 00:33:14,760
on the AWS Edge.

582
00:33:14,760 --> 00:33:16,981
You can apply template policies

583
00:33:16,981 --> 00:33:21,390
that can apply on the
entire list of tenants,

584
00:33:21,390 --> 00:33:25,110
or you can override
certain specific policies

585
00:33:25,110 --> 00:33:28,050
because of you may have some
premium set of customers

586
00:33:28,050 --> 00:33:31,623
and you know, other tiers of customers.

587
00:33:32,700 --> 00:33:35,280
This is again, one of
the great simplifications

588
00:33:35,280 --> 00:33:37,290
that we are evolving.

589
00:33:37,290 --> 00:33:38,340
This was the first step

590
00:33:38,340 --> 00:33:40,248
and we are adding more capabilities such

591
00:33:40,248 --> 00:33:43,953
as tenant specific analytics and reports.

592
00:33:47,130 --> 00:33:51,450
Great, to learn about the
real world applications

593
00:33:51,450 --> 00:33:54,270
of the services and
enhancements we talked about.

594
00:33:54,270 --> 00:33:57,213
I would like to invite
Ambrose from Atlassian.

595
00:34:01,830 --> 00:34:02,837
- Thank you Nishit.

596
00:34:04,500 --> 00:34:06,390
I'm excited to be sharing in the ways

597
00:34:06,390 --> 00:34:10,920
in which Atlassian has leveraged
CloudFront, WAF and Shield

598
00:34:10,920 --> 00:34:13,080
to improve our global security footprint

599
00:34:13,080 --> 00:34:14,970
alongside some useful
patterns we have found

600
00:34:14,970 --> 00:34:16,893
in our widespread adoption journey.

601
00:34:18,630 --> 00:34:21,750
To give some background,
Atlassian as a whole aims

602
00:34:21,750 --> 00:34:24,180
to unlock the potential in every team.

603
00:34:24,180 --> 00:34:26,910
We do so by offering our
applications across a variety

604
00:34:26,910 --> 00:34:30,390
of collections, but all on the
goal to help teams organize,

605
00:34:30,390 --> 00:34:33,900
communicate, and collaborate
around shared work.

606
00:34:33,900 --> 00:34:36,330
Some commonly used applications
you might have seen

607
00:34:36,330 --> 00:34:39,660
before include Confluence
for information sharing.

608
00:34:39,660 --> 00:34:41,790
Jira for project and issue tracking.

609
00:34:41,790 --> 00:34:43,940
Loom for asynchronous video messaging.

610
00:34:43,940 --> 00:34:47,490
Bitbucket for code hosting
and Rovo, our AI powered suite

611
00:34:47,490 --> 00:34:49,980
of applications and agents connected

612
00:34:49,980 --> 00:34:51,333
to the Atlassian platform.

613
00:34:52,350 --> 00:34:54,720
As of today, Atlassian now serves millions

614
00:34:54,720 --> 00:34:58,143
of customers globally across
a wide range of industries.

615
00:35:00,750 --> 00:35:02,460
Atlassian's come a really long way

616
00:35:02,460 --> 00:35:05,310
from when we first launched in 2002.

617
00:35:05,310 --> 00:35:08,610
Over the years, we've released
and acquired many products

618
00:35:08,610 --> 00:35:11,130
and even went public back in 2015.

619
00:35:11,130 --> 00:35:14,730
Now, in 2016, Atlassian
began the journey to move all

620
00:35:14,730 --> 00:35:17,850
of its workloads to be
fully hosted in the cloud.

621
00:35:17,850 --> 00:35:21,030
And as of 2022, we completed this journey.

622
00:35:21,030 --> 00:35:22,950
As of today, we handle tens of billions

623
00:35:22,950 --> 00:35:25,140
of requests over tens of thousands

624
00:35:25,140 --> 00:35:28,500
of EC2 instances across
13 different regions,

625
00:35:28,500 --> 00:35:30,510
handling multiple petabytes of data out

626
00:35:30,510 --> 00:35:33,333
to clients every single day.

627
00:35:34,470 --> 00:35:36,360
But that's not the end of our story.

628
00:35:36,360 --> 00:35:38,730
Over the years, the team
has continued to improve

629
00:35:38,730 --> 00:35:40,657
and develop upon its cloud posture

630
00:35:40,657 --> 00:35:44,100
and architecture leading
to our resultant migration

631
00:35:44,100 --> 00:35:45,570
of our largest products.

632
00:35:45,570 --> 00:35:48,243
Duran Confluence onto CloudFront.

633
00:35:50,460 --> 00:35:52,770
Now, Atlassian already
has a really long running

634
00:35:52,770 --> 00:35:53,970
history with CloudFront.

635
00:35:55,080 --> 00:35:56,370
We've invested several years

636
00:35:56,370 --> 00:35:58,743
and deployed thousands of distributions.

637
00:35:59,790 --> 00:36:03,030
This figure here shows a
historical high level view

638
00:36:03,030 --> 00:36:05,853
of a request flow on what a
page load might look like.

639
00:36:07,050 --> 00:36:09,900
Dynamic requests land on
a network load balancer

640
00:36:09,900 --> 00:36:11,520
towards our ingress proxies

641
00:36:11,520 --> 00:36:13,170
before getting routed to a number

642
00:36:13,170 --> 00:36:15,300
of different upstream services.

643
00:36:15,300 --> 00:36:18,780
And CloudFront accelerating
our static front end

644
00:36:18,780 --> 00:36:21,723
and single page application
delivery across the company.

645
00:36:22,590 --> 00:36:24,990
As of today, every single page load

646
00:36:24,990 --> 00:36:29,280
on every Atlassian product
uses CloudFront in some way.

647
00:36:29,280 --> 00:36:31,590
And to add to that, we were
already using a mixture

648
00:36:31,590 --> 00:36:34,009
off the shelf and internally technologies

649
00:36:34,009 --> 00:36:38,130
to mitigate inauthentic
and malicious requests.

650
00:36:38,130 --> 00:36:41,253
So with that, what more
were we looking to achieve?

651
00:36:43,320 --> 00:36:46,440
Building on our rich experience
with CloudFront, we wanted

652
00:36:46,440 --> 00:36:49,383
to leverage it beyond just
acting as a basic CDN.

653
00:36:50,280 --> 00:36:52,410
We still had not yet
adopted this infrastructure

654
00:36:52,410 --> 00:36:54,270
of the delivery of our first fragment

655
00:36:54,270 --> 00:36:57,210
or primary domains on our major products.

656
00:36:57,210 --> 00:36:58,560
And so our goals of moving Jira

657
00:36:58,560 --> 00:37:01,110
and Confluence in the
CloudFront were multifaceted.

658
00:37:02,520 --> 00:37:04,950
We wanted to strengthen our
global security footprint

659
00:37:04,950 --> 00:37:07,620
against growing sophistication
in modern attacks

660
00:37:07,620 --> 00:37:09,093
and compliance regimes.

661
00:37:10,290 --> 00:37:12,240
Deploy a layered defense at the Edge,

662
00:37:12,240 --> 00:37:14,100
leveraging a consistent
control plane to help

663
00:37:14,100 --> 00:37:17,555
with operational burden, identify common

664
00:37:17,555 --> 00:37:19,620
and shared logic in our application,

665
00:37:19,620 --> 00:37:22,500
which we could perform
closer to our customers.

666
00:37:22,500 --> 00:37:25,350
And finally, improve our
last mile performance

667
00:37:25,350 --> 00:37:26,250
for our end users.

668
00:37:28,830 --> 00:37:30,510
Now potentially you might be thinking

669
00:37:30,510 --> 00:37:33,360
if a large portion of our goals
were pertaining to security,

670
00:37:33,360 --> 00:37:36,990
why not just place WAF on
our existing load balances?

671
00:37:36,990 --> 00:37:39,450
And that would be a good question.

672
00:37:39,450 --> 00:37:41,760
Firstly, as network load
balances are a Layer 3,

673
00:37:41,760 --> 00:37:44,643
Layer 4 construct, WAF logic
just doesn't belong there.

674
00:37:45,750 --> 00:37:47,010
And whilst we could have attached them

675
00:37:47,010 --> 00:37:49,050
to our application load balances,

676
00:37:49,050 --> 00:37:51,060
this would've still left
our ingress proxies needing

677
00:37:51,060 --> 00:37:54,180
to do a lot of the heavy
lifting to mitigate inauthentic

678
00:37:54,180 --> 00:37:55,623
and malicious requests.

679
00:37:57,000 --> 00:37:58,980
We wants to push this defense

680
00:37:58,980 --> 00:38:01,293
beyond the compute
infrastructure we managed.

681
00:38:03,630 --> 00:38:05,610
With that in mind, the
journey of getting Jira

682
00:38:05,610 --> 00:38:08,370
and Confluence onto
CloudFront would pose quite

683
00:38:08,370 --> 00:38:09,483
a unique challenge.

684
00:38:10,380 --> 00:38:13,290
As it would need to handle
orders of magnitude more traffic

685
00:38:13,290 --> 00:38:16,083
than any previously existing
CloudFront distribution.

686
00:38:17,280 --> 00:38:19,770
Accommodate logic to support
customer data distributed

687
00:38:19,770 --> 00:38:23,246
across 13 different regions,
be able to host millions

688
00:38:23,246 --> 00:38:25,863
of customer domains and customer sites,

689
00:38:26,730 --> 00:38:28,740
and finally support an
architecture which aligned

690
00:38:28,740 --> 00:38:30,933
with our customer's security requirements.

691
00:38:31,770 --> 00:38:33,780
All in all, this would
prove to be more involved

692
00:38:33,780 --> 00:38:36,600
than just changing where a record pointed

693
00:38:36,600 --> 00:38:37,770
and required us to use some

694
00:38:37,770 --> 00:38:39,513
of CloudFront's newest features.

695
00:38:42,090 --> 00:38:44,000
One of the big questions
before even moving

696
00:38:44,000 --> 00:38:45,780
to CloudFront was to identify

697
00:38:45,780 --> 00:38:48,390
how we could differentiate ourselves

698
00:38:48,390 --> 00:38:50,613
amongst other CloudFront customers.

699
00:38:52,230 --> 00:38:54,540
To build some context,
Atlassian has a variety

700
00:38:54,540 --> 00:38:57,210
of customers who might
operate their workstations

701
00:38:57,210 --> 00:39:00,423
or API integrations under
strict egress controls.

702
00:39:01,260 --> 00:39:02,910
Others might be doing something similar

703
00:39:02,910 --> 00:39:06,030
to this figure where they
leverage split tunnel VPNs

704
00:39:06,030 --> 00:39:07,710
or secure web gateways to ensure

705
00:39:07,710 --> 00:39:09,870
that our products are only accessible

706
00:39:09,870 --> 00:39:11,553
from their corporate IPs.

707
00:39:12,900 --> 00:39:13,890
Such customers require

708
00:39:13,890 --> 00:39:15,930
that their cloud SaaS
provider present itself

709
00:39:15,930 --> 00:39:20,400
on the internet from a predefined
list of IPs, not cohabited

710
00:39:20,400 --> 00:39:23,670
with any other SaaS
software, allowing them

711
00:39:23,670 --> 00:39:26,463
to perform enterprise
application allow listing.

712
00:39:28,500 --> 00:39:31,800
Typically when you use
CloudFront, your distribution will

713
00:39:31,800 --> 00:39:34,893
use a rotating pool of IP
addresses to serve traffic from.

714
00:39:35,880 --> 00:39:37,950
As you can imagine, this
would pose quite a problem

715
00:39:37,950 --> 00:39:40,710
for our customers as
there'll be no clear way

716
00:39:40,710 --> 00:39:41,910
to differentiate ourselves

717
00:39:41,910 --> 00:39:43,966
amongst other CloudFront services,

718
00:39:43,966 --> 00:39:46,233
other services sitting behind CloudFront.

719
00:39:47,100 --> 00:39:48,060
But this is exactly where CloudFront's,

720
00:39:48,060 --> 00:39:51,183
Anycast static IP feature came into play.

721
00:39:53,280 --> 00:39:54,600
By leveraging this new feature

722
00:39:54,600 --> 00:39:57,485
on our CloudFronts, we
were able to dedicate a set

723
00:39:57,485 --> 00:40:00,690
of IPs across our
CloudFront distributions,

724
00:40:00,690 --> 00:40:02,881
allowing ourselves to
be uniquely identifiable

725
00:40:02,881 --> 00:40:05,910
against other CloudFront customers.

726
00:40:05,910 --> 00:40:08,700
This was a massive UN blocker
in unlocking the transition

727
00:40:08,700 --> 00:40:11,220
of Jira and Confluence onto CloudFront.

728
00:40:11,220 --> 00:40:13,620
As many customer network
policies just would not have been

729
00:40:13,620 --> 00:40:15,646
compatible with CloudFront's traditional

730
00:40:15,646 --> 00:40:18,033
shared dynamic IP space.

731
00:40:19,500 --> 00:40:21,180
With the confidence
that we had a unique way

732
00:40:21,180 --> 00:40:25,167
to present ourselves, our eyes
turned to protection building

733
00:40:25,167 --> 00:40:27,858
on our previous experience, we
launched the Shield Advanced

734
00:40:27,858 --> 00:40:30,608
and layer seven application
protection feature enabled.

735
00:40:31,470 --> 00:40:32,970
This enables WAF and CloudFront

736
00:40:32,970 --> 00:40:34,983
to intelligently catch DDoS attacks.

737
00:40:35,910 --> 00:40:37,710
We then combine this with managed rules

738
00:40:37,710 --> 00:40:39,960
for anti-DDoS, common web attacks.

739
00:40:39,960 --> 00:40:43,863
IP reputation lists alongside
a variety of rate limits.

740
00:40:45,000 --> 00:40:46,700
Now, when crafting your managed rules,

741
00:40:46,700 --> 00:40:48,810
it can sometimes be overwhelming trying

742
00:40:48,810 --> 00:40:51,540
to decide which rules
should go in what order,

743
00:40:51,540 --> 00:40:54,030
and this figure here
is a fantastic example

744
00:40:54,030 --> 00:40:56,580
and mental model approach to use,

745
00:40:56,580 --> 00:40:58,732
but you might need to do
something a bit more bespoke

746
00:40:58,732 --> 00:40:59,913
to your environment.

747
00:41:01,440 --> 00:41:03,480
What we have found to
be effective for us is

748
00:41:03,480 --> 00:41:05,730
by layering our rules
in the following order.

749
00:41:06,570 --> 00:41:08,430
First, label any traffic
that you might want

750
00:41:08,430 --> 00:41:11,160
to apply modifications
or exclusions against

751
00:41:11,160 --> 00:41:13,650
in different policies in your chain.

752
00:41:13,650 --> 00:41:17,220
So these might be for
trusted IPs, countries

753
00:41:17,220 --> 00:41:19,470
or even specific clients.

754
00:41:19,470 --> 00:41:22,140
Next come your strict blocking rules.

755
00:41:22,140 --> 00:41:24,360
So these might be your
known blocking conditions

756
00:41:24,360 --> 00:41:27,330
or managed rules or common web attacks.

757
00:41:27,330 --> 00:41:29,700
Nearly behind those come
your course grain rate limits

758
00:41:29,700 --> 00:41:31,110
and custom rules.

759
00:41:31,110 --> 00:41:33,480
And finally, your IP
reputation list pushing

760
00:41:33,480 --> 00:41:35,763
out silent challenges and captures.

761
00:41:36,930 --> 00:41:38,160
Now I wanna take a second

762
00:41:38,160 --> 00:41:41,613
to call out the managed
anti-DDoS rule set.

763
00:41:42,450 --> 00:41:44,130
This is something you
might want to put earlier

764
00:41:44,130 --> 00:41:46,680
in your rule chain, and
we've seen this being

765
00:41:46,680 --> 00:41:49,770
incredibly effective
at stopping the initial

766
00:41:49,770 --> 00:41:53,610
and largest wave of attacks
in a matter of seconds.

767
00:41:53,610 --> 00:41:55,440
It's also paired really well with Shield

768
00:41:55,440 --> 00:41:56,730
in blocking the remaining trail

769
00:41:56,730 --> 00:41:58,203
of malicious requests.

770
00:41:59,340 --> 00:42:00,930
All of this combined has allowed us

771
00:42:00,930 --> 00:42:04,140
to help create a cost-effective
protection funnel

772
00:42:04,140 --> 00:42:05,163
at the network Edge.

773
00:42:08,160 --> 00:42:09,900
As part of all of this, you'll likely need

774
00:42:09,900 --> 00:42:11,193
to perform some tuning.

775
00:42:12,450 --> 00:42:14,550
This typically is quite
an iterative process

776
00:42:14,550 --> 00:42:18,480
and does require both time and patience.

777
00:42:18,480 --> 00:42:19,964
As per this figure, it is recommended

778
00:42:19,964 --> 00:42:23,160
to first implement your
rules set into count mode,

779
00:42:23,160 --> 00:42:26,940
allowing you the opportunity
to observe and adjust any logic

780
00:42:26,940 --> 00:42:30,270
before promoting it to a
block or challenge action.

781
00:42:30,270 --> 00:42:32,370
In our case, some
interesting tuning scenarios

782
00:42:32,370 --> 00:42:35,970
included confluence pages with .conf, MD

783
00:42:35,970 --> 00:42:38,010
or Java exceptions in them.

784
00:42:38,010 --> 00:42:40,890
Others included scenarios
where customers would put bits

785
00:42:40,890 --> 00:42:44,486
of source code or program outputs
into their pages, searches

786
00:42:44,486 --> 00:42:47,343
or even Jira ticket
comments and descriptions.

787
00:42:49,500 --> 00:42:51,030
The result of all of this work though,

788
00:42:51,030 --> 00:42:52,890
is we're now blocking
hundreds of thousands

789
00:42:52,890 --> 00:42:56,010
of requests now made by bots and scanners.

790
00:42:56,010 --> 00:42:57,720
As well as the occasional 10

791
00:42:57,720 --> 00:42:59,493
and hundred million DDoS attack.

792
00:43:03,030 --> 00:43:05,220
Another capability that Atlassian provides

793
00:43:05,220 --> 00:43:07,540
to its customers is something
commonly referred to

794
00:43:07,540 --> 00:43:09,363
as data residency.

795
00:43:10,800 --> 00:43:12,780
This gives organizations the ability

796
00:43:12,780 --> 00:43:15,399
to choose where the application
data is hosted, such

797
00:43:15,399 --> 00:43:17,707
as whether the data is
globally distributed

798
00:43:17,707 --> 00:43:20,863
or stored in a defined
geographic location such

799
00:43:20,863 --> 00:43:23,223
as the EU or the US.

800
00:43:24,240 --> 00:43:25,590
This is particularly important

801
00:43:25,590 --> 00:43:27,930
in regulated industries
where customers need

802
00:43:27,930 --> 00:43:30,633
to meet a number of data
management requirements.

803
00:43:32,370 --> 00:43:36,600
So using this figure as a
example to help paint a picture.

804
00:43:36,600 --> 00:43:39,660
Let's say we have a company
whose confluence tenant resides

805
00:43:39,660 --> 00:43:42,660
in the EU, but they might
have employees living

806
00:43:42,660 --> 00:43:45,948
in the US, previously requests would land

807
00:43:45,948 --> 00:43:48,120
on the nearest ingress proxy to them.

808
00:43:48,120 --> 00:43:49,950
So let's say in Virginia,

809
00:43:49,950 --> 00:43:51,450
before getting routed cross-region

810
00:43:51,450 --> 00:43:53,373
to their backend tenant in the EU.

811
00:43:54,870 --> 00:43:57,300
Bringing our attention back
to CloudFront, we wanted

812
00:43:57,300 --> 00:43:59,790
to find a way to optimize our ability

813
00:43:59,790 --> 00:44:01,380
to route our customer requests

814
00:44:01,380 --> 00:44:03,780
to their respective data
tables, which could be located

815
00:44:03,780 --> 00:44:06,633
in one of our 13 different regions.

816
00:44:07,590 --> 00:44:10,080
This is exactly where the
origin control helper method

817
00:44:10,080 --> 00:44:12,393
for CloudFront functions came into play.

818
00:44:14,820 --> 00:44:16,950
Now leveraging CloudFront functions

819
00:44:16,950 --> 00:44:19,170
and this new helper method, we were able

820
00:44:19,170 --> 00:44:20,580
to implement logic where we take

821
00:44:20,580 --> 00:44:22,372
a customer's site name, look them up

822
00:44:22,372 --> 00:44:25,860
in a key value store to
identify their backend region

823
00:44:25,860 --> 00:44:27,960
and subsequently steer traffic directly to

824
00:44:27,960 --> 00:44:29,510
that customer's backend tenant.

825
00:44:30,690 --> 00:44:32,040
We were still able to route traffic

826
00:44:32,040 --> 00:44:33,600
to the closest possible region where

827
00:44:33,600 --> 00:44:35,250
that made sense, such as

828
00:44:35,250 --> 00:44:38,283
for loading common front-end
components and assets.

829
00:44:39,152 --> 00:44:41,550
In a to in total across
a number of experiences,

830
00:44:41,550 --> 00:44:44,280
we saw improvements in
our time-to-first-byte,

831
00:44:44,280 --> 00:44:47,220
but more importantly, for
requests that were region steered,

832
00:44:47,220 --> 00:44:50,940
we managed to completely
remove cross-region charges

833
00:44:50,940 --> 00:44:53,016
and benefit from a zero rating of data out

834
00:44:53,016 --> 00:44:56,580
between AWS regions and CloudFront.

835
00:44:56,580 --> 00:44:59,583
Resulting in some very
natural cost optimizations.

836
00:45:00,480 --> 00:45:02,370
Now with the mention of cost savings,

837
00:45:02,370 --> 00:45:04,773
you're probably wondering, but how much?

838
00:45:05,730 --> 00:45:07,470
Well here are the results.

839
00:45:07,470 --> 00:45:09,210
Each color in this graph is representing

840
00:45:09,210 --> 00:45:11,850
an individual region and
in total is representing

841
00:45:11,850 --> 00:45:13,893
the stacked total cost over time.

842
00:45:14,730 --> 00:45:16,920
As you can see, we've seen
significant reductions

843
00:45:16,920 --> 00:45:19,620
in our data transfer out fees
thanks to the zero rating

844
00:45:19,620 --> 00:45:21,543
between Amazon regions and CloudFront.

845
00:45:23,190 --> 00:45:24,750
We've also seen similar reductions

846
00:45:24,750 --> 00:45:27,450
in our cross-region fees thanks
to CloudFront doing the work

847
00:45:27,450 --> 00:45:30,123
of determining the data residency region.

848
00:45:31,590 --> 00:45:33,750
Additionally, we enjoy zero rated requests

849
00:45:33,750 --> 00:45:36,720
to CloudFront that get
blocked by WAF opposed

850
00:45:36,720 --> 00:45:38,763
to if they were blocked on an ALB.

851
00:45:39,720 --> 00:45:41,130
This region steering feature has been

852
00:45:41,130 --> 00:45:42,750
so well received across the company

853
00:45:42,750 --> 00:45:45,480
that we've had many requests
from teams across Atlassian

854
00:45:45,480 --> 00:45:48,933
to help provide similar
functionality to their services too.

855
00:45:50,040 --> 00:45:51,630
So all this combined now means

856
00:45:51,630 --> 00:45:54,496
that we're delivering a more
secure experience presented

857
00:45:54,496 --> 00:45:59,010
behind unique static IPs and
we're leveraging CloudFront

858
00:45:59,010 --> 00:46:01,950
to pull data from the
correct origin region,

859
00:46:01,950 --> 00:46:04,110
all the whilst saving money doing it.

860
00:46:04,110 --> 00:46:05,313
How amazing is that?

861
00:46:07,800 --> 00:46:09,660
Before I move on to the
next section, I want

862
00:46:09,660 --> 00:46:11,280
to share some additional notes

863
00:46:11,280 --> 00:46:12,930
that we've learned along the way.

864
00:46:13,860 --> 00:46:15,750
First, if you're using
a network load balancer

865
00:46:15,750 --> 00:46:18,780
as your origin, make sure
your proxies return the HCTP

866
00:46:18,780 --> 00:46:21,570
connection close header
during draining events.

867
00:46:21,570 --> 00:46:23,610
This can help prevent
some surprising connection

868
00:46:23,610 --> 00:46:26,010
terminations on in-flight requests

869
00:46:26,010 --> 00:46:28,320
as your proxy scale in.

870
00:46:28,320 --> 00:46:30,810
This isn't a problem with
application load balances,

871
00:46:30,810 --> 00:46:32,610
as they'll add the header for you

872
00:46:32,610 --> 00:46:35,310
to tell CloudFront to close
the connection gracefully.

873
00:46:36,900 --> 00:46:39,720
Next CloudFront supports
the use of stale-if-error

874
00:46:39,720 --> 00:46:42,453
and stale-while-revalidate
cache-control directives.

875
00:46:43,560 --> 00:46:46,260
These respectively let
you serve stale cache data

876
00:46:46,260 --> 00:46:48,870
during transient errors
and allow CloudFront

877
00:46:48,870 --> 00:46:51,090
to asynchronously update its cache,

878
00:46:51,090 --> 00:46:53,973
reducing latency spikes and origin calls.

879
00:46:55,500 --> 00:46:59,160
Finally, a low hanging fruit
to improved performance.

880
00:46:59,160 --> 00:47:01,170
Look to tune your origin
keep alive timeouts

881
00:47:01,170 --> 00:47:03,210
where appropriate to benefit most

882
00:47:03,210 --> 00:47:04,890
from persistent connections.

883
00:47:04,890 --> 00:47:06,330
For us, this has helped us yield

884
00:47:06,330 --> 00:47:09,093
around 100 to 150 millisecond speedups.

885
00:47:12,420 --> 00:47:14,580
In parallel to all of this work,

886
00:47:14,580 --> 00:47:16,320
the team also wanted to find a way

887
00:47:16,320 --> 00:47:19,983
to improve the observability
we had at the network Edge.

888
00:47:21,960 --> 00:47:24,540
CloudFront itself comes
out of the box with a range

889
00:47:24,540 --> 00:47:26,170
of different metrics and logging

890
00:47:27,030 --> 00:47:29,610
and these might range from
giving us insights into our users

891
00:47:29,610 --> 00:47:32,460
are coming from, the types of
requests that we're getting

892
00:47:32,460 --> 00:47:35,040
and even the responses
that we're sending back.

893
00:47:35,040 --> 00:47:37,690
But these are all from the
perspective of CloudFront.

894
00:47:38,760 --> 00:47:39,900
Our team wanted

895
00:47:39,900 --> 00:47:43,170
to enhance the visibility
we had into the network

896
00:47:43,170 --> 00:47:44,853
and enrich our overall view.

897
00:47:45,810 --> 00:47:47,730
This is exactly where
network error logging came

898
00:47:47,730 --> 00:47:48,563
into play.

899
00:47:49,620 --> 00:47:50,730
For a little background,

900
00:47:50,730 --> 00:47:53,670
network error logging is
a client side mechanism

901
00:47:53,670 --> 00:47:55,740
that is supported by
a variety of browsers,

902
00:47:55,740 --> 00:47:58,830
particularly Chrome and
Chromium, which can generate

903
00:47:58,830 --> 00:48:01,230
and send reports about network issues

904
00:48:01,230 --> 00:48:02,883
as seen from the client side.

905
00:48:04,350 --> 00:48:06,150
As members of the network Edge, this data

906
00:48:06,150 --> 00:48:08,310
about the availability
off our Edge as seen

907
00:48:08,310 --> 00:48:11,700
by our clients, can be incredibly
valuable when diagnosing

908
00:48:11,700 --> 00:48:15,480
a variety of network issues,
including ones about issues

909
00:48:15,480 --> 00:48:17,730
that might never reach our infrastructure.

910
00:48:17,730 --> 00:48:19,830
So what did this implementation look like?

911
00:48:21,060 --> 00:48:23,910
Believe it or not, it
wasn't overly complex.

912
00:48:23,910 --> 00:48:26,250
By getting our reverse
proxies to add the report to

913
00:48:26,250 --> 00:48:29,070
and any NEL headers on
all client responses,

914
00:48:29,070 --> 00:48:32,640
we can tell supported browsers
where the report errors to.

915
00:48:32,640 --> 00:48:33,900
Leveraging CloudFront

916
00:48:33,900 --> 00:48:35,790
to access a globally accessible endpoint.

917
00:48:35,790 --> 00:48:38,340
We run a Lambda@Edge function to intercept

918
00:48:38,340 --> 00:48:39,600
and process all requests

919
00:48:39,600 --> 00:48:41,730
to be sent towards a Kinesis endpoint

920
00:48:41,730 --> 00:48:44,070
before further processing
by our observability

921
00:48:44,070 --> 00:48:46,530
and monitoring services.

922
00:48:46,530 --> 00:48:48,660
This architecture allows
us to leverage CloudFront

923
00:48:48,660 --> 00:48:51,360
and Lambda@Edge to serverless process

924
00:48:51,360 --> 00:48:54,003
these network error logs into Kinesis.

925
00:48:55,950 --> 00:48:58,200
And this enhanced visibility
has already proved useful

926
00:48:58,200 --> 00:49:00,933
when investigating low
grade and network failures.

927
00:49:01,770 --> 00:49:04,050
One example of this was when
we were investigating an

928
00:49:04,050 --> 00:49:07,410
intermittent TCP reset
issue impacting a percentage

929
00:49:07,410 --> 00:49:09,453
of customers across a random country.

930
00:49:10,650 --> 00:49:13,020
These errors were occurring
before requests even reached our

931
00:49:13,020 --> 00:49:14,223
CDN infrastructure.

932
00:49:15,090 --> 00:49:16,830
But thanks to our serverless
network error logging

933
00:49:16,830 --> 00:49:18,420
architecture, we were able

934
00:49:18,420 --> 00:49:20,760
to gain insights on failed
requests that were not

935
00:49:20,760 --> 00:49:24,660
yet visible from our
CloudFront metrics or logs.

936
00:49:24,660 --> 00:49:26,940
This information has helped
us accurately identify,

937
00:49:26,940 --> 00:49:31,860
start times, error rates,
affected clients geolocations

938
00:49:31,860 --> 00:49:33,873
and the exact TCP error itself.

939
00:49:34,800 --> 00:49:37,350
By collaboratively working
with Amazon, this allowed us

940
00:49:37,350 --> 00:49:40,110
to confidently and accurately
identify the root cause

941
00:49:40,110 --> 00:49:42,870
of this connection issue
pertaining to a network change

942
00:49:42,870 --> 00:49:44,420
outside our own infrastructure.

943
00:49:47,010 --> 00:49:50,370
Alright, we've talked about WAF, Shield

944
00:49:50,370 --> 00:49:51,390
and a few different ways we're

945
00:49:51,390 --> 00:49:53,280
using CloudFront distributions

946
00:49:53,280 --> 00:49:55,923
across a range of our
products and services.

947
00:49:56,820 --> 00:49:58,680
There's one last product
that the CloudFront team has

948
00:49:58,680 --> 00:50:01,350
shipped that I would like to
share how the team is looking

949
00:50:01,350 --> 00:50:03,960
to use, not just scale our services,

950
00:50:03,960 --> 00:50:07,413
but also scale the operational
effectiveness of our team.

951
00:50:08,730 --> 00:50:11,160
Everything I've discussed so far has been

952
00:50:11,160 --> 00:50:13,173
to do with standard distributions.

953
00:50:14,130 --> 00:50:15,870
These distributions are singular

954
00:50:15,870 --> 00:50:19,140
and contain all the settings
pertaining to origin, configs,

955
00:50:19,140 --> 00:50:21,663
cache behaviors and security settings.

956
00:50:22,620 --> 00:50:24,180
What that has meant for us is that

957
00:50:24,180 --> 00:50:26,700
by deploying these distributions
in front of variety

958
00:50:26,700 --> 00:50:30,300
of our products has been an
involved task between members

959
00:50:30,300 --> 00:50:33,930
of our Edge team and our service
owners, where we provision

960
00:50:33,930 --> 00:50:37,140
the distribution for them
and then begin this dance

961
00:50:37,140 --> 00:50:41,190
of collaborative effort to
transition traffic across, tune

962
00:50:41,190 --> 00:50:43,210
a variety of security rules and just

963
00:50:43,210 --> 00:50:45,453
in general smooth out the rough edges.

964
00:50:46,800 --> 00:50:48,960
With that in mind, Atlassian has thousands

965
00:50:48,960 --> 00:50:52,014
of ancillary services which
range from supporting features

966
00:50:52,014 --> 00:50:54,810
and functionality on our main product

967
00:50:54,810 --> 00:50:56,610
to the purposes of internal tooling.

968
00:50:58,320 --> 00:51:01,215
This approach of standard
distributions just did not scale

969
00:51:01,215 --> 00:51:02,400
with our DevOps model

970
00:51:02,400 --> 00:51:05,283
and philosophy of you
build it, you run it.

971
00:51:06,720 --> 00:51:07,971
On top of that, operating

972
00:51:07,971 --> 00:51:10,668
and managing thousands
of distributions at scale

973
00:51:10,668 --> 00:51:14,523
in a conjoined way just
created too much friction.

974
00:51:15,930 --> 00:51:18,990
We were hitting service
limits, account limits,

975
00:51:18,990 --> 00:51:21,150
and it was going to be
too operationally painful

976
00:51:21,150 --> 00:51:23,850
to issue out current level configuration

977
00:51:23,850 --> 00:51:26,610
for these shared distributions.

978
00:51:26,610 --> 00:51:29,460
We really just wanted a
way to have the flexibility

979
00:51:29,460 --> 00:51:32,520
of enforcing a strict base configuration

980
00:51:32,520 --> 00:51:37,110
that the Edge team could
manage, control and roll out.

981
00:51:37,110 --> 00:51:39,360
Whilst allowing our
service owners the ability

982
00:51:39,360 --> 00:51:42,600
to own and run their own
CloudFronts without needing

983
00:51:42,600 --> 00:51:44,193
to be CloudFront experts.

984
00:51:46,020 --> 00:51:48,600
This is exactly where
CloudFront SaaS Manager played

985
00:51:48,600 --> 00:51:51,250
a huge role in unblocking
this operational nightmare.

986
00:51:52,650 --> 00:51:54,480
CloudFront SaaS Manager
has a construct called

987
00:51:54,480 --> 00:51:56,820
multi-tenant distributions, which act

988
00:51:56,820 --> 00:51:59,700
as a parent template for
child distribution tenants

989
00:51:59,700 --> 00:52:00,533
to inherit.

990
00:52:01,710 --> 00:52:04,740
This effectively gave us a
really clean demarcation point

991
00:52:04,740 --> 00:52:08,310
for what and how our team
manages the global configuration

992
00:52:08,310 --> 00:52:10,997
that we expect all distribution
templates to adhere to.

993
00:52:10,997 --> 00:52:13,770
Whilst was giving our service
owners the flexibility

994
00:52:13,770 --> 00:52:15,930
and the ability to load perimeters

995
00:52:15,930 --> 00:52:17,730
into these defined templates

996
00:52:17,730 --> 00:52:20,760
to define customer origins, domains,

997
00:52:20,760 --> 00:52:22,508
and even apply customizations

998
00:52:22,508 --> 00:52:24,937
to their specific distribution WAF.

999
00:52:26,670 --> 00:52:28,863
So in practice, how did this look like?

1000
00:52:30,210 --> 00:52:32,523
We deployed numbers of
distribution tenants based

1001
00:52:32,523 --> 00:52:36,090
on use case to IMP to
help improve reliability

1002
00:52:36,090 --> 00:52:38,259
and reduce blast radius,
including the addition

1003
00:52:38,259 --> 00:52:41,613
of a canary style template
to soak initial changes on.

1004
00:52:42,720 --> 00:52:44,430
Next, we integrated a service broker

1005
00:52:44,430 --> 00:52:46,770
for our service owners to interact with.

1006
00:52:46,770 --> 00:52:50,190
Which provisions a distribution
tenant on behalf of them.

1007
00:52:50,190 --> 00:52:51,060
This additional broker

1008
00:52:51,060 --> 00:52:54,630
also helps us enforce final
base configuration elements,

1009
00:52:54,630 --> 00:52:56,850
which we want to restrict
our service owners

1010
00:52:56,850 --> 00:53:00,030
from having the flexibility to adjust such

1011
00:53:00,030 --> 00:53:01,020
as specific inclusions

1012
00:53:01,020 --> 00:53:03,453
of WAF rules we want permanently enforced.

1013
00:53:04,740 --> 00:53:06,510
As a result, this will pave the way

1014
00:53:06,510 --> 00:53:07,920
for our ancillary services

1015
00:53:07,920 --> 00:53:10,110
and their service owners
to onboard onto CloudFront

1016
00:53:10,110 --> 00:53:13,050
and WAF, being able to
do so in a self-service

1017
00:53:13,050 --> 00:53:15,120
and self-managed model.

1018
00:53:15,120 --> 00:53:17,730
Leading to increased speed
of CloudFront adoption

1019
00:53:17,730 --> 00:53:18,870
and allowing our developers

1020
00:53:18,870 --> 00:53:21,630
to focus on building more
features at the Edge,

1021
00:53:21,630 --> 00:53:25,113
possibly handholding of
individual CloudFront adoptions.

1022
00:53:27,330 --> 00:53:29,400
As I look to wrap up, I want to reiterate

1023
00:53:29,400 --> 00:53:31,233
on a couple of key takeaways.

1024
00:53:32,880 --> 00:53:34,821
First, look to leverage CloudFront's new

1025
00:53:34,821 --> 00:53:37,401
Anycast static IP feature in scenarios

1026
00:53:37,401 --> 00:53:40,773
where your customers have
specific firewall requirements.

1027
00:53:42,540 --> 00:53:44,975
In multi-origin and
region scenarios, think

1028
00:53:44,975 --> 00:53:48,540
of how you can leverage the new
origin control helper method

1029
00:53:48,540 --> 00:53:50,440
to steer traffic to different origins.

1030
00:53:51,420 --> 00:53:52,950
This can potentially help reduce

1031
00:53:52,950 --> 00:53:56,073
or even avoid cross-region
data transfer fees.

1032
00:53:58,110 --> 00:54:00,720
When you need a scalable
multi-domain solution whilst

1033
00:54:00,720 --> 00:54:03,810
keeping configuration and
infrastructure simple.

1034
00:54:03,810 --> 00:54:06,033
Consider the use of
CloudFront SaaS Manager.

1035
00:54:07,170 --> 00:54:09,690
And finally, Ben, a principal engineer

1036
00:54:09,690 --> 00:54:12,660
in our team has open sourced
the Python Lambda function,

1037
00:54:12,660 --> 00:54:15,637
which prepares CloudFront
logs sent to S3 for Kinesis.

1038
00:54:15,637 --> 00:54:17,520
This can help save a lot

1039
00:54:17,520 --> 00:54:19,503
of money versus realtime logs at scale.

1040
00:54:20,760 --> 00:54:22,980
Finally, I'd like to just say
thank you for taking the time

1041
00:54:22,980 --> 00:54:24,990
to listen to our story and our journey

1042
00:54:24,990 --> 00:54:28,140
and I hope you've all found
something useful to take away.

1043
00:54:28,140 --> 00:54:30,240
But for now, I'll pass it back to Etienne.

1044
00:54:35,910 --> 00:54:39,150
- Alright, thank you
everyone for having a listen.

1045
00:54:39,150 --> 00:54:42,000
We hope that you've
enjoyed today's session.

1046
00:54:42,000 --> 00:54:45,090
I just wanna highlight that
we have a number of sessions

1047
00:54:45,090 --> 00:54:48,000
that will dive a lot more deeply
into a number of the topics

1048
00:54:48,000 --> 00:54:49,410
that we've discussed today.

1049
00:54:49,410 --> 00:54:51,870
I'd encourage you to look them up.

1050
00:54:51,870 --> 00:54:53,640
This is worth taking a photograph of.

1051
00:54:53,640 --> 00:54:57,960
If it's too small, have a search
for any session that starts

1052
00:54:57,960 --> 00:55:01,200
with NET and that will
get you in the realm

1053
00:55:01,200 --> 00:55:02,493
of these sessions.

1054
00:55:04,080 --> 00:55:07,140
Lastly, I'd encourage you to go build.

1055
00:55:07,140 --> 00:55:11,280
It's never been a a better time
to go build with CloudFront

1056
00:55:11,280 --> 00:55:14,707
and especially when you start
layering in Shield and WAF.

1057
00:55:16,080 --> 00:55:17,880
Thank you again for your time today

1058
00:55:17,880 --> 00:55:21,510
and please provide some feedback for us.

1059
00:55:21,510 --> 00:55:23,014
Thank you.
- Thank you.

1060
00:55:23,014 --> 00:55:24,889
(audience clapping)

