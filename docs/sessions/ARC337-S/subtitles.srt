1
00:00:00,000 --> 00:00:01,800
- Sorry, I didn't realize we're live.

2
00:00:01,800 --> 00:00:05,640
Hi everyone, thank you very
much for joining us today

3
00:00:05,640 --> 00:00:08,730
for our session on maxing
AI governance and speed

4
00:00:08,730 --> 00:00:12,090
only with ServiceNow and AWS.

5
00:00:12,090 --> 00:00:13,800
My name is Amanda Grady

6
00:00:13,800 --> 00:00:17,427
and I lead AI platform
security at ServiceNow.

7
00:00:17,427 --> 00:00:20,790
And I'm joined here today by Sampada.

8
00:00:20,790 --> 00:00:23,190
- Hey everyone, nice to be here.

9
00:00:23,190 --> 00:00:24,570
My name is Sampada Chavan

10
00:00:24,570 --> 00:00:26,840
and I'm part of the AI
platform product team

11
00:00:26,840 --> 00:00:29,613
and the lead product manager
for AI Control Tower.

12
00:00:30,960 --> 00:00:32,550
And Ofer.

13
00:00:32,550 --> 00:00:34,620
- Hello everybody, my
name is Ofer Vaisler.

14
00:00:34,620 --> 00:00:36,990
I'm part of the platform
product management team

15
00:00:36,990 --> 00:00:38,673
and I lead the AI Control Tower.

16
00:00:39,900 --> 00:00:41,460
So welcome to the session.

17
00:00:41,460 --> 00:00:43,350
We're excited to have you.

18
00:00:43,350 --> 00:00:46,890
Before we start, just have to
show this safe harbor slide.

19
00:00:46,890 --> 00:00:48,540
You all know the drill.

20
00:00:48,540 --> 00:00:52,560
Don't make purchasing decisions
based on future statements

21
00:00:52,560 --> 00:00:57,150
and with that, let's start our session.

22
00:00:57,150 --> 00:00:59,850
So we've prepared a great
presentation for you

23
00:00:59,850 --> 00:01:03,740
about governance of AI
and about securing AI.

24
00:01:03,740 --> 00:01:05,670
But before we jump into that,

25
00:01:05,670 --> 00:01:07,640
I wanna talk about the ServiceNow platform

26
00:01:07,640 --> 00:01:09,240
just a little bit.

27
00:01:09,240 --> 00:01:11,000
So we built the ServiceNow platform

28
00:01:11,000 --> 00:01:13,440
in order to automate work for people.

29
00:01:13,440 --> 00:01:14,640
You all know that.

30
00:01:14,640 --> 00:01:17,820
And we've been doing that
now for over 20 years.

31
00:01:17,820 --> 00:01:21,810
So in fact, today our platform
powers billions and billions

32
00:01:21,810 --> 00:01:23,280
of automations every month.

33
00:01:23,280 --> 00:01:26,970
Flows, playbooks for many,
many thousands of customers

34
00:01:26,970 --> 00:01:28,500
across all industries.

35
00:01:28,500 --> 00:01:31,170
So automation is not really new to us.

36
00:01:31,170 --> 00:01:32,940
In fact, it's part of who we are.

37
00:01:32,940 --> 00:01:34,263
It's part of our identity.

38
00:01:35,220 --> 00:01:38,190
Now we all know that the
landscape is changing

39
00:01:38,190 --> 00:01:41,340
and AI is taking the world by storm.

40
00:01:41,340 --> 00:01:42,780
And we think that this change

41
00:01:42,780 --> 00:01:45,210
is going to be pretty significant.

42
00:01:45,210 --> 00:01:48,060
I'm sure some of you, if
you're at least as old as me,

43
00:01:48,060 --> 00:01:51,630
then you remember when
virtualization came out.

44
00:01:51,630 --> 00:01:53,040
Everybody thought in the beginning

45
00:01:53,040 --> 00:01:55,800
that this is about saving server costs.

46
00:01:55,800 --> 00:01:57,840
Well, fast forward for today,

47
00:01:57,840 --> 00:02:00,570
it turns out that it fueled
the entire revolution

48
00:02:00,570 --> 00:02:03,450
into cloud computing,
enabling new products,

49
00:02:03,450 --> 00:02:06,240
new services, new business models.

50
00:02:06,240 --> 00:02:08,850
And we think that AI is
gonna be at least as big,

51
00:02:08,850 --> 00:02:10,650
if not bigger than that.

52
00:02:10,650 --> 00:02:13,380
And that's why we've built AI natively

53
00:02:13,380 --> 00:02:15,120
into the ServiceNow platform,

54
00:02:15,120 --> 00:02:17,730
making sure that it
continues to be the platform

55
00:02:17,730 --> 00:02:20,733
for business transformation
into the AI era.

56
00:02:22,960 --> 00:02:27,720
Now we think that the AI
revolution is gonna be so big

57
00:02:27,720 --> 00:02:29,670
that over the next few years,

58
00:02:29,670 --> 00:02:31,860
every workflow for every industry

59
00:02:31,860 --> 00:02:35,790
is going to be reimagined with AI.

60
00:02:35,790 --> 00:02:38,310
That's a pretty bold statement.

61
00:02:38,310 --> 00:02:42,270
But we know that AI is
not a one-size-fits-all.

62
00:02:42,270 --> 00:02:46,230
We know that in order to
build amazing AI experiences,

63
00:02:46,230 --> 00:02:48,630
you have to pick the right model.

64
00:02:48,630 --> 00:02:51,300
You have to pick the right data.

65
00:02:51,300 --> 00:02:53,600
You have to pick the right infrastructure

66
00:02:53,600 --> 00:02:55,113
that it will run on.

67
00:02:56,700 --> 00:03:00,840
So we know that that's exactly why

68
00:03:00,840 --> 00:03:03,450
we built the ServiceNow
platform in a flexible way

69
00:03:03,450 --> 00:03:05,500
that allows you to do exactly that.

70
00:03:05,500 --> 00:03:08,400
You pick the use case, and based on that,

71
00:03:08,400 --> 00:03:10,620
you pick the right model for the use case.

72
00:03:10,620 --> 00:03:13,050
You pick the right data for the use case.

73
00:03:13,050 --> 00:03:14,340
And you pick the right cloud

74
00:03:14,340 --> 00:03:16,590
that you want this use case to run on

75
00:03:16,590 --> 00:03:19,443
so it runs most efficiently at scale.

76
00:03:21,780 --> 00:03:24,180
So we all know how powerful AI

77
00:03:24,180 --> 00:03:27,780
and how big is the potential, right?

78
00:03:27,780 --> 00:03:31,830
It can help unlock so many
amazing business outcomes.

79
00:03:31,830 --> 00:03:33,660
It can increase productivity.

80
00:03:33,660 --> 00:03:35,730
It can accelerate time to market.

81
00:03:35,730 --> 00:03:37,920
It can reduce costs.

82
00:03:37,920 --> 00:03:39,630
But even more than that,

83
00:03:39,630 --> 00:03:42,750
it's actually becoming
table stakes, right?

84
00:03:42,750 --> 00:03:44,580
If you're not implementing AI,

85
00:03:44,580 --> 00:03:45,780
then you're gonna stay behind.

86
00:03:45,780 --> 00:03:49,110
You're not gonna be able to
stay ahead of your competition.

87
00:03:49,110 --> 00:03:51,240
And that's why it's not surprising

88
00:03:51,240 --> 00:03:52,920
that we're seeing many of our customers

89
00:03:52,920 --> 00:03:55,840
now looking to move from
experimenting with AI

90
00:03:55,840 --> 00:03:59,193
to operationalizing AI at scale.

91
00:04:03,180 --> 00:04:08,180
But the potential is huge,
but with this potential,

92
00:04:08,700 --> 00:04:11,433
there are also increasing risks, right?

93
00:04:12,300 --> 00:04:15,540
If you played with AI and
you experimented with AI,

94
00:04:15,540 --> 00:04:19,680
you know that having a
successful POC is one thing,

95
00:04:19,680 --> 00:04:23,500
and scaling AI and getting
enterprise value out of it

96
00:04:23,500 --> 00:04:25,083
is a different thing.

97
00:04:26,250 --> 00:04:30,390
So AI obviously comes with
huge set of challenges.

98
00:04:30,390 --> 00:04:33,690
It's an undeterministic
technology by nature, right?

99
00:04:33,690 --> 00:04:36,750
So you cannot overlook things like bias,

100
00:04:36,750 --> 00:04:40,113
hallucinations, or lack of transparency.

101
00:04:41,400 --> 00:04:43,230
Also, there are increasing concerns

102
00:04:43,230 --> 00:04:48,210
about risks and security
issues and data privacy,

103
00:04:48,210 --> 00:04:51,240
especially as this technology
becomes more capable

104
00:04:51,240 --> 00:04:54,810
and even more so, more autonomous.

105
00:04:54,810 --> 00:04:58,710
So scaling AI is not just
a technology challenge,

106
00:04:58,710 --> 00:05:02,673
but it's actually at least as
big as a governance challenge.

107
00:05:05,190 --> 00:05:08,430
Now, as you start looking
into organizations

108
00:05:08,430 --> 00:05:10,440
and how they're implementing AI

109
00:05:10,440 --> 00:05:13,170
and who's involved in this process,

110
00:05:13,170 --> 00:05:14,800
you tend to see two forces.

111
00:05:14,800 --> 00:05:18,540
On the one hand, you have product owners

112
00:05:18,540 --> 00:05:22,110
and business users who
want to prove value fast

113
00:05:22,110 --> 00:05:24,660
and move as quickly as possible.

114
00:05:24,660 --> 00:05:28,140
On the other hand, you have
risk teams and security teams

115
00:05:28,140 --> 00:05:30,870
and compliance teams and legal teams.

116
00:05:30,870 --> 00:05:32,760
They also want to move fast,

117
00:05:32,760 --> 00:05:34,770
but they're thinking all the time

118
00:05:34,770 --> 00:05:37,350
about all the new threats that are coming

119
00:05:37,350 --> 00:05:41,460
if AI is gonna be used without
the appropriate guardrails.

120
00:05:41,460 --> 00:05:43,710
So many companies are stuck

121
00:05:43,710 --> 00:05:46,560
in this kind of phase of analysis

122
00:05:46,560 --> 00:05:48,000
when they're looking to transition

123
00:05:48,000 --> 00:05:51,930
between proof of concept to scaling AI.

124
00:05:51,930 --> 00:05:56,100
And most of them do not have
the right governance process

125
00:05:56,100 --> 00:06:00,573
and tools in place to enable
that scale with trust.

126
00:06:03,810 --> 00:06:06,780
So in response, we are
seeing many organizations

127
00:06:06,780 --> 00:06:11,160
that have either created or
are in the process of creating

128
00:06:11,160 --> 00:06:13,560
AI centers of excellence.

129
00:06:13,560 --> 00:06:16,050
Those centers of
excellence are responsible

130
00:06:16,050 --> 00:06:19,320
for holistically managing and coordinating

131
00:06:19,320 --> 00:06:22,170
and governing the implementation of AI

132
00:06:22,170 --> 00:06:24,240
across the enterprise.

133
00:06:24,240 --> 00:06:26,340
But just creating those organizations

134
00:06:26,340 --> 00:06:28,350
is not gonna be enough.

135
00:06:28,350 --> 00:06:31,120
What you really need is
a seamless collaboration

136
00:06:31,120 --> 00:06:33,810
between all the stakeholders
that are involved

137
00:06:33,810 --> 00:06:37,560
in the process of
building AI, deploying AI,

138
00:06:37,560 --> 00:06:40,950
and addressing issues like risks

139
00:06:40,950 --> 00:06:44,580
and compliance issues when they arise.

140
00:06:44,580 --> 00:06:49,580
What's needed is a true way
to break down all the silos

141
00:06:50,940 --> 00:06:54,060
and have everybody on one platform.

142
00:06:54,060 --> 00:06:56,400
Everybody need to speak the same language,

143
00:06:56,400 --> 00:06:58,470
everybody need to see the same data,

144
00:06:58,470 --> 00:07:00,360
everybody need to get the same context

145
00:07:00,360 --> 00:07:02,220
from a technology perspective

146
00:07:02,220 --> 00:07:03,960
and from a business perspective

147
00:07:03,960 --> 00:07:07,740
in order to understand
how those AI initiatives

148
00:07:07,740 --> 00:07:09,723
are going to impact the business.

149
00:07:12,300 --> 00:07:16,140
And that's exactly why we
built the AI Control Tower.

150
00:07:16,140 --> 00:07:18,720
The AI Control Tower
provides an integrated

151
00:07:18,720 --> 00:07:22,260
and holistic approach to
manage your AI at scale.

152
00:07:22,260 --> 00:07:23,660
So you don't need to trade off

153
00:07:23,660 --> 00:07:27,750
between moving fast and moving safe.

154
00:07:27,750 --> 00:07:30,330
You can now do both.

155
00:07:30,330 --> 00:07:33,880
So it streamlines all the life cycle of AI

156
00:07:33,880 --> 00:07:37,650
from onboarding to change to offboarding,

157
00:07:37,650 --> 00:07:42,060
and it connects all the dots
between your AI strategy,

158
00:07:42,060 --> 00:07:46,290
your AI execution, your AI governance,

159
00:07:46,290 --> 00:07:49,113
and the value that you're
generating from AI.

160
00:07:50,100 --> 00:07:54,900
So all of that is built
also on top of our CMDB,

161
00:07:54,900 --> 00:07:58,230
and that is a super important fact.

162
00:07:58,230 --> 00:08:01,080
And let me now just touch
on each one of those pillars

163
00:08:01,080 --> 00:08:04,650
so that you can understand a
little bit more the details,

164
00:08:04,650 --> 00:08:07,260
and then we will go into a live demo

165
00:08:07,260 --> 00:08:10,233
that will show you how it
all works in real life.

166
00:08:11,920 --> 00:08:15,270
So let's start with the
underlying data model.

167
00:08:15,270 --> 00:08:16,103
Here's the thing,

168
00:08:16,103 --> 00:08:20,130
AI assets are just like
any technology assets.

169
00:08:20,130 --> 00:08:23,460
They need to be discovered,
they need to be tracked,

170
00:08:23,460 --> 00:08:27,780
they need to be governed,
just like any other server

171
00:08:27,780 --> 00:08:30,560
or business application or network device

172
00:08:30,560 --> 00:08:32,313
that you're already managing.

173
00:08:33,150 --> 00:08:36,540
And that's why we built
ServiceNow Control Tower

174
00:08:36,540 --> 00:08:38,190
on top of CMDB.

175
00:08:38,190 --> 00:08:41,580
So the AI Control Tower
discovers all your AI footprint,

176
00:08:41,580 --> 00:08:44,490
and not just agents, but also the models

177
00:08:44,490 --> 00:08:46,710
that those agents are running on,

178
00:08:46,710 --> 00:08:51,600
the data sets that those
agents are trained on,

179
00:08:51,600 --> 00:08:56,220
the prompts that help define
those agents and what they do,

180
00:08:56,220 --> 00:08:59,670
and this is how the AI Control Tower

181
00:08:59,670 --> 00:09:02,160
provides a single system of record

182
00:09:02,160 --> 00:09:05,970
for all your AI footprint on one platform.

183
00:09:05,970 --> 00:09:08,550
And because it's integrated with CMDB,

184
00:09:08,550 --> 00:09:12,560
it is also out-of-the-box coordinated

185
00:09:12,560 --> 00:09:17,250
and tightly aligned with
your technology architecture,

186
00:09:17,250 --> 00:09:21,273
your network architecture,
and your workflows.

187
00:09:24,780 --> 00:09:26,640
Now, when you think about AI,

188
00:09:26,640 --> 00:09:29,700
you always want to start
with your strategy.

189
00:09:29,700 --> 00:09:32,780
You want to make sure
that all your AI efforts

190
00:09:32,780 --> 00:09:36,270
are tightly aligned to
your business objective.

191
00:09:36,270 --> 00:09:39,990
And that's why we integrated AICT

192
00:09:39,990 --> 00:09:42,760
with our strategic portfolio
management solution

193
00:09:42,760 --> 00:09:46,920
to give you exactly that visibility

194
00:09:46,920 --> 00:09:49,170
and connection to your strategy.

195
00:09:49,170 --> 00:09:51,690
So what you can do with AI Control Tower

196
00:09:51,690 --> 00:09:55,680
is you can connect all
your business priorities

197
00:09:55,680 --> 00:09:58,440
and business goals into
your AI initiatives

198
00:09:58,440 --> 00:10:01,320
to make sure that your AI efforts

199
00:10:01,320 --> 00:10:03,423
and your strategy are tightly aligned.

200
00:10:07,260 --> 00:10:09,540
Now, with AI moving so fast,

201
00:10:09,540 --> 00:10:13,020
it's critical that
execution will be flawless.

202
00:10:13,020 --> 00:10:15,600
So with the AI Control Tower,

203
00:10:15,600 --> 00:10:19,700
we've also packaged out-of-the-box
workflows and playbooks

204
00:10:19,700 --> 00:10:24,700
that allows you to run all
the AI lifecycle seamlessly,

205
00:10:25,380 --> 00:10:28,200
ensuring that nothing
falls between the cracks.

206
00:10:28,200 --> 00:10:32,430
So for example, if a team
wants to onboard a new model,

207
00:10:32,430 --> 00:10:37,430
that kicks off a new workflow
that goes to security teams,

208
00:10:37,530 --> 00:10:40,980
to risk teams, to legal teams for review

209
00:10:40,980 --> 00:10:43,770
to ensure that this model is not onboarded

210
00:10:43,770 --> 00:10:45,640
and become operationalized

211
00:10:45,640 --> 00:10:49,413
without the appropriate
reviews and sign-off.

212
00:10:52,200 --> 00:10:54,960
Same for, let's say
you wanna make a change

213
00:10:54,960 --> 00:10:57,870
to a model that is powering an agent,

214
00:10:57,870 --> 00:11:01,770
or at some point you would also
want to retire some assets.

215
00:11:01,770 --> 00:11:04,440
All of those playbooks
are packaged together

216
00:11:04,440 --> 00:11:05,760
with the AI Control Tower,

217
00:11:05,760 --> 00:11:09,330
ensuring that your execution is smooth

218
00:11:09,330 --> 00:11:11,163
and everybody are on the same page.

219
00:11:14,190 --> 00:11:17,130
Now also, when you
deploy a new application,

220
00:11:17,130 --> 00:11:19,320
a new agent, a new model,

221
00:11:19,320 --> 00:11:22,500
you wanna make sure you have
the right controls in place,

222
00:11:22,500 --> 00:11:24,360
you wanna make sure that you stay

223
00:11:24,360 --> 00:11:26,610
in compliance of regulations,

224
00:11:26,610 --> 00:11:29,730
you wanna make sure that
you have auditability

225
00:11:29,730 --> 00:11:32,160
and access to audit trails.

226
00:11:32,160 --> 00:11:37,050
So AICT is integrated with our
market-leading IRM solution,

227
00:11:37,050 --> 00:11:41,010
which allows you to
track your risk exposure.

228
00:11:41,010 --> 00:11:45,090
It also comes with out-of-the-box
regulatory frameworks

229
00:11:45,090 --> 00:11:49,410
like AI EU Act, so it maps your risks

230
00:11:49,410 --> 00:11:53,820
into the right compliance framework

231
00:11:53,820 --> 00:11:55,800
and regulation and it ensures

232
00:11:55,800 --> 00:11:58,593
that your exposure is minimized.

233
00:12:01,670 --> 00:12:03,990
Now at the end of the day,

234
00:12:03,990 --> 00:12:06,840
the last pillar of the AI
Control Tower is value.

235
00:12:06,840 --> 00:12:10,260
Everybody want to understand
what is the bottom line,

236
00:12:10,260 --> 00:12:14,520
what return am I getting
on all those investments?

237
00:12:14,520 --> 00:12:16,740
So with AI Control Tower,

238
00:12:16,740 --> 00:12:19,890
you can see all kind of
value operational metrics

239
00:12:19,890 --> 00:12:24,540
like productivity gains or ROI.

240
00:12:24,540 --> 00:12:28,410
And because we know that
value is defined differently

241
00:12:28,410 --> 00:12:30,030
for different use cases,

242
00:12:30,030 --> 00:12:32,770
then we built a very
flexible value framework

243
00:12:34,140 --> 00:12:37,950
that allows you to create
custom value templates

244
00:12:37,950 --> 00:12:40,510
and associate them to the use cases

245
00:12:40,510 --> 00:12:43,743
and measure value the way
you want to measure it.

246
00:12:46,470 --> 00:12:51,240
So the result is AICT helps you unlock

247
00:12:51,240 --> 00:12:53,910
all this potential of AI at scale,

248
00:12:53,910 --> 00:12:57,870
move from proof of concept
to successful implementations

249
00:12:57,870 --> 00:13:01,290
that actually produce real value at scale,

250
00:13:01,290 --> 00:13:04,710
but better aligning with
your business goals,

251
00:13:04,710 --> 00:13:09,060
streamlining your project
delivery, maintaining compliance,

252
00:13:09,060 --> 00:13:12,120
and seeing the value
that you're generating.

253
00:13:12,120 --> 00:13:14,460
And with that, I wanna hand it to Sampada

254
00:13:14,460 --> 00:13:17,430
to show us a real live
demo of the product.

255
00:13:17,430 --> 00:13:19,980
You can see how it all comes together.

256
00:13:19,980 --> 00:13:21,750
- Thank you, Ofer.

257
00:13:21,750 --> 00:13:25,170
All right, so let me
switch over to the view

258
00:13:25,170 --> 00:13:27,570
that the AICOE sees.

259
00:13:27,570 --> 00:13:31,590
So with AI Control Tower, we
talked about how the AICOE,

260
00:13:31,590 --> 00:13:34,020
the governance team actually
helps connect the dot

261
00:13:34,020 --> 00:13:36,570
across multiple cross-functional teams.

262
00:13:36,570 --> 00:13:39,510
And what this AICOE gets to view

263
00:13:39,510 --> 00:13:42,480
is the state of the AI in the enterprise.

264
00:13:42,480 --> 00:13:45,960
So they have a view of all
of the different AI systems

265
00:13:45,960 --> 00:13:47,430
which are available.

266
00:13:47,430 --> 00:13:49,560
Where are they in their life cycle?

267
00:13:49,560 --> 00:13:51,300
What types of AI do you have?

268
00:13:51,300 --> 00:13:53,070
So within the AI inventory,

269
00:13:53,070 --> 00:13:56,820
we can track AI agents,
your generative use cases,

270
00:13:56,820 --> 00:13:59,100
even the classical AIML use cases

271
00:13:59,100 --> 00:14:01,770
where you were fine-tuning models for,

272
00:14:01,770 --> 00:14:05,160
let's say, prediction or
classification type of use cases.

273
00:14:05,160 --> 00:14:07,320
The data model handles that.

274
00:14:07,320 --> 00:14:09,360
You also have a view into

275
00:14:09,360 --> 00:14:11,520
what is the overall risk classification

276
00:14:11,520 --> 00:14:13,470
for those AI systems.

277
00:14:13,470 --> 00:14:14,970
Where are you sourcing them from?

278
00:14:14,970 --> 00:14:17,790
So it could be ServiceNow AI,

279
00:14:17,790 --> 00:14:20,490
AI that is on your AWS instances.

280
00:14:20,490 --> 00:14:22,020
It could be AI that is embedded

281
00:14:22,020 --> 00:14:25,830
in other software applications,
bringing those all in.

282
00:14:25,830 --> 00:14:28,230
And then looking at
overall where do you stand

283
00:14:28,230 --> 00:14:30,060
in terms of the compliance,

284
00:14:30,060 --> 00:14:32,670
in terms of your standards, regulations,

285
00:14:32,670 --> 00:14:35,910
or even your own internal
governance policies.

286
00:14:35,910 --> 00:14:37,620
You can also track the productivity.

287
00:14:37,620 --> 00:14:38,910
Value is very important.

288
00:14:38,910 --> 00:14:42,030
You would want to understand
how AI is being used,

289
00:14:42,030 --> 00:14:43,530
what value it is deriving,

290
00:14:43,530 --> 00:14:46,280
and you would have the ability
to measure that as well.

291
00:14:47,340 --> 00:14:50,610
So once you have this overview
of AI in the enterprise,

292
00:14:50,610 --> 00:14:52,440
you can then start digging deeper

293
00:14:52,440 --> 00:14:55,200
into each of the aspects of it.

294
00:14:55,200 --> 00:14:58,830
When I look at AI strategy,
I am able to look at

295
00:14:58,830 --> 00:15:01,200
what are my overall strategic priorities,

296
00:15:01,200 --> 00:15:03,660
what are the targets that
are associated with it,

297
00:15:03,660 --> 00:15:06,360
and how am I tracking towards those,

298
00:15:06,360 --> 00:15:08,280
those particular goals as well.

299
00:15:08,280 --> 00:15:11,150
I could potentially also
look at planned costs

300
00:15:11,150 --> 00:15:14,670
if I have access to it,
and prioritize my AI work.

301
00:15:14,670 --> 00:15:16,230
So again, ensuring that the AI

302
00:15:16,230 --> 00:15:17,790
that is getting built and deployed

303
00:15:17,790 --> 00:15:20,400
aligns with your overall AI strategy

304
00:15:20,400 --> 00:15:23,373
that you want to implement
in your organization.

305
00:15:24,870 --> 00:15:26,850
In AI asset inventory,

306
00:15:26,850 --> 00:15:28,530
you are going to get a little bit deeper

307
00:15:28,530 --> 00:15:31,020
into what type of AI
artifacts are available.

308
00:15:31,020 --> 00:15:34,140
So you have your AI
systems, the AI models,

309
00:15:34,140 --> 00:15:36,000
prompt templates, even data sets

310
00:15:36,000 --> 00:15:38,760
that you could be using for evaluations.

311
00:15:38,760 --> 00:15:40,980
If you're fine-tuning and
training your own models,

312
00:15:40,980 --> 00:15:43,860
you could capture those data
set information as well.

313
00:15:43,860 --> 00:15:45,180
And then additional information

314
00:15:45,180 --> 00:15:47,613
on how those assets are
spread across the board.

315
00:15:49,500 --> 00:15:51,000
Next up with value,

316
00:15:51,000 --> 00:15:52,830
this is where you are
going to start looking at

317
00:15:52,830 --> 00:15:54,840
what is the overall value

318
00:15:54,840 --> 00:15:57,240
that AI in the organization is driving,

319
00:15:57,240 --> 00:16:00,600
where does usage look like,
and potentially a scoreboard

320
00:16:00,600 --> 00:16:02,070
of what are your most used systems,

321
00:16:02,070 --> 00:16:04,110
what are the most valuable systems.

322
00:16:04,110 --> 00:16:06,903
You get a view and an
insight into that as well.

323
00:16:09,480 --> 00:16:11,520
Next up with risk and compliance,

324
00:16:11,520 --> 00:16:14,010
this is going the next level of detail

325
00:16:14,010 --> 00:16:19,010
into risk status and classification
of individual assets.

326
00:16:19,860 --> 00:16:23,670
So be it AI systems,
different models, data sets,

327
00:16:23,670 --> 00:16:26,670
it all comes together
along with the compliance

328
00:16:26,670 --> 00:16:30,900
of where we are in terms
of the particular standards

329
00:16:30,900 --> 00:16:32,820
or regulations that you're looking at,

330
00:16:32,820 --> 00:16:35,190
as well as your own internal policies.

331
00:16:35,190 --> 00:16:36,690
Now how does all of this
information come together?

332
00:16:36,690 --> 00:16:39,660
So it starts off with ways

333
00:16:39,660 --> 00:16:42,000
of getting the data into the inventory.

334
00:16:42,000 --> 00:16:44,010
You could have a standard intake process

335
00:16:44,010 --> 00:16:45,937
where as a user I can go in and say that,

336
00:16:45,937 --> 00:16:47,490
"Hey, I want to build this use case out,"

337
00:16:47,490 --> 00:16:50,700
or, "I want to use this
model in my system."

338
00:16:50,700 --> 00:16:52,500
Another way to look at it is also

339
00:16:52,500 --> 00:16:55,050
where we provide discovery capabilities.

340
00:16:55,050 --> 00:16:57,630
So by directly connecting to AWS Bedrock,

341
00:16:57,630 --> 00:16:59,210
we are able to bring in agents

342
00:16:59,210 --> 00:17:01,250
and their associated information

343
00:17:01,250 --> 00:17:03,153
into this inventory as well.

344
00:17:04,080 --> 00:17:06,840
Now let's talk about an
example of such an agent.

345
00:17:06,840 --> 00:17:07,980
I'm gonna pull that up.

346
00:17:07,980 --> 00:17:11,100
Here we talk about this
autonomous recruiting agent

347
00:17:11,100 --> 00:17:15,300
which is being used or built
and deployed on AWS Bedrock.

348
00:17:15,300 --> 00:17:16,740
We are able to bring the information

349
00:17:16,740 --> 00:17:20,160
or the metadata about that
agent, but it's not just that.

350
00:17:20,160 --> 00:17:22,320
Along with it, we are
also able to bring in

351
00:17:22,320 --> 00:17:24,900
what are the related
assets or artifacts to it,

352
00:17:24,900 --> 00:17:27,210
because that is what is going
to give you the full picture

353
00:17:27,210 --> 00:17:29,730
of how an agent is going to be designed

354
00:17:29,730 --> 00:17:32,400
and then deployed and
then used in the system

355
00:17:32,400 --> 00:17:33,840
or in your enterprise.

356
00:17:33,840 --> 00:17:36,960
So you have a view into what
are the different other agents

357
00:17:36,960 --> 00:17:39,960
that this particular
agent would be calling,

358
00:17:39,960 --> 00:17:43,230
what are the tools this
particular agent has access to,

359
00:17:43,230 --> 00:17:45,930
what are the models that this
particular agent is using,

360
00:17:45,930 --> 00:17:47,640
and so on and so forth.

361
00:17:47,640 --> 00:17:49,770
And then once you have
all of this information,

362
00:17:49,770 --> 00:17:52,770
you will want to ensure that
you are onboarding this agent

363
00:17:52,770 --> 00:17:54,390
into your enterprise.

364
00:17:54,390 --> 00:17:57,240
So that's where playbooks
come into play, into picture,

365
00:17:57,240 --> 00:18:01,050
wherein as a playbook, I
can set up different tasks

366
00:18:01,050 --> 00:18:03,870
of bringing those
cross-functional teams together

367
00:18:03,870 --> 00:18:05,470
to run either an impact assessment

368
00:18:05,470 --> 00:18:08,820
to understand how is this
agent going to be used?

369
00:18:08,820 --> 00:18:10,770
How does it handle fairness and bias?

370
00:18:10,770 --> 00:18:14,700
Is there going to be a
human oversight present?

371
00:18:14,700 --> 00:18:17,410
And based on that, you can also look at,

372
00:18:17,410 --> 00:18:19,050
does legal need to wane?

373
00:18:19,050 --> 00:18:21,600
Is there data security
and privacy concerns

374
00:18:21,600 --> 00:18:23,070
that we need to look at?

375
00:18:23,070 --> 00:18:25,320
Kind of bringing all of
that information together

376
00:18:25,320 --> 00:18:28,740
will then help you understand
what is the risk associated

377
00:18:28,740 --> 00:18:29,750
with that particular asset.

378
00:18:29,750 --> 00:18:31,650
So once you run through that,

379
00:18:31,650 --> 00:18:33,330
you run through those
different assessments,

380
00:18:33,330 --> 00:18:36,510
you can then identify what
are the risks associated

381
00:18:36,510 --> 00:18:39,630
with this particular agent
to mitigate those risks,

382
00:18:39,630 --> 00:18:42,330
what type of controls do I need to handle?

383
00:18:42,330 --> 00:18:45,370
And then as you move this
agent through its lifecycle

384
00:18:45,370 --> 00:18:48,690
of assessing, approving
it to be built and tested,

385
00:18:48,690 --> 00:18:51,510
you can then start looking at validating

386
00:18:51,510 --> 00:18:52,950
whether those controls are present,

387
00:18:52,950 --> 00:18:55,620
do you have the right set
of guardrails available?

388
00:18:55,620 --> 00:18:57,270
And also at point in time,

389
00:18:57,270 --> 00:19:00,360
look at how do you measure value of that?

390
00:19:00,360 --> 00:19:03,600
And those are all tasks
that would be associated

391
00:19:03,600 --> 00:19:06,510
or provided to the specific users,

392
00:19:06,510 --> 00:19:08,103
bringing those teams together.

393
00:19:09,060 --> 00:19:10,930
An example of how do you measure value

394
00:19:10,930 --> 00:19:13,770
is going to be looking at
a formula that we look at,

395
00:19:13,770 --> 00:19:16,050
like once this agent is deployed,

396
00:19:16,050 --> 00:19:18,780
we would want to then
look at how many times

397
00:19:18,780 --> 00:19:20,040
is this agent going to be used?

398
00:19:20,040 --> 00:19:21,720
And this is where the data will come in

399
00:19:21,720 --> 00:19:24,900
from those CloudWatch integrations
that I just showed you.

400
00:19:24,900 --> 00:19:26,970
So we look at how many
times this particular agent

401
00:19:26,970 --> 00:19:29,490
is going to run, and
then making an assumption

402
00:19:29,490 --> 00:19:33,030
in this particular case that
every time this agent runs,

403
00:19:33,030 --> 00:19:36,300
we are saving about 10
minutes of an end user time,

404
00:19:36,300 --> 00:19:38,520
so that becomes our productivity metric.

405
00:19:38,520 --> 00:19:41,670
And assuming an accuracy of 85%

406
00:19:41,670 --> 00:19:45,240
is also the way we would capture
the value for this agent.

407
00:19:45,240 --> 00:19:47,790
Now this is constants,
but you could completely

408
00:19:47,790 --> 00:19:50,490
bring in additional data
streams into the platform

409
00:19:50,490 --> 00:19:55,490
to have indicators available
to run this particular formula.

410
00:19:55,830 --> 00:19:58,710
So now imagine this is
everything that we are doing

411
00:19:58,710 --> 00:20:00,210
for one single agent.

412
00:20:00,210 --> 00:20:04,080
When we start doing this over
multiple different AI systems,

413
00:20:04,080 --> 00:20:06,570
the models, that is
where we start bringing

414
00:20:06,570 --> 00:20:10,350
all of that together into
this AI control tower view

415
00:20:10,350 --> 00:20:12,390
that we first started off with.

416
00:20:12,390 --> 00:20:15,120
So I focused a little
bit on the inventory,

417
00:20:15,120 --> 00:20:19,980
the risk and compliance, and
the lifecycle of that asset.

418
00:20:19,980 --> 00:20:21,690
Amanda is now going to talk about

419
00:20:21,690 --> 00:20:24,190
the data security and privacy aspects.

420
00:20:24,190 --> 00:20:26,103
- Great, thank you Sampada.

421
00:20:27,900 --> 00:20:31,530
So Sampada just gave us a fantastic demo

422
00:20:31,530 --> 00:20:34,050
of AI control tower, and also talked about

423
00:20:34,050 --> 00:20:38,910
how that helps you
manage your AI lifecycle,

424
00:20:38,910 --> 00:20:43,050
govern your AI, and manage the strategy

425
00:20:43,050 --> 00:20:45,330
and understand the value of your AI.

426
00:20:45,330 --> 00:20:46,890
I'm going to talk about another aspect,

427
00:20:46,890 --> 00:20:49,800
which is the security of your AI.

428
00:20:49,800 --> 00:20:54,720
And we're really in a completely
new era of cyber security.

429
00:20:54,720 --> 00:20:56,700
I've been in cyber security over 20 years,

430
00:20:56,700 --> 00:21:00,450
and this year, the pace
of change has just been,

431
00:21:00,450 --> 00:21:04,770
I would say, at least 3x any
other year, if not higher.

432
00:21:04,770 --> 00:21:09,770
And we've really moved from
security being on computers

433
00:21:11,940 --> 00:21:14,670
or individual devices, to cloud security,

434
00:21:14,670 --> 00:21:18,750
which was a massive shift,
and now to AI security,

435
00:21:18,750 --> 00:21:22,830
which is another really seismic shift.

436
00:21:22,830 --> 00:21:27,150
And all of the existing
challenges that we had in,

437
00:21:27,150 --> 00:21:30,270
or that we still have in
the cloud security era,

438
00:21:30,270 --> 00:21:34,020
in terms of things like data
breaches, privacy leaks,

439
00:21:34,020 --> 00:21:38,280
adversarial attacks,
whether from nation states

440
00:21:38,280 --> 00:21:41,550
or malicious actors who
are trying to make money,

441
00:21:41,550 --> 00:21:44,010
all of these challenges still exist,

442
00:21:44,010 --> 00:21:46,250
but now we have new
challenges to worry about.

443
00:21:46,250 --> 00:21:49,800
Thinking about what AI agents can access,

444
00:21:49,800 --> 00:21:53,343
thinking about MCP and agent-to-agent,

445
00:21:54,810 --> 00:21:57,810
being concerned about model
poisoning and prompt injections.

446
00:21:59,530 --> 00:22:01,710
So, with that in mind,

447
00:22:01,710 --> 00:22:03,600
these are some of the key considerations

448
00:22:03,600 --> 00:22:04,800
that you need to think about

449
00:22:04,800 --> 00:22:08,810
when you're considering
deploying AI agents.

450
00:22:08,810 --> 00:22:13,810
The first pillar really is the
identity and access controls.

451
00:22:14,040 --> 00:22:17,790
We consider that AI agents
are a new type of identity,

452
00:22:17,790 --> 00:22:19,650
somewhere between humans,

453
00:22:19,650 --> 00:22:22,110
because they're kind of like
anthropomorphized humans,

454
00:22:22,110 --> 00:22:25,773
and machines, because
they're kind of like code.

455
00:22:26,760 --> 00:22:30,870
But just like humans, we
are going to need to ensure

456
00:22:30,870 --> 00:22:34,620
that they adhere to the
standard security principle

457
00:22:34,620 --> 00:22:35,730
of least privilege.

458
00:22:35,730 --> 00:22:38,400
They should only have enough
access to do their job,

459
00:22:38,400 --> 00:22:39,573
and not more than that.

460
00:22:40,430 --> 00:22:43,530
I'm also very excited
that ServiceNow today

461
00:22:43,530 --> 00:22:46,740
announced the intent to acquire VASA,

462
00:22:46,740 --> 00:22:49,170
a modern identity security company,

463
00:22:49,170 --> 00:22:51,370
which I believe is really going to enhance

464
00:22:51,370 --> 00:22:56,370
the ServiceNow AI agent trust story,

465
00:22:56,400 --> 00:22:58,230
because today we are well-known

466
00:22:58,230 --> 00:23:02,910
as a system of record for IT assets.

467
00:23:02,910 --> 00:23:06,630
We are also very well-known
as a system of action

468
00:23:06,630 --> 00:23:08,490
across many different types of use cases,

469
00:23:08,490 --> 00:23:13,020
and now we will be a system of
record for identity as well.

470
00:23:13,020 --> 00:23:16,890
Second pillar that you need to
think about is data security,

471
00:23:16,890 --> 00:23:21,180
and this is ever more
important in the AI era,

472
00:23:21,180 --> 00:23:26,180
where we all know that
AI needs tons of data

473
00:23:27,060 --> 00:23:30,350
to be able to operate efficiently,

474
00:23:30,350 --> 00:23:32,040
but it's more important than ever

475
00:23:32,040 --> 00:23:34,080
to know where your sensitive data is,

476
00:23:34,080 --> 00:23:36,750
and ensure that that data is protected.

477
00:23:36,750 --> 00:23:40,890
So those first two pillars
are really the hard boundaries

478
00:23:40,890 --> 00:23:44,270
that are essential for the
foundations of secure AI.

479
00:23:44,270 --> 00:23:47,280
The next pillar is the guardrails.

480
00:23:47,280 --> 00:23:49,020
So ServiceNow is actually,

481
00:23:49,020 --> 00:23:51,990
we have a model agnostic strategy,

482
00:23:51,990 --> 00:23:54,060
so we work with all
the major hyperscalers,

483
00:23:54,060 --> 00:23:58,470
including obviously AWS,
and all of these LLMs have,

484
00:23:58,470 --> 00:24:01,650
all the LLM providers have
guardrails built into them.

485
00:24:01,650 --> 00:24:04,530
On ServiceNow, we have our
own guardrails as well,

486
00:24:04,530 --> 00:24:07,680
called ServiceNow, or
called Now Assist Guardian,

487
00:24:07,680 --> 00:24:11,670
which ensures that the,

488
00:24:11,670 --> 00:24:14,430
it's monitoring for offensive content,

489
00:24:14,430 --> 00:24:16,470
detecting prompt injections,

490
00:24:16,470 --> 00:24:19,623
and also detecting personally
identifiable information.

491
00:24:21,600 --> 00:24:24,000
Finally, monitoring is an essential part

492
00:24:24,000 --> 00:24:25,530
of any security strategy,

493
00:24:25,530 --> 00:24:28,230
ensuring that you know what's going on,

494
00:24:28,230 --> 00:24:30,330
and ensuring that you have an audit trail

495
00:24:30,330 --> 00:24:31,930
in case something does go wrong.

496
00:24:33,710 --> 00:24:36,870
So let's just talk a little
bit more about identity

497
00:24:36,870 --> 00:24:39,990
and how this impacts security.

498
00:24:39,990 --> 00:24:41,370
So again, I talked a little bit about

499
00:24:41,370 --> 00:24:44,340
how security was very localized.

500
00:24:44,340 --> 00:24:49,340
In the cloud era, identity
really became the new perimeter.

501
00:24:50,630 --> 00:24:53,610
But what we're seeing in the AI era

502
00:24:53,610 --> 00:24:58,200
is the boundaries between
internal and external IT

503
00:24:58,200 --> 00:24:59,820
are starting to blur more and more,

504
00:24:59,820 --> 00:25:01,670
because the vision really that we have

505
00:25:01,670 --> 00:25:05,770
is that AI agents will
be acting on our behalf

506
00:25:05,770 --> 00:25:08,910
and working across different platforms

507
00:25:08,910 --> 00:25:13,910
to be able to carry out
autonomous actions on our behalf.

508
00:25:14,220 --> 00:25:16,500
So this means there is just going to be

509
00:25:16,500 --> 00:25:18,960
an absolute explosion
in non-human identities.

510
00:25:18,960 --> 00:25:21,360
And that explosion has even
really already started.

511
00:25:21,360 --> 00:25:24,990
In fact, there was a report by Imperva,

512
00:25:24,990 --> 00:25:26,280
now part of Thales this year,

513
00:25:26,280 --> 00:25:30,210
that said 51% of internet
traffic is automated.

514
00:25:30,210 --> 00:25:32,550
So as AI agents become more perfect,

515
00:25:32,550 --> 00:25:35,250
this is only going to get even bigger.

516
00:25:35,250 --> 00:25:39,690
And we're seeing an evolution
still in the standards.

517
00:25:39,690 --> 00:25:42,870
We have things like MCP, agent-to-agent,

518
00:25:42,870 --> 00:25:47,460
that do require OAuth, but it
doesn't really go deep enough.

519
00:25:47,460 --> 00:25:49,380
And I think we're going to need to see,

520
00:25:49,380 --> 00:25:51,810
in particular, more standards evolving

521
00:25:51,810 --> 00:25:54,300
around cross-platform authorization

522
00:25:54,300 --> 00:25:56,110
or cross-platform access controls.

523
00:25:56,110 --> 00:26:00,330
Today, the problem that
identity providers really solve

524
00:26:00,330 --> 00:26:02,130
is cross-platform authentication.

525
00:26:02,130 --> 00:26:05,580
So another reason why I'm
super excited about ServiceNow,

526
00:26:05,580 --> 00:26:07,830
announcing the intent to purchase VESA.

527
00:26:07,830 --> 00:26:10,410
So we will see what happens there.

528
00:26:10,410 --> 00:26:15,410
But even today, we have a great view

529
00:26:15,510 --> 00:26:19,200
to help you with your AI
with AI Control Tower.

530
00:26:19,200 --> 00:26:21,630
And AI Control Tower helps you

531
00:26:21,630 --> 00:26:23,890
with the security of
AI agents and AI assets

532
00:26:23,890 --> 00:26:28,590
by providing you visibility into access,

533
00:26:28,590 --> 00:26:30,930
ensuring that you have the trust

534
00:26:30,930 --> 00:26:34,713
that your AI assets have
the right level of access,

535
00:26:36,720 --> 00:26:38,400
showing privacy violations,

536
00:26:38,400 --> 00:26:40,320
ensuring that any sensitive data,

537
00:26:40,320 --> 00:26:42,450
especially personally
identifiable information,

538
00:26:42,450 --> 00:26:46,920
is either redacted or
detected as appropriate,

539
00:26:46,920 --> 00:26:49,990
and giving you visibility
into the security

540
00:26:49,990 --> 00:26:53,460
through either guardrail detections

541
00:26:53,460 --> 00:26:58,460
or providing that observability chain.

542
00:27:02,970 --> 00:27:07,260
And with that, I'm gonna
have Sampada come back up,

543
00:27:07,260 --> 00:27:09,810
and we're going to show another
demo of AI Control Tower.

544
00:27:09,810 --> 00:27:11,850
So I just wanna show a couple of use cases

545
00:27:11,850 --> 00:27:13,770
that AI Control Tower can help with,

546
00:27:13,770 --> 00:27:17,340
showing when AI agents
have privileged access,

547
00:27:17,340 --> 00:27:21,670
which can indicate potentially more risk,

548
00:27:21,670 --> 00:27:26,670
showing dormant agent, sorry,
identifying dormant agents,

549
00:27:27,840 --> 00:27:30,450
potentially agents that
are ready for retirement,

550
00:27:30,450 --> 00:27:32,460
they don't need that access anymore,

551
00:27:32,460 --> 00:27:35,250
showing streamlined access visibility.

552
00:27:35,250 --> 00:27:40,050
We're also showing already
AI scoring, security scoring,

553
00:27:40,050 --> 00:27:42,900
with plans to enhance that in our,

554
00:27:42,900 --> 00:27:44,730
very soon coming up in
our January release,

555
00:27:44,730 --> 00:27:48,570
we're gonna be adding the
new AI VSS scoring mechanism,

556
00:27:48,570 --> 00:27:52,020
as well as not just highlighting issues,

557
00:27:52,020 --> 00:27:55,290
but showing automated issue resolution.

558
00:27:55,290 --> 00:27:58,050
So with that, I will pass
to Sampada again, thank you.

559
00:27:58,050 --> 00:27:59,050
- Thank you, Amanda.

560
00:28:02,490 --> 00:28:06,570
All right, so let's talk about
the security and privacy tab.

561
00:28:06,570 --> 00:28:10,050
As Amanda mentioned, for
someone to truly trust

562
00:28:10,050 --> 00:28:12,090
and have that confidence in AI,

563
00:28:12,090 --> 00:28:14,880
securing data, having
that confidence in privacy

564
00:28:14,880 --> 00:28:16,140
is very important.

565
00:28:16,140 --> 00:28:17,400
And with AI Control Tower,

566
00:28:17,400 --> 00:28:20,460
you are able to manage that
data security and privacy

567
00:28:20,460 --> 00:28:25,460
for all of your AI systems,
be it ServiceNow or with AWS,

568
00:28:25,920 --> 00:28:28,500
those are the agents
that we are discovering.

569
00:28:28,500 --> 00:28:30,210
What you will see here is that

570
00:28:30,210 --> 00:28:32,850
the first and foremost important thing

571
00:28:32,850 --> 00:28:34,710
is to have that
transparency and visibility

572
00:28:34,710 --> 00:28:37,950
of what data do your
agents have access to.

573
00:28:37,950 --> 00:28:40,770
And you kind of do that
through your access maps.

574
00:28:40,770 --> 00:28:42,450
So as you go to an access map,

575
00:28:42,450 --> 00:28:44,550
I can bring up a particular agent,

576
00:28:44,550 --> 00:28:46,500
I can look at what are the different tools

577
00:28:46,500 --> 00:28:48,093
that agent is leveraging.

578
00:28:49,230 --> 00:28:51,330
Let's take this as an example.

579
00:28:51,330 --> 00:28:54,480
You have access to that, you
can then get information about

580
00:28:54,480 --> 00:28:57,930
the particular type of that
tool, where it is running,

581
00:28:57,930 --> 00:29:00,330
what data it would be getting access to.

582
00:29:00,330 --> 00:29:01,980
And that helps in understanding

583
00:29:01,980 --> 00:29:04,560
and having that truly
transparency and visibility

584
00:29:04,560 --> 00:29:06,273
into how your agents run.

585
00:29:07,790 --> 00:29:10,980
The next step is, how
are these agents running?

586
00:29:10,980 --> 00:29:13,380
Are they running in a supervised fashion

587
00:29:13,380 --> 00:29:14,213
or are they autonomous?

588
00:29:14,213 --> 00:29:15,720
And having that visibility

589
00:29:15,720 --> 00:29:19,440
into what are your autonomous
agents is extremely important,

590
00:29:19,440 --> 00:29:22,320
because knowing that,
you are able to then set

591
00:29:22,320 --> 00:29:23,730
what are the right set of guardrails

592
00:29:23,730 --> 00:29:26,583
that you would want to ensure
that the agents run within.

593
00:29:27,990 --> 00:29:31,440
Now digging a little bit
deeper, once your agents run,

594
00:29:31,440 --> 00:29:32,850
you also would want to understand

595
00:29:32,850 --> 00:29:34,380
how are these agents running,

596
00:29:34,380 --> 00:29:37,230
with what access levels
are they running with.

597
00:29:37,230 --> 00:29:39,720
Any agents that are running
with an admin access

598
00:29:39,720 --> 00:29:41,790
would be considered privileged agents,

599
00:29:41,790 --> 00:29:43,050
and you get a visibility

600
00:29:43,050 --> 00:29:46,370
into how many of your overall
agents in your ecosystem

601
00:29:46,370 --> 00:29:48,633
are running with that higher access.

602
00:29:49,650 --> 00:29:51,720
On the other side, you
would also want to know

603
00:29:51,720 --> 00:29:53,370
which agents are not being used,

604
00:29:53,370 --> 00:29:55,530
because they become open doors

605
00:29:55,530 --> 00:29:57,930
for threats and vulnerabilities.

606
00:29:57,930 --> 00:30:01,020
So with AI Control Tower, you
will be able to also get to

607
00:30:01,020 --> 00:30:02,493
how many agents are dormant.

608
00:30:04,260 --> 00:30:05,640
The next step is the guardrails

609
00:30:05,640 --> 00:30:07,290
that Amanda was talking about.

610
00:30:07,290 --> 00:30:09,840
With that, we would be
able to bring in guardrails

611
00:30:09,840 --> 00:30:13,950
around things around what
is offensive content.

612
00:30:13,950 --> 00:30:15,540
With Guardian, you can identify

613
00:30:15,540 --> 00:30:17,220
different types of offensive content

614
00:30:17,220 --> 00:30:22,220
in terms of either toxic content
or inappropriate content.

615
00:30:22,290 --> 00:30:23,160
You could flag that,

616
00:30:23,160 --> 00:30:25,160
you know how your agents are performing.

617
00:30:26,510 --> 00:30:29,400
The other piece that is
also equally important

618
00:30:29,400 --> 00:30:30,630
is the sensitive data.

619
00:30:30,630 --> 00:30:32,160
So you would want to understand

620
00:30:32,160 --> 00:30:35,340
are your agents processing
or handling sensitive data,

621
00:30:35,340 --> 00:30:36,810
which could be PII.

622
00:30:36,810 --> 00:30:39,810
In this example, of all the
data that we have collected,

623
00:30:39,810 --> 00:30:41,280
we have not identified it.

624
00:30:41,280 --> 00:30:42,960
But again, having visibility into that

625
00:30:42,960 --> 00:30:44,700
becomes extremely important.

626
00:30:44,700 --> 00:30:48,390
And then, if there is
sensitive data detected,

627
00:30:48,390 --> 00:30:50,310
you would also want to have anonymized.

628
00:30:50,310 --> 00:30:53,490
We would then capture
that information as well.

629
00:30:53,490 --> 00:30:54,960
All of this information is great,

630
00:30:54,960 --> 00:30:57,570
but you really want to
make this actionable.

631
00:30:57,570 --> 00:31:00,270
So what we then offer is insights.

632
00:31:00,270 --> 00:31:02,220
So as your insights run,

633
00:31:02,220 --> 00:31:06,090
and this is live, so let's
see how it comes across.

634
00:31:06,090 --> 00:31:07,440
So with that, you can see

635
00:31:07,440 --> 00:31:09,900
where are things that are working well,

636
00:31:09,900 --> 00:31:12,120
what are the areas that need attention,

637
00:31:12,120 --> 00:31:14,700
and anything that is
particularly actionable,

638
00:31:14,700 --> 00:31:17,370
we would be able to drive that as well.

639
00:31:17,370 --> 00:31:19,410
So by bringing together the inventory,

640
00:31:19,410 --> 00:31:22,020
the governance and the
lifecycle that we talked about,

641
00:31:22,020 --> 00:31:25,500
and then completing it up
with the security and privacy,

642
00:31:25,500 --> 00:31:26,490
with AI Control Tower,

643
00:31:26,490 --> 00:31:28,860
you can actually have your full oversight

644
00:31:28,860 --> 00:31:30,993
and governance for AI in the enterprise.

645
00:31:31,860 --> 00:31:33,750
Now, Amanda's going to
talk a little bit more

646
00:31:33,750 --> 00:31:36,600
about how we get to the sensitive data

647
00:31:36,600 --> 00:31:38,733
and managing that as well.

648
00:31:42,480 --> 00:31:43,770
- Okay, great, thank you.

649
00:31:43,770 --> 00:31:47,550
So AI Control Tower is all
about governing and securing

650
00:31:47,550 --> 00:31:49,980
and managing AI across the enterprise.

651
00:31:49,980 --> 00:31:51,510
But what about when you're building AI

652
00:31:51,510 --> 00:31:53,400
specifically on the ServiceNow platform?

653
00:31:53,400 --> 00:31:57,360
So we truly believe that
security is absolutely essential,

654
00:31:57,360 --> 00:32:00,480
just as it was in the cloud era.

655
00:32:00,480 --> 00:32:02,640
It's even more essential in the AI era

656
00:32:02,640 --> 00:32:04,530
to be able to trust the platform

657
00:32:04,530 --> 00:32:06,080
that you're running your AI on.

658
00:32:08,050 --> 00:32:10,080
That's why at ServiceNow,

659
00:32:10,080 --> 00:32:14,070
we have invested in multiple
layers of platform security

660
00:32:14,070 --> 00:32:16,090
to give our customers the right controls

661
00:32:16,090 --> 00:32:18,590
of the security and privacy of their data

662
00:32:18,590 --> 00:32:22,170
to be able to bring
that data to ServiceNow.

663
00:32:22,170 --> 00:32:24,090
So things like, I talked a lot already

664
00:32:24,090 --> 00:32:26,250
about identity and access controls,

665
00:32:26,250 --> 00:32:28,080
but also things like Security Center

666
00:32:28,080 --> 00:32:31,080
to give you visibility into the posture,

667
00:32:31,080 --> 00:32:34,390
the security posture of
your ServiceNow deployment.

668
00:32:34,390 --> 00:32:36,840
Then for customers that need even more

669
00:32:36,840 --> 00:32:39,150
and really want to make sure
that their data is secure,

670
00:32:39,150 --> 00:32:41,610
we have ServiceNow Vault.

671
00:32:41,610 --> 00:32:43,020
So let me talk a little
bit more about that

672
00:32:43,020 --> 00:32:44,880
and why it's super important.

673
00:32:44,880 --> 00:32:46,890
So a lot of people think about ServiceNow

674
00:32:46,890 --> 00:32:49,950
as our roots IT service management,

675
00:32:49,950 --> 00:32:53,490
but of course we've evolved a lot

676
00:32:53,490 --> 00:32:55,950
since then being a Fortune 500 company,

677
00:32:55,950 --> 00:32:58,590
serving multiple different
kinds of use cases

678
00:32:58,590 --> 00:33:02,340
out of the box like CRM,
like security operations,

679
00:33:02,340 --> 00:33:05,430
vulnerability management,
employee workflows,

680
00:33:05,430 --> 00:33:08,640
finance and supply chain, like
you name the C-suite leader

681
00:33:08,640 --> 00:33:11,790
and we pretty much have a
product for them out of the box.

682
00:33:11,790 --> 00:33:15,720
Not only that, but the
power of ServiceNow platform

683
00:33:15,720 --> 00:33:17,610
is its customizability.

684
00:33:17,610 --> 00:33:19,200
So you can really fulfill

685
00:33:19,200 --> 00:33:21,330
almost any kind of use case you want.

686
00:33:21,330 --> 00:33:24,210
In fact, I had one of
the top four US banks

687
00:33:24,210 --> 00:33:27,630
tell me recently, I love
the ServiceNow platform

688
00:33:27,630 --> 00:33:29,640
because I can achieve in a few clicks

689
00:33:29,640 --> 00:33:31,590
what my colleagues can only dream about.

690
00:33:31,590 --> 00:33:33,120
They're talking in weeks or months

691
00:33:33,120 --> 00:33:35,490
to achieve certain use cases.

692
00:33:35,490 --> 00:33:38,390
But of course, with all of these use cases

693
00:33:38,390 --> 00:33:41,280
comes more and more
types of sensitive data.

694
00:33:41,280 --> 00:33:43,530
So it's very important
to be able to ensure

695
00:33:43,530 --> 00:33:45,390
that you have the right visibility

696
00:33:45,390 --> 00:33:46,803
and control over this data.

697
00:33:48,300 --> 00:33:51,000
That's why we created ServiceNow Vault,

698
00:33:51,000 --> 00:33:55,800
which is a unified console
to help you know your data,

699
00:33:55,800 --> 00:33:58,830
protect your data and monitor your data.

700
00:33:58,830 --> 00:34:00,480
And this is again, very important

701
00:34:00,480 --> 00:34:03,630
because ServiceNow is in this,

702
00:34:03,630 --> 00:34:07,310
I think very strong position in the AI era

703
00:34:07,310 --> 00:34:11,460
of bringing together the
data that we already have,

704
00:34:11,460 --> 00:34:14,880
now the AI and the workflows

705
00:34:14,880 --> 00:34:18,273
to truly be able to automate
work across the enterprise.

706
00:34:19,230 --> 00:34:22,530
And of course, not only are
we helping to secure AI,

707
00:34:22,530 --> 00:34:25,353
but we're using AI to
help make security easier.

708
00:34:28,590 --> 00:34:31,350
These are the products
that are included in Vault.

709
00:34:31,350 --> 00:34:33,210
I won't go into too much of this

710
00:34:33,210 --> 00:34:34,530
'cause I'm gonna show you in a demo,

711
00:34:34,530 --> 00:34:37,470
but data privacy
essentially helps you find

712
00:34:37,470 --> 00:34:39,420
not just personally
identifiable information,

713
00:34:39,420 --> 00:34:41,790
but really any type of sensitive data.

714
00:34:41,790 --> 00:34:45,180
Multiple layers of
encryption can be applied

715
00:34:45,180 --> 00:34:47,940
either at volume or at the field level.

716
00:34:47,940 --> 00:34:52,070
We can apply granular access policies.

717
00:34:52,070 --> 00:34:56,400
We have near real-time export of log data

718
00:34:56,400 --> 00:35:00,450
via Kafka Stream to your security,

719
00:35:00,450 --> 00:35:02,040
log monitoring tool, your SIMs,

720
00:35:02,040 --> 00:35:05,190
or whatever your log analytics
platform of choice is.

721
00:35:05,190 --> 00:35:09,060
And we provide code signing to ensure code

722
00:35:09,060 --> 00:35:11,730
that is being deployed
out to your IT assets

723
00:35:11,730 --> 00:35:14,433
in your network is secure
and untampered with.

724
00:35:15,870 --> 00:35:17,703
So let's take a look.

725
00:35:23,790 --> 00:35:26,700
So here I am in a ServiceNow instance.

726
00:35:26,700 --> 00:35:30,240
I'm going to start at the Vault console.

727
00:35:30,240 --> 00:35:32,840
Now, we already have a good understanding

728
00:35:32,840 --> 00:35:34,800
of the out-of-the-box applications,

729
00:35:34,800 --> 00:35:39,180
so we are able to, we
know that this instance

730
00:35:39,180 --> 00:35:42,060
has a couple of pre-built ServiceNow apps,

731
00:35:42,060 --> 00:35:44,040
so I'm gonna get started.

732
00:35:44,040 --> 00:35:47,730
And here I can see that
based on our knowledge

733
00:35:47,730 --> 00:35:52,350
of the data model, we have
suggested data classifications.

734
00:35:52,350 --> 00:35:53,910
Now, of course, as a customer,

735
00:35:53,910 --> 00:35:55,860
you can review these data classifications

736
00:35:55,860 --> 00:35:59,130
and make sure they adhere
to your company policies

737
00:35:59,130 --> 00:36:01,350
and your local regulatory requirements,

738
00:36:01,350 --> 00:36:05,310
adapt them if needed,
but providing you're good

739
00:36:05,310 --> 00:36:08,730
with these classifications,
you simply need to check agree

740
00:36:08,730 --> 00:36:10,740
and apply recommended classes.

741
00:36:10,740 --> 00:36:13,140
So very simply, within a few clicks,

742
00:36:13,140 --> 00:36:16,173
you're able to classify the
data of an entire application.

743
00:36:18,900 --> 00:36:23,220
So, of course, we're not just finding data

744
00:36:23,220 --> 00:36:27,577
via data templates, we're also using our,

745
00:36:28,650 --> 00:36:30,360
we have pattern-based matching,

746
00:36:30,360 --> 00:36:32,280
we have out-of-the-box templates,

747
00:36:32,280 --> 00:36:34,590
and we also use AI to detect

748
00:36:34,590 --> 00:36:36,750
personally identifiable information.

749
00:36:36,750 --> 00:36:39,540
So once you have found the sensitive data,

750
00:36:39,540 --> 00:36:41,730
then you have various different ways

751
00:36:41,730 --> 00:36:43,620
that you can protect this data.

752
00:36:43,620 --> 00:36:47,580
So one of the ways is anonymization.

753
00:36:47,580 --> 00:36:50,550
It could be that, hey, this is
something like a credit card

754
00:36:50,550 --> 00:36:54,180
or a social security number
that I just don't want

755
00:36:54,180 --> 00:36:57,390
in the environment at all,
and I'm going to redact it,

756
00:36:57,390 --> 00:37:00,990
or it could be that you're
cloning all of this data

757
00:37:00,990 --> 00:37:02,580
to a lower-production environment,

758
00:37:02,580 --> 00:37:04,230
and you want it all anonymized.

759
00:37:04,230 --> 00:37:06,240
You want the developers that are working

760
00:37:06,240 --> 00:37:07,700
in those lower-production environments

761
00:37:07,700 --> 00:37:12,180
to have a very real-world-like environment

762
00:37:12,180 --> 00:37:14,760
in terms of the shape
and size of the data,

763
00:37:14,760 --> 00:37:17,280
but you don't want them to
see the actual sensitive data.

764
00:37:17,280 --> 00:37:20,310
So that's a good use
case for anonymization.

765
00:37:20,310 --> 00:37:21,660
You can encrypt.

766
00:37:21,660 --> 00:37:24,800
This is a good compensating
access control,

767
00:37:24,800 --> 00:37:28,350
and it also ensures an
extra layer of security

768
00:37:28,350 --> 00:37:30,030
against insider threat access

769
00:37:30,030 --> 00:37:34,833
against the cloud service
provider-privileged access users.

770
00:37:36,000 --> 00:37:38,580
And then the third type of
protection that you can apply

771
00:37:38,580 --> 00:37:41,040
is zero-trust access.

772
00:37:41,040 --> 00:37:43,530
So these are above and beyond.

773
00:37:43,530 --> 00:37:45,390
These are like dynamic access policies

774
00:37:45,390 --> 00:37:48,570
that you can apply to
specific sensitive data

775
00:37:48,570 --> 00:37:51,780
to when the risk, you can,
I'll show you an example,

776
00:37:51,780 --> 00:37:54,000
but let's write a policy here.

777
00:37:54,000 --> 00:37:58,920
So I'm going to create a
policy for confidential data.

778
00:37:58,920 --> 00:38:01,800
I'm typing very fast. (laughs)

779
00:38:01,800 --> 00:38:03,660
And I'm going to apply this

780
00:38:03,660 --> 00:38:08,553
to all of our confidential
data for CSM case management.

781
00:38:10,980 --> 00:38:13,740
And the policy that
I'm going to apply here

782
00:38:13,740 --> 00:38:16,530
is that I'm going to enforce
multi-factor authentication.

783
00:38:16,530 --> 00:38:18,750
Because this is highly confidential data,

784
00:38:18,750 --> 00:38:20,910
I want to make sure that the user

785
00:38:20,910 --> 00:38:22,710
really is who they say they are

786
00:38:22,710 --> 00:38:24,780
when they're accessing this data.

787
00:38:24,780 --> 00:38:26,490
But a couple of other types of policies

788
00:38:26,490 --> 00:38:28,290
that you could choose to apply are

789
00:38:28,290 --> 00:38:30,060
if the user's in a specific,

790
00:38:30,060 --> 00:38:33,420
or in or out of a specific
geographic region,

791
00:38:33,420 --> 00:38:35,730
in or out of a specific IP range,

792
00:38:35,730 --> 00:38:40,560
we can also use risk factors
from the single sign-on,

793
00:38:40,560 --> 00:38:43,830
so from the likes of Okta,
for example, as a factor.

794
00:38:43,830 --> 00:38:46,680
So you can dynamically
change a person's access

795
00:38:46,680 --> 00:38:48,630
based on their risk profile,

796
00:38:48,630 --> 00:38:49,950
either at the time of logging in

797
00:38:49,950 --> 00:38:51,963
or using continuous authentication.

798
00:38:53,520 --> 00:38:58,520
So with this, I can see, for
this table of classified data,

799
00:38:59,670 --> 00:39:01,200
what protections have been applied

800
00:39:01,200 --> 00:39:02,850
and what's still available to me.

801
00:39:04,760 --> 00:39:07,980
So now I can see that the
zero-trust access policies

802
00:39:07,980 --> 00:39:09,810
have been applied to this table.

803
00:39:09,810 --> 00:39:12,780
And just like that, again,
within a few clicks,

804
00:39:12,780 --> 00:39:14,820
I have the ability to
find my sensitive data

805
00:39:14,820 --> 00:39:16,370
and ensure that it's protected.

806
00:39:18,450 --> 00:39:21,660
Now, we're not only detecting
data that's written in tables,

807
00:39:21,660 --> 00:39:24,000
we're also doing this with real-time data.

808
00:39:24,000 --> 00:39:29,000
So whether it's in Now
Assist, our AI-powered chat,

809
00:39:31,020 --> 00:39:32,580
or email, for example,

810
00:39:32,580 --> 00:39:34,623
you can also detect data in real-time.

811
00:39:35,640 --> 00:39:38,580
So with this, I'm able to, again,

812
00:39:38,580 --> 00:39:41,460
very quickly find and protect the data.

813
00:39:41,460 --> 00:39:43,320
But that's not all.

814
00:39:43,320 --> 00:39:45,180
As I said, we're also using AI

815
00:39:45,180 --> 00:39:48,000
to make it easier to protect the data.

816
00:39:48,000 --> 00:39:50,280
So I can chat with Now Assist and say,

817
00:39:50,280 --> 00:39:54,900
can you write me a new filter to detect,

818
00:39:54,900 --> 00:39:57,900
for example, a zip code?

819
00:39:57,900 --> 00:40:02,900
And it will choose, generate
custom data pattern,

820
00:40:05,340 --> 00:40:08,520
and it will help generate
that regular expression for me

821
00:40:08,520 --> 00:40:10,140
in case I don't know how to
write regular expressions.

822
00:40:10,140 --> 00:40:10,973
They're not that hard,

823
00:40:10,973 --> 00:40:12,993
but not everybody knows how to write them.

824
00:40:13,890 --> 00:40:15,570
And it will also test it for me.

825
00:40:15,570 --> 00:40:20,160
And I can just say, looks
good, and I can apply that.

826
00:40:20,160 --> 00:40:24,720
So now, I can use that both for, again,

827
00:40:24,720 --> 00:40:27,820
written data or real-time data detection.

828
00:40:27,820 --> 00:40:31,620
So that's how the Vault
console helps you find,

829
00:40:31,620 --> 00:40:35,490
protect, and monitor your sensitive data.

830
00:40:35,490 --> 00:40:37,110
And this helps you ensure

831
00:40:37,110 --> 00:40:38,700
that data in the ServiceNow platform

832
00:40:38,700 --> 00:40:40,710
is kept secure and private,

833
00:40:40,710 --> 00:40:43,680
is aligning with regulatory compliance,

834
00:40:43,680 --> 00:40:46,060
and really reducing your risk,

835
00:40:46,060 --> 00:40:48,840
and enabling you to
bring more sensitive data

836
00:40:48,840 --> 00:40:50,133
to the ServiceNow Cloud.

837
00:40:52,560 --> 00:40:55,320
And really, this emphasizes that

838
00:40:55,320 --> 00:40:59,940
with AI Control Tower and
with ServiceNow Vault,

839
00:40:59,940 --> 00:41:03,030
you have security, privacy,
and access controls

840
00:41:03,030 --> 00:41:06,057
really baked in and not bolted on.

841
00:41:06,057 --> 00:41:07,950
And the reason why this
is ever more important

842
00:41:07,950 --> 00:41:09,690
is because, again, those boundaries

843
00:41:09,690 --> 00:41:14,250
between internal and external
IT are starting to blur.

844
00:41:14,250 --> 00:41:16,830
With ServiceNow Workflow Data Fabric

845
00:41:16,830 --> 00:41:19,620
that is connected to the AWS data lakes,

846
00:41:19,620 --> 00:41:21,990
we're operating on the data
as if it's in ServiceNow.

847
00:41:21,990 --> 00:41:25,320
So it's, again, super
important to be able to ensure

848
00:41:25,320 --> 00:41:29,790
that you are able to monitor
the access of AI agents,

849
00:41:29,790 --> 00:41:31,920
be able to detect sensitive data,

850
00:41:31,920 --> 00:41:35,037
be able to do this for external AI,

851
00:41:35,037 --> 00:41:37,140
and to have those security policy

852
00:41:37,140 --> 00:41:38,613
enforcements and guardrails.

853
00:41:39,480 --> 00:41:41,340
Thank you, hope you
have a great conference.

854
00:41:41,340 --> 00:41:42,173
- Thank you.
- Thank you.

855
00:41:42,173 --> 00:41:43,876
(audience applauding)

