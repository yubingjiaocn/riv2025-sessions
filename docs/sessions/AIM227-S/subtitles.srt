1
00:00:01,170 --> 00:00:02,003
- Welcome all.

2
00:00:02,003 --> 00:00:03,003
My name is JJ Sharma.

3
00:00:03,915 --> 00:00:06,000
I'm the TBM and FinOps Practice Lead

4
00:00:06,000 --> 00:00:08,100
for KPMG Australia.

5
00:00:08,100 --> 00:00:11,261
With us today is Andrew Midgley,

6
00:00:11,261 --> 00:00:13,649
principal product marketing manager

7
00:00:13,649 --> 00:00:15,453
for IBM Cloudability.

8
00:00:17,280 --> 00:00:18,330
- Thanks, JJ.

9
00:00:18,330 --> 00:00:20,250
So one thing I can tell you is

10
00:00:20,250 --> 00:00:21,660
that certainly my manager has

11
00:00:21,660 --> 00:00:23,337
never given me half a million dollars

12
00:00:23,337 --> 00:00:24,390
to go on training,

13
00:00:24,390 --> 00:00:25,881
that's for sure.

14
00:00:25,881 --> 00:00:28,260
But yeah, it's awesome to be

15
00:00:28,260 --> 00:00:29,522
back at re:Invent.

16
00:00:29,522 --> 00:00:31,440
Over 10 years, for me,

17
00:00:31,440 --> 00:00:32,550
working on Cloudability,

18
00:00:32,550 --> 00:00:34,122
it's been an amazing ride.

19
00:00:34,122 --> 00:00:36,930
What I would say is that this AI wave

20
00:00:36,930 --> 00:00:38,010
that we're going through right now,

21
00:00:38,010 --> 00:00:38,843
for me, personally,

22
00:00:38,843 --> 00:00:40,652
has been very invigorating.

23
00:00:40,652 --> 00:00:43,140
To me, it feels quite momentous,

24
00:00:43,140 --> 00:00:44,997
very similar to the way it felt

25
00:00:44,997 --> 00:00:47,730
in the early days of public cloud.

26
00:00:47,730 --> 00:00:48,750
So moving forward,

27
00:00:48,750 --> 00:00:49,890
it's very exciting working

28
00:00:49,890 --> 00:00:51,158
with our customers

29
00:00:51,158 --> 00:00:52,901
with just how transformational

30
00:00:52,901 --> 00:00:54,750
this technology is.

31
00:00:54,750 --> 00:00:55,583
So, yeah, it's great to be

32
00:00:55,583 --> 00:00:56,416
with you today.

33
00:00:58,991 --> 00:01:01,339
So let's just quickly start

34
00:01:01,339 --> 00:01:03,480
with the scale of what's happening

35
00:01:03,480 --> 00:01:05,689
right now in AI.

36
00:01:05,689 --> 00:01:07,050
Gartner is predicting

37
00:01:07,050 --> 00:01:07,920
that global spending

38
00:01:07,920 --> 00:01:11,580
on Generative AI will hit $664 billion

39
00:01:11,580 --> 00:01:12,857
this year.

40
00:01:12,857 --> 00:01:17,086
That's up more than 75% from 2024.

41
00:01:17,086 --> 00:01:18,729
It's massive growth.

42
00:01:18,729 --> 00:01:21,300
Pretty much every company is investing

43
00:01:21,300 --> 00:01:23,760
in AI somewhere right now.

44
00:01:23,760 --> 00:01:25,772
But here's the reality check.

45
00:01:25,772 --> 00:01:28,605
Less than 30% of AI leaders say

46
00:01:28,605 --> 00:01:30,434
that their CEOs are happy

47
00:01:30,434 --> 00:01:32,310
with the return they're getting

48
00:01:32,310 --> 00:01:33,810
on that spending.

49
00:01:33,810 --> 00:01:35,513
So there's a bit of a problem here.

50
00:01:36,570 --> 00:01:37,770
So while everyone's racing

51
00:01:37,770 --> 00:01:39,299
to build and deploy AI,

52
00:01:39,299 --> 00:01:42,300
most organizations are still figuring out

53
00:01:42,300 --> 00:01:45,005
how to make it financially worthwhile.

54
00:01:45,005 --> 00:01:46,050
And that's really what

55
00:01:46,050 --> 00:01:47,760
this session is about;

56
00:01:47,760 --> 00:01:50,456
bringing some financial discipline to AI

57
00:01:50,456 --> 00:01:52,410
so that all the innovation

58
00:01:52,410 --> 00:01:53,670
that we're investing in

59
00:01:53,670 --> 00:01:56,223
actually delivers on its goals.

60
00:01:58,714 --> 00:02:00,590
So my goal for you today is

61
00:02:00,590 --> 00:02:02,940
that you can leave this session

62
00:02:02,940 --> 00:02:04,140
with a clear view of

63
00:02:04,140 --> 00:02:06,468
the key trends shaping GenAI,

64
00:02:06,468 --> 00:02:08,970
the options and cost considerations

65
00:02:08,970 --> 00:02:11,418
when running these workloads on AWS,

66
00:02:11,418 --> 00:02:13,680
and how FinOps can turn this spend

67
00:02:13,680 --> 00:02:15,513
into measurable business value.

68
00:02:16,620 --> 00:02:18,914
So what will we actually cover today?

69
00:02:18,914 --> 00:02:20,220
JJ will start

70
00:02:20,220 --> 00:02:21,930
with a quick overview of FinOps,

71
00:02:21,930 --> 00:02:22,763
and what we're hearing

72
00:02:22,763 --> 00:02:24,150
from the FinOps community.

73
00:02:24,150 --> 00:02:26,046
Hopefully, that's a few of you here.

74
00:02:26,046 --> 00:02:27,750
Then we'll take a strategic look

75
00:02:27,750 --> 00:02:29,003
at AI trends.

76
00:02:29,003 --> 00:02:30,870
What's happening in the Brocket mar...

77
00:02:30,870 --> 00:02:32,520
What's happening in
the broader marketplace

78
00:02:32,520 --> 00:02:34,410
from technology providers,

79
00:02:34,410 --> 00:02:37,457
and how the GenAI
operating model is evolving

80
00:02:37,457 --> 00:02:40,999
from the point of view of consumers.

81
00:02:40,999 --> 00:02:42,630
From there, we'll review

82
00:02:42,630 --> 00:02:44,970
the main deployment modes for GenAI,

83
00:02:44,970 --> 00:02:46,590
from SaaS APIs through

84
00:02:46,590 --> 00:02:48,810
to fully self-managed infrastructure,

85
00:02:48,810 --> 00:02:50,520
and how those choices impact

86
00:02:50,520 --> 00:02:52,983
both flexibility and your cost control.

87
00:02:53,963 --> 00:02:55,680
We'll follow that with a deep dive

88
00:02:55,680 --> 00:02:57,990
into AWS services and pricing,

89
00:02:57,990 --> 00:03:00,180
so you can see how costs break down

90
00:03:00,180 --> 00:03:01,696
across the build, train,

91
00:03:01,696 --> 00:03:03,647
and run phases.

92
00:03:03,647 --> 00:03:05,217
After that, we'll talk about

93
00:03:05,217 --> 00:03:06,660
key FinOps practices

94
00:03:06,660 --> 00:03:07,858
that you can apply right now

95
00:03:07,858 --> 00:03:09,900
to get better visibility,

96
00:03:09,900 --> 00:03:12,000
better predictability,

97
00:03:12,000 --> 00:03:13,110
and better efficiency

98
00:03:13,110 --> 00:03:14,827
for your AI spend.

99
00:03:14,827 --> 00:03:16,455
And finally, we'll wrap up

100
00:03:16,455 --> 00:03:18,279
with unit economics.

101
00:03:18,279 --> 00:03:20,413
How to measure success with AI,

102
00:03:20,413 --> 00:03:21,853
not by total spend

103
00:03:21,853 --> 00:03:24,420
but by cost per transaction, per user,

104
00:03:24,420 --> 00:03:25,670
whatever matters for you,

105
00:03:25,670 --> 00:03:27,660
so that we can tie investment

106
00:03:27,660 --> 00:03:29,283
directly back to value.

107
00:03:32,525 --> 00:03:34,877
And a quick introduction to FinOps.

108
00:03:35,871 --> 00:03:38,220
- I think a learned audience would know

109
00:03:38,220 --> 00:03:39,619
a lot about FinOps,

110
00:03:39,619 --> 00:03:42,360
but I often meet new colleagues at KPMG

111
00:03:42,360 --> 00:03:44,760
who work in different technology areas.

112
00:03:44,760 --> 00:03:46,290
And the way I describe it is

113
00:03:46,290 --> 00:03:48,112
it's a collective brains trust

114
00:03:48,112 --> 00:03:53,112
of about 65,000 practicing professionals.

115
00:03:53,186 --> 00:03:55,410
And what that gives us collectively,

116
00:03:55,410 --> 00:03:57,000
that brains trust,

117
00:03:57,000 --> 00:04:00,778
is tooling processes, best practices,

118
00:04:00,778 --> 00:04:02,700
that we call as the discipline

119
00:04:02,700 --> 00:04:04,228
of cloud FinOps.

120
00:04:04,228 --> 00:04:07,650
And it does two very
important things for us.

121
00:04:07,650 --> 00:04:09,722
It helps us have the conversation

122
00:04:09,722 --> 00:04:12,493
in the metrics that business,

123
00:04:12,493 --> 00:04:14,938
finance, and technology understand

124
00:04:14,938 --> 00:04:16,392
for themselves,

125
00:04:16,392 --> 00:04:18,513
and with FinOps, for each other.

126
00:04:19,364 --> 00:04:20,977
And the second thing

127
00:04:20,977 --> 00:04:23,254
that it does for us is

128
00:04:23,254 --> 00:04:27,222
it helps us to align our initiatives

129
00:04:27,222 --> 00:04:29,078
and get the best out of

130
00:04:29,078 --> 00:04:30,570
our cloud investments

131
00:04:30,570 --> 00:04:31,920
in terms of maximizing

132
00:04:31,920 --> 00:04:32,883
its business value.

133
00:04:34,995 --> 00:04:37,410
You wanna talk about the foundation?

134
00:04:37,410 --> 00:04:38,372
- Next slide.

135
00:04:38,372 --> 00:04:39,540
Oh, the foundation?

136
00:04:39,540 --> 00:04:40,373
Yeah.

137
00:04:40,373 --> 00:04:41,206
Yeah, I guess, sorry.

138
00:04:41,206 --> 00:04:42,390
Yeah, so the FinOps Foundation,

139
00:04:42,390 --> 00:04:43,223
as you said,

140
00:04:43,223 --> 00:04:44,871
I think about 65,000 people

141
00:04:44,871 --> 00:04:46,050
in that community.

142
00:04:46,050 --> 00:04:47,220
- Yep.
- So I'm gonna guess

143
00:04:47,220 --> 00:04:49,350
a few of you're amongst that group.

144
00:04:49,350 --> 00:04:50,559
Yeah, so it's...

145
00:04:50,559 --> 00:04:52,590
I mean, I encourage everyone

146
00:04:52,590 --> 00:04:53,670
to get involved,

147
00:04:53,670 --> 00:04:55,683
just to Google the FinOps Foundation.

148
00:04:55,683 --> 00:04:57,054
Yeah, their website has

149
00:04:57,054 --> 00:04:58,470
so many good practices,

150
00:04:58,470 --> 00:04:59,989
and recommendations, and videos,

151
00:04:59,989 --> 00:05:02,170
and information about vendors like us.

152
00:05:02,170 --> 00:05:03,450
But yeah, that's sort of the...

153
00:05:03,450 --> 00:05:04,560
The foundation has grown up

154
00:05:04,560 --> 00:05:05,610
to solve these problems

155
00:05:05,610 --> 00:05:07,350
around cloud cost optimization,

156
00:05:07,350 --> 00:05:08,370
cloud cost management,

157
00:05:08,370 --> 00:05:09,840
making sure that we're all maximizing

158
00:05:09,840 --> 00:05:11,430
the value of these investments.

159
00:05:11,430 --> 00:05:12,840
And there's obviously a massive push

160
00:05:12,840 --> 00:05:13,923
within the FinOps Foundation

161
00:05:13,923 --> 00:05:15,480
around AI as well.

162
00:05:15,480 --> 00:05:16,920
White papers around AI.

163
00:05:16,920 --> 00:05:18,660
There's a lot of thought leadership there

164
00:05:18,660 --> 00:05:19,953
to go to.
- Great.

165
00:05:21,747 --> 00:05:22,833
And one of the things

166
00:05:22,833 --> 00:05:24,175
that the foundation does is

167
00:05:24,175 --> 00:05:25,343
to take a pulse

168
00:05:25,343 --> 00:05:27,375
of the community itself.

169
00:05:27,375 --> 00:05:29,634
And these are the results from

170
00:05:29,634 --> 00:05:32,952
the latest survey of 2025.

171
00:05:32,952 --> 00:05:34,980
Midge, does it surprise you to see

172
00:05:34,980 --> 00:05:36,903
where AI and ML spend is?

173
00:05:37,785 --> 00:05:40,260
- Yeah, well, it sort of does.

174
00:05:40,260 --> 00:05:41,850
So I'll just backtrack a little bit.

175
00:05:41,850 --> 00:05:46,726
So obviously, this survey
goes out every year,

176
00:05:46,726 --> 00:05:48,570
so we're getting that feedback

177
00:05:48,570 --> 00:05:49,860
from the community

178
00:05:49,860 --> 00:05:51,270
about what's important to you.

179
00:05:51,270 --> 00:05:52,170
What are your priorities?

180
00:05:52,170 --> 00:05:53,466
What are your challenges?

181
00:05:53,466 --> 00:05:54,930
All kinds of information.

182
00:05:54,930 --> 00:05:57,420
Is Kubernetes an area of concern?

183
00:05:57,420 --> 00:05:58,320
Whatever.

184
00:05:58,320 --> 00:05:59,520
So I believe there's

185
00:05:59,520 --> 00:06:00,960
about 1,000 practitioners

186
00:06:00,960 --> 00:06:02,223
actually respond to this every year.

187
00:06:02,223 --> 00:06:03,090
- Yep.
- So I might actually

188
00:06:03,090 --> 00:06:03,923
just pause for a second.

189
00:06:03,923 --> 00:06:06,030
Has anyone here actually contributed

190
00:06:06,030 --> 00:06:08,610
to the State of FinOps Report?

191
00:06:08,610 --> 00:06:09,750
- Great.

192
00:06:09,750 --> 00:06:10,590
- Yeah, got a few.

193
00:06:10,590 --> 00:06:12,630
So recommend everyone go and check it out.

194
00:06:12,630 --> 00:06:15,429
So data.finops.org is the website.

195
00:06:15,429 --> 00:06:17,104
Every year, it's run.

196
00:06:17,104 --> 00:06:18,930
Obviously, 1,000 practitioners.

197
00:06:18,930 --> 00:06:20,340
You're getting a lot of information

198
00:06:20,340 --> 00:06:22,230
about what's important to the community.

199
00:06:22,230 --> 00:06:23,400
So yeah I was surprised

200
00:06:23,400 --> 00:06:24,802
because looking back

201
00:06:24,802 --> 00:06:26,346
to the prior 12 months,

202
00:06:26,346 --> 00:06:27,827
the FinOps community said

203
00:06:27,827 --> 00:06:29,040
this was amongst...

204
00:06:29,040 --> 00:06:30,620
AI and ML was amongst

205
00:06:30,620 --> 00:06:32,643
the absolute lowest priorities.

206
00:06:32,643 --> 00:06:34,442
And I was quite surprised by that.

207
00:06:34,442 --> 00:06:37,560
Looking forward to the next 12 months,

208
00:06:37,560 --> 00:06:39,697
which is what the slide is here,

209
00:06:39,697 --> 00:06:41,430
you can see that it's actually

210
00:06:41,430 --> 00:06:42,750
now bumped up four places

211
00:06:42,750 --> 00:06:45,030
to the middle-of-the-pack priority.

212
00:06:45,030 --> 00:06:46,173
So I was surprised.

213
00:06:46,173 --> 00:06:47,565
But I think, yeah,

214
00:06:47,565 --> 00:06:49,470
we have some ideas around that.

215
00:06:49,470 --> 00:06:50,303
- I was surprised

216
00:06:50,303 --> 00:06:51,888
but in a very different manner.

217
00:06:51,888 --> 00:06:54,012
I was mostly surprised to see

218
00:06:54,012 --> 00:06:57,490
how everything that's showed up has

219
00:06:57,490 --> 00:07:01,470
just bursted up four or five spots.

220
00:07:01,470 --> 00:07:03,328
That's very unusual.

221
00:07:03,328 --> 00:07:06,344
And now, governance is a higher priority

222
00:07:06,344 --> 00:07:07,863
than waste reduction.

223
00:07:08,850 --> 00:07:11,337
Quickly followed by the idea

224
00:07:11,337 --> 00:07:13,020
of not just looking at cloud,

225
00:07:13,020 --> 00:07:14,479
but beyond cloud,

226
00:07:14,479 --> 00:07:17,670
and getting into unit economics,

227
00:07:17,670 --> 00:07:20,400
and doing so by enabled automation.

228
00:07:20,400 --> 00:07:22,140
So we're talking about a altogether

229
00:07:22,140 --> 00:07:25,890
different scale of prioritization

230
00:07:25,890 --> 00:07:27,423
for the FinOps practitioners.

231
00:07:28,914 --> 00:07:31,650
And when I look at this

232
00:07:31,650 --> 00:07:33,420
more as a forest instead

233
00:07:33,420 --> 00:07:35,229
of the individual trees,

234
00:07:35,229 --> 00:07:38,752
then I think there's a
clear recognition here

235
00:07:38,752 --> 00:07:42,111
that we are now expected

236
00:07:42,111 --> 00:07:44,850
not just to be tactically optimizing

237
00:07:44,850 --> 00:07:46,800
as practitioners all the time,

238
00:07:46,800 --> 00:07:49,680
but gotta take a more
strategic view of things

239
00:07:49,680 --> 00:07:51,940
and align our outcomes

240
00:07:51,940 --> 00:07:53,673
to that business value.

241
00:07:53,673 --> 00:07:54,506
- Yeah.

242
00:07:55,830 --> 00:07:56,663
Perfect.

243
00:07:58,928 --> 00:08:01,410
- So just so we can continue speaking

244
00:08:01,410 --> 00:08:03,090
this candidly with you,

245
00:08:03,090 --> 00:08:04,254
just wanna make sure that

246
00:08:04,254 --> 00:08:05,970
we get the gist of it,

247
00:08:05,970 --> 00:08:09,088
that this is a purely
educational presentation

248
00:08:09,088 --> 00:08:11,250
and we are not here to endorse

249
00:08:11,250 --> 00:08:12,783
any products or services.

250
00:08:13,758 --> 00:08:15,540
And may I request you all

251
00:08:15,540 --> 00:08:16,590
to keep us honest here?

252
00:08:16,590 --> 00:08:18,810
So if you hear anything that sounds

253
00:08:18,810 --> 00:08:20,920
even remotely like endorsement,

254
00:08:20,920 --> 00:08:22,860
I urge you to stop us

255
00:08:22,860 --> 00:08:25,473
and we fix that, all right?

256
00:08:26,580 --> 00:08:27,600
Thank you.

257
00:08:27,600 --> 00:08:28,770
So we talked a couple of times

258
00:08:28,770 --> 00:08:30,868
about taking a strategic view.

259
00:08:30,868 --> 00:08:32,400
How do you do that?

260
00:08:32,400 --> 00:08:34,860
How do you take a strategic view?

261
00:08:34,860 --> 00:08:35,693
So let's talk about

262
00:08:35,693 --> 00:08:37,470
in the context of GenAI.

263
00:08:37,470 --> 00:08:39,120
And a good starting point is

264
00:08:39,120 --> 00:08:40,440
to ask some simple questions

265
00:08:40,440 --> 00:08:42,090
about any technology

266
00:08:42,090 --> 00:08:44,455
to get started with
that strategic outlook.

267
00:08:44,455 --> 00:08:46,063
And I usually think about "why?"

268
00:08:46,063 --> 00:08:47,823
Why are we gonna be using it?

269
00:08:48,937 --> 00:08:49,800
"What?"

270
00:08:49,800 --> 00:08:51,360
What is the economic environment

271
00:08:51,360 --> 00:08:53,490
in which we're gonna be using it?

272
00:08:53,490 --> 00:08:54,323
And "how?"

273
00:08:54,323 --> 00:08:56,190
How are we gonna adopt it?

274
00:08:56,190 --> 00:08:58,966
How much of it are we gonna be using?

275
00:08:58,966 --> 00:09:01,320
So if we ask the same three questions

276
00:09:01,320 --> 00:09:02,673
of GenAI,

277
00:09:05,308 --> 00:09:07,020
my first impression

278
00:09:07,020 --> 00:09:09,904
with GenAI was ChatGPT coming out

279
00:09:09,904 --> 00:09:13,353
about November 2022,

280
00:09:15,600 --> 00:09:19,346
and just the language intelligence

281
00:09:19,346 --> 00:09:20,850
of the whole thing.

282
00:09:20,850 --> 00:09:23,490
You could do emails, summaries,

283
00:09:23,490 --> 00:09:26,670
blogs, content creation

284
00:09:26,670 --> 00:09:28,803
in seconds instead of hours.

285
00:09:29,970 --> 00:09:34,361
Excel formulas, code
reviews, code rewrites,

286
00:09:34,361 --> 00:09:37,071
such wide range of application

287
00:09:37,071 --> 00:09:39,720
towards knowledge work.

288
00:09:39,720 --> 00:09:41,850
So the "why" was very quickly answered

289
00:09:41,850 --> 00:09:44,266
right from the onset in terms of

290
00:09:44,266 --> 00:09:47,070
its very compelling value proposition

291
00:09:47,070 --> 00:09:49,730
of "Why would we look to use it?"

292
00:09:49,730 --> 00:09:53,212
So this almost near vertical graph

293
00:09:53,212 --> 00:09:56,217
of GenAI doesn't surprise me.

294
00:09:56,217 --> 00:09:57,540
In fact, as Midge said,

295
00:09:57,540 --> 00:09:58,373
you'd be hard pressed

296
00:09:58,373 --> 00:09:59,940
to find an organization

297
00:09:59,940 --> 00:10:01,392
that's operating in cloud today

298
00:10:01,392 --> 00:10:04,860
and is not doing something with GenAI.

299
00:10:04,860 --> 00:10:06,600
Would you all agree?

300
00:10:06,600 --> 00:10:08,015
Yeah?

301
00:10:08,015 --> 00:10:09,837
So let's talk about the "what?"

302
00:10:09,837 --> 00:10:11,329
The economic environment in which

303
00:10:11,329 --> 00:10:13,053
this is likely to operate.

304
00:10:15,955 --> 00:10:17,640
The prices at which

305
00:10:17,640 --> 00:10:20,760
this technology is being
offered are plummeting.

306
00:10:20,760 --> 00:10:22,170
Look at the graph in purple

307
00:10:22,170 --> 00:10:23,853
for ChatGPT-4.

308
00:10:25,020 --> 00:10:26,400
Every step down is

309
00:10:26,400 --> 00:10:29,319
on a logarithmic scale.

310
00:10:29,319 --> 00:10:32,283
So within a period of 18 months,

311
00:10:32,283 --> 00:10:35,913
it's come down 100 times.

312
00:10:38,220 --> 00:10:39,303
100 times.

313
00:10:41,841 --> 00:10:44,528
Midge, microeconomics 101,

314
00:10:44,528 --> 00:10:46,406
when prices go down,

315
00:10:46,406 --> 00:10:48,175
what happens to demand?

316
00:10:48,175 --> 00:10:49,290
- I think it normally goes up,

317
00:10:49,290 --> 00:10:51,960
right?
- Yes, right.

318
00:10:51,960 --> 00:10:52,830
Demand goes up.

319
00:10:52,830 --> 00:10:54,530
Price elasticity of demand, right?

320
00:10:55,725 --> 00:10:58,650
So there's this growing expectation.

321
00:10:58,650 --> 00:11:00,030
Already there's so much demand.

322
00:11:00,030 --> 00:11:00,930
Almost every CEO,

323
00:11:00,930 --> 00:11:02,190
we saw that investment,

324
00:11:02,190 --> 00:11:04,680
is willing to put the money out there.

325
00:11:04,680 --> 00:11:06,210
And that's kind of where we are hearing

326
00:11:06,210 --> 00:11:08,669
all the supply side being shored up

327
00:11:08,669 --> 00:11:10,770
by these billions and trillions

328
00:11:10,770 --> 00:11:12,570
of dollars of deal to build

329
00:11:12,570 --> 00:11:14,287
these big data centers and whatnot

330
00:11:14,287 --> 00:11:16,083
to meet that demand.

331
00:11:17,769 --> 00:11:20,457
Some of these deals are so big

332
00:11:20,457 --> 00:11:22,778
that a billion sometimes sounds

333
00:11:22,778 --> 00:11:23,973
like a million.

334
00:11:26,430 --> 00:11:27,630
And add to that

335
00:11:27,630 --> 00:11:31,170
the idea of research being done

336
00:11:31,170 --> 00:11:33,810
by firms like DeepSeek,

337
00:11:33,810 --> 00:11:35,700
using model distillation

338
00:11:35,700 --> 00:11:37,320
and whatever techniques,

339
00:11:37,320 --> 00:11:38,340
and investments happening

340
00:11:38,340 --> 00:11:40,080
all over the world,

341
00:11:40,080 --> 00:11:41,816
not just in US and China,

342
00:11:41,816 --> 00:11:43,042
we can say

343
00:11:43,042 --> 00:11:46,020
that the economic environment suggests

344
00:11:46,020 --> 00:11:48,481
that this technology is very likely

345
00:11:48,481 --> 00:11:52,209
to be available to us

346
00:11:52,209 --> 00:11:56,186
abundantly, reliably, economically

347
00:11:56,186 --> 00:11:57,723
at a global scale.

348
00:12:00,145 --> 00:12:02,400
- Couple thoughts about that, JJ.

349
00:12:02,400 --> 00:12:05,250
So first thought is...

350
00:12:05,250 --> 00:12:06,840
Actually, just go back

351
00:12:06,840 --> 00:12:07,830
for one second.
- Yep.

352
00:12:07,830 --> 00:12:09,600
- So the first thought is

353
00:12:09,600 --> 00:12:11,970
that this is definitely pushing

354
00:12:11,970 --> 00:12:14,490
towards commoditory territory.

355
00:12:14,490 --> 00:12:18,480
This GenAI technology
is being commoditized.

356
00:12:18,480 --> 00:12:19,313
- Yep.

357
00:12:19,313 --> 00:12:20,146
- A little bit like electricity,

358
00:12:20,146 --> 00:12:20,979
which I think we'll talk about

359
00:12:20,979 --> 00:12:21,812
in a moment.

360
00:12:21,812 --> 00:12:23,098
The other thing that comes to mind,

361
00:12:23,098 --> 00:12:25,530
just seeing these charts of these costs

362
00:12:25,530 --> 00:12:27,729
just dropping precipitously,

363
00:12:27,729 --> 00:12:30,544
is Moore's Law being turbocharged.

364
00:12:30,544 --> 00:12:32,589
So we're used to Moore's Law

365
00:12:32,589 --> 00:12:35,210
where the cost of computing power is going

366
00:12:35,210 --> 00:12:37,256
to be dropping by half

367
00:12:37,256 --> 00:12:39,330
about every 18 months to two years.

368
00:12:39,330 --> 00:12:41,610
That's been the case for decades.

369
00:12:41,610 --> 00:12:43,238
And just to see these charts go

370
00:12:43,238 --> 00:12:45,709
like this is incredible.

371
00:12:45,709 --> 00:12:47,434
And so, we're sort of seeing,

372
00:12:47,434 --> 00:12:49,260
instead of being 18 months

373
00:12:49,260 --> 00:12:50,640
to two years,

374
00:12:50,640 --> 00:12:51,473
we're seeing it be more

375
00:12:51,473 --> 00:12:53,850
like two months to three months.

376
00:12:53,850 --> 00:12:54,960
And the compounding effect

377
00:12:54,960 --> 00:12:57,180
of that is just huge.

378
00:12:57,180 --> 00:12:58,080
And so, that's why we're seeing

379
00:12:58,080 --> 00:12:59,183
this sort of...

380
00:12:59,183 --> 00:13:01,080
The cost really dropping--
- Absolutely.

381
00:13:01,080 --> 00:13:02,100
- This commoditization that

382
00:13:02,100 --> 00:13:02,933
you're touching on--

383
00:13:02,933 --> 00:13:03,766
- Yep.
- Hitting.

384
00:13:03,766 --> 00:13:04,599
And so, yeah,

385
00:13:04,599 --> 00:13:05,432
it reminds me of the commoditization

386
00:13:05,432 --> 00:13:06,754
or something like electricity.
- Great.

387
00:13:06,754 --> 00:13:09,210
I think you're in some very elite company

388
00:13:09,210 --> 00:13:11,280
when you compare this to electricity.

389
00:13:11,280 --> 00:13:13,928
Industry stalwarts, like Andrew Ng,

390
00:13:13,928 --> 00:13:15,849
have predicted exactly that,

391
00:13:15,849 --> 00:13:16,980
is that this would be

392
00:13:16,980 --> 00:13:20,712
as transformative as electricity was.

393
00:13:20,712 --> 00:13:23,839
But what that comparison also does is

394
00:13:23,839 --> 00:13:25,402
it gives us a roadmap

395
00:13:25,402 --> 00:13:27,960
to answer the third part, the "how."

396
00:13:27,960 --> 00:13:29,940
How are we gonna adopt to this?

397
00:13:29,940 --> 00:13:30,773
Right?

398
00:13:33,234 --> 00:13:35,385
Leading researchers in this area,

399
00:13:35,385 --> 00:13:37,769
like Dr. Ajay Agrawal and others,

400
00:13:37,769 --> 00:13:39,840
have published a lot of good research

401
00:13:39,840 --> 00:13:42,120
that shows parallels

402
00:13:42,120 --> 00:13:45,390
between electricity and AI.

403
00:13:45,390 --> 00:13:48,420
And they posit that
electricity transformed

404
00:13:48,420 --> 00:13:50,403
the world in three stages,

405
00:13:51,508 --> 00:13:53,767
or you could consider that

406
00:13:53,767 --> 00:13:55,563
at three different scales.

407
00:13:56,561 --> 00:13:59,038
The first, as a point solution,

408
00:13:59,038 --> 00:14:00,510
was quite simple:

409
00:14:00,510 --> 00:14:01,740
Replacing steam.

410
00:14:01,740 --> 00:14:03,150
You took the steam engine out,

411
00:14:03,150 --> 00:14:04,860
you put electrical generator in.

412
00:14:04,860 --> 00:14:06,570
Everything else about your factory remains

413
00:14:06,570 --> 00:14:07,800
exactly the same.

414
00:14:07,800 --> 00:14:09,762
You produce the same output,

415
00:14:09,762 --> 00:14:12,810
you just now have a cheaper, cleaner fuel,

416
00:14:12,810 --> 00:14:14,360
and you've unlocked some value.

417
00:14:16,235 --> 00:14:19,234
As knowledge of using
electricity improved,

418
00:14:19,234 --> 00:14:21,960
tooling start to improve as well.

419
00:14:21,960 --> 00:14:25,239
Lathes, mills, drills started having

420
00:14:25,239 --> 00:14:27,600
these small, small electrical motors.

421
00:14:27,600 --> 00:14:29,160
And so, now, you could fractionalize

422
00:14:29,160 --> 00:14:31,140
your manufacturing by turning

423
00:14:31,140 --> 00:14:33,387
those individual machines on and off.

424
00:14:33,387 --> 00:14:35,190
And that meant you are

425
00:14:35,190 --> 00:14:36,437
now paying for power

426
00:14:36,437 --> 00:14:39,084
only when you were using it.

427
00:14:39,084 --> 00:14:41,703
And that unlocked a little more value.

428
00:14:42,952 --> 00:14:45,420
And then, the architects started to look

429
00:14:45,420 --> 00:14:46,410
at the unique properties

430
00:14:46,410 --> 00:14:48,153
of electricity and realized

431
00:14:48,153 --> 00:14:50,499
that we could transfer power

432
00:14:50,499 --> 00:14:52,560
from one corner of the factory

433
00:14:52,560 --> 00:14:54,180
to another using these

434
00:14:54,180 --> 00:14:56,295
very small cables.

435
00:14:56,295 --> 00:14:57,875
And that gave them

436
00:14:57,875 --> 00:14:59,761
the design flexibility

437
00:14:59,761 --> 00:15:01,717
to start putting machines

438
00:15:01,717 --> 00:15:04,738
in the order of the completion

439
00:15:04,738 --> 00:15:06,331
of the process rather than

440
00:15:06,331 --> 00:15:10,295
their power intensiveness
and consumptiveness.

441
00:15:10,295 --> 00:15:11,732
And that gave us

442
00:15:11,732 --> 00:15:15,775
the single greatest productivity invention

443
00:15:15,775 --> 00:15:17,343
of the 20th century:

444
00:15:18,450 --> 00:15:19,950
The assembly line.

445
00:15:19,950 --> 00:15:21,837
It optimized the whole factory

446
00:15:21,837 --> 00:15:23,193
for the flow.

447
00:15:24,337 --> 00:15:28,034
If we take that analogy towards AI

448
00:15:28,034 --> 00:15:29,664
and see some parallels,

449
00:15:29,664 --> 00:15:30,960
we are already seeing a lot

450
00:15:30,960 --> 00:15:32,070
of use cases that talk

451
00:15:32,070 --> 00:15:33,720
about task substitution.

452
00:15:33,720 --> 00:15:35,337
Clearly, this thing is far better,

453
00:15:35,337 --> 00:15:38,259
cheaper, and faster at some other things

454
00:15:38,259 --> 00:15:40,249
than most humans.

455
00:15:40,249 --> 00:15:42,153
And we're seeing all kinds

456
00:15:42,153 --> 00:15:43,650
of content creation;

457
00:15:43,650 --> 00:15:45,600
first drafts, business writing,

458
00:15:45,600 --> 00:15:47,790
great examples of where we are leveraging

459
00:15:47,790 --> 00:15:49,800
this task substitution type

460
00:15:49,800 --> 00:15:52,113
of value creation with this technology.

461
00:15:53,168 --> 00:15:54,732
Take it a step further,

462
00:15:54,732 --> 00:15:57,530
and we are also looking at areas...

463
00:16:01,447 --> 00:16:02,520
Thanks.

464
00:16:02,520 --> 00:16:03,780
And we are also looking at areas

465
00:16:03,780 --> 00:16:06,330
where we are augmenting human and AI,

466
00:16:06,330 --> 00:16:07,770
with the idea being that

467
00:16:07,770 --> 00:16:09,870
the human expert focuses more

468
00:16:09,870 --> 00:16:11,182
on high value activities

469
00:16:11,182 --> 00:16:13,863
and AI does the leg work.

470
00:16:14,812 --> 00:16:17,173
Good examples would be in medicine.

471
00:16:17,173 --> 00:16:20,149
Diagnostics can be predicted much better

472
00:16:20,149 --> 00:16:21,851
with AI technology now.

473
00:16:21,851 --> 00:16:23,640
And the doctor can focus

474
00:16:23,640 --> 00:16:26,340
on treatment considerations individualized

475
00:16:26,340 --> 00:16:27,630
to each patient,

476
00:16:27,630 --> 00:16:29,550
and thereby you get a better output

477
00:16:29,550 --> 00:16:32,103
and outcome for the patients.

478
00:16:34,939 --> 00:16:36,960
And I know this conference has been

479
00:16:36,960 --> 00:16:38,460
a lot about agentic

480
00:16:38,460 --> 00:16:39,900
and what agents can do

481
00:16:39,900 --> 00:16:41,010
by orchestrating things

482
00:16:41,010 --> 00:16:42,990
between themselves, et cetera, et cetera.

483
00:16:42,990 --> 00:16:44,520
But in the long run,

484
00:16:44,520 --> 00:16:46,251
what may be possible is

485
00:16:46,251 --> 00:16:47,850
possibly anybody's guess

486
00:16:47,850 --> 00:16:49,742
at this point in time.

487
00:16:49,742 --> 00:16:52,410
But one thread that's clear is that

488
00:16:52,410 --> 00:16:55,910
all of that is going to evolve rapidly,

489
00:16:55,910 --> 00:16:58,470
and in ways that may not be

490
00:16:58,470 --> 00:17:01,230
very directly imaginable today.

491
00:17:01,230 --> 00:17:04,523
Just like it was quite unimaginable

492
00:17:04,523 --> 00:17:06,060
to consider that

493
00:17:06,060 --> 00:17:07,920
a whole city would be powered

494
00:17:07,920 --> 00:17:10,010
by one power station.

495
00:17:10,010 --> 00:17:11,823
Electricity made that possible.

496
00:17:14,040 --> 00:17:16,440
But taking this to FinOps,

497
00:17:16,440 --> 00:17:17,520
what are the considerations

498
00:17:17,520 --> 00:17:19,170
for FinOps here?

499
00:17:19,170 --> 00:17:20,274
Right?

500
00:17:20,274 --> 00:17:22,080
From a FinOps standpoint,

501
00:17:22,080 --> 00:17:23,640
what we need to think about is

502
00:17:23,640 --> 00:17:25,860
I gave the example at
three different scales,

503
00:17:25,860 --> 00:17:28,260
point, application, and system,

504
00:17:28,260 --> 00:17:29,785
and your cost

505
00:17:29,785 --> 00:17:32,706
and governance considerations move

506
00:17:32,706 --> 00:17:34,980
very non-linearly at these

507
00:17:34,980 --> 00:17:36,384
three different scales.

508
00:17:36,384 --> 00:17:38,730
And so, when FinOps practices think

509
00:17:38,730 --> 00:17:41,400
about value versus cost,

510
00:17:41,400 --> 00:17:43,560
that's the key thing that
they need to consider,

511
00:17:43,560 --> 00:17:45,147
is what are the cost drivers

512
00:17:45,147 --> 00:17:47,692
and how would they scale?

513
00:17:47,692 --> 00:17:50,225
As they use it scales, right?

514
00:17:50,225 --> 00:17:52,233
So let's look at that next.

515
00:17:54,709 --> 00:17:56,526
Midge, do you drive a car?

516
00:17:56,526 --> 00:17:58,620
- Sorry?
- Do you drive a car?

517
00:17:58,620 --> 00:17:59,820
- I do drive a car.
- Great.

518
00:17:59,820 --> 00:18:01,440
It's got some running expenses,

519
00:18:01,440 --> 00:18:02,687
I suppose?
- It certainly does.

520
00:18:02,687 --> 00:18:03,900
- What would you say is

521
00:18:03,900 --> 00:18:06,630
the topmost running expense

522
00:18:06,630 --> 00:18:07,999
from your perspective?

523
00:18:07,999 --> 00:18:09,480
- I would say it's petrol.

524
00:18:09,480 --> 00:18:10,320
- Petrol?
- Yep.

525
00:18:10,320 --> 00:18:11,153
- Great.

526
00:18:11,153 --> 00:18:11,986
What would be some of

527
00:18:11,986 --> 00:18:13,110
your other running expenses

528
00:18:13,110 --> 00:18:13,998
that come to mind?

529
00:18:13,998 --> 00:18:15,333
- Insurance.
- Yep.

530
00:18:15,333 --> 00:18:17,190
- Registration.
- Yep.

531
00:18:17,190 --> 00:18:18,177
- Tires.
- Yep.

532
00:18:18,177 --> 00:18:19,840
- Servicing.
- Yep.

533
00:18:19,840 --> 00:18:22,710
- I think that's about it.
- Yep.

534
00:18:22,710 --> 00:18:24,150
Okay, great, wonderful.

535
00:18:24,150 --> 00:18:25,456
How about parking?

536
00:18:25,456 --> 00:18:27,420
- Occasionally.
- Occasionally?

537
00:18:27,420 --> 00:18:29,086
- Yes.
- How about infringement?

538
00:18:29,086 --> 00:18:30,310
- Not for a while.

539
00:18:30,310 --> 00:18:31,848
Not for a while.
- That's good.

540
00:18:31,848 --> 00:18:33,240
- Yeah.
- That's good.

541
00:18:33,240 --> 00:18:34,710
Why I was just teasing that out is,

542
00:18:34,710 --> 00:18:35,543
as you see,

543
00:18:35,543 --> 00:18:37,431
when we think about the running cost,

544
00:18:37,431 --> 00:18:39,210
we usually think about

545
00:18:39,210 --> 00:18:41,147
the most consumptive element of it.

546
00:18:41,147 --> 00:18:44,370
But when you look at the scale of things,

547
00:18:44,370 --> 00:18:46,344
there are so many other
contributing factors.

548
00:18:46,344 --> 00:18:47,640
And if you consider

549
00:18:47,640 --> 00:18:50,077
just that example of driving car,

550
00:18:50,077 --> 00:18:51,780
your fuel cost may be worth

551
00:18:51,780 --> 00:18:52,710
like 200 a month,

552
00:18:52,710 --> 00:18:54,354
but once you add all the rest of it up,

553
00:18:54,354 --> 00:18:56,673
it's a sizable amount, yeah?

554
00:18:56,673 --> 00:18:58,257
So let's look at what

555
00:18:58,257 --> 00:19:00,201
the cost drivers for GenAI are,

556
00:19:00,201 --> 00:19:03,483
and just keep that perspective of it.

557
00:19:04,703 --> 00:19:06,360
So what the industry calls

558
00:19:06,360 --> 00:19:08,682
as "inference" is basically

559
00:19:08,682 --> 00:19:10,923
a user, in simple terms,

560
00:19:10,923 --> 00:19:13,260
using an application, sends a prompt,

561
00:19:13,260 --> 00:19:14,340
gets a response back,

562
00:19:14,340 --> 00:19:15,445
you meter that

563
00:19:15,445 --> 00:19:18,319
and you get some kind
of token consumption.

564
00:19:18,319 --> 00:19:20,293
And based on the price of the token,

565
00:19:20,293 --> 00:19:23,223
you get some kind of token cost, right?

566
00:19:26,100 --> 00:19:27,835
But that inference is more like

567
00:19:27,835 --> 00:19:30,704
the tip of the iceberg.

568
00:19:30,704 --> 00:19:32,785
What's underneath that is

569
00:19:32,785 --> 00:19:34,290
to make that happen,

570
00:19:34,290 --> 00:19:35,220
you would still have

571
00:19:35,220 --> 00:19:36,420
all these other costs

572
00:19:36,420 --> 00:19:37,780
in your cloud environments

573
00:19:39,235 --> 00:19:42,810
across production, staging, and dev.

574
00:19:42,810 --> 00:19:43,643
And if you're building

575
00:19:43,643 --> 00:19:45,060
and training your own models,

576
00:19:45,060 --> 00:19:46,244
there'll be even more cost

577
00:19:46,244 --> 00:19:49,743
to get that up and running in cloud.

578
00:19:51,990 --> 00:19:54,022
But that's not all.

579
00:19:54,022 --> 00:19:58,083
How about security, design, observability,

580
00:19:59,138 --> 00:20:01,023
support and maintenance?

581
00:20:02,700 --> 00:20:05,070
How about product management?

582
00:20:05,070 --> 00:20:05,970
How do you get your users

583
00:20:05,970 --> 00:20:08,160
to use it, enablement?

584
00:20:08,160 --> 00:20:09,746
All of these are

585
00:20:09,746 --> 00:20:11,925
very genuine elements

586
00:20:11,925 --> 00:20:14,974
of getting to value,

587
00:20:14,974 --> 00:20:18,540
and many of them may respond

588
00:20:18,540 --> 00:20:22,893
very differently as your solutions scale.

589
00:20:25,128 --> 00:20:27,570
A few slides back, we saw how

590
00:20:27,570 --> 00:20:29,400
the inference cost is coming down

591
00:20:29,400 --> 00:20:31,740
because of the model unit pricing coming

592
00:20:31,740 --> 00:20:33,250
down that much.

593
00:20:33,250 --> 00:20:35,040
Well, what do you think is happening

594
00:20:35,040 --> 00:20:36,783
to some of these other elements?

595
00:20:38,154 --> 00:20:41,101
Do you reckon any of them are going up

596
00:20:41,101 --> 00:20:43,443
instead of coming down?

597
00:20:45,570 --> 00:20:48,930
How about the talent required

598
00:20:48,930 --> 00:20:50,433
to do these activities?

599
00:20:52,687 --> 00:20:53,520
Right?

600
00:20:53,520 --> 00:20:54,960
So there's a lot to think about,

601
00:20:54,960 --> 00:20:57,170
like "Where are our biggest cost risks

602
00:20:57,170 --> 00:21:00,562
"and governance controls would need to be

603
00:21:00,562 --> 00:21:03,210
"to stay on top of this thing?"

604
00:21:03,210 --> 00:21:04,823
- Yeah.
- Right?

605
00:21:04,823 --> 00:21:07,680
So keep these elements in mind

606
00:21:07,680 --> 00:21:09,150
as I talk to you about one

607
00:21:09,150 --> 00:21:11,123
of our success stories with GenAI.

608
00:21:13,530 --> 00:21:15,960
So as Chat-GPT, OpenAI,

609
00:21:15,960 --> 00:21:20,370
came out towards end of 2022, early 2023,

610
00:21:20,370 --> 00:21:22,620
many member firm countries started

611
00:21:22,620 --> 00:21:26,340
to explore this wonderful new technology

612
00:21:26,340 --> 00:21:29,763
that provided so much
potential to innovate.

613
00:21:31,240 --> 00:21:33,000
And they kept going at it

614
00:21:33,000 --> 00:21:34,113
for about a year.

615
00:21:35,310 --> 00:21:37,947
And about March, 2024,

616
00:21:37,947 --> 00:21:39,382
they started comparing

617
00:21:39,382 --> 00:21:41,692
some of their notes.

618
00:21:41,692 --> 00:21:44,460
And they found that, eventually,

619
00:21:44,460 --> 00:21:46,954
they had built something very similar

620
00:21:46,954 --> 00:21:49,140
because the underlying use case was

621
00:21:49,140 --> 00:21:50,047
quite the same.

622
00:21:50,047 --> 00:21:51,727
"How do we get our workforce

623
00:21:51,727 --> 00:21:52,717
"to be more productive?

624
00:21:52,717 --> 00:21:54,353
"How do we get our consulting teams

625
00:21:54,353 --> 00:21:56,227
"to be more productive

626
00:21:56,227 --> 00:21:57,870
"in their engagements?"

627
00:21:57,870 --> 00:21:59,340
And typically, all around

628
00:21:59,340 --> 00:22:00,930
those three examples that I showed,

629
00:22:00,930 --> 00:22:04,920
chat, search, and...

630
00:22:04,920 --> 00:22:06,570
Sorry, the the third one being...

631
00:22:07,530 --> 00:22:08,720
Chat, search, and...

632
00:22:09,750 --> 00:22:10,583
Sorry.

633
00:22:11,970 --> 00:22:14,220
Chat, search.

634
00:22:14,220 --> 00:22:15,390
And I'll just go back and see

635
00:22:15,390 --> 00:22:16,230
what the third one is.

636
00:22:16,230 --> 00:22:17,380
Translation, thank you.

637
00:22:19,898 --> 00:22:21,557
But they also realized that

638
00:22:21,557 --> 00:22:22,620
they were facing some

639
00:22:22,620 --> 00:22:24,240
very common challenges.

640
00:22:24,240 --> 00:22:26,880
Challenges around deployment,

641
00:22:26,880 --> 00:22:28,470
support and maintenance,

642
00:22:28,470 --> 00:22:29,793
release maintenance,

643
00:22:31,041 --> 00:22:33,390
enablement, adoption.

644
00:22:33,390 --> 00:22:35,130
Our surveys indicated that

645
00:22:35,130 --> 00:22:37,650
many of our own people,

646
00:22:37,650 --> 00:22:38,760
as well as the clients,

647
00:22:38,760 --> 00:22:41,403
were a little skeptical

648
00:22:41,403 --> 00:22:44,343
of using AI-generated outputs.

649
00:22:45,442 --> 00:22:47,797
But the key question was,

650
00:22:47,797 --> 00:22:49,397
"Should we continue down

651
00:22:49,397 --> 00:22:52,537
"the individual path track,

652
00:22:52,537 --> 00:22:54,037
"investing time, effort,

653
00:22:54,037 --> 00:22:56,767
"and money in our silos,

654
00:22:56,767 --> 00:22:58,597
"or are there economies of scale

655
00:22:58,597 --> 00:23:00,177
"and scope to be unlocked?"

656
00:23:02,135 --> 00:23:05,100
And the answer to that was

657
00:23:05,100 --> 00:23:06,637
the genesis of what we call

658
00:23:06,637 --> 00:23:09,090
"the KPMG workbench,"

659
00:23:09,090 --> 00:23:13,590
envisaged as a globally available platform

660
00:23:13,590 --> 00:23:17,867
that would enable many, many applications

661
00:23:17,867 --> 00:23:20,812
to leverage GenAI offerings

662
00:23:20,812 --> 00:23:23,613
in a provider-agnostic manner.

663
00:23:25,584 --> 00:23:28,380
And the role that FinOps had to play

664
00:23:28,380 --> 00:23:30,882
in such a global scale is

665
00:23:30,882 --> 00:23:32,580
to be highly strategic

666
00:23:32,580 --> 00:23:33,780
in terms of engaging with

667
00:23:33,780 --> 00:23:35,502
the stakeholders and understand

668
00:23:35,502 --> 00:23:37,080
that once we go to this

669
00:23:37,080 --> 00:23:38,695
global level of scale,

670
00:23:38,695 --> 00:23:41,550
how are we going to invest in this?

671
00:23:41,550 --> 00:23:43,244
How are we going to fund this?

672
00:23:43,244 --> 00:23:44,760
What are the initiatives

673
00:23:44,760 --> 00:23:46,320
that are being taken

674
00:23:46,320 --> 00:23:47,860
to onboard countries,

675
00:23:47,860 --> 00:23:50,670
to bring on developers?

676
00:23:50,670 --> 00:23:52,140
And working with these teams

677
00:23:52,140 --> 00:23:54,728
to understand what timeline

678
00:23:54,728 --> 00:23:57,030
this will scale at.

679
00:23:57,030 --> 00:23:58,923
And how would we then price it?

680
00:24:00,390 --> 00:24:02,162
We often think of chargeback

681
00:24:02,162 --> 00:24:05,304
as a mechanism wherein

682
00:24:05,304 --> 00:24:06,810
we are looking at whatever

683
00:24:06,810 --> 00:24:08,296
it's costing us,

684
00:24:08,296 --> 00:24:10,170
and then finding a fair

685
00:24:10,170 --> 00:24:11,003
and reasonable way

686
00:24:11,003 --> 00:24:13,628
of distributing that onto the users

687
00:24:13,628 --> 00:24:15,900
so that it's cost neutral

688
00:24:15,900 --> 00:24:17,880
to offer for technology teams,

689
00:24:17,880 --> 00:24:20,550
and also so that the user can see

690
00:24:20,550 --> 00:24:21,994
what it's costing and they can make

691
00:24:21,994 --> 00:24:23,463
a judgment on the value.

692
00:24:24,703 --> 00:24:27,780
But when you take a strategic view,

693
00:24:27,780 --> 00:24:28,950
you have to consider,

694
00:24:28,950 --> 00:24:29,820
you don't come up with

695
00:24:29,820 --> 00:24:31,620
a chargeback program

696
00:24:31,620 --> 00:24:32,453
where you're asking

697
00:24:32,453 --> 00:24:35,149
the first passenger to buy the bus.

698
00:24:35,149 --> 00:24:36,519
This thing will scale

699
00:24:36,519 --> 00:24:38,198
at a certain time

700
00:24:38,198 --> 00:24:40,020
to a certain level,

701
00:24:40,020 --> 00:24:41,006
and then only

702
00:24:41,006 --> 00:24:45,723
those unit cost will make sense to apply.

703
00:24:48,900 --> 00:24:50,430
So roll this forward

704
00:24:50,430 --> 00:24:51,633
to where we are today.

705
00:24:53,220 --> 00:24:54,745
Sorry.

706
00:24:54,745 --> 00:24:58,710
And today, KPMG Work Ventures is available

707
00:24:58,710 --> 00:25:02,250
across 100 plus member firm countries.

708
00:25:02,250 --> 00:25:06,120
It's onboarded over 100,000 users,

709
00:25:06,120 --> 00:25:08,227
hundreds of developers,

710
00:25:08,227 --> 00:25:11,820
30 plus applications.

711
00:25:11,820 --> 00:25:12,900
We are about to go live

712
00:25:12,900 --> 00:25:15,360
with 12 modular agents,

713
00:25:15,360 --> 00:25:16,893
hundreds more in development,

714
00:25:17,777 --> 00:25:21,360
enabling multiple teams

715
00:25:21,360 --> 00:25:23,155
across multiple countries

716
00:25:23,155 --> 00:25:28,155
in a globally secure, safe, data governed,

717
00:25:28,595 --> 00:25:31,351
data sovereign environments

718
00:25:31,351 --> 00:25:34,302
to leverage this great technology,

719
00:25:34,302 --> 00:25:36,920
and improve their engagements

720
00:25:36,920 --> 00:25:40,113
both internally as well
as with the clients.

721
00:25:41,760 --> 00:25:45,030
So that's the scale of what's possible,

722
00:25:45,030 --> 00:25:46,530
and we have a long way to go.

723
00:25:46,530 --> 00:25:47,880
We've just started.

724
00:25:47,880 --> 00:25:48,870
It's just been a journey

725
00:25:48,870 --> 00:25:50,103
of about 18 months.

726
00:25:54,480 --> 00:25:55,313
But there's...

727
00:25:55,313 --> 00:25:56,730
As there's so much more to do,

728
00:25:56,730 --> 00:25:57,930
what I would say is,

729
00:25:57,930 --> 00:26:00,150
as Midge talks to you about some

730
00:26:00,150 --> 00:26:02,940
of the deployment options next,

731
00:26:02,940 --> 00:26:04,626
please consider this idea

732
00:26:04,626 --> 00:26:07,470
of what's critical to your organizations

733
00:26:07,470 --> 00:26:10,164
as you leverage this at this scale

734
00:26:10,164 --> 00:26:12,390
that it's potentially possible

735
00:26:12,390 --> 00:26:13,223
to leverage at.

736
00:26:14,940 --> 00:26:15,773
- Awesome.

737
00:26:18,510 --> 00:26:20,010
So strap yourself in,

738
00:26:20,010 --> 00:26:20,910
we're gonna go through

739
00:26:20,910 --> 00:26:22,620
some implementation details,

740
00:26:22,620 --> 00:26:24,360
the trade-offs that
you're gonna look to make,

741
00:26:24,360 --> 00:26:25,193
and then we're gonna dive

742
00:26:25,193 --> 00:26:27,390
into some FinOps practices

743
00:26:27,390 --> 00:26:28,740
that we will apply here.

744
00:26:28,740 --> 00:26:30,059
So...

745
00:26:30,059 --> 00:26:31,920
Yeah, so walking through the three

746
00:26:31,920 --> 00:26:33,784
main ways organizations deploy

747
00:26:33,784 --> 00:26:35,847
Generative AI today,

748
00:26:35,847 --> 00:26:39,133
so SaaS, PaaS, and IaaS.

749
00:26:39,133 --> 00:26:40,431
These are undoubtedly

750
00:26:40,431 --> 00:26:42,396
familiar cloud patterns,

751
00:26:42,396 --> 00:26:45,300
but the trade-offs for GenAI are

752
00:26:45,300 --> 00:26:46,740
extremely important,

753
00:26:46,740 --> 00:26:47,970
so we'll go through those.

754
00:26:47,970 --> 00:26:49,202
So starting on the left,

755
00:26:49,202 --> 00:26:51,120
with SaaS APIs,

756
00:26:51,120 --> 00:26:53,550
these include providers like OpenAI,

757
00:26:53,550 --> 00:26:56,031
Anthropic, and Cohere.

758
00:26:56,031 --> 00:26:57,420
You get instant access

759
00:26:57,420 --> 00:26:58,975
to powerful foundation models

760
00:26:58,975 --> 00:27:01,241
with almost no setup.

761
00:27:01,241 --> 00:27:04,050
You're typically charged per token

762
00:27:04,050 --> 00:27:05,700
or per API call,

763
00:27:05,700 --> 00:27:09,365
so costs scale very cleanly with usage.

764
00:27:09,365 --> 00:27:12,060
A major advantage is the ecosystem

765
00:27:12,060 --> 00:27:13,342
of out-of-the-box tools

766
00:27:13,342 --> 00:27:15,679
these providers offer.

767
00:27:15,679 --> 00:27:18,619
So things like built-in chat interfaces,

768
00:27:18,619 --> 00:27:21,840
coding assistance, productivity apps,

769
00:27:21,840 --> 00:27:23,746
this all comes with it.

770
00:27:23,746 --> 00:27:24,612
But, so...

771
00:27:24,612 --> 00:27:26,040
If sharing data with

772
00:27:26,040 --> 00:27:27,741
a third party isn't a concern

773
00:27:27,741 --> 00:27:30,611
and you don't need deep customization,

774
00:27:30,611 --> 00:27:32,515
this SaaS API is

775
00:27:32,515 --> 00:27:34,479
a very compelling option.

776
00:27:34,479 --> 00:27:35,850
And I know talking from

777
00:27:35,850 --> 00:27:37,440
our own head of AI,

778
00:27:37,440 --> 00:27:39,225
on the Cloudability side,

779
00:27:39,225 --> 00:27:41,160
there are many scenarios we would love

780
00:27:41,160 --> 00:27:42,400
to take this approach

781
00:27:42,400 --> 00:27:44,250
'cause it just comes with all of

782
00:27:44,250 --> 00:27:45,447
these bells and whistles

783
00:27:45,447 --> 00:27:47,165
for free in a sense.

784
00:27:47,165 --> 00:27:48,750
But if sharing your data

785
00:27:48,750 --> 00:27:50,959
with a third party is an issue,

786
00:27:50,959 --> 00:27:52,994
or if you need to do a
lot of customization,

787
00:27:52,994 --> 00:27:54,594
it's just not gonna be possible.

788
00:27:55,950 --> 00:27:57,386
In the middle, we have PaaS.

789
00:27:57,386 --> 00:27:59,220
So PaaS for AWS,

790
00:27:59,220 --> 00:28:00,127
that comprises two services

791
00:28:00,127 --> 00:28:01,440
and we're gonna talk a lot

792
00:28:01,440 --> 00:28:02,610
about those in a moment.

793
00:28:02,610 --> 00:28:03,900
So they are SageMaker...

794
00:28:03,900 --> 00:28:06,543
Amazon SageMaker and Amazon Bedrock.

795
00:28:06,543 --> 00:28:08,700
This gives you more flexibility,

796
00:28:08,700 --> 00:28:10,290
compared to SaaS,

797
00:28:10,290 --> 00:28:11,520
while still offloading

798
00:28:11,520 --> 00:28:13,120
a lot of the operational burden.

799
00:28:13,956 --> 00:28:15,608
You can run pre-trained models,

800
00:28:15,608 --> 00:28:17,314
you can fine tune them,

801
00:28:17,314 --> 00:28:20,320
or you can even build your own.

802
00:28:20,320 --> 00:28:23,010
The good news is that AWS takes care

803
00:28:23,010 --> 00:28:23,940
of the scaling,

804
00:28:23,940 --> 00:28:25,955
the patching, and availability.

805
00:28:25,955 --> 00:28:28,620
You are charged based on usage.

806
00:28:28,620 --> 00:28:30,726
And crucially, you retain control

807
00:28:30,726 --> 00:28:32,733
of your data boundaries.

808
00:28:33,810 --> 00:28:35,790
And a really key point here is

809
00:28:35,790 --> 00:28:37,050
that there are quite a few

810
00:28:37,050 --> 00:28:40,260
very popular GenAI models.

811
00:28:40,260 --> 00:28:43,912
For example, like Claude 4, Amazon Titan.

812
00:28:43,912 --> 00:28:45,540
The only way you can actually run

813
00:28:45,540 --> 00:28:47,490
these models in AWS is

814
00:28:47,490 --> 00:28:48,323
to use Bedrock.

815
00:28:48,323 --> 00:28:49,156
It's the only option

816
00:28:49,156 --> 00:28:50,260
you have available to you.

817
00:28:51,911 --> 00:28:53,706
Finally, IAS on...

818
00:28:53,706 --> 00:28:55,636
IaaS on the right hand side.

819
00:28:55,636 --> 00:28:57,420
This is a self-hosted path

820
00:28:57,420 --> 00:29:00,293
and this centers around EC2, or EKS,

821
00:29:00,293 --> 00:29:01,860
where typically you're gonna run

822
00:29:01,860 --> 00:29:03,030
an open source model

823
00:29:03,030 --> 00:29:05,580
or run your own custom models.

824
00:29:05,580 --> 00:29:06,630
You have full control

825
00:29:06,630 --> 00:29:07,950
over the architecture,

826
00:29:07,950 --> 00:29:09,888
the scaling, optimization,

827
00:29:09,888 --> 00:29:11,560
the data handling.

828
00:29:11,560 --> 00:29:13,950
But of course, with that control comes

829
00:29:13,950 --> 00:29:15,500
all the operational complexity.

830
00:29:17,584 --> 00:29:20,108
Here, you're primarily paying

831
00:29:20,108 --> 00:29:22,623
for the provisioned EC2 instances,

832
00:29:22,623 --> 00:29:25,154
which are usually backed by GPUs.

833
00:29:25,154 --> 00:29:27,716
What you have is maximum flexibility,

834
00:29:27,716 --> 00:29:29,190
but also requires

835
00:29:29,190 --> 00:29:32,160
the most expertise from your side.

836
00:29:32,160 --> 00:29:33,090
So in summary,

837
00:29:33,090 --> 00:29:34,680
each deployment mode reflects

838
00:29:34,680 --> 00:29:36,160
a trade off between control,

839
00:29:36,160 --> 00:29:39,273
customization, and operational complexity.

840
00:29:41,833 --> 00:29:43,410
So now that we've looked

841
00:29:43,410 --> 00:29:44,551
at the three different ways

842
00:29:44,551 --> 00:29:46,454
that GenAI can be deployed,

843
00:29:46,454 --> 00:29:47,450
I wanna ground that

844
00:29:47,450 --> 00:29:48,540
in what we're seeing

845
00:29:48,540 --> 00:29:50,943
from our own customers on AWS.

846
00:29:52,020 --> 00:29:53,782
So let's just start on the left.

847
00:29:53,782 --> 00:29:55,290
This chart shows

848
00:29:55,290 --> 00:29:57,360
the EC2 instance spend breakdown

849
00:29:57,360 --> 00:29:59,309
across our customer base.

850
00:29:59,309 --> 00:30:01,170
What's interesting here is that

851
00:30:01,170 --> 00:30:03,840
about 15% of all EC2 spend is

852
00:30:03,840 --> 00:30:07,208
now on GPU-backed instances.

853
00:30:07,208 --> 00:30:09,385
We can't say that's entirely AI,

854
00:30:09,385 --> 00:30:11,193
some of it will be for HPC

855
00:30:11,193 --> 00:30:12,924
or graphics workloads,

856
00:30:12,924 --> 00:30:16,050
but a large portion of this growth is

857
00:30:16,050 --> 00:30:18,693
directly tied to GenAI adoption.

858
00:30:19,530 --> 00:30:20,363
And for me,

859
00:30:20,363 --> 00:30:23,290
that's a really striking number, 15%.

860
00:30:23,290 --> 00:30:27,128
GPU usage at this scale didn't exist

861
00:30:27,128 --> 00:30:28,799
a couple of years ago.

862
00:30:28,799 --> 00:30:30,120
And it just shows

863
00:30:30,120 --> 00:30:32,444
how quickly GenAI workloads have become

864
00:30:32,444 --> 00:30:36,390
a meaningful slice of our overall AWS

865
00:30:36,390 --> 00:30:38,917
and overall cloud spend.

866
00:30:38,917 --> 00:30:40,413
Now, on the right,

867
00:30:40,413 --> 00:30:42,151
we isolate spend that

868
00:30:42,151 --> 00:30:44,196
we know is associated with AI

869
00:30:44,196 --> 00:30:46,865
and compare GPU-backed instances

870
00:30:46,865 --> 00:30:49,433
to the managed services.

871
00:30:49,433 --> 00:30:50,615
What we see is

872
00:30:50,615 --> 00:30:52,470
the majority of spend today is

873
00:30:52,470 --> 00:30:53,850
actually still on

874
00:30:53,850 --> 00:30:56,055
the self-hosted GPU infrastructure.

875
00:30:56,055 --> 00:30:58,590
Bedrock and SageMaker represent

876
00:30:58,590 --> 00:31:01,540
a smaller but steadily growing share.

877
00:31:01,540 --> 00:31:04,050
And this really does make sense.

878
00:31:04,050 --> 00:31:05,340
Many organizations started

879
00:31:05,340 --> 00:31:07,655
their GenAI journey experimenting,

880
00:31:07,655 --> 00:31:10,118
doing that with open source models

881
00:31:10,118 --> 00:31:11,760
or custom deployments

882
00:31:11,760 --> 00:31:14,090
that they could actually
go ahead and tune.

883
00:31:14,090 --> 00:31:15,360
But we now expect to see

884
00:31:15,360 --> 00:31:16,800
a shift very strongly towards

885
00:31:16,800 --> 00:31:18,618
the managed services because the models

886
00:31:18,618 --> 00:31:19,975
that back those are evolving

887
00:31:19,975 --> 00:31:21,420
from the vendors.

888
00:31:21,420 --> 00:31:25,202
And as organizations mature,

889
00:31:25,202 --> 00:31:27,194
they really care about time to value,

890
00:31:27,194 --> 00:31:28,440
and that's really gonna give them

891
00:31:28,440 --> 00:31:29,740
much better time to value.

892
00:31:32,712 --> 00:31:34,500
So just a little bit of a summary here

893
00:31:34,500 --> 00:31:35,850
of the managed services.

894
00:31:35,850 --> 00:31:37,320
So in terms of managed services,

895
00:31:37,320 --> 00:31:38,597
a quick distinction.

896
00:31:38,597 --> 00:31:40,910
Amazon Bedrock is the serverless way

897
00:31:40,910 --> 00:31:42,981
to run existing models.

898
00:31:42,981 --> 00:31:44,730
It's primarily used

899
00:31:44,730 --> 00:31:46,170
for foundation models,

900
00:31:46,170 --> 00:31:47,430
but it also supports bringing

901
00:31:47,430 --> 00:31:48,360
your own model

902
00:31:48,360 --> 00:31:49,953
through custom model imports.

903
00:31:51,136 --> 00:31:52,258
Amazon SageMaker,

904
00:31:52,258 --> 00:31:54,000
this is the end-to-end

905
00:31:54,000 --> 00:31:57,170
machine learning platform on AWS.

906
00:31:57,170 --> 00:31:58,410
It covers everything

907
00:31:58,410 --> 00:32:00,450
from data preparation to training,

908
00:32:00,450 --> 00:32:02,004
fine tuning, deployment,

909
00:32:02,004 --> 00:32:04,500
and production inference.

910
00:32:04,500 --> 00:32:06,210
Yeah, so just handy visualization to see

911
00:32:06,210 --> 00:32:08,110
where these two services fit together.

912
00:32:12,660 --> 00:32:13,650
So I'm gonna dive into each

913
00:32:13,650 --> 00:32:14,483
of these services.

914
00:32:14,483 --> 00:32:16,677
So starting with Bedrock.

915
00:32:16,677 --> 00:32:17,825
As we just saw,

916
00:32:17,825 --> 00:32:19,170
Bedrock is serverless

917
00:32:19,170 --> 00:32:21,840
so there's no need to provision instances,

918
00:32:21,840 --> 00:32:23,318
and you get really easy access

919
00:32:23,318 --> 00:32:26,206
to really powerful foundation models.

920
00:32:26,206 --> 00:32:27,960
The first workload category

921
00:32:27,960 --> 00:32:29,160
that you see there is the one

922
00:32:29,160 --> 00:32:30,651
that everyone knows best;

923
00:32:30,651 --> 00:32:33,379
Reasoning and text generation.

924
00:32:33,379 --> 00:32:36,000
This is where models like Claude 4

925
00:32:36,000 --> 00:32:37,854
or Llama 3 handle tasks,

926
00:32:37,854 --> 00:32:39,693
like answering questions,

927
00:32:39,693 --> 00:32:43,215
summarizing information,
generating content,

928
00:32:43,215 --> 00:32:46,225
or acting as interactive agents.

929
00:32:46,225 --> 00:32:47,370
So things you're probably

930
00:32:47,370 --> 00:32:48,573
quite familiar with.

931
00:32:49,410 --> 00:32:51,710
Pricing here is based on tokens.

932
00:32:51,710 --> 00:32:53,070
And these are just really

933
00:32:53,070 --> 00:32:54,681
small chunks of text.

934
00:32:54,681 --> 00:32:57,570
The general way people frame this

935
00:32:57,570 --> 00:32:58,800
at about three quarters

936
00:32:58,800 --> 00:33:00,297
of a word is a token.

937
00:33:00,297 --> 00:33:01,920
If you Google more about it,

938
00:33:01,920 --> 00:33:05,040
you'll find out how that breaks down.

939
00:33:05,040 --> 00:33:06,630
But yeah, so you're paying for tokens,

940
00:33:06,630 --> 00:33:07,560
you're paying for what's sent

941
00:33:07,560 --> 00:33:08,749
into the model,

942
00:33:08,749 --> 00:33:09,780
and you're also paying

943
00:33:09,780 --> 00:33:11,430
for what's sent out of the model.

944
00:33:12,317 --> 00:33:14,133
So yeah, your cloud spend really

945
00:33:14,133 --> 00:33:17,073
directly tracks with actual usage.

946
00:33:17,910 --> 00:33:19,127
Another major car...

947
00:33:19,127 --> 00:33:21,756
Another major category is RAG,

948
00:33:21,756 --> 00:33:24,522
"Retrieval augmented generation."

949
00:33:24,522 --> 00:33:26,760
So RAG is all about giving the model

950
00:33:26,760 --> 00:33:28,584
the extra context it needs

951
00:33:28,584 --> 00:33:31,179
to answer questions accurately.

952
00:33:31,179 --> 00:33:32,760
Instead of relying only

953
00:33:32,760 --> 00:33:34,470
on what the model was trained on,

954
00:33:34,470 --> 00:33:35,303
RAG lets you bring

955
00:33:35,303 --> 00:33:36,894
in documents, knowledge bases,

956
00:33:36,894 --> 00:33:38,627
or business-specific information

957
00:33:38,627 --> 00:33:40,432
at query time.

958
00:33:40,432 --> 00:33:43,200
This helps reduce
hallucination and ensures

959
00:33:43,200 --> 00:33:44,511
the model's responses are grounded

960
00:33:44,511 --> 00:33:47,507
in real trusted sources.

961
00:33:47,507 --> 00:33:49,374
It is one of the most common patterns

962
00:33:49,374 --> 00:33:50,751
because it's often the fastest

963
00:33:50,751 --> 00:33:52,504
and most cost effective way

964
00:33:52,504 --> 00:33:54,840
to make a model truly useful

965
00:33:54,840 --> 00:33:56,100
to your business.

966
00:33:56,100 --> 00:33:57,270
So talking from our perspective

967
00:33:57,270 --> 00:33:58,300
on Cloudability,

968
00:33:58,300 --> 00:34:00,477
RAG's really important to what we do.

969
00:34:00,477 --> 00:34:01,614
But of course,

970
00:34:01,614 --> 00:34:02,730
there is these costs

971
00:34:02,730 --> 00:34:04,233
that are associated with it.

972
00:34:09,909 --> 00:34:13,016
All right, so switching over to SageMaker,

973
00:34:13,016 --> 00:34:16,500
AWS's end-to-end machine
learning platform.

974
00:34:16,500 --> 00:34:17,430
Let me walk you through

975
00:34:17,430 --> 00:34:18,460
the typical cost areas

976
00:34:18,460 --> 00:34:20,517
you're going to encounter.

977
00:34:20,517 --> 00:34:21,957
So starting at the top,

978
00:34:21,957 --> 00:34:23,910
the building phase usually runs

979
00:34:23,910 --> 00:34:25,380
on lightweight instances,

980
00:34:25,380 --> 00:34:28,860
like ml.t3s or ml.m5s.

981
00:34:28,860 --> 00:34:30,780
This is where teams prep data,

982
00:34:30,780 --> 00:34:32,048
explore notebooks,

983
00:34:32,048 --> 00:34:35,013
and prototype ideas.

984
00:34:36,189 --> 00:34:37,800
It actually normally is...

985
00:34:37,800 --> 00:34:39,180
Actually, it always is pretty much

986
00:34:39,180 --> 00:34:40,470
the lowest cost phase.

987
00:34:40,470 --> 00:34:42,030
From an infrastructure standpoint,

988
00:34:42,030 --> 00:34:43,409
it's not particularly expensive.

989
00:34:43,409 --> 00:34:44,991
Even though it's where a lot of

990
00:34:44,991 --> 00:34:47,703
the actual hands-on
development process happens.

991
00:34:49,160 --> 00:34:50,544
Next is training,

992
00:34:50,544 --> 00:34:53,336
which is where SageMaker really shines.

993
00:34:53,336 --> 00:34:55,003
So this is where you scale out

994
00:34:55,003 --> 00:34:56,446
on GPU clusters,

995
00:34:56,446 --> 00:34:57,920
typically backed by P4

996
00:34:57,920 --> 00:35:00,220
or P5 instances

997
00:35:00,220 --> 00:35:01,622
for deep learning,

998
00:35:01,622 --> 00:35:03,602
fine tuning foundation models,

999
00:35:03,602 --> 00:35:07,727
or running large
distributed training jobs.

1000
00:35:07,727 --> 00:35:09,384
It's also the most expensive

1001
00:35:09,384 --> 00:35:11,241
in most ML pipelines,

1002
00:35:11,241 --> 00:35:12,570
the half a million dollars

1003
00:35:12,570 --> 00:35:14,656
that you said before, JJ,

1004
00:35:14,656 --> 00:35:17,100
so visibility and optimization is

1005
00:35:17,100 --> 00:35:18,600
really, really important here.

1006
00:35:19,776 --> 00:35:21,510
Finally, we get to the third row,

1007
00:35:21,510 --> 00:35:22,606
which is inference,

1008
00:35:22,606 --> 00:35:23,880
which is all about serving

1009
00:35:23,880 --> 00:35:25,200
those models back...

1010
00:35:25,200 --> 00:35:26,070
Serving those models back

1011
00:35:26,070 --> 00:35:28,285
to consumers in production.

1012
00:35:28,285 --> 00:35:30,346
SageMaker gives you a few options here

1013
00:35:30,346 --> 00:35:32,070
that you can choose from.

1014
00:35:32,070 --> 00:35:32,903
So you can use

1015
00:35:32,903 --> 00:35:34,891
regular GPU-backed instances

1016
00:35:34,891 --> 00:35:37,547
or you can run on Inferentia 2,

1017
00:35:37,547 --> 00:35:39,365
I hope I pronounced that correctly,

1018
00:35:39,365 --> 00:35:40,848
which is custom silicon

1019
00:35:40,848 --> 00:35:43,001
from AWS purpose built

1020
00:35:43,001 --> 00:35:46,760
for high throughput low cost inference.

1021
00:35:46,760 --> 00:35:50,573
And if you wanna avoid
managing instances altogether,

1022
00:35:50,573 --> 00:35:52,393
SageMaker actually does have

1023
00:35:52,393 --> 00:35:54,213
a serverless option as well.

1024
00:35:55,149 --> 00:35:57,090
So yeah, generally speaking,

1025
00:35:57,090 --> 00:35:58,680
I'm hoping that the pricing structure

1026
00:35:58,680 --> 00:36:01,000
here should feel fairly familiar,

1027
00:36:01,000 --> 00:36:02,670
given how closely it

1028
00:36:02,670 --> 00:36:04,353
actually is tied to EC2.

1029
00:36:07,099 --> 00:36:10,257
Now, let's take a look at EC2 itself.

1030
00:36:10,257 --> 00:36:11,400
So this is obviously

1031
00:36:11,400 --> 00:36:12,930
the fully self-managed option.

1032
00:36:12,930 --> 00:36:14,300
As we mentioned earlier,

1033
00:36:14,300 --> 00:36:15,943
it's still the backbone

1034
00:36:15,943 --> 00:36:18,162
for a lot of GenAI workloads

1035
00:36:18,162 --> 00:36:20,751
because it gives teams
complete flexibility

1036
00:36:20,751 --> 00:36:23,160
over the environment.

1037
00:36:23,160 --> 00:36:24,560
And at a very large scale,

1038
00:36:24,560 --> 00:36:25,920
what will tend to happen is

1039
00:36:25,920 --> 00:36:26,753
this will actually be

1040
00:36:26,753 --> 00:36:28,509
the cheapest option as well.

1041
00:36:28,509 --> 00:36:30,171
So just like with SageMaker,

1042
00:36:30,171 --> 00:36:32,130
the workflows break down

1043
00:36:32,130 --> 00:36:33,810
into the same three phases.

1044
00:36:33,810 --> 00:36:35,460
So you've got our building again,

1045
00:36:35,460 --> 00:36:37,493
so using lightweight CPU instances,

1046
00:36:37,493 --> 00:36:39,396
like T3s or your M5s,

1047
00:36:39,396 --> 00:36:41,130
to set up a dev environment,

1048
00:36:41,130 --> 00:36:42,720
run your notebooks,

1049
00:36:42,720 --> 00:36:43,953
and iterate quickly.

1050
00:36:44,850 --> 00:36:45,780
Second, training.

1051
00:36:45,780 --> 00:36:46,980
Again, very similar.

1052
00:36:46,980 --> 00:36:48,552
Typically on the P instance families

1053
00:36:48,552 --> 00:36:50,460
for large scale training

1054
00:36:50,460 --> 00:36:51,570
and fine tuning,

1055
00:36:51,570 --> 00:36:54,055
where GPU performance really matters.

1056
00:36:54,055 --> 00:36:57,199
And then, the final one here is inference.

1057
00:36:57,199 --> 00:36:59,370
Traditionally, on the G instances,

1058
00:36:59,370 --> 00:37:00,238
with the Nv...

1059
00:37:00,238 --> 00:37:01,958
Obviously, Nvidia GPUs,

1060
00:37:01,958 --> 00:37:04,080
but increasingly these are shifting

1061
00:37:04,080 --> 00:37:05,940
over to Inferentia 2,

1062
00:37:05,940 --> 00:37:06,840
which is the chips

1063
00:37:06,840 --> 00:37:09,300
from AWS purpose-built for this.

1064
00:37:09,300 --> 00:37:10,830
So conceptually,

1065
00:37:10,830 --> 00:37:12,626
this really does mirror SageMaker,

1066
00:37:12,626 --> 00:37:15,975
even down to the same instance families.

1067
00:37:15,975 --> 00:37:17,640
But the point here is that

1068
00:37:17,640 --> 00:37:19,110
you're actually really in charge

1069
00:37:19,110 --> 00:37:20,790
of the entire stack.

1070
00:37:20,790 --> 00:37:22,090
It's a little bit cheaper.

1071
00:37:23,940 --> 00:37:26,130
- It's way too many options to consider,

1072
00:37:26,130 --> 00:37:27,924
and what you gotta just think about is

1073
00:37:27,924 --> 00:37:31,444
"What is your organization's capability

1074
00:37:31,444 --> 00:37:33,375
"of handling?"

1075
00:37:33,375 --> 00:37:34,652
At the same time,

1076
00:37:34,652 --> 00:37:35,980
contrast that with,

1077
00:37:35,980 --> 00:37:37,177
"What is the purpose

1078
00:37:37,177 --> 00:37:38,587
"to which you're working?

1079
00:37:38,587 --> 00:37:39,817
"And do you really need

1080
00:37:39,817 --> 00:37:41,319
"that level of flexibility?"

1081
00:37:41,319 --> 00:37:43,959
'Cause this can really get very intensive

1082
00:37:43,959 --> 00:37:46,761
for your human resource team,

1083
00:37:46,761 --> 00:37:48,375
your talented people,

1084
00:37:48,375 --> 00:37:50,765
to work out all those details.

1085
00:37:50,765 --> 00:37:51,900
So if you're just doing

1086
00:37:51,900 --> 00:37:53,895
some minor experimenting type of work,

1087
00:37:53,895 --> 00:37:55,830
you may be able to use just

1088
00:37:55,830 --> 00:37:56,999
the basic SaaS offering

1089
00:37:56,999 --> 00:37:59,077
and test it out first.

1090
00:37:59,077 --> 00:38:00,660
But yes, if you truly need

1091
00:38:00,660 --> 00:38:02,040
to scale to a solution

1092
00:38:02,040 --> 00:38:03,318
to what it needs to be,

1093
00:38:03,318 --> 00:38:05,025
and you need all the flexibility,

1094
00:38:05,025 --> 00:38:07,380
then there is all those options

1095
00:38:07,380 --> 00:38:09,376
certainly available.
- Absolutely.

1096
00:38:09,376 --> 00:38:12,054
All right, so as a FinOps person,

1097
00:38:12,054 --> 00:38:14,823
this is the more fun part for me.

1098
00:38:16,603 --> 00:38:18,390
Our FinOps practices.

1099
00:38:18,390 --> 00:38:20,100
So the diagram you had up earlier,

1100
00:38:20,100 --> 00:38:21,120
we had the three phases;

1101
00:38:21,120 --> 00:38:22,440
Inform, optimize, operate.

1102
00:38:22,440 --> 00:38:23,273
- Yeah.
- So of course,

1103
00:38:23,273 --> 00:38:24,106
we're gonna start with "Inform,"

1104
00:38:24,106 --> 00:38:25,050
that's where it all begins.

1105
00:38:25,050 --> 00:38:26,155
Now, I often have...

1106
00:38:26,155 --> 00:38:28,054
I often say to people,

1107
00:38:28,054 --> 00:38:30,818
"If you're good at cost allocation,

1108
00:38:30,818 --> 00:38:32,347
"there's a good chance

1109
00:38:32,347 --> 00:38:33,757
"you'll be good at FinOps.

1110
00:38:33,757 --> 00:38:34,717
"Good chance.

1111
00:38:34,717 --> 00:38:36,789
"If you are bad at cost allocation,

1112
00:38:36,789 --> 00:38:39,600
"you will be bad at FinOps."

1113
00:38:39,600 --> 00:38:40,433
So it really is

1114
00:38:40,433 --> 00:38:42,000
the foundation to everything.

1115
00:38:42,000 --> 00:38:42,833
So...

1116
00:38:42,833 --> 00:38:43,666
Of course, it's the foundation

1117
00:38:43,666 --> 00:38:44,640
to everything AI as well

1118
00:38:44,640 --> 00:38:45,540
in terms of FinOps.

1119
00:38:45,540 --> 00:38:47,840
So the first place to start are areas

1120
00:38:47,840 --> 00:38:49,110
where we can directly map

1121
00:38:49,110 --> 00:38:50,490
these cost back to teams.

1122
00:38:50,490 --> 00:38:52,140
So some of this AI infrastructure will be

1123
00:38:52,140 --> 00:38:53,486
entirely owned by one team

1124
00:38:53,486 --> 00:38:54,810
or one business unit,

1125
00:38:54,810 --> 00:38:56,400
one group, et cetera.

1126
00:38:56,400 --> 00:38:58,347
So we want to have strategies

1127
00:38:58,347 --> 00:38:59,850
that we can fully allocate

1128
00:38:59,850 --> 00:39:00,930
those costs back to

1129
00:39:00,930 --> 00:39:02,160
that team, business unit,

1130
00:39:02,160 --> 00:39:03,284
whatever it might be.

1131
00:39:03,284 --> 00:39:05,400
And so, the two main things

1132
00:39:05,400 --> 00:39:06,951
that we use in AWS,

1133
00:39:06,951 --> 00:39:09,428
regardless of really what service it is,

1134
00:39:09,428 --> 00:39:12,045
is gonna be accounts and tags.

1135
00:39:12,045 --> 00:39:13,860
And you can see some of the details

1136
00:39:13,860 --> 00:39:16,071
about those constructs on the slide.

1137
00:39:16,071 --> 00:39:18,655
So accounts are the most foolproof way.

1138
00:39:18,655 --> 00:39:20,700
You are provisioning resources

1139
00:39:20,700 --> 00:39:21,990
in an account,

1140
00:39:21,990 --> 00:39:23,910
so we can use that directly

1141
00:39:23,910 --> 00:39:25,110
to map cost back in some,

1142
00:39:25,110 --> 00:39:26,493
in some cases.

1143
00:39:26,493 --> 00:39:27,780
In other cases, you might have

1144
00:39:27,780 --> 00:39:28,650
a shared account

1145
00:39:28,650 --> 00:39:30,367
where resources are existing together,

1146
00:39:30,367 --> 00:39:32,038
in which case tags become

1147
00:39:32,038 --> 00:39:33,150
the most useful way

1148
00:39:33,150 --> 00:39:35,007
of doing the allocation.

1149
00:39:35,007 --> 00:39:36,510
So the good news is that

1150
00:39:36,510 --> 00:39:37,343
all of these services

1151
00:39:37,343 --> 00:39:38,520
that we just went through,

1152
00:39:38,520 --> 00:39:39,982
they do all support tags.

1153
00:39:39,982 --> 00:39:41,310
SageMaker, EC2, Bedrock,

1154
00:39:41,310 --> 00:39:42,465
they all support tags.

1155
00:39:42,465 --> 00:39:43,830
So we need to be working

1156
00:39:43,830 --> 00:39:44,790
with our engineers to make sure

1157
00:39:44,790 --> 00:39:46,470
that we're using the right team tag,

1158
00:39:46,470 --> 00:39:47,370
the right business unit tag,

1159
00:39:47,370 --> 00:39:49,364
department tag, so on and so forth.

1160
00:39:49,364 --> 00:39:51,180
And then, at the end of it,

1161
00:39:51,180 --> 00:39:52,191
we wanna try and use,

1162
00:39:52,191 --> 00:39:54,012
ideally, like a mapping engine,

1163
00:39:54,012 --> 00:39:56,010
'cause undoubtedly you're gonna have

1164
00:39:56,010 --> 00:39:56,843
a mixture of rules,

1165
00:39:56,843 --> 00:39:57,840
sometimes you use a tag,

1166
00:39:57,840 --> 00:39:59,100
sometimes you use accounts,

1167
00:39:59,100 --> 00:40:00,229
use other things as well.

1168
00:40:00,229 --> 00:40:02,160
We'll try and use a mapping engine

1169
00:40:02,160 --> 00:40:05,037
to officially assign those costs

1170
00:40:05,037 --> 00:40:06,450
back to the business

1171
00:40:06,450 --> 00:40:08,400
and try and automate a chargeback.

1172
00:40:08,400 --> 00:40:09,300
So for this scenario,

1173
00:40:09,300 --> 00:40:10,290
ideally, we have all of

1174
00:40:10,290 --> 00:40:13,103
our team-owned AI costs,

1175
00:40:13,103 --> 00:40:14,628
we're using these strategies

1176
00:40:14,628 --> 00:40:16,920
that are automatically getting chargeback.

1177
00:40:16,920 --> 00:40:19,329
So that's the first
thing about allocation.

1178
00:40:19,329 --> 00:40:21,257
That isn't always the case.

1179
00:40:21,257 --> 00:40:22,946
So just like you have databases

1180
00:40:22,946 --> 00:40:24,119
that might be shared,

1181
00:40:24,119 --> 00:40:26,119
or APIs that might be shared,

1182
00:40:26,119 --> 00:40:28,915
for sure you're gonna
have AI infrastructure

1183
00:40:28,915 --> 00:40:30,062
that is shared.

1184
00:40:30,062 --> 00:40:31,290
And so, you're gonna need to find

1185
00:40:31,290 --> 00:40:32,240
a way to allocate that

1186
00:40:32,240 --> 00:40:34,424
as cost back to the consumers.

1187
00:40:34,424 --> 00:40:35,950
And again, we're gonna use

1188
00:40:35,950 --> 00:40:37,350
a very similar strategy

1189
00:40:37,350 --> 00:40:39,756
that we would with a database or an API.

1190
00:40:39,756 --> 00:40:40,770
And we're gonna try

1191
00:40:40,770 --> 00:40:42,093
and use consumption data,

1192
00:40:42,093 --> 00:40:43,410
which we would normally refer

1193
00:40:43,410 --> 00:40:44,839
to as "telemetry data."

1194
00:40:44,839 --> 00:40:46,680
So with a database, for example,

1195
00:40:46,680 --> 00:40:47,513
if we're trying...

1196
00:40:47,513 --> 00:40:48,450
We've got five different teams using

1197
00:40:48,450 --> 00:40:49,478
the one database,

1198
00:40:49,478 --> 00:40:50,430
we might use something

1199
00:40:50,430 --> 00:40:52,122
like database transactions

1200
00:40:52,122 --> 00:40:54,090
to split those costs up.

1201
00:40:54,090 --> 00:40:54,923
So if you have 50%

1202
00:40:54,923 --> 00:40:56,400
of the database transactions,

1203
00:40:56,400 --> 00:40:58,320
you get 50% of the cost.

1204
00:40:58,320 --> 00:41:00,300
So how are we gonna do that with AI?

1205
00:41:00,300 --> 00:41:01,230
With GenAI?

1206
00:41:01,230 --> 00:41:03,420
So the most obvious
telemetry data is gonna be

1207
00:41:03,420 --> 00:41:04,597
something like tokens.

1208
00:41:04,597 --> 00:41:06,690
So if we have our five consumers

1209
00:41:06,690 --> 00:41:07,970
and we can track how many tokens

1210
00:41:07,970 --> 00:41:09,926
each of those consumers is using,

1211
00:41:09,926 --> 00:41:12,051
we can now split those costs up

1212
00:41:12,051 --> 00:41:15,333
and allocate them back as needed.

1213
00:41:17,431 --> 00:41:19,530
Yeah, but at the end of the day,

1214
00:41:19,530 --> 00:41:20,490
the net result of both of

1215
00:41:20,490 --> 00:41:22,410
these types of cost allocation is

1216
00:41:22,410 --> 00:41:25,560
that all that cost
allocated back accurately,

1217
00:41:25,560 --> 00:41:26,880
we're now able to start holding

1218
00:41:26,880 --> 00:41:28,440
our teams accountable.

1219
00:41:28,440 --> 00:41:31,442
So yeah, do you have any experiences

1220
00:41:31,442 --> 00:41:33,969
that are worth sharing on this topic?

1221
00:41:33,969 --> 00:41:35,884
- Well, we've always found

1222
00:41:35,884 --> 00:41:38,073
that nobody likes receiving costs.

1223
00:41:39,787 --> 00:41:41,633
I would say it's not very different

1224
00:41:41,633 --> 00:41:44,584
in the context of AI costs versus

1225
00:41:44,584 --> 00:41:46,020
if you're doing chargeback

1226
00:41:46,020 --> 00:41:47,610
in other areas of the cloud.

1227
00:41:47,610 --> 00:41:49,169
One common thread that comes out is

1228
00:41:49,169 --> 00:41:50,911
if you're charging somebody,

1229
00:41:50,911 --> 00:41:52,442
they should have some kind

1230
00:41:52,442 --> 00:41:54,660
of a lever about their usage,

1231
00:41:54,660 --> 00:41:56,335
so they can work on it

1232
00:41:56,335 --> 00:41:58,984
and use it more or less off.

1233
00:41:58,984 --> 00:42:00,390
The worst outcome,

1234
00:42:00,390 --> 00:42:01,860
from their perspective, would be that

1235
00:42:01,860 --> 00:42:03,194
they're getting charged for something

1236
00:42:03,194 --> 00:42:06,194
but they have little
to no control about it.

1237
00:42:06,194 --> 00:42:08,310
So when you choose that telemetry,

1238
00:42:08,310 --> 00:42:09,660
as you were talking about,

1239
00:42:09,660 --> 00:42:11,820
see that there is some kind of a lever,

1240
00:42:11,820 --> 00:42:13,662
some kind of a mechanism,

1241
00:42:13,662 --> 00:42:15,899
that user behavior ties it

1242
00:42:15,899 --> 00:42:17,358
to that telemetry,

1243
00:42:17,358 --> 00:42:18,930
ties it to their--

1244
00:42:18,930 --> 00:42:20,400
- Yeah.
- Portioned cost.

1245
00:42:20,400 --> 00:42:21,385
So share--
- Yes.

1246
00:42:21,385 --> 00:42:23,790
- But with a little care.
- Yes.

1247
00:42:23,790 --> 00:42:25,186
Make sure it's accurate.

1248
00:42:25,186 --> 00:42:26,490
- Yes.
- Awesome.

1249
00:42:26,490 --> 00:42:28,110
All right, so now that we've got

1250
00:42:28,110 --> 00:42:28,943
our first phase,

1251
00:42:28,943 --> 00:42:29,996
we've got our foundations there,

1252
00:42:29,996 --> 00:42:30,930
where we're working

1253
00:42:30,930 --> 00:42:32,320
towards being successful at FinOps,

1254
00:42:32,320 --> 00:42:33,750
we can now start optimize...

1255
00:42:33,750 --> 00:42:35,100
We can start optimizing.

1256
00:42:35,100 --> 00:42:36,510
And there's sort of two
parts of optimizing.

1257
00:42:36,510 --> 00:42:37,530
One is optimizing usage,

1258
00:42:37,530 --> 00:42:38,363
one's optimizing rates.

1259
00:42:38,363 --> 00:42:39,960
We'll talk about rates in a second.

1260
00:42:39,960 --> 00:42:41,895
So optimizing usage is

1261
00:42:41,895 --> 00:42:43,444
really, really specific

1262
00:42:43,444 --> 00:42:44,880
to the type of resources

1263
00:42:44,880 --> 00:42:45,840
that you're doing...

1264
00:42:45,840 --> 00:42:46,673
That you're working with.

1265
00:42:46,673 --> 00:42:48,368
So with AI, GenAI,

1266
00:42:48,368 --> 00:42:51,270
you do have some quite specific things

1267
00:42:51,270 --> 00:42:52,560
that you need to think about.

1268
00:42:52,560 --> 00:42:54,030
So I'll just go through these levers

1269
00:42:54,030 --> 00:42:54,892
that you have here.

1270
00:42:54,892 --> 00:42:56,643
So the first one is to choose

1271
00:42:56,643 --> 00:42:59,417
the right foundation models for the job.

1272
00:42:59,417 --> 00:43:01,593
No matter what mode you are using,

1273
00:43:01,593 --> 00:43:04,013
the three modes we went through earlier,

1274
00:43:04,013 --> 00:43:05,250
this is something

1275
00:43:05,250 --> 00:43:06,600
you're gonna have to do.

1276
00:43:06,600 --> 00:43:08,079
And if you choose the wrong model

1277
00:43:08,079 --> 00:43:09,450
that's inefficient for

1278
00:43:09,450 --> 00:43:10,479
what you're doing,

1279
00:43:10,479 --> 00:43:12,071
you are gonna be inefficient.

1280
00:43:12,071 --> 00:43:14,670
So it's the commonality there.

1281
00:43:14,670 --> 00:43:16,526
So yeah, look at the model.

1282
00:43:16,526 --> 00:43:18,120
Often, you'll see,

1283
00:43:18,120 --> 00:43:20,340
there's light models, or mini models,

1284
00:43:20,340 --> 00:43:21,784
or domain-specific models.

1285
00:43:21,784 --> 00:43:23,119
They're gonna be cheaper,

1286
00:43:23,119 --> 00:43:24,390
and often they'll be

1287
00:43:24,390 --> 00:43:25,929
more performant as well.

1288
00:43:25,929 --> 00:43:28,023
So as a FinOps practitioner,

1289
00:43:28,023 --> 00:43:30,087
there's only so much we can do here.

1290
00:43:30,087 --> 00:43:31,857
But as our head of AI,

1291
00:43:31,857 --> 00:43:33,277
when I asked him, I said,

1292
00:43:33,277 --> 00:43:35,767
"Should the FinOps
practitioners be talking

1293
00:43:35,767 --> 00:43:36,600
"to the engineering people,

1294
00:43:36,600 --> 00:43:38,283
"questioning these kind of things?

1295
00:43:38,283 --> 00:43:40,249
"Should we be facilitating

1296
00:43:40,249 --> 00:43:42,360
"these conversations as FinOps people?"

1297
00:43:42,360 --> 00:43:43,613
His answer is "Yes, yes, yes,"

1298
00:43:43,613 --> 00:43:45,157
we need to do that.

1299
00:43:45,157 --> 00:43:47,190
The second one here is probably one

1300
00:43:47,190 --> 00:43:48,023
that's more familiar.

1301
00:43:48,023 --> 00:43:50,069
Rightsizing instances and EKS.

1302
00:43:50,069 --> 00:43:52,382
If these things are over-provisioned,

1303
00:43:52,382 --> 00:43:54,934
we see cases where the
GPUs aren't even used.

1304
00:43:54,934 --> 00:43:56,190
Just make sure you're turning

1305
00:43:56,190 --> 00:43:57,023
these things off,

1306
00:43:57,023 --> 00:43:58,396
getting the right size.

1307
00:43:58,396 --> 00:44:00,600
Caching, just like we can
cache database requests,

1308
00:44:00,600 --> 00:44:02,282
we can cache API...

1309
00:44:02,282 --> 00:44:06,120
Cache GenAI interactions.

1310
00:44:06,120 --> 00:44:08,963
So if there's prompts that are coming in

1311
00:44:08,963 --> 00:44:11,182
that are kind of consistent,

1312
00:44:11,182 --> 00:44:12,985
we can cache those.

1313
00:44:12,985 --> 00:44:14,510
And finally, batching.

1314
00:44:14,510 --> 00:44:16,320
And this is actually one that confused me

1315
00:44:16,320 --> 00:44:17,340
a little bit initially.

1316
00:44:17,340 --> 00:44:18,540
I was like, "Well, how
would batching work?"

1317
00:44:18,540 --> 00:44:19,530
'Cause normally, when you batch something,

1318
00:44:19,530 --> 00:44:20,970
you batch it up for a while

1319
00:44:20,970 --> 00:44:21,920
then you run it overnight.

1320
00:44:21,920 --> 00:44:23,400
That's not how this works.

1321
00:44:23,400 --> 00:44:24,801
This is kinda like micro-batching,

1322
00:44:24,801 --> 00:44:26,674
where it happening really, really quickly

1323
00:44:26,674 --> 00:44:27,740
in real time,

1324
00:44:27,740 --> 00:44:29,190
and it's just trying to take

1325
00:44:29,190 --> 00:44:30,133
a load off the GPUs

1326
00:44:30,133 --> 00:44:32,285
by grouping requests together.

1327
00:44:32,285 --> 00:44:33,990
So yeah, just some quick things there

1328
00:44:33,990 --> 00:44:35,163
for optimizing usage.

1329
00:44:36,720 --> 00:44:38,677
Optimizing rates.

1330
00:44:38,677 --> 00:44:42,393
Again, so this is the
other side of optimizing.

1331
00:44:43,441 --> 00:44:46,104
You commit to ongoing levels of usage.

1332
00:44:46,104 --> 00:44:48,590
Amazon gives you significant discounting

1333
00:44:48,590 --> 00:44:50,060
as a part of that.

1334
00:44:50,060 --> 00:44:51,750
It's great because you don't

1335
00:44:51,750 --> 00:44:53,088
really need much engineering effort.

1336
00:44:53,088 --> 00:44:55,050
What we just saw a moment ago, you do.

1337
00:44:55,050 --> 00:44:56,503
With this, you don't.

1338
00:44:56,503 --> 00:44:58,440
I think most people will be familiar

1339
00:44:58,440 --> 00:44:59,831
with the EC2 side of this.

1340
00:44:59,831 --> 00:45:02,190
The savings plans and reserved instances.

1341
00:45:02,190 --> 00:45:03,210
Everything is really moving

1342
00:45:03,210 --> 00:45:04,425
towards reserved instances.

1343
00:45:04,425 --> 00:45:06,591
We saw an announcement yesterday from AWS,

1344
00:45:06,591 --> 00:45:08,580
now they're available for RDS.

1345
00:45:08,580 --> 00:45:10,080
Savings plans were available for that.

1346
00:45:10,080 --> 00:45:12,543
So everything is really
moving towards that.

1347
00:45:14,498 --> 00:45:16,050
And yeah, savings plans are great

1348
00:45:16,050 --> 00:45:16,883
because you get the...

1349
00:45:16,883 --> 00:45:17,716
You do...

1350
00:45:17,716 --> 00:45:19,110
They are more flexible,

1351
00:45:19,110 --> 00:45:20,220
they're easier to manage,

1352
00:45:20,220 --> 00:45:21,053
and you do end up with

1353
00:45:21,053 --> 00:45:22,080
a higher savings rate in a sense

1354
00:45:22,080 --> 00:45:23,010
that they sort of gravitate

1355
00:45:23,010 --> 00:45:24,729
to the higher saving resources.

1356
00:45:24,729 --> 00:45:26,384
In terms of SageMaker,

1357
00:45:26,384 --> 00:45:27,962
they have savings plans.

1358
00:45:27,962 --> 00:45:29,910
So I would say they're most similar

1359
00:45:29,910 --> 00:45:31,654
to compute savings plans for EC2.

1360
00:45:31,654 --> 00:45:33,183
And they're similar in a sense

1361
00:45:33,183 --> 00:45:34,770
that they will go across regions,

1362
00:45:34,770 --> 00:45:36,348
they'll go across instance families.

1363
00:45:36,348 --> 00:45:37,380
So if you wanna think

1364
00:45:37,380 --> 00:45:38,610
about SageMaker savings plans,

1365
00:45:38,610 --> 00:45:39,930
think of compute savings plans.

1366
00:45:39,930 --> 00:45:41,219
They work in a very similar way.

1367
00:45:41,219 --> 00:45:42,870
One thing that did kind of confuse me

1368
00:45:42,870 --> 00:45:43,770
in the past was I wondered

1369
00:45:43,770 --> 00:45:45,480
whether compute savings plans would apply

1370
00:45:45,480 --> 00:45:46,470
to SageMaker.

1371
00:45:46,470 --> 00:45:48,693
They don't is the answer to that one.

1372
00:45:49,543 --> 00:45:51,929
Bedrock is the unique one here.

1373
00:45:51,929 --> 00:45:54,616
So in terms of making a commitment there,

1374
00:45:54,616 --> 00:45:56,559
it's called "Provision throughput."

1375
00:45:56,559 --> 00:45:58,080
But it's actually primarily about...

1376
00:45:58,080 --> 00:45:59,757
That's primarily about performance.

1377
00:45:59,757 --> 00:46:01,080
You're doing it to try

1378
00:46:01,080 --> 00:46:02,768
and guarantee that throughput.

1379
00:46:02,768 --> 00:46:04,883
And you do get a discount

1380
00:46:04,883 --> 00:46:06,037
with it as well.

1381
00:46:06,037 --> 00:46:07,443
Those discounts are not published

1382
00:46:07,443 --> 00:46:09,330
so it's hard to exactly know

1383
00:46:09,330 --> 00:46:10,163
what they are,

1384
00:46:10,163 --> 00:46:12,153
but we here they're about 20 to 40%.

1385
00:46:12,153 --> 00:46:13,584
But the point is, with Bedrock,

1386
00:46:13,584 --> 00:46:14,700
if you are gonna be doing

1387
00:46:14,700 --> 00:46:16,430
these commitments like this,

1388
00:46:16,430 --> 00:46:18,270
you need to have a really high base load

1389
00:46:18,270 --> 00:46:19,533
to make that worthwhile.

1390
00:46:22,503 --> 00:46:23,850
All right, so getting to

1391
00:46:23,850 --> 00:46:24,840
the last phase of...

1392
00:46:24,840 --> 00:46:26,112
So we've done inform,

1393
00:46:26,112 --> 00:46:27,233
we've done optimize,

1394
00:46:27,233 --> 00:46:28,620
and now we're gonna do operate.

1395
00:46:28,620 --> 00:46:30,330
- Great, thank you.
- Gonna finish up in a minute.

1396
00:46:30,330 --> 00:46:31,163
- Yep.

1397
00:46:32,160 --> 00:46:34,027
This is all about tying back

1398
00:46:34,027 --> 00:46:35,610
to the business value

1399
00:46:35,610 --> 00:46:37,083
in the operate phase, right?

1400
00:46:38,878 --> 00:46:41,501
At KPMG, we have maintained

1401
00:46:41,501 --> 00:46:44,640
a repository in SharePoint

1402
00:46:44,640 --> 00:46:47,310
around all our AI use cases.

1403
00:46:47,310 --> 00:46:48,567
Anything that anybody thought

1404
00:46:48,567 --> 00:46:49,400
they could do something

1405
00:46:49,400 --> 00:46:51,330
with the UI that will generate value

1406
00:46:51,330 --> 00:46:52,530
for the business,

1407
00:46:52,530 --> 00:46:53,520
we try and get an entry

1408
00:46:53,520 --> 00:46:55,183
into that repository.

1409
00:46:55,183 --> 00:46:56,460
And last I checked,

1410
00:46:56,460 --> 00:46:58,768
there were like 1,500-1,600 rows

1411
00:46:58,768 --> 00:47:00,315
of data in that.

1412
00:47:00,315 --> 00:47:02,426
I'm sure some of you would have

1413
00:47:02,426 --> 00:47:05,673
something similar in nature, right?

1414
00:47:06,813 --> 00:47:09,661
Well, when you look at categorizing

1415
00:47:09,661 --> 00:47:14,173
those 1,600 into the scale aspect of it,

1416
00:47:14,173 --> 00:47:15,750
it kind of boil down

1417
00:47:15,750 --> 00:47:17,220
to those three areas.

1418
00:47:17,220 --> 00:47:18,994
So let's look at that unit economics

1419
00:47:18,994 --> 00:47:20,531
in that same fashion

1420
00:47:20,531 --> 00:47:23,390
of those three different scales.

1421
00:47:23,390 --> 00:47:25,705
First is experimenting.

1422
00:47:25,705 --> 00:47:27,390
Your teams are looking

1423
00:47:27,390 --> 00:47:29,700
to do something with GenAI,

1424
00:47:29,700 --> 00:47:33,217
to test out that "Is this thing predicting

1425
00:47:33,217 --> 00:47:34,633
"with reliable accuracy

1426
00:47:34,633 --> 00:47:36,397
"that I can build some automation

1427
00:47:36,397 --> 00:47:37,507
"on top of it

1428
00:47:37,507 --> 00:47:38,835
"and create an offering

1429
00:47:38,835 --> 00:47:40,800
"that would be worthwhile?"

1430
00:47:40,800 --> 00:47:41,633
Right?

1431
00:47:41,633 --> 00:47:44,250
I'm sure many of you have this use case,

1432
00:47:44,250 --> 00:47:45,928
or use cases similar to that.

1433
00:47:45,928 --> 00:47:47,340
And what's key here is

1434
00:47:47,340 --> 00:47:49,062
to look at the unit economics lens

1435
00:47:49,062 --> 00:47:50,527
in the context of

1436
00:47:50,527 --> 00:47:53,400
"What is the cost per such experiment?"

1437
00:47:53,400 --> 00:47:54,233
Right?

1438
00:47:54,233 --> 00:47:55,440
What is the expected learning

1439
00:47:55,440 --> 00:47:56,580
that we're looking to get

1440
00:47:56,580 --> 00:47:58,060
and what is that costing?

1441
00:47:58,060 --> 00:48:00,270
And that's most relevant to the business.

1442
00:48:00,270 --> 00:48:01,795
So we can focus on token costs

1443
00:48:01,795 --> 00:48:03,761
or GPU-hour cost.

1444
00:48:03,761 --> 00:48:05,849
And for short lived workloads,

1445
00:48:05,849 --> 00:48:08,580
that may be just enough, right?

1446
00:48:08,580 --> 00:48:10,752
Use some sort of SaaS or PaaS offering

1447
00:48:10,752 --> 00:48:12,318
and get to that.

1448
00:48:12,318 --> 00:48:14,430
And examples would be you could look

1449
00:48:14,430 --> 00:48:15,450
at cost per 1,000

1450
00:48:15,450 --> 00:48:16,950
or million tokens,

1451
00:48:16,950 --> 00:48:19,838
or cost per fine-tuning run.

1452
00:48:19,838 --> 00:48:24,240
We talked about the
second idea, or category,

1453
00:48:24,240 --> 00:48:27,120
would be that big productivity boosting,

1454
00:48:27,120 --> 00:48:30,270
augmenting type of use case.

1455
00:48:30,270 --> 00:48:31,140
And here, you're looking to

1456
00:48:31,140 --> 00:48:32,850
obviously boost the team performance

1457
00:48:32,850 --> 00:48:34,139
or individual's performance,

1458
00:48:34,139 --> 00:48:36,060
and at the same time you wanna have

1459
00:48:36,060 --> 00:48:38,622
a control on the costs, right?

1460
00:48:38,622 --> 00:48:40,690
And the unit economics lens

1461
00:48:40,690 --> 00:48:42,763
then needs to shift to

1462
00:48:42,763 --> 00:48:46,859
"What is the cost per that assistance

1463
00:48:46,859 --> 00:48:49,198
"that AI is able to provide?"

1464
00:48:49,198 --> 00:48:51,390
Or "per that user interaction?"

1465
00:48:51,390 --> 00:48:52,787
If it's support triaging

1466
00:48:52,787 --> 00:48:54,985
or summarizing of a document,

1467
00:48:54,985 --> 00:48:56,391
what is that

1468
00:48:56,391 --> 00:49:00,382
individual activity task costing us

1469
00:49:00,382 --> 00:49:02,178
by leveraging AI?

1470
00:49:02,178 --> 00:49:05,189
And have a baseline from non-AI

1471
00:49:05,189 --> 00:49:06,771
to compare it to,

1472
00:49:06,771 --> 00:49:08,220
so that you get some sense

1473
00:49:08,220 --> 00:49:10,716
of value versus the cost.

1474
00:49:10,716 --> 00:49:13,143
That's your productivity uplift.

1475
00:49:15,515 --> 00:49:16,754
The third case is

1476
00:49:16,754 --> 00:49:17,790
where we are looking

1477
00:49:17,790 --> 00:49:19,620
to build something that, previously,

1478
00:49:19,620 --> 00:49:23,220
we just couldn't do without AI.

1479
00:49:23,220 --> 00:49:24,690
So it's like something

1480
00:49:24,690 --> 00:49:26,344
that will differentiate our offering,

1481
00:49:26,344 --> 00:49:28,590
something completely net new

1482
00:49:28,590 --> 00:49:30,090
as a new feature into a product

1483
00:49:30,090 --> 00:49:31,524
or a service.

1484
00:49:31,524 --> 00:49:33,007
And I'm sure many of you are building

1485
00:49:33,007 --> 00:49:36,331
such wonderful things, right?

1486
00:49:36,331 --> 00:49:38,100
And here, you're looking at

1487
00:49:38,100 --> 00:49:39,330
that strategic advantage.

1488
00:49:39,330 --> 00:49:41,535
So the unit of that advantage would be

1489
00:49:41,535 --> 00:49:44,130
something tied either to some kind

1490
00:49:44,130 --> 00:49:46,283
of a revenue generating outcome,

1491
00:49:46,283 --> 00:49:50,880
or something where the AI feature has

1492
00:49:50,880 --> 00:49:53,597
very directly improved the business value.

1493
00:49:53,597 --> 00:49:55,467
And a couple of examples there are

1494
00:49:55,467 --> 00:49:57,780
if you're looking at it in terms of sales

1495
00:49:57,780 --> 00:49:59,588
or marketing leads that are being closed,

1496
00:49:59,588 --> 00:50:04,050
or any kind of AI-driven
fraud detection type

1497
00:50:04,050 --> 00:50:05,580
of services that basically,

1498
00:50:05,580 --> 00:50:07,688
very directly, impacted your top

1499
00:50:07,688 --> 00:50:09,003
or bottom line.

1500
00:50:10,941 --> 00:50:12,273
Awesome, Midge.

1501
00:50:12,273 --> 00:50:15,210
- Oh, we're just about to finish up here.

1502
00:50:15,210 --> 00:50:17,220
We've used our full allotment

1503
00:50:17,220 --> 00:50:18,480
of time nearly.

1504
00:50:18,480 --> 00:50:19,928
All right, so some key resources

1505
00:50:19,928 --> 00:50:21,848
to take back with you here.

1506
00:50:21,848 --> 00:50:23,653
But some thoughts for you

1507
00:50:23,653 --> 00:50:25,769
as you go back next week

1508
00:50:25,769 --> 00:50:27,960
to your office.

1509
00:50:27,960 --> 00:50:28,876
Back to work.

1510
00:50:28,876 --> 00:50:30,030
So what are some things

1511
00:50:30,030 --> 00:50:31,710
that you can look to action?

1512
00:50:31,710 --> 00:50:32,550
Well, if you are early

1513
00:50:32,550 --> 00:50:35,077
as FinOps practitioner on this AI journey,

1514
00:50:35,077 --> 00:50:37,051
maybe start at a high level.

1515
00:50:37,051 --> 00:50:38,400
Just try and capture

1516
00:50:38,400 --> 00:50:39,625
what is your total AI spend

1517
00:50:39,625 --> 00:50:42,233
across AWS, across other vendors,

1518
00:50:42,233 --> 00:50:44,197
across SaaS, whatever it might be,

1519
00:50:44,197 --> 00:50:46,290
just try and capture that total cost.

1520
00:50:46,290 --> 00:50:47,940
Try and report that back every week.

1521
00:50:47,940 --> 00:50:48,773
Maybe that's something

1522
00:50:48,773 --> 00:50:50,070
you could look to do.

1523
00:50:50,070 --> 00:50:51,395
If you're further along on that journey,

1524
00:50:51,395 --> 00:50:53,508
maybe you've started allocating costs,

1525
00:50:53,508 --> 00:50:55,540
but you haven't got your
shared costs done yet,

1526
00:50:55,540 --> 00:50:56,970
make sure you're bringing in

1527
00:50:56,970 --> 00:50:58,141
that telemetry data.

1528
00:50:58,141 --> 00:50:59,640
Make sure that those

1529
00:50:59,640 --> 00:51:03,070
shared AI infrastructure
costs can be allocated back.

1530
00:51:03,070 --> 00:51:04,740
Maybe you are even past that,

1531
00:51:04,740 --> 00:51:05,640
maybe you are...

1532
00:51:05,640 --> 00:51:06,981
Maybe you are doing really well

1533
00:51:06,981 --> 00:51:09,814
and it comes down to unit economics.

1534
00:51:09,814 --> 00:51:12,090
You know, be clear with your teams.

1535
00:51:12,090 --> 00:51:13,228
What is that unit metric

1536
00:51:13,228 --> 00:51:15,148
that you are tracking to?

1537
00:51:15,148 --> 00:51:17,022
Do you have a unit metric?

1538
00:51:17,022 --> 00:51:18,652
And work towards that.

1539
00:51:18,652 --> 00:51:21,764
So that's what we have for you today.

1540
00:51:21,764 --> 00:51:23,895
Thank you for joining us.

1541
00:51:23,895 --> 00:51:24,953
We appreciate it.

1542
00:51:24,953 --> 00:51:26,760
I think we have a few
minutes of questions.

1543
00:51:26,760 --> 00:51:28,950
- Yes, we're happy to take questions.

1544
00:51:28,950 --> 00:51:29,783
Thank you.

