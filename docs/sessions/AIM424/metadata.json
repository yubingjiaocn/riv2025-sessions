{
  "title": "AWS re:Invent 2025 - Scaling foundation model inference on Amazon SageMaker AI (AIM424)",
  "title_cn": "AWS re:Invent 2025 - 在 Amazon SageMaker AI 上扩展基础模型推理 (AIM424)",
  "abstract": "Learn how to optimize and deploy popular open-source models like Qwen3, GPT-OSS, and Llama4 using advanced inference engines such as vLLM on SageMaker. We'll explore key features including bidirectional streaming for audio and text applications, and share proven optimization techniques for inferencing. Through live demos, learn to boost performance with KV caching, intelligent routing, and autoscaling to maintain stability under varying loads. We'll demonstrate solutions for building Agentic workflows with SageMaker AI, LangChain, and Amazon Bedrock AgentCore integration and share best practices helping you confidently move from prototype to trusted AI experiences that delight users.",
  "abstract_cn": "学习如何使用 vLLM 等高级推理引擎在 SageMaker 上优化和部署 Qwen3、GPT-OSS 和 Llama4 等流行的开源模型。我们将探索关键功能，包括用于音频和文本应用的双向流式传输，并分享经过验证的推理优化技术。通过现场演示，学习如何利用 KV 缓存、智能路由和自动扩展来提升性能，以在不同负载下保持稳定性。我们将展示使用 SageMaker AI、LangChain 和 Amazon Bedrock AgentCore 集成构建 Agentic 工作流的解决方案，并分享最佳实践，帮助您自信地从原型过渡到为用户带来愉悦体验的可信 AI 体验。",
  "presenter": [
    {
      "name": "Vivek Gangasani",
      "title": "Principal GenAI Specialist Architect",
      "company": "AWS"
    },
    {
      "name": "Kareem Syed-Mohammed",
      "title": "Principal Product Manager - Tech",
      "company": "Amazon Web Services"
    },
    {
      "name": "Richard Chang",
      "title": "Software Architect-AI/ML",
      "company": "SalesForce"
    }
  ],
  "attributes": {
    "topic": "Compute",
    "area_of_interest": [
      "Generative AI",
      "Cost Optimization",
      "Machine Learning"
    ],
    "services": [
      "Amazon SageMaker AI"
    ],
    "type": "Breakout session"
  },
  "video_url": "https://www.youtube.com/watch?v=nHaLbyLPK7s",
  "session_code": "AIM424"
}