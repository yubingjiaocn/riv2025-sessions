1
00:00:00,118 --> 00:00:02,798
Thank you for coming to AIM 383.

2
00:00:03,079 --> 00:00:05,650
Build more effective agent through model customization.

3
00:00:05,969 --> 00:00:08,409
I'm gonna be one of the two hosts, David De Galitelli,

4
00:00:08,800 --> 00:00:10,849
worldwide senior specialist solutions architect for

5
00:00:10,849 --> 00:00:12,038
the StageMaker AI team.

6
00:00:12,409 --> 00:00:14,608
I have the pleasure to have with me on stage today, Sam.

7
00:00:14,849 --> 00:00:17,010
Sam, you wanna introduce yourself? Hey everyone, my name is

8
00:00:17,010 --> 00:00:19,208
Sam Palani, and I lead the Nova

9
00:00:19,208 --> 00:00:20,690
go to market team here at EWS.

10
00:00:21,818 --> 00:00:23,859
Awesome, thank you very much. This is a silent

11
00:00:23,859 --> 00:00:26,100
session, so you guys are happy to

12
00:00:26,100 --> 00:00:28,399
come ask questions after the session.

13
00:00:28,780 --> 00:00:30,850
We're pretty packed on content, so there's a lot

14
00:00:30,850 --> 00:00:31,559
to go through.

15
00:00:31,899 --> 00:00:33,899
Without further, you know, waiting, we're just gonna

16
00:00:33,899 --> 00:00:35,020
go ahead and get started.

17
00:00:36,130 --> 00:00:38,168
The agenda, as I was saying, is pretty packed.

18
00:00:38,289 --> 00:00:40,329
There's a lot to talk about, uh, lots of

19
00:00:40,329 --> 00:00:41,289
new things coming.

20
00:00:41,679 --> 00:00:44,048
A lot of new things were announced as of

21
00:00:44,048 --> 00:00:46,090
yesterday and Tuesday. Hope you guys checked out the

22
00:00:46,090 --> 00:00:47,950
keynotes. Today we're gonna go through

23
00:00:48,450 --> 00:00:50,630
how to build custom AI agents using

24
00:00:50,630 --> 00:00:52,560
the Amazon Nova Foundation models.

25
00:00:52,929 --> 00:00:55,450
How many Foundation models do we have available

26
00:00:55,450 --> 00:00:57,389
when we talk about the Amazon Nova family?

27
00:00:58,029 --> 00:01:00,319
And then because we know that you guys have your own

28
00:01:00,319 --> 00:01:03,259
kind of use cases and you have your own peculiarities

29
00:01:03,439 --> 00:01:05,680
in the way that you solve your tasks, we will

30
00:01:05,680 --> 00:01:07,719
show you how to customize Amazon

31
00:01:07,719 --> 00:01:10,058
Nova models. There's different techniques,

32
00:01:10,069 --> 00:01:11,879
uh, both from a point of view of the

33
00:01:12,198 --> 00:01:14,400
open source community as well as the specifics

34
00:01:14,400 --> 00:01:15,900
of what we allow you to do

35
00:01:16,159 --> 00:01:18,198
within Bedrock and Sagemaker. So we're gonna go

36
00:01:18,198 --> 00:01:18,709
through that.

37
00:01:19,439 --> 00:01:21,680
Of course, this is not an AWS tech talk.

38
00:01:21,838 --> 00:01:23,159
It doesn't come with a demo,

39
00:01:23,439 --> 00:01:25,510
so we're gonna go through an example of a model

40
00:01:25,510 --> 00:01:26,659
customization using

41
00:01:27,040 --> 00:01:28,739
Amazon Sage Maker as part of a demo.

42
00:01:29,120 --> 00:01:31,198
And then finally we'll wrap up. We'll give you some

43
00:01:31,198 --> 00:01:33,198
resources to get started and to learn

44
00:01:33,198 --> 00:01:35,278
more about how to use Nova for your

45
00:01:35,278 --> 00:01:36,019
use cases.

46
00:01:36,359 --> 00:01:37,750
All right? With that said,

47
00:01:38,040 --> 00:01:40,159
not gonna take any more of your time. I'm gonna let

48
00:01:40,159 --> 00:01:42,469
Sam do the rest of the talk. Thank you. Thanks,

49
00:01:42,558 --> 00:01:45,028
David. So

50
00:01:45,028 --> 00:01:47,540
how many of you have attended a silence session

51
00:01:47,540 --> 00:01:49,750
before? OK.

52
00:01:51,019 --> 00:01:53,028
For those who have not, I'm with you because

53
00:01:53,028 --> 00:01:54,888
this is also my first silence session.

54
00:01:55,308 --> 00:01:56,528
So let's see how this goes.

55
00:01:59,319 --> 00:02:01,379
Let's start with the basics. What is an AI

56
00:02:01,379 --> 00:02:03,439
agent? Now

57
00:02:03,439 --> 00:02:05,599
there are quite a few definitions of what

58
00:02:05,599 --> 00:02:06,879
an AI agent is,

59
00:02:07,439 --> 00:02:09,719
but a simple one that most of the

60
00:02:09,719 --> 00:02:11,800
industry is also gravitating towards is

61
00:02:11,800 --> 00:02:13,118
to think of them as

62
00:02:13,439 --> 00:02:15,439
LLMs calling tools in a loop to

63
00:02:15,439 --> 00:02:16,419
accomplish a goal.

64
00:02:17,719 --> 00:02:18,960
Let's break that down a bit.

65
00:02:19,808 --> 00:02:22,159
So an agent has access to a model.

66
00:02:22,788 --> 00:02:24,788
A set of tools and is given

67
00:02:24,788 --> 00:02:26,008
a very specific goal.

68
00:02:27,330 --> 00:02:29,330
It then uses these tools to take

69
00:02:29,330 --> 00:02:31,250
certain actions within an environment.

70
00:02:32,179 --> 00:02:35,020
The environment can be something like your

71
00:02:35,020 --> 00:02:37,368
web browser, your computer terminal,

72
00:02:39,419 --> 00:02:41,679
or even your enterprise application. It then

73
00:02:41,679 --> 00:02:44,020
analyses the results of these actions

74
00:02:44,020 --> 00:02:45,838
to verify if the goal has been met.

75
00:02:46,750 --> 00:02:48,008
If the goal is met,

76
00:02:48,308 --> 00:02:50,308
the loop ends. If not, the

77
00:02:50,308 --> 00:02:52,659
agent continues to take more actions

78
00:02:52,669 --> 00:02:54,008
until the goal is accomplished.

79
00:02:55,050 --> 00:02:57,149
So there you have it, a model calling

80
00:02:57,149 --> 00:02:59,069
tools in a loop to accomplish a goal.

81
00:03:03,210 --> 00:03:05,740
But let's also look at what's causing this inflection

82
00:03:05,740 --> 00:03:07,899
point in agentic AI, starting with reasoning

83
00:03:07,899 --> 00:03:10,389
models. Now

84
00:03:10,389 --> 00:03:12,479
sometime last year there was a perception

85
00:03:12,479 --> 00:03:14,588
that frontier model intelligence had hit a

86
00:03:14,588 --> 00:03:16,689
wall. It seemed that

87
00:03:16,689 --> 00:03:19,050
we had consumed all the data that was available

88
00:03:19,050 --> 00:03:21,250
to train these models, and most model

89
00:03:21,250 --> 00:03:23,288
releases seemed more like incremental

90
00:03:23,288 --> 00:03:25,429
updates rather than a fundamental

91
00:03:25,429 --> 00:03:27,308
shift in frontier intelligence.

92
00:03:28,729 --> 00:03:30,729
It also seemed that the scaling laws were

93
00:03:30,729 --> 00:03:31,788
no longer working.

94
00:03:32,569 --> 00:03:35,088
Just a quick recap, the scaling laws famously

95
00:03:35,088 --> 00:03:36,028
stated that if you

96
00:03:36,439 --> 00:03:37,449
add more data,

97
00:03:37,969 --> 00:03:40,008
continue to train longer, keep

98
00:03:40,008 --> 00:03:42,240
increasing the model size, you will eventually

99
00:03:42,240 --> 00:03:42,919
get a more

100
00:03:43,210 --> 00:03:44,050
performance model.

101
00:03:44,960 --> 00:03:47,139
It seemed that that was no longer holding true.

102
00:03:49,610 --> 00:03:51,719
All this changed when reasoning models

103
00:03:51,719 --> 00:03:53,719
burst into the scene. Suddenly the focus

104
00:03:53,719 --> 00:03:55,338
shifted from pure training

105
00:03:55,639 --> 00:03:57,639
to test time compute and inference time

106
00:03:57,639 --> 00:03:59,679
compute. What happened was that

107
00:03:59,679 --> 00:04:01,838
these new models were able to think and

108
00:04:01,838 --> 00:04:04,520
act out of the box, unlocking new capabilities

109
00:04:04,520 --> 00:04:06,520
for agentic AI that was

110
00:04:06,520 --> 00:04:07,740
previously challenging.

111
00:04:09,528 --> 00:04:11,919
The other benefit of reasoning

112
00:04:11,919 --> 00:04:13,929
models was that it enabled you to

113
00:04:13,929 --> 00:04:15,929
deploy agents at scale and

114
00:04:15,929 --> 00:04:17,290
in a cost effective manner.

115
00:04:18,187 --> 00:04:20,187
For example, you could now break down

116
00:04:20,187 --> 00:04:22,187
complex long running tasks into smaller

117
00:04:22,187 --> 00:04:24,269
tasks and run them in parallel at

118
00:04:24,269 --> 00:04:26,488
scale. You could also

119
00:04:26,488 --> 00:04:28,988
choose to route tasks based on complexity

120
00:04:28,988 --> 00:04:31,088
to a smaller and more efficient variant

121
00:04:31,088 --> 00:04:33,369
of the model, making it more cost effective.

122
00:04:35,629 --> 00:04:37,750
Now a model with all the intelligence

123
00:04:37,750 --> 00:04:40,028
and reasoning capabilities can only

124
00:04:40,028 --> 00:04:42,189
do so much if it doesn't have

125
00:04:42,189 --> 00:04:43,869
access to your specific context.

126
00:04:44,470 --> 00:04:46,689
So what we saw was during this time,

127
00:04:46,738 --> 00:04:49,069
organizations also invested in building a secure

128
00:04:49,069 --> 00:04:50,369
data infrastructure

129
00:04:50,629 --> 00:04:53,028
that enabled them to connect their proprietary

130
00:04:53,028 --> 00:04:54,910
data to these powerful models.

131
00:04:55,959 --> 00:04:58,040
And last but not the least, the emergence of

132
00:04:58,040 --> 00:04:59,139
specialized tooling

133
00:04:59,559 --> 00:05:01,639
and technologies such as model

134
00:05:01,639 --> 00:05:04,000
context protocol, the agent to agent protocol,

135
00:05:04,600 --> 00:05:07,000
model level skills, and even tool calling

136
00:05:07,000 --> 00:05:09,119
further streamline the process of building and

137
00:05:09,119 --> 00:05:10,480
deploying these agents.

138
00:05:14,928 --> 00:05:16,238
But this is not just us.

139
00:05:16,569 --> 00:05:18,569
This is what customers like you and builders

140
00:05:18,569 --> 00:05:19,608
like you are telling us.

141
00:05:19,970 --> 00:05:22,170
According to Gartner, 1/3 of all

142
00:05:22,170 --> 00:05:24,410
enterprise applications would be powered

143
00:05:24,410 --> 00:05:26,720
by generative AI or agentic AI

144
00:05:26,720 --> 00:05:27,709
by 2028.

145
00:05:28,738 --> 00:05:30,809
And 15% of all day to day

146
00:05:30,809 --> 00:05:33,209
business decisions would be taken autonomously

147
00:05:33,209 --> 00:05:34,379
by an AI agent.

148
00:05:35,238 --> 00:05:37,699
To put these things in perspective,

149
00:05:38,278 --> 00:05:40,358
at the same time last year, this number was close

150
00:05:40,358 --> 00:05:41,220
to 1%.

151
00:05:43,170 --> 00:05:45,369
They also predict that of all these AI

152
00:05:45,369 --> 00:05:47,488
interactions, at least 1/3

153
00:05:47,488 --> 00:05:49,809
of them would involve invoking an action

154
00:05:49,809 --> 00:05:50,389
model

155
00:05:50,660 --> 00:05:52,889
or an AI agent for task completion.

156
00:05:54,920 --> 00:05:57,290
But this is not a road map of the future. This is happening

157
00:05:57,290 --> 00:05:57,869
right now.

158
00:06:01,059 --> 00:06:03,108
Although this session is around customization,

159
00:06:03,699 --> 00:06:06,220
it's also important to understand that customization

160
00:06:06,220 --> 00:06:08,608
is just one step in your journey to production,

161
00:06:09,019 --> 00:06:11,459
where you have other steps such as building, deployment,

162
00:06:11,500 --> 00:06:12,178
and testing.

163
00:06:14,600 --> 00:06:16,720
For now though, we'll focus on customization.

164
00:06:19,509 --> 00:06:21,528
But why talk about customization

165
00:06:21,528 --> 00:06:23,528
in the context or model customization in

166
00:06:23,528 --> 00:06:24,889
the context of agents?

167
00:06:26,048 --> 00:06:28,420
Now while Frontier model intelligence has

168
00:06:28,420 --> 00:06:31,399
increased, it also exhibits

169
00:06:31,738 --> 00:06:33,939
brittle behavior, specifically with agentic

170
00:06:33,939 --> 00:06:36,048
AI. You saw that

171
00:06:36,048 --> 00:06:38,048
an agent takes a series of steps

172
00:06:38,048 --> 00:06:39,278
to accomplish a goal.

173
00:06:39,689 --> 00:06:41,809
This introduces a unique risk that

174
00:06:41,809 --> 00:06:44,250
we sometimes call it as compounding

175
00:06:44,250 --> 00:06:46,369
mistakes, where an error from one

176
00:06:46,369 --> 00:06:48,369
step propagates and compounds to the

177
00:06:48,369 --> 00:06:49,048
other step.

178
00:06:49,569 --> 00:06:50,088
For instance,

179
00:06:50,369 --> 00:06:52,569
consider a scenario where your model achieves

180
00:06:52,569 --> 00:06:54,649
95% accuracy on a single

181
00:06:54,649 --> 00:06:56,889
step. Over the course of 10

182
00:06:56,889 --> 00:06:59,588
steps, there is a risk that this might actually

183
00:07:00,519 --> 00:07:02,608
reduce to around 60%, turning a

184
00:07:02,608 --> 00:07:05,209
highly performing model into a very unreliable

185
00:07:05,209 --> 00:07:07,519
agent. Now customization

186
00:07:07,519 --> 00:07:09,588
can directly help reduce these errors,

187
00:07:09,600 --> 00:07:11,639
both at the step level as well as across

188
00:07:11,639 --> 00:07:12,278
the steps.

189
00:07:14,608 --> 00:07:16,869
The next one is not specific to agentic AI

190
00:07:16,869 --> 00:07:18,869
but still very applicable here. Your

191
00:07:18,869 --> 00:07:21,470
domain specific acronyms, taxonomies,

192
00:07:21,588 --> 00:07:23,670
and business process knowledge are

193
00:07:23,670 --> 00:07:24,829
not internet average.

194
00:07:25,389 --> 00:07:27,829
Customization can help align and steer

195
00:07:27,829 --> 00:07:30,500
the model to your specific business semantics.

196
00:07:32,750 --> 00:07:35,420
We also talked about tools in the context of agents.

197
00:07:35,790 --> 00:07:37,790
In order for these models to make these

198
00:07:37,790 --> 00:07:39,988
tool calls perfectly in the first

199
00:07:39,988 --> 00:07:41,889
attempts, it's important that they have a

200
00:07:42,189 --> 00:07:44,269
good understanding of the underlying

201
00:07:44,269 --> 00:07:46,670
schema as well as the parameters

202
00:07:46,670 --> 00:07:48,298
needed to invoke these tools.

203
00:07:48,709 --> 00:07:50,928
Customization can directly help you do that.

204
00:07:53,139 --> 00:07:55,858
Now related to the problem of compounding

205
00:07:55,858 --> 00:07:58,100
mistakes, customization can

206
00:07:58,100 --> 00:08:00,420
help compress long running chains

207
00:08:00,420 --> 00:08:02,059
within your agentic workflow.

208
00:08:02,579 --> 00:08:05,019
Your model learns micro policies

209
00:08:05,019 --> 00:08:07,738
for each step. You get shorter trajectories,

210
00:08:08,100 --> 00:08:10,178
fewer backtracks, and fewer dead ends.

211
00:08:12,619 --> 00:08:15,309
Customization techniques such as distillation

212
00:08:15,309 --> 00:08:17,548
can directly help reduce your

213
00:08:17,548 --> 00:08:19,928
P50 and P90 latency

214
00:08:20,079 --> 00:08:21,569
and cost per step.

215
00:08:26,910 --> 00:08:28,470
But what do we mean by customization?

216
00:08:30,670 --> 00:08:32,678
Again, a bare bones definition that

217
00:08:32,678 --> 00:08:34,678
I'd like to think about here is

218
00:08:34,678 --> 00:08:36,719
customization is anything that

219
00:08:36,719 --> 00:08:38,779
you do to a model to modify its behavior.

220
00:08:39,769 --> 00:08:41,928
It has a broad set of options as you can

221
00:08:41,928 --> 00:08:44,168
see here, ranging from simple and progressing

222
00:08:44,168 --> 00:08:45,090
in complexity.

223
00:08:46,759 --> 00:08:48,849
At a high level, we like to break this down into

224
00:08:48,849 --> 00:08:51,048
two categories, which is optimizing the output

225
00:08:51,048 --> 00:08:52,950
and modifying the underlying model itself.

226
00:08:53,489 --> 00:08:54,440
Or in other words,

227
00:08:54,769 --> 00:08:57,119
optimizing the output, no weight updates,

228
00:08:57,408 --> 00:08:59,450
and modifying the model where you actually make

229
00:08:59,450 --> 00:09:00,690
weight updates to the model.

230
00:09:02,979 --> 00:09:05,109
At the very simplest end of the

231
00:09:05,109 --> 00:09:07,190
spectrum, you have techniques such as prompt

232
00:09:07,190 --> 00:09:09,250
engineering, which is a bucket term that we use

233
00:09:09,250 --> 00:09:11,489
to describe everything ranging from

234
00:09:11,788 --> 00:09:14,070
simple, few short examples to more

235
00:09:14,070 --> 00:09:16,349
complex chain of thought examples to everything in

236
00:09:16,349 --> 00:09:18,869
between, such as crafting efficient

237
00:09:18,869 --> 00:09:20,109
systems and user prompts.

238
00:09:22,070 --> 00:09:24,149
Next we have retrieval augmented generation or

239
00:09:24,149 --> 00:09:26,288
RAG. While context

240
00:09:26,288 --> 00:09:28,529
sizes of these models have

241
00:09:28,529 --> 00:09:30,729
increased exponentially in the past few years,

242
00:09:31,229 --> 00:09:33,529
RA continues to be a very effective

243
00:09:33,529 --> 00:09:35,529
way of providing additional

244
00:09:35,529 --> 00:09:37,729
context to the models, especially at runtime.

245
00:09:40,609 --> 00:09:42,969
context engineering has emerged as

246
00:09:42,969 --> 00:09:45,288
the most effective way of optimizing

247
00:09:45,288 --> 00:09:47,450
the model specifically for agentic AI.

248
00:09:48,590 --> 00:09:50,668
Now sticking to our theme of keeping things

249
00:09:50,668 --> 00:09:53,070
simple, we can consider context

250
00:09:53,070 --> 00:09:55,190
engineering as providing the right

251
00:09:55,190 --> 00:09:57,308
information in the right format and at the right

252
00:09:57,308 --> 00:09:58,149
time to the model.

253
00:09:59,889 --> 00:10:02,048
Now if you think about it, a model needs more than just

254
00:10:02,048 --> 00:10:02,918
the prompts.

255
00:10:03,250 --> 00:10:05,570
It also needs to have a good understanding

256
00:10:05,570 --> 00:10:07,668
of the tools that it has access to,

257
00:10:08,250 --> 00:10:10,450
any additional context that was retrieved

258
00:10:10,450 --> 00:10:12,279
as part of the rack pipeline,

259
00:10:12,609 --> 00:10:14,759
as well as a memory of all

260
00:10:14,759 --> 00:10:15,989
previous interactions.

261
00:10:17,830 --> 00:10:19,908
Now in contrast to prompt engineering, which

262
00:10:19,908 --> 00:10:22,229
involves working with discrete prompts,

263
00:10:22,739 --> 00:10:24,869
context engineering is an iterative

264
00:10:24,869 --> 00:10:27,058
process where the curation happens

265
00:10:27,058 --> 00:10:28,869
each time a pass to an LLM is made.

266
00:10:31,279 --> 00:10:33,320
Now moving on to the techniques which involve

267
00:10:33,320 --> 00:10:35,389
modifying the underlying model itself,

268
00:10:35,798 --> 00:10:37,840
we can break this down further into two

269
00:10:37,840 --> 00:10:39,960
subcategories, post-training techniques and

270
00:10:39,960 --> 00:10:41,000
pre-training techniques.

271
00:10:41,840 --> 00:10:43,928
This is also where we'll spend the rest of this breakout

272
00:10:43,928 --> 00:10:44,570
session on.

273
00:10:46,359 --> 00:10:48,359
On the post-training side, you have techniques

274
00:10:48,359 --> 00:10:50,918
such as fine-tuning or supervised fine tuning,

275
00:10:51,558 --> 00:10:53,719
model distillation, and reinforcement

276
00:10:53,719 --> 00:10:55,840
learning techniques such as direct preference

277
00:10:55,840 --> 00:10:57,509
optimization, DPO

278
00:10:57,849 --> 00:10:58,509
and PPO.

279
00:10:59,509 --> 00:11:01,629
And on the post-training side, we have techniques

280
00:11:01,629 --> 00:11:03,109
such as continued pre-training.

281
00:11:04,418 --> 00:11:06,418
And we'll go into each of these techniques in

282
00:11:06,418 --> 00:11:08,479
much more detail as we progress along.

283
00:11:13,399 --> 00:11:14,690
Starting with fine tuning.

284
00:11:17,149 --> 00:11:19,269
Now, just by a show of hands, how many of you

285
00:11:19,269 --> 00:11:20,469
have tried fine tuning?

286
00:11:21,558 --> 00:11:23,590
OK. Good.

287
00:11:24,418 --> 00:11:26,580
So when we talk about fine

288
00:11:26,580 --> 00:11:27,210
tuning,

289
00:11:28,219 --> 00:11:30,288
this includes both full fine tuning,

290
00:11:30,580 --> 00:11:32,779
which involves modifying the base model

291
00:11:32,779 --> 00:11:34,859
weights, as well as performance

292
00:11:34,859 --> 00:11:36,678
efficient fine tuning or theft,

293
00:11:37,019 --> 00:11:39,259
where you freeze the base layers and train

294
00:11:39,259 --> 00:11:41,629
only a set of added low rank

295
00:11:41,629 --> 00:11:43,849
parameters, also known as adapters.

296
00:11:44,259 --> 00:11:46,940
They're called low rank because they are of a lower dimension

297
00:11:46,940 --> 00:11:49,058
or rank compared to the weights of the base

298
00:11:49,058 --> 00:11:51,719
model. You

299
00:11:51,719 --> 00:11:53,820
start by adapting a model

300
00:11:53,820 --> 00:11:56,599
to a specific task by using a relatively

301
00:11:57,099 --> 00:11:58,879
small labeled data set.

302
00:11:59,649 --> 00:12:02,090
As such, this is also referred to as supervised

303
00:12:02,090 --> 00:12:02,649
fine tuning.

304
00:12:05,149 --> 00:12:07,239
We use direct preference optimization

305
00:12:07,239 --> 00:12:09,320
or DPO when you want to align

306
00:12:09,320 --> 00:12:11,869
the model to a very specific user preference

307
00:12:11,869 --> 00:12:13,678
without having to train a reward model.

308
00:12:15,450 --> 00:12:17,769
You can do DPO either in a performance

309
00:12:17,769 --> 00:12:20,029
efficient way, as we discussed above, or

310
00:12:20,029 --> 00:12:21,330
you could do a full DPO.

311
00:12:23,950 --> 00:12:26,000
Proximal policy optimization, or

312
00:12:26,000 --> 00:12:28,000
PPO is a way to improve

313
00:12:28,000 --> 00:12:30,058
your model based on live feedback.

314
00:12:31,418 --> 00:12:33,460
How do you get that live feedback? You can

315
00:12:33,460 --> 00:12:35,859
get that via a task completion,

316
00:12:36,058 --> 00:12:38,090
a tool execution, or more commonly,

317
00:12:38,099 --> 00:12:39,739
via direct human feedback.

318
00:12:41,320 --> 00:12:43,619
A few important things to remember here is that

319
00:12:44,000 --> 00:12:46,320
you will need a full cycle of reinforcement

320
00:12:46,320 --> 00:12:48,479
learning here and as such you will need a reward

321
00:12:48,479 --> 00:12:49,519
model and a function.

322
00:12:50,399 --> 00:12:52,599
This is also more costly and time

323
00:12:52,599 --> 00:12:53,239
consuming,

324
00:12:53,558 --> 00:12:55,678
but can give you really good results for

325
00:12:55,678 --> 00:12:57,239
very specific use cases.

326
00:13:00,009 --> 00:13:02,489
Model distillation is a technique where you distill

327
00:13:02,489 --> 00:13:04,649
complex behaviors from a larger

328
00:13:04,649 --> 00:13:06,739
and a high performing model known

329
00:13:06,739 --> 00:13:08,029
as the teacher model

330
00:13:08,288 --> 00:13:10,489
to a smaller and a more efficient model

331
00:13:10,489 --> 00:13:12,330
that we refer to as a student model.

332
00:13:13,229 --> 00:13:14,469
As we saw earlier,

333
00:13:14,788 --> 00:13:16,989
distillation can directly help reduce

334
00:13:16,989 --> 00:13:19,269
your latency and cost at a task level.

335
00:13:22,200 --> 00:13:24,200
Continuous pre-training, as the name implies, is

336
00:13:24,200 --> 00:13:26,298
a pre-training technique where you continue

337
00:13:26,298 --> 00:13:28,479
to train on the pre-training

338
00:13:28,479 --> 00:13:30,259
checkpoints of the base model

339
00:13:30,519 --> 00:13:32,840
using a large corpus of unlabeled

340
00:13:32,840 --> 00:13:34,960
data. Now

341
00:13:34,960 --> 00:13:37,119
again, important points over here is that you

342
00:13:37,119 --> 00:13:39,200
will need a large corpus of unlabeled

343
00:13:39,200 --> 00:13:40,700
domain-specific data.

344
00:13:41,658 --> 00:13:43,739
You should also

345
00:13:43,739 --> 00:13:46,019
watch out for risks such as overfitting

346
00:13:46,019 --> 00:13:47,479
and catastrophic forgetting.

347
00:13:48,558 --> 00:13:50,639
There are additional techniques that you can do

348
00:13:50,639 --> 00:13:52,239
such as early stopping

349
00:13:52,558 --> 00:13:54,759
or implementing intelligent

350
00:13:54,759 --> 00:13:57,099
data mixing to mitigate some of these risks.

351
00:13:57,639 --> 00:13:59,719
And David will cover a lot about this

352
00:13:59,719 --> 00:14:02,219
as he goes into the Sagemaker customization.

353
00:14:09,129 --> 00:14:11,570
Now, uh, moving on to Amazon Nova.

354
00:14:11,928 --> 00:14:12,509
So,

355
00:14:12,969 --> 00:14:14,690
how many of you have used Nova over here?

356
00:14:16,629 --> 00:14:17,219
Quite a few.

357
00:14:17,700 --> 00:14:19,960
So we, we had a big release

358
00:14:19,960 --> 00:14:22,019
just a couple of days back. This, this slide is

359
00:14:22,019 --> 00:14:24,109
not updated to cover all of those releases, but I

360
00:14:24,109 --> 00:14:25,658
will happily talk through all of them.

361
00:14:27,239 --> 00:14:29,389
So at the very top, we have our understanding

362
00:14:29,389 --> 00:14:31,788
and reasoning models, starting with Nova Micro,

363
00:14:31,830 --> 00:14:33,989
which is our fastest and most efficient text

364
00:14:33,989 --> 00:14:34,969
to text model.

365
00:14:35,509 --> 00:14:37,509
Uh, we see a lot of customers use

366
00:14:37,509 --> 00:14:39,590
micro in their latency sensitive

367
00:14:39,590 --> 00:14:41,859
agentic work uh workflows.

368
00:14:43,369 --> 00:14:44,308
Next we have our

369
00:14:44,690 --> 00:14:47,129
multi-modal understanding and reasoning models

370
00:14:47,129 --> 00:14:49,250
Light, Premiere and Pro, Light

371
00:14:49,250 --> 00:14:50,070
Pro and Premiere,

372
00:14:50,369 --> 00:14:52,690
each increasing in intelligence, with Premiere

373
00:14:52,690 --> 00:14:54,710
being our most performant model

374
00:14:55,168 --> 00:14:57,210
until 2 days back, because 2 days back

375
00:14:57,210 --> 00:14:58,729
we released Nova 2 Pro,

376
00:14:59,009 --> 00:15:01,009
which is now the most performant

377
00:15:01,009 --> 00:15:02,250
model that is available.

378
00:15:04,058 --> 00:15:06,359
A lot of customers use Premiere, used

379
00:15:06,359 --> 00:15:08,428
to use Premiere in the past as the teacher

380
00:15:08,428 --> 00:15:10,389
model within the distillation pipelines.

381
00:15:12,139 --> 00:15:13,899
Now they'll probably use pro.

382
00:15:15,580 --> 00:15:17,700
Next, we have our creative content generation

383
00:15:17,700 --> 00:15:19,899
model, uh, starting with Nova

384
00:15:19,899 --> 00:15:22,048
Canvas, which is our text to image

385
00:15:22,048 --> 00:15:22,639
generation model,

386
00:15:22,899 --> 00:15:25,500
and Nova Reels, which is our text to video

387
00:15:25,500 --> 00:15:26,019
generation model.

388
00:15:27,359 --> 00:15:29,428
2 days back we also announced Nova

389
00:15:29,428 --> 00:15:31,599
2 Omni, which is the state of the art

390
00:15:31,599 --> 00:15:33,719
and more performance text to image

391
00:15:33,719 --> 00:15:34,239
generation model.

392
00:15:36,719 --> 00:15:39,119
Next we have Amazon Nova Sonic, which is the

393
00:15:39,119 --> 00:15:41,279
industry's first real-time speech to

394
00:15:41,279 --> 00:15:43,599
speech model delivering frontier capabilities

395
00:15:43,599 --> 00:15:46,000
such as automatic speaker recognition,

396
00:15:46,158 --> 00:15:48,428
speaker dialization, polyglot voices,

397
00:15:48,678 --> 00:15:50,418
as well as multilingual support.

398
00:15:52,558 --> 00:15:54,678
Nova Act became generally

399
00:15:54,678 --> 00:15:56,320
available 2 days back as well,

400
00:15:56,719 --> 00:15:58,759
and it is an agentic browser

401
00:15:58,759 --> 00:16:00,879
use model specifically designed

402
00:16:00,879 --> 00:16:03,320
to build agents that operate within your browser.

403
00:16:04,408 --> 00:16:06,729
We talked about agents taking actions in an

404
00:16:06,729 --> 00:16:08,769
environment and one of those actions could be a web

405
00:16:08,769 --> 00:16:10,788
browser. So if you are building an agent

406
00:16:10,788 --> 00:16:12,788
that's designed to operate within

407
00:16:12,788 --> 00:16:15,038
a web browser, then NA Act is a model

408
00:16:15,038 --> 00:16:16,599
specifically designed to do that.

409
00:16:21,989 --> 00:16:24,070
Now we all know that embeddings

410
00:16:24,070 --> 00:16:26,279
are the foundation of any generative

411
00:16:26,279 --> 00:16:28,969
AI application or an agentic AI

412
00:16:28,969 --> 00:16:30,969
application. Very recently,

413
00:16:31,129 --> 00:16:33,428
in fact, a couple of months back, we released the Nova

414
00:16:33,428 --> 00:16:34,979
multimodal embeddings model,

415
00:16:35,349 --> 00:16:37,590
which is the only embeddings model that is

416
00:16:37,590 --> 00:16:39,658
available in the industry that will

417
00:16:39,658 --> 00:16:42,139
generate embeddings for all your multimodal

418
00:16:42,139 --> 00:16:43,009
data, which is

419
00:16:43,298 --> 00:16:45,509
text, video, images, and audio

420
00:16:45,509 --> 00:16:46,928
within the same vector space.

421
00:16:47,690 --> 00:16:50,000
Why this is important is that this enables

422
00:16:50,000 --> 00:16:52,070
you to build really powerful

423
00:16:52,070 --> 00:16:54,158
applications that utilize semantic

424
00:16:54,158 --> 00:16:55,649
search and agentic rag.

425
00:16:58,019 --> 00:17:00,500
Last but not the least, we have our Nova public

426
00:17:00,500 --> 00:17:02,279
website, nova.amazon.com,

427
00:17:02,859 --> 00:17:04,979
where you can try out any of these models

428
00:17:04,979 --> 00:17:06,979
free of charge or without needing

429
00:17:06,979 --> 00:17:08,160
an AWS account.

430
00:17:14,509 --> 00:17:15,828
Now the chart here looks busy,

431
00:17:16,509 --> 00:17:18,598
but if you look at this, Nova provides

432
00:17:18,598 --> 00:17:20,759
a broad range of customization

433
00:17:20,759 --> 00:17:22,799
options both on Amazon Bedrock as

434
00:17:22,799 --> 00:17:23,920
well as Sagemaker AI.

435
00:17:26,029 --> 00:17:28,868
Most of these options are available both as

436
00:17:28,868 --> 00:17:31,269
full rank options as well as

437
00:17:31,269 --> 00:17:33,469
performance efficient low rank options that we

438
00:17:33,469 --> 00:17:34,068
discussed above.

439
00:17:35,848 --> 00:17:38,039
Depending on the option you choose, you can choose

440
00:17:38,039 --> 00:17:40,098
to do your customization either on

441
00:17:40,098 --> 00:17:42,539
Bedrock or you can do the customization

442
00:17:42,539 --> 00:17:43,818
on Sagemaker AI.

443
00:17:44,209 --> 00:17:46,380
Once you are done, you can deploy

444
00:17:46,380 --> 00:17:48,578
this model in a Cerberus manner

445
00:17:48,578 --> 00:17:50,618
on Amazon Bedrock. For example, if

446
00:17:50,618 --> 00:17:52,439
you choose to do model distillation,

447
00:17:52,900 --> 00:17:54,979
you can choose to do that very quickly

448
00:17:54,979 --> 00:17:56,318
on Amazon Bedrock

449
00:17:56,660 --> 00:17:58,858
or build your own distillation pipeline

450
00:17:58,858 --> 00:17:59,939
on Sagemaker AI.

451
00:18:00,890 --> 00:18:03,400
Once done, you can import your distilled

452
00:18:03,400 --> 00:18:05,449
model onto Amazon Bedrock

453
00:18:05,449 --> 00:18:07,868
and deploy it using on-demand inference

454
00:18:08,059 --> 00:18:09,269
or provision throughput.

455
00:18:10,199 --> 00:18:12,400
And we'll talk much more about these

456
00:18:12,400 --> 00:18:14,439
deployment options as we progress further.

457
00:18:16,000 --> 00:18:16,910
But for now,

458
00:18:17,489 --> 00:18:20,410
let's look at specifically the Nova customization

459
00:18:20,410 --> 00:18:22,229
options available on Amazon Bedrock,

460
00:18:22,848 --> 00:18:23,969
starting with fine tuning.

461
00:18:26,259 --> 00:18:28,459
Now we talked about fine tuning. We also covered

462
00:18:28,459 --> 00:18:30,598
full fine tuning where you modify the

463
00:18:31,059 --> 00:18:33,539
weights of the base model as well as performance efficient

464
00:18:33,539 --> 00:18:34,680
fine tuning where you

465
00:18:35,049 --> 00:18:37,479
train a set of added low rank parameters.

466
00:18:38,059 --> 00:18:40,259
On Bedrock, you can do performance efficient

467
00:18:40,259 --> 00:18:42,500
fine tuning and deploy your model

468
00:18:42,500 --> 00:18:43,660
in just a few clicks.

469
00:18:45,338 --> 00:18:47,420
Since this is a form of supervised

470
00:18:47,420 --> 00:18:49,539
fine tuning, you start by uploading a

471
00:18:49,539 --> 00:18:51,670
set of labeled data and kickstart

472
00:18:51,670 --> 00:18:52,880
your fine tuning job.

473
00:18:54,219 --> 00:18:55,699
Once your job completes,

474
00:18:56,130 --> 00:18:58,180
the model is available on the Bedrock

475
00:18:58,180 --> 00:19:00,489
platform just as any other Bedrock model

476
00:19:00,489 --> 00:19:01,848
for evaluation and testing.

477
00:19:03,939 --> 00:19:06,068
You could also try out the model

478
00:19:06,068 --> 00:19:08,118
on the Bedrock model playground before

479
00:19:08,118 --> 00:19:10,150
you decide to scale or deploy them.

480
00:19:12,549 --> 00:19:14,789
One common use case agentic

481
00:19:14,789 --> 00:19:17,549
AI use case that we see for

482
00:19:17,549 --> 00:19:19,670
this type of fine tuning is for tool

483
00:19:19,670 --> 00:19:21,709
calling and schema stickiness, where

484
00:19:21,709 --> 00:19:23,868
you want the model to emit a very

485
00:19:23,868 --> 00:19:26,068
specific Jason schema consistently.

486
00:19:28,299 --> 00:19:30,348
Another good example over here is

487
00:19:30,348 --> 00:19:32,449
for persona switching, where you want to use

488
00:19:32,449 --> 00:19:34,789
the same base model across your agentic

489
00:19:34,789 --> 00:19:36,910
AI workflow and have it switch

490
00:19:36,910 --> 00:19:39,068
between multiple personas such as sales and

491
00:19:39,068 --> 00:19:42,598
support. Now

492
00:19:42,598 --> 00:19:44,858
as a quick recap, model distillation is a technique

493
00:19:44,858 --> 00:19:46,989
where you distill complex behavior from a

494
00:19:46,989 --> 00:19:49,318
larger and a highly performant model

495
00:19:49,318 --> 00:19:51,338
to a smaller and more efficient model.

496
00:19:52,338 --> 00:19:54,338
Now, have you, how many of you have

497
00:19:54,338 --> 00:19:55,578
done model distillation here?

498
00:19:57,309 --> 00:19:59,269
Very cool. We have one gentleman over there.

499
00:20:00,199 --> 00:20:02,289
So if you have done model distillation, one

500
00:20:02,289 --> 00:20:04,489
of the biggest challenges with model distillation

501
00:20:04,489 --> 00:20:06,618
is building a robust data pipeline

502
00:20:06,618 --> 00:20:07,568
for your distillation.

503
00:20:08,618 --> 00:20:10,979
With Bedrock, you can do model distillation

504
00:20:10,979 --> 00:20:12,259
again in just a few clicks.

505
00:20:13,838 --> 00:20:15,959
Now if you think about it, distillation is just a

506
00:20:15,959 --> 00:20:18,420
type of fine tuning with a teacher model in the loop.

507
00:20:19,400 --> 00:20:21,608
What I mean by that is when you do this on Bedrock,

508
00:20:21,650 --> 00:20:23,750
you start by picking your teacher model

509
00:20:23,750 --> 00:20:24,969
and your student model.

510
00:20:26,039 --> 00:20:28,039
You upload a set of task

511
00:20:28,039 --> 00:20:30,160
specific prompts, just the prompts, not

512
00:20:30,160 --> 00:20:31,039
the responses.

513
00:20:32,588 --> 00:20:34,868
Bedrock will automatically use the teacher model

514
00:20:34,868 --> 00:20:36,868
to generate the responses for your

515
00:20:36,868 --> 00:20:37,989
prompts that you uploaded.

516
00:20:38,789 --> 00:20:40,900
It will then use the prompts

517
00:20:40,910 --> 00:20:43,029
and the responses generated by the

518
00:20:43,029 --> 00:20:45,068
teacher model to fine tune the student

519
00:20:45,068 --> 00:20:47,608
model. A

520
00:20:47,608 --> 00:20:49,789
good example over here is productionizing

521
00:20:49,789 --> 00:20:51,449
a high performing prototype.

522
00:20:51,969 --> 00:20:54,250
For example, if your prototype

523
00:20:54,250 --> 00:20:56,640
only works with a high performing model,

524
00:20:57,009 --> 00:20:59,439
you can choose to distill those specific

525
00:20:59,439 --> 00:21:01,489
behaviors into a smaller variant of the

526
00:21:01,489 --> 00:21:03,650
model as you deploy and scale

527
00:21:03,650 --> 00:21:04,608
it in your production.

528
00:21:06,358 --> 00:21:08,578
Now talking about deployment, Bedrock offers

529
00:21:08,578 --> 00:21:11,019
two modes of deployment on-demand inference,

530
00:21:11,420 --> 00:21:13,959
which is token-based pay as you go pricing,

531
00:21:14,259 --> 00:21:16,299
as well as provision throughput, where you pay

532
00:21:16,299 --> 00:21:18,500
a fixed price upfront for guaranteed

533
00:21:18,500 --> 00:21:22,209
throughput. With

534
00:21:22,209 --> 00:21:24,250
that, we'll move over to the sage maker side of

535
00:21:24,250 --> 00:21:26,279
customization, which David will

536
00:21:26,279 --> 00:21:27,309
happily take us through.

537
00:21:29,439 --> 00:21:30,160
Thank you, Sam.

538
00:21:33,519 --> 00:21:34,039
Awesome.

539
00:21:35,699 --> 00:21:37,439
I don't know if you guys saw the mind map

540
00:21:37,858 --> 00:21:40,029
before about the different techniques of customizing

541
00:21:40,029 --> 00:21:42,098
uh uh Nova. I just wanna call out that

542
00:21:42,098 --> 00:21:43,348
it's a work that Sam did.

543
00:21:43,900 --> 00:21:46,368
Uh, I think it's one of the best mind maps that I've seen in AWS

544
00:21:46,368 --> 00:21:48,500
in the last 7 years that I've been in this

545
00:21:48,500 --> 00:21:50,539
company, so I really wanna do a shout out to the

546
00:21:50,539 --> 00:21:51,539
work that he has done

547
00:21:51,900 --> 00:21:53,959
and to the work that he will do now that he goes back

548
00:21:53,959 --> 00:21:55,729
because we have released new techniques now.

549
00:21:56,019 --> 00:21:58,328
So you know that the first thing Monday is gonna do

550
00:21:58,328 --> 00:22:00,660
when he comes back, it will be to update that that

551
00:22:00,660 --> 00:22:02,979
slide. Awesome.

552
00:22:03,250 --> 00:22:05,608
But let's focus now for a second on other

553
00:22:05,608 --> 00:22:07,430
customization techniques. So you've seen

554
00:22:07,848 --> 00:22:10,170
how to perform customization using Amazon

555
00:22:10,170 --> 00:22:10,910
Bedrock so far

556
00:22:11,410 --> 00:22:13,969
with the theft and with the model distillation

557
00:22:13,969 --> 00:22:14,828
capabilities,

558
00:22:15,289 --> 00:22:17,000
but let's go a little bit deeper, right?

559
00:22:17,328 --> 00:22:19,489
So if you're a little bit more advanced

560
00:22:19,489 --> 00:22:21,469
and you wanna have a little bit more control

561
00:22:22,130 --> 00:22:23,769
on the fine tuning process,

562
00:22:24,170 --> 00:22:26,410
Bedrock is still gonna give you a lot of bells and whistles

563
00:22:26,410 --> 00:22:28,130
and a lot of knobs to turns.

564
00:22:28,529 --> 00:22:30,729
However, if you wanna have a lower level

565
00:22:30,729 --> 00:22:32,848
understanding and a lower level impact on

566
00:22:32,848 --> 00:22:33,910
the training process,

567
00:22:34,328 --> 00:22:36,380
SageMaker must be your go to tool.

568
00:22:36,729 --> 00:22:38,848
It's an end to end machine learning platform, machine

569
00:22:38,848 --> 00:22:40,719
learning engine AI platform, of course,

570
00:22:41,009 --> 00:22:43,049
which allows you to choose a model that

571
00:22:43,049 --> 00:22:44,150
you want to fine tune.

572
00:22:44,608 --> 00:22:46,650
Perform fine tuning using the option

573
00:22:46,650 --> 00:22:48,729
you prefer, and we have two examples

574
00:22:48,729 --> 00:22:51,229
here, the training jobs API

575
00:22:51,229 --> 00:22:53,328
for fully managed and

576
00:22:53,328 --> 00:22:54,150
server-less

577
00:22:54,568 --> 00:22:57,209
model fine-tuning. We have announced the serverless fine-tuning

578
00:22:57,568 --> 00:22:59,769
just yesterday morning, so I really

579
00:22:59,769 --> 00:23:00,969
suggest you guys check that out.

580
00:23:01,799 --> 00:23:04,180
Or you can have a complete

581
00:23:04,348 --> 00:23:06,400
orchestration managed by yourself,

582
00:23:06,699 --> 00:23:07,500
yourself truly

583
00:23:07,838 --> 00:23:09,559
in the form of Sagemaker Hyperpod.

584
00:23:09,920 --> 00:23:12,279
Hyperpod is a managed cluster based

585
00:23:12,279 --> 00:23:14,088
either on EKS or on SLUM

586
00:23:14,598 --> 00:23:16,180
and allows you to really go

587
00:23:16,640 --> 00:23:18,680
low, a level deeper, managing

588
00:23:18,680 --> 00:23:19,660
the infrastructure

589
00:23:20,039 --> 00:23:21,479
for your training workloads.

590
00:23:22,699 --> 00:23:24,939
It allows you to really customize what kind of orchestration

591
00:23:24,939 --> 00:23:26,729
you wanna do, as I was saying, through Slur Marques.

592
00:23:27,500 --> 00:23:29,539
It allows you to also schedule the workloads

593
00:23:29,539 --> 00:23:31,739
to make sure that you get the best of the

594
00:23:31,739 --> 00:23:33,598
resources that you're actually paying for.

595
00:23:35,759 --> 00:23:38,160
But not just that, SageMaker also provides

596
00:23:38,160 --> 00:23:40,199
optimized recipes for you to

597
00:23:40,199 --> 00:23:42,358
make sure that your training is

598
00:23:42,358 --> 00:23:43,019
successful

599
00:23:44,400 --> 00:23:45,239
and works well the first time.

600
00:23:46,068 --> 00:23:48,189
So, what you've gotta focus on is not

601
00:23:48,189 --> 00:23:50,348
figuring out what is the best code that you need to write

602
00:23:50,348 --> 00:23:51,078
for your training loop.

603
00:23:51,989 --> 00:23:54,209
Most of the time we see customers focusing on

604
00:23:54,390 --> 00:23:56,410
the data science process, generating

605
00:23:56,410 --> 00:23:57,739
the data if they don't have it,

606
00:23:58,108 --> 00:24:00,108
cleaning their data if they already have

607
00:24:00,108 --> 00:24:02,549
that. And then provide this data

608
00:24:02,549 --> 00:24:04,469
to already well-known scripts.

609
00:24:04,890 --> 00:24:05,910
So what we have done

610
00:24:06,328 --> 00:24:08,368
in the back end is that we have taken those

611
00:24:08,368 --> 00:24:10,779
scripts, we have customized some of those scripts,

612
00:24:10,930 --> 00:24:12,930
making sure that they perform the best in

613
00:24:12,930 --> 00:24:15,130
our architecture, and we have packaged

614
00:24:15,130 --> 00:24:17,108
them in the form of recipes.

615
00:24:17,449 --> 00:24:19,608
Now we call them hyperpod recipes, but they're

616
00:24:19,608 --> 00:24:21,689
also working foragemer

617
00:24:21,689 --> 00:24:22,380
training jobs.

618
00:24:22,689 --> 00:24:25,088
So if you prefer a more serverless or managed

619
00:24:25,088 --> 00:24:27,289
approach to training your model, absolutely

620
00:24:27,289 --> 00:24:29,430
go ahead and use the SageMaker training job,

621
00:24:29,519 --> 00:24:30,469
or SMTJ.

622
00:24:31,000 --> 00:24:33,108
Or otherwise, if you want to have a lower level

623
00:24:33,108 --> 00:24:35,000
of customization and orchestration,

624
00:24:35,368 --> 00:24:37,410
those are also compatible for Hyperpod.

625
00:24:38,959 --> 00:24:41,039
So, let's take a deeper look at how those

626
00:24:41,039 --> 00:24:42,420
rep recipes work.

627
00:24:42,959 --> 00:24:45,078
So, first of all, you're gonna go ahead and select your

628
00:24:45,078 --> 00:24:46,019
Nova recipe.

629
00:24:46,400 --> 00:24:48,439
You're gonna go ahead and make an API call to

630
00:24:48,439 --> 00:24:49,598
Sage Maker control plane,

631
00:24:49,920 --> 00:24:51,959
which will then leverage some of the launchers that

632
00:24:51,959 --> 00:24:53,949
we have available in SageMaker,

633
00:24:54,318 --> 00:24:57,039
spin up the right training job on the Hyperpod

634
00:24:57,039 --> 00:24:59,338
instance, download the ECR

635
00:24:59,680 --> 00:25:01,838
training image directly on those

636
00:25:01,838 --> 00:25:03,199
instances that have been deployed.

637
00:25:03,500 --> 00:25:05,509
And then finally, load the data

638
00:25:05,509 --> 00:25:07,949
from the different data sources that you have. Whether

639
00:25:07,949 --> 00:25:10,380
they are S3, whether they are FSX,

640
00:25:10,469 --> 00:25:12,130
whether they are uh

641
00:25:12,670 --> 00:25:13,269
EFS.

642
00:25:13,930 --> 00:25:15,789
I know the image is a little bit fast,

643
00:25:16,529 --> 00:25:18,729
and uh this is an image that I took from one of the blogs

644
00:25:18,729 --> 00:25:20,930
that is publicly available. So if you guys wanna

645
00:25:20,930 --> 00:25:23,269
learn more about how Sage Maker recipes

646
00:25:23,410 --> 00:25:25,559
help you understand and how to help

647
00:25:25,559 --> 00:25:26,430
simplify

648
00:25:26,809 --> 00:25:28,930
training a model using SageMaker, you might

649
00:25:28,930 --> 00:25:31,199
wanna scan the QR code that you see here on the right,

650
00:25:31,368 --> 00:25:33,368
which will actually take you directly to the

651
00:25:33,368 --> 00:25:35,368
blog post introducing this

652
00:25:35,368 --> 00:25:36,549
uh this infrastructure.

653
00:25:38,420 --> 00:25:40,489
I see a lot of people are taking pictures, so I'm gonna wait a

654
00:25:40,489 --> 00:25:41,920
second until the full image is there,

655
00:25:42,180 --> 00:25:43,279
and you guys gotta be fast.

656
00:25:44,939 --> 00:25:46,559
There you go, now is the moment for the photo.

657
00:25:47,279 --> 00:25:48,500
Perfect. All right.

658
00:25:49,509 --> 00:25:51,509
Those lights will be sent offline anyway, so

659
00:25:51,509 --> 00:25:53,630
don't worry if you can't really be as fast

660
00:25:53,630 --> 00:25:55,709
as possible in taking that picture. It's

661
00:25:55,709 --> 00:25:57,789
all available online. Once again, the blog

662
00:25:57,789 --> 00:25:58,789
is gonna be your best friend.

663
00:25:59,709 --> 00:26:01,828
So what I'm going to do now instead is gonna walk you

664
00:26:01,828 --> 00:26:04,068
through a quick demo of how to

665
00:26:04,068 --> 00:26:06,670
perform all of what I showed you in the architecture

666
00:26:06,670 --> 00:26:08,680
before, actually do it in the studio console.

667
00:26:09,420 --> 00:26:11,469
So one heads up I want to give you before I start

668
00:26:11,469 --> 00:26:13,670
the demo is that as you know, we

669
00:26:13,670 --> 00:26:15,650
have released a lot of things during this week.

670
00:26:16,390 --> 00:26:17,088
Including

671
00:26:17,469 --> 00:26:19,588
some minor updates to the console in

672
00:26:19,588 --> 00:26:20,709
the Sagemaker studio.

673
00:26:21,029 --> 00:26:22,328
So what you see right now

674
00:26:22,680 --> 00:26:24,939
was true until two days ago,

675
00:26:25,430 --> 00:26:27,549
but because we have to prepare the slides ahead of time,

676
00:26:27,630 --> 00:26:29,670
we haven't had the time to update it yet to the

677
00:26:29,670 --> 00:26:30,189
new video.

678
00:26:30,500 --> 00:26:32,509
However, the concept that I wanna, whether

679
00:26:32,509 --> 00:26:34,680
I'm gonna walk you through and talk you through,

680
00:26:34,949 --> 00:26:36,759
are actually gonna be exactly the same,

681
00:26:37,049 --> 00:26:38,729
regardless of what the UI looks like,

682
00:26:39,309 --> 00:26:41,848
right? So let's get started doing a

683
00:26:41,848 --> 00:26:44,150
prefer direct preference optimization with SageMaker AI

684
00:26:44,150 --> 00:26:45,068
on Nova models.

685
00:26:46,699 --> 00:26:48,900
So, how does that work? So, you jump into Sage

686
00:26:48,900 --> 00:26:49,559
Maker Studio,

687
00:26:49,900 --> 00:26:52,098
you have a use case that you wanna solve, you already

688
00:26:52,098 --> 00:26:53,818
have in your brain, what is your use case.

689
00:26:54,098 --> 00:26:55,848
So you need to figure out where to start.

690
00:26:56,209 --> 00:26:58,338
Starting point is always the jumpstart

691
00:26:58,338 --> 00:27:00,459
hub in this case, because Nova is available

692
00:27:00,459 --> 00:27:02,539
as part of the jumpstart model hub. Now it's

693
00:27:02,539 --> 00:27:03,799
called just models.

694
00:27:04,380 --> 00:27:06,180
You select the model that you wanna use.

695
00:27:06,578 --> 00:27:08,809
Sam was talking about Nova Micro before,

696
00:27:09,019 --> 00:27:11,098
but now you can use Nova 2.0 Lite, etc.

697
00:27:11,170 --> 00:27:13,739
etc. And then select

698
00:27:13,739 --> 00:27:15,739
the train button all the way

699
00:27:15,739 --> 00:27:16,410
up top,

700
00:27:16,818 --> 00:27:18,858
which effectively allows you to choose the

701
00:27:18,858 --> 00:27:19,979
right training option.

702
00:27:20,660 --> 00:27:22,880
I think this got stuck somehow, so.

703
00:27:23,848 --> 00:27:24,358
Let me

704
00:27:26,180 --> 00:27:27,848
Let me start that again real quick.

705
00:27:33,699 --> 00:27:36,259
The good thing about live demos, even the recording

706
00:27:36,259 --> 00:27:37,818
sometimes can break, all right?

707
00:27:38,259 --> 00:27:39,979
PowerPoint is not always our friend.

708
00:27:40,930 --> 00:27:41,489
But you know,

709
00:27:41,818 --> 00:27:43,608
let's recap. Let's go to the jumpstart.

710
00:27:43,868 --> 00:27:46,130
Let's choose the right model from the model hub.

711
00:27:46,420 --> 00:27:48,420
There's many models out there. We're focusing on

712
00:27:48,420 --> 00:27:50,539
Nova right now, but there's also Lama model,

713
00:27:50,650 --> 00:27:52,799
Queen model, Mistral model, really,

714
00:27:52,900 --> 00:27:53,519
uh,

715
00:27:54,189 --> 00:27:56,289
you, it's just a matter of choice. Choose the right one for your

716
00:27:56,289 --> 00:27:56,920
use case.

717
00:27:57,699 --> 00:28:00,059
Some of them will be trainable, so you can select

718
00:28:00,059 --> 00:28:01,559
train all the way up top.

719
00:28:02,269 --> 00:28:04,479
And then you get to choose the right techniques

720
00:28:04,479 --> 00:28:05,078
that you want,

721
00:28:05,400 --> 00:28:07,479
whether it's supervised fine tuning, whether it's direct

722
00:28:07,479 --> 00:28:09,588
preference optimization. It tells you which

723
00:28:09,588 --> 00:28:11,588
compute, it tells you what format

724
00:28:11,588 --> 00:28:12,630
of data do you need,

725
00:28:12,959 --> 00:28:15,039
so make sure that you have data in the right

726
00:28:15,039 --> 00:28:17,118
format before starting your

727
00:28:17,118 --> 00:28:19,469
job. It shows you the code

728
00:28:19,469 --> 00:28:21,509
for the notebook itself, so you don't have to

729
00:28:21,509 --> 00:28:23,539
do anything through the UI if you don't want

730
00:28:23,539 --> 00:28:25,430
to. You are provided with the code.

731
00:28:26,140 --> 00:28:28,229
In this example, I'll walk through the recipe

732
00:28:28,229 --> 00:28:30,229
using the recipe in StageMaker Hyperpot,

733
00:28:30,269 --> 00:28:32,189
but you can also use the training jobs.

734
00:28:33,259 --> 00:28:35,410
Make sure you have a training cluster available,

735
00:28:35,500 --> 00:28:37,219
so a hyperpod cluster available.

736
00:28:37,500 --> 00:28:39,239
In this case, it is a restricted instance group

737
00:28:40,338 --> 00:28:42,618
cluster type inage maker, Hyperpod,

738
00:28:42,979 --> 00:28:45,019
and then all you have to do is just select

739
00:28:45,019 --> 00:28:47,259
that cluster and click the notebook

740
00:28:47,259 --> 00:28:48,838
to click the button to open

741
00:28:49,380 --> 00:28:51,578
the notebook in the right, uh, Jupiter lab

742
00:28:51,578 --> 00:28:52,279
space running

743
00:28:52,779 --> 00:28:54,259
on top of the Hyperpod cluster.

744
00:28:55,489 --> 00:28:57,489
Of course, these notebooks are publicly available. They

745
00:28:57,489 --> 00:28:59,489
are available in the Gitup repository. So, if

746
00:28:59,489 --> 00:29:01,769
you don't wanna go through having a hyperpod cluster,

747
00:29:02,000 --> 00:29:03,769
you can just pull the notebook directly from the web.

748
00:29:04,920 --> 00:29:07,039
The Notebook contains a bunch of information, contains

749
00:29:07,039 --> 00:29:09,219
the usual prerequisites, the usual installation,

750
00:29:09,549 --> 00:29:11,578
running the different code. It shows you what

751
00:29:11,578 --> 00:29:13,098
is the code to actually run

752
00:29:13,479 --> 00:29:15,559
the start the training job, and you will see that

753
00:29:15,559 --> 00:29:17,828
we pointed to the recipes,

754
00:29:18,160 --> 00:29:20,239
and once you start the actual

755
00:29:20,239 --> 00:29:22,239
training job from the Hyperpod cluster,

756
00:29:22,519 --> 00:29:24,380
all the information will be available

757
00:29:24,640 --> 00:29:26,838
in the available tasks in

758
00:29:26,838 --> 00:29:27,799
Sage Baker Hyperpod.

759
00:29:30,779 --> 00:29:33,059
So, if we go back to the end

760
00:29:33,059 --> 00:29:33,809
to end path for

761
00:29:34,900 --> 00:29:36,890
model customization and for creating agents,

762
00:29:37,299 --> 00:29:39,078
now we've gone through customization,

763
00:29:39,380 --> 00:29:41,578
but the next step is evaluating the model.

764
00:29:42,469 --> 00:29:44,549
So how do you go about evaluating

765
00:29:44,549 --> 00:29:45,229
an LLM?

766
00:29:45,868 --> 00:29:47,939
There's different techniques, there are different metrics,

767
00:29:48,029 --> 00:29:49,449
and we're, there is no

768
00:29:49,739 --> 00:29:50,689
silver bullet

769
00:29:50,949 --> 00:29:52,939
to correct to correctly perform evaluation.

770
00:29:53,289 --> 00:29:55,799
You will have different techniques. You will have general metrics.

771
00:29:56,088 --> 00:29:58,250
You can use, for example, perplexity or accuracy

772
00:29:58,250 --> 00:30:00,489
to to statistically evaluate

773
00:30:00,489 --> 00:30:01,680
the quality of the model,

774
00:30:02,019 --> 00:30:04,130
but you can also go a little bit deeper and

775
00:30:04,130 --> 00:30:04,640
for example,

776
00:30:04,969 --> 00:30:05,509
consider

777
00:30:05,848 --> 00:30:07,969
tasks specific metrics. This is very

778
00:30:07,969 --> 00:30:10,318
relevant, especially in the world of agents,

779
00:30:10,650 --> 00:30:12,920
where you wanna make sure that the agent actually follows,

780
00:30:12,949 --> 00:30:14,449
for example, the trajectory.

781
00:30:15,229 --> 00:30:17,088
Of solving the problem in the right way.

782
00:30:17,549 --> 00:30:19,309
Although the results might be the same,

783
00:30:19,670 --> 00:30:21,670
a model or an agent can take

784
00:30:21,670 --> 00:30:22,568
10 steps,

785
00:30:22,828 --> 00:30:24,630
whereas another one can take 2 steps.

786
00:30:25,358 --> 00:30:27,358
So it could be a number of steps, it

787
00:30:27,358 --> 00:30:29,439
could be the quality of the steps that are being executed

788
00:30:29,439 --> 00:30:29,959
in between.

789
00:30:30,858 --> 00:30:33,140
Of course, we can't forget about hallucinations,

790
00:30:33,219 --> 00:30:35,608
bias and toxic toxicity metrics.

791
00:30:35,979 --> 00:30:37,979
So all of those kind of metrics, they

792
00:30:37,979 --> 00:30:40,059
need to be taken into account for evaluating

793
00:30:40,059 --> 00:30:41,059
the model the right way.

794
00:30:43,029 --> 00:30:45,430
So how can you perform evaluation of a model?

795
00:30:46,509 --> 00:30:49,140
Classically, you would go with a rule-based heuristics.

796
00:30:49,598 --> 00:30:51,719
For example, this is great if you all

797
00:30:51,719 --> 00:30:53,719
you care about is using publicly

798
00:30:53,719 --> 00:30:56,039
available or commonly known metrics

799
00:30:56,039 --> 00:30:58,219
like F1, Rouge, uh,

800
00:30:58,239 --> 00:30:59,660
or any other kind of

801
00:30:59,920 --> 00:31:02,068
uh well-known metrics. A real good

802
00:31:02,068 --> 00:31:04,118
example is also if you're solving a problem

803
00:31:04,118 --> 00:31:06,368
which could be, for example, SQL query

804
00:31:06,368 --> 00:31:08,400
generation, could be execution of the

805
00:31:08,400 --> 00:31:09,259
SQL query.

806
00:31:09,719 --> 00:31:11,759
Does the SQL query actually execute once you've

807
00:31:11,759 --> 00:31:12,439
generated it?

808
00:31:13,328 --> 00:31:15,368
Does the result that come out of the SQL query,

809
00:31:15,449 --> 00:31:17,709
is it actually correct or is it wrong?

810
00:31:18,170 --> 00:31:20,750
So those kind of rule-based, they can be leveraged

811
00:31:20,969 --> 00:31:22,588
and used to improve

812
00:31:23,009 --> 00:31:24,068
the model training itself.

813
00:31:24,328 --> 00:31:26,650
I'm thinking about techniques like RLVR,

814
00:31:26,930 --> 00:31:29,118
so reinforcement learning with verifiable rewards.

815
00:31:29,368 --> 00:31:31,449
You execute a query in that case, you get the result.

816
00:31:31,529 --> 00:31:33,189
Is the result correct? Let's give a reward

817
00:31:33,568 --> 00:31:34,519
to the model training.

818
00:31:34,809 --> 00:31:37,009
If it's not correct, then just give a negative

819
00:31:37,009 --> 00:31:39,469
reward. However,

820
00:31:39,588 --> 00:31:41,930
some use cases, they do not necessarily

821
00:31:42,469 --> 00:31:43,729
have a way

822
00:31:43,989 --> 00:31:46,390
to correctly define heuristics or rules

823
00:31:46,390 --> 00:31:47,009
to evaluate

824
00:31:47,469 --> 00:31:47,989
the model.

825
00:31:49,059 --> 00:31:51,430
Which is why we go for LLM as a judge

826
00:31:51,430 --> 00:31:52,920
or LLM based critique.

827
00:31:53,309 --> 00:31:55,900
It's a really flexible technique and a really customizable

828
00:31:55,900 --> 00:31:58,098
technique, because it allows you to define

829
00:31:58,098 --> 00:31:59,328
a specific prompt.

830
00:32:00,009 --> 00:32:02,019
Which can evaluate through a

831
00:32:02,489 --> 00:32:04,650
bigger model, a teacher model if you wanna call it that way, or

832
00:32:04,650 --> 00:32:06,689
rather a judge model as we

833
00:32:06,689 --> 00:32:07,559
should call it.

834
00:32:08,000 --> 00:32:09,150
It allows you to evaluate

835
00:32:09,809 --> 00:32:11,930
a textual output from another

836
00:32:11,930 --> 00:32:14,009
model. So, let's think for example that

837
00:32:14,009 --> 00:32:16,269
as Sam was saying before, we have Nova Premiere,

838
00:32:16,449 --> 00:32:18,299
that's a great model, it's a very big model,

839
00:32:18,650 --> 00:32:20,858
performing super well on a range of use cases,

840
00:32:21,410 --> 00:32:23,259
but we wanna make sure that Nova Micro

841
00:32:23,689 --> 00:32:25,209
can solve the use cases I want.

842
00:32:25,868 --> 00:32:28,269
So what I can do is that I can fine tune,

843
00:32:28,709 --> 00:32:30,719
as I was showing before, Nova Micro,

844
00:32:31,068 --> 00:32:33,259
and then leverage, for example, Nova Premiere

845
00:32:33,259 --> 00:32:36,068
to evaluate the output and the inferences

846
00:32:36,309 --> 00:32:38,338
of Nova Micro after fine tuning,

847
00:32:38,789 --> 00:32:41,029
to make sure that I can compare, for example, the base

848
00:32:41,029 --> 00:32:43,180
performance to the fine-tuned performance.

849
00:32:43,430 --> 00:32:45,469
Is the outcome better? In what

850
00:32:45,479 --> 00:32:46,838
measure is it better?

851
00:32:47,269 --> 00:32:49,348
For example, if we go back to the SQL query

852
00:32:49,348 --> 00:32:50,029
use case,

853
00:32:50,299 --> 00:32:52,390
semantic correctness is not something that

854
00:32:52,390 --> 00:32:54,588
you can actually compute in terms of a number.

855
00:32:55,358 --> 00:32:57,420
Someone has to look at the semantics of your SQL

856
00:32:57,420 --> 00:32:58,880
query and say,

857
00:32:59,479 --> 00:33:01,640
does writing the SQL query in that way

858
00:33:01,640 --> 00:33:03,719
actually equates to running

859
00:33:03,719 --> 00:33:05,769
a the writing it in this other

860
00:33:05,769 --> 00:33:07,799
way. And LLMs are great at

861
00:33:07,799 --> 00:33:09,519
doing those kind of uh tasks.

862
00:33:12,640 --> 00:33:14,719
If you wanna know more about different metrics

863
00:33:14,719 --> 00:33:16,920
for uh evaluation using LLM as a judge,

864
00:33:17,239 --> 00:33:19,108
there's a whole list of some examples,

865
00:33:19,439 --> 00:33:21,640
but once again, what I usually suggest is that

866
00:33:21,640 --> 00:33:23,640
evaluate and possibly

867
00:33:23,640 --> 00:33:24,318
create

868
00:33:24,680 --> 00:33:26,910
the metric that makes the most sense for your

869
00:33:26,910 --> 00:33:27,588
use case.

870
00:33:27,880 --> 00:33:29,880
In my case was the semantic correctness

871
00:33:29,880 --> 00:33:31,920
or semantic equivalence. In your case, it

872
00:33:31,920 --> 00:33:33,739
might be something completely different.

873
00:33:36,509 --> 00:33:38,709
So, now you've fine tuned your model

874
00:33:38,709 --> 00:33:40,949
using Hyperpod, or Sagemaker training

875
00:33:40,949 --> 00:33:41,578
jobs,

876
00:33:41,890 --> 00:33:44,088
you've evaluated the performances of your model.

877
00:33:44,509 --> 00:33:46,029
So what do you do after that?

878
00:33:46,509 --> 00:33:48,930
The next step is to take that model

879
00:33:49,189 --> 00:33:51,828
and make sure it's available for queries and for inferences.

880
00:33:52,650 --> 00:33:54,650
Now, you can take a Nova model and deploy

881
00:33:54,650 --> 00:33:56,799
it on a a Bedrock inference using custom

882
00:33:56,799 --> 00:33:57,598
model import.

883
00:33:57,930 --> 00:34:00,180
You can use either on-demand provisioning

884
00:34:00,180 --> 00:34:02,289
of that model, which means it's there, it

885
00:34:02,289 --> 00:34:04,368
will be offline until you actually call it. It will take a

886
00:34:04,368 --> 00:34:06,410
second to spin up, and then it's available

887
00:34:06,410 --> 00:34:07,930
for inferences as much as you want.

888
00:34:08,289 --> 00:34:10,409
And this is available for techniques such as

889
00:34:10,409 --> 00:34:12,840
theft, DPO, direct preference optimization,

890
00:34:12,849 --> 00:34:13,648
and distillation.

891
00:34:14,427 --> 00:34:16,548
Or it's available through provision throughput, which

892
00:34:16,548 --> 00:34:18,447
means it's always available, always there,

893
00:34:18,708 --> 00:34:20,849
just call it and it's available for you to run a query,

894
00:34:21,068 --> 00:34:22,668
but it's available for all techniques.

895
00:34:24,219 --> 00:34:26,228
On the other side, you can also take that

896
00:34:26,228 --> 00:34:28,429
model and deploy it on Sagemaker.

897
00:34:28,789 --> 00:34:30,949
Whether it's on a real-time inference endpoint,

898
00:34:31,309 --> 00:34:32,688
which is effectively a

899
00:34:32,949 --> 00:34:34,369
virtual machine, an instance

900
00:34:34,789 --> 00:34:36,869
that we run for you managed by the SageMaker

901
00:34:36,869 --> 00:34:37,550
control plane.

902
00:34:37,869 --> 00:34:39,989
We load it with the image, we load it with a with

903
00:34:39,989 --> 00:34:41,289
a with a model image,

904
00:34:41,550 --> 00:34:44,110
and it's available for you to run queries 24/7

905
00:34:44,110 --> 00:34:44,809
as much as you want.

906
00:34:45,579 --> 00:34:48,340
Or you can also use HyperPod. We recently

907
00:34:48,340 --> 00:34:50,789
introduced the capability of running inference

908
00:34:50,789 --> 00:34:52,369
endpoints in HyperPod,

909
00:34:52,699 --> 00:34:54,820
so that you can either choose to pay by the minute

910
00:34:54,820 --> 00:34:56,458
that you're running the inference endpoint

911
00:34:56,739 --> 00:34:59,019
or just have it available in a highly scalable

912
00:34:59,019 --> 00:34:59,539
cluster.

913
00:35:00,929 --> 00:35:01,570
Just a note,

914
00:35:01,889 --> 00:35:04,050
it's currently not possible for Amazon Nova models

915
00:35:04,050 --> 00:35:06,409
to be deployed on Sage Maker, neither endpoints

916
00:35:06,409 --> 00:35:07,208
or Hyperpod,

917
00:35:07,728 --> 00:35:09,648
but You know,

918
00:35:10,010 --> 00:35:12,010
just wait for it, all right? I'm afraid I

919
00:35:12,010 --> 00:35:13,010
can't say anything more.

920
00:35:15,519 --> 00:35:17,570
Let's take a look at what evaluation and deployment

921
00:35:17,570 --> 00:35:18,168
look like.

922
00:35:18,688 --> 00:35:20,769
So after I've trained my model, what I

923
00:35:20,769 --> 00:35:21,789
can do is that I can select,

924
00:35:22,128 --> 00:35:23,750
evaluate all the way up top.

925
00:35:24,958 --> 00:35:27,070
And there would be also evaluation recipes, which

926
00:35:27,070 --> 00:35:28,369
are also available in GitHub.

927
00:35:29,289 --> 00:35:31,320
Just like before, you can select which recipe

928
00:35:31,320 --> 00:35:31,829
you wanna do,

929
00:35:32,159 --> 00:35:33,659
generic text benchmark,

930
00:35:34,000 --> 00:35:36,119
bring your own data set for uh

931
00:35:36,119 --> 00:35:38,659
question and answering, or LLM is a judge recipe.

932
00:35:39,039 --> 00:35:41,199
This example will do question answer. You

933
00:35:41,199 --> 00:35:43,349
always have the button that says view the format,

934
00:35:43,639 --> 00:35:45,750
and once again, if you use Hyperpot, it's as

935
00:35:45,750 --> 00:35:47,938
simple as Hyperpot start job

936
00:35:47,938 --> 00:35:49,958
and provide the path to the recipe.

937
00:35:50,769 --> 00:35:51,398
Once again,

938
00:35:51,728 --> 00:35:53,760
this will become a task in your Hyperport

939
00:35:53,760 --> 00:35:54,550
cluster management.

940
00:35:54,929 --> 00:35:57,010
So if you have Hyperport task manager, you will

941
00:35:57,010 --> 00:35:57,619
see everything,

942
00:35:58,489 --> 00:35:59,829
and you will be able to

943
00:36:00,099 --> 00:36:02,250
output the evaluation metrics and

944
00:36:02,250 --> 00:36:04,610
consume them as you prefer in a streamlet

945
00:36:04,610 --> 00:36:06,789
app or directly on a in a notebook.

946
00:36:08,320 --> 00:36:10,360
Then you can take the model and deploy it to

947
00:36:10,360 --> 00:36:12,570
Bedrock for inference. It's literally

948
00:36:12,570 --> 00:36:13,610
two calls.

949
00:36:14,159 --> 00:36:16,478
Create a custom model import

950
00:36:16,478 --> 00:36:18,510
or create provision model throughput.

951
00:36:18,918 --> 00:36:21,000
That's all you need to do, and then you can ask a

952
00:36:21,000 --> 00:36:23,079
question. What is the weather in Rome, Italy Italy?

953
00:36:23,559 --> 00:36:25,679
Of course, make sure you provide a tool to your

954
00:36:25,679 --> 00:36:27,840
agent, otherwise, how does he know what the weather

955
00:36:27,840 --> 00:36:29,478
looks like in Rome at this point?

956
00:36:30,860 --> 00:36:33,340
And if you can tell, yes, I am Italian as well, so

957
00:36:33,340 --> 00:36:35,449
this is why the demo talks about Rome, Italy.

958
00:36:35,500 --> 00:36:37,500
I'm not from Rome, but it's a beautiful city. If you

959
00:36:37,500 --> 00:36:38,199
haven't been, please

960
00:36:38,820 --> 00:36:41,639
go. Awesome.

961
00:36:42,179 --> 00:36:43,500
So we have customized the model,

962
00:36:43,789 --> 00:36:46,418
we evaluated its performances. We have deployed

963
00:36:46,820 --> 00:36:49,039
the model to production with an endpoint or

964
00:36:49,039 --> 00:36:50,559
in this case with Bedrock CMI.

965
00:36:51,219 --> 00:36:53,539
How do we go to production? So how do we actually

966
00:36:53,539 --> 00:36:55,619
build an agent? Who has already

967
00:36:55,619 --> 00:36:57,059
built an agent here in this room?

968
00:36:58,628 --> 00:37:00,719
OK, OK, good. I see a lot of people building

969
00:37:00,719 --> 00:37:01,260
agents.

970
00:37:02,789 --> 00:37:04,769
And you might have used one of these,

971
00:37:05,030 --> 00:37:07,168
uh, open source frameworks, right?

972
00:37:07,708 --> 00:37:09,478
Our heart goes with Stras agents

973
00:37:09,750 --> 00:37:12,010
because it's one of the opinionated ways that we have

974
00:37:12,228 --> 00:37:14,128
for building agents in a simple way

975
00:37:14,590 --> 00:37:16,668
with AWS technologies and not

976
00:37:16,668 --> 00:37:18,300
necessarily only AWS technologies.

977
00:37:18,619 --> 00:37:20,750
You're gonna see that Stras agents is a framework that allows

978
00:37:20,750 --> 00:37:21,628
you to connect to

979
00:37:21,898 --> 00:37:23,389
Olama, OpenAI,

980
00:37:23,668 --> 00:37:24,389
Gemini,

981
00:37:24,659 --> 00:37:26,708
anthropic, really connect to whatever kind

982
00:37:26,708 --> 00:37:27,849
of model provider you want.

983
00:37:28,750 --> 00:37:30,800
We think it's the easiest way to build agents,

984
00:37:31,110 --> 00:37:33,139
but we know you have your opinionated view.

985
00:37:33,469 --> 00:37:34,679
So if you wanna use Lagraph,

986
00:37:34,949 --> 00:37:37,110
land chain, OpenAI agents SDK,

987
00:37:37,369 --> 00:37:38,989
Crew AI, Google ADK,

988
00:37:39,389 --> 00:37:41,429
Lama Index, and probably so many more out there that I

989
00:37:41,429 --> 00:37:42,789
don't even know they exist.

990
00:37:43,510 --> 00:37:45,449
Most of the frameworks out there are compatible

991
00:37:45,989 --> 00:37:48,510
with Bedrock custom model inference. They're compatible

992
00:37:48,510 --> 00:37:50,648
with SageMaker endpoints to generate

993
00:37:50,648 --> 00:37:51,309
inferences.

994
00:37:53,260 --> 00:37:55,539
And once you have built your agents, you have written

995
00:37:55,539 --> 00:37:57,289
the code to create your agent,

996
00:37:57,739 --> 00:38:00,019
then the very next step is to

997
00:38:00,019 --> 00:38:02,260
get that, that agent into production.

998
00:38:03,438 --> 00:38:05,438
We have created an end to end managed

999
00:38:05,438 --> 00:38:07,599
platform for agent deployment

1000
00:38:07,599 --> 00:38:10,148
and management and running those agents,

1001
00:38:10,438 --> 00:38:12,119
which is called Amazon Bedrock Agent Corp.

1002
00:38:12,478 --> 00:38:14,639
If you haven't been to an agent core specific session,

1003
00:38:14,789 --> 00:38:16,260
I highly suggest you guys

1004
00:38:16,519 --> 00:38:18,559
take the time between today and tomorrow to

1005
00:38:18,559 --> 00:38:19,820
go to an agent core session.

1006
00:38:20,159 --> 00:38:22,280
I believe it's a very interesting service that you should

1007
00:38:22,280 --> 00:38:23,378
definitely check out.

1008
00:38:23,878 --> 00:38:26,579
Also, because it comes with many different sub-services

1009
00:38:26,719 --> 00:38:28,418
which solve different problems

1010
00:38:28,679 --> 00:38:30,760
in the what we call this production

1011
00:38:30,760 --> 00:38:31,369
chasm.

1012
00:38:31,760 --> 00:38:34,079
So, what do you need to get an agent

1013
00:38:34,079 --> 00:38:36,159
from development, all the way down to

1014
00:38:36,159 --> 00:38:38,199
production, ranging from where do you

1015
00:38:38,199 --> 00:38:39,019
run the model,

1016
00:38:39,679 --> 00:38:40,519
the agent, sorry.

1017
00:38:41,489 --> 00:38:42,918
If it has a memory or not,

1018
00:38:43,208 --> 00:38:44,610
please use memory with your agents.

1019
00:38:45,329 --> 00:38:47,449
Identity. How does it have the permission to

1020
00:38:47,449 --> 00:38:49,000
access the different resources?

1021
00:38:49,320 --> 00:38:51,530
How does it connect to the available APIs

1022
00:38:51,530 --> 00:38:52,829
that you have in your enterprise?

1023
00:38:53,719 --> 00:38:55,760
How can you use, for example, tools like code

1024
00:38:55,760 --> 00:38:57,019
interpreter or browser

1025
00:38:57,280 --> 00:38:59,438
to effectively run code or connect

1026
00:38:59,438 --> 00:39:00,079
to the web?

1027
00:39:00,360 --> 00:39:01,188
And then finally,

1028
00:39:01,519 --> 00:39:02,860
arguably the most important,

1029
00:39:03,280 --> 00:39:05,458
how do you understand how your agent is running

1030
00:39:05,760 --> 00:39:07,039
in terms of observability.

1031
00:39:09,059 --> 00:39:09,878
I've spoken enough

1032
00:39:10,378 --> 00:39:11,929
already. We've seen 2 demos,

1033
00:39:12,378 --> 00:39:14,739
we've covered the agent capabilities, we've covered

1034
00:39:14,739 --> 00:39:16,860
how to customize the model, so let's wrap up

1035
00:39:16,860 --> 00:39:17,599
things a little bit.

1036
00:39:19,739 --> 00:39:22,059
When you go back home after this, of

1037
00:39:22,059 --> 00:39:24,070
course, enjoy the replay tonight first, then

1038
00:39:24,070 --> 00:39:26,219
go home. What you will

1039
00:39:26,219 --> 00:39:28,458
need to do in order to solve your genic

1040
00:39:28,458 --> 00:39:29,300
AI use case.

1041
00:39:30,208 --> 00:39:32,030
You will likely need to, first of all,

1042
00:39:32,530 --> 00:39:34,208
take a stab at the already available models.

1043
00:39:34,530 --> 00:39:36,349
There are many different good models out there.

1044
00:39:37,128 --> 00:39:39,168
Sam walked us through techniques like

1045
00:39:39,168 --> 00:39:40,228
context engineering,

1046
00:39:40,708 --> 00:39:41,329
rag,

1047
00:39:41,769 --> 00:39:43,889
prompt engineering, that can help you solve already

1048
00:39:43,889 --> 00:39:44,929
your problem as is.

1049
00:39:46,329 --> 00:39:48,289
If your problem is a really custom one,

1050
00:39:48,659 --> 00:39:50,019
then you might want to evaluate

1051
00:39:50,378 --> 00:39:51,199
model customization.

1052
00:39:51,978 --> 00:39:53,918
In a simpler way, you can do it through

1053
00:39:54,719 --> 00:39:56,829
Bedrock is really easy to

1054
00:39:56,829 --> 00:39:57,590
get started.

1055
00:39:57,929 --> 00:39:59,539
If you wanna have a little bit more control,

1056
00:40:00,000 --> 00:40:02,300
then you can use the techniques available in SageMaker

1057
00:40:02,599 --> 00:40:03,599
to customize your model.

1058
00:40:04,628 --> 00:40:07,389
Then always, always evaluate

1059
00:40:07,750 --> 00:40:09,909
the performances of the model after you fine-tuned

1060
00:40:09,909 --> 00:40:12,030
it. Cause you wanna understand if

1061
00:40:12,030 --> 00:40:14,110
it's actually performing better than the base

1062
00:40:14,110 --> 00:40:14,648
model,

1063
00:40:14,918 --> 00:40:17,148
or you might wanna go through additional techniques.

1064
00:40:18,989 --> 00:40:21,188
Then that model needs to be available for queries,

1065
00:40:21,389 --> 00:40:23,590
so we deploy it either with Bedrock CMI

1066
00:40:24,188 --> 00:40:24,728
or

1067
00:40:24,989 --> 00:40:27,099
on a Sage maker inference, whether it's an

1068
00:40:27,099 --> 00:40:28,978
endpoint or hyperpod.

1069
00:40:29,309 --> 00:40:30,398
And then finally,

1070
00:40:31,110 --> 00:40:33,139
write the code for your agent in the lang

1071
00:40:33,139 --> 00:40:35,148
in the open source framework that you prefer.

1072
00:40:36,228 --> 00:40:38,619
Once again, shout out to Strand's agents for that,

1073
00:40:39,199 --> 00:40:40,978
and then take that to production using

1074
00:40:41,599 --> 00:40:43,878
a tool like Amazon Sage Maker, Amazon Bedrock

1075
00:40:43,878 --> 00:40:44,519
Agent core.

1076
00:40:47,128 --> 00:40:49,250
When do you need to customize? It's a

1077
00:40:49,250 --> 00:40:51,250
very valid and interesting

1078
00:40:51,250 --> 00:40:53,030
question to ask yourself at the very beginning.

1079
00:40:53,438 --> 00:40:55,570
Once again, for me, the easiest way is just

1080
00:40:55,570 --> 00:40:57,728
test the base model as is and

1081
00:40:57,728 --> 00:40:59,070
decide on there if you need

1082
00:40:59,369 --> 00:41:00,289
more performance,

1083
00:41:00,648 --> 00:41:02,679
if you need to be more aligned to your business, if

1084
00:41:02,679 --> 00:41:04,769
you need to be more cost effective. We've

1085
00:41:04,769 --> 00:41:06,469
seen a lot of customers move.

1086
00:41:07,139 --> 00:41:09,148
To smaller language models rather than using

1087
00:41:09,148 --> 00:41:11,389
large language models because they are much

1088
00:41:11,389 --> 00:41:12,750
more cost effective,

1089
00:41:13,070 --> 00:41:15,570
they can be customized and they can solve one task

1090
00:41:15,869 --> 00:41:18,139
really well at a fraction of the cost of a larger

1091
00:41:18,139 --> 00:41:20,219
model. But it could also

1092
00:41:20,219 --> 00:41:21,340
be a technical question.

1093
00:41:21,619 --> 00:41:23,679
Maybe you have already the training data,

1094
00:41:23,898 --> 00:41:26,329
which makes it super easy to customize a model,

1095
00:41:26,619 --> 00:41:28,860
or you have a team with a technical expertise,

1096
00:41:29,179 --> 00:41:31,409
and that team can then act effectively

1097
00:41:31,409 --> 00:41:33,619
as a reinforcement algorithm

1098
00:41:33,619 --> 00:41:35,260
for the model fine-tune.

1099
00:41:37,918 --> 00:41:40,329
To recap the techniques that are available for fine tuning,

1100
00:41:40,679 --> 00:41:42,610
Bedrock supports theft and installation.

1101
00:41:42,918 --> 00:41:45,090
SageMaker supports a whole range of different

1102
00:41:45,090 --> 00:41:45,719
techniques,

1103
00:41:46,010 --> 00:41:48,168
so you can go ahead and choose the one that makes the most sense

1104
00:41:48,168 --> 00:41:48,719
for you.

1105
00:41:49,050 --> 00:41:51,050
And one thing that I want you to take away from this

1106
00:41:51,050 --> 00:41:51,570
is that

1107
00:41:51,889 --> 00:41:54,128
do not just settle on one fine tuning

1108
00:41:54,128 --> 00:41:54,679
techniques.

1109
00:41:55,019 --> 00:41:57,128
Fine tuning is a spectrum. It

1110
00:41:57,128 --> 00:41:59,050
goes from just prompt engineering

1111
00:41:59,329 --> 00:42:01,760
all the way down to continued pre-training,

1112
00:42:02,360 --> 00:42:02,878
per per.

1113
00:42:03,809 --> 00:42:05,958
Theft, full rank and all the other

1114
00:42:05,958 --> 00:42:06,628
different techniques,

1115
00:42:06,889 --> 00:42:09,090
direct preference optimization, etc. etc.

1116
00:42:09,398 --> 00:42:10,909
So really evaluate

1117
00:42:11,289 --> 00:42:12,550
how much time and effort

1118
00:42:12,958 --> 00:42:15,168
you wanna put in the model customization process,

1119
00:42:15,530 --> 00:42:17,610
how much complicated you want this

1120
00:42:17,610 --> 00:42:19,840
process to be, and what kind of outcome

1121
00:42:19,840 --> 00:42:21,849
you expect from the different techniques.

1122
00:42:23,659 --> 00:42:25,739
And of course, remember that if you wanna learn more

1123
00:42:25,739 --> 00:42:28,050
about Amazonova, but in general about

1124
00:42:28,099 --> 00:42:29,250
AWS technologies,

1125
00:42:29,539 --> 00:42:31,579
we do have the skill builder portal. It's

1126
00:42:31,579 --> 00:42:34,519
a great way for you to get more hands-on.

1127
00:42:35,059 --> 00:42:37,320
First of all, you have to go through the documentation, etc. etc.

1128
00:42:37,570 --> 00:42:39,878
but if you wanna be a little bit more hands-on and learn more

1129
00:42:40,139 --> 00:42:42,139
about the specificity of some of the techniques,

1130
00:42:42,579 --> 00:42:44,938
you can go ahead and jump into the skill builder

1131
00:42:44,938 --> 00:42:47,000
process where you have all the trainings available

1132
00:42:47,000 --> 00:42:49,378
for Nova, as well as for a bunch of other techniques.

1133
00:42:51,199 --> 00:42:53,239
With that said, I wanna thank you. Thank you

1134
00:42:53,239 --> 00:42:55,378
for listening to us for, uh, all this time,

1135
00:42:55,840 --> 00:42:58,119
uh, and if you have any questions, we're gonna be

1136
00:42:58,119 --> 00:43:00,119
just here, uh, next to the

1137
00:43:00,119 --> 00:43:02,519
room. Uh, feel free to come and ask any

1138
00:43:02,519 --> 00:43:04,320
question and please, as you leave,

1139
00:43:04,599 --> 00:43:06,059
remember, if you take a second

1140
00:43:06,360 --> 00:43:08,360
to go to the app and

1141
00:43:08,360 --> 00:43:10,398
fill in the survey, we say the feedback is a

1142
00:43:10,398 --> 00:43:12,438
gift. It's always nice if you can tell us,

1143
00:43:12,639 --> 00:43:14,898
hey, Sam and David, they were two great presenters,

1144
00:43:15,360 --> 00:43:17,000
so we're looking forward to their next session.

1145
00:43:17,789 --> 00:43:18,570
Thank you very much.

