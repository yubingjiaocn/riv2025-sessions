# AWS re:Invent 2025 - AIM 383 会议总结

## 会议概述

本次会议主题为"通过模型定制构建更有效的AI代理"（Build More Effective Agents Through Model Customization），由AWS SageMaker AI团队的高级专家解决方案架构师David Galitelli和Amazon Nova产品上市团队负责人Sam Palani共同主持。

会议深入探讨了如何使用Amazon Nova基础模型构建和定制AI代理。演讲者首先阐述了AI代理的基本概念——即在循环中调用工具以完成目标的大语言模型。随着推理模型的出现，代理AI迎来了拐点，使得大规模部署代理成为可能。会议强调，虽然前沿模型智能水平不断提高，但在代理AI场景中仍表现出脆弱性，特别是"复合错误"问题——一个步骤的错误会传播并放大到后续步骤。模型定制可以直接帮助减少这些错误，提高代理的可靠性和效率。

会议详细介绍了Amazon Nova模型家族的各个成员，包括理解推理模型（Micro、Lite、Pro、Premier、Nova 2 Pro）、创意内容生成模型（Canvas、Reels、Nova 2 Omni）、语音模型（Sonic）、浏览器代理模型（Act）以及多模态嵌入模型。演讲者展示了在Amazon Bedrock和SageMaker上进行模型定制的多种技术，包括微调、蒸馏、直接偏好优化（DPO）、近端策略优化（PPO）和持续预训练。通过现场演示，观众了解了如何使用SageMaker Hyperpod和训练任务进行实际的模型定制操作，以及如何评估和部署定制后的模型。

## 详细时间线

### 开场介绍 (00:00 - 02:30)
- **00:00** - 会议开始，David Galitelli介绍自己为AWS SageMaker AI团队的全球高级专家解决方案架构师
- **00:30** - Sam Palani自我介绍，担任AWS Nova产品上市团队负责人
- **01:00** - 说明这是一个静默会议（silent session），内容丰富，会后可提问
- **01:30** - 介绍会议议程：构建自定义AI代理、Amazon Nova基础模型家族、模型定制技术、演示和资源分享

### AI代理基础概念 (02:30 - 08:00)
- **02:30** - Sam询问有多少人参加过静默会议，这是他的第一次
- **03:00** - 定义AI代理：在循环中调用工具以完成目标的LLM
- **03:30** - 解释代理的工作原理：访问模型、工具集和特定目标，在环境中采取行动
- **04:00** - 分析代理AI拐点的原因：推理模型的出现
- **05:00** - 讨论推理模型如何改变了格局，从纯训练转向测试时计算和推理时计算
- **06:00** - 推理模型使代理能够以成本效益的方式大规模部署
- **06:30** - 强调安全数据基础设施的重要性，将专有数据连接到强大模型
- **07:00** - 介绍专业工具和技术的出现：模型上下文协议、代理间协议、模型级技能
- **07:30** - 引用Gartner预测：到2028年，三分之一的企业应用将由生成式AI或代理AI驱动

### 模型定制的重要性 (08:00 - 15:00)
- **08:00** - 说明定制是生产之旅中的一步，还包括构建、部署和测试
- **08:30** - 解释为什么在代理上下文中讨论模型定制
- **09:00** - 介绍"复合错误"风险：一个步骤的错误传播到其他步骤
- **09:30** - 举例说明：单步95%准确率的模型，经过10步后可能降至60%
- **10:00** - 定制可以帮助减少步骤级别和跨步骤的错误
- **10:30** - 领域特定的首字母缩写、分类法和业务流程知识不是互联网平均水平
- **11:00** - 定制可以帮助模型理解工具调用的底层架构和参数
- **11:30** - 定制可以压缩代理工作流中的长链，获得更短的轨迹
- **12:00** - 蒸馏等定制技术可以直接降低P50和P90延迟及每步成本

### 定制技术概览 (15:00 - 22:00)
- **15:00** - 定义定制：对模型进行的任何修改其行为的操作
- **15:30** - 将定制分为两大类：优化输出（无权重更新）和修改模型（权重更新）
- **16:00** - 介绍提示工程：从简单的少样本示例到复杂的思维链示例
- **16:30** - 检索增强生成（RAG）：在运行时提供额外上下文的有效方式
- **17:00** - 上下文工程：在正确的时间以正确的格式提供正确的信息
- **18:00** - 后训练技术：微调、模型蒸馏、DPO、PPO
- **19:00** - 预训练技术：持续预训练
- **20:00** - 询问有多少人尝试过微调
- **20:30** - 解释全微调和参数高效微调（PEFT）的区别

### 各种定制技术详解 (22:00 - 30:00)
- **22:00** - 监督微调：使用相对较小的标记数据集使模型适应特定任务
- **23:00** - 直接偏好优化（DPO）：在不训练奖励模型的情况下将模型与用户偏好对齐
- **24:00** - 近端策略优化（PPO）：基于实时反馈改进模型
- **25:00** - 模型蒸馏：将复杂行为从大型高性能教师模型蒸馏到小型高效学生模型
- **26:00** - 持续预训练：使用大量未标记的领域特定数据继续训练
- **27:00** - 警告过拟合和灾难性遗忘的风险
- **28:00** - 介绍早停和智能数据混合等缓解技术

### Amazon Nova模型家族 (30:00 - 38:00)
- **30:00** - 询问有多少人使用过Nova
- **30:30** - 说明幻灯片未更新到最新发布，但会讨论所有内容
- **31:00** - Nova Micro：最快、最高效的文本到文本模型
- **31:30** - 多模态理解推理模型：Lite、Premier和Pro
- **32:00** - Nova 2 Pro：两天前发布，现在是最高性能的模型
- **33:00** - 创意内容生成模型：Canvas（文本到图像）、Reels（文本到视频）
- **33:30** - Nova 2 Omni：最先进的文本到图像生成模型
- **34:00** - Nova Sonic：业界首个实时语音到语音模型
- **35:00** - Nova Act：两天前正式发布，专为在浏览器中操作的代理设计
- **36:00** - Nova多模态嵌入模型：在同一向量空间中为文本、视频、图像和音频生成嵌入
- **37:00** - 介绍Nova公共网站：nova.amazon.com，可免费试用模型

### Bedrock上的Nova定制选项 (38:00 - 45:00)
- **38:00** - 展示Nova在Bedrock和SageMaker上提供的广泛定制选项
- **39:00** - 大多数选项都提供全秩和参数高效低秩选项
- **40:00** - 可以在Bedrock或SageMaker上进行定制，然后在Bedrock上无服务器部署
- **41:00** - Bedrock上的微调：几次点击即可完成参数高效微调
- **42:00** - 工具调用和架构一致性是常见的代理AI用例
- **43:00** - 角色切换示例：在销售和支持等多个角色之间切换
- **44:00** - Bedrock上的模型蒸馏：几次点击即可完成，自动生成响应

### SageMaker定制功能 (45:00 - 55:00)
- **45:00** - David接手，介绍SageMaker的更高级定制选项
- **46:00** - SageMaker是端到端的机器学习平台，提供更低级别的控制
- **47:00** - 两个选项：训练任务API（完全托管和无服务器）和Hyperpod（完全编排）
- **48:00** - 昨天早上宣布了无服务器微调
- **49:00** - Hyperpod是基于EKS或SLURM的托管集群
- **50:00** - SageMaker提供优化的配方（recipes），确保训练首次成功
- **51:00** - 配方在Hyperpod和训练任务中都可用
- **52:00** - 展示配方工作流程：选择Nova配方、API调用、启动训练任务
- **53:00** - 展示QR码链接到博客文章

### 现场演示 (55:00 - 65:00)
- **55:00** - David开始演示如何使用SageMaker AI对Nova模型进行DPO
- **56:00** - 警告UI可能与两天前略有不同，但概念相同
- **57:00** - 演示步骤：进入SageMaker Studio，选择JumpStart hub
- **58:00** - 选择模型（Nova Micro、Nova 2.0 Lite等）
- **59:00** - 点击训练按钮，选择训练选项（监督微调或DPO）
- **60:00** - 显示所需的计算和数据格式
- **61:00** - 提供notebook代码，可通过UI或代码操作
- **62:00** - 演示使用Hyperpod配方，但也可使用训练任务
- **63:00** - 选择训练集群，打开Jupyter lab notebook
- **64:00** - Notebook包含先决条件、安装、代码执行等信息

### 模型评估 (65:00 - 72:00)
- **65:00** - 讨论评估LLM的不同技术和指标
- **66:00** - 通用指标：困惑度、准确率
- **67:00** - 任务特定指标：步骤数量、步骤质量
- **68:00** - 幻觉、偏见和毒性指标
- **69:00** - 基于规则的启发式方法：F1、Rouge等公开指标
- **70:00** - SQL查询生成示例：查询是否执行、结果是否正确
- **71:00** - LLM作为评判者：灵活且可定制的技术
- **71:30** - 使用更大的模型（如Nova Premier）评估较小模型（如Nova Micro）的输出

### 模型部署 (72:00 - 78:00)
- **72:00** - 微调和评估后的下一步：部署模型进行推理
- **73:00** - Bedrock部署选项：使用自定义模型导入
- **74:00** - 按需配置：离线直到调用，然后可用于推理
- **75:00** - 预置吞吐量：始终可用，适用于所有技术
- **76:00** - SageMaker部署选项：实时推理端点
- **77:00** - Hyperpod推理端点：按分钟付费或在高度可扩展集群中运行
- **77:30** - 注意：目前Amazon Nova模型无法部署在SageMaker端点或Hyperpod上

### 评估和部署演示 (78:00 - 结束)
- **78:00** - 演示训练后的评估流程
- **79:00** - 选择评估配方：通用文本基准、自带数据集、LLM作为评判者
- **80:00** - 演示问答评估，查看格式按钮
- **81:00** - 使用Hyperpod启动评估任务
- **82:00** - 评估指标可在Streamlit应用或notebook中使用
- **83:00** - 演示部署到Bedrock：两个API调用（创建自定义模型导入或创建预置模型吞吐量）
- **84:00** - 会议结束，提供后续资源和联系方式