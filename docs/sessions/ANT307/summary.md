# AWS re:Invent 2025 - NT307 会议总结

## 会议概述

本次会议主题为"运营和扩展托管 Kafka 与 Apache Flink"（Operating and Scaling Managed Kafka and Apache Flink），由 AWS 的 Ashish Palar 和 Sai Madali 主讲。Ashish 负责 Kafka、Flink 和 Kinesis Data Firehose 服务，Sai 则领导 Amazon MSK（Managed Streaming for Apache Kafka）、Apache Flink 托管服务和 Kinesis Data Firehose 的产品团队。

会议深入探讨了在 AWS 上大规模运营流数据处理系统的实践经验和技术洞察。演讲者分享了从数千个客户工作负载中获得的运营经验，重点关注价格性能、可靠性、安全性和性能这四个核心成果。会议涵盖了从存储管理、故障处理、水平扩展到智能重平衡等关键技术挑战，并详细介绍了 AWS 如何通过 MSK Express Brokers 和托管 Flink 服务来简化这些复杂的运营任务。

演讲者特别强调了流数据处理在实时决策、持续智能和 AI 工作负载中的重要性，并通过 Nexthink 等客户案例展示了如何从每秒 200MB 扩展到 5GB 的吞吐量，处理每天数万亿事件。

## 详细时间线与关键要点

### **开场介绍** (0:00-2:30)
- 会议编号 NT307，主题为运营和扩展托管 Kafka 与 Apache Flink
- Ashish Palar 介绍自己负责 Kafka、Flink 和 Firehose 服务的运营和构建
- Sai Madali 介绍自己领导 MSK、Flink 和 Firehose 的产品团队
- 会议将分享大规模运营这些服务的经验教训

### **流数据的价值** (2:30-4:00)
- 客户选择流数据的四个原因：实时解锁数据价值、实时决策、持续智能、为 AI 工作负载提供更新鲜的上下文数据
- AWS 运营 Kafka 和 Flink 服务已超过五年
- 现场调查显示大多数参会者运营 Kafka 服务，少数使用 Flink

### **大规模运营的核心成果** (4:00-5:30)
- 客户关注的四个核心领域：价格性能、可靠性、安全性和性能
- 这些基础要素在大规模场景下会被放大
- 展示了多个使用 AWS 服务的客户案例

### **客户案例：Nexthink** (5:30-7:00)
- Nexthink 是瑞士的客户，专注于开发者体验
- 从本地部署迁移到 AWS MSK
- 现在每天处理数万亿事件，达到每秒 5GB 的聚合吞吐量
- 从每秒 200MB 扩展到 5GB 的历程提供了宝贵经验

### **MSK 服务谱系** (7:00-9:00)
- AWS 提供三种 Kafka 服务选项：
  - **Standard Brokers**：适合需要细粒度 Kafka 控制和深度专业知识的迁移场景
  - **Express Brokers**：平衡性能和弹性，适合大规模管理 Kafka 的场景
  - **MSK Serverless**：零 Kafka 管理，快速部署和扩展
- 建议：除非有特殊需求，否则从 Express Brokers 开始

### **存储管理挑战** (9:00-12:00)
- 存储扩展需要时间（4TB → 8TB → 12TB）
- 客户常见问题：未监控存储利用率，导致容量突然耗尽
- 建议订阅磁盘满告警（60%、80% 和 100% 阈值）
- 传统 Kafka 的问题：容易扩容但无法缩容，导致客户延迟扩容决策

### **Express Brokers 的存储优势** (12:00-14:00)
- 消除存储管理：无需配置存储，只需指定保留期
- 每个 broker 提供几乎无限的存储容量
- 按集群而非按 broker 配置存储
- 按实际使用付费，而非预配置容量
- 提供即时、免维护的存储扩展

### **故障处理挑战** (14:00-18:00)
- 三 broker 集群的正常流量包括：生产者流量、消费者流量、复制流量和分区计算需求
- 当 broker 故障时需要考虑的因素：
  - 生产者切换
  - 复制切换
  - 领导权变更
  - broker 恢复后的追赶复制
  - 消费者重平衡
- 客户常见问题：工作负载在正常情况下运行良好，但故障时出现问题

### **故障恢复时间** (18:00-20:00)
- 标准 Kafka 中，计算和存储耦合在一起
- 节点故障后的恢复时间不确定，取决于：存储吞吐量、存储容量、计算到本地存储的网络吞吐量
- Kafka 在故障发生前非常稳定，但故障时客户只能等待恢复
- Express Brokers 通过资源分离实现恢复速度提升 90%，显著提高系统韧性

### **水平扩展挑战** (20:00-23:00)
- "每个人都有计划，直到需要重平衡分区"
- 传统扩展过程：添加 broker、移动分区、预留重平衡带宽、精心编排以避免影响现有工作负载、持续监控
- 重平衡可能需要数小时且时间不确定

### **弹性实验对比** (23:00-27:00)
- 实验设置：3 个 broker、1 个主题、2000 个分区、每个 broker 4TB 数据、每秒 90MB 生产速率
- **Standard Brokers 结果**：
  - 添加 3 个 broker 后吞吐量立即下降
  - 持续受限直到稳定
  - 整个过程约 175 分钟
- **Express Brokers 结果**：
  - 添加 broker 后立即达到新吞吐量
  - 10 分钟内完成重平衡
  - 弹性提升高达 20 倍

### **智能重平衡功能** (27:00-30:00)
- 几周前发布的新功能
- 特性包括：
  - 始终开启的重平衡
  - 自动分区放置
  - 全自动水平扩展
  - 零点击自动热点管理
- 与 Standard Brokers 相比，重平衡速度提升高达 180 倍
- 内置运营感知：检测修复和补丁操作，防止不安全的重叠
- 在扩缩容前应用最佳实践

### **韧性重新思考** (30:00-34:00)
- **Standard Kafka 行为**：
  - 按需分配系统
  - 依赖客户端和用户不过载系统
  - 过载时导致 broker 故障
- **Express Brokers 改进**：
  - 对计算、内存和网络添加安全动态限流
  - 保护 broker 免受故障影响
  - 可以在一段时间内承受存储故障
  - 客户端可以对限流做出反应，而非仅对故障做出反应

### **额外的韧性特性** (34:00-36:00)
- 补丁无需维护窗口
- 分区级公平性：防止单个分区占用所有吞吐量
- 设计上阻止潜在的级联故障并进行隔离

### **MSK Serverless** (36:00-37:00)
- 适合希望更低管理负担的客户
- 零 Kafka 管理
- 快速扩缩容
- 推荐给 Kafka 或流处理新手

### **监控 Kafka** (37:00-39:00)
- 虽然看似基础，但监控不足是常见故障原因
- **每 Broker/每集群指标**：
  - 每个 broker 的分区数
  - 每个集群的总分区数
  - 每个 broker 的连接数
- **使用率指标**：
  - Broker CPU 使用率
  - 磁盘使用率
  - 内存使用率
  - 吞吐量使用率
- 建议设置告警以便及时响应

### **Flink 使用场景** (39:00-41:00)
- Sai 接手介绍 Flink 部分
- 现场调查：异常检测、数据转换后加载到 OLAP 系统、事件驱动应用
- 使用 Apache Flink 的四个原因：实时、擅长处理动态数据集、有状态、可编程

### **Flink 实时处理示例** (41:00-45:00)
- 场景：构建车队监控系统以快速检测异常
- 从少量节点扩展到数千个节点
- 数据集动态变化：客户创建新资源时添加监控，删除资源时移除监控
- 可以演进监控逻辑：从基础监控扩展到存储、软件版本、区域等
- Flink 的连续处理优于批处理：批处理像照片（捕捉瞬间），流处理像视频（捕捉每一帧）

### **Flink 的状态管理** (45:00-47:00)
- 按键、按服务器、按软件类型捕获状态
- 随着新事件到来增量更新状态
- 等待模式出现并决定是噪音（抑制）还是有效信号（采取行动）
- 示例：监控每分钟超过 5 个故障的阈值，触发自动替换故障节点
- 有状态性提供丰富的上下文记忆以做出更明智的决策

### **Flink 的可编程性** (47:00-49:00)
- 从简单的 if-then-else 逻辑开始
- 随时间演进：添加更多指标监控、映射到数据库表以丰富上下文
- 从简单操作（创建告警）演进到自动化操作（自动替换节点）
- 这种组合使 Flink 成为构建代理 AI 应用的理想选择

### **实时数据处理的三个模式** (49:00-51:00)
- 与客户交流发现的三个关键模式：
  1. 需要改变运营模式
  2. 需要弹性的 Flink 基础设施
  3. 构建健壮的编程逻辑

### **运营模式对比** (51:00-54:00)
- **批处理**：
  - 数据基本固定（数天或数小时前的数据）
  - 分析师运行不同查询寻找洞察
  - 依赖人工采取行动
- **流处理**：
  - 数据持续生成
  - 对连续数据应用静态规则
  - 自动化操作（如替换故障节点）
- 时间在批处理中是隐式的，在流处理中必须显式指定

### **Flink 核心概念** (54:00-57:00)
- **事件时间**：事件实际发生的时间，而非处理时间（避免因处理顺序导致的错误）
- **窗口**：将连续数据流分组到小批次进行分析
- **分区**：数据分布方式，实现并行处理，对高吞吐量低延迟至关重要
- **精确一次处理**：保证每个事件只处理一次，无重复

### **Flink 架构** (57:00-60:00)
- **Job Manager**：Flink 系统的大脑，负责规划、调度和协调工作
- **Task Manager**：执行实际处理，进一步分为 Task Slots 以支持并行处理
- 工作流程：
  1. 部署 JAR 文件
  2. Job Manager 将代码转换为逻辑工作单元
  3. 分解为物理工作单元并放置到 Task Slots
  4. 保证并行性

### **检查点机制** (60:00-62:00)
- Flink 定期将状态检查点持久化到 S3
- 目的：保证精确一次处理，并在故障时提供韧性
- 故障时知道从哪里重启以及如何重启操作符

### **管理员职责** (62:00-64:00)
- 三大类活动：
  1. **部署**：选择基础设施提供商（如 Kubernetes），选择应用模式（专用基础设施）或会话模式（共享基础设施）
  2. **监控**：确保始终在处理数据
  3. **扩展和演进**：监控何时需要扩展，执行扩展，支持部署新代码

### **AWS 托管 Flink 服务** (64:00-67:00)
- 提供构建弹性 Flink 应用的最简单方式
- 开发者体验简化：
  - 无需基础设施设置
  - 内置多可用区韧性
  - 无需配置调优
- 工作流程：在 IDE 中构建应用 → 生成 JAR 文件 → 在托管服务中创建应用 → 开始处理数据

### **减少处理延迟** (67:00-71:00)
- 问题：Flink 中的重大变更（扩展、节点故障、补丁）会导致处理中断
- Flink 的反应：暂停、重新分配、恢复处理
- 解决方案：将 EC2 实例启动时间与作业停机时间分离
- **蓝绿部署**：
  1. 启动新 EC2 实例
  2. 验证作业配置和前置条件
  3. 从旧基础设施切换到新基础设施
  4. 从上次停止点恢复处理
- **热池**：维护预热的基础设施池，无需等待 EC2 实例启动

### **简化代码演进** (71:00-74:00)
- 目标：使流程可重复、防故障、快速
- 工作流程：
  1. 开发者构建新 JAR 文件并提交
  2. 检测到新部署，但不立即停止作业
  3. 对当前运行作业拍摄快照并持久化到 S3
  4. 设置新作业和基础设施
  5. 验证配置
  6. 从快照恢复状态并继续处理

### **总结** (74:00-结束)
- 会议全面覆盖了在 AWS 上大规模运营 Kafka 和 Flink 的最佳实践
- 强调了从存储管理到故障恢复、从水平扩展到智能重平衡的各个方面
- 展示了 AWS 托管服务如何简化复杂的运营任务并提高系统韧性