1
00:00:02,910 --> 00:00:05,160
- Hi, folks, my name is Bryan Landes.

2
00:00:05,160 --> 00:00:07,230
I am a global solutions architect.

3
00:00:07,230 --> 00:00:09,180
First off, welcome.

4
00:00:09,180 --> 00:00:10,650
I hope you're having a great day.

5
00:00:10,650 --> 00:00:13,080
I hope every one of you
makes like $5 million

6
00:00:13,080 --> 00:00:14,610
in the casinos.

7
00:00:14,610 --> 00:00:17,550
If you don't gamble, I hope
you're having great food.

8
00:00:17,550 --> 00:00:19,200
And if you're anything
like me and you hate Vegas,

9
00:00:19,200 --> 00:00:20,400
we're almost outta here.

10
00:00:21,450 --> 00:00:22,710
I wanna introduce myself again.

11
00:00:22,710 --> 00:00:23,543
My name is Bryan.

12
00:00:23,543 --> 00:00:25,350
I've actually been supporting Toyota

13
00:00:25,350 --> 00:00:27,180
for about seven and a half years.

14
00:00:27,180 --> 00:00:28,890
And we wanted to actually
talk a little bit

15
00:00:28,890 --> 00:00:31,890
about some generative AI use
cases and agentic platforms,

16
00:00:31,890 --> 00:00:34,530
especially specifically in the dealership.

17
00:00:34,530 --> 00:00:37,053
I'm here with Stephen and Stephen.

18
00:00:38,070 --> 00:00:39,390
This is a little bit different.

19
00:00:39,390 --> 00:00:41,370
And, you know, there's
definitely a lot of other talks.

20
00:00:41,370 --> 00:00:43,800
I think BMW and Rivian,
a couple of others.

21
00:00:43,800 --> 00:00:45,240
But we kinda wanted to
go a little bit different

22
00:00:45,240 --> 00:00:46,380
this time around.

23
00:00:46,380 --> 00:00:48,780
And we're actually having
two Toyota entities

24
00:00:48,780 --> 00:00:50,160
on stage at once, right?

25
00:00:50,160 --> 00:00:51,840
So we have Toyota Motor North America

26
00:00:51,840 --> 00:00:54,330
and then also Toyota
Connected North America.

27
00:00:54,330 --> 00:00:56,160
They will introduce
themselves in a second.

28
00:00:56,160 --> 00:00:59,100
But again, I just wanna
thank you for being here.

29
00:00:59,100 --> 00:00:59,933
By the way,

30
00:00:59,933 --> 00:01:01,890
we do know how hard it is
to get around re:Invent.

31
00:01:01,890 --> 00:01:03,840
We really do appreciate your time.

32
00:01:03,840 --> 00:01:06,030
If you ever see us in these
orange badges running around,

33
00:01:06,030 --> 00:01:07,890
we're trying to give you the best of show.

34
00:01:07,890 --> 00:01:09,510
We know how things get a little crazy.

35
00:01:09,510 --> 00:01:11,883
So again, thank you for being here.

36
00:01:13,170 --> 00:01:15,000
So yeah, this is basically the flow.

37
00:01:15,000 --> 00:01:16,650
This is what we are gonna be doing.

38
00:01:16,650 --> 00:01:18,330
So I'm gonna come up here.

39
00:01:18,330 --> 00:01:20,160
I'm gonna be about 100 level.

40
00:01:20,160 --> 00:01:23,190
I'm just gonna kind of quickly
level set for a second.

41
00:01:23,190 --> 00:01:24,330
I'm gonna actually talk a little bit

42
00:01:24,330 --> 00:01:26,580
about the story of AWS and Toyota.

43
00:01:26,580 --> 00:01:28,470
That's something that we
don't normally talk about,

44
00:01:28,470 --> 00:01:30,510
but, you know, just kind of
wanted to give you a sneak peek.

45
00:01:30,510 --> 00:01:32,790
I'm gonna pass it off to Stephen Ellis.

46
00:01:32,790 --> 00:01:35,040
He's actually gonna tell you about TMNA,

47
00:01:35,040 --> 00:01:39,090
or Toyota Motor North America's
gen AI enterprise approach.

48
00:01:39,090 --> 00:01:41,580
And then we're gonna nerd
down with Stephen Short.

49
00:01:41,580 --> 00:01:42,580
It's gonna be great.

50
00:01:44,070 --> 00:01:46,920
So yeah, just to kind of level
set for a couple seconds.

51
00:01:46,920 --> 00:01:50,070
Basically just to kind
of again, level set.

52
00:01:50,070 --> 00:01:52,590
We look at our generative AI stack,

53
00:01:52,590 --> 00:01:55,920
basically what you see here, right?

54
00:01:55,920 --> 00:01:57,810
If we start from the
infrastructure layer, right,

55
00:01:57,810 --> 00:02:01,680
we have multiple GPUs, P4s,
P5s, whatever have you.

56
00:02:01,680 --> 00:02:03,420
And you also have SageMaker

57
00:02:03,420 --> 00:02:05,460
that's actually doing the
undifferentiated heavy lifting

58
00:02:05,460 --> 00:02:08,190
to basically help build out
models, whatever it may have,

59
00:02:08,190 --> 00:02:10,350
within your actual stack itself.

60
00:02:10,350 --> 00:02:12,240
If we actually go a little
bit higher up, right,

61
00:02:12,240 --> 00:02:13,470
we use Amazon Bedrock,

62
00:02:13,470 --> 00:02:18,470
which is our way of actually
helping provide LLMs at scale

63
00:02:18,900 --> 00:02:20,100
for our users.

64
00:02:20,100 --> 00:02:22,020
And then if we go a little bit higher,

65
00:02:22,020 --> 00:02:25,380
you know, we still have Nova
Act and also we have Strands,

66
00:02:25,380 --> 00:02:27,270
which is actually our
open source framework

67
00:02:27,270 --> 00:02:30,840
to help build out agents
and deploy them at scale.

68
00:02:30,840 --> 00:02:33,060
Again, we have Kiro, Amazon Q,

69
00:02:33,060 --> 00:02:35,160
but I think more
importantly about this slide

70
00:02:35,160 --> 00:02:38,100
is Toyota's using all this
in various different forms

71
00:02:38,100 --> 00:02:39,233
and fashions, right?

72
00:02:39,233 --> 00:02:42,450
So we try to democratize our AI tooling,

73
00:02:42,450 --> 00:02:43,950
and this is kind of how they approach it.

74
00:02:43,950 --> 00:02:45,480
But again, this is from AWS.

75
00:02:45,480 --> 00:02:47,943
This is how we kind of
look at this whole thing.

76
00:02:49,650 --> 00:02:50,970
I think what's kind of important too

77
00:02:50,970 --> 00:02:54,000
is that we all may,
definitely by now, right?

78
00:02:54,000 --> 00:02:57,120
I think ChatGPT like
launched three years ago.

79
00:02:57,120 --> 00:02:59,220
You know, generative AI chat assistance

80
00:02:59,220 --> 00:03:00,630
were kind of the big thing.

81
00:03:00,630 --> 00:03:02,400
But what we are truly seeing,

82
00:03:02,400 --> 00:03:05,310
and I feel like you know, even
with Swami's keynote today,

83
00:03:05,310 --> 00:03:08,970
is that we are seeing gen
AI actually being deployed

84
00:03:08,970 --> 00:03:10,200
throughout the enterprises

85
00:03:10,200 --> 00:03:12,630
in different specific lines of businesses,

86
00:03:12,630 --> 00:03:17,310
and it's actually becoming much
more agentic all throughout.

87
00:03:17,310 --> 00:03:19,140
And in fact, when Stephen
Short gets up here

88
00:03:19,140 --> 00:03:20,400
in a little bit, he'll
talk to you a little bit

89
00:03:20,400 --> 00:03:22,950
about how he's actually
been working with AgentCore

90
00:03:22,950 --> 00:03:26,220
to be able to deploy these agents at scale

91
00:03:26,220 --> 00:03:31,220
within Toyota Connected and
also Toyota Motor North America.

92
00:03:31,230 --> 00:03:34,260
And that's kind of why we built AgentCore.

93
00:03:34,260 --> 00:03:35,730
I don't know how many of you all may

94
00:03:35,730 --> 00:03:37,290
or may not be using the AgentCore,

95
00:03:37,290 --> 00:03:38,880
but basically this is our service

96
00:03:38,880 --> 00:03:42,810
to have composable infrastructure units

97
00:03:42,810 --> 00:03:45,960
so that you can basically
deploy agents at scale.

98
00:03:45,960 --> 00:03:49,290
So instead of spending 20
months writing identity scripts

99
00:03:49,290 --> 00:03:51,510
or trying to figure out observability

100
00:03:51,510 --> 00:03:53,160
with Datadog for six hours,

101
00:03:53,160 --> 00:03:54,600
you know, basically we have actually

102
00:03:54,600 --> 00:03:56,760
built out these composable points

103
00:03:56,760 --> 00:03:59,610
that you can use with your agents

104
00:03:59,610 --> 00:04:01,500
and be able to deploy
them at scale, right?

105
00:04:01,500 --> 00:04:02,670
'Cause a lot of time we were all trying

106
00:04:02,670 --> 00:04:05,130
to kind of figure out like do
we keep making chat assistants

107
00:04:05,130 --> 00:04:06,510
but actually how do we actually work

108
00:04:06,510 --> 00:04:07,467
with these LLM and agents?

109
00:04:07,467 --> 00:04:09,720
And so that's why this is actually made

110
00:04:09,720 --> 00:04:12,480
and that's what we are
seeing used at scale.

111
00:04:12,480 --> 00:04:15,060
Very quickly just kind of
show you a little bit more

112
00:04:15,060 --> 00:04:15,893
about AgentCore.

113
00:04:15,893 --> 00:04:17,580
I'm not sure if a lot
of folks may or may not

114
00:04:17,580 --> 00:04:18,413
have used AgentCore.

115
00:04:18,413 --> 00:04:20,580
I feel like it's still relatively,

116
00:04:20,580 --> 00:04:22,530
you know, day one service.

117
00:04:22,530 --> 00:04:25,050
But basically this is a
great small example, right,

118
00:04:25,050 --> 00:04:26,730
where you have an application

119
00:04:26,730 --> 00:04:29,430
that might be hitting API
calls to AgentCore runtime,

120
00:04:29,430 --> 00:04:30,630
which is an isolated VM,

121
00:04:30,630 --> 00:04:33,600
so that basically you can have
your own secure environment.

122
00:04:33,600 --> 00:04:36,630
And then you can use any
type of framework, right?

123
00:04:36,630 --> 00:04:38,310
It's actually a framework agnostic

124
00:04:38,310 --> 00:04:40,320
and also LLM agnostic, right?

125
00:04:40,320 --> 00:04:43,873
But in these particular examples,
it's Strands, LlamaIndex,

126
00:04:43,873 --> 00:04:46,650
LangGraph, and also CrewAI, right?

127
00:04:46,650 --> 00:04:48,750
And so basically you would
use these frameworks,

128
00:04:48,750 --> 00:04:51,750
and then you would be able
to deploy these frameworks

129
00:04:51,750 --> 00:04:56,370
and your agents with, again,
the actual AgentCore runtime.

130
00:04:56,370 --> 00:04:58,830
Also there's AgentCore Gateway,

131
00:04:58,830 --> 00:05:00,840
which Stephen Short will talk
about in a couple minutes

132
00:05:00,840 --> 00:05:02,370
about how he's implemented with that.

133
00:05:02,370 --> 00:05:04,020
And then also there's some actual tools

134
00:05:04,020 --> 00:05:06,540
that come out of the box
such as AgentCore browser

135
00:05:06,540 --> 00:05:08,217
and also your code interpreter.

136
00:05:08,217 --> 00:05:10,320
I don't know if anyone's
actually working a lot

137
00:05:10,320 --> 00:05:11,153
with agents as well.

138
00:05:11,153 --> 00:05:13,110
Identity is kind of a very
hard challenge, right,

139
00:05:13,110 --> 00:05:14,640
off Z and off N.

140
00:05:14,640 --> 00:05:16,260
So we actually take this away from you

141
00:05:16,260 --> 00:05:17,190
and help you with this

142
00:05:17,190 --> 00:05:20,100
and so you can actually
have true identities

143
00:05:20,100 --> 00:05:22,290
with your agents without going too crazy

144
00:05:22,290 --> 00:05:24,960
or letting them go off
on their own, right?

145
00:05:24,960 --> 00:05:26,400
Last but not least is memory.

146
00:05:26,400 --> 00:05:27,270
That's a huge thing.

147
00:05:27,270 --> 00:05:28,980
Context windows and everything, right?

148
00:05:28,980 --> 00:05:31,710
Again, we take that away, and
we put it on our backbone.

149
00:05:31,710 --> 00:05:33,930
And then also last but not least
is the observability layer.

150
00:05:33,930 --> 00:05:35,700
You want to actually know
what these agents are doing.

151
00:05:35,700 --> 00:05:38,010
You actually wanna see if
it's actually bringing value

152
00:05:38,010 --> 00:05:39,540
to your lines of businesses, right?

153
00:05:39,540 --> 00:05:41,010
And that's another key component

154
00:05:41,010 --> 00:05:42,780
to why we built out this infrastructure.

155
00:05:42,780 --> 00:05:44,850
And again, when Stephen
Short comes up here,

156
00:05:44,850 --> 00:05:47,512
he'll give you a solid example.

157
00:05:47,512 --> 00:05:50,040
Again, I'm gonna talk
very high level again.

158
00:05:50,040 --> 00:05:52,080
That's why I said I'm 100 level right now.

159
00:05:52,080 --> 00:05:53,550
But basically I do wanna mention

160
00:05:53,550 --> 00:05:56,580
that literally we are seeing
agents across the stack,

161
00:05:56,580 --> 00:05:59,610
specifically with
automotive and manufacturing

162
00:05:59,610 --> 00:06:02,460
being deployed through almost
every single line of business.

163
00:06:02,460 --> 00:06:03,810
We are gonna talk and focus

164
00:06:03,810 --> 00:06:05,070
on the digital customer experience

165
00:06:05,070 --> 00:06:07,080
within this particular talk,

166
00:06:07,080 --> 00:06:09,030
but I am seeing software-defined vehicle

167
00:06:09,030 --> 00:06:10,920
being actually agents deployed.

168
00:06:10,920 --> 00:06:13,350
I am seeing in vehicle
assistance being deployed

169
00:06:13,350 --> 00:06:14,880
within the head unit.

170
00:06:14,880 --> 00:06:16,830
We are seeing agents actually being tested

171
00:06:16,830 --> 00:06:19,860
through smart manufacturing
and call to control.

172
00:06:19,860 --> 00:06:23,310
And we also are seeing product engineering

173
00:06:23,310 --> 00:06:24,660
with your CAD as well

174
00:06:24,660 --> 00:06:27,180
to help generate and
build out faster vehicles

175
00:06:27,180 --> 00:06:29,610
and prototyping, especially
if you're a PM, right?

176
00:06:29,610 --> 00:06:31,740
Sometimes us nerds, like
we nerd down too much,

177
00:06:31,740 --> 00:06:33,900
but your PMs, they use
something like lovable

178
00:06:33,900 --> 00:06:35,040
or some of these other stacks

179
00:06:35,040 --> 00:06:37,020
so they can quickly iterate fast, right?

180
00:06:37,020 --> 00:06:39,660
And basically we were
seeing productivity increase

181
00:06:39,660 --> 00:06:40,743
across the board.

182
00:06:41,850 --> 00:06:43,249
So I do get asked this a lot,

183
00:06:43,249 --> 00:06:45,540
how do you actually do this, right?

184
00:06:45,540 --> 00:06:47,190
So we're talking about
all these cool services,

185
00:06:47,190 --> 00:06:48,840
how do we actually do
this for an enterprise?

186
00:06:48,840 --> 00:06:52,830
And basically platform
engineering is the key, right?

187
00:06:52,830 --> 00:06:53,670
Platform engineering,

188
00:06:53,670 --> 00:06:55,140
if you are not familiar with that term,

189
00:06:55,140 --> 00:06:57,330
I highly recommend you look it up.

190
00:06:57,330 --> 00:07:00,540
It's kind of taken the world
by storm outside of agentic AI.

191
00:07:00,540 --> 00:07:01,800
But basically the idea

192
00:07:01,800 --> 00:07:04,020
is that you have one centralized platform,

193
00:07:04,020 --> 00:07:07,770
and your platform will actually
enable DevOps at scale.

194
00:07:07,770 --> 00:07:11,580
So I do, I'm actually a
platform engineering leader,

195
00:07:11,580 --> 00:07:14,190
and I actually do work with
a lot of other customers

196
00:07:14,190 --> 00:07:16,500
that's not just automotive
and manufacturing.

197
00:07:16,500 --> 00:07:20,550
In fact, my colleague Neil
actually spoke with Cisco

198
00:07:20,550 --> 00:07:24,540
on Monday about this
very particular use case.

199
00:07:24,540 --> 00:07:27,990
But again, ideally one
centralized platform.

200
00:07:27,990 --> 00:07:29,010
I will brag a little bit.

201
00:07:29,010 --> 00:07:31,080
Toyota has like four or five.

202
00:07:31,080 --> 00:07:33,540
It depends on your
organization how you're set up.

203
00:07:33,540 --> 00:07:35,910
But nevertheless, you
focus on your developers,

204
00:07:35,910 --> 00:07:37,710
and then you start
building out more features

205
00:07:37,710 --> 00:07:39,360
and capabilities to your builders,

206
00:07:39,360 --> 00:07:41,160
which I kind of use it as an et al.

207
00:07:41,160 --> 00:07:42,300
And then data scientists,

208
00:07:42,300 --> 00:07:44,910
and then don't forget
about your business, right?

209
00:07:44,910 --> 00:07:46,500
And here you can see very quickly,

210
00:07:46,500 --> 00:07:48,030
it doesn't matter where
you deploy these things.

211
00:07:48,030 --> 00:07:50,760
It could be in a VPC or if you
have a corporate data center,

212
00:07:50,760 --> 00:07:52,770
remember internal development platforms

213
00:07:52,770 --> 00:07:54,720
to solve your cloud problems.

214
00:07:54,720 --> 00:07:57,600
Now that's why.

215
00:07:57,600 --> 00:07:58,470
So turns out

216
00:07:58,470 --> 00:08:00,540
when you actually start using
internal development platform

217
00:08:00,540 --> 00:08:01,950
throughout your organization

218
00:08:01,950 --> 00:08:03,660
and you start using agentic frameworks

219
00:08:03,660 --> 00:08:05,880
and integration into the IDP,

220
00:08:05,880 --> 00:08:08,160
you actually have the ability
to actually deploy agents

221
00:08:08,160 --> 00:08:11,010
at scale within your
own confined arguments

222
00:08:11,010 --> 00:08:13,350
and scale and identity and guardrails,

223
00:08:13,350 --> 00:08:15,780
so your security team's
not freaking out, right?

224
00:08:15,780 --> 00:08:19,230
But basically I'm using AgentCore
icons and also MCP servers

225
00:08:19,230 --> 00:08:21,150
and also I just put strands there for fun.

226
00:08:21,150 --> 00:08:22,920
But ideally what you're
trying to really do

227
00:08:22,920 --> 00:08:26,640
from a centralized cloud
team is democratize agents

228
00:08:26,640 --> 00:08:28,140
so that anyone can deploy these

229
00:08:28,140 --> 00:08:29,940
and actually scale them up at scale.

230
00:08:29,940 --> 00:08:32,130
This is what I'm seeing the most for sure.

231
00:08:32,130 --> 00:08:33,990
Like I just said, Cisco kind of talked

232
00:08:33,990 --> 00:08:35,580
about their whole experience on Monday.

233
00:08:35,580 --> 00:08:37,920
I worked with Spotify, same thing.

234
00:08:37,920 --> 00:08:39,120
And this is kind of the way we're going.

235
00:08:39,120 --> 00:08:40,620
So just remember it doesn't matter

236
00:08:40,620 --> 00:08:43,259
if you're using Kubernetes,
Terraform, CDK, CloudFormation.

237
00:08:43,259 --> 00:08:45,270
But ideally what you
would do is use something

238
00:08:45,270 --> 00:08:46,740
like AgentCore

239
00:08:46,740 --> 00:08:49,080
and you would let these
internal development platforms

240
00:08:49,080 --> 00:08:50,820
have self-service templates,

241
00:08:50,820 --> 00:08:54,060
so you can deploy them in say legal or HR

242
00:08:54,060 --> 00:08:55,620
and anything like that, right?

243
00:08:55,620 --> 00:08:57,900
And help scale these things up.

244
00:08:57,900 --> 00:08:59,923
So story of AWS and Toyota.

245
00:08:59,923 --> 00:09:01,713
This is kind of personal for me.

246
00:09:02,881 --> 00:09:05,790
I've been at AWS for about
seven and a half years.

247
00:09:05,790 --> 00:09:08,400
Before I actually started
really helping out Toyota,

248
00:09:08,400 --> 00:09:11,520
I actually floated around
our self central enterprise

249
00:09:11,520 --> 00:09:12,750
strategic and global accounts.

250
00:09:12,750 --> 00:09:14,970
So I was actually
working with agriculture,

251
00:09:14,970 --> 00:09:17,190
so like Tyson Foods if anyone's
ever been out to Arkansas

252
00:09:17,190 --> 00:09:18,720
to have fun with that.

253
00:09:18,720 --> 00:09:20,730
Also media, entertainment, gaming.

254
00:09:20,730 --> 00:09:23,373
But one day I was very
lucky I got to be on Toyota.

255
00:09:24,840 --> 00:09:26,520
I joined in 2018,

256
00:09:26,520 --> 00:09:29,544
and their footprint was very,
very small to keep it light.

257
00:09:29,544 --> 00:09:33,750
And my team alone, we have
actually spent every single day

258
00:09:33,750 --> 00:09:36,000
and we're helping 'em with
their mobility journey.

259
00:09:36,000 --> 00:09:38,220
And it's not just North America, right?

260
00:09:38,220 --> 00:09:40,710
It's also Toyota Motor
Corporation in Japan.

261
00:09:40,710 --> 00:09:43,050
It's also Toyota Connected in Japan.

262
00:09:43,050 --> 00:09:44,220
Woven by Toyota.

263
00:09:44,220 --> 00:09:46,680
Toyota Racing Development,
which is the NASCAR team.

264
00:09:46,680 --> 00:09:49,800
They're actually using
SageMaker to predict races.

265
00:09:49,800 --> 00:09:51,780
And basically I just
wanted to talk about like

266
00:09:51,780 --> 00:09:53,400
if you are a customer out here,

267
00:09:53,400 --> 00:09:54,750
force your account teams to do this,

268
00:09:54,750 --> 00:09:57,030
because literally I
wake up in the morning,

269
00:09:57,030 --> 00:09:58,050
I'm calling Toyota.

270
00:09:58,050 --> 00:09:59,900
When I go to bed, I'm calling Toyota.

271
00:10:00,780 --> 00:10:03,930
And that's also one big thing
too is that actually they push

272
00:10:03,930 --> 00:10:06,510
on our services every single day.

273
00:10:06,510 --> 00:10:09,210
And in fact we actually
are discovering new types

274
00:10:09,210 --> 00:10:10,350
of workloads all the time.

275
00:10:10,350 --> 00:10:11,257
And in fact,

276
00:10:11,257 --> 00:10:14,370
when I walked into the
internal development platform,

277
00:10:14,370 --> 00:10:16,530
I called up Kashur, which is right there,

278
00:10:16,530 --> 00:10:19,590
and basically said, "Hey,
are you doing this?"

279
00:10:19,590 --> 00:10:22,410
And sure enough, basically
we're on the bleeding edge

280
00:10:22,410 --> 00:10:23,760
and building together.

281
00:10:23,760 --> 00:10:27,120
And so basically I do only
have four use cases up here,

282
00:10:27,120 --> 00:10:29,730
but there's almost about like I think 47.

283
00:10:29,730 --> 00:10:30,870
It's crazy, right?

284
00:10:30,870 --> 00:10:32,880
And so basically I
think a big thing for us

285
00:10:32,880 --> 00:10:34,920
is that we're always learning,
we're always building,

286
00:10:34,920 --> 00:10:37,830
and that's why I'm gonna
show you something better.

287
00:10:37,830 --> 00:10:40,500
Stephen, if you don't
mind, let's go places.

288
00:10:40,500 --> 00:10:42,063
- All right. Thank you, Bryan.

289
00:10:43,830 --> 00:10:47,190
So as Bryan alluded to,

290
00:10:47,190 --> 00:10:50,490
Toyota and AWS has worked
together for a very long time.

291
00:10:50,490 --> 00:10:54,210
And one of the things that's
kind of led to the inception

292
00:10:54,210 --> 00:10:55,590
of our journey with generative AI

293
00:10:55,590 --> 00:10:58,023
was the formation of
our enterprise AI team.

294
00:10:58,920 --> 00:11:01,110
The enterprise AI team
was brought together

295
00:11:01,110 --> 00:11:03,180
to be a center of
excellence for generative AI

296
00:11:03,180 --> 00:11:07,200
for TMNA overall, but it also
has a kind of unique factor

297
00:11:07,200 --> 00:11:09,360
that we don't see in a
lot of enterprise COEs

298
00:11:09,360 --> 00:11:12,960
where almost the entirety
of the team are engineers.

299
00:11:12,960 --> 00:11:16,560
And so what we do is we focus

300
00:11:16,560 --> 00:11:18,930
on either building AI accelerators,

301
00:11:18,930 --> 00:11:20,610
which are baked into tools

302
00:11:20,610 --> 00:11:23,340
that we're using in existing platforms

303
00:11:23,340 --> 00:11:24,330
and then bridging the gap

304
00:11:24,330 --> 00:11:26,070
between the outcome we're trying to get

305
00:11:26,070 --> 00:11:28,560
and the efficiency we're trying to create.

306
00:11:28,560 --> 00:11:30,960
And then at the same time
researching into ways

307
00:11:30,960 --> 00:11:32,820
that we can generate new use cases

308
00:11:32,820 --> 00:11:35,190
and create what we call AI teammates.

309
00:11:35,190 --> 00:11:40,080
Toyota has a policy to keep our teammates

310
00:11:40,080 --> 00:11:41,940
at the center of all of our work.

311
00:11:41,940 --> 00:11:43,050
And so because of that,

312
00:11:43,050 --> 00:11:46,020
everything is based on
augmenting our current teammates

313
00:11:46,020 --> 00:11:49,590
and capabilities and going
to reach full capacity

314
00:11:49,590 --> 00:11:51,330
for whatever the use case is.

315
00:11:51,330 --> 00:11:53,640
And so one of the things that
Stephen Short's gonna show

316
00:11:53,640 --> 00:11:56,340
is how we're looking to
enhance our capability

317
00:11:56,340 --> 00:11:58,800
for delivering product
information at scale

318
00:11:58,800 --> 00:12:01,350
so that our advocates in
our brand engagement center,

319
00:12:01,350 --> 00:12:03,330
our end users on the websites,

320
00:12:03,330 --> 00:12:05,490
our dealers in the shop
can get all of the latest

321
00:12:05,490 --> 00:12:07,800
and greatest data as fast as possible,

322
00:12:07,800 --> 00:12:10,170
but we don't have to create
unique custom pipelines

323
00:12:10,170 --> 00:12:12,390
for every single use case and iteration

324
00:12:12,390 --> 00:12:13,890
and then continue basic,

325
00:12:13,890 --> 00:12:16,290
you know, the normal for
all that you see in IT.

326
00:12:18,000 --> 00:12:20,910
To do that, our group has
kind of a unique structure

327
00:12:20,910 --> 00:12:22,500
inside of our IT organization

328
00:12:22,500 --> 00:12:25,920
where we are kind of a diagonal across.

329
00:12:25,920 --> 00:12:28,080
Brian Kursar, head of global AI,

330
00:12:28,080 --> 00:12:30,570
likes to call our diagonal,
we're not a horizontal.

331
00:12:30,570 --> 00:12:32,160
But we start with exploration.

332
00:12:32,160 --> 00:12:34,890
So this is novel use cases

333
00:12:34,890 --> 00:12:36,330
starting with brand new technology

334
00:12:36,330 --> 00:12:37,650
that no one's ever done before.

335
00:12:37,650 --> 00:12:40,440
And then through
experimentation and education

336
00:12:40,440 --> 00:12:41,940
where we work with our IT teams,

337
00:12:41,940 --> 00:12:44,070
bringing that into business as usual.

338
00:12:44,070 --> 00:12:45,930
So this is where if someone says,

339
00:12:45,930 --> 00:12:49,110
you know, I want to use gen
AI for document retrieval

340
00:12:49,110 --> 00:12:51,450
was one where they wanted
to take all of the contracts

341
00:12:51,450 --> 00:12:53,400
and combine 'em together
to start looking at trends

342
00:12:53,400 --> 00:12:56,700
across the entire SOW scope.

343
00:12:56,700 --> 00:12:58,530
We had a couple of analysts
that were doing that.

344
00:12:58,530 --> 00:12:59,850
There's 300,000 contracts.

345
00:12:59,850 --> 00:13:01,680
They were getting through
about 30,000 a year.

346
00:13:01,680 --> 00:13:03,720
So one of our first
implementations two years ago

347
00:13:03,720 --> 00:13:05,940
was to bring that all into one platform,

348
00:13:05,940 --> 00:13:08,070
use generative AI to go
through and do the analysis,

349
00:13:08,070 --> 00:13:09,600
pull out all the key components,

350
00:13:09,600 --> 00:13:11,340
and then turn that into analytics data

351
00:13:11,340 --> 00:13:13,860
for them to look at all of it at scale.

352
00:13:13,860 --> 00:13:16,670
Time reduction was somewhere
in the order of like 15

353
00:13:16,670 --> 00:13:19,680
to 17 hours per user,

354
00:13:19,680 --> 00:13:21,810
which then also allowed
us to start seeing things

355
00:13:21,810 --> 00:13:25,530
like creep in labor increases

356
00:13:25,530 --> 00:13:28,470
or like we'd see contracts
that had expiration clauses

357
00:13:28,470 --> 00:13:29,340
that we were missing,

358
00:13:29,340 --> 00:13:31,590
and so we're paying way more
than we should have been paying

359
00:13:31,590 --> 00:13:34,380
because we weren't doing like
good decent compliance work.

360
00:13:34,380 --> 00:13:36,270
And we're still evaluating
like the savings,

361
00:13:36,270 --> 00:13:37,410
which continue to grow every year

362
00:13:37,410 --> 00:13:41,040
as we do more and more business
with different partners.

363
00:13:41,040 --> 00:13:43,110
We also take those learnings

364
00:13:43,110 --> 00:13:44,790
and enable other teams to replicate.

365
00:13:44,790 --> 00:13:46,590
So one of the things we're looking to do

366
00:13:46,590 --> 00:13:49,380
is democratize all of
the different use cases

367
00:13:49,380 --> 00:13:50,400
across the board.

368
00:13:50,400 --> 00:13:53,070
So I kind of break them
down to like three groups.

369
00:13:53,070 --> 00:13:55,650
You are taking data and doing analysis,

370
00:13:55,650 --> 00:13:57,990
you're taking content and
generating new content,

371
00:13:57,990 --> 00:14:00,300
or you're distilling disparate content

372
00:14:00,300 --> 00:14:02,250
down into some unified source

373
00:14:02,250 --> 00:14:04,740
that can be distributed
to different groups

374
00:14:04,740 --> 00:14:07,830
and different stakeholders
depending on the audience.

375
00:14:07,830 --> 00:14:10,050
Pretty much all of our use cases
fall into like that bucket.

376
00:14:10,050 --> 00:14:12,240
And so once we find the capability

377
00:14:12,240 --> 00:14:14,190
and are able to develop it for gen AI,

378
00:14:14,190 --> 00:14:16,440
we then wanna spread it out
across the different groups

379
00:14:16,440 --> 00:14:19,140
because time to market is
kind of the only key metric

380
00:14:19,140 --> 00:14:21,810
that we're looking at because
this space moves so fast,

381
00:14:21,810 --> 00:14:23,190
if you don't do it quickly,

382
00:14:23,190 --> 00:14:24,893
you might as well not do it at all.

383
00:14:25,830 --> 00:14:27,930
Once we have those identified,

384
00:14:27,930 --> 00:14:30,000
then we engage with
business users for adoption.

385
00:14:30,000 --> 00:14:33,150
So this is one of the things
that's probably most important

386
00:14:33,150 --> 00:14:35,040
in change management is
getting people to understand

387
00:14:35,040 --> 00:14:36,510
that there's no perfect version,

388
00:14:36,510 --> 00:14:38,250
it's whatever version you can get done

389
00:14:38,250 --> 00:14:40,380
and then you improve upon
it based on learnings.

390
00:14:40,380 --> 00:14:42,840
And sometimes that is a
little bit interesting

391
00:14:42,840 --> 00:14:44,070
in a manufacturing perspective

392
00:14:44,070 --> 00:14:47,250
because everyone kind of
wants to de-risk the project

393
00:14:47,250 --> 00:14:49,230
and plan it out perfectly before we do it.

394
00:14:49,230 --> 00:14:50,640
And doing that in gen AI

395
00:14:50,640 --> 00:14:52,980
just means you're behind every single day.

396
00:14:52,980 --> 00:14:55,440
And then lastly, we work
with our business units

397
00:14:55,440 --> 00:14:59,430
in legal and cyber and
then also for like policy

398
00:14:59,430 --> 00:15:02,868
to ensure that everyone's
using all gen AI responsibly

399
00:15:02,868 --> 00:15:04,326
and that we're not drifting off

400
00:15:04,326 --> 00:15:07,950
or letting additional viewpoints

401
00:15:07,950 --> 00:15:10,920
that are not Toyota specific
come into our products

402
00:15:10,920 --> 00:15:12,390
and then turn us into a company

403
00:15:12,390 --> 00:15:15,303
that may be like not exactly
following like Toyota's way.

404
00:15:17,100 --> 00:15:20,610
To do that, to manage
all of that at scale,

405
00:15:20,610 --> 00:15:23,700
we've kind of taken this
build, configured, buy approach

406
00:15:23,700 --> 00:15:26,343
where because we started with engineers

407
00:15:26,343 --> 00:15:28,800
and research scientists,

408
00:15:28,800 --> 00:15:30,330
we were able to build a
lot of these capabilities

409
00:15:30,330 --> 00:15:31,163
from day one.

410
00:15:31,163 --> 00:15:34,410
So like as soon as ChatGPT
was available as an API,

411
00:15:34,410 --> 00:15:37,560
we started building
systems from the get go.

412
00:15:37,560 --> 00:15:38,850
And the reason we started building

413
00:15:38,850 --> 00:15:41,177
was because those didn't
exist as products.

414
00:15:41,177 --> 00:15:43,410
Once we've built them
and defined requirements

415
00:15:43,410 --> 00:15:44,790
that we know work for our use cases,

416
00:15:44,790 --> 00:15:47,430
we then look for a product
that can be configured

417
00:15:47,430 --> 00:15:50,010
so that it can be worked
into an existing platform.

418
00:15:50,010 --> 00:15:52,620
And then finally, if
those existing products

419
00:15:52,620 --> 00:15:55,590
and features turn into a SaaS platform

420
00:15:55,590 --> 00:15:57,840
or delivered through one
of our trusted partners,

421
00:15:57,840 --> 00:15:59,790
we look to buy that based on knowing

422
00:15:59,790 --> 00:16:02,160
that we're gonna get a certain
outcome from that spend,

423
00:16:02,160 --> 00:16:05,970
which then allows us to then
get support to get maintenance,

424
00:16:05,970 --> 00:16:09,060
get upgrades without us needing
to invest all of that money

425
00:16:09,060 --> 00:16:11,130
into places that we are not the best at.

426
00:16:11,130 --> 00:16:12,960
Toyota is a manufacturer for cars.

427
00:16:12,960 --> 00:16:14,490
We are not a UI/UX shop.

428
00:16:14,490 --> 00:16:16,290
We're not really a
software development shop,

429
00:16:16,290 --> 00:16:17,670
and so it doesn't make sense for us

430
00:16:17,670 --> 00:16:18,990
to try to recreate the wheel

431
00:16:18,990 --> 00:16:21,340
when someone is already
delivering it at scale.

432
00:16:23,340 --> 00:16:25,920
So to make that lifecycle work,

433
00:16:25,920 --> 00:16:27,960
we engage with business on ideas.

434
00:16:27,960 --> 00:16:29,400
So it's basically the idea

435
00:16:29,400 --> 00:16:32,010
is like I want to use generative AI for X.

436
00:16:32,010 --> 00:16:34,890
We engage with them from the
product management perspective

437
00:16:34,890 --> 00:16:37,170
and we have a couple of
engineers that usually engage

438
00:16:37,170 --> 00:16:39,990
with each unit to shape
that into a submission

439
00:16:39,990 --> 00:16:42,780
for our AI/ML governance board.

440
00:16:42,780 --> 00:16:45,030
And it basically means we
would look to evaluate to see

441
00:16:45,030 --> 00:16:46,830
if the solution, vendor,

442
00:16:46,830 --> 00:16:48,600
or the technology is gonna be compliant

443
00:16:48,600 --> 00:16:50,580
with existing standards.

444
00:16:50,580 --> 00:16:53,190
In some cases we find that
there is not a standard

445
00:16:53,190 --> 00:16:54,180
for what we're trying to do,

446
00:16:54,180 --> 00:16:56,220
and so we then help shape a new standard

447
00:16:56,220 --> 00:16:58,890
to make sure that that
can be adopted by groups

448
00:16:58,890 --> 00:17:00,360
across the board.

449
00:17:00,360 --> 00:17:02,820
And then finally, once it goes
through the governance board,

450
00:17:02,820 --> 00:17:04,391
we then engage to build prototypes,

451
00:17:04,391 --> 00:17:06,510
set up productionalization plans,

452
00:17:06,510 --> 00:17:10,650
and then we also help support
authorization when necessary.

453
00:17:10,650 --> 00:17:12,840
There are a lot of teams that
already have their full stack,

454
00:17:12,840 --> 00:17:14,370
and so once we build a prototype

455
00:17:14,370 --> 00:17:16,440
or we validate the
solution, we hand it off,

456
00:17:16,440 --> 00:17:18,890
and then support them by
enabling new technology.

457
00:17:20,730 --> 00:17:24,870
So what that leads us to
is we are now looking at

458
00:17:24,870 --> 00:17:27,960
how do we come up with a
unified enterprise strategy

459
00:17:27,960 --> 00:17:30,210
for agentic SaaS.

460
00:17:30,210 --> 00:17:33,360
And so what we have decided to focus on

461
00:17:33,360 --> 00:17:36,690
is using this stack to
guide most of our choices

462
00:17:36,690 --> 00:17:38,550
and decisions across the board

463
00:17:38,550 --> 00:17:41,520
when it comes to like the future
forward looking enterprise.

464
00:17:41,520 --> 00:17:45,390
So Toyota has a lot of
existing AI/ML investments.

465
00:17:45,390 --> 00:17:47,010
We have an office of data science

466
00:17:47,010 --> 00:17:49,680
that is gonna continue to
build models and tools.

467
00:17:49,680 --> 00:17:52,230
Those tools flow up
through the business rules

468
00:17:52,230 --> 00:17:55,230
and workflows that are
enabling existing processes.

469
00:17:55,230 --> 00:17:57,750
And then once those processes
have been solidified

470
00:17:57,750 --> 00:18:01,020
and we understand what our
KPIs are, we usually run them

471
00:18:01,020 --> 00:18:02,760
through an orchestration layer that says,

472
00:18:02,760 --> 00:18:05,400
okay, here's how we're going
to manage this at scale,

473
00:18:05,400 --> 00:18:06,630
where there's a single team member,

474
00:18:06,630 --> 00:18:09,150
it's a small team or it's an entire org.

475
00:18:09,150 --> 00:18:12,210
And then utilizing
interoperability anchors,

476
00:18:12,210 --> 00:18:13,043
as we were calling 'em,

477
00:18:13,043 --> 00:18:16,620
MCP servers, the app protocols,

478
00:18:16,620 --> 00:18:18,390
frameworks like strands agents.

479
00:18:18,390 --> 00:18:21,090
We're then helping each
team build agents and bots

480
00:18:21,090 --> 00:18:24,030
for their specific use case
but with a common context

481
00:18:24,030 --> 00:18:26,760
that allows them to be shareable
across the organization

482
00:18:26,760 --> 00:18:31,350
and also maintain
precision on the outcome.

483
00:18:31,350 --> 00:18:33,720
So as models change, if we see drift,

484
00:18:33,720 --> 00:18:35,310
if we need to update for new use cases

485
00:18:35,310 --> 00:18:37,980
or a use case develops
like a new capability

486
00:18:37,980 --> 00:18:39,240
that we hadn't seen before,

487
00:18:39,240 --> 00:18:40,980
we can actually bring that back in

488
00:18:40,980 --> 00:18:42,873
and update very quickly and iterate.

489
00:18:43,770 --> 00:18:45,900
One of the reasons that we're
looking at it at that layer

490
00:18:45,900 --> 00:18:48,540
is because we want to infuse this

491
00:18:48,540 --> 00:18:49,950
into our existing platforms

492
00:18:49,950 --> 00:18:52,500
so that the end users that
are actually doing this

493
00:18:52,500 --> 00:18:54,060
on a day to day feel comfortable

494
00:18:54,060 --> 00:18:56,010
with the space that they're
engaging with these agents

495
00:18:56,010 --> 00:18:59,160
and they don't have to relearn
an entirely new UX process

496
00:18:59,160 --> 00:19:01,320
to then get these capabilities.

497
00:19:01,320 --> 00:19:04,380
That will really, really,
really hinder our ability

498
00:19:04,380 --> 00:19:06,300
to get this out at scale,

499
00:19:06,300 --> 00:19:07,590
because as most people understand,

500
00:19:07,590 --> 00:19:09,150
this space changes so quickly.

501
00:19:09,150 --> 00:19:10,950
Every three months there's
something different.

502
00:19:10,950 --> 00:19:13,740
And so once we have an
anchor inside of a space

503
00:19:13,740 --> 00:19:15,240
where a team is using it familiar,

504
00:19:15,240 --> 00:19:17,220
it's a lot easier for us to
upgrade in the background

505
00:19:17,220 --> 00:19:18,690
than to try to redesign those products

506
00:19:18,690 --> 00:19:21,660
every single quarter at this point

507
00:19:21,660 --> 00:19:23,610
because the technology moves that fast.

508
00:19:24,750 --> 00:19:27,540
So for the project we're looking at today,

509
00:19:27,540 --> 00:19:30,030
we were addressed with
an interesting problem.

510
00:19:30,030 --> 00:19:34,260
The experience for the
dealers before gen AI kind of,

511
00:19:34,260 --> 00:19:35,490
probably a little before
they came into the mix

512
00:19:35,490 --> 00:19:37,200
was they were dealing with customers

513
00:19:37,200 --> 00:19:38,640
who were highly researched.

514
00:19:38,640 --> 00:19:39,780
Most people would go on YouTube,

515
00:19:39,780 --> 00:19:42,420
they would look up a vehicle,
they would go through videos,

516
00:19:42,420 --> 00:19:44,190
do a lot of information about our product,

517
00:19:44,190 --> 00:19:45,960
sometimes the history of it.

518
00:19:45,960 --> 00:19:47,940
I remember when the Supra
came out, you could see forms

519
00:19:47,940 --> 00:19:49,290
where everyone was talking
about the differences

520
00:19:49,290 --> 00:19:51,030
between the mark four and the new one

521
00:19:51,030 --> 00:19:52,020
and then they go into a dealer,

522
00:19:52,020 --> 00:19:52,897
and they ask the sales person,

523
00:19:52,897 --> 00:19:55,710
"Hey, why should I buy this new Supra?"

524
00:19:55,710 --> 00:19:56,767
And the dealer's like,

525
00:19:56,767 --> 00:19:58,380
"Because I'm trying to sell it to you."

526
00:19:58,380 --> 00:20:00,180
And so then they go on Google
on their phones on the side

527
00:20:00,180 --> 00:20:02,520
to try to figure out why this
customer is very interested

528
00:20:02,520 --> 00:20:04,500
in like the specific
model of like the engine

529
00:20:04,500 --> 00:20:05,610
that's going into this vehicle

530
00:20:05,610 --> 00:20:07,500
versus a different trim level.

531
00:20:07,500 --> 00:20:09,000
And so to solve that,

532
00:20:09,000 --> 00:20:12,000
we took all of our product
data about the vehicles

533
00:20:12,000 --> 00:20:14,040
that comes from our
manufacturing, our sales,

534
00:20:14,040 --> 00:20:17,340
and our marketing put that
together inside of a pipeline

535
00:20:17,340 --> 00:20:20,010
that allowed it to be delivered
as a RAG implementation

536
00:20:20,010 --> 00:20:22,050
in addition to governance rules

537
00:20:22,050 --> 00:20:24,090
and then guidance from legal

538
00:20:24,090 --> 00:20:26,520
as to how we're supposed
to manage the brand voice

539
00:20:26,520 --> 00:20:29,580
and enable that to be
delivered to the dealerships

540
00:20:29,580 --> 00:20:31,350
for them to like have that conversation

541
00:20:31,350 --> 00:20:33,090
in concert with the user

542
00:20:33,090 --> 00:20:34,770
and then also to the dot coms for them

543
00:20:34,770 --> 00:20:36,360
to do product research.

544
00:20:36,360 --> 00:20:39,090
And so currently that
first version of the system

545
00:20:39,090 --> 00:20:42,090
is deployed to the entire dealer
body for the Toyota dealers

546
00:20:42,090 --> 00:20:45,930
and we're looking at about 7,000
plus interactions per month

547
00:20:45,930 --> 00:20:46,950
that is going through the system

548
00:20:46,950 --> 00:20:48,780
where people were having these sales

549
00:20:48,780 --> 00:20:51,870
and discovery conversations
on a regular basis.

550
00:20:51,870 --> 00:20:53,370
Actually the day we submitted this deck,

551
00:20:53,370 --> 00:20:55,509
Bryan sent me a video of
himself in a dealership

552
00:20:55,509 --> 00:20:58,170
with the product up talking to a dealer

553
00:20:58,170 --> 00:21:00,550
as like we were prepping for showing this.

554
00:21:00,550 --> 00:21:03,450
So to go a little bit deeper
into how the system works,

555
00:21:03,450 --> 00:21:04,710
I'm gonna hand it off
to my partner in crime,

556
00:21:04,710 --> 00:21:05,543
Stephen Short.

557
00:21:11,640 --> 00:21:12,473
- Hello, everyone.

558
00:21:12,473 --> 00:21:13,440
Good afternoon.

559
00:21:13,440 --> 00:21:14,760
My name is Stephen Short,

560
00:21:14,760 --> 00:21:17,010
I'm a senior engineer at Toyota Connected.

561
00:21:17,010 --> 00:21:19,230
And I'm the lead engineer on this project.

562
00:21:19,230 --> 00:21:22,080
Toyota Connected is an
independent Toyota company

563
00:21:22,080 --> 00:21:24,660
that works as a software development shop

564
00:21:24,660 --> 00:21:26,280
and innovation hub.

565
00:21:26,280 --> 00:21:28,546
Today I'm going to
provide a technical live

566
00:21:28,546 --> 00:21:31,740
on what we've built out for
version one of our system,

567
00:21:31,740 --> 00:21:34,980
which as Stephen said, is
a RAG based implementation

568
00:21:34,980 --> 00:21:37,380
as well as where we're
heading for version two,

569
00:21:37,380 --> 00:21:38,880
which is an agentic platform

570
00:21:38,880 --> 00:21:41,530
that we are building within
Amazon Bedrock AgentCore.

571
00:21:43,290 --> 00:21:45,390
To continue with the business context,

572
00:21:45,390 --> 00:21:48,330
what we've built here is
we've built out an assistant,

573
00:21:48,330 --> 00:21:50,280
a platform that serves as an assistant

574
00:21:50,280 --> 00:21:53,790
that allows for users to
ask natural language queries

575
00:21:53,790 --> 00:21:56,460
to learn about Toyota vehicle information.

576
00:21:56,460 --> 00:21:58,050
You can think of this as information

577
00:21:58,050 --> 00:22:01,860
such as vehicle specifications,
pricing details,

578
00:22:01,860 --> 00:22:04,203
trim options, and accessory options.

579
00:22:05,970 --> 00:22:09,330
And we built this in-house
as a custom RAG solution

580
00:22:09,330 --> 00:22:11,193
in order to meet our business needs.

581
00:22:12,240 --> 00:22:15,360
Some of the key capabilities
of our platform are one,

582
00:22:15,360 --> 00:22:18,720
we integrate with Toyota
official backed data sources.

583
00:22:18,720 --> 00:22:21,690
We did not want to rely on
the world knowledge of LLMs

584
00:22:21,690 --> 00:22:24,120
in order to represent our vehicles.

585
00:22:24,120 --> 00:22:28,380
Two, we provide accurate
citation-backed responses.

586
00:22:28,380 --> 00:22:31,980
And three, we support all
Toyota North America vehicles

587
00:22:31,980 --> 00:22:35,580
from model years 2023 through 2026.

588
00:22:36,840 --> 00:22:38,970
In order for us to get this to production,

589
00:22:38,970 --> 00:22:40,410
it was really a team effort.

590
00:22:40,410 --> 00:22:43,680
We worked with many of our
business units within TMNA

591
00:22:43,680 --> 00:22:46,410
such as enterprise AI, our legal teams,

592
00:22:46,410 --> 00:22:47,928
and our cybersecurity teams

593
00:22:47,928 --> 00:22:50,043
in order to get this out to market.

594
00:22:51,000 --> 00:22:53,310
One of the key requirements
that was provided to us

595
00:22:53,310 --> 00:22:57,270
from our legal teams is that any answer

596
00:22:57,270 --> 00:22:59,910
that the assistant sends

597
00:22:59,910 --> 00:23:02,793
needs to include contextually
relevant disclaimers.

598
00:23:04,020 --> 00:23:05,640
The raw data from the sources

599
00:23:05,640 --> 00:23:07,680
that we are pulling the data from,

600
00:23:07,680 --> 00:23:11,106
it includes disclaimer codes as raw text,

601
00:23:11,106 --> 00:23:13,290
as you can see on the left here.

602
00:23:13,290 --> 00:23:16,200
The left is a segment
of a large JSON object,

603
00:23:16,200 --> 00:23:18,240
which is our primary data source,

604
00:23:18,240 --> 00:23:21,510
and within it it has a
disclaimer code in line

605
00:23:21,510 --> 00:23:23,010
that we have to parse

606
00:23:23,010 --> 00:23:26,910
and then map it to an
unaltered legal disclaimer text

607
00:23:26,910 --> 00:23:29,853
that must be shown whenever
contextually relevant.

608
00:23:30,900 --> 00:23:32,310
There were many other requirements

609
00:23:32,310 --> 00:23:34,530
that we had to attend to as well,

610
00:23:34,530 --> 00:23:37,080
such as verbiage of how
we talk about fuel economy

611
00:23:37,080 --> 00:23:38,853
or Toyota Safety Sense features.

612
00:23:43,710 --> 00:23:44,700
And now I'm going to walk you

613
00:23:44,700 --> 00:23:46,620
through the architecture diagram

614
00:23:46,620 --> 00:23:48,123
for version one of our system.

615
00:23:49,140 --> 00:23:51,090
To begin, with the front end,

616
00:23:51,090 --> 00:23:54,870
it will make a request to
the enterprise AI account.

617
00:23:54,870 --> 00:23:57,300
It'll be routed through route 53,

618
00:23:57,300 --> 00:23:59,640
which has a WAF attached to it,

619
00:23:59,640 --> 00:24:03,510
and then we will utilize
Lambda edge authentication

620
00:24:03,510 --> 00:24:05,070
in order to authenticate

621
00:24:05,070 --> 00:24:10,070
and authorize the incoming
request utilizing Entra ID.

622
00:24:10,080 --> 00:24:11,910
Once this is authorized,

623
00:24:11,910 --> 00:24:14,250
then it will route to a piece of code

624
00:24:14,250 --> 00:24:15,990
that is deployed within ECS

625
00:24:15,990 --> 00:24:19,320
that we refer to as the intent router.

626
00:24:19,320 --> 00:24:23,190
The intent router's purpose
is to identify which vehicle

627
00:24:23,190 --> 00:24:25,080
that the user is asking about

628
00:24:25,080 --> 00:24:27,900
so that we know which data to look up.

629
00:24:27,900 --> 00:24:31,050
Before we perform any execution

630
00:24:31,050 --> 00:24:32,970
or inference on the intent router,

631
00:24:32,970 --> 00:24:35,130
we immediately route it to a solution

632
00:24:35,130 --> 00:24:37,710
that was built in-house
by our cybersecurity team

633
00:24:37,710 --> 00:24:39,540
called Prompt Guard.

634
00:24:39,540 --> 00:24:43,440
Prompt Guard is a solution that
is intended to help identify

635
00:24:43,440 --> 00:24:47,373
and block malicious activities
such as prompt injection.

636
00:24:48,300 --> 00:24:50,010
Once this check clears,

637
00:24:50,010 --> 00:24:53,340
then the intent router performs
the vehicle identification,

638
00:24:53,340 --> 00:24:55,860
utilizing an external LLM.

639
00:24:55,860 --> 00:24:59,340
It will create a web socket
connection with the front end.

640
00:24:59,340 --> 00:25:02,010
It will initialize a conversation,

641
00:25:02,010 --> 00:25:04,593
and track that history utilizing DynamoDB.

642
00:25:05,700 --> 00:25:08,190
After this is done, it
will send the request over

643
00:25:08,190 --> 00:25:10,920
to Toyota Connect's main account.

644
00:25:10,920 --> 00:25:13,470
This will go over the internet,
go through CloudFlare,

645
00:25:13,470 --> 00:25:17,343
which has a WAF attached to
it, and hit our API gateway.

646
00:25:18,240 --> 00:25:20,670
From there, it will route immediately

647
00:25:20,670 --> 00:25:23,820
to the Toyota Connected
Shared Services account.

648
00:25:23,820 --> 00:25:27,330
This is an account that is
maintained and supported

649
00:25:27,330 --> 00:25:30,510
by our cloud engineering
team at Toyota Connected,

650
00:25:30,510 --> 00:25:32,482
who helped us take our solution

651
00:25:32,482 --> 00:25:35,315
and help build this up and scale it up

652
00:25:35,315 --> 00:25:37,323
to meet our traffic numbers.

653
00:25:38,190 --> 00:25:40,410
We have our RAG application code

654
00:25:40,410 --> 00:25:43,923
living within an EKS cluster
inside of this account.

655
00:25:44,820 --> 00:25:48,930
We are also utilizing Datadog
for our observability platform

656
00:25:48,930 --> 00:25:51,170
and we will forward all logs to this

657
00:25:51,170 --> 00:25:54,253
and export those to Datadog.

658
00:25:54,253 --> 00:25:57,990
When we are performing
the actual inference,

659
00:25:57,990 --> 00:26:00,840
the RAG application will
call the data services

660
00:26:00,840 --> 00:26:03,510
from the main account.

661
00:26:03,510 --> 00:26:05,971
It'll first hit Amazon SageMaker.

662
00:26:05,971 --> 00:26:07,680
It will generate embeddings

663
00:26:07,680 --> 00:26:09,930
for not only the most recent query

664
00:26:09,930 --> 00:26:12,780
but the previous five
turns of the conversation

665
00:26:12,780 --> 00:26:14,970
and use a weighted average algorithm

666
00:26:14,970 --> 00:26:19,380
in order to provide more preference

667
00:26:19,380 --> 00:26:22,200
towards the most recent conversation

668
00:26:22,200 --> 00:26:24,813
and then keep those within
the contextual window.

669
00:26:25,800 --> 00:26:27,360
And we'll take those embeddings,

670
00:26:27,360 --> 00:26:29,580
and then we will perform a semantic search

671
00:26:29,580 --> 00:26:31,350
against our vector database,

672
00:26:31,350 --> 00:26:34,339
which is hosted inside
of OpenSearch serverless.

673
00:26:34,339 --> 00:26:38,700
We will then retrieve,
using the semantic search,

674
00:26:38,700 --> 00:26:41,613
30 documents per vehicle
that is asked about.

675
00:26:42,510 --> 00:26:46,500
We will use these documents as
our primary source of truth,

676
00:26:46,500 --> 00:26:49,170
and then we will utilize Amazon Bedrock.

677
00:26:49,170 --> 00:26:52,170
We are utilizing the
anthropic models hosted there

678
00:26:52,170 --> 00:26:53,853
in order to drive the inference.

679
00:26:55,020 --> 00:26:57,390
In addition to our assistant prompt

680
00:26:57,390 --> 00:26:59,610
as well as the data that we retrieved,

681
00:26:59,610 --> 00:27:02,700
we are then able to begin
generating an answer.

682
00:27:02,700 --> 00:27:04,440
To meet our business requirements,

683
00:27:04,440 --> 00:27:08,040
we also do some post-processing
on the streaming output,

684
00:27:08,040 --> 00:27:09,783
which I'll dive into shortly.

685
00:27:11,250 --> 00:27:13,590
Once the inference is actually completed,

686
00:27:13,590 --> 00:27:17,010
we will then push them
the message to an SQS,

687
00:27:17,010 --> 00:27:20,190
which is picked up from a Lambda,

688
00:27:20,190 --> 00:27:21,930
which will take these logs

689
00:27:21,930 --> 00:27:26,340
and pull and export them to
MongoDB, which we utilize

690
00:27:26,340 --> 00:27:29,043
to satisfy our compliance
reporting requirements.

691
00:27:30,420 --> 00:27:34,140
From there, we will begin
buffering the output stream

692
00:27:34,140 --> 00:27:37,083
and post it back to TMNA on a web hook.

693
00:27:38,100 --> 00:27:42,450
This will then add it to the
DynamoDB conversation history

694
00:27:42,450 --> 00:27:44,490
and post it back to the front end client

695
00:27:44,490 --> 00:27:46,170
so that it is streamed.

696
00:27:46,170 --> 00:27:47,331
It is worth pointing out

697
00:27:47,331 --> 00:27:50,790
that from the Toyota
Connected perspective,

698
00:27:50,790 --> 00:27:53,610
the RAG application is
completely stateless.

699
00:27:53,610 --> 00:27:55,620
All conversation management is handled

700
00:27:55,620 --> 00:27:57,213
by the enterprise AI account.

701
00:28:00,150 --> 00:28:02,220
In order to support this use case,

702
00:28:02,220 --> 00:28:05,880
we had to figure out a way
to take these raw JSON data

703
00:28:05,880 --> 00:28:08,253
and then translate it
into a usable format.

704
00:28:09,240 --> 00:28:12,090
The approach that we took was we landed

705
00:28:12,090 --> 00:28:14,940
on utilizing natural
language summarizations

706
00:28:14,940 --> 00:28:16,890
for these JSON objects.

707
00:28:16,890 --> 00:28:19,590
You can see an example of a single chunk

708
00:28:19,590 --> 00:28:21,660
from a large JSON object

709
00:28:21,660 --> 00:28:25,140
that represents one feature
of one of our vehicles.

710
00:28:25,140 --> 00:28:29,040
Inside of there, there are
internal mappings for trim codes

711
00:28:29,040 --> 00:28:32,910
as well as MSRP information,
descriptions, titles,

712
00:28:32,910 --> 00:28:34,950
and other various fields.

713
00:28:34,950 --> 00:28:38,490
We take that, and then we utilize Bedrock

714
00:28:38,490 --> 00:28:42,900
to generate natural language
translations of this object

715
00:28:42,900 --> 00:28:44,460
that we then utilize

716
00:28:44,460 --> 00:28:47,343
in order to perform the semantic search.

717
00:28:48,210 --> 00:28:50,430
In addition to the processed fields,

718
00:28:50,430 --> 00:28:52,380
we also include the raw data

719
00:28:52,380 --> 00:28:56,490
that the processed field
was generated from.

720
00:28:56,490 --> 00:28:58,590
This raw data is important for us

721
00:28:58,590 --> 00:29:01,320
to actually perform
the citations workflows

722
00:29:01,320 --> 00:29:03,063
that I was mentioning previously.

723
00:29:05,940 --> 00:29:09,510
And now I'm going to walk you
all through our ETL pipeline

724
00:29:09,510 --> 00:29:12,090
of how we ingest this data.

725
00:29:12,090 --> 00:29:14,910
We have a data account
within Toyota Connected,

726
00:29:14,910 --> 00:29:17,760
which utilizes AWS Step Functions

727
00:29:17,760 --> 00:29:19,897
to orchestrate a series of Glue scripts

728
00:29:19,897 --> 00:29:22,410
to perform the actual extract

729
00:29:22,410 --> 00:29:24,873
and transform portions of the ETL.

730
00:29:25,890 --> 00:29:28,440
The first script is the extract script.

731
00:29:28,440 --> 00:29:31,080
It will pull all of the
supported vehicle data

732
00:29:31,080 --> 00:29:35,043
from our Toyota API servers
and then push those into S3.

733
00:29:36,060 --> 00:29:39,480
The second script is the transform script.

734
00:29:39,480 --> 00:29:42,240
This is the heaviest
portion of our pipeline.

735
00:29:42,240 --> 00:29:44,580
In order to maximize throughput,

736
00:29:44,580 --> 00:29:46,890
we were able to paralyze this,

737
00:29:46,890 --> 00:29:50,490
and we are able to transform

738
00:29:50,490 --> 00:29:53,760
up to around 30 vehicles concurrently.

739
00:29:53,760 --> 00:29:57,930
This script will first
chunk the JSON data,

740
00:29:57,930 --> 00:30:01,260
and then two, it will do the translation

741
00:30:01,260 --> 00:30:02,700
that I mentioned before

742
00:30:02,700 --> 00:30:05,250
and generate natural
language summarizations

743
00:30:05,250 --> 00:30:06,813
using Amazon Bedrock.

744
00:30:07,710 --> 00:30:12,600
Afterwards, due to the
non-deterministic nature

745
00:30:12,600 --> 00:30:15,930
of LLM output, it is up to us to ensure

746
00:30:15,930 --> 00:30:19,410
that these summarizations are accurate,

747
00:30:19,410 --> 00:30:22,140
and hence we added data quality checks

748
00:30:22,140 --> 00:30:25,260
that verify the output
of these summarizations

749
00:30:25,260 --> 00:30:28,830
and ensure the accuracy of
critical pieces of information

750
00:30:28,830 --> 00:30:32,073
such as pricing details
and trim availabilities.

751
00:30:33,000 --> 00:30:36,360
From there, another script
will take these outputs

752
00:30:36,360 --> 00:30:37,500
and generate embeddings

753
00:30:37,500 --> 00:30:41,010
of the natural language summarization

754
00:30:41,010 --> 00:30:44,130
and then tie together
them with the raw data

755
00:30:44,130 --> 00:30:46,473
and then publish those into S3.

756
00:30:47,370 --> 00:30:50,730
From there, the extract
and transform is complete.

757
00:30:50,730 --> 00:30:52,950
And now we need to move on to the load.

758
00:30:52,950 --> 00:30:55,830
And this is facilitated
via publishing an event

759
00:30:55,830 --> 00:30:58,080
to Amazon EventBridge,

760
00:30:58,080 --> 00:31:02,400
which then triggers a Lambda
on each of our dev stage

761
00:31:02,400 --> 00:31:04,290
and prod accounts.

762
00:31:04,290 --> 00:31:06,960
This Lambda will pull the data,

763
00:31:06,960 --> 00:31:10,560
or first it will grab necessary parameters

764
00:31:10,560 --> 00:31:14,310
from AWS systems manager that it utilizes

765
00:31:14,310 --> 00:31:18,120
to configure an OpenSearch
ingest pipeline.

766
00:31:18,120 --> 00:31:21,090
From there, it will proceed
to create a new index

767
00:31:21,090 --> 00:31:23,100
in our OpenSearch collection.

768
00:31:23,100 --> 00:31:26,160
This index is created
based off of the timestamp

769
00:31:26,160 --> 00:31:28,173
of the start of the ETL pipeline.

770
00:31:29,220 --> 00:31:30,390
Then it will proceed

771
00:31:30,390 --> 00:31:33,780
to create the OpenSearch
ingest pipeline itself,

772
00:31:33,780 --> 00:31:36,870
which then is configured
to read from the output

773
00:31:36,870 --> 00:31:40,413
of the transform step on
our data account S3 bucket.

774
00:31:41,280 --> 00:31:42,543
It will take that output

775
00:31:42,543 --> 00:31:46,710
and then ingest it into
the newly created index.

776
00:31:46,710 --> 00:31:50,584
Once this is completed,
we stop the pipeline,

777
00:31:50,584 --> 00:31:53,970
and then the data is
almost ready to be used.

778
00:31:53,970 --> 00:31:57,360
However, due to the,
as I mentioned before,

779
00:31:57,360 --> 00:32:01,590
there's non-determinism
involved in every LLM call.

780
00:32:01,590 --> 00:32:04,290
In order to ensure the
quality of our system

781
00:32:04,290 --> 00:32:06,060
and that the newly ingested data

782
00:32:06,060 --> 00:32:09,060
will meet our performance expectations,

783
00:32:09,060 --> 00:32:12,270
we have created an evaluations engine

784
00:32:12,270 --> 00:32:16,020
that we have created and
orchestrated a series of scripts

785
00:32:16,020 --> 00:32:17,823
utilizing GitLab Runners.

786
00:32:19,170 --> 00:32:21,630
Our counterparts at TMNA provided us

787
00:32:21,630 --> 00:32:25,440
with a golden set of data
for one of our vehicles.

788
00:32:25,440 --> 00:32:28,050
This is a series of
question and answer pairs

789
00:32:28,050 --> 00:32:33,000
that has been proven from
one of the SMEs over at TMNA.

790
00:32:33,000 --> 00:32:34,470
We took this output,

791
00:32:34,470 --> 00:32:37,200
and we utilized it as our golden data set

792
00:32:37,200 --> 00:32:40,290
in order to generate a synthetic test set.

793
00:32:40,290 --> 00:32:43,050
This synthetic test set can be generated

794
00:32:43,050 --> 00:32:45,030
for any of our vehicles.

795
00:32:45,030 --> 00:32:49,050
We will take that output,
and then use that output

796
00:32:49,050 --> 00:32:52,320
to invoke against our
deployed RAG application.

797
00:32:52,320 --> 00:32:57,240
From there, we will take the
output of the evaluation calls

798
00:32:57,240 --> 00:33:02,240
and actually perform utilizing
a council of LLM approach

799
00:33:02,370 --> 00:33:05,730
to understand and gauge
against a series of metrics

800
00:33:05,730 --> 00:33:08,817
that we've defined to measure
the performance of our system

801
00:33:08,817 --> 00:33:10,323
and the quality of data.

802
00:33:11,340 --> 00:33:14,340
Once this is done, then
we have an understanding

803
00:33:14,340 --> 00:33:16,429
of how well the new data set is performed

804
00:33:16,429 --> 00:33:19,887
and we can switch our index alias,

805
00:33:19,887 --> 00:33:22,260
which is how our RAG application knows

806
00:33:22,260 --> 00:33:23,940
which data set to utilize,

807
00:33:23,940 --> 00:33:26,730
and point it to the newly created index.

808
00:33:26,730 --> 00:33:30,210
This allows for us to
swap to a new data version

809
00:33:30,210 --> 00:33:31,803
without any downtime.

810
00:33:35,010 --> 00:33:39,450
Beyond evaluations, it is also
important for us to ensure

811
00:33:39,450 --> 00:33:42,150
that we are meeting the
compliance guidelines

812
00:33:42,150 --> 00:33:45,120
that was provided to us from our partners

813
00:33:45,120 --> 00:33:47,430
from our legal teams at TMNA.

814
00:33:47,430 --> 00:33:50,400
They provided us with a set of guidelines

815
00:33:50,400 --> 00:33:53,370
of how the assistant
should answer questions

816
00:33:53,370 --> 00:33:55,950
and how it should generally behave.

817
00:33:55,950 --> 00:34:00,780
The way that we do this is
we take incoming Q&A pairs

818
00:34:00,780 --> 00:34:03,210
and then we utilize Amazon Bedrock

819
00:34:03,210 --> 00:34:06,300
to first categorize the incoming question

820
00:34:06,300 --> 00:34:08,970
to understand what the
user was asking about,

821
00:34:08,970 --> 00:34:13,590
and then two, measure how
well the response measured up

822
00:34:13,590 --> 00:34:16,230
and complied with these guidelines.

823
00:34:16,230 --> 00:34:20,010
We will then ingest this
compliance status to MongoDB,

824
00:34:20,010 --> 00:34:23,145
which we utilize as the
primary backend database

825
00:34:23,145 --> 00:34:26,040
for our compliance reporting engine.

826
00:34:26,040 --> 00:34:28,140
You can see a snapshot of the front end

827
00:34:28,140 --> 00:34:30,120
that we've created to support this,

828
00:34:30,120 --> 00:34:33,090
and we share access to this
with our friends from legal

829
00:34:33,090 --> 00:34:36,330
in order for them to understand
how the system is performing

830
00:34:36,330 --> 00:34:37,203
in production.

831
00:34:40,170 --> 00:34:43,500
On the topic of compliance,
one thing I mentioned before

832
00:34:43,500 --> 00:34:46,680
was how we have to handle disclaimers.

833
00:34:46,680 --> 00:34:48,960
In order for us to provide disclaimers

834
00:34:48,960 --> 00:34:52,200
that are contextually
relevant to the output,

835
00:34:52,200 --> 00:34:54,930
we have to ensure that
our disclaimers text

836
00:34:54,930 --> 00:34:57,720
is treated as immutable data.

837
00:34:57,720 --> 00:35:00,150
In addition to the disclaimers text,

838
00:35:00,150 --> 00:35:03,210
we also support showing vehicle images,

839
00:35:03,210 --> 00:35:05,217
which also the image URLs

840
00:35:05,217 --> 00:35:10,217
and the image metadata also
must not be altered by the LLM.

841
00:35:10,260 --> 00:35:12,840
The way that we approached
solving this problem

842
00:35:12,840 --> 00:35:15,840
is we took a stream splitting approach.

843
00:35:15,840 --> 00:35:19,230
We provided instructions
and provided many examples

844
00:35:19,230 --> 00:35:20,280
to our system prompt

845
00:35:20,280 --> 00:35:23,070
to utilize and leverage
in context learning

846
00:35:23,070 --> 00:35:26,970
to split the stream into
three distinct segments.

847
00:35:26,970 --> 00:35:29,760
The first is the main output stream.

848
00:35:29,760 --> 00:35:31,020
This is what gets streamed

849
00:35:31,020 --> 00:35:33,750
and shown directly on the front ends.

850
00:35:33,750 --> 00:35:36,450
The second is a list of disclaimers codes

851
00:35:36,450 --> 00:35:40,350
that the LLM will utilize as citations

852
00:35:40,350 --> 00:35:42,780
and then populate the disclaimers codes

853
00:35:42,780 --> 00:35:45,180
that it believes should be surfaced

854
00:35:45,180 --> 00:35:47,430
as part of its inference.

855
00:35:47,430 --> 00:35:50,913
And then the third, the images
follow the same principle.

856
00:35:51,870 --> 00:35:54,750
Any images that need to
be shown to the end user

857
00:35:54,750 --> 00:35:57,180
as part of this answer, it is published,

858
00:35:57,180 --> 00:35:59,100
we collect image IDs,

859
00:35:59,100 --> 00:36:03,150
and then after this is done,
we will take the list of codes

860
00:36:03,150 --> 00:36:04,655
and then the list of image IDs

861
00:36:04,655 --> 00:36:07,860
and then utilize a mapping
that we have available

862
00:36:07,860 --> 00:36:11,940
to our service to send this
up and post it onto the stream

863
00:36:11,940 --> 00:36:13,923
without ever being touched by the LLM.

864
00:36:15,240 --> 00:36:17,460
An example of how we do
this is shown in the code

865
00:36:17,460 --> 00:36:18,450
on the right.

866
00:36:18,450 --> 00:36:22,080
We are essentially going
through the output stream

867
00:36:22,080 --> 00:36:25,020
of the invoke model with
the response stream,

868
00:36:25,020 --> 00:36:28,770
and we are looking for specific delimiters

869
00:36:28,770 --> 00:36:32,530
for either the disclaimers
case or the images case

870
00:36:32,530 --> 00:36:36,483
and then switching the state
of the output accordingly.

871
00:36:39,210 --> 00:36:41,250
As we built out version one,

872
00:36:41,250 --> 00:36:43,050
we saw that there were many opportunities

873
00:36:43,050 --> 00:36:46,170
of how we wanted to expand our services.

874
00:36:46,170 --> 00:36:49,500
First we wanted to onboard
additional data sets

875
00:36:49,500 --> 00:36:50,880
and additional clients.

876
00:36:50,880 --> 00:36:54,300
There's many use cases
that we could pivot into,

877
00:36:54,300 --> 00:36:57,777
and we also wanted to reduce the reliance

878
00:37:00,330 --> 00:37:02,520
on our ETL pipelines.

879
00:37:02,520 --> 00:37:03,570
As you can see,

880
00:37:03,570 --> 00:37:07,350
there's actually a lot going
on for us to do this ETL,

881
00:37:07,350 --> 00:37:10,530
and this was compounded by
the fact that every year

882
00:37:10,530 --> 00:37:13,290
when Toyota is rolling
out a new model year,

883
00:37:13,290 --> 00:37:16,500
the frequency of changes in
this upstream data source

884
00:37:16,500 --> 00:37:21,180
is very rapid, which would every
time that the data changes,

885
00:37:21,180 --> 00:37:24,600
we would need to do the entire ingest

886
00:37:24,600 --> 00:37:27,540
and then rerun the evaluation strategy.

887
00:37:27,540 --> 00:37:30,705
This data stillness issue
was a real problem for us

888
00:37:30,705 --> 00:37:34,230
and something that we
saw as an opportunity

889
00:37:34,230 --> 00:37:35,463
for us to improve on.

890
00:37:36,630 --> 00:37:40,230
In addition to this, the
business started to have appetite

891
00:37:40,230 --> 00:37:43,500
for actions that were
beyond the capabilities

892
00:37:43,500 --> 00:37:46,950
of what our version one
assistant was able to perform,

893
00:37:46,950 --> 00:37:49,859
such as allowing users to ask

894
00:37:49,859 --> 00:37:54,120
and look for local availability
from their local dealership

895
00:37:54,120 --> 00:37:55,623
for Toyota vehicles.

896
00:37:56,970 --> 00:37:59,010
As part of these opportunities,

897
00:37:59,010 --> 00:38:03,566
we started to perform research
into agentic platforms.

898
00:38:03,566 --> 00:38:08,100
Our early experimentations
utilizing the Strands SDK

899
00:38:08,100 --> 00:38:12,482
and creating our own
agents and MCP servers

900
00:38:12,482 --> 00:38:17,220
revealed to us a key finding
that we actually can utilize

901
00:38:17,220 --> 00:38:21,570
due to the advancements
of both MCP and LLMs.

902
00:38:21,570 --> 00:38:25,320
We are able to connect our
agents directly to the data

903
00:38:25,320 --> 00:38:27,150
and then remove the support,

904
00:38:27,150 --> 00:38:29,430
we were able to drop our ETL pipeline

905
00:38:29,430 --> 00:38:31,890
and traditional RAG system entirely,

906
00:38:31,890 --> 00:38:35,250
and then that allows us to
avoid the data stillness issues

907
00:38:35,250 --> 00:38:38,010
while giving flexibility
to support actions

908
00:38:38,010 --> 00:38:39,213
and advanced reasoning.

909
00:38:41,280 --> 00:38:43,170
However, while this was easy

910
00:38:43,170 --> 00:38:47,070
for us to put together proofs
of concepts and demo this,

911
00:38:47,070 --> 00:38:50,010
actually planning a
system in agentic platform

912
00:38:50,010 --> 00:38:53,400
and getting to this to
production is difficult.

913
00:38:53,400 --> 00:38:56,640
Agents, they bring a lot of complexities

914
00:38:56,640 --> 00:38:58,710
as well as MCP servers.

915
00:38:58,710 --> 00:39:03,180
Creating sane authentication
and authorization strategies,

916
00:39:03,180 --> 00:39:04,680
auto-scale and configurations

917
00:39:04,680 --> 00:39:06,960
to support the expected traffic loads,

918
00:39:06,960 --> 00:39:09,960
and then guaranteeing
context and session isolation

919
00:39:09,960 --> 00:39:11,805
is a difficult task.

920
00:39:11,805 --> 00:39:14,280
And so to reiterate,

921
00:39:14,280 --> 00:39:17,040
some of the platform goals of
what we are looking to build

922
00:39:17,040 --> 00:39:18,780
for version two of the system

923
00:39:18,780 --> 00:39:22,080
is we are building an
extensible agentic platform.

924
00:39:22,080 --> 00:39:24,420
We are going to be enabling actions,

925
00:39:24,420 --> 00:39:27,480
perform enhanced auth
and session isolation

926
00:39:27,480 --> 00:39:30,510
to address the complexities
of a multi-agent system

927
00:39:30,510 --> 00:39:32,013
with MCP servers.

928
00:39:32,850 --> 00:39:34,371
And we are going to be doing this

929
00:39:34,371 --> 00:39:38,010
to support increased traffic numbers

930
00:39:38,010 --> 00:39:40,350
as well as having lower
infrastructure overhead

931
00:39:40,350 --> 00:39:42,330
for our team to maintain.

932
00:39:42,330 --> 00:39:44,430
Our platform target for version two

933
00:39:44,430 --> 00:39:47,817
is we are looking to build
a series of strands agents

934
00:39:47,817 --> 00:39:49,470
and MCP servers

935
00:39:49,470 --> 00:39:52,623
leveraging Amazon Bedrock
AgentCore Services.

936
00:39:54,360 --> 00:39:59,360
Our early experiments in
AgentCore have been great.

937
00:39:59,430 --> 00:40:01,110
The services are actually built out

938
00:40:01,110 --> 00:40:02,580
to address many of the concerns

939
00:40:02,580 --> 00:40:06,461
that I had of getting our
system from demo to production.

940
00:40:06,461 --> 00:40:10,650
AgentCore runtime, it's a
firecracker VM-based solution

941
00:40:10,650 --> 00:40:13,710
that provides isolation by default.

942
00:40:13,710 --> 00:40:16,890
It's scalable as it's a
serverless technology.

943
00:40:16,890 --> 00:40:18,840
And there's low infrastructure overhead

944
00:40:18,840 --> 00:40:20,876
for us to build these.

945
00:40:20,876 --> 00:40:25,876
AgentCore identity will tackle
the complexities of identity

946
00:40:26,280 --> 00:40:29,400
and inbound and outbound authentication

947
00:40:29,400 --> 00:40:32,850
within a multi-agent and multi-MCP system.

948
00:40:32,850 --> 00:40:35,250
In AgentCore memory, it allows for us

949
00:40:35,250 --> 00:40:38,550
to simplify the conversation
management pattern

950
00:40:38,550 --> 00:40:41,880
as well as provide some
interesting novel use cases

951
00:40:41,880 --> 00:40:44,043
that we can tie into our agents.

952
00:40:44,940 --> 00:40:48,390
And MCP servers, there's two options here.

953
00:40:48,390 --> 00:40:50,490
You can utilize AgentCore Gateway,

954
00:40:50,490 --> 00:40:52,331
which is a fantastic service,

955
00:40:52,331 --> 00:40:57,331
and if you need additional customization

956
00:40:58,320 --> 00:41:00,030
such as response caching,

957
00:41:00,030 --> 00:41:03,810
what I found is that we can
actually deploy the MCP servers

958
00:41:03,810 --> 00:41:06,840
into AgentCore runtime and
couple them with memory,

959
00:41:06,840 --> 00:41:08,313
which I'll dive into shortly.

960
00:41:10,740 --> 00:41:11,700
And now I'm going to walk you

961
00:41:11,700 --> 00:41:14,460
through our target infrastructure diagram

962
00:41:14,460 --> 00:41:15,960
for version two of our system.

963
00:41:16,950 --> 00:41:19,380
As you can see on the left,

964
00:41:19,380 --> 00:41:23,610
much of the stack from the
enterprise AI side is similar.

965
00:41:23,610 --> 00:41:28,110
There are two key pieces that
I want to point out however.

966
00:41:28,110 --> 00:41:32,040
First is that we are looking
to replace the intent router

967
00:41:32,040 --> 00:41:33,243
with an orchestrator.

968
00:41:34,110 --> 00:41:37,770
This orchestrator will
integrate with an agent registry

969
00:41:37,770 --> 00:41:40,410
that Toyota Connected will be building.

970
00:41:40,410 --> 00:41:41,850
This agent registry,

971
00:41:41,850 --> 00:41:45,960
you can think of it as a
mapping of authenticated clients

972
00:41:45,960 --> 00:41:49,173
to which agents are available
to each calling client.

973
00:41:50,280 --> 00:41:52,678
Utilizing this registry,

974
00:41:52,678 --> 00:41:57,180
when a front end request comes
in and hits the orchestrator,

975
00:41:57,180 --> 00:42:00,000
the orchestrator will know
what agents are available

976
00:42:00,000 --> 00:42:01,350
for the client,

977
00:42:01,350 --> 00:42:04,770
and then it will route it
to the appropriate agent.

978
00:42:04,770 --> 00:42:08,910
We are also looking to
remove the external LLM calls

979
00:42:08,910 --> 00:42:13,140
that we utilize inside of the
intent router in version one

980
00:42:13,140 --> 00:42:16,503
and utilize Bedrock calls
for that orchestrator in V2.

981
00:42:17,759 --> 00:42:21,300
On the right in the Toyota
Connected infrastructure,

982
00:42:21,300 --> 00:42:23,640
you can see I have a couple of agents,

983
00:42:23,640 --> 00:42:27,510
the product expert agent and
the product support agent.

984
00:42:27,510 --> 00:42:29,610
Both of these are going
to be strands agents

985
00:42:29,610 --> 00:42:32,133
that are deployed within
AgentCore runtime.

986
00:42:33,120 --> 00:42:36,870
These agents are going to
be coupled with MCP servers

987
00:42:36,870 --> 00:42:39,540
that provide tools that
are necessary for them

988
00:42:39,540 --> 00:42:41,043
in order to do their job.

989
00:42:42,420 --> 00:42:45,480
So we have a couple of
options for MCP servers

990
00:42:45,480 --> 00:42:46,920
as I mentioned.

991
00:42:46,920 --> 00:42:48,720
We believe that AgentCore gateway

992
00:42:48,720 --> 00:42:50,520
is going to be a perfect fit

993
00:42:50,520 --> 00:42:53,043
for our product support MCP server.

994
00:42:54,930 --> 00:42:56,280
To back up a little bit,

995
00:42:56,280 --> 00:42:58,830
to explain the differences
between the agents,

996
00:42:58,830 --> 00:43:00,930
the product expert agent,
you can think of it

997
00:43:00,930 --> 00:43:05,070
as basically agentifying
the version one capabilities

998
00:43:05,070 --> 00:43:06,420
of our platform.

999
00:43:06,420 --> 00:43:08,280
That's the purpose of that agent.

1000
00:43:08,280 --> 00:43:11,130
And the product support
agent is a separate agent

1001
00:43:11,130 --> 00:43:13,950
that is intended to help
service customer inquiries

1002
00:43:13,950 --> 00:43:15,033
about their vehicle.

1003
00:43:16,590 --> 00:43:20,100
So we believe the product
support MCP server

1004
00:43:20,100 --> 00:43:22,830
will be a good fit for AgentCore Gateway.

1005
00:43:22,830 --> 00:43:25,620
The product expert MCP server, however,

1006
00:43:25,620 --> 00:43:29,550
it is on us to ensure that
we are responsible consumers

1007
00:43:29,550 --> 00:43:34,550
of the Toyota APIs that drive
the data for this agent.

1008
00:43:34,710 --> 00:43:38,310
As such, we must implement
response caching.

1009
00:43:38,310 --> 00:43:40,050
It's a hard requirement.

1010
00:43:40,050 --> 00:43:41,970
We have to make sure that we do it.

1011
00:43:41,970 --> 00:43:46,570
And I found via some
experiments last week actually

1012
00:43:47,430 --> 00:43:52,110
that we can utilize AgentCore memory

1013
00:43:52,110 --> 00:43:54,750
in order to achieve response caching.

1014
00:43:54,750 --> 00:43:56,430
And I'm going to provide an example

1015
00:43:56,430 --> 00:44:00,060
of how we can utilize memory
as a distributed cache,

1016
00:44:00,060 --> 00:44:03,273
and it looks like it will
work quite well actually.

1017
00:44:05,220 --> 00:44:07,470
In addition to these AgentCore services,

1018
00:44:07,470 --> 00:44:10,500
we are looking at utilizing
the other AgentCore services

1019
00:44:10,500 --> 00:44:12,100
such as AgentCore observability.

1020
00:44:14,700 --> 00:44:17,100
It supports open telemetry by default,

1021
00:44:17,100 --> 00:44:19,440
so we will be passing these along

1022
00:44:19,440 --> 00:44:22,710
and forwarding the logs
to our Datadog instance.

1023
00:44:22,710 --> 00:44:25,440
We'll be utilizing AgentCore
identity to integrate

1024
00:44:25,440 --> 00:44:27,480
with our chosen identity provider.

1025
00:44:27,480 --> 00:44:28,350
And we will continue

1026
00:44:28,350 --> 00:44:30,963
to support our compliance
analysis workflows.

1027
00:44:33,390 --> 00:44:37,140
In order for us to
perform response caching,

1028
00:44:37,140 --> 00:44:40,350
one of our experiments
that we've been doing is,

1029
00:44:40,350 --> 00:44:41,520
I'll walk you through it.

1030
00:44:41,520 --> 00:44:43,770
So we have our product expert agent,

1031
00:44:43,770 --> 00:44:45,440
which will be making a tool call

1032
00:44:45,440 --> 00:44:48,330
to the corresponding MCP server.

1033
00:44:48,330 --> 00:44:51,420
From there, we'll first check to ensure

1034
00:44:51,420 --> 00:44:54,210
whether or not this exists in the cache.

1035
00:44:54,210 --> 00:44:57,270
We are utilizing AgentCore
memory event metadata

1036
00:44:57,270 --> 00:44:59,520
to accomplish this.

1037
00:44:59,520 --> 00:45:01,740
So if there is a cache hit,

1038
00:45:01,740 --> 00:45:04,620
it'll pull the information
from the event metadata

1039
00:45:04,620 --> 00:45:07,440
and then pass it up to the calling agent.

1040
00:45:07,440 --> 00:45:10,320
On a cache miss, we will be going out

1041
00:45:10,320 --> 00:45:13,170
and making the call to the external APIs

1042
00:45:13,170 --> 00:45:16,890
and then caching them
within the response cache.

1043
00:45:16,890 --> 00:45:20,190
On the right, you can see
some code that I've created

1044
00:45:20,190 --> 00:45:24,510
that is a decorator of which
we can apply to any tool call

1045
00:45:24,510 --> 00:45:27,000
within our MCP server.

1046
00:45:27,000 --> 00:45:28,230
This is a decorator

1047
00:45:28,230 --> 00:45:31,650
that essentially takes
the function signature

1048
00:45:31,650 --> 00:45:35,160
as well as the parameters that
are passed in the invocation,

1049
00:45:35,160 --> 00:45:37,140
concatenates them together,

1050
00:45:37,140 --> 00:45:42,140
and then creates a hashing
key utilizing SHA-256.

1051
00:45:42,750 --> 00:45:44,850
Once we have this caching key,

1052
00:45:44,850 --> 00:45:49,500
we can then make a look up
within AgentCore memory.

1053
00:45:49,500 --> 00:45:51,540
So I wanted to touch in on this

1054
00:45:51,540 --> 00:45:54,300
because this is an important
piece of information.

1055
00:45:54,300 --> 00:45:58,830
Utilizing the AgentCore Bedrock
SDK for AgentCore memory,

1056
00:45:58,830 --> 00:46:01,500
it exposes a high level client.

1057
00:46:01,500 --> 00:46:04,890
This high level client has a
list of events function on it.

1058
00:46:04,890 --> 00:46:07,140
However, while a high level client

1059
00:46:07,140 --> 00:46:08,910
does not have the capability

1060
00:46:08,910 --> 00:46:12,360
to filter based off of event metadata.

1061
00:46:12,360 --> 00:46:15,630
However the low level client does.

1062
00:46:15,630 --> 00:46:18,510
And you can access the
low level client directly

1063
00:46:18,510 --> 00:46:21,660
utilizing the code that
I have on the bottom.

1064
00:46:21,660 --> 00:46:25,710
This code will invoke the GMDP
client list events function,

1065
00:46:25,710 --> 00:46:28,140
which is identical with
additional functionality

1066
00:46:28,140 --> 00:46:31,200
to support this metadata filtering option.

1067
00:46:31,200 --> 00:46:35,820
On the top, you can see how
we utilize the metadata filter

1068
00:46:35,820 --> 00:46:38,880
and construct that query on event metadata

1069
00:46:38,880 --> 00:46:41,970
only if the cache key matches.

1070
00:46:41,970 --> 00:46:44,640
This allows for us to achieve our goal

1071
00:46:44,640 --> 00:46:48,150
of utilizing AgentCore
memory as a response cache.

1072
00:46:48,150 --> 00:46:49,920
It's also worth pointing out,

1073
00:46:49,920 --> 00:46:52,830
in order for AgentCore memory to be shared

1074
00:46:52,830 --> 00:46:57,830
across different sessions
of the actual MCP server,

1075
00:46:58,290 --> 00:47:01,650
it is important to note that
you have to configure a couple

1076
00:47:01,650 --> 00:47:03,600
of key pieces of information.

1077
00:47:03,600 --> 00:47:07,200
I believe it's the actor
ID and it's the session ID

1078
00:47:07,200 --> 00:47:08,520
or the agent ID.

1079
00:47:08,520 --> 00:47:10,443
I can provide that afterwards.

1080
00:47:11,580 --> 00:47:13,650
Anyways, once you have that,

1081
00:47:13,650 --> 00:47:16,500
you statically code
those lookup variables,

1082
00:47:16,500 --> 00:47:21,330
then memory can actually
act as a shared cache

1083
00:47:21,330 --> 00:47:22,893
across any agents.

1084
00:47:24,720 --> 00:47:27,000
And to walk away with
some of the key findings

1085
00:47:27,000 --> 00:47:30,780
that we've had from version
two of our product APIs

1086
00:47:30,780 --> 00:47:33,420
is AgentCore services are great.

1087
00:47:33,420 --> 00:47:36,450
They're going to enable us
to build an agentic platform

1088
00:47:36,450 --> 00:47:39,150
that doesn't bring aboard all

1089
00:47:39,150 --> 00:47:41,640
of the infrastructure
overhead complexities

1090
00:47:41,640 --> 00:47:44,913
that we were anticipating
pivoting into an agentic future.

1091
00:47:45,870 --> 00:47:48,000
And also AgentCore,

1092
00:47:48,000 --> 00:47:51,240
utilizing the combination of agents MCP

1093
00:47:51,240 --> 00:47:53,910
will allow us to avoid
the data stillness issues

1094
00:47:53,910 --> 00:47:56,280
that we have today in version one.

1095
00:47:56,280 --> 00:48:00,153
And that we are targeting
our launch in Q1 of 2026.

1096
00:48:02,160 --> 00:48:04,593
And thank you everybody for attending.

