# AWS re:Invent 2025 分会场总结：丰田汽车的生成式AI与智能体平台实践

## 会议概述

本次分会场由AWS全球解决方案架构师Brian Landis主持，联合丰田北美汽车公司(Toyota Motor North America, TMA)和丰田互联北美公司(Toyota Connected North America)的两位Stephen（Stephen Ellis和Stephen Short）共同呈现。会议重点探讨了丰田汽车如何在经销商场景中部署生成式AI用例和智能体平台，展示了企业级AI实施的完整路径。

丰田汽车与AWS已经合作超过七年半时间，从最初非常小的云足迹发展到如今在全球范围内（包括北美、日本以及NASCAR赛车团队）广泛应用AWS服务。本次分享的核心案例是一个面向经销商的产品信息智能助手系统，该系统已部署到所有丰田经销商，每月处理超过7000次交互。丰田采用了"构建-配置-购买"的三阶段策略，从自建原型开始，逐步过渡到配置化产品，最终采购成熟的SaaS解决方案，确保在快速变化的AI领域保持敏捷性。

会议展示了从RAG（检索增强生成）实现的V1版本到基于Amazon Bedrock Agent Core的V2智能体平台的演进路径，强调了平台工程在企业级AI部署中的关键作用，以及如何通过内部开发平台(IDP)实现智能体的规模化部署。

## 详细时间线与关键要点

[00:00-02:30] 开场与演讲者介绍
- Brian Landis介绍自己作为AWS全球解决方案架构师，已支持丰田约七年半时间
- 说明本次演讲的独特性：同时有两个丰田实体（TMA和Toyota Connected）登台
- 感谢与会者参加，承认re:Invent会场导航的困难

[02:30-05:00] 演讲流程概览
- Brian负责100级别的高层次介绍和AWS-丰田合作故事
- Stephen Ellis将介绍TMA的企业级生成式AI方法
- Stephen Short将进行技术深度讲解

[05:00-08:30] AWS生成式AI技术栈介绍
- 基础设施层：多种GPU（P4、P5等）和SageMaker
- 中间层：Amazon Bedrock提供大规模LLM服务
- 上层：Nova、Agents以及开源框架Strands
- 强调丰田正在以各种形式使用整个技术栈

[08:30-11:00] 从聊天助手到智能体的演进
- ChatGPT三年前推出，聊天助手曾是主流
- 当前趋势：生成式AI正在企业各业务线中以智能体形式部署
- 引出Agent Core作为规模化部署智能体的解决方案

[11:00-14:30] Amazon Bedrock Agent Core详解
- 提供可组合的基础设施单元，避免花费数月编写身份脚本或配置可观测性
- 核心组件：Agent Core Runtime（隔离VM环境）
- 框架无关和LLM无关：支持Strands、LlamaIndex、LangGraph、CrewAI
- Agent Core Gateway用于路由和管理

[14:30-17:00] Agent Core的关键能力
- 开箱即用工具：Agent Core Browser和Code Interpreter
- 身份管理：解决智能体身份认证的复杂挑战
- 内存管理：处理上下文窗口问题
- 可观测性层：监控智能体行为和业务价值

[17:00-20:00] 智能体在汽车制造业的广泛应用
- 软件定义车辆(Software-Defined Vehicle)
- 车载助手（部署在车机系统中）
- 智能制造和质量控制
- 产品工程和CAD设计加速
- 本次重点：数字化客户体验

[20:00-24:00] 平台工程是关键
- 平台工程作为企业级AI部署的核心方法论
- 一个集中化平台实现DevOps规模化
- 丰田拥有4-5个平台（根据组织结构）
- 服务对象：开发者、数据科学家和业务用户
- 可部署到VPC或企业数据中心

[24:00-27:30] 通过IDP实现智能体规模化部署
- 将Agent Core、MCP服务器和Strands集成到内部开发平台
- 提供自助服务模板，让各部门（法务、HR等）都能部署智能体
- 确保安全团队的合规要求和防护栏
- 参考案例：Cisco（周一演讲）、Spotify

[27:30-32:00] AWS与丰田的合作故事
- Brian于2018年加入丰田项目，当时云足迹非常小
- 团队每天都在支持丰田的移动出行转型
- 覆盖范围：北美、日本丰田总部、Toyota Connected、NASCAR赛车队
- NASCAR团队使用SageMaker预测比赛结果
- 强调客户应该推动AWS团队提供最佳服务
- 丰田每天都在挑战AWS服务极限，共同发现新工作负载类型
- 约47个用例正在进行中

[32:00-36:00] Stephen Ellis介绍TMA企业AI团队
- 企业AI团队作为生成式AI卓越中心成立
- 独特之处：几乎整个团队都是工程师
- 两大职能：构建AI加速器集成到现有平台；研究新用例创建"AI队友"
- 丰田政策：将员工置于所有工作的中心，AI用于增强而非替代

[36:00-40:00] 产品信息智能助手的业务背景
- 目标：大规模提供产品信息
- 服务对象：品牌互动中心的客服、网站终端用户、经销商
- 避免为每个用例创建独立定制管道
- 已部署到所有丰田经销商，每月7000+次交互

[40:00-44:30] TMA的组织结构与工作流程
- "对角线"组织结构（非传统横向或纵向）
- 三个阶段：探索（全新用例）→ 实验与教育（与IT团队合作）→ 业务常规化
- 案例：合同分析项目处理30万份合同，从每年3万份提升到全量处理
- 每用户节省15-17小时，发现劳动力成本增长和过期条款遗漏问题

[44:30-48:00] 用例分类与民主化策略
- 三大类用例：数据分析、内容生成、内容整合分发
- 快速上市是唯一关键指标（AI领域每3个月就有重大变化）
- 强调"没有完善版本"的理念，先发布再根据学习改进
- 制造业文化挑战：习惯于完美规划后再执行

[48:00-52:00] 变更管理与合规
- 与业务单元、法务、网络安全团队合作
- 确保负责任地使用生成式AI
- 防止非丰田观点渗入产品
- 维护"丰田之道"(Toyota's Way)

[52:00-56:30] 构建-配置-购买策略
- 第一阶段：从零开始构建（ChatGPT API刚推出时）
- 第二阶段：定义需求后寻找可配置产品
- 第三阶段：当功能成熟后购买SaaS解决方案
- 原因：丰田是汽车制造商，不是UI/UX或软件开发公司
- 避免重复造轮子，专注核心业务

[56:30-60:00] AI/ML治理流程
- 业务提交想法："我想用生成式AI做X"
- 产品管理和工程师参与塑造提案
- 提交到AI和ML治理委员会评估
- 评估解决方案/供应商/技术的合规性
- 必要时制定新标准

[60:00-64:00] 从原型到生产的路径
- 构建原型并制定生产化计划
- 支持运营化（某些团队已有完整技术栈）
- 验证解决方案后移交，持续提供新技术支持

[64:00-68:30] 企业级智能体SaaS统一策略
- 基于AWS生成式AI技术栈指导决策
- 现有AI/ML投资继续由数据科学办公室维护
- 工具通过业务规则和工作流向上流动
- 编排层管理规模化（单个成员、小团队或整个组织）

[68:30-72:00] 互操作性锚点
- MCP服务器、OpenAPI协议、Strands等框架
- 为各团队构建特定用例的智能体和机器人
- 共享通用上下文，确保跨组织可共享性
- 保持结果精确性，快速应对模型变化和漂移

[72:00-75:30] 集成到现有平台的重要性
- 将AI能力注入现有平台，用户在熟悉环境中使用
- 避免重新学习全新UX流程
- 技术快速变化（每3个月一次），后台升级比重新设计产品更容易

[75:30-80:00] 经销商痛点分析
- 传统场景：客户通过YouTube等渠道深度研究车辆
- 客户比销售人员更了解产品细节（如Supra MarkV与新款对比）
- 销售人员现场用Google搜索回答客户问题
- 解决方案：整合制造、销售、营销的产品数据

[80:00-83:30] V1解决方案架构
- RAG实现 + 治理规则 + 法务品牌声音指导
- 部署到所有丰田经销商
- 每月7000+次交互
- 支持销售对话和产品研究
- Brian在经销商现场验证产品使用情况

[83:30-87:00] Stephen Short介绍与Toyota Connected背景
- Stephen Short是Toyota Connected的高级工程师和项目技术负责人
- Toyota Connected是独立的丰田公司，作为软件开发和创新中心
- 将介绍V1的RAG实现和V2的Agent Core智能体平台

[87:00-91:00] 系统业务能力
- 自然语言查询学习丰田车辆信息
- 信息类型：车辆规格、价格详情、配置选项、配件选项
- 定制RAG解决方案满足业务需求
- 三大关键能力：集成丰田官方数据源、提供带引用的准确回答、支持2023-2026年所有北美车型

[91:00-95:00] 跨团队协作与法务要求
- 与企业AI、法务、网络安全团队合作
- 关键法务要求：所有回答必须包含上下文相关的免责声明
- 原始数据包含免责声明代码（需解析和映射）
- 必须显示未经修改的法律免责声明文本
- 其他要求：燃油经济性措辞、丰田安全感知功能描述

[95:00-100:00] V1架构：前端与认证
- 前端请求路由到企业AI账户
- Route 53 + WAF
- Lambda@Edge认证使用Entra ID
- 授权后路由到ECS部署的"意图路由器"

[100:00-104:00] 意图路由器与安全防护
- 识别用户询问的车辆型号
- 先经过Prompt Guard（网络安全团队自建）
- 防止恶意活动如提示注入攻击
- 使用外部LLM进行车辆识别

[104:00-108:00] 会话管理
- 创建WebSocket连接
- 使用DynamoDB初始化和跟踪对话历史
- 请求转发到Toyota Connected主账户
- 经过Cloudflare（带WAF）到达API Gateway

[108:00-112:00] Toyota Connected共享服务账户
- 由云工程团队维护和支持
- 帮助扩展解决方案以满足流量需求
- RAG应用代码运行在EKS集群中
- 使用DataDog作为可观测性平台，转发所有日志

[112:00-116:30] RAG推理流程
- 调用数据服务账户
- Amazon SageMaker生成嵌入向量
- 不仅对最新查询，还对前5轮对话生成嵌入
- 使用加权平均算法，优先考虑最近对话
- 保持在上下文窗口内

[116:30-120:00] 向量搜索与推理
- 对OpenSearch Serverless中的向量数据库执行语义搜索
- 每个车辆检索30个文档作为主要真实来源
- 使用Amazon Bedrock（Anthropic模型）驱动推理
- 结合系统提示和检索数据生成答案
- 对流式输出进行后处理

[120:00-124:00] 日志与合规
- 推理完成后推送消息到SQS
- Lambda提取日志并导出到MongoDB
- 满足合规报告要求
- 缓冲输出流并通过webhook回传到TMA

[124:00-127:00] 响应返回
- 添加到DynamoDB对话历史
- 流式传输回前端客户端
- 关键点：从Toyota Connected角度，RAG应用完全无状态
- 所有对话管理由企业AI账户处理

[127:00-131:30] 数据处理挑战与解决方案
- 原始JSON数据需要转换为可用格式
- 方案：为JSON对象生成自然语言摘要
- 示例：单个JSON块代表车辆的一个特性
- 包含配置代码、MSRP信息、描述、标题等字段

[131:30-135:00] 自然语言翻译
- 使用Bedrock生成对象的自然语言翻译
- 用于执行语义搜索
- 除处理字段外，还包含原始数据
- 原始数据对引用工作流至关重要

[135:00-140:00] ETL管道：提取阶段
- Toyota Connected数据账户使用AWS Step Functions编排
- 一系列Glue脚本执行提取和转换
- 提取脚本：从Toyota API服务器拉取所有支持车辆数据
- 数据推送到S3

[140:00-145:00] ETL管道：转换阶段
- 管道中最重的部分
- 并行化处理最多30辆车
- 步骤1：分块JSON数据
- 步骤2：使用Amazon Bedrock生成自然语言摘要
- 步骤3：数据质量检查

[145:00-149:00] 数据质量保证
- 由于LLM输出的非确定性，必须确保摘要准确性
- 验证关键信息：价格详情、配置可用性
- 另一个脚本生成自然语言摘要的嵌入向量
- 与原始数据绑定并发布到S3

[149:00-153:30] ETL管道：加载阶段
- 发布事件到Amazon EventBridge
- 触发各环境（dev、stage、prod）的Lambda
- Lambda从AWS Systems Manager获取参数
- 配置OpenSearch摄取管道

[153:30-157:00] OpenSearch索引创建
- 基于ETL管道启动时间戳创建新索引
- 创建OpenSearch摄取管道
- 配置从数据账户S3存储桶读取转换步骤输出
- 将输出摄取到新创建的索引
- 完成后停止管道

[157:00-162:00] 评估引擎
- 由于LLM调用的非确定性，需要确保数据质量
- 使用GitLab runners编排一系列脚本
- TMA提供一个车辆的黄金数据集
- 问答对已由TMA团队验证
- 用于生成合成测试集

[162:00-166:00] 合成测试与评估
- 可为任何车辆生成合成测试集
- 对已部署的RAG应用进行调用
- 获取评估输出（演讲在此处被截断）

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


注： 由于字幕在评估引擎部分被截断，完整的V2智能体平台架构和Agent Core实现细节未能在提供的字幕中呈现。