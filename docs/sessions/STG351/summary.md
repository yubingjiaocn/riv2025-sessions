# AWS re:Invent 2025 - STG351: S3 数据湖现代化经验总结

## 会议概述

本次会议由 S3 团队首席工程师 Carl Summers 和高级专家解决方案架构师 Ron 共同主讲,深入探讨了 Amazon S3 如何处理和分析其 exabyte 级别的内部运营日志数据。

S3 每小时产生的内部日志数据如果打印出来,其高度将超过珠穆朗玛峰。这些日志不仅仅是数据记录,每一条日志都代表着客户与 S3 的交互——家庭照片上传、医疗记录存储、机器学习模型训练或气候研究数据共享。面对如此海量的数据,S3 团队面临的核心挑战不是生成或存储数据,而是如何让这些数据变得有用。

团队发现工程师们花费大量时间寻找数据而非分析数据,许多业务问题因数据访问困难而无法得到解答。为此,S3 团队启动了一项为期两年的数据湖现代化项目,从传统的文本日志查询系统迁移到基于 Apache Iceberg 的现代化分析平台。该项目的核心目标是将查询响应时间从小时级降低到分钟级,让数据发现和访问变得简单直观,并支持跨服务日志关联分析和任意数据集连接。

通过采用 SQL 查询接口、实现谓词和投影下推优化、转换为列式存储格式(Parquet)、智能分区和排序策略,以及利用 Apache Iceberg 的元数据管理能力,S3 团队成功构建了一个能够在 exabyte 规模下高效运行的现代化数据分析平台,将原本需要扫描 PB 级数据的查询优化到只需扫描 TB 甚至 GB 级别的数据。

## 详细时间线与关键要点

### 开场与背景介绍 (00:00 - 05:30)

00:00 - 00:30 - 会议开场
- 主讲人介绍：Carl Summers(S3 首席工程师)和 Ron(高级专家解决方案架构师)
- 会议主题：STG351 - S3 exabyte 规模数据湖现代化的经验教训

00:30 - 02:00 - S3 日志规模的震撼展示
- S3 一小时的内部日志数据打印出来比珠穆朗玛峰还高
- 这些日志代表着数百万客户的真实业务需求和信任
- 日志中蕴含着关键问题的答案：请求失败原因、延迟峰值、功能使用情况等

02:00 - 03:30 - 核心挑战的三个问题
- 工程师是否花更多时间寻找数据而非分析数据?
- 通过更好的日志洞察,能多快解决问题?
- 有多少业务问题因数据难以访问而未被提出?

### Carl 的个人故事：理解"不太可能"的真正含义 (03:30 - 08:00)

03:30 - 05:00 - 2013 年的新人经历
- Carl 作为新工程师开发第一个功能时的故事
- 需要调用其他服务获取存储桶配置信息
- 遇到一个"看起来不太可能发生"的异常情况

05:00 - 06:30 - 关键的顿悟时刻
- Carl 认为某个异常"十亿分之一的概率"不会发生
- 资深工程师指出：在 S3 的请求量下,这意味着每 3 分钟发生一次
- 核心教训：**在 S3 规模下,极不可能的事情会极其频繁地发生**

06:30 - 08:00 - 日志和指标的重要性
- Carl 添加了大量日志和指标来捕获上下文
- 每一行业务逻辑代码配有一到两行日志代码
- 捕获配置获取、缓存命中、重试次数、错误详情等信息

### S3 日志系统架构 (08:00 - 15:00)

08:00 - 10:00 - 日志格式和结构
- S3 使用多行键值对格式的结构化日志
- 平均每个请求约 5KB 的日志数据
- 包含数万个唯一字段元素
- 强调尊重历史系统：虽然格式不是最现代的,但简单、可读、可扩展且运行了近 20 年

10:00 - 12:00 - 日志采集流程
- 服务将日志写入磁盘
- 按小时(或更频繁)压缩并上传到 S3
- 通过中央服务索引时间范围和源服务
- S3 由数百个微服务组成,由数百名工程师运营

12:00 - 15:00 - 日志规模的数学计算
- 2013 年：S3 每秒约 100 万次请求
- 每个日志条目平均 5KB
- 计算结果：当时每小时产生 TB 级日志(压缩前)
- 今天：同一服务每小时产生接近 PB 级日志
- 总存储量：exabyte 级别

### 传统查询工具的局限性 (15:00 - 22:00)

15:00 - 17:00 - 11 年前的解决方案
- 让实习生开发了一个查询工具
- 设计目标：在数十亿条日志中找到关键的那一条
- 接口简单：字符串搜索、正则表达式、JavaScript 代码执行

17:00 - 19:30 - JavaScript 查询的滥用
- 工程师用 JavaScript 解决各种复杂查询
- 示例：查找命中主缓存但仍超过 50ms 的请求
- 产品经理让工程师编写 JavaScript 来分析功能使用情况
- 积累了数百页 wiki 文档和笔记

19:30 - 22:00 - 系统的根本问题
- 工具擅长找单条日志,但不擅长聚合分析
- 趋势分析需要后处理 TB 甚至 PB 级的查询结果
- 虽然有指标和追踪工具,但原始日志提供的洞察无可替代
- 日志是理解客户和系统当前及历史行为的唯一途径

### 现代化目标 (22:00 - 25:00)

22:00 - 23:30 - 核心需求
- 保持基础用例：在海量日志中找到单条记录
- 客户支持工程师能轻松使用
- 支持跨微服务日志关联
- 能够连接任意数据集(如硬件信息)

23:30 - 25:00 - 可访问性目标
- 产品经理和业务负责人可以自主使用
- 用于功能提案、路线图和规划
- 将工程师时间还给构建和运营服务

### 面临的挑战 (25:00 - 28:00)

25:00 - 26:00 - 规模挑战
- 规模是相对的：12 年前 TB 级就很困难
- 问题随着规模增长而加剧

26:00 - 27:00 - 遗产系统挑战
- 这些是"传承系统"而非"遗留系统"
- 多年来一直在交付价值
- 需要尽可能少地中断现有系统

27:00 - 28:00 - 基础服务要求
- S3 是基础服务,其运营工具必须在其他服务故障时仍能工作
- 向后兼容性：现有查询必须在新系统中继续工作

### Ron 的现代化方案 (28:00 - 45:00)

28:00 - 30:00 - 思维转变
- 从"提出正确问题"转向"尽快获得答案"
- 从被动故障排查转向主动智能分析
- 分析用户工作流程,识别优化机会

30:00 - 32:00 - 工作流程的三个阶段
1. 探索和学习阶段：发现数据、制定查询
2. 数据收集阶段：等待或主动收集数据
3. 后处理阶段：聚合和格式化结果

32:00 - 35:00 - 数据可发现性
- 通过适当的目录使数据可发现
- 关键洞察：目录中的每个条目都必须有用
- 平衡摩擦：确保数据集足够有价值,值得维护
- 避免成为数据的集中所有者,而是作为工具提供者和中介

35:00 - 38:00 - 传统查询流程的问题
- 示例：按存储桶统计生命周期策略请求
- 传统流程：下载日志 → 提取数据 → 计数排序 → 保存 → 重复
- 效率极低,需要大量手动工作

38:00 - 40:00 - SQL 查询接口
- 使用 SQL 简化查询表达
- 将复杂的多步骤流程简化为单个 SQL 语句
- 将查询编目化,便于发现和重用
- 通过代码变更技术维护查询

40:00 - 42:00 - 查询优化：下推技术
- 谓词下推(Predicate Pushdown)：扫描时过滤,不匹配的行不物化
- 投影下推(Projection Pushdown)：只提取查询需要的字段
- 显著减少处理的行数和提取的数据量

42:00 - 45:00 - 优化的局限性
- 查询引擎优化有上限
- 文本日志格式有固有限制
- 需要转换底层数据结构本身

### Apache Iceberg 数据平台 (45:00 - 60:00)

45:00 - 47:00 - 为什么选择 Iceberg
- 需要支持列式存储、高效分区、模式演化、事务一致性
- Iceberg 在 S3 规模下已被验证有效
- 提供事务更新、时间旅行、模式和分区演化能力
- 为未来 15-20 年构建新基础

47:00 - 50:00 - Iceberg 表结构解析
- 数据文件层：Parquet、ORC、Avro 等格式
- Manifest 文件：指向数据文件的指针,包含统计信息和列信息
- Manifest List：聚合多个 manifest 文件,创建表视图
- 元数据文件：包含模式、版本信息,管理快照
- 目录：将表名映射到元数据文件

50:00 - 52:00 - Iceberg 的本质
- 不是运行的服务器,而是规范和库的集合
- 定义数据文件和元数据文件的布局结构
- 提供类似数据库的语义、模式管理、一致性和事务性

52:00 - 55:00 - 文件格式选择
- Avro(行式)适合日志收集
- Parquet(列式)适合分析查询
- 查询通常只涉及数千列中的 10 个左右
- 选择 Parquet 用于分析层
- 需要智能分区和摄取来使其高效工作

55:00 - 58:00 - 分区策略的重要性
- 分区是区分扫描 PB 级与 TB/GB 级数据的关键
- Iceberg 允许在不重写数据的情况下演化分区策略
- 两级剪枝：
  - Manifest 文件剪枝：消除整个数据集
  - 列统计：跳过分区内不相关的文件
- 可将扫描数据量减少几个数量级

58:00 - 60:00 - 排序的作用
- 示例：查找请求 ID 7
- 未排序：需要扫描所有文件(每个文件范围 0-15)
- 已排序：只需扫描一个文件(每个文件有不同范围)
- 排序可再次减少数量级的数据扫描
- 通过分析数千个查询确定正确的排序键

### 模式设计 (60:00 - 结束)

60:00 - 62:00 - 日志模式的挑战
- 日志混乱、可变、不断变化
- 需要平衡结构性和灵活性
- 已编目的查询需要继续工作
- 同时为未知情况保留灵活性

62:00 - 64:00 - 设计目标
- 分钟级而非小时级的查询响应时间
- 易于理解和维护(复杂性会扼杀采用)
- 在 exabyte 规模下具有成本效益

64:00 - 结束 - 三层模式架构
1. 身份层：扁平简单,包含最常见的过滤字段(请求 ID、时间戳、服务信息、用户账户),几乎出现在每个 WHERE 或 JOIN 子句中,是自然的分区候选和排序键
2. 指标层：嵌套结构,组织数千个指标(性能数据、容量统计、资源利用率),逻辑分组
3. 上下文层：其他所有内容(调试信息、服务上下文等),不适合指标或身份层的任何内容

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


## 核心要点总结

- **规模思维**：在 S3 规模下,"十亿分之一"的事件每几分钟就会发生一次
- **尊重传承**：不要为了现代化而抛弃运行良好的系统
- **用户为中心**：分析 7 年的历史查询,确保新系统更易用
- **渐进优化**：从查询引擎优化开始,最终转向数据结构转换
- **Apache Iceberg**：为 exabyte 规模的分析提供现代化基础
- **智能分区和排序**：可将数据扫描量减少多个数量级
- **三层模式**：身份、指标、上下文的清晰分离使系统易于理解和使用