# AWS re:Invent 2025 会议总结：解决AI"自信地犯错"的问题

## 会议概述

本次演讲聚焦于AI在数据分析领域面临的核心挑战——"自信地犯错"（confidently wrong）问题。演讲者指出,尽管AI技术已经普及并拥有近十亿用户,但MIT的一份报告显示95%的AI试点项目失败。问题的根源在于AI系统无法准确表达自己的不确定性,导致用户无法信任其输出结果。即使AI能够连接数据库、执行SQL查询和数据分析,但由于缺乏可信度,最终无法真正应用于业务决策场景。

演讲者来自PromQL团队,他们提出了一个创新的解决方案：让AI主动承认自己不知道的内容,从而建立用户信任。这种方法的核心理念是"只有当AI承认无知时,才能被教导和改进"。通过构建一个包含知识维基、专家协作和持续学习的产品循环,PromQL实现了让非技术用户也能安全使用AI进行数据分析的目标。该系统不仅能处理简单查询,还能应对包含10万张表和1万个指标的复杂企业数据环境。

演讲强调,与其追求100%的初始准确率,不如建立一个透明的、可持续改进的AI系统。当AI能够明确标识已知和未知的概念时,即使初始准确率只有50%,用户仍然可以信任并使用该系统,因为他们知道哪些答案是可靠的,哪些需要进一步验证。

## 详细时间线

0:00 - 2:30 | 问题引入：AI试点项目的高失败率
- 提及MIT关于95%的AI试点项目失败的报告
- 指出核心问题：AI"自信地犯错"导致用户无法信任系统
- AI技术已存在2-3年,用户数接近10亿,但实际应用仍面临挑战

2:30 - 4:45 | 业务场景中的信任危机
- 描述企业场景：技术人员向业务人员推荐使用AI做决策
- 业务决策包括人员配置、定价策略等关键领域
- 问题：AI连接数据后虽然能工作,但业务用户无法信任其输出
- 即使人类也难以回答复杂问题,但人类至少会承认不知道

4:45 - 6:30 | 核心观点：自信与错误的矛盾
- AI始终表现得极度自信,用户无法判断这种自信是否可靠
- "自信地犯错"严重阻碍了AI的实际采用
- 从有趣的试点项目变成"无法真正信任使用"的工具
- 提出问题：这是模型能力问题还是可以通过其他方式解决？

6:30 - 8:15 | 理论基础：Ilya Sutskever的观点
- 引用Dwarkesh Patel播客中的内容（包括Andrej Karpathy和Ilya Sutskever的访谈）
- 核心引用：人类的价值不在于拥有500点智商或赢得IMO金牌
- 人类的优势在于持续吸收情境知识、从失败中学习并改进的能力
- LLM在原始智力上已经超越人类,但在可信度上仍不如人类

8:15 - 9:30 | 关键洞察：教学的前提
- 强调持续学习和吸收部落知识（tribal knowledge）的重要性
- 提出核心论点："只有当AI承认不知道时,才能教导它"
- 即使AI擅长持续学习,如果不承认错误就无法被教导
- 这是AI产品中缺失的核心产品循环

9:30 - 11:45 | PromQL产品介绍
- 自我定位：又一个"与数据对话"的产品
- 传统流程：业务用户需要与分析师、数据科学家、工程师沟通,通常2周后才能得到答案
- AI的承诺：AI替代中间环节,直接完成数据工程、分析和数据科学工作
- 现状：技术上已经可行（如Claude Code可以编写管道、SQL和数据科学程序）

11:45 - 13:00 | 现有方案的局限性
- 问题：无法让最终用户以可信的方式使用AI
- 现有的"与数据对话"产品本质上都是"文本转SQL"工具
- 需要技术人员验证SQL,非技术人员无法独立使用
- PromQL的运营模式：让AI承认不知道,让专家教导,从而持续改进

13:00 - 14:30 | 核心产品循环介绍
- 三个关键步骤：
  1. 告诉用户AI知道什么和不知道什么
  2. 当AI不知道时,允许用户修正
  3. AI从修正中学习
- 即使初始准确率只有50%,用户仍可信任系统

14:30 - 17:00 | 演示1：基础查询场景
- 示例问题："昨天按地区划分的毛利率是多少？"
- 系统生成解决计划,用蓝色链接标注已知概念
- 点击链接显示支持AI的知识维基
- 维基条目包含：概念定义、计算方法、季度目标、预期值范围等
- 多个概念相互关联,形成知识网络

17:00 - 19:30 | 演示2：处理未知概念
- 示例问题："上一财年的毛利率是多少？"
- AI识别"FY"（财年）为新概念,标记为红色链接
- AI做出假设并告知用户该假设
- 用户查看答案但不确定财年的具体定义
- 真实场景：业务用户自己也可能不清楚财年的确切周期

19:30 - 21:45 | 演示3：专家协作机制
- 用户邀请专家加入对话以澄清"财年"概念
- 真实人类专家加入对话并提供定义
- AI接收专家输入,填补知识空白
- 系统重新规划并给出更新的答案
- 用户满意因为通过协作获得了准确答案

21:45 - 23:30 | 知识捕获与学习循环
- 整个对话捕获了大量部落知识
- 对话成为学习的种子
- 代理循环自动帮助创建和更新维基条目
- 维基类似Wikipedia,AI和人类可以协作维护
- 知识库随时间持续改进

23:30 - 25:15 | 演示4：复杂财务场景
- 示例："True North收入Q3数据并预测Q4"
- 系统读取维基条目,包含：数据表位置、Google Drive中的PDF文件、需要提取和调整的内容
- 维基条目相互引用（如"调整"概念链接到其定义）
- 预测功能的维基包含：数据科学方法、异常值处理等

25:15 - 27:00 | 知识的渐进式积累
- 维基条目初始时较为稀疏,随使用逐渐丰富
- 示例：预测功能最初只有基本模型,后来用户发现黑色星期五是异常值
- 数据科学专家加入并教导系统考虑该因素
- 这种积累支持创建准确的执行计划

27:00 - 29:00 | 技术细节的不确定性处理
- 不确定性不仅存在于语义和业务概念,也存在于技术细节
- 系统会标注预测方法的假设（如"假设无退款"）
- 用户可以讨论这些假设是否重要
- 专家可以确认假设的有效性或提出修正
- 通过教导和修正,学习循环持续改进

29:00 - 30:30 | 双层界面设计
- 非技术用户：使用维基界面
- 技术专家：使用置信度分析/置信度代码
- 用户关注维基内容,专家关注置信度评分
- 这种设计创建了有效的反馈循环

30:30 - 32:45 | 核心理念：拥抱失败
- 当前使用的AI注定会失败
- 失败原因：
  1. 不可能将100%的部落知识预先嵌入AI
  2. 对于有规模的企业,预先嵌入所有知识根本不可能
  3. 缺乏让用户信任AI的系统
- 解决方案：承认AI永远会不准确,关键是告知不准确性并从中学习

32:45 - 34:30 | 技术优势：规模化能力
- 建立信任循环后,可以专注解决有趣的技术问题
- 对比：Databricks Genie和Snowflake Cortex限制在20-25张表
- 质疑：哪个企业只有25张表？这不是真实场景
- PromQL的目标：支持10万张表、1万个指标
- 只有解决了产品循环问题,才能处理这些规模化挑战

34:30 - 35:45 | 成果与应用场景
- 自2025年初以来实现大规模扩展
- 应用于需要高速决策的多个有趣用例
- 邀请参观展位1733号
- 提供技术团队和销售团队支持
- 欢迎交流学习和探讨合作

35:45 - 36:00 | 结束致谢
- 感谢听众参与
- 再次强调展位位置和交流机会