# AWS re:Invent 2025 - 使用 LaunchDarkly AI Configs 进行实时幻觉检测

## 会议概述

本次会议由 LaunchDarkly 的高级开发者教育者 Scarlett Attensil 和产品负责人 Mark Pollock 主讲，重点探讨了生成式 AI 系统在生产环境中面临的最大挑战——幻觉问题，以及如何通过 LaunchDarkly AI Configs 构建能够自我修复的 AI 系统。

演讲者强调，幻觉是阻碍 AI 产品从预生产环境进入生产环境的首要问题。然而，幻觉本质上是大语言模型（LLM）的固有特性，是其处理非结构化数据和应对随机性的核心能力。因此，解决方案不是消除幻觉，而是构建能够容忍准确性波动、自动从错误中恢复的系统。会议通过医疗保险聊天机器人的实际案例，展示了如何利用特性标志（feature flags）技术实现 AI 配置的实时控制、A/B 测试实验以及自动故障恢复。

演讲者还特别提到了模型漂移问题——斯坦福和加州大学伯克利分校 2023 年的研究显示，GPT-4 在相同提示词下，准确率在 3 个月内从 97.6% 下降到仅 2.4%。这凸显了持续监控 AI 系统的重要性。传统的确定性软件开发原则（可预测、可复现、可追溯）在面对随机性的 AI 系统时失效，需要全新的方法论。

## 详细时间线与关键要点

### **开场介绍 (0:00-2:30)**
- Scarlett Attensil 和 Mark Pollock 介绍 LaunchDarkly AI Configs 产品
- 邀请观众会后交流，讨论产品现状和未来发展

### **幻觉问题的核心挑战 (2:30-5:45)**
- **时间戳 2:30**: Mark 指出幻觉是客户反馈的首要问题，在前五大障碍中占据所有位置
- **时间戳 3:15**: 幻觉导致的成本：金钱损失、工程时间浪费、信心下降、品牌资产受损
- **时间戳 4:00**: 关键观点：无法通过持续强化学习从根本上解决幻觉，因为 LLM 本质上就是在"幻觉"——这是生成式 AI 的本体论特征
- **时间戳 4:45**: 解决方案：构建容错系统，能够自动修复服务中断，防止准确性异常影响客户

### **模型漂移问题 (5:45-7:30)**
- **时间戳 6:00**: Scarlett 介绍斯坦福和 UC Berkeley 2023 年研究
- **时间戳 6:30**: 关键数据：GPT-4 在素数测试中，准确率从 97.6% 降至 2.4%（90 天内，零代码更改）
- **时间戳 7:00**: 结论：持续监控不是可选项，而是生存必需

### **AI 系统的三层失效机制 (7:30-10:00)**
- **时间戳 7:45**: 第一层 - 模型层：提供商（OpenAI、Anthropic）无预警更新导致提示词失效
- **时间戳 8:15**: 第二层 - 知识层：医疗保险示例中，提供商目录每月变化，州法规每季度更新，静态知识库累积风险
- **时间戳 8:45**: 第三层 - 用户层：用户查询模式有机演变，从简单问题（"我的牙科保险是什么？"）到复杂场景（2000 字病史分析）
- **时间戳 9:30**: 解决方案：按节点问责制 + 实时评估器，而非仅依赖滞后的可观测性指标

### **传统软件原则在 AI 中的失效 (10:00-12:30)**
- **时间戳 10:15**: 确定性代码的三大特征：可预测（相同输入=相同输出）、可复现（版本控制）、可追溯（可调试）
- **时间戳 11:00**: AI 系统的三大特征：动态（无法单元测试创造力）、演变（模型行为随时间变化）、不透明（黑盒链接）
- **时间戳 11:45**: 核心论点：我们不再只是发布代码，而是发布统计模型，确定性部署策略对概率系统无效

### **LaunchDarkly AI Configs 解决方案 (12:30-18:00)**
- **时间戳 12:45**: Mark 提出核心挑战：构建实时自优化准确性系统
- **时间戳 13:15**: 三大核心组件：
  1. 实时控制：无需重新部署即可修改 AI 代理组件
  2. 实验：使用统计方法评估不同代理配置
  3. 自我修复：捕获幻觉、回滚到已知良好状态、自动纠正

### **第一个核心论点：AI 组件不是代码 (18:00-22:00)**
- **时间戳 18:30**: Mark 的挑衅性观点：提示词、工具、模型超参数、模型提供商、代理拓扑结构都不应该是代码
- **时间戳 19:00**: 两大理由：
  1. 变更频率和灵活性需求高出数量级
  2. 需要专门的警惕性——这些是被联想机器解释的指令，而非确定性输出
- **时间戳 20:00**: 解决方案：将这些视为配置，使用特性标志流式传输
- **时间戳 20:45**: LaunchDarkly 每天服务近 50 万亿个特性标志

### **实时控制架构 (22:00-25:00)**
- **时间戳 22:30**: 应用程序通过特性标志流式获取 AI 配置，而非硬编码
- **时间戳 23:00**: 优势：无需重新部署即可更改提示词、工具、模型、超参数
- **时间戳 23:45**: 上下文感知：根据用户上下文动态提供不同的代理配置

### **第二个核心论点：AI 代理配置始终是多元的 (25:00-27:30)**
- **时间戳 25:15**: 反对单一配置流的迭代改进方法
- **时间戳 25:45**: 主张：AI 代理是"遗传生物"，应始终包含多个变体进行统计测试
- **时间戳 26:30**: 指标回传：性能数据、LM 评判评估、OpenLM 风格追踪、标准可观测性、自定义业务 KPI

### **医疗保险聊天机器人演示架构 (27:30-31:00)**
- **时间戳 28:00**: 五代理系统 + 两个嵌套评判子代理
- **时间戳 28:30**: 架构：分诊代理 → 专家代理（政策、提供商、索赔）→ 品牌声音代理
- **时间戳 29:15**: 品牌声音代理的作用：反思机会 + 允许非工程团队（PM、PMM）参与调整
- **时间戳 30:00**: 所有 AI 组件通过 LaunchDarkly 特性标志提供，使用 LangGraph 构建

### **实时配置演示 (31:00-35:30)**
- **时间戳 31:30**: 展示 AI Configs 仪表板：分诊代理、三个专家、品牌声音代理、评判器
- **时间戳 32:00**: 品牌声音代理配置：调用 AWS Bedrock Haiku 4.5、超参数、提示词、工具、评判器
- **时间戳 32:45**: 版本控制、基于角色的访问控制、审计日志、审批流程
- **时间戳 33:15**: 演示查询："在旧金山找医生" → 系统返回 Dr. Patricia Rodriguez
- **时间戳 34:00**: 实时修改提示词为"用法语回答所有问题"，无需重新部署
- **时间戳 34:45**: 再次查询，系统立即用法语响应
- **时间戳 35:00**: 评判器反馈：准确性下降，因为上下文不支持法语

### **实验方法论：科学方法应用于 AI (35:30-38:00)**
- **时间戳 35:45**: Scarlett 分享个人经验：系统化提示词实验结果出乎意料，排名垫底
- **时间戳 36:30**: 教训：直觉常常错误，应基于科学方法优化
- **时间戳 37:00**: 流程：假设 → 构建变体 → 针对真实用户流量测试 → 测量业务相关指标
- **时间戳 37:45**: 医疗保险示例：真实用户预约、保险咨询查询

### **模型选择实验演示 (38:00-41:30)**
- **时间戳 38:30**: 政策子代理实验：Sonnet 4 vs Haiku 4.5 vs Llama 4 Maverick
- **时间戳 39:00**: 问题：使用更便宜的模型会牺牲多少准确性？
- **时间戳 39:30**: 结果（2000 次用户曝光后）：Llama 4 有 100% 概率最佳
- **时间戳 40:00**: 关键数据：
  - 准确性提高 2.89%（相比 Sonnet 4）
  - Token 使用减少 24%
  - 响应时间减少 22%
  - 成本降低 24%

### **提示词策略实验演示 (41:30-45:00)**
- **时间戳 41:45**: 四种提示词变体：控制组、系统化、简洁、推理型
- **时间戳 42:15**: AI 建议的系统化提示词（指定输出格式和顺序）
- **时间戳 42:45**: 推理型提示词强制模型展示推理过程
- **时间戳 43:00**: 结果：简洁提示词在 2000 次曝光前达到 100% 最佳概率
- **时间戳 43:30**: 关键数据：
  - 响应时间减少 34%
  - 成本节省 48%
  - 负面反馈率降低 72%（非 7.2%）
- **时间戳 44:15**: 原因分析：更快 + 更准确 = 更少客户投诉

### **成本节省计算 (45:00-46:30)**
- **时间戳 45:15**: 假设每天 50,000 用户
- **时间戳 45:30**: 原始 Sonnet 4 成本：每天 $250
- **时间戳 45:45**: 模型优化节省：$61/天
- **时间戳 46:00**: 提示词优化节省：$91/天
- **时间戳 46:15**: 总节省：$152/天，年度节省超过 $55,000（仅一个子代理）
- **时间戳 46:30**: 建议：在所有代理和评判器上应用此方法

### **实验指标选择建议 (46:30-48:00)**
- **时间戳 46:45**: 根据业务阶段选择指标：成本、客户满意度、曝光度等
- **时间戳 47:15**: 核心原则：发布结果，而非发布观点
- **时间戳 47:45**: 使用指标设置故障回退策略

### **自我修复 AI 系统 (48:00-52:00)**
- **时间戳 48:30**: Mark 讨论评估策略的常见问题
- **时间戳 49:00**: 典型场景：预生产环境大量评估（Phoenix、自建方案、人工标注），但生产环境评估缺失或延迟 24 小时
- **时间戳 49:45**: 问题：24 小时延迟太长，无法及时响应生产问题
- **时间戳 50:15**: LaunchDarkly 方案：预生产和生产环境使用相同的在线评估器，实现持续评估
- **时间戳 50:45**: 实验在生产环境的价值：针对真实客户测试，获取真实信息
- **时间戳 51:30**: 最佳评估标准："它是否为公司赚钱？"——业务结果导向的评估基准

### **总结 (52:00-结束)**
- 演讲强调了从传统软件开发范式转向适应 AI 随机性的新方法论
- LaunchDarkly AI Configs 通过特性标志技术实现了 AI 系统的实时控制、科学实验和自动修复
- 实际案例证明了该方法在提升准确性、降低成本、改善用户体验方面的显著效果