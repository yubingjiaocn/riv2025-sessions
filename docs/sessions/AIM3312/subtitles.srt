1
00:00:00,150 --> 00:00:02,250
- Hello, everyone.

2
00:00:02,250 --> 00:00:04,890
And I welcome you all to our session

3
00:00:04,890 --> 00:00:06,930
on Making Agents Remember

4
00:00:06,930 --> 00:00:10,530
Using Amazon Bedrock AgentCore Memory.

5
00:00:10,530 --> 00:00:12,510
So before we begin our session,

6
00:00:12,510 --> 00:00:13,740
I'm Mani Khanuja,

7
00:00:13,740 --> 00:00:16,680
I'm principal generative AI
specialist solution architect

8
00:00:16,680 --> 00:00:17,970
at AWS.

9
00:00:17,970 --> 00:00:21,390
Very excited to be here
with you today morning.

10
00:00:21,390 --> 00:00:22,620
And before we begin,

11
00:00:22,620 --> 00:00:24,660
can I have a quick show of hands

12
00:00:24,660 --> 00:00:27,720
for people who are aware
of the memory concept

13
00:00:27,720 --> 00:00:29,253
in the agentic AI world?

14
00:00:30,750 --> 00:00:32,160
Okay. Awesome.

15
00:00:32,160 --> 00:00:34,440
So we have many folks who are aware of

16
00:00:34,440 --> 00:00:36,510
and we also have few of the folks

17
00:00:36,510 --> 00:00:39,300
who will be hearing about the agent memory

18
00:00:39,300 --> 00:00:42,510
for the first time and
what role does it play.

19
00:00:42,510 --> 00:00:45,690
And today I also have with me Jay,

20
00:00:45,690 --> 00:00:48,360
who's our product manager,

21
00:00:48,360 --> 00:00:51,840
and Imran, who's from Experian,

22
00:00:51,840 --> 00:00:53,520
you know, sharing the stage with us.

23
00:00:53,520 --> 00:00:57,630
He's the senior VP, head of
engineering from Experian.

24
00:00:57,630 --> 00:00:59,820
And he'll be sharing the journey

25
00:00:59,820 --> 00:01:02,700
and how Experian has been
using AgentCore Memory

26
00:01:02,700 --> 00:01:04,650
for building their applications.

27
00:01:04,650 --> 00:01:06,030
So very excited to be here.

28
00:01:06,030 --> 00:01:08,460
And I hope we all have had your coffee

29
00:01:08,460 --> 00:01:10,290
so that you're all awake.

30
00:01:10,290 --> 00:01:11,253
Is that true?

31
00:01:12,360 --> 00:01:15,240
Okay, awesome. Let's get started then.

32
00:01:15,240 --> 00:01:18,960
So the main thing about the memory

33
00:01:18,960 --> 00:01:23,460
when it comes to agentic AI
applications is providing

34
00:01:23,460 --> 00:01:28,110
the right context to the
agent at the right time.

35
00:01:28,110 --> 00:01:30,690
And that's what we see

36
00:01:30,690 --> 00:01:34,050
the agent applications
without memory lack.

37
00:01:34,050 --> 00:01:36,270
And by the end of this presentation,

38
00:01:36,270 --> 00:01:41,010
I promise that you will understand
and also see a good demo

39
00:01:41,010 --> 00:01:43,470
on how it can make the difference

40
00:01:43,470 --> 00:01:47,280
when you're building the
agentic AI applications.

41
00:01:47,280 --> 00:01:50,370
So let's talk about the context first,

42
00:01:50,370 --> 00:01:54,630
what goes into the context of an agent

43
00:01:54,630 --> 00:01:57,240
and what really this agent is.

44
00:01:57,240 --> 00:01:59,370
So when I think about agent,

45
00:01:59,370 --> 00:02:03,780
it's literally a model that has
access to some of the tools.

46
00:02:03,780 --> 00:02:06,300
It can take actions on your behalf

47
00:02:06,300 --> 00:02:08,790
based on the tools that you provide.

48
00:02:08,790 --> 00:02:12,240
Now those tools could be some data APIs,

49
00:02:12,240 --> 00:02:17,240
real-time APIs that you want
the agent to give access to,

50
00:02:18,030 --> 00:02:21,120
or it can be access to
your knowledge store

51
00:02:21,120 --> 00:02:23,793
where you have your organization data,

52
00:02:24,840 --> 00:02:27,150
or it can be instructions

53
00:02:27,150 --> 00:02:29,490
and system prompt is super important

54
00:02:29,490 --> 00:02:33,090
because system prompt is what
makes the agent understand

55
00:02:33,090 --> 00:02:35,340
what it's supposed to do, right?

56
00:02:35,340 --> 00:02:39,030
So there's so many things
that goes into the context

57
00:02:39,030 --> 00:02:40,650
of an agent.

58
00:02:40,650 --> 00:02:42,690
And that's where we have seen

59
00:02:42,690 --> 00:02:45,840
that memory is often overlooked.

60
00:02:45,840 --> 00:02:48,300
But imagine you are in a party,

61
00:02:48,300 --> 00:02:50,790
you have been talking to few people.

62
00:02:50,790 --> 00:02:55,140
And suddenly after the
conversation is over

63
00:02:55,140 --> 00:02:57,357
and you're like, "Oh, what's your name?"

64
00:02:58,230 --> 00:03:01,500
Right? So we don't want our
agents to be in that situation,

65
00:03:01,500 --> 00:03:05,820
especially when they're
interacting with your users.

66
00:03:05,820 --> 00:03:09,090
You also want to give
a good user experience

67
00:03:09,090 --> 00:03:10,770
or customer experience

68
00:03:10,770 --> 00:03:15,770
in addition to providing
relevant and accurate responses.

69
00:03:16,140 --> 00:03:19,710
And that's where memory plays a big role.

70
00:03:19,710 --> 00:03:23,220
And it literally is, you
know, bridging this gap.

71
00:03:23,220 --> 00:03:24,783
So let's take an example.

72
00:03:26,370 --> 00:03:29,520
So obviously like, for this presentation,

73
00:03:29,520 --> 00:03:32,850
we had to build our presentation, right,

74
00:03:32,850 --> 00:03:34,200
the slide deck.

75
00:03:34,200 --> 00:03:36,150
And then when we were discussing,

76
00:03:36,150 --> 00:03:38,910
we were like, "Okay, why
not take this example

77
00:03:38,910 --> 00:03:43,200
and share how you can build slide decks."

78
00:03:43,200 --> 00:03:48,200
So we build a slide deck agent
that can do a lot of things.

79
00:03:49,410 --> 00:03:53,520
So I started with a very
basic agent with no memory.

80
00:03:53,520 --> 00:03:56,220
It was good. It was able to do the work.

81
00:03:56,220 --> 00:04:00,510
If I provide a big prompt,
I give all the instructions,

82
00:04:00,510 --> 00:04:02,673
it's able to generate the deck.

83
00:04:03,570 --> 00:04:05,490
I have to give some tools,

84
00:04:05,490 --> 00:04:08,580
such as, I love Python.

85
00:04:08,580 --> 00:04:12,900
So I provided some tools like
Python-pptx and all of those.

86
00:04:12,900 --> 00:04:16,083
And it did a good job.
No doubt about that.

87
00:04:16,980 --> 00:04:19,867
But then I noticed, every
time I have to mention,

88
00:04:19,867 --> 00:04:23,220
"Oh, for technical
presentations, use this style."

89
00:04:23,220 --> 00:04:27,930
I'm in AI, and responsible
AI is close to my heart.

90
00:04:27,930 --> 00:04:30,360
So in all of my presentations,

91
00:04:30,360 --> 00:04:31,440
I want some angle

92
00:04:31,440 --> 00:04:35,880
about how people use this
AI responsibly, right?

93
00:04:35,880 --> 00:04:37,800
So those are my preferences,

94
00:04:37,800 --> 00:04:41,310
which I wanted the agent to remember,

95
00:04:41,310 --> 00:04:43,140
but with this basic agent,

96
00:04:43,140 --> 00:04:45,630
I always have to provide
these instructions

97
00:04:45,630 --> 00:04:47,520
over and over again.

98
00:04:47,520 --> 00:04:49,380
So how do I overcome that?

99
00:04:49,380 --> 00:04:53,160
That's where I created
another agent with memory.

100
00:04:53,160 --> 00:04:57,870
Now, this agent could understand
my preferences over time.

101
00:04:57,870 --> 00:05:00,120
When I was building a lot of slide decks,

102
00:05:00,120 --> 00:05:01,890
it learned my preferences.

103
00:05:01,890 --> 00:05:04,417
And then after a while, I just say,

104
00:05:04,417 --> 00:05:05,973
"Oh, for tech presentation,

105
00:05:06,810 --> 00:05:09,060
this is a tech presentation
on this topic,"

106
00:05:09,060 --> 00:05:11,460
and it'll just do the job.

107
00:05:11,460 --> 00:05:13,050
Not just that,

108
00:05:13,050 --> 00:05:15,630
because I know when we
are talking about it,

109
00:05:15,630 --> 00:05:17,520
we make it sound very simple.

110
00:05:17,520 --> 00:05:22,520
So that's where we will show
you this demo up and running.

111
00:05:22,980 --> 00:05:25,350
So stay tuned. It'll be at the end.

112
00:05:25,350 --> 00:05:28,380
So you have to stay for that.

113
00:05:28,380 --> 00:05:33,380
And also I want to make sure
that you understand the fact

114
00:05:33,480 --> 00:05:37,170
that how memory bridges this gap

115
00:05:37,170 --> 00:05:40,140
when you are interacting with the agent.

116
00:05:40,140 --> 00:05:42,720
So when the user is
interacting with the agent,

117
00:05:42,720 --> 00:05:43,920
there is conversation,

118
00:05:43,920 --> 00:05:48,270
there is a lot of context
that agents need to remember.

119
00:05:48,270 --> 00:05:49,950
So we have to make sure

120
00:05:49,950 --> 00:05:52,890
that that context we are
providing to the agent

121
00:05:52,890 --> 00:05:57,890
so that they give response
in an accurate, reliable way,

122
00:05:58,200 --> 00:06:03,200
relevant response, and also
give good customer experience.

123
00:06:04,710 --> 00:06:08,340
You don't just want your
agents to remember stuff.

124
00:06:08,340 --> 00:06:10,500
You also want them to be smart.

125
00:06:10,500 --> 00:06:12,210
And they can only be smart

126
00:06:12,210 --> 00:06:14,490
if they're able to retain that knowledge.

127
00:06:14,490 --> 00:06:18,300
If they have the full
context of your application

128
00:06:18,300 --> 00:06:22,020
or the job that you are asking
the agent to accomplish,

129
00:06:22,020 --> 00:06:25,440
you want the user preferences,
or maybe the facts,

130
00:06:25,440 --> 00:06:28,170
or maybe the summary of
the previous sessions

131
00:06:28,170 --> 00:06:30,690
to be remembered and
retained by this agent,

132
00:06:30,690 --> 00:06:34,380
or maybe the agent should be
able to call those things.

133
00:06:34,380 --> 00:06:37,110
So those are the things
which are very critical.

134
00:06:37,110 --> 00:06:41,340
For example, you had a long
conversation with the agent,

135
00:06:41,340 --> 00:06:43,230
and then you come back

136
00:06:43,230 --> 00:06:46,590
and you want to do is basically resume

137
00:06:46,590 --> 00:06:47,790
from that conversation.

138
00:06:47,790 --> 00:06:50,130
That's a very common use case.

139
00:06:50,130 --> 00:06:51,810
But imagine if you are storing

140
00:06:51,810 --> 00:06:56,810
the entire conversation
history, it'll go so big, right?

141
00:06:57,480 --> 00:07:00,360
So you might want to summarize it

142
00:07:00,360 --> 00:07:02,643
and maybe when your user comes back,

143
00:07:04,146 --> 00:07:04,979
the agent can say,

144
00:07:04,979 --> 00:07:06,780
"You know what, last
time when we interacted,

145
00:07:06,780 --> 00:07:08,010
you talked about these topics.

146
00:07:08,010 --> 00:07:09,960
Do you want to continue with these topics,

147
00:07:09,960 --> 00:07:12,030
or you want to start a new one?"

148
00:07:12,030 --> 00:07:13,230
So those are the things

149
00:07:13,230 --> 00:07:16,140
that you want your agent
to remember, right?

150
00:07:16,140 --> 00:07:17,820
It would be so cool.

151
00:07:17,820 --> 00:07:21,900
So that's where you want your
agent not just to remember,

152
00:07:21,900 --> 00:07:26,790
but be smart about it, be
able to recall those things.

153
00:07:26,790 --> 00:07:28,830
And that's where we are going to show you

154
00:07:28,830 --> 00:07:29,973
how would you do that.

155
00:07:30,930 --> 00:07:33,360
Now, let's talk about this demo sneak peek

156
00:07:33,360 --> 00:07:35,400
that I talked about, right?

157
00:07:35,400 --> 00:07:36,233
So the first thing,

158
00:07:36,233 --> 00:07:38,760
when you're building
an agentic application,

159
00:07:38,760 --> 00:07:41,730
you need the interface.

160
00:07:41,730 --> 00:07:44,670
Your UI should be
attractive, should be nice,

161
00:07:44,670 --> 00:07:48,060
but at the same time you
need some kind of a framework

162
00:07:48,060 --> 00:07:50,040
to build your agent.

163
00:07:50,040 --> 00:07:51,750
So in our application,

164
00:07:51,750 --> 00:07:53,340
I'm going to show you two agents.

165
00:07:53,340 --> 00:07:55,530
One, the agent without memory.

166
00:07:55,530 --> 00:07:57,420
Second, the agent with memory.

167
00:07:57,420 --> 00:07:59,220
And you will see the difference.

168
00:07:59,220 --> 00:08:00,690
We are going to give the same prompt

169
00:08:00,690 --> 00:08:02,070
to both of these agents.

170
00:08:02,070 --> 00:08:07,070
And I'm using Strands Framework
to build these agents.

171
00:08:07,080 --> 00:08:10,650
Then of course the main layer,
we are talking about memory,

172
00:08:10,650 --> 00:08:13,200
we want agents to remember, right?

173
00:08:13,200 --> 00:08:18,120
So then for this demo,
I have the Memory Hooks.

174
00:08:18,120 --> 00:08:20,880
So why Memory Hooks and
what are these hooks, right?

175
00:08:20,880 --> 00:08:22,920
So within these frameworks,

176
00:08:22,920 --> 00:08:26,250
when we are using to build
agents, there are two ways.

177
00:08:26,250 --> 00:08:28,560
One, you can use memory as a tool

178
00:08:28,560 --> 00:08:30,810
or you can use memory as a hook.

179
00:08:30,810 --> 00:08:35,040
So why we use memory as a
hook if we want to make sure

180
00:08:35,040 --> 00:08:38,610
that agent calls the
memory at a specific time

181
00:08:38,610 --> 00:08:39,840
in their lifecycle.

182
00:08:39,840 --> 00:08:43,050
For example, on every message added,

183
00:08:43,050 --> 00:08:48,050
I want my agent to add it
to the short-term memory.

184
00:08:48,360 --> 00:08:49,950
And then there is a long-term memory,

185
00:08:49,950 --> 00:08:54,950
which agent needs to retain
the key specific facts, right?

186
00:08:55,050 --> 00:08:56,910
Maybe I can use that as a tool

187
00:08:56,910 --> 00:08:58,650
because whenever the agent needs it,

188
00:08:58,650 --> 00:09:01,740
it can retrieve from the
long-term memory, right?

189
00:09:01,740 --> 00:09:04,440
So that's how you need the memory hooks

190
00:09:04,440 --> 00:09:05,940
and sometimes memory as a tool,

191
00:09:05,940 --> 00:09:08,010
depending upon your application.

192
00:09:08,010 --> 00:09:12,300
Memory hooks is a more
deterministic way of agent

193
00:09:12,300 --> 00:09:15,090
making sure that every message added goes

194
00:09:15,090 --> 00:09:16,340
to the short-term memory.

195
00:09:17,190 --> 00:09:19,650
Then when you are using these frameworks,

196
00:09:19,650 --> 00:09:21,780
there is a session manager
that you might need,

197
00:09:21,780 --> 00:09:23,100
and this will become more clear

198
00:09:23,100 --> 00:09:26,790
when we'll, you know, go
through our presentation.

199
00:09:26,790 --> 00:09:28,590
Then there is a configuration,

200
00:09:28,590 --> 00:09:32,160
like what gets extracted
from the short-term memory

201
00:09:32,160 --> 00:09:34,140
and goes into the long-term memory.

202
00:09:34,140 --> 00:09:37,680
So you should have
control over that, right?

203
00:09:37,680 --> 00:09:40,920
So in my demo, I'm using the memory config

204
00:09:40,920 --> 00:09:43,890
where you can literally
override the prompts,

205
00:09:43,890 --> 00:09:45,960
figure out what gets extracted,

206
00:09:45,960 --> 00:09:49,680
and we are using user
preferences for this demo.

207
00:09:49,680 --> 00:09:51,150
And all of this will become clear

208
00:09:51,150 --> 00:09:52,290
when we'll do a deeper dive

209
00:09:52,290 --> 00:09:56,790
on how, you know, AgentCore
Memory will help you out.

210
00:09:56,790 --> 00:09:58,470
And the last but not the least,

211
00:09:58,470 --> 00:10:01,380
I want to mention the
services that we are using.

212
00:10:01,380 --> 00:10:03,750
So I'm using Amazon Bedrock,

213
00:10:03,750 --> 00:10:08,340
Anthropic Claude Sonnet 4.5 model.

214
00:10:08,340 --> 00:10:10,290
I'm using AgentCore Memory.

215
00:10:10,290 --> 00:10:13,530
And of course security is super important.

216
00:10:13,530 --> 00:10:15,000
So with IAM permissions

217
00:10:15,000 --> 00:10:18,720
and integration with
memory makes sure of that.

218
00:10:18,720 --> 00:10:22,740
It makes sure that I'm
only giving the permissions

219
00:10:22,740 --> 00:10:25,410
that the agent needs to do its job.

220
00:10:25,410 --> 00:10:27,030
Nothing more than that.

221
00:10:27,030 --> 00:10:30,120
This helps me in reducing my blast radius.

222
00:10:30,120 --> 00:10:32,373
So one of the key principles of security,

223
00:10:33,570 --> 00:10:35,850
the principle of least privilege.

224
00:10:35,850 --> 00:10:37,353
So that's what this does.

225
00:10:38,340 --> 00:10:41,430
So now you have looked
and you have got some idea

226
00:10:41,430 --> 00:10:44,700
about what this demo
is going to look like.

227
00:10:44,700 --> 00:10:46,110
But now imagine,

228
00:10:46,110 --> 00:10:49,890
you have to build all of this on your own,

229
00:10:49,890 --> 00:10:51,000
the whole memory system.

230
00:10:51,000 --> 00:10:54,510
I'm not even talking about
building agent and deploying it,

231
00:10:54,510 --> 00:10:55,680
just the memory system.

232
00:10:55,680 --> 00:10:58,953
Imagine, you have to do
all of this on your own.

233
00:10:59,850 --> 00:11:00,903
What would you need?

234
00:11:02,370 --> 00:11:06,840
So short-term conversations,
or the short-term memory,

235
00:11:06,840 --> 00:11:09,180
should have everything as is,

236
00:11:09,180 --> 00:11:11,940
like some raw messages, some storage.

237
00:11:11,940 --> 00:11:15,360
And you should be able to give, let's say,

238
00:11:15,360 --> 00:11:17,820
last K turns to your agent.

239
00:11:17,820 --> 00:11:21,123
So that will maintain
your conversation history.

240
00:11:21,990 --> 00:11:24,810
So there's the short-term memory, right?

241
00:11:24,810 --> 00:11:29,040
Short-term memory is
literally like raw messages.

242
00:11:29,040 --> 00:11:32,100
I should be able to retain.
I should be able to call.

243
00:11:32,100 --> 00:11:34,620
So you need some kind of like a database

244
00:11:34,620 --> 00:11:39,210
or a key value system which
can store these messages.

245
00:11:39,210 --> 00:11:44,210
Now, long-term memory is that
the agent should remember.

246
00:11:44,220 --> 00:11:47,310
For example, if we are
talking about user preferences

247
00:11:47,310 --> 00:11:49,533
across multiple sessions.

248
00:11:50,370 --> 00:11:54,000
So I need a different type of
a data store over there. Why?

249
00:11:54,000 --> 00:11:55,500
Because based on the query,

250
00:11:55,500 --> 00:11:57,270
the agent should be able

251
00:11:57,270 --> 00:12:01,560
to semantically retrieve the information.

252
00:12:01,560 --> 00:12:02,760
When I say semantically,

253
00:12:02,760 --> 00:12:05,940
I mean based on the
meaning of the cushion,

254
00:12:05,940 --> 00:12:09,993
it should be able to extract
the right information.

255
00:12:11,010 --> 00:12:14,340
So I mean maybe a vector
store for that, right?

256
00:12:14,340 --> 00:12:16,620
Now, these two storage systems,

257
00:12:16,620 --> 00:12:19,050
I have to make sure that I'm managing.

258
00:12:19,050 --> 00:12:21,210
There is a memory refresh all the time.

259
00:12:21,210 --> 00:12:25,320
My data is refreshed. I
have automatic pipeline.

260
00:12:25,320 --> 00:12:28,830
Whenever there is a
duplicate user preference,

261
00:12:28,830 --> 00:12:32,310
it's consolidating, it's
updating, it's not really,

262
00:12:32,310 --> 00:12:37,310
oh, you know, adding new
preferences without consolidation,

263
00:12:37,380 --> 00:12:41,070
because imagine if I tell
you that I'm a vegetarian,

264
00:12:41,070 --> 00:12:42,393
and I'm a non-vegetarian,

265
00:12:43,920 --> 00:12:46,680
what will you serve me when
I'm, you know, with you?

266
00:12:46,680 --> 00:12:49,410
Nothing, because you are confused.

267
00:12:49,410 --> 00:12:51,780
But because I was a vegetarian earlier

268
00:12:51,780 --> 00:12:53,460
and now I'm a non-vegetarian,

269
00:12:53,460 --> 00:12:55,890
it makes sense for me to
order non-vegetarian food

270
00:12:55,890 --> 00:13:00,317
or the agent to give me,
you know, recommendations

271
00:13:01,260 --> 00:13:04,200
of the non-vegetarian
food, for example, right?

272
00:13:04,200 --> 00:13:05,820
But if I give both those things,

273
00:13:05,820 --> 00:13:06,967
the agent will get confused,

274
00:13:06,967 --> 00:13:10,080
"Oh, what do I need to do now?" Right?

275
00:13:10,080 --> 00:13:13,680
So the consolidation logic
becomes very important.

276
00:13:13,680 --> 00:13:15,540
So you have to do that on your own.

277
00:13:15,540 --> 00:13:19,050
And you have to do all of
this in a very secure way.

278
00:13:19,050 --> 00:13:20,430
And not just that,

279
00:13:20,430 --> 00:13:22,020
imagine something happens

280
00:13:22,020 --> 00:13:25,680
while your user is interacting
with the application

281
00:13:25,680 --> 00:13:28,140
and you need to troubleshoot,
or you need to debug,

282
00:13:28,140 --> 00:13:31,020
you need to build and
integrate observability

283
00:13:31,020 --> 00:13:33,090
into your system.

284
00:13:33,090 --> 00:13:38,090
So all of this becomes
really, really lot of work

285
00:13:38,160 --> 00:13:39,600
and heavy lifting.

286
00:13:39,600 --> 00:13:43,410
So that's where we have
Amazon Bedrock AgentCore

287
00:13:43,410 --> 00:13:47,070
to help you out so that you can focus

288
00:13:47,070 --> 00:13:49,590
on doing what you do best,

289
00:13:49,590 --> 00:13:52,320
is building applications
for your customers.

290
00:13:52,320 --> 00:13:55,720
And we take away all that
heavy lifting from you

291
00:13:57,054 --> 00:14:00,150
and you should be able to
quickly integrate memory

292
00:14:00,150 --> 00:14:02,100
into your agentic applications.

293
00:14:02,100 --> 00:14:05,730
Now to go deeper into
this, now I'll invite Jay,

294
00:14:05,730 --> 00:14:09,330
who is the product manager
for AgentCore Memory,

295
00:14:09,330 --> 00:14:11,433
and the best person to talk about it.

296
00:14:12,979 --> 00:14:16,146
(audience applauding)

297
00:14:17,487 --> 00:14:18,320
- Thanks, Mani.

298
00:14:19,230 --> 00:14:21,210
I think in that case with the meal,

299
00:14:21,210 --> 00:14:23,793
I'd probably go vegetarian
just to be safe.

300
00:14:26,820 --> 00:14:30,660
All right, so we built AgentCore
Memory, as Mani mentioned,

301
00:14:30,660 --> 00:14:33,300
to ensure that your agents
have the right context

302
00:14:33,300 --> 00:14:34,263
at the right time.

303
00:14:35,250 --> 00:14:37,770
It's a fully managed
service that addresses

304
00:14:37,770 --> 00:14:39,660
many of the traditional challenges

305
00:14:39,660 --> 00:14:42,240
associated with agentic memory.

306
00:14:42,240 --> 00:14:43,590
Let's look at how it works.

307
00:14:46,260 --> 00:14:48,690
So we're gonna do another
thought exercise here.

308
00:14:48,690 --> 00:14:50,400
I want you to think about a conversation

309
00:14:50,400 --> 00:14:52,803
that you've had in the last week or so.

310
00:14:56,490 --> 00:14:59,280
You probably remember that
conversation pretty well.

311
00:14:59,280 --> 00:15:01,710
Maybe even word for word.

312
00:15:01,710 --> 00:15:04,440
Now, why don't you think
about a conversation

313
00:15:04,440 --> 00:15:06,420
you had about a year ago?

314
00:15:06,420 --> 00:15:08,310
If you went to re:Invent last year,

315
00:15:08,310 --> 00:15:10,230
think about a conversation at re:Invent,

316
00:15:10,230 --> 00:15:12,690
or a presentation at re:Invent.

317
00:15:12,690 --> 00:15:17,010
If not, maybe last
Thanksgiving or last Christmas.

318
00:15:17,010 --> 00:15:20,700
Now, for that conversation,
for that interaction,

319
00:15:20,700 --> 00:15:24,240
you probably don't remember it super well.

320
00:15:24,240 --> 00:15:27,390
Your brain probably remembers
the most important details

321
00:15:27,390 --> 00:15:29,700
and generally what happened.

322
00:15:29,700 --> 00:15:31,890
And you might have used that information

323
00:15:31,890 --> 00:15:36,183
to inform future conversations
or future interactions.

324
00:15:37,260 --> 00:15:39,087
That's how your brain works.

325
00:15:39,087 --> 00:15:41,913
And that's how we designed
the AgentCore Memory as well.

326
00:15:44,370 --> 00:15:49,110
It all starts with your memory,
memory resource, excuse me.

327
00:15:49,110 --> 00:15:52,900
That's this blue and slightly pink box

328
00:15:54,000 --> 00:15:55,650
surrounding your short-term memory

329
00:15:55,650 --> 00:15:58,050
and long-term memory here.

330
00:15:58,050 --> 00:15:59,850
Within the memory resource,

331
00:15:59,850 --> 00:16:02,430
which you set up in your AWS account,

332
00:16:02,430 --> 00:16:04,230
we have short-term memory.

333
00:16:04,230 --> 00:16:06,270
That's your raw interaction history,

334
00:16:06,270 --> 00:16:10,380
that word for word that
you remember more recently.

335
00:16:10,380 --> 00:16:14,100
And that persists for from
seven days to up to a year

336
00:16:14,100 --> 00:16:16,293
based on your configuration settings.

337
00:16:18,090 --> 00:16:20,580
And then we also have long-term memory.

338
00:16:20,580 --> 00:16:24,090
And your long-term memory are
that important information,

339
00:16:24,090 --> 00:16:28,470
those key insights that
persist throughout.

340
00:16:28,470 --> 00:16:33,470
And your agent can retrieve
both short-term memory

341
00:16:33,510 --> 00:16:36,993
and long-term memory in order
to complete the job at hand.

342
00:16:40,050 --> 00:16:44,280
So let's start by looking at
how short-term memory works.

343
00:16:44,280 --> 00:16:45,780
In short-term memory,

344
00:16:45,780 --> 00:16:48,840
your agent interactions are captured

345
00:16:48,840 --> 00:16:52,923
and sent to the memory
resource in the form of events.

346
00:16:54,270 --> 00:16:58,110
Events contain an actor
ID, so who this is,

347
00:16:58,110 --> 00:17:02,730
or maybe who it is combined
with what the agent is,

348
00:17:02,730 --> 00:17:04,110
and a session ID

349
00:17:04,110 --> 00:17:07,200
which is generally your
specific interaction.

350
00:17:07,200 --> 00:17:09,570
And the actor ID and the
session ID can be used

351
00:17:09,570 --> 00:17:12,600
in conjunction with the events
with that raw information

352
00:17:12,600 --> 00:17:15,243
for easy context tracking.

353
00:17:16,620 --> 00:17:19,890
Events can contain your
conversation history.

354
00:17:19,890 --> 00:17:22,170
They can contain metadata.

355
00:17:22,170 --> 00:17:24,390
And they can also contain blob payloads.

356
00:17:24,390 --> 00:17:27,993
So images or audio, things like that.

357
00:17:29,940 --> 00:17:34,080
This is most useful for
hydrating your agent

358
00:17:34,080 --> 00:17:36,180
with the recent conversation history

359
00:17:36,180 --> 00:17:38,490
and the recent interaction history.

360
00:17:38,490 --> 00:17:40,890
This is sort of the
baseline at this point.

361
00:17:40,890 --> 00:17:43,140
And this is that example Mani gave

362
00:17:43,140 --> 00:17:45,570
of having the conversation

363
00:17:45,570 --> 00:17:48,270
and then someone comes back
and says, "Who are you?"

364
00:17:48,270 --> 00:17:51,150
You know, no one wants their
agent to be a goldfish,

365
00:17:51,150 --> 00:17:52,320
is what we say.

366
00:17:52,320 --> 00:17:54,903
And short-term memory is
really good with that.

367
00:17:57,780 --> 00:18:00,720
It has a few other uses as well.

368
00:18:00,720 --> 00:18:04,290
And for that I'd like
to talk about a topic

369
00:18:04,290 --> 00:18:06,213
that is near and dear to me,

370
00:18:07,410 --> 00:18:09,600
unsuccessful so far.

371
00:18:09,600 --> 00:18:14,600
And that topic is convincing my family

372
00:18:14,700 --> 00:18:16,683
to get a golden retriever puppy.

373
00:18:19,200 --> 00:18:22,020
So I've been unsuccessful so far.

374
00:18:22,020 --> 00:18:24,330
And I'm thinking about a new approach.

375
00:18:24,330 --> 00:18:29,330
And that new approach is using
the PowerPoint builder agent

376
00:18:30,600 --> 00:18:31,770
to create a PowerPoint

377
00:18:31,770 --> 00:18:34,560
convincing my family to get the puppy.

378
00:18:34,560 --> 00:18:39,450
So I'm going to tell it to
include a bunch of cute pictures.

379
00:18:39,450 --> 00:18:41,340
I'm going to tell it to include

380
00:18:41,340 --> 00:18:43,980
some of the pros of getting a puppy,

381
00:18:43,980 --> 00:18:45,450
getting a dog in general,

382
00:18:45,450 --> 00:18:49,020
which include that it
teaches responsibility,

383
00:18:49,020 --> 00:18:51,450
that statistically people

384
00:18:51,450 --> 00:18:54,480
who have dogs are shown to be happier.

385
00:18:54,480 --> 00:18:56,040
And I'm also gonna ask the agent

386
00:18:56,040 --> 00:18:58,440
to do a bit of a financial analysis

387
00:18:58,440 --> 00:19:00,720
to address some of my family's concerns

388
00:19:00,720 --> 00:19:03,900
that maybe costs are an issue.

389
00:19:03,900 --> 00:19:06,000
So I've put in a lot of effort here,

390
00:19:06,000 --> 00:19:07,950
gone back and forth with the agent.

391
00:19:07,950 --> 00:19:10,683
And the most annoying
thing that can happen,

392
00:19:11,520 --> 00:19:12,720
the screen goes blank.

393
00:19:12,720 --> 00:19:14,343
Let's say I quit by mistake.

394
00:19:15,660 --> 00:19:18,780
Now it can be really painful to get back

395
00:19:18,780 --> 00:19:20,310
to that exact point.

396
00:19:20,310 --> 00:19:21,900
Can be a lot of effort.

397
00:19:21,900 --> 00:19:25,590
With AgentCore Memory,
conversation history can be stored,

398
00:19:25,590 --> 00:19:28,890
and also interaction state can be stored.

399
00:19:28,890 --> 00:19:31,920
And what that means is
that you can go back

400
00:19:31,920 --> 00:19:34,590
to the exact spot where you are,

401
00:19:34,590 --> 00:19:36,750
and hopefully I'll keep you posted,

402
00:19:36,750 --> 00:19:39,723
next year at re:Invent,
we'll have a puppy.

403
00:19:43,560 --> 00:19:47,850
AgentCore Memory supports a
few other advanced features

404
00:19:47,850 --> 00:19:50,703
for event organization
with short-term memory,

405
00:19:52,110 --> 00:19:54,390
one of which is branching.

406
00:19:54,390 --> 00:19:56,820
Branching is useful for going back

407
00:19:56,820 --> 00:20:01,260
and editing messages or editing events.

408
00:20:01,260 --> 00:20:04,830
And it's also useful for
concurrent event streams.

409
00:20:04,830 --> 00:20:07,410
So what that means is,

410
00:20:07,410 --> 00:20:11,490
let's say I put in some
effort for this presentation

411
00:20:11,490 --> 00:20:14,490
and I wanted to get the agent to go off

412
00:20:14,490 --> 00:20:17,340
and build me one presentation

413
00:20:17,340 --> 00:20:20,040
on getting a golden retriever puppy,

414
00:20:20,040 --> 00:20:23,580
one presentation on getting
a Siberian Husky puppy,

415
00:20:23,580 --> 00:20:25,470
and, you know, maybe one presentation

416
00:20:25,470 --> 00:20:27,510
on getting a German Shepherd puppy,

417
00:20:27,510 --> 00:20:29,163
though I doubt that last one.

418
00:20:31,230 --> 00:20:33,220
AgentCore can do that with branching

419
00:20:34,110 --> 00:20:36,453
and maintain logical separation.

420
00:20:39,780 --> 00:20:41,280
So that's short-term memory.

421
00:20:41,280 --> 00:20:44,040
And now we're gonna look
at long-term memory.

422
00:20:44,040 --> 00:20:45,870
With long-term memory,

423
00:20:45,870 --> 00:20:48,570
your raw interactions short-term memory

424
00:20:48,570 --> 00:20:50,310
are automatically transformed

425
00:20:50,310 --> 00:20:53,133
into structured and persistent insights.

426
00:20:54,690 --> 00:20:56,910
Unlike short-term memory

427
00:20:56,910 --> 00:21:00,180
where the interactions
are, full interactions,

428
00:21:00,180 --> 00:21:03,090
your full conversation
history is captured;

429
00:21:03,090 --> 00:21:04,830
with long-term memory,

430
00:21:04,830 --> 00:21:06,810
we only pull key insights

431
00:21:06,810 --> 00:21:08,610
that you're going to need over time.

432
00:21:10,290 --> 00:21:14,910
It's a multi-step process to
capture these interactions

433
00:21:14,910 --> 00:21:17,280
and write them to long-term memory.

434
00:21:17,280 --> 00:21:18,420
And as you may have guessed,

435
00:21:18,420 --> 00:21:20,823
we're using large
language models for this.

436
00:21:24,180 --> 00:21:26,220
You may also be wondering

437
00:21:26,220 --> 00:21:30,723
how we know what information
to pull into long-term memory.

438
00:21:32,070 --> 00:21:35,913
And the answer to that is by
choosing a memory strategy.

439
00:21:37,650 --> 00:21:40,080
We have three built-in strategies:

440
00:21:40,080 --> 00:21:43,650
summary, user preferences, and semantic.

441
00:21:43,650 --> 00:21:45,510
And it's very simple to add those.

442
00:21:45,510 --> 00:21:48,540
You go into the AWS console,

443
00:21:48,540 --> 00:21:50,490
or add them via API,

444
00:21:50,490 --> 00:21:53,640
or programmatically you
pick the strategy you want,

445
00:21:53,640 --> 00:21:54,473
you add it,

446
00:21:54,473 --> 00:21:57,120
and information
automatically starts flowing

447
00:21:57,120 --> 00:21:59,730
from short-term memory
into long-term memory.

448
00:21:59,730 --> 00:22:02,880
So really easy, we really like that.

449
00:22:02,880 --> 00:22:06,960
The strategies themselves
are pretty self-explanatory.

450
00:22:06,960 --> 00:22:09,630
Summary condenses down your interaction,

451
00:22:09,630 --> 00:22:14,370
condenses down your
conversation, and saves that.

452
00:22:14,370 --> 00:22:17,370
User preferences captures
the user's preferences.

453
00:22:17,370 --> 00:22:21,030
So for me, for that
interaction we talked about,

454
00:22:21,030 --> 00:22:24,720
it might be the user
prefers golden retrievers

455
00:22:24,720 --> 00:22:27,333
and Siberian Huskies to German Shepherds.

456
00:22:28,950 --> 00:22:33,950
And then semantic captures
facts about the interaction.

457
00:22:34,200 --> 00:22:37,320
So that one might be user has a family

458
00:22:37,320 --> 00:22:40,803
and family wants a dog, hopefully.

459
00:22:42,270 --> 00:22:44,820
You may also want a little more control

460
00:22:44,820 --> 00:22:48,420
over what you send into long-term memory.

461
00:22:48,420 --> 00:22:51,870
And that's what those bottom
two strategies are for.

462
00:22:51,870 --> 00:22:54,420
So with the override strategy,

463
00:22:54,420 --> 00:22:58,080
you can choose which large
language models to use

464
00:22:58,080 --> 00:22:59,370
and what prompts to use

465
00:22:59,370 --> 00:23:02,043
to send information into long-term memory.

466
00:23:03,750 --> 00:23:06,780
Self-managed gives you complete control

467
00:23:06,780 --> 00:23:08,793
over the extraction process.

468
00:23:10,200 --> 00:23:13,560
So what we do with that
is we deliver the events

469
00:23:13,560 --> 00:23:17,490
to an S3 Bucket and notify you of those.

470
00:23:17,490 --> 00:23:19,500
And you can pick up those events,

471
00:23:19,500 --> 00:23:23,040
bring them through any sort
of processing you want,

472
00:23:23,040 --> 00:23:26,880
and write them to long-term
memory as memory records

473
00:23:26,880 --> 00:23:28,623
via our dedicated APIs.

474
00:23:30,450 --> 00:23:33,630
All of these strategies can be,

475
00:23:33,630 --> 00:23:36,000
memory records created
from these strategies

476
00:23:36,000 --> 00:23:37,980
can be retrieved semantically,

477
00:23:37,980 --> 00:23:40,440
so based on a query search.

478
00:23:40,440 --> 00:23:44,760
And memory and strategies
can be combined as well.

479
00:23:44,760 --> 00:23:45,870
And if you think about it,

480
00:23:45,870 --> 00:23:50,070
it makes a lot of sense to wanna
summarize your interactions

481
00:23:50,070 --> 00:23:51,690
and also capture facts about it.

482
00:23:51,690 --> 00:23:54,210
So if you're creating an agent,

483
00:23:54,210 --> 00:23:57,180
summary and semantic
might be the way to start.

484
00:23:57,180 --> 00:23:59,310
And then as you want
more control over time,

485
00:23:59,310 --> 00:24:01,923
think about looking at
override or self-managed.

486
00:24:05,610 --> 00:24:08,550
So let's put all of this together.

487
00:24:08,550 --> 00:24:11,970
We're gonna start on the left side here.

488
00:24:11,970 --> 00:24:15,540
As we remember, interactions,
conversations are captured

489
00:24:15,540 --> 00:24:20,013
and sent to the agent as
short-term memory, as events.

490
00:24:21,030 --> 00:24:23,643
Depending on the strategies
you've configured,

491
00:24:24,510 --> 00:24:27,180
those events are sent
into long-term memory

492
00:24:27,180 --> 00:24:28,623
as memory records.

493
00:24:30,330 --> 00:24:33,690
Both short-term memory
and long-term memory,

494
00:24:33,690 --> 00:24:37,560
both events and memory records
can be retrieved by the agent

495
00:24:37,560 --> 00:24:42,333
to complete whatever task it
is that the agent's completing.

496
00:24:43,920 --> 00:24:45,060
You may have also noticed,

497
00:24:45,060 --> 00:24:48,450
we now have Agent 2 and Agent 3 up here.

498
00:24:48,450 --> 00:24:51,000
Multiple agents can write to

499
00:24:51,000 --> 00:24:53,190
and read from a single memory resource.

500
00:24:53,190 --> 00:24:55,230
So that's an option you can make.

501
00:24:55,230 --> 00:24:57,483
And we can support multi-agent use cases.

502
00:24:59,790 --> 00:25:01,293
Or we can support just one.

503
00:25:05,580 --> 00:25:08,070
Yeah, so that's AgentCore Memory.

504
00:25:08,070 --> 00:25:13,070
It's a fully-managed service
with built-in observability

505
00:25:14,070 --> 00:25:16,950
and enterprise-grade security features.

506
00:25:16,950 --> 00:25:18,630
And now I'm going to pass things

507
00:25:18,630 --> 00:25:21,690
over to my friend Imran at Experian,

508
00:25:21,690 --> 00:25:24,510
to talk a bit about his
organization's experience

509
00:25:24,510 --> 00:25:25,893
with agentic memory.

510
00:25:27,195 --> 00:25:30,362
(audience applauding)

511
00:25:32,970 --> 00:25:34,923
Need that?
- Thanks, Jay.

512
00:25:36,900 --> 00:25:38,160
I am Imran Shah.

513
00:25:38,160 --> 00:25:40,200
I'm here today from Experian

514
00:25:40,200 --> 00:25:42,870
to talk about what you have
heard from Mani and Jay

515
00:25:42,870 --> 00:25:45,930
in terms of putting this into perspective

516
00:25:45,930 --> 00:25:49,053
with the likes of an organization
and enterprise scale.

517
00:25:52,200 --> 00:25:55,440
So I'm here to talk about Experian journey

518
00:25:55,440 --> 00:25:59,010
of how we have moved
from a short-term memory

519
00:25:59,010 --> 00:26:02,340
to a unified memory architecture,

520
00:26:02,340 --> 00:26:04,830
and especially using AgentCore Memory

521
00:26:04,830 --> 00:26:07,590
to simplify our direction within Experian.

522
00:26:07,590 --> 00:26:10,833
As all of you can experience today,

523
00:26:12,300 --> 00:26:16,890
the whole AI across enterprise
is a rapid evolution.

524
00:26:16,890 --> 00:26:19,230
On a daily basis, it is changing.

525
00:26:19,230 --> 00:26:22,260
And that is how Experian was
thinking before AgentCore

526
00:26:22,260 --> 00:26:25,020
in terms of short-term
memory as Mani said.

527
00:26:25,020 --> 00:26:27,270
We talk about something, we
introduced with our name,

528
00:26:27,270 --> 00:26:28,890
and I forget who you were.

529
00:26:28,890 --> 00:26:30,273
That's short-term memory.

530
00:26:31,500 --> 00:26:35,250
So we have actually pivoted our roadmap

531
00:26:35,250 --> 00:26:39,450
with this whole AgentCore
long-term memory architecture.

532
00:26:39,450 --> 00:26:42,420
And we have adopted that in
the pilot mode within Experian

533
00:26:42,420 --> 00:26:44,670
and I'm gonna you through
that journey today.

534
00:26:46,920 --> 00:26:48,630
A little bit about Experian.

535
00:26:48,630 --> 00:26:51,510
As you know, the credit
bureau all across the globe,

536
00:26:51,510 --> 00:26:52,650
we have credit bureaus.

537
00:26:52,650 --> 00:26:57,240
We are a innovative global
data and technology business.

538
00:26:57,240 --> 00:26:58,770
And our main aim is

539
00:26:58,770 --> 00:27:01,653
to work towards the
financial health for all.

540
00:27:03,181 --> 00:27:08,181
We have around 1.5 billion plus
consumers across the globe.

541
00:27:08,220 --> 00:27:11,160
And we serve both small, medium, large,

542
00:27:11,160 --> 00:27:14,610
201 million plus businesses
across the globe,

543
00:27:14,610 --> 00:27:16,083
across the geography.

544
00:27:18,930 --> 00:27:20,963
From our richness perspective,

545
00:27:20,963 --> 00:27:23,790
we serve 25,000 employees
across 32 countries.

546
00:27:23,790 --> 00:27:26,910
And from a domains-wise, you
can name it as you can see,

547
00:27:26,910 --> 00:27:29,700
cable to credit, not only credit,

548
00:27:29,700 --> 00:27:33,870
but also data solutions,
automotive, healthcare.

549
00:27:33,870 --> 00:27:38,700
And we are delivering this
whole with the 99.9% accuracy

550
00:27:38,700 --> 00:27:41,823
of data across multiple domains.

551
00:27:43,980 --> 00:27:47,430
Now let's talk about
Experian AgentCore journey.

552
00:27:47,430 --> 00:27:50,370
As you heard from Mani and Jay,

553
00:27:50,370 --> 00:27:52,830
we started our journey with a short-term,

554
00:27:52,830 --> 00:27:56,040
very product-specific
memory implementations.

555
00:27:56,040 --> 00:27:59,340
And very quickly we realized
that's not the way to go,

556
00:27:59,340 --> 00:28:01,650
and we changed our unified approach

557
00:28:01,650 --> 00:28:05,463
to more conversational context
and moving towards long term.

558
00:28:07,860 --> 00:28:10,170
What AgentCore has also brought us is

559
00:28:10,170 --> 00:28:11,550
rethinking our roadmaps

560
00:28:11,550 --> 00:28:15,660
in terms of how Amazon
Bedrock AgentCore Memory,

561
00:28:15,660 --> 00:28:16,890
we are actually moving

562
00:28:16,890 --> 00:28:19,110
to more time to value simpler journeys

563
00:28:19,110 --> 00:28:21,510
and pivoting our roadmap towards that.

564
00:28:21,510 --> 00:28:23,520
And we'll talk in subsequent slides

565
00:28:23,520 --> 00:28:26,223
about how we are doing
that in perspective.

566
00:28:27,450 --> 00:28:29,790
So as you can see in this diagram,

567
00:28:29,790 --> 00:28:31,890
our current memory implementation is

568
00:28:31,890 --> 00:28:36,180
across products in two different ways.

569
00:28:36,180 --> 00:28:37,690
One is managed memory

570
00:28:38,550 --> 00:28:43,260
where you have assistance which
are using tools like OpenAI,

571
00:28:43,260 --> 00:28:45,390
providing thread-level memory.

572
00:28:45,390 --> 00:28:47,370
In the right hand side,

573
00:28:47,370 --> 00:28:50,130
we also have custom
memory implementations,

574
00:28:50,130 --> 00:28:53,490
which are some of the agents leveraging

575
00:28:53,490 --> 00:28:55,410
OSS open service frameworks,

576
00:28:55,410 --> 00:28:57,990
again providing thread-level memory.

577
00:28:57,990 --> 00:28:59,730
In the contrast, as you can see,

578
00:28:59,730 --> 00:29:03,480
we have a managed and we
have a custom, both coexist,

579
00:29:03,480 --> 00:29:06,180
which creates a lot of user frustration

580
00:29:06,180 --> 00:29:08,043
and confusions across teams.

581
00:29:10,380 --> 00:29:12,810
So from a short-term memory perspective,

582
00:29:12,810 --> 00:29:15,030
as you can see, it works,

583
00:29:15,030 --> 00:29:18,873
but it doesn't scale into
the enterprise world.

584
00:29:21,240 --> 00:29:24,360
A very small company
with even 500 employees

585
00:29:24,360 --> 00:29:26,610
or 200 customers,

586
00:29:26,610 --> 00:29:30,123
even in that regard, short-term
memory has some limitations.

587
00:29:31,140 --> 00:29:32,550
Starting with the first one,

588
00:29:32,550 --> 00:29:34,470
which is more around continuity

589
00:29:34,470 --> 00:29:38,850
and persisting the long
conversation histories.

590
00:29:38,850 --> 00:29:42,300
The second one is more
around performance and cost,

591
00:29:42,300 --> 00:29:44,910
which is very important
to all organization

592
00:29:44,910 --> 00:29:46,803
at any scale levels.

593
00:29:47,970 --> 00:29:50,340
We also have cross product recall issues,

594
00:29:50,340 --> 00:29:52,320
which leads to a lot of user frustration

595
00:29:52,320 --> 00:29:54,360
where no memory recall happens

596
00:29:54,360 --> 00:29:56,253
across the threads or products.

597
00:29:57,660 --> 00:29:59,190
And last but not the least is

598
00:29:59,190 --> 00:30:02,160
the compliance and regulatory

599
00:30:02,160 --> 00:30:06,000
where it is difficult
to meet your regulatory

600
00:30:06,000 --> 00:30:09,120
or compliance needs where
you have to go back two years

601
00:30:09,120 --> 00:30:12,240
and represent any retention requirements.

602
00:30:12,240 --> 00:30:14,400
It's very difficult to achieve that

603
00:30:14,400 --> 00:30:15,750
with the short-term memory.

604
00:30:17,250 --> 00:30:20,850
If we now move on to more
context orchestration

605
00:30:20,850 --> 00:30:25,290
and how unified memory has
changed our whole implementation

606
00:30:25,290 --> 00:30:27,000
and the roadmap with this,

607
00:30:27,000 --> 00:30:31,290
as you can see, there are
two planes of context here.

608
00:30:31,290 --> 00:30:34,380
We have a authoritative context,

609
00:30:34,380 --> 00:30:38,850
which is more around
knowledge bases, APIs,

610
00:30:38,850 --> 00:30:40,200
you have databases,

611
00:30:40,200 --> 00:30:44,400
the things which are kind of
your knowledge ecosystems.

612
00:30:44,400 --> 00:30:46,440
And you have a conversational context

613
00:30:46,440 --> 00:30:48,000
which has short-term memory,

614
00:30:48,000 --> 00:30:49,440
it has long-term memory,

615
00:30:49,440 --> 00:30:52,140
and it also has the agent state.

616
00:30:52,140 --> 00:30:55,050
When you combine these
two planes of context

617
00:30:55,050 --> 00:30:58,230
into a more context workflow,

618
00:30:58,230 --> 00:31:00,090
it becomes very impactful

619
00:31:00,090 --> 00:31:02,010
for an organization which can scale

620
00:31:02,010 --> 00:31:04,530
from an enterprise perspective.

621
00:31:04,530 --> 00:31:07,620
Your LLM reporting can
be much more efficient

622
00:31:07,620 --> 00:31:12,000
and your user personas can
give you the user context

623
00:31:12,000 --> 00:31:13,533
which is required by a user.

624
00:31:16,260 --> 00:31:19,290
Before, pre-AgentCore,

625
00:31:19,290 --> 00:31:23,580
our planned architecture for
unified memory look like this,

626
00:31:23,580 --> 00:31:25,650
like any other build scenario,

627
00:31:25,650 --> 00:31:26,940
a classic build scenario

628
00:31:26,940 --> 00:31:29,190
where you have a conversational manager

629
00:31:29,190 --> 00:31:32,730
which stores and retrieves
all your conversations.

630
00:31:32,730 --> 00:31:34,830
You also have a memory manager

631
00:31:34,830 --> 00:31:37,060
which stores and retrieves memory records

632
00:31:37,940 --> 00:31:42,540
powered by a typical memory
store or a vector DB store.

633
00:31:42,540 --> 00:31:46,380
And your ETL pipeline is
kicking off periodically

634
00:31:46,380 --> 00:31:47,853
in order to feed this.

635
00:31:48,960 --> 00:31:52,770
So this model had a lot of, I would say,

636
00:31:52,770 --> 00:31:56,370
significant operational complexity

637
00:31:56,370 --> 00:32:00,210
due to managing multiple
custom components.

638
00:32:00,210 --> 00:32:02,940
So this was pre-AgentCore.

639
00:32:02,940 --> 00:32:05,760
Now let's talk about what was,

640
00:32:05,760 --> 00:32:08,130
after we have implemented AgentCore,

641
00:32:08,130 --> 00:32:11,310
a long-term memory
assumptions into our roadmap

642
00:32:11,310 --> 00:32:13,320
and into our architecture.

643
00:32:13,320 --> 00:32:14,490
As you can see,

644
00:32:14,490 --> 00:32:18,780
it is lot more simplified
both in direction

645
00:32:18,780 --> 00:32:20,680
and also in terms of the architecture.

646
00:32:21,720 --> 00:32:25,680
With this, you have a fully
managed conversational store,

647
00:32:25,680 --> 00:32:29,730
you have a fully managed
conversational APIs,

648
00:32:29,730 --> 00:32:31,950
and you have zero ATL overhead

649
00:32:31,950 --> 00:32:34,743
for your extraction of your memory.

650
00:32:37,620 --> 00:32:39,360
What it brings to the table

651
00:32:39,360 --> 00:32:44,103
for a enterprise-wide scale
is faster time to value,

652
00:32:44,970 --> 00:32:47,400
improved operational efficiency,

653
00:32:47,400 --> 00:32:50,250
and a lot of increased functionality.

654
00:32:50,250 --> 00:32:54,780
In this scenario, our engineers
focus on building agents

655
00:32:54,780 --> 00:32:57,450
and not worry about the infrastructure.

656
00:32:57,450 --> 00:33:00,510
So this is how we have
simplified our direction,

657
00:33:00,510 --> 00:33:02,830
and we are still in the
process of improving

658
00:33:03,810 --> 00:33:06,903
towards a better scale and a
better roadmap for Experian.

659
00:33:08,790 --> 00:33:11,250
Our code design principles
which are underpinning

660
00:33:11,250 --> 00:33:13,050
all of this architecture you have seen,

661
00:33:13,050 --> 00:33:15,510
the current state and the two state,

662
00:33:15,510 --> 00:33:18,450
is leveraging these four pillars,

663
00:33:18,450 --> 00:33:20,700
evaluation and test frameworks,

664
00:33:20,700 --> 00:33:23,310
which actually continuously evaluate

665
00:33:23,310 --> 00:33:26,040
your memory extraction processes.

666
00:33:26,040 --> 00:33:30,690
We also focused on cross-agent
memory interoperability

667
00:33:30,690 --> 00:33:33,480
so that we can enable
agents to share memory

668
00:33:33,480 --> 00:33:34,710
across different agents

669
00:33:34,710 --> 00:33:37,170
because then they can
orchestrate with each other

670
00:33:37,170 --> 00:33:39,150
and give you a very informed opinion

671
00:33:39,150 --> 00:33:40,563
with the context in mind.

672
00:33:41,490 --> 00:33:45,810
We also have shorter targeted
context windows with this,

673
00:33:45,810 --> 00:33:49,890
which keep it very purposeful and concise.

674
00:33:49,890 --> 00:33:52,470
And namespace-based isolation,

675
00:33:52,470 --> 00:33:55,230
which every enterprise would need

676
00:33:55,230 --> 00:33:58,950
in terms of achieving
multi-tenants architecture

677
00:33:58,950 --> 00:34:00,840
where you can serve multiple tenants

678
00:34:00,840 --> 00:34:04,770
with the same master shared
kind of architecture.

679
00:34:04,770 --> 00:34:07,230
So these are some of our
core design principles

680
00:34:07,230 --> 00:34:10,290
which are not only met
with this whole design,

681
00:34:10,290 --> 00:34:13,833
but also we keep this on a daily basis.

682
00:34:15,480 --> 00:34:20,480
Now, this is where a design
for privacy, transparency,

683
00:34:21,930 --> 00:34:23,133
and control comes in.

684
00:34:24,810 --> 00:34:27,150
The whole memory governance service,

685
00:34:27,150 --> 00:34:28,830
which we have designed with this,

686
00:34:28,830 --> 00:34:33,830
it's a unified first way to
manage long-term AI memory.

687
00:34:34,020 --> 00:34:37,260
What it allows is a user
can selectively delete

688
00:34:37,260 --> 00:34:39,870
their own memories if they don't need it

689
00:34:39,870 --> 00:34:42,690
and an administrator would be able to,

690
00:34:42,690 --> 00:34:45,540
will have an ability to
purge it on a periodic basis

691
00:34:45,540 --> 00:34:46,770
when it is required.

692
00:34:46,770 --> 00:34:49,800
So it gives the control in hands of a user

693
00:34:49,800 --> 00:34:52,350
and also in the hands of administration

694
00:34:52,350 --> 00:34:55,623
if they need to take some
action in terms purging.

695
00:34:56,850 --> 00:34:59,880
The whole approach actually enhances

696
00:34:59,880 --> 00:35:02,310
great user experience, trust,

697
00:35:02,310 --> 00:35:06,180
and more importantly it ensures compliance

698
00:35:06,180 --> 00:35:09,960
for guidelines like GDPR or CCPA.

699
00:35:09,960 --> 00:35:12,360
And these are very important,

700
00:35:12,360 --> 00:35:14,070
because at the heart of Experian,

701
00:35:14,070 --> 00:35:15,900
we believe in security, compliance,

702
00:35:15,900 --> 00:35:18,930
and user experience all together.

703
00:35:18,930 --> 00:35:21,780
So I think AgentCore Memory
architecture is bringing

704
00:35:21,780 --> 00:35:23,010
all that to life for us.

705
00:35:23,010 --> 00:35:25,230
It's solving multiple problems

706
00:35:25,230 --> 00:35:29,523
and also giving us a way to
scale at the enterprise AI-wide.

707
00:35:30,780 --> 00:35:33,030
With that I will also thank our partners

708
00:35:33,030 --> 00:35:35,340
who have helped us doing
this implementation

709
00:35:35,340 --> 00:35:38,220
from Tiger Analytics and AWS team.

710
00:35:38,220 --> 00:35:39,180
And at this time,

711
00:35:39,180 --> 00:35:41,700
I'm more than happy to
hand it over to Mani,

712
00:35:41,700 --> 00:35:45,033
to take us through a very impactful demo.

713
00:35:45,033 --> 00:35:47,089
With that, thank you so much.

714
00:35:47,089 --> 00:35:50,256
(audience applauding)

715
00:35:52,890 --> 00:35:56,880
- Okay, I'm back. Hard to get rid of.

716
00:35:56,880 --> 00:35:58,260
Okay, no worries.

717
00:35:58,260 --> 00:36:02,370
So now that you have understood
about AgentCore Memory

718
00:36:02,370 --> 00:36:04,230
that Jay went deep into,

719
00:36:04,230 --> 00:36:07,560
the constructs, the
components, how it works,

720
00:36:07,560 --> 00:36:11,010
and especially I would like to thank Imran

721
00:36:11,010 --> 00:36:14,340
on sharing how Experian has
been using it in their products

722
00:36:14,340 --> 00:36:19,020
and how it was able to
simplify their implementation

723
00:36:19,020 --> 00:36:20,550
and also scale.

724
00:36:20,550 --> 00:36:23,850
It is so important to make sure

725
00:36:23,850 --> 00:36:27,120
that your agents and your
applications can scale.

726
00:36:27,120 --> 00:36:30,570
And when we are building AgentCore Memory,

727
00:36:30,570 --> 00:36:32,160
we are taking that into mind

728
00:36:32,160 --> 00:36:33,690
because that's what our customers

729
00:36:33,690 --> 00:36:37,290
like yourself have been asking us, right?

730
00:36:37,290 --> 00:36:39,600
So with that, I know
it's time for the demo,

731
00:36:39,600 --> 00:36:43,770
which I promised to you
right in the beginning.

732
00:36:43,770 --> 00:36:46,788
So are you all ready for the demo?

733
00:36:46,788 --> 00:36:48,033
- Yes.
- Okay.

734
00:36:49,230 --> 00:36:53,957
So this is the demo that I
built using AgentCore Memory.

735
00:36:54,900 --> 00:36:57,330
So, as promised, there are two agents,

736
00:36:57,330 --> 00:36:59,760
the basic agent which has no memory,

737
00:36:59,760 --> 00:37:02,640
then the memory with the
agent and a comparison thing.

738
00:37:02,640 --> 00:37:03,900
And as you can see,

739
00:37:03,900 --> 00:37:07,980
I have some slides that I've
already built out using this.

740
00:37:07,980 --> 00:37:12,690
So my agent now should
remember my preferences.

741
00:37:12,690 --> 00:37:15,420
But let's see the basic agent first.

742
00:37:15,420 --> 00:37:18,270
You can see there is like
it doesn't have any memory.

743
00:37:18,270 --> 00:37:20,580
I can build some prompts, provide it.

744
00:37:20,580 --> 00:37:23,130
It's a full running application.

745
00:37:23,130 --> 00:37:25,380
And I have to provide the prompts,

746
00:37:25,380 --> 00:37:27,690
I have to mention that
I like the blue theme.

747
00:37:27,690 --> 00:37:29,100
Or if I don't mention anything,

748
00:37:29,100 --> 00:37:30,990
it will just use the default.

749
00:37:30,990 --> 00:37:34,560
But when I go to the memory-enabled agent,

750
00:37:34,560 --> 00:37:38,160
then as you can see, it
can remember my styling.

751
00:37:38,160 --> 00:37:40,200
Like for technical presentations,

752
00:37:40,200 --> 00:37:43,920
I like the purple theme,
I like the technical font.

753
00:37:43,920 --> 00:37:46,560
So because I have already
built out presentations

754
00:37:46,560 --> 00:37:47,880
using this agent,

755
00:37:47,880 --> 00:37:50,790
it's able to capture it
in the long-term memory

756
00:37:50,790 --> 00:37:53,490
and also some real world use cases

757
00:37:53,490 --> 00:37:56,910
that it should include in
all of my presentations.

758
00:37:56,910 --> 00:38:00,990
And also it shows my obsession with AI.

759
00:38:00,990 --> 00:38:02,640
So it's capturing that, you know,

760
00:38:02,640 --> 00:38:06,390
the user likes to build
the AI presentations.

761
00:38:06,390 --> 00:38:09,660
So it literally shows that I'm into it.

762
00:38:09,660 --> 00:38:13,620
And then you can literally
create a smart presentation.

763
00:38:13,620 --> 00:38:16,080
And now I don't have to
specify my preferences

764
00:38:16,080 --> 00:38:17,640
over and over again.

765
00:38:17,640 --> 00:38:21,120
But who am I to say that?
Let's see it in action.

766
00:38:21,120 --> 00:38:23,400
So with this agent comparison thing,

767
00:38:23,400 --> 00:38:26,070
I'm going to give the exact same prompt

768
00:38:26,070 --> 00:38:29,430
to both of these agents at the same time.

769
00:38:29,430 --> 00:38:30,750
And as you can see,

770
00:38:30,750 --> 00:38:33,930
I'm not going to provide my preferences.

771
00:38:33,930 --> 00:38:37,080
Even this prefer and
clean, let's remove that.

772
00:38:37,080 --> 00:38:39,120
Let's just make it simple.

773
00:38:39,120 --> 00:38:43,110
What type of presentation
I want, the key components.

774
00:38:43,110 --> 00:38:46,530
So now this is behind the
scenes what's happening.

775
00:38:46,530 --> 00:38:49,020
So you can see my prompt,
behind the scenes,

776
00:38:49,020 --> 00:38:51,180
it calling the basic agent first.

777
00:38:51,180 --> 00:38:53,460
It gave the whole prompt.

778
00:38:53,460 --> 00:38:56,670
And after this, now you will see

779
00:38:56,670 --> 00:39:00,030
that it is also calling the memory agent.

780
00:39:00,030 --> 00:39:05,030
Let's take a closer look,
the topic and stuff,

781
00:39:05,640 --> 00:39:08,370
so that it can search the long-term memory

782
00:39:08,370 --> 00:39:10,320
behind the scene

783
00:39:10,320 --> 00:39:15,320
and find the relevant preferences
related to the content.

784
00:39:15,660 --> 00:39:20,310
But I also need preferences
related to the styling.

785
00:39:20,310 --> 00:39:24,690
So then it's again making a
call for my styling preferences

786
00:39:24,690 --> 00:39:28,140
and finding and searching and retrieving

787
00:39:28,140 --> 00:39:33,030
the right memory which might be relevant

788
00:39:33,030 --> 00:39:35,373
to build this presentation.

789
00:39:36,360 --> 00:39:38,700
And then it is applying those things,

790
00:39:38,700 --> 00:39:43,700
as you can see in the backend,
to build my presentation.

791
00:39:45,150 --> 00:39:47,160
So it's all done.

792
00:39:47,160 --> 00:39:51,990
Now let's take a look into
and get back to our UI.

793
00:39:51,990 --> 00:39:54,420
So there are two comparisons.

794
00:39:54,420 --> 00:39:57,060
And it's also giving a good understanding

795
00:39:57,060 --> 00:39:59,820
and a summary what these
two agents have done

796
00:39:59,820 --> 00:40:02,253
based on the styling,
based on the preferences.

797
00:40:03,630 --> 00:40:06,150
So with the basic one,

798
00:40:06,150 --> 00:40:08,460
it is using blue because
that's the default theme

799
00:40:08,460 --> 00:40:09,660
that I have provided.

800
00:40:09,660 --> 00:40:11,910
But for the styling that it has applied

801
00:40:11,910 --> 00:40:14,220
to the memory agent is the purple theme.

802
00:40:14,220 --> 00:40:16,413
Yes, I'm obsessed with the purple color.

803
00:40:17,407 --> 00:40:18,510
(clears throat)

804
00:40:18,510 --> 00:40:22,410
So now let's take a look
again at those preferences

805
00:40:22,410 --> 00:40:24,090
because I want you to remember those

806
00:40:24,090 --> 00:40:25,890
because when you see the actual slides,

807
00:40:25,890 --> 00:40:29,310
you're able to correlate
this purple theme,

808
00:40:29,310 --> 00:40:32,730
tech font, AI ethics.

809
00:40:32,730 --> 00:40:35,760
I'm obsessed with AI. It shows everything.

810
00:40:35,760 --> 00:40:38,190
So my agent knows me, right?

811
00:40:38,190 --> 00:40:40,560
That's the main idea behind it.

812
00:40:40,560 --> 00:40:42,660
So now let's take a look into the deck.

813
00:40:42,660 --> 00:40:45,720
Now you can see there is
AI ethics tech added to it.

814
00:40:45,720 --> 00:40:48,300
Let's take a look at the basic one.

815
00:40:48,300 --> 00:40:50,730
Blue team, it's a default one

816
00:40:50,730 --> 00:40:52,770
because I never provided what I want.

817
00:40:52,770 --> 00:40:54,750
No styling preferences.

818
00:40:54,750 --> 00:40:56,370
It is still doing a really good job

819
00:40:56,370 --> 00:40:57,840
as I explained you earlier.

820
00:40:57,840 --> 00:41:00,873
It is giving the slide,
the format, and everything.

821
00:41:01,740 --> 00:41:04,533
So now let's take a look
at the memory agent.

822
00:41:05,460 --> 00:41:09,990
Look my style, purple color, tech font.

823
00:41:09,990 --> 00:41:11,940
This is basically the font

824
00:41:11,940 --> 00:41:15,750
that you see while you do the
coding in one of the IDEs.

825
00:41:15,750 --> 00:41:16,980
So I like that.

826
00:41:16,980 --> 00:41:21,980
So now you can see those
concepts into the presentation.

827
00:41:22,320 --> 00:41:25,620
So it's not just about my
style and the preferences.

828
00:41:25,620 --> 00:41:28,230
But even if you look
closely at the content,

829
00:41:28,230 --> 00:41:32,040
you will realize that it has
incorporated those things,

830
00:41:32,040 --> 00:41:35,280
the content that I prefer in my deck.

831
00:41:35,280 --> 00:41:36,960
Obviously this is 25 slides,

832
00:41:36,960 --> 00:41:39,360
I couldn't go through all of them,

833
00:41:39,360 --> 00:41:42,000
but I've showing you some of those ideas.

834
00:41:42,000 --> 00:41:44,352
And if you are interested,

835
00:41:44,352 --> 00:41:47,160
this demo is actually in
our GitHub repository.

836
00:41:47,160 --> 00:41:51,930
If you search AgentCore Samples GitHub,

837
00:41:51,930 --> 00:41:56,880
under Memory, you will
see this full demo code.

838
00:41:56,880 --> 00:41:59,043
And you can try and play it yourself.

839
00:42:00,030 --> 00:42:04,500
Okay, so now that we have seen this demo,

840
00:42:04,500 --> 00:42:06,510
it is using AgentCore Memory.

841
00:42:06,510 --> 00:42:10,680
Simply, I was able to
integrate, based on the APIs,

842
00:42:10,680 --> 00:42:12,660
my existing agent.

843
00:42:12,660 --> 00:42:15,240
I started with the first basic agent.

844
00:42:15,240 --> 00:42:18,630
And then I integrated
this with the memory.

845
00:42:18,630 --> 00:42:20,580
I literally called some of the APIs.

846
00:42:20,580 --> 00:42:22,863
It took me few minutes to do that.

847
00:42:23,760 --> 00:42:26,400
But then there are a lot
of other use cases as well.

848
00:42:26,400 --> 00:42:30,240
The example that I gave
you is literally related

849
00:42:30,240 --> 00:42:32,820
to the content creation example.

850
00:42:32,820 --> 00:42:35,310
So you have this on the slide, right?

851
00:42:35,310 --> 00:42:39,480
But there are way more use
cases than these six of them

852
00:42:39,480 --> 00:42:42,480
that I'm showing you on the slide deck

853
00:42:42,480 --> 00:42:44,940
because obviously there is not much space

854
00:42:44,940 --> 00:42:48,720
and not much time to talk
about all the use cases

855
00:42:48,720 --> 00:42:49,833
in this hour.

856
00:42:51,210 --> 00:42:54,360
So let's take an example of
some of the other use cases

857
00:42:54,360 --> 00:42:56,970
that might be relevant to you.

858
00:42:56,970 --> 00:42:58,800
So a quick show of hands,

859
00:42:58,800 --> 00:43:01,920
have you used coding
assistant to build your code

860
00:43:01,920 --> 00:43:03,003
like WhiteCoding?

861
00:43:04,770 --> 00:43:07,650
Okay, I see a lot of them
on the left side, center,

862
00:43:07,650 --> 00:43:08,483
and the right.

863
00:43:08,483 --> 00:43:10,350
So you are aware. Okay.

864
00:43:10,350 --> 00:43:11,910
Have you noticed this?

865
00:43:11,910 --> 00:43:14,040
When you are using the coding assistant

866
00:43:14,040 --> 00:43:16,050
and you provide all the instructions,

867
00:43:16,050 --> 00:43:17,790
it generates the code.

868
00:43:17,790 --> 00:43:21,360
Then you run the code, there
might be some issues, right?

869
00:43:21,360 --> 00:43:23,913
And then you give some
additional instructions.

870
00:43:24,840 --> 00:43:27,690
And there is one instruction specifically

871
00:43:27,690 --> 00:43:32,250
that at least I give when I
use the WhiteCoding thing,

872
00:43:32,250 --> 00:43:37,110
is make changes using
minimal lines of code.

873
00:43:37,110 --> 00:43:41,613
Do not create any new files
if they are not needed.

874
00:43:42,540 --> 00:43:46,440
Because agents usually when
you ask them to fix anything,

875
00:43:46,440 --> 00:43:48,573
they will create a bunch of test files.

876
00:43:49,500 --> 00:43:51,280
So that's like every time

877
00:43:52,260 --> 00:43:55,140
you have to type those instructions

878
00:43:55,140 --> 00:43:57,490
if your coding assistant
doesn't have a memory.

879
00:43:58,530 --> 00:44:01,983
So have you noticed that
one? Or is it just me?

880
00:44:02,970 --> 00:44:05,340
Okay, I do see some nodding heads.

881
00:44:05,340 --> 00:44:09,180
Absolutely. So that's an indication

882
00:44:09,180 --> 00:44:12,543
to integrate your coding
assistance with AgentCore Memory.

883
00:44:14,160 --> 00:44:15,480
It'll make your job easier.

884
00:44:15,480 --> 00:44:17,580
You don't have to type these instructions

885
00:44:17,580 --> 00:44:19,140
over and over again.

886
00:44:19,140 --> 00:44:21,847
And whenever you are making
an edit, you're just saying,

887
00:44:21,847 --> 00:44:23,460
"Oh, edit this file?"

888
00:44:23,460 --> 00:44:24,903
How cool will that be?

889
00:44:25,770 --> 00:44:27,510
So that's one use case

890
00:44:27,510 --> 00:44:32,073
on how you can build a really
smart coding assistant,

891
00:44:33,177 --> 00:44:38,123
which can literally remember
your preferences, your style.

892
00:44:38,970 --> 00:44:40,920
Maybe you love coding in Python.

893
00:44:40,920 --> 00:44:43,080
So it should not generate code in Java

894
00:44:43,080 --> 00:44:45,360
or it should not continuously ask you

895
00:44:45,360 --> 00:44:48,060
which language, for example, right?

896
00:44:48,060 --> 00:44:52,440
So personal to you,
understanding your experience,

897
00:44:52,440 --> 00:44:54,480
giving you a better experience.

898
00:44:54,480 --> 00:44:57,903
And this is exactly what
you want for your customers.

899
00:44:58,980 --> 00:45:00,450
So another example,

900
00:45:00,450 --> 00:45:03,033
let's talk about a customer support agent.

901
00:45:04,140 --> 00:45:07,320
Now, with the customer support agent,

902
00:45:07,320 --> 00:45:10,440
you would call the customer
support for specific issue.

903
00:45:10,440 --> 00:45:13,650
For example, talking about a refund

904
00:45:13,650 --> 00:45:17,940
or maybe something else that
you don't like the product

905
00:45:17,940 --> 00:45:20,880
and you want a replacement, for example.

906
00:45:20,880 --> 00:45:23,220
Or you just want to complain
that it took so long

907
00:45:23,220 --> 00:45:25,080
for the product to arrive.

908
00:45:25,080 --> 00:45:28,620
So those are some of the
queries on the customer support

909
00:45:28,620 --> 00:45:30,270
for a e-commerce thing, right?

910
00:45:30,270 --> 00:45:31,680
We all do online shopping.

911
00:45:31,680 --> 00:45:33,723
So I just thought let's use that.

912
00:45:35,400 --> 00:45:39,510
Now, what you want is you
want this customer support

913
00:45:39,510 --> 00:45:41,940
to remember the past issues.

914
00:45:41,940 --> 00:45:45,420
Why? Because you want to
understand your users better.

915
00:45:45,420 --> 00:45:49,530
Is this customer having the
same issue over and over again?

916
00:45:49,530 --> 00:45:50,730
So what's going on?

917
00:45:50,730 --> 00:45:54,540
Maybe it's time that you
might want to update something

918
00:45:54,540 --> 00:45:57,810
or maybe for the agent
who's on the other side

919
00:45:57,810 --> 00:46:00,420
can quickly look and
say, "Oh, you know what,

920
00:46:00,420 --> 00:46:03,300
this is how we fix the issue in the past,

921
00:46:03,300 --> 00:46:05,520
let's do the same thing again."

922
00:46:05,520 --> 00:46:08,283
So those information becomes,

923
00:46:09,797 --> 00:46:11,940
that type of information becomes critical

924
00:46:11,940 --> 00:46:15,030
to providing good
experience to your customers

925
00:46:15,030 --> 00:46:16,950
who are on one side

926
00:46:16,950 --> 00:46:19,860
and to your agent who's
actually interacting

927
00:46:19,860 --> 00:46:23,790
with the customer and
providing a better experience.

928
00:46:23,790 --> 00:46:25,860
So memory becomes important

929
00:46:25,860 --> 00:46:28,740
because that shows how much
you care about your customers

930
00:46:28,740 --> 00:46:31,650
because you are remembering
their preferences.

931
00:46:31,650 --> 00:46:35,400
You are not just giving them
the accurate and reliable help,

932
00:46:35,400 --> 00:46:39,570
but also remembering them.

933
00:46:39,570 --> 00:46:43,140
That's the thing that you want
to give to your customers.

934
00:46:43,140 --> 00:46:46,140
So also I want to make sure that next,

935
00:46:46,140 --> 00:46:49,260
whenever you are building
an agentic application,

936
00:46:49,260 --> 00:46:52,740
think about not just
the accuracy, relevancy,

937
00:46:52,740 --> 00:46:57,420
those are very important,
absolute must things to have.

938
00:46:57,420 --> 00:47:00,360
But also think about
your customer experience.

939
00:47:00,360 --> 00:47:05,100
Also think about how you can
minimize these number of calls

940
00:47:05,100 --> 00:47:06,870
that the agent has to do,

941
00:47:06,870 --> 00:47:10,020
because that will save
you the cost also, right?

942
00:47:10,020 --> 00:47:12,750
So providing the right context

943
00:47:12,750 --> 00:47:15,213
to the agent at the right time.

944
00:47:16,710 --> 00:47:19,200
You have AgentCore Memory

945
00:47:19,200 --> 00:47:21,870
as one of the components
that will help you

946
00:47:21,870 --> 00:47:26,760
without you having to do
too much heavy lifting

947
00:47:26,760 --> 00:47:30,180
because we are taking care
of that on your behalf.

948
00:47:30,180 --> 00:47:33,120
So with that, there is a next step

949
00:47:33,120 --> 00:47:34,743
that I really want you to do.

950
00:47:35,940 --> 00:47:40,260
What we have presented today
is actually the beginning.

951
00:47:40,260 --> 00:47:42,180
It's not the end of the presentation,

952
00:47:42,180 --> 00:47:44,100
it's literally the beginning.

953
00:47:44,100 --> 00:47:48,930
There is more to come and
more to be seen and heard

954
00:47:48,930 --> 00:47:50,520
at this re:Invent.

955
00:47:50,520 --> 00:47:55,463
So I invite you to join
keynote by Dr. Swami

956
00:47:56,970 --> 00:47:59,850
who will be talking about the new features

957
00:47:59,850 --> 00:48:00,810
that we'll be launching

958
00:48:00,810 --> 00:48:05,403
across our agent code line
of products or services.

959
00:48:06,720 --> 00:48:11,130
And also I want to invite you

960
00:48:11,130 --> 00:48:13,620
to build one of these use cases,

961
00:48:13,620 --> 00:48:16,260
connect with us, either on LinkedIn,

962
00:48:16,260 --> 00:48:19,740
or shoot us an email or reach
out to your account teams,

963
00:48:19,740 --> 00:48:22,290
and they can connect you with us.

964
00:48:22,290 --> 00:48:25,980
And I'm so excited to hear your stories

965
00:48:25,980 --> 00:48:29,730
and understand what you are building next.

966
00:48:29,730 --> 00:48:31,680
So with that, thank you so much

967
00:48:31,680 --> 00:48:33,600
for your time today early morning.

968
00:48:33,600 --> 00:48:37,830
And I know it's difficult
to get up, but you are here.

969
00:48:37,830 --> 00:48:41,310
So thank you. Thank you.

970
00:48:41,310 --> 00:48:43,462
And thank you for that.

971
00:48:43,462 --> 00:48:46,629
(audience applauding)

