1
00:00:01,949 --> 00:00:04,230
Hey folks, um, great to, great to see y'all,

2
00:00:04,389 --> 00:00:06,578
uh, really excited to be here. My name's Russell

3
00:00:06,578 --> 00:00:09,060
Kaplan, co-founder, president at Cognition,

4
00:00:09,349 --> 00:00:11,569
and, uh, today we wanted to talk about, uh, just

5
00:00:11,710 --> 00:00:13,750
building with agents and what we're seeing in real

6
00:00:13,750 --> 00:00:16,030
world enterprises, uh, adopting

7
00:00:16,030 --> 00:00:18,309
AI for software engineering, what's working,

8
00:00:18,429 --> 00:00:20,568
what's not working, and, uh, sharing

9
00:00:20,568 --> 00:00:21,158
some details.

10
00:00:21,429 --> 00:00:23,469
Uh, before we get into it, I guess, can you raise your hand?

11
00:00:23,589 --> 00:00:24,609
Have, has, uh,

12
00:00:24,908 --> 00:00:27,039
if you've ever heard of Cognition or Devon

13
00:00:27,039 --> 00:00:28,089
or Windsurf before.

14
00:00:29,739 --> 00:00:32,139
Great. OK, basically, everyone, um, so for,

15
00:00:32,179 --> 00:00:34,639
uh, for those who, who haven't heard of us, uh,

16
00:00:34,819 --> 00:00:37,380
we are an AI software

17
00:00:37,380 --> 00:00:39,658
engineering company, uh, an agent lab.

18
00:00:39,819 --> 00:00:40,359
We started,

19
00:00:40,719 --> 00:00:42,000
uh, almost 2 years ago

20
00:00:42,380 --> 00:00:43,959
originally as a research lab

21
00:00:44,219 --> 00:00:46,259
focused on long-term reasoning and

22
00:00:46,259 --> 00:00:48,539
planning. Uh, we're lucky to work with many

23
00:00:48,539 --> 00:00:50,770
of the largest, most sophisticated enterprises

24
00:00:50,770 --> 00:00:53,000
in the world, uh, as well as thousands of companies

25
00:00:53,418 --> 00:00:54,500
globally, um.

26
00:00:55,090 --> 00:00:57,149
When we got started, it was really out of a,

27
00:00:57,158 --> 00:00:59,158
a love of software engineering,

28
00:00:59,319 --> 00:01:01,329
uh, and programming. Many of the folks on the

29
00:01:01,329 --> 00:01:02,348
founding team are

30
00:01:02,609 --> 00:01:04,888
competitive, uh, programmers by training.

31
00:01:05,129 --> 00:01:07,329
I joke that Scott is the CEO

32
00:01:07,329 --> 00:01:09,338
because he has the most gold medals on the team.

33
00:01:09,448 --> 00:01:11,540
Uh, he's the most in the history of the United States.

34
00:01:11,730 --> 00:01:13,808
Uh, he's actually still the coach for the US national

35
00:01:13,808 --> 00:01:15,888
team on the side. Um, so it's a bunch of people who

36
00:01:15,888 --> 00:01:16,750
really love to code

37
00:01:17,129 --> 00:01:17,980
and, um,

38
00:01:18,418 --> 00:01:20,439
we. Noticed

39
00:01:20,439 --> 00:01:23,379
in the sort of end of 2023 early 2024

40
00:01:23,689 --> 00:01:25,969
that AI has made lots

41
00:01:25,969 --> 00:01:28,209
of progress in chat and

42
00:01:28,209 --> 00:01:30,448
real-time interfaces, uh, but

43
00:01:30,448 --> 00:01:32,730
reasoning was really falling behind and you couldn't really

44
00:01:32,730 --> 00:01:34,730
give real world long

45
00:01:34,730 --> 00:01:36,870
term end to end work to AI systems

46
00:01:37,049 --> 00:01:38,349
and have this work actually well

47
00:01:38,730 --> 00:01:41,058
so we started cognition originally as a reason. lab

48
00:01:41,430 --> 00:01:43,510
focused on, uh, long term thinking,

49
00:01:43,599 --> 00:01:45,609
planning in the context of

50
00:01:45,790 --> 00:01:47,790
software engineering, um, and it's been a

51
00:01:47,790 --> 00:01:49,198
really exciting journey so far.

52
00:01:49,510 --> 00:01:51,689
Uh, we are now nearly 200 people

53
00:01:51,790 --> 00:01:53,829
with several offices around the world. Uh, we've

54
00:01:53,829 --> 00:01:55,909
raised about $700 million most recently at

55
00:01:55,909 --> 00:01:57,329
a $10 billion evaluation,

56
00:01:57,888 --> 00:01:59,948
uh, and we're deployed at, uh, a lot of great companies

57
00:01:59,948 --> 00:02:01,388
including some of the folks in this room.

58
00:02:03,379 --> 00:02:04,409
One thing we've seen

59
00:02:04,730 --> 00:02:06,028
is that the ability

60
00:02:06,409 --> 00:02:08,808
of AI to code well

61
00:02:09,129 --> 00:02:11,258
has been increasing significantly

62
00:02:11,258 --> 00:02:13,808
uh since the beginning of AI

63
00:02:13,808 --> 00:02:15,349
products in software engineering.

64
00:02:15,710 --> 00:02:17,520
And there's lots of different ways to measure this.

65
00:02:17,960 --> 00:02:20,240
This is just one example. This is the

66
00:02:20,240 --> 00:02:21,740
merge rate of

67
00:02:22,000 --> 00:02:24,038
Devon pull requests. So every time

68
00:02:24,038 --> 00:02:26,479
someone gives Devin, the AI software

69
00:02:26,479 --> 00:02:27,550
engineer that we make,

70
00:02:27,979 --> 00:02:29,278
um, a task to go do,

71
00:02:29,599 --> 00:02:31,679
that task will result in a pull request, and it

72
00:02:31,679 --> 00:02:33,159
will be automatically submitted.

73
00:02:33,460 --> 00:02:35,558
Uh, and up for a human to review

74
00:02:35,860 --> 00:02:37,879
and we, this, this rate at which these,

75
00:02:38,099 --> 00:02:40,330
these, uh, requests are getting merged is, is steadily

76
00:02:40,330 --> 00:02:42,919
increasing and it's doubled to, uh, almost 70%

77
00:02:43,058 --> 00:02:45,058
over, over the last year, um, and these

78
00:02:45,058 --> 00:02:47,118
workloads are, you know, these are not one

79
00:02:47,118 --> 00:02:48,599
line fixes, these are kind of

80
00:02:48,899 --> 00:02:51,020
4 to 8 hour typically like

81
00:02:51,020 --> 00:02:53,149
junior engineering to mid-level

82
00:02:53,149 --> 00:02:55,460
engineering scope tasks on real

83
00:02:55,460 --> 00:02:57,500
world, uh, production code

84
00:02:57,500 --> 00:02:59,538
base, but what we've

85
00:02:59,538 --> 00:03:01,699
seen is that in the kind of broader ecosystem.

86
00:03:02,550 --> 00:03:04,710
Most teams in industry are

87
00:03:04,710 --> 00:03:06,868
significantly uh behind

88
00:03:06,868 --> 00:03:08,528
using the full potential

89
00:03:08,788 --> 00:03:10,788
of AI for software

90
00:03:10,788 --> 00:03:11,330
engineering

91
00:03:11,588 --> 00:03:13,508
and today we wanna talk about why we think that is

92
00:03:13,788 --> 00:03:15,729
what are the important ingredients to change that

93
00:03:16,028 --> 00:03:18,250
and where are some examples of this already working really well

94
00:03:18,580 --> 00:03:19,569
at scale,

95
00:03:20,149 --> 00:03:22,229
um. To put this in perspective,

96
00:03:22,308 --> 00:03:24,550
I think you could really view the

97
00:03:24,550 --> 00:03:27,028
progress of AI tooling and software engineering

98
00:03:27,308 --> 00:03:28,849
over sort of three waves,

99
00:03:29,250 --> 00:03:31,729
uh, and the first was really like, uh,

100
00:03:31,868 --> 00:03:33,868
the kind of co-pilot tab

101
00:03:33,868 --> 00:03:35,909
completion style way where you're in

102
00:03:35,909 --> 00:03:38,288
your editor, you're writing some code, and you get a prediction.

103
00:03:39,278 --> 00:03:41,360
What, uh, you know, what code should come next.

104
00:03:41,409 --> 00:03:43,409
It's a very real-time synchronous experience,

105
00:03:43,710 --> 00:03:45,889
uh, for a sort of line by line, uh,

106
00:03:45,909 --> 00:03:48,189
programming or function by function programming, and this

107
00:03:48,189 --> 00:03:50,028
already was an amazing product experience.

108
00:03:50,349 --> 00:03:52,429
GitHub copilot really led the way in this, and it's

109
00:03:52,429 --> 00:03:54,508
been used by many, many folks all around

110
00:03:54,508 --> 00:03:56,569
the world for real productivity gains.

111
00:03:57,360 --> 00:03:59,219
The second wave has been

112
00:03:59,679 --> 00:04:01,800
full AI IDEs, so

113
00:04:01,800 --> 00:04:04,080
no longer just tab completion, but

114
00:04:04,080 --> 00:04:06,118
a completely sort of a new

115
00:04:06,118 --> 00:04:08,199
development environment built for the ground

116
00:04:08,199 --> 00:04:10,360
up for leveraging AI

117
00:04:10,360 --> 00:04:12,399
at every turn, both for tab completion

118
00:04:12,399 --> 00:04:14,520
but also for chat, for code-based understanding,

119
00:04:14,758 --> 00:04:17,040
uh, for local synchronous agents working

120
00:04:17,040 --> 00:04:19,119
with you for documentation, uh,

121
00:04:19,199 --> 00:04:21,238
for all of the sort of ways you could get leverage

122
00:04:21,238 --> 00:04:22,379
from AI at every turn,

123
00:04:22,759 --> 00:04:25,040
um. The third wave,

124
00:04:25,199 --> 00:04:27,399
which is really the most recent, is

125
00:04:27,399 --> 00:04:29,838
the full AI software

126
00:04:29,838 --> 00:04:32,160
engineer. So this is more co-worker

127
00:04:32,160 --> 00:04:34,199
than co-pilot, something you delegate

128
00:04:34,199 --> 00:04:36,738
complete units of work to, maybe going directly

129
00:04:36,738 --> 00:04:37,738
from a ticket

130
00:04:38,000 --> 00:04:40,500
to a full finished pull request,

131
00:04:40,850 --> 00:04:42,278
um, and

132
00:04:42,608 --> 00:04:44,720
what we've seen is that across these different ways of

133
00:04:44,720 --> 00:04:45,928
working. Uh,

134
00:04:46,290 --> 00:04:48,329
these types of systems are already having

135
00:04:48,329 --> 00:04:50,389
meaningful real impact at scale

136
00:04:50,809 --> 00:04:52,970
in the enterprise, um, as some

137
00:04:52,970 --> 00:04:54,850
examples from our customer customer base,

138
00:04:55,199 --> 00:04:57,528
one top five global bank measured a roughly

139
00:04:57,528 --> 00:04:59,608
16x faster migration timeline

140
00:04:59,608 --> 00:05:01,970
for 40,000 legacy ETL framework

141
00:05:01,970 --> 00:05:02,670
files going,

142
00:05:02,928 --> 00:05:03,928
uh, to Java.

143
00:05:04,309 --> 00:05:06,358
Another example is test coverage automation

144
00:05:06,358 --> 00:05:08,459
and improvement, top 3 global retailer

145
00:05:08,559 --> 00:05:11,059
measuring at least 90% of system coverage,

146
00:05:11,199 --> 00:05:13,678
uh, system testing coverage after

147
00:05:13,678 --> 00:05:16,040
using AI to improve both unit

148
00:05:16,040 --> 00:05:18,160
and end to end integration tests

149
00:05:18,160 --> 00:05:20,619
written automatically by AI coding agents.

150
00:05:21,079 --> 00:05:23,079
Um, a third example is, um.

151
00:05:23,699 --> 00:05:25,699
Documentation and indexing and

152
00:05:25,699 --> 00:05:26,759
code-based understanding,

153
00:05:27,019 --> 00:05:29,399
um, one of the largest banks in the world has

154
00:05:29,540 --> 00:05:31,588
more than 300,000 repositories

155
00:05:31,588 --> 00:05:33,160
documented automatically

156
00:05:33,459 --> 00:05:35,579
by cognition, uh, and this

157
00:05:35,579 --> 00:05:37,579
includes very legacy systems as well as very

158
00:05:37,579 --> 00:05:38,480
modern systems,

159
00:05:38,750 --> 00:05:40,819
um. And we're also seeing this

160
00:05:41,040 --> 00:05:43,160
in Project Velocity, so a Fortune

161
00:05:43,160 --> 00:05:45,178
5 healthcare, uh, company that's getting

162
00:05:45,439 --> 00:05:47,480
a multi-X improvement in product velocity

163
00:05:47,480 --> 00:05:49,519
as measured from the beginning of when

164
00:05:49,519 --> 00:05:51,600
you start up the project to when it's going

165
00:05:51,600 --> 00:05:53,920
to ship, how you would have done it the old way, how

166
00:05:53,920 --> 00:05:55,119
you are doing it the new way.

167
00:05:56,338 --> 00:05:58,459
Um, and so some of these companies are doing really

168
00:05:58,459 --> 00:06:00,608
well, basically deploying these systems and getting

169
00:06:00,608 --> 00:06:01,920
real value to them at scale,

170
00:06:02,420 --> 00:06:04,858
and we've worked with many such companies now, more than 1000

171
00:06:04,858 --> 00:06:05,899
enterprises around the world,

172
00:06:06,178 --> 00:06:07,838
and we've noticed a few patterns

173
00:06:08,100 --> 00:06:10,100
that are common among the folks

174
00:06:10,100 --> 00:06:12,540
who are the most successful at deploying

175
00:06:12,540 --> 00:06:13,119
and using

176
00:06:13,420 --> 00:06:15,540
AI. So we're gonna talk about what these

177
00:06:15,540 --> 00:06:17,738
patterns are from the product and rollout

178
00:06:17,738 --> 00:06:18,399
perspective

179
00:06:18,778 --> 00:06:20,939
and what they are from the change management perspective

180
00:06:20,939 --> 00:06:21,519
as well.

181
00:06:22,059 --> 00:06:23,639
So first, the deployment patterns.

182
00:06:24,278 --> 00:06:26,358
The first is a recognition that

183
00:06:26,548 --> 00:06:28,850
different forms of AI for software engineering

184
00:06:28,850 --> 00:06:30,850
have different fundamental technical

185
00:06:30,850 --> 00:06:33,250
trade-offs, and so multiple modes

186
00:06:33,250 --> 00:06:35,730
of using AI are actually quite important, both

187
00:06:35,730 --> 00:06:37,769
the real-time synchronous assistant

188
00:06:37,769 --> 00:06:40,088
type workflow and also the asynchronous,

189
00:06:40,170 --> 00:06:42,649
more autonomous delegation type

190
00:06:42,649 --> 00:06:43,250
workflow.

191
00:06:44,028 --> 00:06:45,259
The second is that

192
00:06:45,949 --> 00:06:48,629
understanding the existing code and context

193
00:06:48,629 --> 00:06:50,689
inside a company is really critical

194
00:06:50,869 --> 00:06:52,910
to getting true real world

195
00:06:52,910 --> 00:06:55,108
value. Um, it's, it's actually relatively

196
00:06:55,108 --> 00:06:57,189
straightforward at this point to, to build an AI system

197
00:06:57,189 --> 00:06:59,189
that can kind of prototype a new

198
00:06:59,189 --> 00:07:01,108
website or or a product from scratch. But

199
00:07:02,019 --> 00:07:04,428
to work within the context of an existing

200
00:07:04,428 --> 00:07:06,569
business that has its own requirements,

201
00:07:06,699 --> 00:07:07,970
proprietary frameworks,

202
00:07:08,298 --> 00:07:10,298
um, historical decisions that have lots

203
00:07:10,298 --> 00:07:12,639
of context that maybe no one person even has,

204
00:07:12,829 --> 00:07:15,100
um, and maybe regulatory or

205
00:07:15,100 --> 00:07:17,139
process requirements that have to get followed for code

206
00:07:17,139 --> 00:07:18,079
to be successful,

207
00:07:18,699 --> 00:07:20,699
it's a lot more complicated and we've learned

208
00:07:20,699 --> 00:07:22,879
a lot about how to do that well and not well

209
00:07:22,980 --> 00:07:25,379
and why that's really important for, um,

210
00:07:25,389 --> 00:07:26,778
driving real world results.

211
00:07:27,769 --> 00:07:29,790
The third is how do you start to use these

212
00:07:29,790 --> 00:07:30,608
AI tools

213
00:07:30,939 --> 00:07:33,149
to help improve velocity

214
00:07:33,149 --> 00:07:34,088
across the entire

215
00:07:34,588 --> 00:07:36,290
software development life cycle.

216
00:07:36,699 --> 00:07:38,709
Writing code is one part of that, but it's

217
00:07:38,709 --> 00:07:40,750
only one part of that, and the next generation

218
00:07:40,750 --> 00:07:43,230
of productivity gains to go from the 10,

219
00:07:43,238 --> 00:07:45,470
20% to the multi-X all involve

220
00:07:45,470 --> 00:07:48,009
automating entire swaths of the STLC

221
00:07:48,108 --> 00:07:50,189
for specific workloads, not just the

222
00:07:50,189 --> 00:07:50,949
writing code.

223
00:07:52,420 --> 00:07:54,528
So a little bit more on this, this first point

224
00:07:54,528 --> 00:07:56,850
of multiple modes of working with

225
00:07:56,850 --> 00:07:58,338
AI software engineering tooling.

226
00:07:59,709 --> 00:08:00,250
Uh,

227
00:08:00,709 --> 00:08:03,149
we're finding that it's relatively

228
00:08:03,149 --> 00:08:05,730
easier to adopt synchronous

229
00:08:05,988 --> 00:08:08,108
real-time AI assistance.

230
00:08:08,389 --> 00:08:10,428
Um, developers are already very comfortable in

231
00:08:10,428 --> 00:08:11,019
their IDE.

232
00:08:11,579 --> 00:08:13,899
And this paradigm of working in flow

233
00:08:13,899 --> 00:08:15,939
state writing code has been the way we write

234
00:08:15,939 --> 00:08:18,019
code for a long time, right, from, from

235
00:08:18,019 --> 00:08:20,338
Vim to modern, uh, modern IDEs

236
00:08:20,338 --> 00:08:22,619
to now agentic IDEs, you're in flow

237
00:08:22,619 --> 00:08:24,619
state in your editor writing code just

238
00:08:24,619 --> 00:08:26,750
now with leverage and speed up from AI

239
00:08:26,750 --> 00:08:28,778
systems, um, at cognition we make

240
00:08:28,778 --> 00:08:31,358
Windsurf, the, um, agentic IDE.

241
00:08:31,519 --> 00:08:33,639
It's designed to keep engineers in flow

242
00:08:33,639 --> 00:08:35,340
state as they're programming,

243
00:08:35,599 --> 00:08:37,678
and there's a fundamentally 1 to 1

244
00:08:37,678 --> 00:08:39,619
relationship between each engineer

245
00:08:39,918 --> 00:08:41,940
and their real-time AI

246
00:08:42,190 --> 00:08:42,808
assistants,

247
00:08:43,200 --> 00:08:44,859
so immediate speed ups

248
00:08:45,129 --> 00:08:47,719
very useful for, uh, challenging

249
00:08:47,719 --> 00:08:49,759
creative work where you have to be working

250
00:08:49,759 --> 00:08:51,479
hand in hand with AI to deliver outcomes.

251
00:08:52,330 --> 00:08:54,418
Increasingly, a lot of software

252
00:08:54,418 --> 00:08:55,558
engineering has become

253
00:08:55,940 --> 00:08:58,058
addressable by a completely different form factor.

254
00:08:58,440 --> 00:09:00,479
Which is the asynchronous autonomous

255
00:09:00,479 --> 00:09:02,639
delegation style model, um, you have an AI

256
00:09:02,639 --> 00:09:04,658
engineer that's actually doing the full work end to end

257
00:09:04,879 --> 00:09:07,599
from the details of the scoping to the implementation

258
00:09:07,599 --> 00:09:09,178
to the testing to the review

259
00:09:09,479 --> 00:09:11,479
to, um, the complete proposal of

260
00:09:11,479 --> 00:09:12,619
a, of a pull request,

261
00:09:12,899 --> 00:09:15,158
um, and this has different technical trade-offs, so it's

262
00:09:15,158 --> 00:09:17,239
asynchronous instead of synchronous. Uh, it's gonna

263
00:09:17,239 --> 00:09:17,899
take longer,

264
00:09:18,200 --> 00:09:20,239
but you can kick off many of these in parallel,

265
00:09:20,489 --> 00:09:22,558
um, and because it's

266
00:09:22,558 --> 00:09:23,340
asynchronous,

267
00:09:23,678 --> 00:09:24,700
uh, you can tolerate

268
00:09:25,080 --> 00:09:27,234
much longer latency. In exchange for higher degrees

269
00:09:27,234 --> 00:09:28,774
of correctness and completeness,

270
00:09:29,114 --> 00:09:30,933
um, and there's certain workloads that are

271
00:09:31,433 --> 00:09:33,783
extremely appealing for this type of software

272
00:09:33,783 --> 00:09:36,075
engineering automation. There are others where it's frankly,

273
00:09:36,215 --> 00:09:38,455
um, too hard and the systems are not yet

274
00:09:38,594 --> 00:09:39,913
good enough to do this reliably.

275
00:09:40,183 --> 00:09:42,364
Our heuristic that we found with Devon

276
00:09:42,634 --> 00:09:44,835
is that tasks that are roughly half

277
00:09:44,835 --> 00:09:46,575
day to 1 day's worth of work

278
00:09:46,835 --> 00:09:49,195
for a junior to mid-level engineer are

279
00:09:49,195 --> 00:09:51,224
about the right level of difficulty to

280
00:09:51,224 --> 00:09:53,474
delegate to any one Devon session.

281
00:09:53,940 --> 00:09:55,500
And for things that are more complicated,

282
00:09:55,788 --> 00:09:58,029
um, the human engineer is responsible for

283
00:09:58,029 --> 00:10:00,229
really breaking up that project into discrete

284
00:10:00,229 --> 00:10:02,330
components and then you can delegate it to

285
00:10:02,469 --> 00:10:04,500
an entire team of AI agents

286
00:10:04,830 --> 00:10:07,070
and in this way the role of being an

287
00:10:07,070 --> 00:10:08,408
individual software engineer

288
00:10:08,668 --> 00:10:10,779
is changing a little bit to becoming

289
00:10:10,779 --> 00:10:12,779
kind of. Like a tech lead manager where you're still writing

290
00:10:12,779 --> 00:10:15,019
some code yourself but you're also increasingly delegating

291
00:10:15,019 --> 00:10:18,239
work to your team of async AI agents

292
00:10:18,500 --> 00:10:20,538
and that's a fundamentally different work flow for

293
00:10:20,538 --> 00:10:22,538
a lot of folks, uh, and it means that to roll this

294
00:10:22,538 --> 00:10:24,619
out successfully there's a kind of a learning

295
00:10:24,619 --> 00:10:26,399
curve and an organizational change element

296
00:10:26,658 --> 00:10:28,080
that's really important as well.

297
00:10:29,210 --> 00:10:31,678
Um, so how are we actually building towards this, uh,

298
00:10:32,019 --> 00:10:34,340
uh, with Windsurf we're very, very focused

299
00:10:34,340 --> 00:10:36,418
on speed, keeping people in flow

300
00:10:36,418 --> 00:10:38,580
state. One of the first observations we

301
00:10:38,580 --> 00:10:40,899
found is that modern models make tough

302
00:10:40,899 --> 00:10:43,139
trade-offs between intelligence and

303
00:10:43,139 --> 00:10:45,500
speed. Uh, you can use frontier models,

304
00:10:45,668 --> 00:10:47,879
uh, relatively slow token per second rate, and

305
00:10:47,879 --> 00:10:50,158
you're kind of waiting for a response from your chat

306
00:10:50,158 --> 00:10:52,239
or from code suggestions, and those

307
00:10:52,239 --> 00:10:54,239
few seconds really add up. They can interrupt

308
00:10:54,239 --> 00:10:56,178
your flow state. They can get you distracted.

309
00:10:56,440 --> 00:10:58,479
It's sort of the modern day equivalent of I'm waiting for

310
00:10:58,479 --> 00:10:59,418
my code to compile.

311
00:10:59,908 --> 00:11:02,279
Um, uh, on the other hand, historically,

312
00:11:02,519 --> 00:11:04,599
very, very fast models have had to make severe

313
00:11:04,599 --> 00:11:06,418
intelligence trade-offs to make them run quickly.

314
00:11:06,979 --> 00:11:08,210
Um, we've done a lot of work

315
00:11:08,548 --> 00:11:11,129
building in-house RL models at cognition

316
00:11:11,428 --> 00:11:13,548
to try to balance the best of both

317
00:11:13,548 --> 00:11:15,590
worlds, and we recently released a new

318
00:11:15,590 --> 00:11:17,629
model family called Suite 1.5

319
00:11:17,950 --> 00:11:20,000
which is achieving roughly

320
00:11:20,000 --> 00:11:22,330
frontier class performance on

321
00:11:22,529 --> 00:11:24,548
the, the sort of state of the art industry benchmark

322
00:11:24,548 --> 00:11:26,869
for. Agentic coding which is called Swi Bench

323
00:11:26,869 --> 00:11:29,029
Pro so you can see, uh, in this,

324
00:11:29,109 --> 00:11:31,229
in this evaluation, the x axis here

325
00:11:31,229 --> 00:11:33,349
is the score on this benchmark on a

326
00:11:33,349 --> 00:11:35,548
standardized harness, and it's a little bit

327
00:11:35,548 --> 00:11:37,668
behind Sonnet 4.5. It's a little bit

328
00:11:37,668 --> 00:11:39,788
ahead of GPT, uh, of

329
00:11:39,788 --> 00:11:41,869
the sort of frontier open AI model

330
00:11:41,869 --> 00:11:42,960
series, um,

331
00:11:43,349 --> 00:11:45,509
so it's, it's not outperforming, but it's

332
00:11:45,509 --> 00:11:47,149
not underperforming on quality.

333
00:11:47,859 --> 00:11:49,908
On the other hand, on speed, it's in

334
00:11:49,908 --> 00:11:52,149
order of magnitude faster, so this is served at roughly

335
00:11:52,149 --> 00:11:53,710
950 tokens per second,

336
00:11:54,109 --> 00:11:56,408
about 10 times faster than kind of other alternatives,

337
00:11:56,700 --> 00:11:58,950
and the way we made that possible was by building a lot of

338
00:11:58,950 --> 00:12:01,109
infrastructure and modeling in-house and

339
00:12:01,109 --> 00:12:03,489
partnering with Cerebris, the maker of wafer scale

340
00:12:03,489 --> 00:12:05,590
chips, uh, which collectively allow us to

341
00:12:05,590 --> 00:12:07,330
serve these models extremely quickly.

342
00:12:07,859 --> 00:12:10,239
And because of that we get an end to end

343
00:12:10,250 --> 00:12:11,279
product experience where

344
00:12:11,619 --> 00:12:13,700
you can get results nearly as fast as you

345
00:12:13,700 --> 00:12:15,700
can think them and we found that this is the key

346
00:12:15,700 --> 00:12:18,070
for staying in flow state as you're using

347
00:12:18,139 --> 00:12:20,139
AI tools yourself, uh, to,

348
00:12:20,219 --> 00:12:21,200
to create code.

349
00:12:21,719 --> 00:12:23,918
Uh, on the other end of the spectrum you have

350
00:12:24,099 --> 00:12:26,798
the asynchronous delegation workflow,

351
00:12:27,099 --> 00:12:29,719
um, and so what's the best practice for making that

352
00:12:29,719 --> 00:12:30,519
really work inside a company.

353
00:12:30,979 --> 00:12:33,788
I'll talk through an example of a migration

354
00:12:33,788 --> 00:12:36,570
project because this is one type of workload migrations,

355
00:12:36,619 --> 00:12:38,820
modernizations, refactors that are

356
00:12:38,820 --> 00:12:41,178
especially well suited to the Devon

357
00:12:41,178 --> 00:12:42,119
form factor.

358
00:12:42,538 --> 00:12:44,658
Typically a large migration project, um,

359
00:12:44,859 --> 00:12:47,000
first has to be architected by a

360
00:12:47,000 --> 00:12:49,330
senior, uh, engineer, uh,

361
00:12:49,340 --> 00:12:51,418
from, uh, from the existing team who has

362
00:12:51,418 --> 00:12:53,619
context on everything going on in the organization and

363
00:12:53,619 --> 00:12:55,719
can make the right technical trade-offs of

364
00:12:55,979 --> 00:12:58,080
what's the desired end state we're trying to get to

365
00:12:58,460 --> 00:13:00,440
and then also what's our incremental path there.

366
00:13:01,229 --> 00:13:03,340
That part of the process is not going away

367
00:13:03,479 --> 00:13:04,019
right now.

368
00:13:04,440 --> 00:13:06,440
We need humans to architect the desired

369
00:13:06,440 --> 00:13:08,149
end state of these migrations.

370
00:13:08,678 --> 00:13:10,879
But once you've done that architecting work and

371
00:13:10,879 --> 00:13:13,038
you've kind of broken up how should this get

372
00:13:13,038 --> 00:13:15,058
done, you end up with lots of individual

373
00:13:15,058 --> 00:13:17,269
pieces. Maybe they're tickets in an Epic and Jira, uh,

374
00:13:17,359 --> 00:13:19,960
maybe they're specific, uh, ETL pipelines

375
00:13:19,960 --> 00:13:22,158
in a broader overall ecosystem. Maybe they're

376
00:13:22,158 --> 00:13:24,678
files or libraries in a monolithic repository

377
00:13:24,678 --> 00:13:26,219
where you have to do a major version upgrade,

378
00:13:26,479 --> 00:13:28,719
uh, to a, to a, to a modern, uh, a modern version.

379
00:13:29,619 --> 00:13:31,349
Once you have those individual pieces,

380
00:13:31,779 --> 00:13:34,019
that's where you can start to really get the benefit of

381
00:13:34,019 --> 00:13:36,058
delegation to autonomous AI software

382
00:13:36,058 --> 00:13:36,678
agents

383
00:13:36,940 --> 00:13:37,599
and so,

384
00:13:37,979 --> 00:13:40,119
uh, the workflow we found works best with Devon

385
00:13:40,119 --> 00:13:42,119
is after these pieces are broken up,

386
00:13:42,639 --> 00:13:44,700
you can delegate one piece to Devon

387
00:13:44,899 --> 00:13:45,840
and Devin will

388
00:13:46,099 --> 00:13:48,139
work on the specific execution

389
00:13:48,139 --> 00:13:50,580
and implementation of that narrow

390
00:13:50,580 --> 00:13:52,629
change. And because it's broken up,

391
00:13:52,808 --> 00:13:55,009
that change is actually digestible and doable

392
00:13:55,009 --> 00:13:57,090
entirely end to end again, not just the writing of the code,

393
00:13:57,330 --> 00:13:59,529
but any further gathering of specific requirements

394
00:13:59,529 --> 00:14:01,609
that need to be accounted for, the writing and the

395
00:14:01,609 --> 00:14:03,840
planning of the code, uh, and then the testing

396
00:14:03,840 --> 00:14:04,369
of the code.

397
00:14:04,960 --> 00:14:07,158
We found that uh since day one when we launched 7,

398
00:14:07,519 --> 00:14:09,519
every session runs in an isolated virtual

399
00:14:09,519 --> 00:14:12,009
machine which in addition to having a code editor

400
00:14:12,009 --> 00:14:14,080
also has a command line. It has a web

401
00:14:14,080 --> 00:14:16,200
browser. It's a full replica of the

402
00:14:16,200 --> 00:14:18,399
human development environment of the companies

403
00:14:18,399 --> 00:14:20,558
we work with and because of that, after

404
00:14:20,558 --> 00:14:21,210
the code is written,

405
00:14:21,519 --> 00:14:23,558
the code can be tested whether it's using existing tests

406
00:14:23,558 --> 00:14:25,594
that are. Exists inside the organization or

407
00:14:25,594 --> 00:14:27,634
having Devin write new tests to check its own work

408
00:14:27,994 --> 00:14:30,154
even if there are no tests we found, you know, Devin can

409
00:14:30,154 --> 00:14:32,274
do pixel level interaction on these

410
00:14:32,274 --> 00:14:34,494
systems so that you end up understanding

411
00:14:34,715 --> 00:14:36,715
does uh does this new website actually work

412
00:14:36,715 --> 00:14:39,014
when you click with it does this new desktop app actually work

413
00:14:39,315 --> 00:14:41,384
and the result of that might be, hey, it didn't work on the

414
00:14:41,384 --> 00:14:41,913
first try,

415
00:14:42,195 --> 00:14:42,793
but that's OK.

416
00:14:43,308 --> 00:14:45,668
Because this is an asynchronous form factor,

417
00:14:45,859 --> 00:14:47,899
so Devon can notice that and then fix its

418
00:14:47,899 --> 00:14:49,899
code, test itself again, fix its code, test

419
00:14:49,899 --> 00:14:50,450
itself again

420
00:14:50,750 --> 00:14:52,830
until it gets to a state where it's very confident the

421
00:14:52,830 --> 00:14:53,849
change is correct.

422
00:14:54,349 --> 00:14:56,500
Only when you're at that point is that change served

423
00:14:56,500 --> 00:14:58,599
up as a ready to review pull

424
00:14:58,599 --> 00:15:00,609
request for the human software engineer,

425
00:15:01,029 --> 00:15:03,690
and this can be paralyzed across many,

426
00:15:03,739 --> 00:15:05,950
many projects, uh, many, many components of the overall

427
00:15:05,950 --> 00:15:06,879
larger project in parallel.

428
00:15:08,029 --> 00:15:10,109
So this is the workflow that we're seeing for

429
00:15:10,109 --> 00:15:12,469
really deploying asynchronous autonomous

430
00:15:12,469 --> 00:15:14,548
software engineering agents at scale in a way

431
00:15:14,548 --> 00:15:16,769
that drives really measurable impact.

432
00:15:18,570 --> 00:15:20,808
If you imagine the day in the life of a software

433
00:15:20,808 --> 00:15:22,928
engineer who's fully embraced this modern

434
00:15:22,928 --> 00:15:24,099
suite of AI tooling,

435
00:15:24,418 --> 00:15:26,489
you might start out in the morning, the beginning of your

436
00:15:26,489 --> 00:15:28,519
day, planning out the work

437
00:15:28,519 --> 00:15:29,450
that needs to get done,

438
00:15:29,710 --> 00:15:31,769
uh, delegating some tasks to your

439
00:15:31,769 --> 00:15:33,840
asynchronous agents, scoping some

440
00:15:33,840 --> 00:15:35,928
things in more detail so that they're sufficiently broken

441
00:15:35,928 --> 00:15:37,989
up, and firing off a lot of these things

442
00:15:37,989 --> 00:15:38,649
in parallel.

443
00:15:39,259 --> 00:15:41,288
Once those things are working, uh,

444
00:15:41,418 --> 00:15:43,590
then you can sit down and actually start coding yourself,

445
00:15:43,820 --> 00:15:45,960
uh, in Windsurf or whatever tool you choose

446
00:15:46,139 --> 00:15:48,619
to have that flow state quick interaction

447
00:15:48,619 --> 00:15:50,538
with systems, especially for the more complicated,

448
00:15:50,979 --> 00:15:52,979
complex projects or projects that aren't

449
00:15:52,979 --> 00:15:55,058
really scoped like complex greenfield development

450
00:15:55,058 --> 00:15:57,099
where you're kind of building, you're, you're discovering and

451
00:15:57,099 --> 00:15:58,519
you're building as you go,

452
00:15:58,859 --> 00:16:00,460
but critically in this future mode of working.

453
00:16:00,840 --> 00:16:03,090
If you don't also have those asynchronous agents

454
00:16:03,090 --> 00:16:04,038
working in the background,

455
00:16:04,369 --> 00:16:06,058
you're, you're not being very efficient with your time

456
00:16:06,399 --> 00:16:08,649
because you could have also at the same time been delegating

457
00:16:08,649 --> 00:16:09,548
this work to others.

458
00:16:09,849 --> 00:16:12,048
It actually reminds me of my time previously

459
00:16:12,048 --> 00:16:13,989
where I was at Tesla on the autopilot team

460
00:16:14,320 --> 00:16:16,330
as a kind of computer vision scientist working on

461
00:16:16,330 --> 00:16:18,389
training neural networks for the self-driving system.

462
00:16:18,750 --> 00:16:20,788
And we had a rule of thumb internally that

463
00:16:20,950 --> 00:16:21,489
you can never

464
00:16:21,950 --> 00:16:23,820
go to bed with the GPUs idling

465
00:16:24,190 --> 00:16:26,519
because you're wasting tremendous amounts of compute,

466
00:16:26,668 --> 00:16:28,918
uh, where the models could be working while you're sleeping,

467
00:16:29,190 --> 00:16:31,190
and I think what we're gonna see in software engineering is kind of the

468
00:16:31,190 --> 00:16:33,379
same type of concept applied, uh,

469
00:16:33,389 --> 00:16:35,469
to working with asynchronous agents as well. The

470
00:16:35,469 --> 00:16:37,729
agent should be working while you are working too.

471
00:16:38,190 --> 00:16:40,349
And then it's time to check that work. Maybe after

472
00:16:40,349 --> 00:16:42,369
your lunch break you look at the PRs, ready

473
00:16:42,369 --> 00:16:44,658
to review. You leave some feedback. Some are ready to merge,

474
00:16:44,908 --> 00:16:46,349
and then you can go back to your own coding.

475
00:16:46,700 --> 00:16:48,700
Uh, your own approvals, your own merging, and

476
00:16:48,700 --> 00:16:49,798
then the delegation again.

477
00:16:50,340 --> 00:16:52,700
This is the workflow of the most productive software

478
00:16:52,700 --> 00:16:54,918
engineers that we see in the organizations

479
00:16:54,979 --> 00:16:55,639
we work with,

480
00:16:55,899 --> 00:16:58,239
the mix of synchronous and asynchronous

481
00:16:58,239 --> 00:16:59,178
AI collaboration.

482
00:17:01,090 --> 00:17:03,119
One important lesson is that you have to

483
00:17:03,119 --> 00:17:05,430
really pick a side, synchronous or asynchronous,

484
00:17:05,479 --> 00:17:06,519
for any given workflow,

485
00:17:06,920 --> 00:17:08,959
and the worst experience is what we call

486
00:17:08,959 --> 00:17:10,939
the semi- async valley of death.

487
00:17:11,348 --> 00:17:13,660
It's, uh, those tasks that maybe take

488
00:17:14,338 --> 00:17:16,400
a few minutes, 1 minute, 2 minutes. It's enough

489
00:17:16,400 --> 00:17:18,680
time that you can't stay in flow state anymore,

490
00:17:18,959 --> 00:17:21,039
uh, but it's not so much time that you're getting the full

491
00:17:21,039 --> 00:17:22,059
benefits of

492
00:17:22,709 --> 00:17:23,838
independent autonomy.

493
00:17:24,568 --> 00:17:26,733
Um, it's. OK to make things run for a very long

494
00:17:26,733 --> 00:17:28,904
time if by the time those changes come back

495
00:17:29,055 --> 00:17:31,334
we're confident that they're likely to be correct, it's

496
00:17:31,334 --> 00:17:33,525
also OK to work closely hand in hand with AI

497
00:17:33,525 --> 00:17:34,154
systems yourself.

498
00:17:34,614 --> 00:17:36,775
The semi- async valley of death is what you need to

499
00:17:36,775 --> 00:17:38,493
avoid, and we've tried to build our product suite,

500
00:17:39,134 --> 00:17:41,213
really embracing that, making different technical trade-offs for

501
00:17:41,213 --> 00:17:42,934
the different surfaces that we work with.

502
00:17:44,779 --> 00:17:45,650
The second pattern

503
00:17:45,989 --> 00:17:46,630
is that

504
00:17:46,949 --> 00:17:49,068
it's really important for agents to

505
00:17:49,068 --> 00:17:51,029
understand the existing code.

506
00:17:51,989 --> 00:17:54,259
This is, I think, the single biggest

507
00:17:54,259 --> 00:17:55,118
rate limiter

508
00:17:55,479 --> 00:17:57,920
on overall software engineering productivity,

509
00:17:58,259 --> 00:17:59,219
certainly for AI.

510
00:17:59,559 --> 00:18:01,500
I would argue probably for humans as well.

511
00:18:01,838 --> 00:18:03,920
This is one of the central challenges of scaling engineering

512
00:18:03,920 --> 00:18:06,289
velocity as the organization gets larger.

513
00:18:06,588 --> 00:18:08,608
No one person. Has all the context of what's

514
00:18:08,608 --> 00:18:11,029
going on. There are decisions that are made. There's historical

515
00:18:11,029 --> 00:18:13,250
details that are unclear, and

516
00:18:13,250 --> 00:18:15,430
a huge amount of time is spent gathering that

517
00:18:15,430 --> 00:18:17,269
context, groing new systems,

518
00:18:17,559 --> 00:18:19,680
onboarding and ramping as a new engineer to a new

519
00:18:19,680 --> 00:18:21,838
part of the code base. Um, and the same is

520
00:18:21,838 --> 00:18:22,500
true of AI.

521
00:18:23,239 --> 00:18:25,479
In AI, this, the issue is sufficiently

522
00:18:25,479 --> 00:18:26,939
exac exacerbated

523
00:18:27,400 --> 00:18:29,479
because models have limited context windows.

524
00:18:30,000 --> 00:18:32,078
And so if you're just working with an LLM

525
00:18:32,078 --> 00:18:34,098
as opposed to an agent, you'll run

526
00:18:34,098 --> 00:18:34,818
into this issue

527
00:18:35,328 --> 00:18:36,660
extremely quickly. Even

528
00:18:36,959 --> 00:18:38,180
most agents today

529
00:18:38,479 --> 00:18:40,219
very clearly struggle with

530
00:18:40,719 --> 00:18:42,900
working on larger, more complex systems,

531
00:18:42,910 --> 00:18:43,979
brownfield development

532
00:18:44,439 --> 00:18:46,549
because of this fundamental lack of understanding,

533
00:18:46,598 --> 00:18:47,559
this lack of context.

534
00:18:48,088 --> 00:18:50,318
And we recognized that this was a central challenge to building

535
00:18:50,318 --> 00:18:51,459
agents that provide useful

536
00:18:51,719 --> 00:18:52,529
real world work.

537
00:18:52,799 --> 00:18:54,828
And so earlier in 2025, uh,

538
00:18:54,880 --> 00:18:56,880
we released a product called Deep Wiki,

539
00:18:57,160 --> 00:18:57,838
which is an

540
00:18:58,239 --> 00:19:00,420
indexing and understanding of

541
00:19:00,529 --> 00:19:02,559
the macro scale context of

542
00:19:02,559 --> 00:19:03,420
your code base.

543
00:19:03,868 --> 00:19:06,160
Uh, this product surface is deployed at

544
00:19:06,160 --> 00:19:08,459
very, very large scale, for example, tens to hundreds

545
00:19:08,459 --> 00:19:10,000
of millions of lines of code,

546
00:19:10,259 --> 00:19:12,759
um, and these are, these are repositories

547
00:19:12,759 --> 00:19:14,019
that could be.

548
00:19:14,739 --> 00:19:15,979
Thrown into an LLM

549
00:19:16,309 --> 00:19:17,568
and use this context,

550
00:19:17,910 --> 00:19:19,959
we built this product experience originally

551
00:19:19,959 --> 00:19:22,170
entirely as an internal tool

552
00:19:22,549 --> 00:19:24,789
for Deb so that Devon could have

553
00:19:24,789 --> 00:19:26,868
macro context on the code

554
00:19:26,868 --> 00:19:28,049
base it was working on

555
00:19:28,390 --> 00:19:29,269
as it was working.

556
00:19:29,689 --> 00:19:32,000
And we found that this tool was so useful

557
00:19:32,000 --> 00:19:32,739
for improving

558
00:19:33,059 --> 00:19:34,759
Devon and later Windsurf's performance

559
00:19:35,140 --> 00:19:37,239
that the human engineers on our team got jealous

560
00:19:37,500 --> 00:19:39,640
and said we, we, we want to use this too,

561
00:19:40,059 --> 00:19:42,170
and we eventually decided let's, let's put a front end

562
00:19:42,170 --> 00:19:43,680
around it, uh, and make it available

563
00:19:44,059 --> 00:19:46,358
and that's what became. DeepWiki and today DeepWiki

564
00:19:46,358 --> 00:19:48,439
is available globally free uh for

565
00:19:48,439 --> 00:19:50,500
all open source repos. You can change

566
00:19:50,500 --> 00:19:52,809
the GitHub URL of any repo to

567
00:19:52,818 --> 00:19:55,068
DeepWiki.com instead of GitHub.com

568
00:19:55,068 --> 00:19:56,059
and try it yourself

569
00:19:56,318 --> 00:19:58,358
and it's also available for all the private code bases

570
00:19:58,358 --> 00:20:00,219
we work with across our customers.

571
00:20:00,559 --> 00:20:01,739
And I wanna show you an example

572
00:20:02,000 --> 00:20:04,299
of what this looks like in practice,

573
00:20:04,750 --> 00:20:06,078
um, so here.

574
00:20:06,750 --> 00:20:08,989
I have a video of pulling

575
00:20:08,989 --> 00:20:10,088
up a very fun

576
00:20:10,368 --> 00:20:12,219
repo with lots of tricky contexts,

577
00:20:12,509 --> 00:20:14,709
the original Apollo 11 source

578
00:20:14,709 --> 00:20:17,289
code. So this is uh Apollo 11

579
00:20:17,289 --> 00:20:19,348
assembly code that was written many

580
00:20:19,348 --> 00:20:20,858
years ago for the Apollo missions,

581
00:20:21,229 --> 00:20:23,309
and Deep Wiki has gone and indexed this

582
00:20:23,309 --> 00:20:25,430
code and provided what's essentially a living

583
00:20:25,430 --> 00:20:27,358
breathing confluence page for the repo

584
00:20:27,828 --> 00:20:28,608
where, um,

585
00:20:28,949 --> 00:20:31,140
modules, architecture diagrams,

586
00:20:31,390 --> 00:20:33,910
macro context is all documented automatically.

587
00:20:34,269 --> 00:20:35,709
And we look at the code,

588
00:20:36,029 --> 00:20:38,150
not just the comments, because we found that

589
00:20:38,150 --> 00:20:40,358
the comments often drift from the code

590
00:20:40,469 --> 00:20:43,108
and are an unreliable source of truth in a large scale

591
00:20:43,108 --> 00:20:45,309
organization. You can look into specific modules,

592
00:20:45,549 --> 00:20:47,818
get more detail, um, see the data flow,

593
00:20:48,029 --> 00:20:49,910
the, um, the interface contracts,

594
00:20:50,219 --> 00:20:52,640
and, uh, really go into a lot of detail.

595
00:20:52,949 --> 00:20:55,189
But sometimes you actually want to ask questions about the codebase

596
00:20:55,189 --> 00:20:57,449
itself and so we built that experience as well.

597
00:20:57,930 --> 00:21:00,469
Uh, here we're asking where is the liftoff sequence

598
00:21:00,469 --> 00:21:02,588
for the Apollo mission actually implemented.

599
00:21:03,068 --> 00:21:05,108
And uh DeepWK has gone through the

600
00:21:05,108 --> 00:21:07,108
code. It's found the specific key

601
00:21:07,108 --> 00:21:09,150
component that's most relevant. It's the P11

602
00:21:09,150 --> 00:21:09,680
component,

603
00:21:10,160 --> 00:21:12,189
uh, and it walks through how liftoff detection works

604
00:21:12,189 --> 00:21:12,930
line by line

605
00:21:13,269 --> 00:21:15,549
with the relevant assembly on the side

606
00:21:15,549 --> 00:21:17,689
as well. So you can validate the work of the AI

607
00:21:17,689 --> 00:21:20,009
again in this like synchronous flow state experience.

608
00:21:20,469 --> 00:21:22,630
And here you can see in even more

609
00:21:22,630 --> 00:21:24,709
detail what we call a code map.

610
00:21:25,759 --> 00:21:28,880
Code map is a human interpretable

611
00:21:28,880 --> 00:21:29,818
representation

612
00:21:30,199 --> 00:21:32,519
of what would otherwise be considered very

613
00:21:32,519 --> 00:21:34,608
complex control flow in code to

614
00:21:34,608 --> 00:21:35,348
follow along.

615
00:21:35,680 --> 00:21:38,039
So you can see on the left, uh, we have

616
00:21:38,039 --> 00:21:40,150
a prose summary of the overall liftoff

617
00:21:40,150 --> 00:21:40,739
sequence

618
00:21:41,049 --> 00:21:43,439
and then this indented nested, uh,

619
00:21:43,449 --> 00:21:45,640
kind of like pseudo code documentation

620
00:21:45,640 --> 00:21:47,900
for how the different components of this process

621
00:21:47,900 --> 00:21:50,019
work. On the right you see

622
00:21:50,219 --> 00:21:50,880
the assembly.

623
00:21:51,640 --> 00:21:53,019
And these are mapped together.

624
00:21:53,519 --> 00:21:55,959
This code map experience, it lets engineers

625
00:21:55,959 --> 00:21:58,180
get much better detailed understanding

626
00:21:58,400 --> 00:22:00,818
of how these tools fit together.

627
00:22:01,199 --> 00:22:03,400
And this is live for all engineers in

628
00:22:03,400 --> 00:22:05,979
Windsurf today. You can use this interface

629
00:22:06,118 --> 00:22:08,358
to really understand whether it's a legacy

630
00:22:08,358 --> 00:22:10,920
system, a modern system, or a complex interconnected

631
00:22:10,920 --> 00:22:11,719
set of code bases,

632
00:22:12,118 --> 00:22:13,699
how these control flows fit together

633
00:22:14,088 --> 00:22:15,880
at different levels of resolution.

634
00:22:18,309 --> 00:22:20,650
Ultimately, scaling code-based understanding

635
00:22:20,779 --> 00:22:23,259
is what affects agent productivity,

636
00:22:23,430 --> 00:22:24,848
but it also affects human productivity.

637
00:22:25,150 --> 00:22:27,269
Um, we found that when folks are

638
00:22:27,269 --> 00:22:27,890
planning

639
00:22:28,189 --> 00:22:30,108
new software engineering projects.

640
00:22:30,779 --> 00:22:33,029
A huge amount of the time spent in the planning

641
00:22:33,029 --> 00:22:35,309
process is gathering this context,

642
00:22:35,789 --> 00:22:37,979
and our customers who have deployed this at scale have

643
00:22:37,979 --> 00:22:40,108
found that this capability is a very

644
00:22:40,108 --> 00:22:42,328
meaningful contributor to

645
00:22:42,338 --> 00:22:43,630
increased planning velocity.

646
00:22:43,900 --> 00:22:46,009
Um, this is an example from ITA

647
00:22:46,009 --> 00:22:48,229
which we'll talk more about later. After rolling

648
00:22:48,229 --> 00:22:50,309
out, uh, documentation through Deep

649
00:22:50,309 --> 00:22:52,509
Wiki to their existing repositories, they

650
00:22:52,509 --> 00:22:54,509
measure on average it would take literally 10

651
00:22:54,509 --> 00:22:56,920
times as fast to plan the infrastructure

652
00:22:56,920 --> 00:22:59,098
architectural work of new projects rather than

653
00:22:59,098 --> 00:23:01,348
engineer going off doing research, writing some Google Docs,

654
00:23:01,509 --> 00:23:03,130
scoping out, here's all the things we need to do.

655
00:23:03,539 --> 00:23:06,068
It starts with an interactive deep wiki sessions where the architecture

656
00:23:06,068 --> 00:23:07,209
diagrams are already there.

657
00:23:07,509 --> 00:23:09,608
They're validated by the engineer by looking at

658
00:23:09,608 --> 00:23:11,229
the source code and double checking.

659
00:23:11,559 --> 00:23:13,568
Um, and the task and scoped

660
00:23:13,568 --> 00:23:14,430
and broken down

661
00:23:14,689 --> 00:23:16,809
through this search and natural language

662
00:23:16,809 --> 00:23:17,410
interface.

663
00:23:19,568 --> 00:23:20,328
What's the 3rd pattern?

664
00:23:20,779 --> 00:23:23,118
The 3rd pattern, arguably the most important,

665
00:23:23,500 --> 00:23:25,739
is that the productivity gains of the future

666
00:23:25,739 --> 00:23:26,439
are going to come

667
00:23:26,818 --> 00:23:28,559
from the usage of AI coding

668
00:23:28,949 --> 00:23:31,439
across the entire software development life cycle.

669
00:23:31,739 --> 00:23:32,759
It's no longer enough

670
00:23:33,019 --> 00:23:35,019
to just help with writing code.

671
00:23:35,858 --> 00:23:37,729
There's lots of different estimates on this.

672
00:23:38,309 --> 00:23:40,750
Um, Microsoft and software.com

673
00:23:40,989 --> 00:23:43,719
have both estimated around 20%

674
00:23:43,719 --> 00:23:44,549
or less

675
00:23:44,949 --> 00:23:46,949
of human software engineering time in an

676
00:23:46,949 --> 00:23:48,170
enterprise is spent

677
00:23:48,430 --> 00:23:49,588
actually writing code.

678
00:23:51,019 --> 00:23:52,130
The rest is everything else

679
00:23:53,068 --> 00:23:55,180
understanding the existing code, planning what code we

680
00:23:55,180 --> 00:23:57,189
should write, collaborating with colleagues to make sure

681
00:23:57,189 --> 00:23:58,420
that those specs are accurate,

682
00:23:58,750 --> 00:24:00,900
writing the code, but then reviewing the code,

683
00:24:01,269 --> 00:24:02,140
testing the code,

684
00:24:02,420 --> 00:24:03,660
running QA through the code,

685
00:24:03,939 --> 00:24:05,049
fixing things that are found,

686
00:24:05,469 --> 00:24:07,549
repeating this process until a change is actually

687
00:24:07,549 --> 00:24:08,068
ready to ship.

688
00:24:08,729 --> 00:24:11,049
And if you think about how we've designed the SDLC.

689
00:24:12,219 --> 00:24:14,519
Most of it has been designed assuming

690
00:24:14,739 --> 00:24:16,439
that the code writing part

691
00:24:16,779 --> 00:24:18,818
is the scarce resource. This is why we

692
00:24:18,818 --> 00:24:20,858
do planning. This is why we do project

693
00:24:20,858 --> 00:24:23,180
management the way we do it. It's that we couldn't waste engineers'

694
00:24:23,180 --> 00:24:25,259
time writing code that's not useful

695
00:24:25,259 --> 00:24:27,380
because that's such an expensive, uh, constrained

696
00:24:27,380 --> 00:24:29,519
resource. But what we're finding is that

697
00:24:29,739 --> 00:24:31,719
when you have this abundance of

698
00:24:31,979 --> 00:24:33,680
code writing happening from AI,

699
00:24:34,259 --> 00:24:35,939
everything else becomes much more of a bottleneck.

700
00:24:36,689 --> 00:24:38,689
Much more of a bottleneck and so to get the next

701
00:24:38,689 --> 00:24:40,769
level of productivity gains you have to figure out how do we optimize

702
00:24:40,769 --> 00:24:42,769
the end to end system, not just one

703
00:24:42,769 --> 00:24:43,328
component

704
00:24:43,809 --> 00:24:44,410
of the system.

705
00:24:45,469 --> 00:24:47,559
Um, as an example of each

706
00:24:47,559 --> 00:24:49,779
step here, on, on the code writing side,

707
00:24:50,118 --> 00:24:51,900
uh, one of our customers, New Bank,

708
00:24:52,279 --> 00:24:54,400
they had a problem to migrate, uh, eight year

709
00:24:54,400 --> 00:24:57,118
old multi-million line ETL monolith.

710
00:24:57,439 --> 00:24:59,818
Uh, this bank had grown very quickly.

711
00:25:00,118 --> 00:25:02,160
They needed help decomposing

712
00:25:02,160 --> 00:25:04,160
their monolithic ETL repository into

713
00:25:04,160 --> 00:25:06,358
separate modules so that each line of business

714
00:25:06,358 --> 00:25:08,519
could have independent control of their work without

715
00:25:08,519 --> 00:25:10,660
breaking changes for other lines of business.

716
00:25:11,640 --> 00:25:14,000
This was originally scoped to be an 18 month

717
00:25:14,000 --> 00:25:16,430
engineering effort requiring some repetitive refactoring

718
00:25:16,430 --> 00:25:18,799
work distributed across more than 1000

719
00:25:18,799 --> 00:25:21,608
engineers. Ultimately,

720
00:25:22,029 --> 00:25:24,348
this type of workload fits extremely

721
00:25:24,348 --> 00:25:26,549
well in the async delegation paradigm

722
00:25:26,549 --> 00:25:27,500
we talked about previously.

723
00:25:28,009 --> 00:25:30,199
And they were able to do this project, um,

724
00:25:30,838 --> 00:25:31,358
with

725
00:25:31,689 --> 00:25:33,318
1/8 of the human time

726
00:25:33,618 --> 00:25:35,789
at a 20x cost saving by delegating

727
00:25:35,789 --> 00:25:37,818
the work to them. The human work doesn't go

728
00:25:37,818 --> 00:25:40,059
away. You still have to scope out what's the desired end

729
00:25:40,059 --> 00:25:42,130
state, um, of the changes. They

730
00:25:42,130 --> 00:25:44,219
should still be reviewed by a human before they're approved.

731
00:25:44,539 --> 00:25:46,880
But if you amortize the human time spent taken,

732
00:25:47,420 --> 00:25:49,618
uh, to review each change and then for some fraction

733
00:25:49,618 --> 00:25:51,618
of the time maybe making modifications or

734
00:25:51,618 --> 00:25:52,160
edits,

735
00:25:52,420 --> 00:25:54,420
on average this was around 1/8 of the time

736
00:25:54,420 --> 00:25:56,299
it took to do it the manual way.

737
00:25:57,019 --> 00:25:59,059
And so the larger the migration that we factor the

738
00:25:59,059 --> 00:26:01,219
project, the bigger these gains can be in

739
00:26:01,219 --> 00:26:02,108
absolute terms.

740
00:26:03,689 --> 00:26:05,989
Once you've written the code, you need to review the code,

741
00:26:06,588 --> 00:26:08,068
uh, and AI is also able to help

742
00:26:08,368 --> 00:26:09,709
with code review. Now,

743
00:26:10,130 --> 00:26:12,170
um, what we found is that increasingly

744
00:26:12,170 --> 00:26:12,989
as a paradigm

745
00:26:13,838 --> 00:26:16,009
organizations are asking AI to take the first

746
00:26:16,009 --> 00:26:18,049
pass at reviewing the code

747
00:26:18,049 --> 00:26:19,759
that's written for correctness,

748
00:26:20,049 --> 00:26:22,130
conformance with organizational best practices,

749
00:26:22,650 --> 00:26:25,009
potential security vulnerabilities, and other

750
00:26:25,009 --> 00:26:27,088
issues, and only then does

751
00:26:27,088 --> 00:26:29,170
it make sense to spend the more precious

752
00:26:29,170 --> 00:26:29,910
human time

753
00:26:30,289 --> 00:26:31,848
looking at things on top.

754
00:26:32,309 --> 00:26:34,509
This can all be configured via API.

755
00:26:35,108 --> 00:26:36,250
Um, this is an example

756
00:26:36,739 --> 00:26:38,848
of a pull request that was reviewed

757
00:26:39,029 --> 00:26:39,729
by Devon,

758
00:26:40,229 --> 00:26:42,650
uh, where a sequel, uh, a SQL injection vulnerability

759
00:26:42,650 --> 00:26:44,769
was discovered automatically. You can configure

760
00:26:44,769 --> 00:26:46,828
Devon, you can configure any, you know, uh, asynchronous

761
00:26:46,828 --> 00:26:47,809
agent experience

762
00:26:48,108 --> 00:26:50,108
to work well within the existing SCLC

763
00:26:50,108 --> 00:26:51,509
at the review layer too.

764
00:26:52,269 --> 00:26:54,368
But let's be real, there are some dedicated tools

765
00:26:54,368 --> 00:26:55,489
for things like

766
00:26:55,789 --> 00:26:58,068
static analysis of security tools.

767
00:26:58,269 --> 00:27:00,318
We don't have to throw AI at everything. In

768
00:27:00,318 --> 00:27:02,670
fact, when there's a deterministic way to do something, we

769
00:27:02,670 --> 00:27:04,689
strongly recommend do it the deterministic way

770
00:27:05,068 --> 00:27:07,108
instead. Only when that doesn't work

771
00:27:07,108 --> 00:27:08,598
should you use AI at all.

772
00:27:09,439 --> 00:27:11,519
But what we found is that the deterministic

773
00:27:11,519 --> 00:27:13,818
way plus AI leverage and automation

774
00:27:13,959 --> 00:27:16,239
is often the best possible solution.

775
00:27:16,680 --> 00:27:18,910
Uh, for example, um, many leading static

776
00:27:18,910 --> 00:27:20,439
analysis tools like SonarCube,

777
00:27:20,719 --> 00:27:22,920
uh, Fortify, Vericode, Sneak, you know, they

778
00:27:22,920 --> 00:27:25,078
produce huge volumes of findings that enterprise

779
00:27:25,078 --> 00:27:27,368
scale can add up to lots of engineering

780
00:27:27,368 --> 00:27:28,959
toil to triage and remediate.

781
00:27:29,618 --> 00:27:31,390
Um, once these, uh, once

782
00:27:31,670 --> 00:27:34,209
these existing static analysis tools are connected

783
00:27:34,400 --> 00:27:36,828
to autonomous asynchronous AI agents,

784
00:27:37,189 --> 00:27:39,269
you get this multiplicative speed up where

785
00:27:39,269 --> 00:27:41,309
engineers only have to look at the alerts that

786
00:27:41,309 --> 00:27:43,279
have already been triaged by AI,

787
00:27:43,818 --> 00:27:46,108
and we find that organizations that adopt

788
00:27:46,108 --> 00:27:49,118
this, um, are able to resolve 70%

789
00:27:49,390 --> 00:27:51,650
of static analysis tool, uh, security scan

790
00:27:52,059 --> 00:27:53,598
issues automatically with them,

791
00:27:54,469 --> 00:27:56,630
and we'll talk about more details of how, how that was achieved.

792
00:27:57,949 --> 00:27:59,769
There's also the test writing.

793
00:28:00,118 --> 00:28:01,328
Many of us, uh,

794
00:28:01,838 --> 00:28:02,789
know tests are important,

795
00:28:03,118 --> 00:28:05,259
but as individual engineers aren't super excited

796
00:28:05,259 --> 00:28:07,640
to write them ourselves, at least speaking in my own

797
00:28:07,640 --> 00:28:09,380
experience, uh, but we're finding that

798
00:28:09,920 --> 00:28:11,380
agents are both

799
00:28:11,799 --> 00:28:13,880
transformative for helping improve

800
00:28:13,880 --> 00:28:14,618
test coverage

801
00:28:14,880 --> 00:28:16,858
and also really benefit

802
00:28:17,160 --> 00:28:19,279
from having better test coverage in organization.

803
00:28:19,358 --> 00:28:20,150
If I were to describe

804
00:28:20,608 --> 00:28:22,640
one of the underlying best practices

805
00:28:22,640 --> 00:28:23,719
for working with AI

806
00:28:24,078 --> 00:28:26,318
inside your code base productively, it's making

807
00:28:26,318 --> 00:28:27,640
sure the feedback loops are tight.

808
00:28:28,219 --> 00:28:30,229
So how do we know that when this AI generated change

809
00:28:30,229 --> 00:28:30,949
is created,

810
00:28:31,348 --> 00:28:32,170
it's actually gonna work

811
00:28:32,549 --> 00:28:34,630
and one of the best ways to do that is with test coverage, you know, unit

812
00:28:34,630 --> 00:28:37,000
tests, and integration tests and things in the middle as well.

813
00:28:37,390 --> 00:28:39,500
Um, what we found is that, uh,

814
00:28:39,630 --> 00:28:41,328
if you have systematically

815
00:28:41,588 --> 00:28:42,969
under, uh, kind of

816
00:28:43,259 --> 00:28:45,348
lower test coverage in sections or large swaths of

817
00:28:45,348 --> 00:28:47,509
your code repositories than you want, you can do

818
00:28:47,509 --> 00:28:49,930
one-time pushes to go improve test coverage

819
00:28:50,029 --> 00:28:52,459
and make sure you're really monitoring the desired

820
00:28:52,459 --> 00:28:53,750
behavior of the existing system.

821
00:28:54,170 --> 00:28:56,449
And then once you have that in place, it unlocks

822
00:28:56,449 --> 00:28:58,608
further velocity gains from AI on every other use

823
00:28:58,608 --> 00:28:59,588
case on top.

824
00:29:02,088 --> 00:29:04,098
It's important that we're not just talking about the

825
00:29:04,098 --> 00:29:06,328
product capabilities that are needed to be successful, but also

826
00:29:06,328 --> 00:29:08,430
what's actually needed from the enterprise

827
00:29:08,519 --> 00:29:10,568
to roll these out in a productive way, and we

828
00:29:10,568 --> 00:29:12,729
have seen many of these rollouts with

829
00:29:12,729 --> 00:29:14,868
varying levels of velocity and success,

830
00:29:15,130 --> 00:29:17,309
and I just wanna share a few best practices that we've seen,

831
00:29:17,568 --> 00:29:19,880
um, for asynchronous agents

832
00:29:19,880 --> 00:29:21,969
in particular, but coding agents in

833
00:29:21,969 --> 00:29:24,180
general. The first is

834
00:29:24,180 --> 00:29:27,459
that this new generation of tools

835
00:29:27,519 --> 00:29:30,019
um represent more of a workflow transformation

836
00:29:30,140 --> 00:29:32,479
than a a new type of developer tool

837
00:29:32,739 --> 00:29:35,029
it's co-worker not co-pilot

838
00:29:35,380 --> 00:29:36,939
and so because of that um.

839
00:29:37,969 --> 00:29:40,170
This is a big, this is a big workflow change. It's

840
00:29:40,170 --> 00:29:41,189
also a new skill

841
00:29:41,529 --> 00:29:43,328
for engineers to learn inside an organization.

842
00:29:43,650 --> 00:29:45,838
We've actually found that people who are already engineering

843
00:29:45,838 --> 00:29:46,489
managers

844
00:29:46,769 --> 00:29:49,029
are sometimes the most productive contributors

845
00:29:49,150 --> 00:29:51,368
with this next generation of tools because they're already good at

846
00:29:51,368 --> 00:29:52,029
delegating.

847
00:29:52,368 --> 00:29:54,559
And so this is something that everyone is going to benefit

848
00:29:54,559 --> 00:29:56,670
from at some point in the future, being able to work

849
00:29:56,809 --> 00:29:58,848
as an individual contributor itself but also delegate

850
00:29:58,848 --> 00:29:59,969
productively to AI.

851
00:30:00,618 --> 00:30:02,739
And having internal teams that

852
00:30:02,739 --> 00:30:04,568
sort of lead the charge on this front become

853
00:30:04,949 --> 00:30:07,289
a center of excellence

854
00:30:07,588 --> 00:30:08,930
for the overall

855
00:30:09,588 --> 00:30:11,618
organization. Is really, really helpful

856
00:30:12,318 --> 00:30:14,578
to making sure that others can kind of learn

857
00:30:14,759 --> 00:30:16,160
from these best practices.

858
00:30:16,949 --> 00:30:19,029
And the most effective rollouts, they

859
00:30:19,029 --> 00:30:20,068
tend to combine.

860
00:30:20,848 --> 00:30:22,868
The top down mandate

861
00:30:22,930 --> 00:30:24,400
with the bottoms up buying,

862
00:30:25,328 --> 00:30:26,709
especially a large enterprise scale,

863
00:30:26,969 --> 00:30:29,029
you will have a wide range of

864
00:30:29,328 --> 00:30:31,489
engineering, uh, of engineering buy-in from

865
00:30:31,489 --> 00:30:33,689
people chomping at the bit to use the las and grace AI

866
00:30:33,689 --> 00:30:35,890
tools to people who say I have done

867
00:30:35,890 --> 00:30:37,930
coding the way I've done it for 30 years and I am

868
00:30:37,930 --> 00:30:38,828
not changing,

869
00:30:39,170 --> 00:30:41,650
um, and we found that, um, you know, both

870
00:30:41,650 --> 00:30:43,709
approaches are gonna be present and are gonna be important

871
00:30:43,890 --> 00:30:45,910
for the future of productivity inside

872
00:30:46,170 --> 00:30:46,910
the enterprise.

873
00:30:47,400 --> 00:30:48,578
But the way to move the needle forward

874
00:30:48,868 --> 00:30:50,939
is to just celebrate the wins and make sure

875
00:30:50,939 --> 00:30:53,239
that there are folks who are getting

876
00:30:53,239 --> 00:30:55,739
success, uh, that that's highlighted, that's emphasized,

877
00:30:55,959 --> 00:30:57,779
and other people can learn from that.

878
00:30:58,118 --> 00:31:00,739
Uh, we've seen even the most grizzled skeptics,

879
00:31:00,880 --> 00:31:03,045
uh, discover a use case. That they thought

880
00:31:03,045 --> 00:31:04,134
was impossible with AI

881
00:31:04,404 --> 00:31:06,723
and completely turn around and become an evangelist,

882
00:31:06,884 --> 00:31:09,243
but it requires this sort of social cohesion

883
00:31:09,443 --> 00:31:10,963
and organizational buy-in,

884
00:31:11,243 --> 00:31:13,275
you know, tactically we've seen everything from

885
00:31:13,275 --> 00:31:15,515
people adding line items in the performance

886
00:31:15,515 --> 00:31:17,604
review rubric about AI utilization

887
00:31:17,884 --> 00:31:20,045
to doing specific all hands or

888
00:31:20,045 --> 00:31:22,055
um highlights of the best uses of AI that are

889
00:31:22,055 --> 00:31:22,614
discovered

890
00:31:23,074 --> 00:31:23,765
inside the team.

891
00:31:25,368 --> 00:31:27,439
The second is that the setup and the integration

892
00:31:27,500 --> 00:31:29,500
is actually really tricky and it's also

893
00:31:29,500 --> 00:31:30,039
critical.

894
00:31:30,618 --> 00:31:32,670
Um, agents are going to be

895
00:31:32,670 --> 00:31:35,160
onboarded more like human engineers

896
00:31:35,348 --> 00:31:36,979
than like dev tools over time.

897
00:31:37,410 --> 00:31:39,939
Again, the best gains come from the

898
00:31:40,250 --> 00:31:42,338
entire software development life cycle automation, not

899
00:31:42,338 --> 00:31:43,078
just one piece,

900
00:31:43,338 --> 00:31:44,719
and to do that actually well,

901
00:31:45,250 --> 00:31:47,420
you need access to the same tools and systems

902
00:31:47,420 --> 00:31:49,680
that a human engineer would use to do their work.

903
00:31:50,289 --> 00:31:52,430
So every Devon session it's configured

904
00:31:52,608 --> 00:31:54,890
in a virtual machine that has an identical

905
00:31:54,890 --> 00:31:57,130
development environment to the human engineer's virtual

906
00:31:57,130 --> 00:31:59,209
machine, but if Devin doesn't have access to

907
00:31:59,209 --> 00:32:01,289
the same tools the human engineer would use to check

908
00:32:01,289 --> 00:32:01,818
their work,

909
00:32:02,088 --> 00:32:04,068
then the productivity gains are going to be capped.

910
00:32:04,559 --> 00:32:06,529
And a particular pitfall to avoid

911
00:32:06,838 --> 00:32:08,848
is the the partial access

912
00:32:08,848 --> 00:32:10,848
rollout trap where you've

913
00:32:10,848 --> 00:32:12,969
approved an exciting new tool, you're ready to roll

914
00:32:12,969 --> 00:32:14,969
it out, but you've only, you've only done it

915
00:32:14,969 --> 00:32:17,130
for the source code and actually for engineers

916
00:32:17,130 --> 00:32:19,170
to be proactive in your systems, they also need to

917
00:32:19,170 --> 00:32:21,199
run the internal, the internal test suite.

918
00:32:21,549 --> 00:32:23,640
Uh, they need to run some internal tools. Um,

919
00:32:23,759 --> 00:32:26,130
if you don't have those as well, you're leaving significant

920
00:32:26,130 --> 00:32:28,170
amounts of autonomy on the table. Um,

921
00:32:28,189 --> 00:32:30,410
Imagine coding yourself without being able to

922
00:32:30,410 --> 00:32:32,309
run or test your code. It would be very hard.

923
00:32:32,809 --> 00:32:34,939
So this is, this is a critical thing, uh,

924
00:32:35,059 --> 00:32:35,680
to get right.

925
00:32:36,170 --> 00:32:38,219
The second is that, uh, you know, how you

926
00:32:38,219 --> 00:32:40,400
actually instruct these AI agents,

927
00:32:40,699 --> 00:32:42,900
it's a skill. It's not, it's not something that

928
00:32:43,420 --> 00:32:45,420
everyone inherently picks up, kind of like

929
00:32:45,420 --> 00:32:47,578
how you delegate tasks to, uh,

930
00:32:47,588 --> 00:32:49,338
coworkers or to reports on your team.

931
00:32:49,920 --> 00:32:50,759
If we've seen

932
00:32:51,059 --> 00:32:53,380
prompts that are one line and

933
00:32:53,380 --> 00:32:55,380
extremely vague to build an entire end

934
00:32:55,380 --> 00:32:57,608
to end system from scratch that have very low probability

935
00:32:57,608 --> 00:32:59,680
of success, and we started to build in

936
00:32:59,818 --> 00:33:01,838
coaching and tooling in our own systems

937
00:33:02,059 --> 00:33:04,479
to help people learn how to work better with AI systems

938
00:33:04,699 --> 00:33:07,059
and in some cases automate the prompt creation

939
00:33:07,059 --> 00:33:07,789
process entirely.

940
00:33:08,140 --> 00:33:10,180
If you are going from a Jira ticket, which is often

941
00:33:10,180 --> 00:33:10,858
underscoped,

942
00:33:11,259 --> 00:33:13,259
we found that rather than just copy and

943
00:33:13,259 --> 00:33:15,660
pasting that Jira ticket into an agentic

944
00:33:15,660 --> 00:33:16,739
AI system like Devon.

945
00:33:17,160 --> 00:33:19,348
That if you assign that ticket to Devin,

946
00:33:19,519 --> 00:33:21,640
we will first do a detailed scoping

947
00:33:21,640 --> 00:33:23,828
deep dive where Devin will research every aspect

948
00:33:23,828 --> 00:33:24,630
of your code base,

949
00:33:25,239 --> 00:33:27,279
understand what's all the relevant context for this

950
00:33:27,279 --> 00:33:28,500
particular ambiguous ticket,

951
00:33:28,959 --> 00:33:31,118
and then it will construct a prompt for itself. It's

952
00:33:31,118 --> 00:33:33,390
much more detailed. It says these are the best practices.

953
00:33:33,598 --> 00:33:35,640
Here's what exactly what we need to do, um, here's

954
00:33:35,640 --> 00:33:36,969
how you can test your own work,

955
00:33:37,239 --> 00:33:39,279
and this type of metap prompting is becoming

956
00:33:39,279 --> 00:33:40,719
increasingly popular.

957
00:33:42,549 --> 00:33:43,699
The next is that uh

958
00:33:44,039 --> 00:33:44,618
training

959
00:33:44,880 --> 00:33:45,939
because of this complexity,

960
00:33:46,358 --> 00:33:48,509
the gains to training are actually really high.

961
00:33:48,880 --> 00:33:50,959
So if you imagine we all know that some engineers

962
00:33:50,959 --> 00:33:52,959
have dramatically higher impact on the organization

963
00:33:52,959 --> 00:33:53,939
than other engineers,

964
00:33:54,269 --> 00:33:56,608
we think that that gap is going to actually widen

965
00:33:56,640 --> 00:33:59,000
with AI. Everyone's, uh, everyone's baseline

966
00:33:59,000 --> 00:34:01,059
moves up, but the best performers

967
00:34:01,160 --> 00:34:03,160
can become even more leveraged than

968
00:34:03,160 --> 00:34:05,170
before and as an extreme example,

969
00:34:05,199 --> 00:34:05,799
you can imagine.

970
00:34:06,250 --> 00:34:08,250
Really proactive individual engineers in

971
00:34:08,250 --> 00:34:09,148
your organization

972
00:34:09,489 --> 00:34:10,500
almost becoming like

973
00:34:10,849 --> 00:34:12,849
CTOs of an entire

974
00:34:12,849 --> 00:34:15,010
army of AI agents. That's the

975
00:34:15,010 --> 00:34:16,969
direction that software engineering is going,

976
00:34:17,329 --> 00:34:19,628
uh, and so getting folks, the

977
00:34:20,128 --> 00:34:22,128
helping folks reach their, the closer to the

978
00:34:22,128 --> 00:34:24,889
ceiling of productivity gains can have like a multiplicative

979
00:34:25,119 --> 00:34:27,168
benefit, um, and there should

980
00:34:27,168 --> 00:34:29,449
be time for people to actually play and learn with these tools and

981
00:34:29,449 --> 00:34:31,519
best prac and knowledge sharing best practice the same

982
00:34:31,519 --> 00:34:33,530
way that we, you know, we help each other learn, learn

983
00:34:33,530 --> 00:34:35,688
coding. The second is, and

984
00:34:35,688 --> 00:34:37,217
the the last, and this is very important,

985
00:34:37,489 --> 00:34:39,748
is like how do we actually measure this stuff,

986
00:34:40,088 --> 00:34:42,467
um, so metrics and measurement

987
00:34:42,467 --> 00:34:44,478
is one of the most talked about parts of AI software

988
00:34:44,478 --> 00:34:46,809
engineering. It's quite challenging for a lot of folks

989
00:34:46,809 --> 00:34:48,849
and um there's many different approaches for how to

990
00:34:48,849 --> 00:34:49,387
do this,

991
00:34:49,849 --> 00:34:51,849
um, on one end of the spectrum you

992
00:34:51,849 --> 00:34:53,927
can have really granular input metrics,

993
00:34:54,128 --> 00:34:56,208
probably the worst one being number of lines

994
00:34:56,208 --> 00:34:58,009
of code written by AI.

995
00:34:58,628 --> 00:35:00,949
On the other end of the spectrum you have complete end to end

996
00:35:00,949 --> 00:35:01,909
business outcomes.

997
00:35:02,228 --> 00:35:04,349
Great, we have saved 10 many billions of dollars

998
00:35:04,349 --> 00:35:04,989
or

999
00:35:05,269 --> 00:35:07,458
made 10 many billions of dollars from AI

1000
00:35:07,458 --> 00:35:09,510
progress and we've shipped at this much higher

1001
00:35:09,510 --> 00:35:10,110
velocity.

1002
00:35:11,199 --> 00:35:13,570
The way we think about it is that it makes sense to take metrics

1003
00:35:13,570 --> 00:35:15,570
at multiple levels of abstraction, but

1004
00:35:15,570 --> 00:35:16,148
over time

1005
00:35:16,809 --> 00:35:18,809
the higher impact metrics are closer

1006
00:35:18,809 --> 00:35:19,809
to the end to end

1007
00:35:20,079 --> 00:35:22,208
outcome-based metrics. Um, uh, that's

1008
00:35:22,208 --> 00:35:24,110
really what matters. And so

1009
00:35:24,648 --> 00:35:26,389
when we're seeing successful

1010
00:35:26,688 --> 00:35:28,769
AI software engineering agent rollouts

1011
00:35:28,769 --> 00:35:29,929
in large enterprises,

1012
00:35:30,409 --> 00:35:32,869
most often this is measured

1013
00:35:33,090 --> 00:35:35,719
on specific project timelines,

1014
00:35:35,929 --> 00:35:38,010
shrinking dramatically and requiring

1015
00:35:38,010 --> 00:35:39,688
much fewer engineering resources.

1016
00:35:40,019 --> 00:35:41,619
And the enterprises we work with, um,

1017
00:35:42,260 --> 00:35:44,269
almost always reinvest those

1018
00:35:44,269 --> 00:35:46,349
engineering resources into more projects because

1019
00:35:46,349 --> 00:35:48,929
the demand for code is sort of insatiable

1020
00:35:49,030 --> 00:35:51,309
and so people are shipping more and more and more migrations

1021
00:35:51,309 --> 00:35:53,389
that maybe wouldn't have gotten done because they were infeasible before

1022
00:35:53,389 --> 00:35:55,090
are now happening and they're happening quickly.

1023
00:35:55,429 --> 00:35:57,628
So the ideal is measure the wall clock

1024
00:35:57,628 --> 00:35:59,628
time of large scale projects. It's

1025
00:35:59,628 --> 00:36:01,708
gonna take 2 years now it's gonna take 6 months. It

1026
00:36:01,708 --> 00:36:03,728
was gonna take 1000 engineers, now it takes 100.

1027
00:36:04,188 --> 00:36:05,668
That's the, that's the sort of the gold standard.

1028
00:36:06,059 --> 00:36:07,969
Uh, one below that is

1029
00:36:08,228 --> 00:36:10,269
how much human time you're

1030
00:36:10,269 --> 00:36:12,570
actually saving on a per unit of work basis.

1031
00:36:12,829 --> 00:36:14,409
This is another huge benefit

1032
00:36:14,668 --> 00:36:16,708
of applying AI software engineering for the

1033
00:36:16,708 --> 00:36:18,030
entire SDLC.

1034
00:36:18,429 --> 00:36:20,750
If you take a Jira ticket and you're assigned to an agent

1035
00:36:20,869 --> 00:36:22,989
and that agent solves it end to end, you

1036
00:36:22,989 --> 00:36:25,119
now know how many story points, uh, were

1037
00:36:25,119 --> 00:36:26,750
done autonomously by AI,

1038
00:36:27,030 --> 00:36:29,070
and you have some accountability metric of that would

1039
00:36:29,070 --> 00:36:31,349
have taken this much human engineering time and

1040
00:36:31,349 --> 00:36:33,429
that's worth this much to me, and the ROI is very easy to

1041
00:36:33,429 --> 00:36:35,458
do. Absent that, uh,

1042
00:36:35,628 --> 00:36:37,628
you look at the velocity of teams, uh,

1043
00:36:37,708 --> 00:36:39,989
you know, what's the merge PR rate? Are the number of merged PRs

1044
00:36:39,989 --> 00:36:42,188
going up? Um, are we able to

1045
00:36:42,188 --> 00:36:44,269
get more, uh, to have more smaller

1046
00:36:44,269 --> 00:36:44,809
teams

1047
00:36:45,079 --> 00:36:47,269
outputting the same amount per team?

1048
00:36:47,708 --> 00:36:49,849
This is how you actually capture the productivity gains

1049
00:36:49,978 --> 00:36:52,349
of AI in a way that's deployable and paralyzable

1050
00:36:52,349 --> 00:36:54,378
as opposed to kind of survey-based and

1051
00:36:54,378 --> 00:36:54,909
anecdotal.

1052
00:36:56,449 --> 00:36:58,849
Um, I wanted to talk about what

1053
00:36:58,849 --> 00:37:00,949
this looks like end to end in the real world

1054
00:37:01,168 --> 00:37:02,628
at large enterprise scale,

1055
00:37:03,168 --> 00:37:05,110
and, and the customer I'm excited to share,

1056
00:37:05,409 --> 00:37:07,599
uh, the details about how they did this successfully is ITA.

1057
00:37:08,079 --> 00:37:10,250
ITA is the largest bank in Latin America.

1058
00:37:10,579 --> 00:37:12,648
They're a global financial scale and

1059
00:37:12,648 --> 00:37:14,989
very high complexity. They have $0.5 trillion

1060
00:37:14,989 --> 00:37:17,090
in assets, over 70 million

1061
00:37:17,090 --> 00:37:19,030
customers. They operate across 18 countries,

1062
00:37:19,530 --> 00:37:21,688
and they have one of the largest engineering organizations

1063
00:37:21,688 --> 00:37:24,050
is all of Latin America, over 17,000 people

1064
00:37:24,050 --> 00:37:25,289
working in technology.

1065
00:37:27,478 --> 00:37:29,599
First, I want to talk about their results, and then we'll talk about how

1066
00:37:29,599 --> 00:37:30,780
they achieve them specifically.

1067
00:37:32,099 --> 00:37:34,289
Um, ITAO has indexed more than 300,000 lines of code

1068
00:37:34,289 --> 00:37:36,019
documented automatically with Devon.

1069
00:37:36,320 --> 00:37:38,398
Um, more than 75% of teams spanning

1070
00:37:38,398 --> 00:37:40,679
17,000 engineers are using Devon

1071
00:37:40,679 --> 00:37:41,458
in production.

1072
00:37:41,878 --> 00:37:44,030
70% of all security vulnerabilities flagged

1073
00:37:44,030 --> 00:37:46,478
by static code analysis tools are auto-mediated

1074
00:37:46,478 --> 00:37:47,579
by Devon today.

1075
00:37:47,958 --> 00:37:50,070
They measure on average 5 to 6x

1076
00:37:50,070 --> 00:37:52,478
faster modernization and migration end to end

1077
00:37:52,478 --> 00:37:53,938
wall clock time for projects.

1078
00:37:54,570 --> 00:37:56,989
And they've 2xed their test coverage from less than 50%

1079
00:37:57,208 --> 00:37:59,289
to around 90% on

1080
00:37:59,300 --> 00:38:00,829
key critical systems.

1081
00:38:01,929 --> 00:38:03,429
So these are some of the, these are some of the results

1082
00:38:03,728 --> 00:38:04,530
deploying this at scale.

1083
00:38:05,579 --> 00:38:06,199
Um,

1084
00:38:06,539 --> 00:38:08,199
IAO approached evaluating agents

1085
00:38:08,458 --> 00:38:09,918
kind of like working with a new person

1086
00:38:10,179 --> 00:38:10,958
on the team.

1087
00:38:11,539 --> 00:38:12,478
Eventually you're gonna

1088
00:38:12,978 --> 00:38:15,179
start with smaller tasks, build trust, learn

1089
00:38:15,179 --> 00:38:16,139
how to work with that person,

1090
00:38:16,458 --> 00:38:18,079
and then grow over time.

1091
00:38:18,510 --> 00:38:20,619
Um, one squad at Itao used Devon

1092
00:38:20,619 --> 00:38:21,559
for everything possible,

1093
00:38:21,938 --> 00:38:24,168
uh, that they could, and they ended up, uh, delivering

1094
00:38:24,168 --> 00:38:26,300
two releases in 3 months, which was double what they had

1095
00:38:26,300 --> 00:38:27,119
originally planned.

1096
00:38:27,659 --> 00:38:29,800
Um, and on measurements of code quality

1097
00:38:29,800 --> 00:38:31,898
and developer satisfaction they saw significant performance

1098
00:38:31,898 --> 00:38:33,019
gains using depth.

1099
00:38:34,320 --> 00:38:36,668
In terms of how this helped over time,

1100
00:38:37,010 --> 00:38:39,128
uh, just like when you're on boarding a new human engineer,

1101
00:38:39,208 --> 00:38:40,590
when you on board a new AI engineer,

1102
00:38:40,878 --> 00:38:42,929
day one, you might know, they might know a lot about coding.

1103
00:38:43,039 --> 00:38:45,039
Devin might know a lot about coding, but it's not going to know anything

1104
00:38:45,039 --> 00:38:47,159
about you. This is the benefit of

1105
00:38:47,159 --> 00:38:49,260
rolling out these systems early

1106
00:38:49,269 --> 00:38:50,219
with compounding knowledge

1107
00:38:50,679 --> 00:38:51,340
under the hood

1108
00:38:51,599 --> 00:38:53,750
every day you work with Devin, every interaction you have,

1109
00:38:54,079 --> 00:38:56,360
it gets smarter, better, faster

1110
00:38:56,360 --> 00:38:58,469
over time. It learns the specific organizational

1111
00:38:58,469 --> 00:38:59,719
context that matters to you,

1112
00:39:00,079 --> 00:39:02,119
and that makes future PRs more likely to

1113
00:39:02,119 --> 00:39:04,119
be successful, more likely to merge, more likely to be

1114
00:39:04,119 --> 00:39:04,639
relevant.

1115
00:39:05,610 --> 00:39:07,789
Um, this code-based understanding,

1116
00:39:07,969 --> 00:39:10,090
uh, is again the, the key starting

1117
00:39:10,090 --> 00:39:12,269
point of how these, of how these systems work.

1118
00:39:12,688 --> 00:39:14,989
Um, where Ita found this in particularly helpful

1119
00:39:15,128 --> 00:39:17,429
was architecture documentation.

1120
00:39:17,769 --> 00:39:20,139
Um, this led to 10x faster planning.

1121
00:39:20,708 --> 00:39:22,800
Again, many of these large scale real world systems

1122
00:39:22,800 --> 00:39:25,090
are written by people who are no longer at the company, uh,

1123
00:39:25,159 --> 00:39:27,250
with inadequate documentation. It takes huge

1124
00:39:27,250 --> 00:39:27,789
amounts of time

1125
00:39:28,090 --> 00:39:29,128
gathering data and information.

1126
00:39:29,878 --> 00:39:32,409
Um, uh, one of the product managers

1127
00:39:32,409 --> 00:39:34,449
for, uh, for IO named Stefano, he said

1128
00:39:34,449 --> 00:39:36,599
that developers at ITO have been excited by how far Devon

1129
00:39:36,599 --> 00:39:38,769
can go. We've seen it handle problems we initially

1130
00:39:38,769 --> 00:39:39,708
thought were too complex,

1131
00:39:39,969 --> 00:39:42,050
especially for teams working across massive codebases where most,

1132
00:39:42,409 --> 00:39:44,530
most other products struggle to absorb that amount of context.

1133
00:39:44,889 --> 00:39:46,958
And I'll say one interesting side note is that

1134
00:39:46,958 --> 00:39:49,010
product managers are some of the biggest beneficiaries of this

1135
00:39:49,010 --> 00:39:51,050
new wave of tools because product managers are often

1136
00:39:51,050 --> 00:39:53,054
dependent. On engineers to get their questions answered,

1137
00:39:53,324 --> 00:39:55,364
but now just like Devin is the first

1138
00:39:55,364 --> 00:39:57,523
line triage for static analysis, security

1139
00:39:57,523 --> 00:39:59,554
vulnerabilities, Devin can also be the first line

1140
00:39:59,554 --> 00:40:01,603
answer triage for questions from tech,

1141
00:40:01,724 --> 00:40:03,724
from engineering adjacent functions, uh, like

1142
00:40:03,724 --> 00:40:05,804
why ask the engineer when you could first ask,

1143
00:40:05,945 --> 00:40:08,054
uh, ask Devin, get an instant answer that's grounded

1144
00:40:08,054 --> 00:40:10,364
in the code, and that's been a killer use case for

1145
00:40:10,364 --> 00:40:11,023
product managers,

1146
00:40:11,385 --> 00:40:12,760
um. In terms of

1147
00:40:13,059 --> 00:40:13,769
writing code,

1148
00:40:14,099 --> 00:40:16,128
one of my favorite use cases that HO, uh,

1149
00:40:16,139 --> 00:40:18,139
deployed Debbonet is what's called the

1150
00:40:18,139 --> 00:40:20,079
CNPJ Compliance Project.

1151
00:40:20,378 --> 00:40:21,719
Uh, so Brazil

1152
00:40:22,019 --> 00:40:23,179
has, like the US,

1153
00:40:23,530 --> 00:40:25,199
taxpayer numbers for companies.

1154
00:40:25,699 --> 00:40:26,739
Uh, unlike the US,

1155
00:40:27,099 --> 00:40:29,300
Brazil's numbers for, uh, taxpayer numbers

1156
00:40:29,300 --> 00:40:31,378
for companies used to be numbers, and

1157
00:40:31,378 --> 00:40:32,610
a new regulation was passed,

1158
00:40:32,898 --> 00:40:34,918
so they're now going to be alphanumeric.

1159
00:40:35,389 --> 00:40:37,500
This is basically the Y2K catastrophe

1160
00:40:37,500 --> 00:40:38,099
of Brazil.

1161
00:40:38,489 --> 00:40:41,168
Uh, every enterprise in all of Brazil is scrambling

1162
00:40:41,168 --> 00:40:42,769
to become compliant with this new thing,

1163
00:40:43,050 --> 00:40:44,309
and this is affecting

1164
00:40:44,610 --> 00:40:46,668
really large scale production systems that have been around

1165
00:40:46,809 --> 00:40:48,429
for decades, uh, including

1166
00:40:48,849 --> 00:40:50,949
significant cobalt infrastructure Eito

1167
00:40:50,949 --> 00:40:52,228
that's mission critical

1168
00:40:52,530 --> 00:40:54,570
to be, um, to kind of maintain performance and

1169
00:40:54,570 --> 00:40:55,148
compliance.

1170
00:40:55,610 --> 00:40:57,728
Um, Devin was able to do end to end

1171
00:40:57,728 --> 00:40:59,829
migration for CMPJ compliance

1172
00:41:00,090 --> 00:41:02,360
across all repos at EIO that were tested.

1173
00:41:02,570 --> 00:41:04,610
Um, one example was a SQL Server migration that

1174
00:41:04,610 --> 00:41:06,688
covered 800 database objects that,

1175
00:41:06,728 --> 00:41:09,050
uh, leveraged stored procedures and kind of legacy

1176
00:41:09,050 --> 00:41:11,128
practices, uh, and they were able to get

1177
00:41:11,128 --> 00:41:13,449
this to compliance to completion with modern CMPJ

1178
00:41:13,800 --> 00:41:16,050
regulation over 5x faster than was

1179
00:41:16,050 --> 00:41:18,128
budgeted. Again, large scale projects that you can

1180
00:41:18,128 --> 00:41:20,250
break up into simple work. This is the recipe.

1181
00:41:20,750 --> 00:41:22,750
And ultimately what we're seeing is

1182
00:41:22,750 --> 00:41:25,188
that you know CIOs are expected

1183
00:41:25,188 --> 00:41:26,050
to get more done,

1184
00:41:26,469 --> 00:41:28,469
and AI leverage is the best way to

1185
00:41:28,469 --> 00:41:30,239
do it. Uh, the, the CTO of Vito said

1186
00:41:31,309 --> 00:41:33,550
that speed is the ultimate competitive advantage.

1187
00:41:33,829 --> 00:41:35,898
Uh, AI is the critical enabler that allows

1188
00:41:35,898 --> 00:41:38,269
us to dramatically accelerate the ability to

1189
00:41:38,269 --> 00:41:39,329
respond to customer needs,

1190
00:41:39,590 --> 00:41:42,039
um, and this is a key part of their strategy

1191
00:41:42,039 --> 00:41:42,789
and their success.

1192
00:41:43,579 --> 00:41:45,648
Uh, with that, thanks so much for joining and happy

1193
00:41:45,648 --> 00:41:47,378
to answer questions from anyone in the audience.

1194
00:41:47,739 --> 00:41:48,099
Thank you.

