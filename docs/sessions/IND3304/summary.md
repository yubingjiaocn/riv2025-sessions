# AWS re:Invent 2025 会议总结

## 会议概述

本次会议由来自 Itaú Bank（伊塔乌银行）的 Wilson 和 Adi，以及 AWS 的 Eduardo 共同主讲，重点分享了伊塔乌银行如何将其关键核心系统——支票账户平台从大型机迁移到 AWS 云的现代化转型之旅。伊塔乌银行是拉丁美洲最大的银行之一，拥有超过 100 年的历史和 7000 万客户。面对巴西金融服务行业的数字化转型浪潮，特别是 Pix 即时支付系统的兴起（每月处理 70 亿笔交易，其中 20% 通过伊塔乌银行），该银行必须重新思考其核心系统架构以满足实时、高可用性的需求。

该项目始于 2018 年，目标是到 2028 年将 100% 的平台迁移到云端。这个支票账户平台已在大型机上运行超过 50 年，现在需要实现 99.99%（四个九）的可用性，即每月停机时间少于 5 分钟。最关键的非协商需求是确保客户账户余额始终保持安全、准确和一致。为实现这些目标，团队采用了基于单元（Cell-based）的架构设计，使用 Kafka 作为事件驱动架构的骨干，并选择 Amazon DynamoDB 作为核心数据库。会议详细介绍了技术架构设计、数据库选型、性能优化以及暗启动（Dark Launch）策略等关键技术细节。

## 详细时间线与关键要点

00:00 - 02:30 | 开场与背景介绍
- 演讲者询问现场有多少人正在或计划迁移需要高可用性的关键系统
- 介绍演讲团队：Eduardo（AWS）、Wilson 和 Adi（Itaú Bank）
- 会议议程：Itaú 面临的挑战、基于单元的架构、DynamoDB 支持以及经验教训

02:30 - 06:00 | Itaú Bank 简介与数字化转型背景
- Itaú Bank 是拉丁美洲最大银行之一，去年庆祝成立 100 周年
- 服务 7000 万客户，提供从信用卡到现金管理的全套金融服务
- 10 年前意识到数字化正在改变业务方式，特别是在巴西金融服务行业

06:00 - 09:30 | 客户行为变化与 Pix 支付系统
- 巴西客户行为变化：使用 WhatsApp 进行支付转账、POS 机扫码支付、在线实时管理投资
- Pix：巴西央行于 2020 年第四季度推出的即时支付服务，10 秒内完成跨行支付
- 约 90% 的巴西人每天使用 Pix，平台开放、可互操作、API 驱动，全年 24/7 可用
- 上个月处理了 70 亿笔 Pix 交易，其中 20% 通过 Itaú 的支票账户平台

09:30 - 12:00 | 现代化决策与目标
- 2018 年决定拥抱数字化转型，扩大现代化规模
- 2024 年 re:Invent 上，CIO Ricardo Gaeta 宣布到 2028 年将 100% 平台迁移到云端
- 现代化目标：将运行 50 多年的大型机支票账户平台迁移到云端
- 目标可用性：99.99%（四个九），即每月停机时间少于 5 分钟
- 核心非协商需求：确保客户支票账户余额安全、准确、一致

12:00 - 15:30 | 当前账户平台架构概览
- 事件驱动架构，基于命令和响应模式
- 使用 Kafka 作为骨干连接微服务，确保实时可靠通信
- 基本流程：账户服务实现幂等性、验证交易、应用业务规则 → 授权器处理交易并与核心遗留系统同步 → 调度器将结果发送回请求者并发布事件

15:30 - 18:00 | 故障隔离理念
- 引用 Amazon CTO Werner Vogels 的名言："一切都会失败，而且一直在失败"
- 提问：更愿意所有客户受影响还是只有部分客户受影响？
- 引入 Cell-based Architecture（基于单元的架构）概念

18:00 - 22:00 | Cell-based Architecture（CZ）介绍
- CZ 是关键系统的实施框架，2022 年 re:Invent 首次展示
- 通过隔离故障、提供部署安全性和帮助扩展性来实现更高可用性
- 每个单元是完全自治的单元，彼此之间不共享状态
- 具有边界大小和容量，通过添加更多单元而非增加现有单元大小来扩展

22:00 - 27:00 | 路由层与分区算法
- 路由层是将客户交易定向到正确单元的薄层
- 客户数据仅存在于一个特定单元中，不跨单元复制
- 四种分区算法：
  1. 完整表映射（Full Table Mapping）：最简单灵活，但需注意存储
  2. 前缀范围映射：可能导致热单元
  3. 朴素模运算：简单但扩展时需重新平衡
  4. 一致性哈希：使用大量桶映射到单元，减少迁移范围
- Itaú 选择完整表映射以获得更多客户放置控制

27:00 - 30:30 | 路由层实现细节
- 路由层遵循基于单元的架构，每个路由实例完全独立
- 将分区算法所需数据保存在内存中以快速决策
- 每个路由实例可与每个单元通信
- 使用 Kafka 消费者组，通过 gRPC 连接将消息发送到单元

30:30 - 34:00 | 单元副本与高可用性
- 单元副本是镜像主单元状态的活动副本
- 可根据需要设置多个副本，直接影响系统弹性
- 最佳实践：将每个单元副本放置在不同的可用区
- 两种设置：主-主（Active-Active）和主-备（Active-Standby）
- Itaú 选择主-备模式以实现强一致性（账户余额需要强一致性）

34:00 - 37:30 | 单元故障恢复机制
- 主-主模式：一个副本失败时，路由器在剩余副本间重新平衡流量
- 主-备模式：主副本失败时，确保数据复制到备用副本后切换流量
- Itaú 使用三个单元副本，可以容忍一个副本失败，但两个或更多失败则该单元不可用
- 其他单元继续运行，仅部分客户受影响

37:30 - 40:30 | 数据复制与 Quorum 模型
- 主副本接收所有流量，备用副本异步复制数据
- 使用基于 Quorum 的复制模型：部分副本同步复制，其余异步复制
- Journal 组件确保复制：协调跨副本持久化，等待主副本和一个 Quorum 副本确认
- 如果出错，Journal 发送撤销请求以保持一致性

40:30 - 44:00 | 单元副本架构详解
- 路由层通过 gRPC 将交易请求发送到授权器应用
- 授权器应用业务规则、更新账户余额，使用 Journal 组件确保复制和持久性
- 响应发送到 Amazon SQS，解耦同步授权流程和调度过程
- 调度器从 SQS 接收响应，写入 DynamoDB，发送响应给请求者和其他平台服务
- 关键变化：不再依赖大型机处理客户交易

44:00 - 46:30 | Cell-based Architecture 总结
- 一个副本失败时，另一个同步副本快速接管
- 两个或更多副本失败时，该单元不可用但仅影响部分客户
- 扩展简单：添加更多单元而非增加现有单元大小
- 缺点：增加复杂性，需要投资路由层，应避免客户迁移

46:30 - 50:00 | 数据库选型背景
- 核心需求：保持账户余额安全、准确、一致
- 性能要求：100 毫秒内授权交易，峰值时每秒 6000 笔交易，大账户每秒 1000 笔交易
- 测试数据库：SQL Server with RDS、Amazon QLDB、Amazon Aurora、Amazon DynamoDB
- 选择 DynamoDB 原因：高可用性（99.99%）、可预测性能、更少运维工作

50:00 - 54:00 | 幂等性与隔离性原则
- 幂等性：多次接收相同请求只处理第一次，后续返回相同结果
- 隔离性：两个进程同时更新同一记录时，一个更改不会覆盖另一个
- 需要原子性、一致性、幂等性和持久性（ACID）操作
- DynamoDB 提供 ACID 事务支持

54:00 - 58:30 | DynamoDB 表结构设计
- 初始设计：主键为账户 ID，排序键为交易 ID
- 问题：大账户（每秒 1000 笔交易）会创建热键
- 解决方案：主键改为"账户 ID + 分片 ID"，排序键为交易 ID
- 将交易分散到多个分区，避免热键问题
- 不建议创建全局二级索引（会在 GSI 上创建热分区）
- 最佳实践：使用 DynamoDB Streams 将记录变更卸载到 S3，使用 Athena 查询
- 余额表添加版本属性用于乐观锁定，提供隔离性

58:30 - 61:00 | DynamoDB 分区键大小限制
- 现场测验：分区键大小限制是多少？
- 答案：无限制（如果不使用本地二级索引）
- 10 GB 限制仅在使用本地二级索引时适用（基于项目集合）
- 项目集合跨越多个物理分区，因此无限制
- 这一发现对团队来说是重要的认知突破

61:00 - 65:00 | DynamoDB 事务操作
- 使用 TransactWriteItems API 调用实现 ACID 事务
- 使用条件表达式实现乐观锁定：
  - 交易记录：条件为"属性不存在"（检查交易 ID 是否已存在）
  - 余额更新：比较版本号（确保版本与授权时使用的版本相同）
- ClientRequestToken 属性使 TransactWriteItems 调用具有幂等性
- 如果条件失败，DynamoDB 返回详细错误信息

65:00 - 68:00 | 条件失败处理策略
- 在主-备单元架构中，条件失败是罕见情况（通常发生在故障转移时）
- 接受性能下降，正确处理：
  - 版本不匹配：使内存缓存失效，从表中重新读取余额，重新授权所有交易
  - 重复交易：从表中读取该交易的响应，立即发送响应，重新授权剩余交易
- 增加延迟但确保余额绝对安全

68:00 - 71:30 | DynamoDB 性能表现
- DynamoDB 不是测试中最快的数据库，但提供最有价值的一致性
- 关系数据库统计信息会随时间变化，影响执行计划和查询性能
- DynamoDB 无论表大小如何，性能始终一致
- 最苛刻场景（大账户 1000 笔/秒）：达到平均 1200 笔/秒，延迟 79 毫秒
- 达到 6000 笔/秒只需扩展单元数量

71:30 - 75:00 | 性能优化最佳实践
- 避免热分区：选择正确的表结构，将交易分散到多个分区
- 使用单线程处理：按账户 ID 分组交易，将同一账户的交易发送到同一线程
- 避免多个进程或线程处理同一账户的交易，防止竞态条件
- 使用批处理：TransactWriteItems 可在一次调用中打包最多 100 个项目

75:00 - 78:00 | 并发处理性能对比
- 单线程：1200 笔/秒，79 毫秒延迟（基准）
- 两个并发线程：性能下降 15%，延迟增加超过 2 倍
- 四个并发线程：性能再下降 15%，延迟增加 5.6 倍（不可接受）
- 结论：必须避免竞态条件

78:00 - 81:00 | IAM 策略对性能的影响
- 在 AWS Professional Services 账户中轻松达到目标性能
- 在 Itaú 账户中仅达到 680 笔/秒和 130 毫秒延迟
- 联系 AWS Enterprise Support 发现：IAM 策略的数量和大小影响 DynamoDB 性能
- Itaú 账户的策略数量是 Professional Services 账户的两倍
- 修复角色和策略后达到目标性能
- 三周前重新测试：策略数量不再影响性能（DynamoDB 团队改进了服务）

81:00 - 83:30 | DynamoDB 选择总结
- 高可用性：无需停机升级版本，满足 99.99% 可用性要求
- ACID 事务：满足余额更新需求
- 可预测性能：无论表大小如何
- 更少运维开销
- 注意事项：了解 DynamoDB 限制、避免热分区、避免竞态条件

83:30 - 88:00 | 暗启动（Dark Launch）策略
- 目标架构：产品通过 Kafka 发送交易请求 → 路由层 → 授权器 → Journal 组件 → SQS → 调度器 → 响应
- 暗启动从影子流量模式开始：
  - 当前架构和新架构同时消费 Kafka 请求
  - 当前架构生成官方响应
  - 新架构逐笔处理交易，验证行为是否符合预期
- 两个系统完全对齐后，开始将客户从当前架构迁移到新架构
- 达到 100% 后，完全淘汰当前架构

88:00 - 91:00 | 下一步计划
- 完成所有产品采用新平台：每月新增约 5 亿笔交易，高峰日超过 1.2 亿笔
- 在单元级别运行，实现弹性、可用性和部署安全性
- 完成开发阶段，开始并行评估业务规则
- 利用生成式 AI 加速流程：50 多年积累的规则中许多已过时或不再使用
- 期望 AI 帮助更快地识别、分析和现代化这些规则
- 希望在 2026 年 re:Invent 分享进展和新发现

91:00 - 94:30 | 关键经验教训
- 转型需要信任、协作，并将需求置于决策中心
- 建立强大基础对实现速度和规模至关重要
- 不断测试想法，了解每个 AWS 服务如何最适合特定用例
- 复杂解决方案并非总是最佳方案，考虑运维、可观测性和成本的权衡
- 先实践、模拟、测量和验证输出，再投入生产
- 伟大的合作伙伴关系至关重要：Itaú、GFT、AWS 共享文化原则

94:30 - 96:00 | 客户至上与持续改进
- 客户至上是 Amazon 的首要领导力原则
- DynamoDB 团队根据支持案例更新服务，所有人受益
- Amazon 提供超过 1000 门免费数字课程、实验室、模拟和培训
- 包括本届 re:Invent 的部分发布内容

96:00 - 97:00 | 结束语
- 感谢观众参与，请填写调查反馈
- 演讲者会后在外面回答问题，深入讨论架构细节
- 祝愿大家在 re:Invent 期间建立联系、学到更多知识