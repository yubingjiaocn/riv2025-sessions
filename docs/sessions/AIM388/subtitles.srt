1
00:00:00,389 --> 00:00:01,169
OK.

2
00:00:01,558 --> 00:00:02,539
Uh, hello, everyone.

3
00:00:03,568 --> 00:00:05,679
Thank you for coming all the way down to Mandalay Bay

4
00:00:05,679 --> 00:00:06,908
on a Thursday afternoon.

5
00:00:07,610 --> 00:00:09,108
Um, and today,

6
00:00:09,368 --> 00:00:10,608
uh, I have with me.

7
00:00:11,489 --> 00:00:13,739
Uh, I'm Summit Thakur. I lead all of

8
00:00:13,739 --> 00:00:15,179
product for Amazon's Sagemaker AI,

9
00:00:15,489 --> 00:00:17,638
and today I have with me David Galitelli,

10
00:00:18,379 --> 00:00:20,500
who is a senior specialist for generative AI

11
00:00:20,500 --> 00:00:21,429
at AWS,

12
00:00:22,100 --> 00:00:24,120
and Nikhil Singhal, who is a senior staff

13
00:00:24,120 --> 00:00:25,379
ML engineer at Robinhood.

14
00:00:26,138 --> 00:00:28,260
And together, we are going to talk about

15
00:00:28,539 --> 00:00:30,818
how we can help you accelerate building agents

16
00:00:31,120 --> 00:00:33,298
using Sage Maker Studio and Bedrock Agent

17
00:00:33,298 --> 00:00:40,389
Core. Now,

18
00:00:40,848 --> 00:00:42,929
before we talk about how we can help accelerate your

19
00:00:42,929 --> 00:00:43,770
Asian development,

20
00:00:44,520 --> 00:00:46,459
I would love to kind of take a step back

21
00:00:46,719 --> 00:00:48,759
and look at some of the key adoption drivers,

22
00:00:48,880 --> 00:00:50,779
which is driving adoption of agentic AI

23
00:00:51,118 --> 00:00:52,139
across enterprises.

24
00:00:54,009 --> 00:00:55,228
Enterprises today,

25
00:00:55,529 --> 00:00:57,649
they are deploying agents to improve their

26
00:00:57,649 --> 00:00:58,950
customer experience,

27
00:00:59,368 --> 00:01:01,149
automate operational workflows,

28
00:01:01,490 --> 00:01:03,848
and to even improve their employee productivity.

29
00:01:04,588 --> 00:01:05,599
And very often,

30
00:01:05,918 --> 00:01:08,239
the enterprises are choosing to use custom

31
00:01:08,239 --> 00:01:09,000
models

32
00:01:09,278 --> 00:01:10,579
to power these agents.

33
00:01:12,069 --> 00:01:14,230
They take off the shelf foundation models

34
00:01:14,230 --> 00:01:16,349
and then customize them on their private

35
00:01:16,349 --> 00:01:16,909
data

36
00:01:17,430 --> 00:01:18,209
to give them

37
00:01:18,629 --> 00:01:20,750
specialized domain knowledge and enable

38
00:01:20,750 --> 00:01:22,269
them for specific tasks.

39
00:01:24,808 --> 00:01:27,230
Gardner predicts that over the next 3 years,

40
00:01:27,569 --> 00:01:29,849
the usage of these custom models is

41
00:01:29,849 --> 00:01:31,888
going to explode, with more than 50% of

42
00:01:31,888 --> 00:01:32,750
enterprises

43
00:01:33,049 --> 00:01:35,129
choosing to use custom models as compared

44
00:01:35,129 --> 00:01:36,989
to just 1% a year ago.

45
00:01:38,909 --> 00:01:41,709
And this upsurge in the model customization

46
00:01:41,909 --> 00:01:43,689
is not a surprise. This is driven

47
00:01:44,069 --> 00:01:46,808
by very broad accessibility and availability

48
00:01:46,989 --> 00:01:49,668
of various state of the art fine tuning techniques

49
00:01:49,948 --> 00:01:51,418
like reinforcement fine tuning,

50
00:01:51,709 --> 00:01:54,069
preference tuning, and supervised fine tuning.

51
00:01:55,209 --> 00:01:57,569
Using these techniques, our customers

52
00:01:57,569 --> 00:02:00,069
are able to take their private data

53
00:02:00,290 --> 00:02:02,319
and build this knowledge into the models in a

54
00:02:02,319 --> 00:02:03,489
very cost effective way.

55
00:02:05,269 --> 00:02:07,308
Some of these techniques, especially reinforcement

56
00:02:07,308 --> 00:02:09,330
learning, have been quite instrumental

57
00:02:09,429 --> 00:02:11,490
in not just imparting specialized knowledge,

58
00:02:11,909 --> 00:02:14,189
but also giving these model critical reasoning

59
00:02:14,189 --> 00:02:15,008
capabilities.

60
00:02:16,379 --> 00:02:18,558
With these reasoning capabilities, a model

61
00:02:18,740 --> 00:02:20,618
can now take an incoming request,

62
00:02:21,099 --> 00:02:23,159
break it down into discrete steps,

63
00:02:23,419 --> 00:02:25,338
execute those steps using tools,

64
00:02:25,860 --> 00:02:27,939
aggregate the responses, and then plan the

65
00:02:27,939 --> 00:02:28,860
next set of steps.

66
00:02:30,610 --> 00:02:33,038
This continuous improvement loop of

67
00:02:33,038 --> 00:02:33,659
thinking,

68
00:02:34,038 --> 00:02:36,080
acting, and observing enables

69
00:02:36,080 --> 00:02:38,080
a model to continuously make progress

70
00:02:38,080 --> 00:02:40,360
towards its goal in a self-sufficient way.

71
00:02:41,360 --> 00:02:43,788
And this is exactly what forms the bedrock

72
00:02:44,088 --> 00:02:46,169
of the brain of your agentic workflow.

73
00:02:48,979 --> 00:02:51,088
Now, I'm going to walk you through

74
00:02:51,088 --> 00:02:53,099
how you can build an agent for yourself.

75
00:02:54,550 --> 00:02:56,639
This is how an agent development workflow typically

76
00:02:56,639 --> 00:02:57,219
looks like.

77
00:02:58,319 --> 00:02:58,868
First,

78
00:02:59,210 --> 00:03:00,449
you have to plan out

79
00:03:00,719 --> 00:03:02,679
your entire Asian development workflow.

80
00:03:03,508 --> 00:03:05,629
In this first step, you think about what

81
00:03:05,629 --> 00:03:06,699
your use case is,

82
00:03:06,990 --> 00:03:08,429
who are your target users,

83
00:03:09,028 --> 00:03:10,889
what goals and objectives do you have,

84
00:03:11,349 --> 00:03:13,330
and even set up a success criteria.

85
00:03:14,219 --> 00:03:16,379
You often use the success criteria to

86
00:03:16,379 --> 00:03:18,860
evaluate the performance of your customized model

87
00:03:18,860 --> 00:03:20,118
against that of a base model.

88
00:03:22,139 --> 00:03:24,258
Then you move on to the next step where

89
00:03:24,258 --> 00:03:26,368
you gather and collect data for training,

90
00:03:26,580 --> 00:03:28,020
validation, and evaluation.

91
00:03:30,110 --> 00:03:32,149
Then you go on to set up a tuning

92
00:03:32,149 --> 00:03:34,338
infrastructure and then tune, evaluate,

93
00:03:34,349 --> 00:03:36,110
and customize your model candidates.

94
00:03:36,919 --> 00:03:39,038
Once you identify a model candidate that meets

95
00:03:39,038 --> 00:03:41,278
your success criteria, you push them into

96
00:03:41,278 --> 00:03:42,419
production for inference.

97
00:03:43,800 --> 00:03:45,929
And finally, you take this customized

98
00:03:45,929 --> 00:03:47,929
model running in production and build an

99
00:03:47,929 --> 00:03:48,909
agent on top.

100
00:03:52,550 --> 00:03:54,830
AWS gives you several purpose-built

101
00:03:54,830 --> 00:03:56,909
services to help you with each step of this

102
00:03:56,909 --> 00:03:59,229
work. So you have Amazon

103
00:03:59,229 --> 00:04:01,429
Sagemaker AI, which is a model development

104
00:04:01,429 --> 00:04:02,050
service

105
00:04:02,308 --> 00:04:04,929
that lets you tune, customize, evaluate,

106
00:04:05,069 --> 00:04:07,149
and deploy foundation models for any use

107
00:04:07,149 --> 00:04:09,639
case. Then

108
00:04:09,639 --> 00:04:11,659
you have Bedrock, which lets you take these

109
00:04:11,659 --> 00:04:13,788
custom models and deploy them onto

110
00:04:13,788 --> 00:04:15,899
a serverless infrastructure, giving you

111
00:04:15,899 --> 00:04:17,939
high cost performance and great ease of use

112
00:04:17,939 --> 00:04:18,678
for inference.

113
00:04:20,209 --> 00:04:22,220
And finally, you have the Bedrock agent

114
00:04:22,220 --> 00:04:24,379
core suite of tools and services

115
00:04:24,619 --> 00:04:25,399
that lets you

116
00:04:25,699 --> 00:04:27,939
build, deploy, and monitor agents in production

117
00:04:27,939 --> 00:04:29,660
on top of these custom models.

118
00:04:31,100 --> 00:04:33,338
And now, I'm going to walk you through the experience

119
00:04:33,338 --> 00:04:35,608
of how to use these services to build an agent for

120
00:04:35,608 --> 00:04:37,699
yourself. Starting with the first

121
00:04:37,699 --> 00:04:39,850
step. Planning and setting

122
00:04:39,850 --> 00:04:41,369
up an evaluation criteria.

123
00:04:42,970 --> 00:04:45,129
Customers often tell us that in this

124
00:04:45,129 --> 00:04:46,500
step, there's a lot of inertia.

125
00:04:47,358 --> 00:04:49,410
You have to not only choose one base

126
00:04:49,410 --> 00:04:51,500
model among many base foundation models.

127
00:04:52,220 --> 00:04:54,470
You also have to set up a robust evaluation

128
00:04:54,470 --> 00:04:55,048
criteria

129
00:04:55,509 --> 00:04:57,910
so you can ensure your models behave responsibly

130
00:04:57,910 --> 00:04:59,189
and accurately in production.

131
00:05:00,738 --> 00:05:02,819
This often requires expertise and

132
00:05:02,819 --> 00:05:05,119
can take weeks if not months to get started.

133
00:05:06,519 --> 00:05:08,809
To help customers overcome this hump,

134
00:05:09,329 --> 00:05:10,350
we are pleased to announce.

135
00:05:11,379 --> 00:05:13,579
A launch of a new capability in Sagemaker,

136
00:05:13,850 --> 00:05:15,939
Sagemaker model customization agent, which

137
00:05:15,939 --> 00:05:17,439
was launched in preview this week.

138
00:05:19,548 --> 00:05:21,949
Using the SageMaker model customization agent,

139
00:05:22,189 --> 00:05:24,389
you can now plan, execute, and reproduce

140
00:05:24,389 --> 00:05:26,528
your end to end model customization workflow

141
00:05:26,528 --> 00:05:28,829
using plain language instructions.

142
00:05:30,790 --> 00:05:32,428
Here is how the experience looks like.

143
00:05:32,709 --> 00:05:35,278
All you need to do is to go inside Sagemaker

144
00:05:35,278 --> 00:05:37,428
Studio, which is the visual interface

145
00:05:37,428 --> 00:05:38,290
for Sagemaker.

146
00:05:39,139 --> 00:05:41,358
Open the chat interface of the model customization

147
00:05:41,358 --> 00:05:43,420
agent and then describe your use case

148
00:05:43,420 --> 00:05:44,480
in plain natural language.

149
00:05:45,838 --> 00:05:48,269
Then, through a mutual discussion and

150
00:05:48,269 --> 00:05:49,420
conversation with the agent,

151
00:05:49,879 --> 00:05:52,480
you will eventually arrive at a model customization

152
00:05:52,480 --> 00:05:53,980
workflow for your use case.

153
00:05:54,439 --> 00:05:56,600
Once you and the agent mutually agree upon that

154
00:05:56,600 --> 00:05:57,278
workflow,

155
00:05:57,759 --> 00:06:00,278
the agent converts that workflow into a hardened

156
00:06:00,278 --> 00:06:02,439
spec which is stored as a JSONL file.

157
00:06:03,290 --> 00:06:05,528
This specification is then used to both

158
00:06:05,528 --> 00:06:07,769
drive the workflow as well as reproduce it at any

159
00:06:07,769 --> 00:06:08,470
point of time.

160
00:06:10,298 --> 00:06:12,959
And now I'm gonna show you how this specification-driven

161
00:06:12,959 --> 00:06:14,088
workflow looks like

162
00:06:14,548 --> 00:06:16,790
uh inside Sagemaker Studio. So here is the landing

163
00:06:16,790 --> 00:06:18,649
page of the chat interface.

164
00:06:19,988 --> 00:06:22,108
You can see on your left, there's a progress

165
00:06:22,108 --> 00:06:24,178
bar, which helps you see where you stand in

166
00:06:24,178 --> 00:06:26,088
your customization workflow.

167
00:06:26,959 --> 00:06:28,139
In the main chat area,

168
00:06:28,600 --> 00:06:29,579
you see the agent,

169
00:06:30,119 --> 00:06:32,338
uh, which greets you and then asks you certain

170
00:06:32,338 --> 00:06:34,649
clarifying questions about your use case.

171
00:06:35,160 --> 00:06:35,980
For example,

172
00:06:36,358 --> 00:06:37,759
whom are you planning to target?

173
00:06:39,170 --> 00:06:41,309
What success criteria do you have in mind?

174
00:06:41,689 --> 00:06:43,850
Are there any challenges that you face today in

175
00:06:43,850 --> 00:06:46,209
addressing this use case with other alternative solutions?

176
00:06:47,528 --> 00:06:48,750
I am going to take an example

177
00:06:49,040 --> 00:06:51,048
of building a customer service chatbot for

178
00:06:51,048 --> 00:06:51,829
a pet store.

179
00:06:53,338 --> 00:06:55,689
So what I tell this agent is, hey, I

180
00:06:55,689 --> 00:06:57,519
want to build this customer service chatbot.

181
00:06:58,778 --> 00:07:00,939
This is going to target my current

182
00:07:00,939 --> 00:07:03,338
and potential customers of Petto who are inquiring

183
00:07:03,338 --> 00:07:04,858
about my products and services.

184
00:07:06,399 --> 00:07:08,199
And as far as success criteria goes,

185
00:07:08,639 --> 00:07:09,899
I have a few things in mind.

186
00:07:10,319 --> 00:07:11,439
I want this agent

187
00:07:11,778 --> 00:07:13,798
to always respond to my customers in a

188
00:07:13,798 --> 00:07:15,319
polite and empathetic tone.

189
00:07:16,588 --> 00:07:18,750
I want this agent to be grounded in factual

190
00:07:18,750 --> 00:07:21,028
correctness when it comes to producing

191
00:07:21,028 --> 00:07:22,988
information about my catalog of products and services.

192
00:07:23,879 --> 00:07:25,949
And I want these responses to be very clear

193
00:07:25,949 --> 00:07:26,720
and succinct.

194
00:07:27,790 --> 00:07:29,819
And my hope is by deploying this

195
00:07:29,819 --> 00:07:31,028
customer service chatbot,

196
00:07:31,309 --> 00:07:33,670
I can achieve a higher customer satisfaction

197
00:07:33,670 --> 00:07:35,778
rate and a higher customer retention rate of at least

198
00:07:35,778 --> 00:07:36,528
20%.

199
00:07:38,829 --> 00:07:40,869
The agent takes all these inputs and

200
00:07:40,869 --> 00:07:42,928
then asks me further clarifying questions.

201
00:07:43,108 --> 00:07:43,869
For example,

202
00:07:45,129 --> 00:07:45,988
What are the typical

203
00:07:46,428 --> 00:07:48,730
prompt response pair that we expect this customer

204
00:07:48,730 --> 00:07:50,449
service chatbot to receive in production?

205
00:07:51,608 --> 00:07:53,689
I provided with a few examples which I

206
00:07:53,689 --> 00:07:54,369
have in mind.

207
00:07:55,519 --> 00:07:57,920
And as the conversation goes, the agent

208
00:07:57,920 --> 00:07:58,910
finally determines

209
00:07:59,199 --> 00:08:01,238
that the right technique to use in this case

210
00:08:01,238 --> 00:08:03,259
is preference tuning, using DPO.

211
00:08:04,548 --> 00:08:06,559
And it provides an explanation that, hey,

212
00:08:07,088 --> 00:08:09,428
DPO is a good technique for this use case

213
00:08:09,428 --> 00:08:11,470
because you want to align the tone

214
00:08:11,470 --> 00:08:13,189
of your customer service chatbot

215
00:08:13,629 --> 00:08:15,670
to match your brand voice, as well as

216
00:08:15,670 --> 00:08:17,928
you want to ground this agent in factual correctness.

217
00:08:18,149 --> 00:08:20,189
And you can meet both of these objectives if you

218
00:08:20,189 --> 00:08:20,988
use DPO.

219
00:08:23,389 --> 00:08:25,670
It goes on to then suggest a small language

220
00:08:25,670 --> 00:08:27,670
model, which is a great fit for my use case. I'm

221
00:08:27,670 --> 00:08:30,290
gonna choose the same model. It's a Lama 3.1

222
00:08:30,629 --> 00:08:31,488
as an example.

223
00:08:33,340 --> 00:08:35,340
And then finally it lays out the success

224
00:08:35,340 --> 00:08:35,960
criteria.

225
00:08:36,908 --> 00:08:38,950
It presents this criteria both in the form

226
00:08:38,950 --> 00:08:40,229
of a simple text,

227
00:08:40,548 --> 00:08:42,590
so it's a human readable, easy to understand

228
00:08:42,590 --> 00:08:44,798
text, as well as in the form of

229
00:08:44,798 --> 00:08:46,570
measurable success metrics.

230
00:08:48,769 --> 00:08:50,820
As you might see, these success metrics are

231
00:08:50,820 --> 00:08:53,158
aligned with the way I had described my use case.

232
00:08:54,109 --> 00:08:56,529
So, it has defined success metrics around

233
00:08:56,788 --> 00:08:58,479
measuring the politeness of the tone,

234
00:08:59,269 --> 00:09:01,269
measuring the alignment of the tone

235
00:09:01,269 --> 00:09:03,469
with my brand voice, making sure the

236
00:09:03,469 --> 00:09:04,469
responses are succinct.

237
00:09:05,340 --> 00:09:07,570
All these metrics are pretty much aligned with how I had

238
00:09:07,570 --> 00:09:08,879
described my use case to the agent.

239
00:09:09,879 --> 00:09:11,879
Now, once I and agent mutually agree upon

240
00:09:11,879 --> 00:09:13,969
this success criteria, I'm going to hit approve,

241
00:09:14,190 --> 00:09:16,479
and this will convert it into a hardened specification

242
00:09:16,479 --> 00:09:18,960
file. Once

243
00:09:18,960 --> 00:09:21,070
that specification is ready, we are ready to move on

244
00:09:21,070 --> 00:09:21,940
to the next step,

245
00:09:22,279 --> 00:09:24,408
which is to gather and prepare data.

246
00:09:25,849 --> 00:09:28,090
In this step, customers often tell us that

247
00:09:28,090 --> 00:09:30,330
sometimes collecting data can be quite costly

248
00:09:30,330 --> 00:09:31,048
and cumbersome.

249
00:09:32,408 --> 00:09:34,529
Other times it may just simply contain some

250
00:09:34,529 --> 00:09:36,928
private and sensitive information, making it impossible

251
00:09:36,928 --> 00:09:38,129
to use that data for training.

252
00:09:39,928 --> 00:09:41,469
To help customers address this sh,

253
00:09:42,288 --> 00:09:43,109
we announced

254
00:09:43,450 --> 00:09:45,649
a new synthetic data generation capability

255
00:09:45,649 --> 00:09:46,950
in Sagemaker AI.

256
00:09:47,529 --> 00:09:49,989
It's also available in preview starting this week.

257
00:09:50,570 --> 00:09:51,989
Using this new capability,

258
00:09:52,250 --> 00:09:54,250
you can generate data which is grounded in

259
00:09:54,250 --> 00:09:55,389
your context

260
00:09:55,808 --> 00:09:57,548
completely privately and securely.

261
00:10:00,250 --> 00:10:01,538
To use this capability,

262
00:10:01,859 --> 00:10:03,940
all you need to do is to go back into the

263
00:10:03,940 --> 00:10:06,440
model customization Asian chat interface.

264
00:10:07,099 --> 00:10:08,798
And then provide your context.

265
00:10:10,029 --> 00:10:12,029
You can choose to provide context in the form of a

266
00:10:12,029 --> 00:10:14,190
few inline prompt response samples,

267
00:10:14,469 --> 00:10:16,629
or you can point to a content repository in

268
00:10:16,629 --> 00:10:17,330
S3,

269
00:10:17,719 --> 00:10:20,200
which contains things like your PDF documents,

270
00:10:20,308 --> 00:10:22,308
customer support tickets, log files, and

271
00:10:22,308 --> 00:10:24,408
other things that you want to provide as a context.

272
00:10:25,379 --> 00:10:27,418
The agent uses this context to

273
00:10:27,418 --> 00:10:29,399
generate statistically similar data.

274
00:10:30,308 --> 00:10:32,349
And also a data quality report, and all of

275
00:10:32,349 --> 00:10:34,428
this process runs completely on a surveillance

276
00:10:34,428 --> 00:10:35,210
infrastructure,

277
00:10:35,509 --> 00:10:37,548
which means you don't have to manage any of the underlying

278
00:10:37,548 --> 00:10:39,090
compute and it automatically

279
00:10:39,548 --> 00:10:41,590
uh matches the size of your workload.

280
00:10:44,690 --> 00:10:47,190
Here is how the experience looks like in the chat interface,

281
00:10:47,369 --> 00:10:48,349
so it opens up

282
00:10:48,609 --> 00:10:50,889
this input form asking you to provide some

283
00:10:50,889 --> 00:10:52,960
inputs, for example, how many samples you want to

284
00:10:52,960 --> 00:10:53,548
generate

285
00:10:53,899 --> 00:10:56,009
and giving the S3 link for

286
00:10:56,009 --> 00:10:57,349
the context repository.

287
00:10:57,889 --> 00:10:58,710
Once you hit

288
00:10:59,168 --> 00:11:01,210
start synthetic generation, it generates both the

289
00:11:01,210 --> 00:11:03,210
data set and a data quality evaluation

290
00:11:03,210 --> 00:11:04,908
report with a bunch of useful metrics.

291
00:11:05,658 --> 00:11:07,200
Let's take a look at a few of those.

292
00:11:08,399 --> 00:11:10,918
So you get something like diversity analysis,

293
00:11:11,119 --> 00:11:13,279
which shows you how diverse your generated data

294
00:11:13,279 --> 00:11:15,359
is and whether you have all your

295
00:11:15,359 --> 00:11:17,359
demographic groups well represented without any

296
00:11:17,359 --> 00:11:18,139
biases.

297
00:11:20,229 --> 00:11:22,668
It also shows you certain quality statistics.

298
00:11:22,869 --> 00:11:25,369
In this case, it's showing you the mean length

299
00:11:25,590 --> 00:11:27,710
of responses generated in the synthetic

300
00:11:27,710 --> 00:11:28,330
data set.

301
00:11:29,080 --> 00:11:31,570
If you remember, I had asked the agent

302
00:11:31,808 --> 00:11:33,928
to create a customer service chatbot for me

303
00:11:33,928 --> 00:11:36,489
which produces clear, succinct responses.

304
00:11:36,899 --> 00:11:39,308
Hence, looking at the mean length of responses

305
00:11:39,570 --> 00:11:41,830
is an important success criteria or a metric

306
00:11:41,830 --> 00:11:43,250
to look at in the synthetic data.

307
00:11:45,570 --> 00:11:47,570
Also gives you access to a few of the responsible

308
00:11:47,570 --> 00:11:49,729
AI quality metrics to make sure

309
00:11:50,129 --> 00:11:52,369
that your generated data does not contain any

310
00:11:52,369 --> 00:11:54,489
toxic, harmful or sensitive content.

311
00:11:55,558 --> 00:11:58,070
Once you review these quality parameters,

312
00:11:58,548 --> 00:12:00,950
you can proceed onto the next step,

313
00:12:01,469 --> 00:12:03,769
which is to customize and evaluate the models.

314
00:12:06,489 --> 00:12:07,349
In this step,

315
00:12:07,769 --> 00:12:09,869
customers were telling us it's often

316
00:12:09,869 --> 00:12:11,969
very hard to set up the right fine-tuning

317
00:12:11,969 --> 00:12:14,298
infrastructure and then manage, scale and operate

318
00:12:14,298 --> 00:12:15,668
this infrastructure over time.

319
00:12:16,548 --> 00:12:18,950
And then as new fine tuning techniques

320
00:12:18,950 --> 00:12:21,418
keep on coming up, you have to keep on experimenting

321
00:12:21,418 --> 00:12:23,509
with those techniques, try out all those different

322
00:12:23,509 --> 00:12:24,859
hyperparameter choices,

323
00:12:25,178 --> 00:12:27,548
try to get the right cost performance, and all of this

324
00:12:27,548 --> 00:12:29,548
process of iteration and experimentation can take

325
00:12:29,548 --> 00:12:31,668
months. To

326
00:12:31,668 --> 00:12:34,029
help customers quickly get to a fine-tuned

327
00:12:34,029 --> 00:12:36,070
model, we announced a new

328
00:12:36,070 --> 00:12:38,548
serverless reinforcement learning capability in Sagemaker

329
00:12:38,548 --> 00:12:39,109
AI.

330
00:12:39,668 --> 00:12:42,149
Using this capability, you can now fine-tune

331
00:12:42,149 --> 00:12:44,149
a broad choice of popular open

332
00:12:44,149 --> 00:12:46,489
weights and Amazon Nova models

333
00:12:47,269 --> 00:12:49,340
using a host of fine-tuning techniques,

334
00:12:49,469 --> 00:12:51,668
including reinforcement learning in a completely

335
00:12:51,668 --> 00:12:52,529
serverless way.

336
00:12:55,038 --> 00:12:57,269
This capability supports a

337
00:12:57,269 --> 00:12:59,570
lot of popular openweight models like

338
00:13:00,548 --> 00:13:02,658
Metalaa, OpenAI GPT

339
00:13:02,658 --> 00:13:03,428
OSS,

340
00:13:03,710 --> 00:13:05,830
Queen, Deep Sek, and Amazon Nova

341
00:13:05,830 --> 00:13:06,729
model families.

342
00:13:08,279 --> 00:13:10,279
It also supports a broad

343
00:13:10,279 --> 00:13:12,580
suite of customization techniques. For example,

344
00:13:12,879 --> 00:13:15,119
you can use reinforcement learning with verifiable

345
00:13:15,119 --> 00:13:15,960
rewards

346
00:13:16,359 --> 00:13:18,399
for domains like math, science,

347
00:13:18,558 --> 00:13:19,219
code generation,

348
00:13:19,798 --> 00:13:21,178
or structured data output generation,

349
00:13:22,038 --> 00:13:24,340
where you can measure the output of a model

350
00:13:24,519 --> 00:13:26,210
using a simple reward function.

351
00:13:26,558 --> 00:13:28,639
And the reward score generated by this function

352
00:13:28,639 --> 00:13:30,558
can then be used to adjust the model weights.

353
00:13:32,219 --> 00:13:34,369
You can also use reinforcement learning with AI

354
00:13:34,369 --> 00:13:36,548
feedback where instead of a reward function,

355
00:13:36,859 --> 00:13:39,029
you can use a state of the art judge model

356
00:13:39,029 --> 00:13:41,190
like a cloud sonnet model to evaluate

357
00:13:41,190 --> 00:13:43,399
your model responses and generate a reward score.

358
00:13:45,479 --> 00:13:47,308
We also support preference tuning

359
00:13:47,729 --> 00:13:50,570
that lets you align your models to human preferences

360
00:13:50,570 --> 00:13:52,908
by providing a data set consisting of a prompt

361
00:13:53,009 --> 00:13:55,288
and a positive and a negative response as evaluated

362
00:13:55,288 --> 00:13:56,469
by human evaluators.

363
00:13:57,629 --> 00:13:59,830
This can be really useful if you're trying to align

364
00:13:59,830 --> 00:14:01,769
your model to things like

365
00:14:02,070 --> 00:14:04,389
helpfulness, to tone, to brand voice,

366
00:14:04,788 --> 00:14:06,509
where human preference is super important.

367
00:14:09,259 --> 00:14:11,379
And finally, you can run all these techniques, as I

368
00:14:11,379 --> 00:14:13,418
said, in a completely surless way, which means

369
00:14:13,418 --> 00:14:15,500
you don't have to procure, provision

370
00:14:15,500 --> 00:14:17,590
or manage any GPU clusters.

371
00:14:18,139 --> 00:14:20,168
You simply fire away your job

372
00:14:20,168 --> 00:14:21,678
with a push button approach

373
00:14:22,219 --> 00:14:24,298
with all the default hyperparameterss which have been

374
00:14:24,298 --> 00:14:26,369
tested by the service to give you the best cost

375
00:14:26,369 --> 00:14:27,038
performance,

376
00:14:27,580 --> 00:14:29,558
and I'm gonna show you what that experience looks like.

377
00:14:30,450 --> 00:14:32,479
So you go back into Sagemaker Studio and you go back

378
00:14:32,479 --> 00:14:33,859
to the Jumpstart Model hub.

379
00:14:34,469 --> 00:14:36,599
From the Jumpstart Model Hub, you get access to

380
00:14:36,750 --> 00:14:38,798
a host of state of the art open weights and

381
00:14:38,798 --> 00:14:40,399
proprietary foundation models.

382
00:14:41,058 --> 00:14:43,090
I'm gonna choose the Metal Armor model as

383
00:14:43,090 --> 00:14:43,840
an example.

384
00:14:44,340 --> 00:14:46,489
Once you click on customized model, you're gonna see

385
00:14:46,489 --> 00:14:47,599
a bunch of options.

386
00:14:48,739 --> 00:14:50,769
We already saw customization using AI

387
00:14:50,769 --> 00:14:53,099
agent as one of the user interfaces

388
00:14:53,099 --> 00:14:54,239
a couple of slides ago.

389
00:14:54,739 --> 00:14:56,798
Now I'm gonna show you the visual interface,

390
00:14:57,288 --> 00:14:58,859
how to customize using UI.

391
00:14:59,460 --> 00:15:01,460
So once I click on customize with UI, the screen

392
00:15:01,460 --> 00:15:03,658
opens up where I have to give a few

393
00:15:03,658 --> 00:15:05,820
minimal inputs. So first I need

394
00:15:05,820 --> 00:15:08,259
to use the technique here I'm gonna choose reinforcement

395
00:15:08,259 --> 00:15:09,678
learning with verifiable rewards.

396
00:15:10,820 --> 00:15:12,979
Then I need to upload my training data set.

397
00:15:13,629 --> 00:15:15,609
And finally, I need to choose a reward function.

398
00:15:16,779 --> 00:15:17,519
I can either

399
00:15:17,979 --> 00:15:20,139
choose from one among the many available

400
00:15:20,139 --> 00:15:21,460
built-in reward functions.

401
00:15:23,320 --> 00:15:25,519
Or I can write my own reward function

402
00:15:25,519 --> 00:15:26,058
as well.

403
00:15:27,710 --> 00:15:29,798
And if I have a reward function hosted

404
00:15:29,798 --> 00:15:30,859
as a lambda,

405
00:15:31,440 --> 00:15:33,178
I can bring that lambda in as well.

406
00:15:34,798 --> 00:15:37,308
Once you have given these few minimal inputs,

407
00:15:37,479 --> 00:15:39,639
you can just hit run. As you can see, all

408
00:15:39,639 --> 00:15:42,029
the hyperparameterss have been filled up by default.

409
00:15:42,399 --> 00:15:44,440
As I said, these recipes have been optimized

410
00:15:44,440 --> 00:15:46,558
by AWS to make sure you get the best

411
00:15:46,558 --> 00:15:48,428
cost performance on AWS hardware,

412
00:15:48,759 --> 00:15:50,820
so you can just straight away go and hit the run button

413
00:15:51,399 --> 00:15:52,619
and get a customized model.

414
00:15:54,869 --> 00:15:56,989
Now, as you go about doing these experiments, you

415
00:15:56,989 --> 00:15:58,450
would need a place to track

416
00:15:58,710 --> 00:16:00,729
and compare these experiments side by side.

417
00:16:02,210 --> 00:16:02,969
To help this,

418
00:16:03,330 --> 00:16:05,690
to help with this problem, we have launched a surless

419
00:16:05,690 --> 00:16:06,668
MLflow capability.

420
00:16:08,048 --> 00:16:10,288
So you can track all your model customization

421
00:16:10,288 --> 00:16:12,649
experiments using the server SML

422
00:16:12,649 --> 00:16:14,769
flow and compare those experiments side by

423
00:16:14,769 --> 00:16:17,048
side. This

424
00:16:17,048 --> 00:16:19,239
capability gives you access to the familiar ML

425
00:16:19,239 --> 00:16:20,210
flow interface.

426
00:16:21,139 --> 00:16:23,190
The entire ML4 tracking server runs

427
00:16:23,190 --> 00:16:25,308
in a completely serverless way, so there is no

428
00:16:25,308 --> 00:16:27,399
compute to manage, and it's available at

429
00:16:27,399 --> 00:16:29,369
no additional charge. It's free.

430
00:16:30,190 --> 00:16:32,349
It's just there, available in studio, and I'm gonna

431
00:16:32,349 --> 00:16:33,379
show you the experience.

432
00:16:33,830 --> 00:16:35,869
So once you launch a fine-tuning job and you go and

433
00:16:35,869 --> 00:16:37,969
open up the job details page, you can

434
00:16:37,969 --> 00:16:40,029
see some of the metrics which already start

435
00:16:40,029 --> 00:16:41,609
appearing on the job details page,

436
00:16:41,960 --> 00:16:44,139
like training loss and validation accuracy. All

437
00:16:44,139 --> 00:16:46,460
these metrics are getting pulled from the server SML

438
00:16:46,460 --> 00:16:49,250
flow. And

439
00:16:49,250 --> 00:16:51,288
if you want to see more metrics and do a deep

440
00:16:51,288 --> 00:16:53,629
dive, you can just click on these links

441
00:16:53,769 --> 00:16:55,769
embedded right there to open up

442
00:16:55,769 --> 00:16:57,690
MLflow in a separate browser tab.

443
00:16:58,779 --> 00:17:00,859
There you can choose to go back into that

444
00:17:00,859 --> 00:17:02,979
training run and do a deep dive, or

445
00:17:02,979 --> 00:17:03,678
you can choose

446
00:17:04,219 --> 00:17:06,618
multiple training runs side by side and do a comparison.

447
00:17:09,269 --> 00:17:11,430
Once you have identified a model candidate after

448
00:17:11,430 --> 00:17:13,949
running a bunch of experiments that you want to take forward,

449
00:17:14,239 --> 00:17:16,269
now is the time for model evaluation

450
00:17:16,269 --> 00:17:18,309
and make sure it meets the success criteria

451
00:17:18,309 --> 00:17:19,608
you had determined at the beginning.

452
00:17:21,838 --> 00:17:23,209
To run model evaluation,

453
00:17:23,650 --> 00:17:25,769
we are pleased to also add another capability

454
00:17:25,769 --> 00:17:27,769
of serverless model evaluation in Sage

455
00:17:27,769 --> 00:17:28,449
Maker AI

456
00:17:28,729 --> 00:17:30,769
that lets you evaluate and compare models

457
00:17:30,769 --> 00:17:33,130
on multiple different dimensions in a completely serverless

458
00:17:33,130 --> 00:17:35,430
way. You

459
00:17:35,430 --> 00:17:37,670
might have already noticed I'm using the word serverless

460
00:17:37,670 --> 00:17:39,949
with every capability, and that's what our vision is,

461
00:17:40,229 --> 00:17:42,239
that every capability comes to you

462
00:17:42,239 --> 00:17:44,529
without having to manage any infrastructure

463
00:17:44,529 --> 00:17:46,549
throughout the model customization workflow.

464
00:17:47,259 --> 00:17:49,469
With this surveillance model evaluation capability, you

465
00:17:49,469 --> 00:17:51,578
simply can try out multiple different

466
00:17:51,578 --> 00:17:53,519
evaluation techniques. For example,

467
00:17:53,939 --> 00:17:54,549
you can run

468
00:17:55,259 --> 00:17:57,608
industry standard benchmarks like MMLU.

469
00:17:58,699 --> 00:18:01,029
You can choose to provide your own custom scoring

470
00:18:01,029 --> 00:18:03,199
function. Or you can use

471
00:18:03,199 --> 00:18:05,199
an LLM as a judge, where you can

472
00:18:05,199 --> 00:18:07,318
use a clot sonnet or a GPT OSS

473
00:18:07,318 --> 00:18:09,699
model as a judge to evaluate your model

474
00:18:09,699 --> 00:18:11,578
responses and generate evaluation scores.

475
00:18:13,380 --> 00:18:15,868
This capability not only collects the evaluation

476
00:18:15,868 --> 00:18:17,670
results from your job, but also

477
00:18:17,930 --> 00:18:20,130
summarizes them, aggregates them, and gives

478
00:18:20,130 --> 00:18:22,289
you a summarized report comparing

479
00:18:22,289 --> 00:18:24,519
the evaluation outcomes of your customized

480
00:18:24,519 --> 00:18:26,568
model against that of the base model.

481
00:18:26,969 --> 00:18:29,108
So you can quickly determine if your customization

482
00:18:29,108 --> 00:18:31,430
is having the right impact on your model.

483
00:18:32,410 --> 00:18:33,759
I'm gonna show this experience.

484
00:18:34,170 --> 00:18:36,729
So here's the visual experience in studio.

485
00:18:37,000 --> 00:18:38,729
You go back, you can see the

486
00:18:39,108 --> 00:18:41,209
3 evaluation techniques on the top. I'm gonna

487
00:18:41,209 --> 00:18:42,549
choose LLM as a judge.

488
00:18:43,380 --> 00:18:45,779
And I'm going to choose clots on it as the

489
00:18:45,779 --> 00:18:46,598
judge model.

490
00:18:47,719 --> 00:18:50,000
Then I'm gonna specify the evaluation metrics

491
00:18:50,000 --> 00:18:51,920
I want the re model to evaluate on.

492
00:18:52,439 --> 00:18:54,338
I can choose among one of the many

493
00:18:54,640 --> 00:18:56,719
quality and responsible AI metrics

494
00:18:56,719 --> 00:18:58,019
which are available out of the box.

495
00:18:59,199 --> 00:19:01,199
Or I can provide my own custom

496
00:19:01,199 --> 00:19:01,979
metrics,

497
00:19:02,380 --> 00:19:03,618
using a simple prompt.

498
00:19:05,838 --> 00:19:08,098
You can use one of the built-in prompt templates,

499
00:19:08,549 --> 00:19:10,559
write down a prompt for your custom metrics, or you

500
00:19:10,559 --> 00:19:12,578
can write a prompt completely from scratch.

501
00:19:13,160 --> 00:19:15,160
All of these options and flexibility is

502
00:19:15,160 --> 00:19:16,219
completely available for you,

503
00:19:16,519 --> 00:19:18,559
so you can choose to run your evaluation in the way

504
00:19:18,559 --> 00:19:20,019
that best fits your use case.

505
00:19:20,719 --> 00:19:22,759
Once you run the evaluation, it generates

506
00:19:22,759 --> 00:19:24,789
this summary report which I was talking about,

507
00:19:25,000 --> 00:19:27,170
that lets you compare the base model against

508
00:19:27,170 --> 00:19:29,689
the fine-tuned model on all the summary statistics.

509
00:19:30,039 --> 00:19:32,439
So you can quickly at a glance determine if your model

510
00:19:32,439 --> 00:19:34,479
looks better after customization and move

511
00:19:34,479 --> 00:19:35,459
on to the next step.

512
00:19:35,880 --> 00:19:38,049
Wishes to deploy the model in production

513
00:19:38,049 --> 00:19:38,779
for inference.

514
00:19:41,358 --> 00:19:43,358
When it comes to deployment, Sagemaker

515
00:19:43,358 --> 00:19:44,588
gives you two options,

516
00:19:44,880 --> 00:19:46,029
easy to use options.

517
00:19:46,358 --> 00:19:47,939
You can choose to deploy either

518
00:19:48,509 --> 00:19:50,858
to Bedrock in a few simple clicks,

519
00:19:51,559 --> 00:19:53,670
or you can deploy it on Sage Maker for

520
00:19:53,670 --> 00:19:54,259
inference.

521
00:19:55,509 --> 00:19:57,150
If you deploy on Sage Maker AI,

522
00:19:57,549 --> 00:19:59,650
we do provide a bunch of

523
00:19:59,650 --> 00:20:01,328
built-in capabilities to help you

524
00:20:02,068 --> 00:20:03,650
improve your cost performance.

525
00:20:04,309 --> 00:20:05,140
For example,

526
00:20:05,420 --> 00:20:07,750
the Sage Maker inference comes with multi-

527
00:20:07,750 --> 00:20:09,789
Lora deployments where if you

528
00:20:09,789 --> 00:20:11,880
are training multiple different Lora adapters for

529
00:20:11,880 --> 00:20:14,219
different use cases on top of the same base model,

530
00:20:14,469 --> 00:20:16,549
you can bin pack all those Lora adapters

531
00:20:16,549 --> 00:20:18,670
along with the base model onto the same instance

532
00:20:18,910 --> 00:20:19,568
and set up

533
00:20:20,108 --> 00:20:22,150
flexible independent scaling policies

534
00:20:22,150 --> 00:20:23,049
for each adapter.

535
00:20:23,400 --> 00:20:24,439
And that lets you

536
00:20:24,759 --> 00:20:26,598
manage the right

537
00:20:27,000 --> 00:20:29,118
performance, matching the demand patterns for each of

538
00:20:29,118 --> 00:20:31,279
those Loa variants, as well as

539
00:20:31,279 --> 00:20:33,598
reduce the cost by bin packing them onto the same instance.

540
00:20:35,289 --> 00:20:37,529
Similarly, we also give other techniques like

541
00:20:37,529 --> 00:20:39,689
dynamic adaptive speculative decoding,

542
00:20:40,009 --> 00:20:41,309
uh, which lets you train

543
00:20:42,130 --> 00:20:44,250
personalized draft models on your private

544
00:20:44,250 --> 00:20:46,309
data. We call them eagleheads.

545
00:20:47,150 --> 00:20:49,229
And using these eagle heads you can

546
00:20:49,229 --> 00:20:51,549
then run inference against the incoming

547
00:20:51,549 --> 00:20:53,828
prompts in a very cost effective way and

548
00:20:53,828 --> 00:20:56,289
then pass on only a subset

549
00:20:56,578 --> 00:20:59,029
of the generated tokens onto your main customized

550
00:20:59,029 --> 00:21:01,549
model, which results this two-phase inference

551
00:21:01,549 --> 00:21:03,779
results in the reduced overall cost of inference

552
00:21:03,779 --> 00:21:04,848
with higher performance.

553
00:21:05,838 --> 00:21:08,269
All these capabilities are built in as part of StageMaker

554
00:21:08,269 --> 00:21:09,039
AI inference,

555
00:21:09,318 --> 00:21:11,410
so I would definitely encourage you all to go

556
00:21:11,410 --> 00:21:12,219
and give it a spin.

557
00:21:14,650 --> 00:21:16,650
Now, once you are done deploying the model

558
00:21:16,650 --> 00:21:18,588
for inference, now comes the final step.

559
00:21:20,000 --> 00:21:20,939
Building the agent.

560
00:21:22,930 --> 00:21:23,539
For this,

561
00:21:23,858 --> 00:21:25,939
you use the Bedrock Asian core suite of tools

562
00:21:25,939 --> 00:21:28,059
which works with both Bedrock endpoints as

563
00:21:28,059 --> 00:21:30,380
well as the Sagemaker AI Inference endpoints.

564
00:21:31,410 --> 00:21:32,689
With Bedrock Agent Core,

565
00:21:32,979 --> 00:21:35,259
you get a bunch of tools and services to deploy

566
00:21:35,259 --> 00:21:36,858
and monitor your agents in production.

567
00:21:38,930 --> 00:21:41,250
First, Bedrock Asian Core is quite open.

568
00:21:41,449 --> 00:21:43,769
It works with all the popular Asian development

569
00:21:43,769 --> 00:21:45,000
software toolkits.

570
00:21:45,529 --> 00:21:47,529
For example, you can bring Crew AI,

571
00:21:47,689 --> 00:21:50,009
Landgraph, OpenAI SDK kit,

572
00:21:50,289 --> 00:21:52,318
or you can use the Amazon's TransAent to

573
00:21:52,318 --> 00:21:53,868
build your Asiantic workflow.

574
00:21:54,660 --> 00:21:57,500
You can then deploy it onto the completely surless

575
00:21:57,500 --> 00:21:59,000
runtime of the agent core.

576
00:21:59,500 --> 00:22:01,618
This runtime allows you to run the agents

577
00:22:01,618 --> 00:22:03,660
even for prolonged periods of time if you have

578
00:22:03,660 --> 00:22:05,779
any batch process running behind the scenes.

579
00:22:08,289 --> 00:22:10,449
Agent Core also gives you managed primitives

580
00:22:10,449 --> 00:22:11,049
for memory,

581
00:22:11,598 --> 00:22:13,809
both short term and long-term memory, so you can maintain

582
00:22:13,809 --> 00:22:16,049
the context of your conversations as well as maintain

583
00:22:16,049 --> 00:22:17,848
user preferences across sessions.

584
00:22:19,088 --> 00:22:21,088
Now, as your agents run, they would typically

585
00:22:21,088 --> 00:22:23,170
need to connect with multiple tools to complete

586
00:22:23,170 --> 00:22:23,828
their task.

587
00:22:24,219 --> 00:22:26,828
So agent code gives you a managed MCP gateway

588
00:22:27,088 --> 00:22:29,519
to connect with these third party and first party tools.

589
00:22:29,848 --> 00:22:32,049
In addition, it also gives you certain first party

590
00:22:32,049 --> 00:22:34,049
tools out of the box. So for example, it gives you

591
00:22:34,049 --> 00:22:35,509
a code execution runtime

592
00:22:35,969 --> 00:22:37,949
and also a browser runtime

593
00:22:38,289 --> 00:22:40,640
to browse the web and extract

594
00:22:40,640 --> 00:22:41,449
information on the fly.

595
00:22:43,739 --> 00:22:45,868
And finally, once you are done deploying the agent,

596
00:22:46,519 --> 00:22:48,519
It gives you ways to just monitor the

597
00:22:48,519 --> 00:22:50,739
agents and trace the entire

598
00:22:50,739 --> 00:22:53,160
agentic call throughout the agentic workflow

599
00:22:53,160 --> 00:22:55,299
and publishes these traces in the form of

600
00:22:55,479 --> 00:22:57,640
an open telemetry format so you can bring your

601
00:22:57,640 --> 00:22:59,759
own choice of observability

602
00:22:59,759 --> 00:23:01,098
stack and

603
00:23:01,598 --> 00:23:03,380
analyze and observe these traces.

604
00:23:07,368 --> 00:23:09,449
One of the things I want to call out here in

605
00:23:09,449 --> 00:23:11,489
the Bedrock Agent Core toolkit is the strands

606
00:23:11,489 --> 00:23:13,309
SDK which really makes it easy

607
00:23:13,729 --> 00:23:15,769
to develop your agentic workflow. This forms

608
00:23:15,769 --> 00:23:17,430
the backbone of developing your agent.

609
00:23:18,078 --> 00:23:20,199
And I think to show you how this can be done

610
00:23:20,199 --> 00:23:22,358
very easily, I'm going to invite my friend Davidek

611
00:23:22,358 --> 00:23:24,439
to come back on stage and show you a live demo.

612
00:23:28,479 --> 00:23:29,160
Thank you, Summit.

613
00:23:31,000 --> 00:23:31,598
Awesome.

614
00:23:32,430 --> 00:23:34,848
Let me prepare my computer for the demo.

615
00:23:35,309 --> 00:23:35,989
There we go.

616
00:23:36,858 --> 00:23:37,519
Perfect.

617
00:23:38,400 --> 00:23:40,439
So, we're just gonna go ahead and get started with the

618
00:23:40,439 --> 00:23:42,680
demo. Let me give you like a brief rundown

619
00:23:42,680 --> 00:23:44,670
of what this is gonna be all about.

620
00:23:45,199 --> 00:23:47,239
Let's assume that you've been tasked

621
00:23:47,239 --> 00:23:49,519
with the one challenge that we've seen

622
00:23:49,519 --> 00:23:50,479
very common

623
00:23:50,838 --> 00:23:53,078
across basically every customer that I've been working

624
00:23:53,078 --> 00:23:55,189
with. Customers normally have a

625
00:23:55,189 --> 00:23:57,640
business analyst or a business intelligence

626
00:23:57,640 --> 00:23:58,368
persona.

627
00:23:58,920 --> 00:24:00,900
They have a platform where they can throw

628
00:24:01,559 --> 00:24:04,000
some questions against this. It could be a chatbot,

629
00:24:04,039 --> 00:24:06,318
it could be just a web interface, a UI.

630
00:24:07,059 --> 00:24:09,420
Normally, these business analysts, they have

631
00:24:09,420 --> 00:24:11,118
great knowledge about the domain

632
00:24:12,588 --> 00:24:13,289
that they wanna work on,

633
00:24:13,578 --> 00:24:15,739
but not necessarily have the knowledge to know

634
00:24:15,739 --> 00:24:18,118
how to write SQL queries from scratch.

635
00:24:19,259 --> 00:24:21,459
So this is the task that we have. Our goal

636
00:24:21,459 --> 00:24:23,500
is to work with this company.

637
00:24:23,588 --> 00:24:25,959
This company, uh, basically

638
00:24:25,959 --> 00:24:28,000
retail is in a new retail

639
00:24:28,000 --> 00:24:30,019
industry. They have different tables, they have a

640
00:24:30,019 --> 00:24:32,439
data catalog, and they wanna make sure

641
00:24:32,439 --> 00:24:34,519
that the agents that they build

642
00:24:34,519 --> 00:24:36,088
is a business analyst agent,

643
00:24:36,880 --> 00:24:39,239
which can receive natural language questions

644
00:24:39,709 --> 00:24:42,420
and output SQL queries, execute

645
00:24:42,420 --> 00:24:44,578
the SQL queries and provide the

646
00:24:44,578 --> 00:24:47,140
results once again in natural language

647
00:24:47,140 --> 00:24:48,019
back to the user.

648
00:24:48,739 --> 00:24:49,500
To do that,

649
00:24:49,828 --> 00:24:50,729
we will use, of course,

650
00:24:50,989 --> 00:24:52,269
Amazon Sage Maker AI.

651
00:24:52,670 --> 00:24:54,789
Specifically, we will use the new capabilities that were

652
00:24:54,789 --> 00:24:56,568
just introduced by Summit

653
00:24:57,108 --> 00:24:59,660
in uh the Sage Maker Studio interface.

654
00:24:59,959 --> 00:25:02,068
Of course, I'm gonna walk you through the UI

655
00:25:02,068 --> 00:25:04,390
aspect of it, just for the sake of it being

656
00:25:04,390 --> 00:25:06,709
easy for you to understand right now, but

657
00:25:06,709 --> 00:25:08,750
all of that you see is also available via

658
00:25:08,750 --> 00:25:10,588
code in the form of an SDK.

659
00:25:12,608 --> 00:25:15,150
So what are the steps that we're gonna go through the demo?

660
00:25:15,689 --> 00:25:16,630
We're gonna start by

661
00:25:17,250 --> 00:25:19,299
choosing an off the shelf small

662
00:25:19,299 --> 00:25:21,568
language model. Our goal is to use a small language

663
00:25:21,568 --> 00:25:22,949
model to be cost effective,

664
00:25:23,449 --> 00:25:25,769
to have a training that doesn't last for weeks

665
00:25:25,769 --> 00:25:27,430
and instead lasts for hours,

666
00:25:27,809 --> 00:25:28,750
maybe even minutes.

667
00:25:30,209 --> 00:25:32,449
We will leverage synthetic data, so

668
00:25:32,449 --> 00:25:34,568
the customer unfortunately didn't provide us with any

669
00:25:34,568 --> 00:25:36,828
specific data or queries that they've already pre-built.

670
00:25:37,209 --> 00:25:39,519
So we're gonna use the service data

671
00:25:39,519 --> 00:25:41,568
generation capabilities in order to create a

672
00:25:41,568 --> 00:25:42,650
synthetic data set.

673
00:25:43,368 --> 00:25:45,410
We'll use that to customize the

674
00:25:45,410 --> 00:25:47,959
small language model, evaluate it, deploy,

675
00:25:48,289 --> 00:25:49,289
use it for an agent.

676
00:25:50,160 --> 00:25:50,789
I think

677
00:25:51,049 --> 00:25:53,549
we spoke already enough in, in general terms

678
00:25:53,549 --> 00:25:54,170
about the demo.

679
00:25:54,529 --> 00:25:56,568
So let's, let's just jump directly into

680
00:25:56,568 --> 00:25:58,150
the UI and into the code.

681
00:26:03,769 --> 00:26:04,630
In a second.

682
00:26:06,259 --> 00:26:08,259
Perfect. Alright. I'm gonna zoom in

683
00:26:08,259 --> 00:26:10,338
a little bit so that the people that are a little bit further away,

684
00:26:10,368 --> 00:26:11,000
they can see.

685
00:26:11,799 --> 00:26:13,779
Uh, at least a little bit better.

686
00:26:14,400 --> 00:26:16,509
Cool. So, our journey, as

687
00:26:16,509 --> 00:26:17,618
always, starts

688
00:26:17,920 --> 00:26:19,299
within Sagemaker Studio.

689
00:26:19,719 --> 00:26:21,920
So in Sage Maker Studio, when you jump in, you will have

690
00:26:21,920 --> 00:26:23,959
all the different applications that are available,

691
00:26:24,000 --> 00:26:26,279
the Jupiter labs, the studios, the Canvas,

692
00:26:26,439 --> 00:26:28,519
the code editor, etc. etc. the new

693
00:26:28,519 --> 00:26:29,689
serverlessML flow.

694
00:26:30,118 --> 00:26:32,699
But our journey actually starts from the Jumpstart

695
00:26:32,979 --> 00:26:35,039
Model hub, which you can access from the

696
00:26:35,039 --> 00:26:36,338
Models tab here on the left.

697
00:26:37,259 --> 00:26:39,380
There are some spotlight models, we're gonna use one

698
00:26:39,380 --> 00:26:40,410
of them today.

699
00:26:40,818 --> 00:26:43,250
Some of them are from Amazon, like the Nova 2

700
00:26:43,250 --> 00:26:45,519
Doo family, which is now available also

701
00:26:45,519 --> 00:26:47,660
in Sage Maker for customization, but

702
00:26:47,660 --> 00:26:49,739
also open source models ranging

703
00:26:49,739 --> 00:26:52,009
from Meta Lamas model to Quan models

704
00:26:52,009 --> 00:26:53,250
to OpenAI models.

705
00:26:53,539 --> 00:26:55,828
And you can actually drill down and see

706
00:26:55,828 --> 00:26:58,000
which models are available for serverless

707
00:26:58,000 --> 00:26:59,049
fine tuning

708
00:26:59,338 --> 00:27:01,380
by selecting this filter here and

709
00:27:01,380 --> 00:27:02,699
check the trainable serverless.

710
00:27:03,618 --> 00:27:05,809
Right now we have 14 models

711
00:27:05,818 --> 00:27:07,939
supported by the serverless capabilities, but you

712
00:27:07,939 --> 00:27:10,259
can expect this number to grow a lot

713
00:27:10,259 --> 00:27:12,098
in the next weeks and the next month.

714
00:27:13,029 --> 00:27:13,618
Months.

715
00:27:14,640 --> 00:27:16,719
So, what I'm gonna be doing today is that I'm gonna

716
00:27:16,719 --> 00:27:17,789
start with the,

717
00:27:18,118 --> 00:27:20,799
uh, I'm gonna choose the MetaLa 3.18

718
00:27:20,799 --> 00:27:22,920
billion instruct. It's a model that I know

719
00:27:22,920 --> 00:27:24,959
and I tested already, so this

720
00:27:24,959 --> 00:27:26,818
is the model that I wanna go ahead and customize.

721
00:27:27,199 --> 00:27:29,279
But of course for your use case, you can use whatever you want.

722
00:27:29,348 --> 00:27:30,118
You can go as

723
00:27:30,479 --> 00:27:32,818
little as, for example, 0.3 0.6

724
00:27:32,818 --> 00:27:33,779
billion model.

725
00:27:34,939 --> 00:27:37,059
23, 4 billion, etc. etc.

726
00:27:37,150 --> 00:27:38,809
There's a lot of different models out there.

727
00:27:39,118 --> 00:27:41,229
I'm just gonna go ahead and choose this one. And

728
00:27:41,229 --> 00:27:43,309
I have two options, actually, I have three

729
00:27:43,309 --> 00:27:44,650
options. There's the

730
00:27:44,949 --> 00:27:45,890
code full version,

731
00:27:46,269 --> 00:27:47,549
so customizing with code.

732
00:27:47,828 --> 00:27:50,019
There's the UI driven optimization,

733
00:27:50,068 --> 00:27:52,068
customization using the interface that

734
00:27:52,068 --> 00:27:53,348
was shown before by Summit.

735
00:27:53,709 --> 00:27:54,250
But today,

736
00:27:54,588 --> 00:27:56,328
we're gonna focus on customizing

737
00:27:56,709 --> 00:27:58,469
a model with an AI agent.

738
00:27:59,509 --> 00:28:01,549
So, the very first thing is the agent

739
00:28:01,549 --> 00:28:03,029
very simply is gonna tell us, hey,

740
00:28:03,390 --> 00:28:05,390
what is the specific task that you

741
00:28:05,390 --> 00:28:06,250
want to solve?

742
00:28:07,430 --> 00:28:09,469
And we're gonna tell it. I should already have it

743
00:28:09,469 --> 00:28:10,430
here in memory.

744
00:28:10,920 --> 00:28:12,209
So let's just to

745
00:28:12,509 --> 00:28:13,809
use this one.

746
00:28:15,338 --> 00:28:15,959
So,

747
00:28:16,618 --> 00:28:18,779
I want to fine tune a model to assist business

748
00:28:18,779 --> 00:28:20,900
analysts and data analysts in writing correct

749
00:28:20,900 --> 00:28:22,979
and efficient SQL queries, improving query

750
00:28:22,979 --> 00:28:25,219
connectness, and reducing time to insights.

751
00:28:26,009 --> 00:28:28,049
This is a message that I already had

752
00:28:28,049 --> 00:28:30,209
pre-created, but virtually you can use any,

753
00:28:30,289 --> 00:28:32,318
you can solve any kind of problem here,

754
00:28:32,568 --> 00:28:34,809
because the goal of the agent behind the scenes is to

755
00:28:34,809 --> 00:28:36,189
walk you through the steps.

756
00:28:36,959 --> 00:28:39,039
So that you can understand and you can

757
00:28:39,039 --> 00:28:41,358
get the best suggestions on how to solve

758
00:28:41,358 --> 00:28:43,439
your problem. You will see, as

759
00:28:43,439 --> 00:28:45,469
it was already shown by Summit, that this is

760
00:28:45,469 --> 00:28:47,519
gonna be spec driven development. You're

761
00:28:47,519 --> 00:28:49,670
gonna see a lot of files that detail step

762
00:28:49,670 --> 00:28:50,338
by step

763
00:28:50,630 --> 00:28:52,699
what the model, what the agent needs to do

764
00:28:52,799 --> 00:28:54,799
in order to make sure that it solves the right

765
00:28:54,799 --> 00:28:55,618
problem for you.

766
00:28:57,209 --> 00:28:59,549
So, first of all, it already identifies, OK,

767
00:28:59,848 --> 00:29:01,848
this is likely gonna be an SFT use case,

768
00:29:02,049 --> 00:29:04,049
supervised fine tuning, and it tells you

769
00:29:04,049 --> 00:29:04,809
why, right?

770
00:29:05,279 --> 00:29:07,358
The SFT leverages labeled examples

771
00:29:07,358 --> 00:29:09,180
of SQL prompts and correct answers,

772
00:29:09,449 --> 00:29:11,650
so basically that's the prompt completion pairs.

773
00:29:12,039 --> 00:29:14,078
This seems correct to me, but if I wanted to,

774
00:29:14,160 --> 00:29:15,160
I could have told him,

775
00:29:15,439 --> 00:29:17,439
hey, another good way to train

776
00:29:17,439 --> 00:29:19,439
a model for SQL query generation

777
00:29:19,439 --> 00:29:20,078
is, for example,

778
00:29:20,439 --> 00:29:22,719
reinforcement learning with verifiable rewards.

779
00:29:23,078 --> 00:29:25,199
Because I could be executing the queries behind the

780
00:29:25,199 --> 00:29:27,400
scenes, getting the results, and using

781
00:29:27,400 --> 00:29:28,818
that results, if correct,

782
00:29:29,118 --> 00:29:31,118
to drive further the

783
00:29:31,118 --> 00:29:32,539
uh fine tuning of the model.

784
00:29:34,479 --> 00:29:36,559
So, for now, uh, for

785
00:29:36,559 --> 00:29:38,650
some reason it's asking me again, so we'll just,

786
00:29:38,719 --> 00:29:39,650
uh, say it again.

787
00:29:39,959 --> 00:29:41,959
So, we're gonna be using SFT and you're gonna see

788
00:29:41,959 --> 00:29:44,140
that the very next step is gonna be asking a little bit

789
00:29:44,140 --> 00:29:45,199
more questions about,

790
00:29:45,479 --> 00:29:47,640
you know, what does the, uh, what, what

791
00:29:47,640 --> 00:29:49,838
should be the data that we want to use. So, first,

792
00:29:49,920 --> 00:29:52,098
the first step is selecting the model. It

793
00:29:52,098 --> 00:29:54,250
remembers that I'm using 3.18

794
00:29:54,250 --> 00:29:56,380
billion. So, I'm gonna go ahead and use

795
00:29:56,380 --> 00:29:57,390
this model, of course,

796
00:29:57,759 --> 00:29:59,838
accepting the license agreement in this

797
00:29:59,838 --> 00:30:01,939
case. And then the next step is,

798
00:30:02,059 --> 00:30:04,140
OK, how do I tell it which data I want

799
00:30:04,140 --> 00:30:04,660
to use.

800
00:30:04,939 --> 00:30:06,939
In this case, I don't have any data, uh, I

801
00:30:06,939 --> 00:30:09,059
just have an example that I can share with it, and

802
00:30:09,059 --> 00:30:11,059
you're gonna see that it will prompt me

803
00:30:11,059 --> 00:30:12,259
to how to generate uh the,

804
00:30:13,199 --> 00:30:14,358
the data set.

805
00:30:15,140 --> 00:30:17,199
First, it make sure that the use case

806
00:30:17,199 --> 00:30:18,150
is the correct one.

807
00:30:18,459 --> 00:30:20,779
So it gives me the spec, This is what I was referring

808
00:30:20,779 --> 00:30:22,479
to in terms of spec driven development.

809
00:30:22,979 --> 00:30:25,019
It tells me, hey, the business problem you want to solve is

810
00:30:25,019 --> 00:30:27,098
to assist the business analysts and data analyst, what I

811
00:30:27,098 --> 00:30:27,799
told you before.

812
00:30:28,549 --> 00:30:30,588
It defines some tenets, tenets

813
00:30:30,588 --> 00:30:31,439
for success.

814
00:30:31,789 --> 00:30:33,979
The query needs to be correct, needs to be efficient,

815
00:30:34,150 --> 00:30:36,189
needs to be explainable, needs to have a professional

816
00:30:36,189 --> 00:30:37,660
tone. OK, maybe this is irrelevant.

817
00:30:37,989 --> 00:30:39,989
Most importantly, it needs to be safety, so it

818
00:30:39,989 --> 00:30:42,150
doesn't have to do any right queries

819
00:30:42,150 --> 00:30:44,588
back to SQL, uh, that needs to be

820
00:30:44,588 --> 00:30:45,348
a safe one.

821
00:30:45,848 --> 00:30:47,969
If I don't like any of these specs, I can go ahead

822
00:30:47,969 --> 00:30:50,000
and just edit, so I can go, for example,

823
00:30:50,009 --> 00:30:52,068
here and change anything about the

824
00:30:52,250 --> 00:30:54,479
description of the explanation, clarity. To

825
00:30:54,479 --> 00:30:56,608
be honest, they're pretty fine. I'm gonna keep also the

826
00:30:56,608 --> 00:30:58,640
professional tone, why not? So I'm gonna save and

827
00:30:58,640 --> 00:30:59,170
approve.

828
00:30:59,689 --> 00:31:01,779
Remember that whenever we do spec

829
00:31:01,779 --> 00:31:04,130
driven development, your goal is not to just

830
00:31:04,130 --> 00:31:06,170
blindly accept the spec that come from

831
00:31:06,170 --> 00:31:06,930
the agent.

832
00:31:07,449 --> 00:31:09,858
That spec is gonna be the one that drives

833
00:31:09,858 --> 00:31:12,088
your use case, so make sure that it is aligned

834
00:31:12,088 --> 00:31:13,630
with what you actually want to achieve.

835
00:31:15,719 --> 00:31:17,880
So in just a second here, what's gonna happen

836
00:31:17,880 --> 00:31:19,699
is that we are gonna jump, there we go.

837
00:31:20,160 --> 00:31:22,279
So, let's create an example for your use case. If

838
00:31:22,279 --> 00:31:24,519
you have any specific details about the space backset

839
00:31:24,519 --> 00:31:26,328
behavior, blah blah blah, please share them now.

840
00:31:26,880 --> 00:31:28,539
I do have something already.

841
00:31:29,328 --> 00:31:30,130
Which is, uh,

842
00:31:30,588 --> 00:31:32,279
there we go. I have an example,

843
00:31:32,598 --> 00:31:35,039
so, this is an example that I can use to generate

844
00:31:35,039 --> 00:31:37,358
more uh more examples here, sorry for the

845
00:31:37,358 --> 00:31:38,299
repetition there.

846
00:31:38,759 --> 00:31:39,828
So my prompt says,

847
00:31:40,160 --> 00:31:42,239
you are an AI assistant tasked with answering

848
00:31:42,239 --> 00:31:44,400
user questions with accurate SQL queries,

849
00:31:44,689 --> 00:31:46,739
so I have a data schema. In this case, I only

850
00:31:46,739 --> 00:31:48,920
have two tables, so it's gonna be very short, but

851
00:31:48,920 --> 00:31:50,509
you can enrich this as you want.

852
00:31:50,838 --> 00:31:52,930
And I provide it with a completion. So, a

853
00:31:52,930 --> 00:31:53,858
SQL query

854
00:31:54,160 --> 00:31:55,500
with a detailed examples.

855
00:31:56,209 --> 00:31:58,568
So what's gonna happen now is that the agent

856
00:31:58,568 --> 00:32:00,689
is gonna leverage this example that I give to it

857
00:32:00,689 --> 00:32:02,519
to generate two more examples.

858
00:32:02,930 --> 00:32:05,130
I'm gonna review them, and if I like them,

859
00:32:05,368 --> 00:32:06,549
then I can define

860
00:32:07,170 --> 00:32:09,449
these as the base for my spec

861
00:32:09,689 --> 00:32:10,709
for data generation.

862
00:32:11,430 --> 00:32:13,348
Let's look at the two examples that were given,

863
00:32:13,709 --> 00:32:15,709
and you can see that the 3 examples

864
00:32:15,709 --> 00:32:17,180
that are now in the chat,

865
00:32:17,509 --> 00:32:19,509
they actually follow the style that I gave to the

866
00:32:19,509 --> 00:32:21,559
agent. So, it has a prompt, which has,

867
00:32:21,630 --> 00:32:23,029
let's say the system prompt per se,

868
00:32:23,469 --> 00:32:25,588
the user input in terms of the query, in this

869
00:32:25,588 --> 00:32:27,910
case find total sale and total quantity

870
00:32:27,910 --> 00:32:30,410
for each region where total sales exceeds 1 million,

871
00:32:30,868 --> 00:32:33,029
and the response in a well-structured

872
00:32:33,029 --> 00:32:33,880
SQL query.

873
00:32:34,380 --> 00:32:37,250
This looks good, so let's say yes, proceed.

874
00:32:39,979 --> 00:32:42,170
So, as I say yes proceed now, what's it gonna

875
00:32:42,170 --> 00:32:44,209
give me is that it's gonna tell me, OK, now

876
00:32:44,209 --> 00:32:46,578
I understand how I'm supposed to create this data,

877
00:32:46,930 --> 00:32:48,529
so let's please align to the,

878
00:32:49,449 --> 00:32:51,689
uh, let's say, let's define together the

879
00:32:51,689 --> 00:32:53,828
spec for how to generate data,

880
00:32:54,559 --> 00:32:56,769
and we will use that spec to

881
00:32:56,769 --> 00:32:59,088
create a certain number of examples.

882
00:32:59,209 --> 00:33:00,640
So let's go through the spec first.

883
00:33:00,900 --> 00:33:02,799
You see information about the use case,

884
00:33:03,279 --> 00:33:05,348
definition, what's important about the data,

885
00:33:06,009 --> 00:33:08,088
some of the examples, which are the ones that

886
00:33:08,088 --> 00:33:09,309
we wrote before.

887
00:33:10,779 --> 00:33:11,549
And finally,

888
00:33:11,868 --> 00:33:14,209
quality standards. What does it mean to have a good

889
00:33:14,430 --> 00:33:16,529
answer? What does it mean to have a bad

890
00:33:17,098 --> 00:33:17,969
generation in this case?

891
00:33:18,630 --> 00:33:19,348
Once again,

892
00:33:19,949 --> 00:33:22,049
here I'm accepting everything blindly.

893
00:33:22,189 --> 00:33:24,348
I'm not suggesting you do that. I'm suggesting you actually

894
00:33:24,348 --> 00:33:26,500
go through the details here,

895
00:33:26,828 --> 00:33:29,259
change anything that might be less relevant.

896
00:33:29,509 --> 00:33:31,868
We try to make it as aligned as possible

897
00:33:31,868 --> 00:33:32,818
to your use case,

898
00:33:33,108 --> 00:33:35,150
but there's no one else out there that knows your

899
00:33:35,150 --> 00:33:36,390
use case better than you.

900
00:33:38,088 --> 00:33:40,828
So let's save the changes in this case and approve

901
00:33:41,209 --> 00:33:42,670
the, the data spec.

902
00:33:43,170 --> 00:33:45,598
And now what's gonna happen is they're gonna tell me, hey,

903
00:33:46,009 --> 00:33:47,549
configure the synthetic data generation,

904
00:33:48,088 --> 00:33:50,410
you know, for a good SFT use case, it's

905
00:33:50,410 --> 00:33:53,328
suggested to, it's recommended to create 5000

906
00:33:53,328 --> 00:33:54,000
records.

907
00:33:54,449 --> 00:33:56,529
I'm gonna also use this

908
00:33:56,529 --> 00:33:57,108
path.

909
00:33:58,459 --> 00:33:59,500
Data the

910
00:34:00,209 --> 00:34:01,719
demo, let's put it that way,

911
00:34:02,259 --> 00:34:03,130
with a role ARN

912
00:34:05,039 --> 00:34:05,900
which I have already handy here.

913
00:34:06,338 --> 00:34:08,489
And if I have additional data which I can use as context

914
00:34:08,489 --> 00:34:10,280
for the data generation, I can provide it here.

915
00:34:10,648 --> 00:34:11,938
Right now I don't have any,

916
00:34:12,260 --> 00:34:14,369
but I'm gonna start the synthetic data

917
00:34:14,369 --> 00:34:16,458
generation. So what you're gonna see is that this is

918
00:34:16,458 --> 00:34:18,539
gonna take a little while. So if you don't have

919
00:34:18,539 --> 00:34:20,659
anything to do for the next 45 minutes,

920
00:34:20,780 --> 00:34:22,489
we can wait for this to be completed.

921
00:34:22,969 --> 00:34:25,099
Of course that's a joke. We have one already pre-done.

922
00:34:25,409 --> 00:34:27,449
But what's important is that the data

923
00:34:27,449 --> 00:34:29,168
generated will be stored in a tree.

924
00:34:29,449 --> 00:34:31,188
It's gonna be Jline's format.

925
00:34:31,449 --> 00:34:33,438
We can take a look at that in just a second,

926
00:34:33,769 --> 00:34:35,929
and this, you can use it not just

927
00:34:35,929 --> 00:34:37,869
as part of the AI agent experience,

928
00:34:38,168 --> 00:34:40,369
but it can be used also with your own

929
00:34:40,369 --> 00:34:42,739
training. To

930
00:34:42,739 --> 00:34:44,878
make sure you guys are not waiting too long here,

931
00:34:44,978 --> 00:34:47,019
because you have to attend a party tonight, so you

932
00:34:47,019 --> 00:34:49,099
might not want to wait necessarily here until this

933
00:34:49,099 --> 00:34:51,208
is done. I'm gonna show you

934
00:34:51,208 --> 00:34:53,260
a complete end to end process, all right?

935
00:34:53,378 --> 00:34:56,378
So, allow me to, you know, pull a

936
00:34:56,378 --> 00:34:57,438
TV magic trick

937
00:34:57,829 --> 00:34:59,679
and get one already done. So,

938
00:35:00,878 --> 00:35:01,820
Data spec

939
00:35:02,699 --> 00:35:04,809
Generation of the data. Data generation

940
00:35:04,809 --> 00:35:05,688
is completed.

941
00:35:06,090 --> 00:35:08,340
I can take a look at the generated synthetic

942
00:35:08,340 --> 00:35:10,429
data. So, it's gonna give me

943
00:35:10,429 --> 00:35:12,610
a couple of examples here, just the, the 1st

944
00:35:12,610 --> 00:35:13,769
5 is gonna tell me that

945
00:35:14,050 --> 00:35:15,590
generated 5000 records

946
00:35:15,849 --> 00:35:17,929
for the SFT strategy, so it's gonna be prompt

947
00:35:17,929 --> 00:35:18,809
completion pair.

948
00:35:19,208 --> 00:35:21,530
They are correctly, you know, they have the uh

949
00:35:21,530 --> 00:35:23,610
data schema in here as well as the

950
00:35:23,610 --> 00:35:24,550
completions,

951
00:35:25,050 --> 00:35:27,050
and you're gonna see all of these examples. If you want, you can look

952
00:35:27,050 --> 00:35:28,188
it up online, uh sorry,

953
00:35:28,449 --> 00:35:30,449
you can look it up in a tree to have the complete

954
00:35:30,449 --> 00:35:32,510
list. But it also provides you with

955
00:35:32,510 --> 00:35:34,829
data quality results. This is very important

956
00:35:34,829 --> 00:35:36,949
because if you're doing any kind of training process, you

957
00:35:36,949 --> 00:35:39,030
wanna understand how the data actually looks, not

958
00:35:39,030 --> 00:35:39,809
just from a few

959
00:35:40,648 --> 00:35:42,789
random samples, but actually get

960
00:35:42,789 --> 00:35:44,489
statistics on your data set.

961
00:35:45,110 --> 00:35:46,648
Get the N-gram diversity,

962
00:35:47,030 --> 00:35:49,030
uh, get any of the, the, you know, the total

963
00:35:49,030 --> 00:35:50,449
text, mean word length,

964
00:35:51,030 --> 00:35:53,179
anything responsible AI metrics, this is very

965
00:35:53,179 --> 00:35:54,860
important to make sure that we are aligned.

966
00:35:55,188 --> 00:35:57,188
Toxicity score is super low, it's basically

967
00:35:57,188 --> 00:35:58,489
zero, it's almost negligible.

968
00:35:59,329 --> 00:36:01,329
In fact, there are 0 toxic records. This

969
00:36:01,329 --> 00:36:03,510
should probably be like a 0 toxicity score.

970
00:36:04,789 --> 00:36:05,659
Once that's done,

971
00:36:05,949 --> 00:36:07,949
the very next step that the agent will suggest

972
00:36:07,949 --> 00:36:09,550
is to start a training job.

973
00:36:09,829 --> 00:36:11,949
And once again, we're doing it here just because we want

974
00:36:11,949 --> 00:36:14,148
to showcase the AI agent capability, which is

975
00:36:14,148 --> 00:36:15,309
available in private preview.

976
00:36:15,590 --> 00:36:17,708
But again, you can take this data and use it anywhere

977
00:36:17,708 --> 00:36:19,978
else. You could be using the UI that Summit

978
00:36:19,978 --> 00:36:22,070
was just showing before, you could be using it in

979
00:36:22,070 --> 00:36:24,110
your code, really, whatever you want. Any

980
00:36:24,110 --> 00:36:26,269
of these components is modular,

981
00:36:26,309 --> 00:36:27,809
and you can reuse it where you want.

982
00:36:28,760 --> 00:36:30,840
For the training job, you have to configure a couple of

983
00:36:30,840 --> 00:36:33,280
parameters like the batch size, learning rate.

984
00:36:33,590 --> 00:36:35,539
We provide this value by default,

985
00:36:36,000 --> 00:36:38,039
because we have tested a couple of recipes behind the

986
00:36:38,039 --> 00:36:40,119
scenes. But again, these values depend

987
00:36:40,119 --> 00:36:42,280
on the use case, on the complexity of the use case.

988
00:36:42,559 --> 00:36:44,559
So you might still wanna have a little bit of knowledge of

989
00:36:44,559 --> 00:36:45,418
data science.

990
00:36:47,059 --> 00:36:49,148
Of course, I've already launched the training job

991
00:36:49,148 --> 00:36:51,378
behind the scenes, so I can show you the full metrics.

992
00:36:51,668 --> 00:36:53,789
As you can see, this was a job for 87

993
00:36:53,789 --> 00:36:54,458
epochs,

994
00:36:54,789 --> 00:36:55,929
epochs is complete,

995
00:36:56,398 --> 00:36:58,659
lasted 6000 seconds. You do the math,

996
00:36:58,789 --> 00:37:01,070
uh, I don't remember exactly how that what that is.

997
00:37:01,389 --> 00:37:02,489
64 batch size,

998
00:37:02,789 --> 00:37:03,728
7 epochs.

999
00:37:04,239 --> 00:37:05,590
Learning rate very low.

1000
00:37:06,039 --> 00:37:08,159
Let's look at the metrics with the

1001
00:37:08,159 --> 00:37:09,918
new serverless ML flow.

1002
00:37:10,199 --> 00:37:12,378
You're gonna see that with a simple click of a button, without

1003
00:37:12,378 --> 00:37:14,639
even leaving, let's say the agent per se, I

1004
00:37:14,639 --> 00:37:16,918
can be rerouted to the ML flow. I'm

1005
00:37:16,918 --> 00:37:18,309
gonna get the list of experiments.

1006
00:37:18,639 --> 00:37:20,719
Spoiler alert, you're gonna see a lot of examples

1007
00:37:20,719 --> 00:37:22,719
here, because this is a shared account, so we're

1008
00:37:22,719 --> 00:37:24,438
using with a bunch of other folks out there.

1009
00:37:24,878 --> 00:37:27,039
But if I remember right, this is mine,

1010
00:37:27,159 --> 00:37:29,418
so it's the Lama SQL with systems prompt.

1011
00:37:30,679 --> 00:37:32,840
Promptly called Lama SQL because it's

1012
00:37:32,840 --> 00:37:35,199
a LMA model that generates SQL query.

1013
00:37:35,949 --> 00:37:38,398
Yeah, in tech we don't have a lot of imagination

1014
00:37:38,398 --> 00:37:39,360
for namings.

1015
00:37:40,889 --> 00:37:43,409
And so, I can go into the details of my experiment,

1016
00:37:43,570 --> 00:37:45,570
get the model metrics, get the system metrics,

1017
00:37:45,639 --> 00:37:46,668
etc. You can see

1018
00:37:47,168 --> 00:37:49,228
the, there's a pretty decent training,

1019
00:37:49,320 --> 00:37:51,610
uh, loss is continuously

1020
00:37:51,610 --> 00:37:53,769
falling, so, uh, converging

1021
00:37:53,769 --> 00:37:55,099
at some point, so that's good.

1022
00:37:55,449 --> 00:37:57,958
Uh, and you can take a look at all the different details,

1023
00:37:57,969 --> 00:37:59,969
uh, and go into much more,

1024
00:38:00,289 --> 00:38:02,530
uh, understanding of the different outcomes

1025
00:38:02,530 --> 00:38:03,250
from this training.

1026
00:38:04,789 --> 00:38:06,869
Once that is done, then what we can do

1027
00:38:06,869 --> 00:38:08,728
is that we can start the evaluation.

1028
00:38:09,148 --> 00:38:10,250
Now, once again,

1029
00:38:10,510 --> 00:38:12,610
the uh agent is gonna suggest a

1030
00:38:12,610 --> 00:38:14,090
spec for evaluation,

1031
00:38:14,389 --> 00:38:16,510
right? It's gonna give me some metrics that I could

1032
00:38:16,510 --> 00:38:17,820
be using if I wanted to,

1033
00:38:18,228 --> 00:38:20,369
to evaluate the performances of this model.

1034
00:38:20,708 --> 00:38:22,898
It's gonna take a while to run the er

1035
00:38:22,898 --> 00:38:24,989
to run the evaluation. I had to rerun it this

1036
00:38:24,989 --> 00:38:27,090
morning because of some clean up in this account.

1037
00:38:27,550 --> 00:38:29,550
Uh, as you can see, it's uh still a little bit

1038
00:38:29,550 --> 00:38:31,688
running, but you can see the progress. Basically

1039
00:38:31,688 --> 00:38:33,909
what it does, oh, there we go, there was an error, maybe I

1040
00:38:33,909 --> 00:38:34,978
changed something in there,

1041
00:38:35,269 --> 00:38:36,289
uh, but it will run,

1042
00:38:36,628 --> 00:38:38,708
uh, an LLM as a judge evaluation as well

1043
00:38:38,708 --> 00:38:40,949
as a custom scoring of what the,

1044
00:38:41,188 --> 00:38:43,269
uh, of what the model actually is

1045
00:38:43,269 --> 00:38:45,510
performing and will give me at the end of this

1046
00:38:45,510 --> 00:38:46,809
a nice report saying,

1047
00:38:47,239 --> 00:38:49,550
hey, this is how the model performs according to the metrics

1048
00:38:49,550 --> 00:38:50,389
that we have defined.

1049
00:38:50,679 --> 00:38:52,760
The metric, it defines itself, for example, in

1050
00:38:52,760 --> 00:38:54,159
this case, efficiency focus,

1051
00:38:54,438 --> 00:38:56,500
user friendly explanation, cost awareness,

1052
00:38:56,760 --> 00:38:59,079
those are all very generic and they require an LLM

1053
00:38:59,079 --> 00:39:00,079
to be confirmed,

1054
00:39:00,389 --> 00:39:02,519
uh, this, which is why we use LLM as a judge

1055
00:39:02,519 --> 00:39:03,579
behind the scenes. But again,

1056
00:39:03,878 --> 00:39:05,958
this has been approved as is. If you want, you can

1057
00:39:05,958 --> 00:39:06,780
go ahead and change

1058
00:39:07,438 --> 00:39:07,958
anything in it.

1059
00:39:09,918 --> 00:39:12,320
So, let's take a look at the model

1060
00:39:12,320 --> 00:39:14,559
results in general. So I'm gonna go once, once

1061
00:39:14,559 --> 00:39:16,668
again into the models tab here.

1062
00:39:16,878 --> 00:39:19,039
I'm gonna look at my models, gonna go through all

1063
00:39:19,039 --> 00:39:21,320
the different models that my colleagues have trained, and

1064
00:39:21,320 --> 00:39:23,340
I'm gonna look at mine, Lama SQL with

1065
00:39:23,340 --> 00:39:24,000
System prompt.

1066
00:39:24,639 --> 00:39:26,918
So, I have here at the scene, a single of

1067
00:39:26,918 --> 00:39:28,949
glass. I will have all the information

1068
00:39:29,679 --> 00:39:31,679
with respect to my model. So, what

1069
00:39:31,679 --> 00:39:32,719
did I train it on?

1070
00:39:33,039 --> 00:39:35,059
When was it trained? What is the training job that led

1071
00:39:35,059 --> 00:39:37,119
to this model? What was the training data set,

1072
00:39:37,280 --> 00:39:39,438
when this happened, which technique was it? What

1073
00:39:39,438 --> 00:39:41,628
was the base model, training hyperparametters,

1074
00:39:42,079 --> 00:39:44,079
performances of the model training as well, which

1075
00:39:44,079 --> 00:39:45,599
come directly from ML flow.

1076
00:39:46,239 --> 00:39:48,958
And then I can also take a look at the evaluation

1077
00:39:48,958 --> 00:39:51,000
report that I was telling you about before. It's still

1078
00:39:51,000 --> 00:39:53,219
going on, but we can take a look at the details later.

1079
00:39:54,260 --> 00:39:56,260
I can also go ahead and deploy this

1080
00:39:56,260 --> 00:39:58,340
model. This is really important because once

1081
00:39:58,340 --> 00:40:00,458
we have trained the model, as Summit was

1082
00:40:00,458 --> 00:40:01,559
telling us about before,

1083
00:40:02,099 --> 00:40:04,219
it's a model that has been fine tuned is

1084
00:40:04,219 --> 00:40:06,579
only valuable when you can actually put it into production.

1085
00:40:07,340 --> 00:40:09,458
So the very first, the very next step after

1086
00:40:09,458 --> 00:40:11,489
evaluating a model should be to

1087
00:40:11,489 --> 00:40:12,079
deploy.

1088
00:40:12,500 --> 00:40:14,659
And in SageMaker it's as easy as clicking

1089
00:40:14,659 --> 00:40:15,599
two buttons here.

1090
00:40:16,050 --> 00:40:18,179
Click the deploy button all the way up top

1091
00:40:18,179 --> 00:40:20,500
right, and then choose your technique.

1092
00:40:21,019 --> 00:40:23,219
Whether you want to deploy it in an end on an endpoint

1093
00:40:23,219 --> 00:40:25,179
on Sage Maker, runs 24/7,

1094
00:40:25,458 --> 00:40:26,199
always available,

1095
00:40:26,500 --> 00:40:28,699
uh, can scale horizontally as much as needed,

1096
00:40:29,099 --> 00:40:31,119
or deployed on Bedrock.

1097
00:40:31,378 --> 00:40:33,659
Rather than deploying, we should be saying import

1098
00:40:33,659 --> 00:40:35,199
in Bedrock, with the custom model.

1099
00:40:35,809 --> 00:40:38,148
Which will make it available in a server-less fashion,

1100
00:40:38,539 --> 00:40:40,659
and you will pay only for the kind of request that you

1101
00:40:40,659 --> 00:40:42,938
do. We tend to prefer

1102
00:40:42,938 --> 00:40:45,309
Sage maker when you have a certain threshold

1103
00:40:45,309 --> 00:40:47,208
of throughput that you want to meet,

1104
00:40:47,668 --> 00:40:49,668
because then you define the architecture, you define how

1105
00:40:49,668 --> 00:40:51,750
big the endpoint is gonna be, and you define how

1106
00:40:51,750 --> 00:40:53,179
many requests you can receive.

1107
00:40:53,510 --> 00:40:55,590
If your workload is spiky or you're still

1108
00:40:55,590 --> 00:40:56,148
more in a

1109
00:40:56,429 --> 00:40:57,550
development sort of fashion,

1110
00:40:57,869 --> 00:40:59,889
Bedrock is a great choice with custom model import

1111
00:40:59,889 --> 00:41:01,309
because it allows you to test,

1112
00:41:01,829 --> 00:41:03,789
understand, and further improve your model.

1113
00:41:05,409 --> 00:41:07,409
So, I can decide to create a new endpoint or

1114
00:41:07,409 --> 00:41:08,769
I use an existing endpoint.

1115
00:41:09,050 --> 00:41:11,369
I'm not gonna do that right now because I already have

1116
00:41:11,369 --> 00:41:12,989
many endpoints deployed here.

1117
00:41:13,329 --> 00:41:15,449
So you will see, uh, again, we are using a

1118
00:41:15,449 --> 00:41:16,510
shared account, so,

1119
00:41:16,809 --> 00:41:18,309
uh, no surprise there.

1120
00:41:18,969 --> 00:41:21,090
But what I'm gonna show you right now is

1121
00:41:21,090 --> 00:41:22,110
what can you do

1122
00:41:22,530 --> 00:41:23,469
once you have

1123
00:41:23,809 --> 00:41:24,869
deployed that model.

1124
00:41:26,679 --> 00:41:29,159
So, my model is available. Let me actually

1125
00:41:29,159 --> 00:41:31,360
clean up this code so we can walk

1126
00:41:31,360 --> 00:41:32,679
you through step by step.

1127
00:41:33,570 --> 00:41:35,639
So as we as we have deployed

1128
00:41:35,639 --> 00:41:37,688
our model, then the next step is to

1129
00:41:37,688 --> 00:41:38,929
use it for inferences.

1130
00:41:39,739 --> 00:41:42,309
The very first thing I'm gonna do is that I'm gonna create

1131
00:41:42,309 --> 00:41:44,429
some utility function. We can go

1132
00:41:44,429 --> 00:41:45,849
back into this in a second.

1133
00:41:47,059 --> 00:41:49,239
And uh what I wanna do now

1134
00:41:49,239 --> 00:41:51,500
is that my very first operation will be

1135
00:41:51,820 --> 00:41:54,148
to generate an inference just to test

1136
00:41:54,148 --> 00:41:56,260
if the model is actually working or not

1137
00:41:56,260 --> 00:41:57,378
on the endpoint, OK?

1138
00:41:57,750 --> 00:41:58,300
Of course,

1139
00:41:58,599 --> 00:42:01,010
we have trained it according to the best practices,

1140
00:42:01,300 --> 00:42:02,559
so it should be working just fine.

1141
00:42:02,938 --> 00:42:05,340
And in fact, I'm gonna use a SageMaker predictor SDK

1142
00:42:05,340 --> 00:42:07,418
here to generate an inference. You

1143
00:42:07,418 --> 00:42:08,398
see it was super fast.

1144
00:42:09,110 --> 00:42:11,039
And you can see that this model,

1145
00:42:11,389 --> 00:42:13,668
because I'm passing, uh, you know, I'm

1146
00:42:13,668 --> 00:42:15,860
passing it the information that it's, uh,

1147
00:42:15,869 --> 00:42:17,409
I'm passing it the system prompt saying

1148
00:42:17,750 --> 00:42:19,369
you are an advanced AI assistant,

1149
00:42:19,760 --> 00:42:21,688
your, your goal is to execute

1150
00:42:22,269 --> 00:42:23,530
a tool to generate,

1151
00:42:23,909 --> 00:42:26,010
to generate SQL queries and to execute them using

1152
00:42:26,010 --> 00:42:26,610
the tool.

1153
00:42:27,309 --> 00:42:29,550
And the query is, can you give me the top 3 markets

1154
00:42:29,550 --> 00:42:31,260
with the highest number of returns?

1155
00:42:32,449 --> 00:42:34,530
So, the model correctly replies by

1156
00:42:34,530 --> 00:42:36,648
saying, hey, you need to call a tool.

1157
00:42:37,050 --> 00:42:39,168
The tool is called execute SQL query. I've

1158
00:42:39,168 --> 00:42:40,809
created it at the beginning of this notebook,

1159
00:42:41,168 --> 00:42:43,280
and the SQL query you need to execute is

1160
00:42:43,280 --> 00:42:45,688
the select market count, blah blah blah, limit

1161
00:42:45,688 --> 00:42:46,599
3, OK?

1162
00:42:47,398 --> 00:42:49,708
Not exactly the most difficult SQL query

1163
00:42:49,708 --> 00:42:51,878
out there, but just for the sake of the demo it's gonna do

1164
00:42:51,878 --> 00:42:54,250
fine. Then

1165
00:42:54,250 --> 00:42:56,449
I can go ahead and test this query

1166
00:42:56,449 --> 00:42:58,148
to make sure that it works all right.

1167
00:42:58,570 --> 00:43:00,849
And as you can see, the output here is says

1168
00:43:00,849 --> 00:43:02,849
LatAM in my demo data set,

1169
00:43:03,000 --> 00:43:06,570
the market with the most return is LaTA with 296,

1170
00:43:06,610 --> 00:43:08,550
followed by APAC and the United States.

1171
00:43:09,349 --> 00:43:11,398
OK, you might say, David, this is nothing new, this is not an

1172
00:43:11,398 --> 00:43:13,398
agent because I had to call it manually.

1173
00:43:13,760 --> 00:43:15,869
So, how about we build an agent

1174
00:43:15,869 --> 00:43:16,418
with this?

1175
00:43:16,760 --> 00:43:18,760
So, we're gonna use reagent for our use

1176
00:43:18,760 --> 00:43:20,918
case, and the good thing about Streagent is that

1177
00:43:20,918 --> 00:43:23,398
it executes the tool behind the scenes,

1178
00:43:23,679 --> 00:43:25,438
and all they have to do is just

1179
00:43:25,840 --> 00:43:28,360
provide it with a system prompt, provide it with the tools,

1180
00:43:28,878 --> 00:43:30,958
pass it to query, and after a

1181
00:43:30,958 --> 00:43:32,320
couple of the query execution,

1182
00:43:32,639 --> 00:43:34,719
it provides me exactly the same result. As you

1183
00:43:34,719 --> 00:43:37,110
see. I didn't go through any steps of

1184
00:43:37,110 --> 00:43:39,228
defining what the tool code was. It did

1185
00:43:39,228 --> 00:43:41,168
everything automatically behind the scenes.

1186
00:43:43,500 --> 00:43:45,579
Final thing that I'm gonna show you, and then I'm

1187
00:43:45,579 --> 00:43:47,820
gonna let uh Nikhil come on stage

1188
00:43:47,820 --> 00:43:48,679
to talk about

1189
00:43:48,978 --> 00:43:51,019
uh good things that Robinhood is doing with

1190
00:43:51,019 --> 00:43:51,780
StageMaker AI.

1191
00:43:52,039 --> 00:43:54,269
The very last step is that, OK, now your

1192
00:43:54,269 --> 00:43:55,719
agent is running on the notebook,

1193
00:43:56,039 --> 00:43:58,099
that's not really useful. How about we put it

1194
00:43:58,099 --> 00:43:59,059
into production.

1195
00:43:59,579 --> 00:44:01,159
So, I wrote this little script

1196
00:44:01,760 --> 00:44:04,179
that basically what it does is that it defines

1197
00:44:04,179 --> 00:44:06,260
the same agent that I just defined, as you see

1198
00:44:06,260 --> 00:44:08,760
is the same strand agent configuration,

1199
00:44:09,139 --> 00:44:10,280
but additionally,

1200
00:44:11,099 --> 00:44:12,128
I have this

1201
00:44:12,750 --> 00:44:14,938
Bedrock Agent Core app definition.

1202
00:44:15,269 --> 00:44:17,389
This is all you need to add in order

1203
00:44:17,389 --> 00:44:19,550
to provide information on how to

1204
00:44:19,550 --> 00:44:21,769
run this agent in production

1205
00:44:21,769 --> 00:44:22,628
on Agent Core.

1206
00:44:23,539 --> 00:44:25,619
And in fact, you can see that as

1207
00:44:25,619 --> 00:44:27,780
I invoke my agent on agent

1208
00:44:27,780 --> 00:44:29,208
core with the prompt,

1209
00:44:29,539 --> 00:44:31,780
with the same kind of question, I will get my

1210
00:44:31,780 --> 00:44:33,239
output out saying, OK,

1211
00:44:33,619 --> 00:44:35,668
show me the number of orders that were returned for each market,

1212
00:44:35,739 --> 00:44:37,059
and if everything goes right,

1213
00:44:37,378 --> 00:44:39,429
then I have exactly the same response.

1214
00:44:39,898 --> 00:44:41,938
So, of course, we can re-look it up, you know, you

1215
00:44:41,938 --> 00:44:44,139
can try different queries, try different prompts.

1216
00:44:44,458 --> 00:44:46,699
The goal for me was to make you understand

1217
00:44:46,699 --> 00:44:49,139
how do you go end to end from chatting

1218
00:44:49,139 --> 00:44:51,059
with an agent to build a machine learning model,

1219
00:44:51,688 --> 00:44:53,398
so Gen AI model, a small language model.

1220
00:44:53,668 --> 00:44:55,599
And go all the way down to production.

1221
00:44:55,869 --> 00:44:57,679
This is ready to go to prod.

1222
00:44:58,039 --> 00:45:00,159
Please don't use this code in your production environment

1223
00:45:00,159 --> 00:45:02,320
cause this is still cory road, so, you know, you

1224
00:45:02,320 --> 00:45:03,280
might, you might wanna be

1225
00:45:03,559 --> 00:45:04,478
careful about that.

1226
00:45:05,878 --> 00:45:08,119
Alright, let's look at someone that actually

1227
00:45:08,119 --> 00:45:10,280
did good production level code with a

1228
00:45:10,280 --> 00:45:12,329
great team. Uh, so I'm gonna invite

1229
00:45:12,329 --> 00:45:14,489
Nico on stage to talk about, uh,

1230
00:45:14,500 --> 00:45:16,280
accelerating AI innovation at Robinhood.

1231
00:45:17,070 --> 00:45:19,099
Thank you, thank you, every day. Uh,

1232
00:45:19,188 --> 00:45:20,789
that was such a wonderful talk.

1233
00:45:21,280 --> 00:45:23,639
And, uh, my name is Nico Singhal.

1234
00:45:23,739 --> 00:45:25,949
I'm a senior staff ML engineer at Robinhood.

1235
00:45:26,030 --> 00:45:28,228
I lead our agentic platform initiatives,

1236
00:45:29,019 --> 00:45:31,378
everything from LLM evaluations to fine-tuning

1237
00:45:31,378 --> 00:45:33,728
infrastructures to inference systems

1238
00:45:33,989 --> 00:45:35,030
at production scale.

1239
00:45:36,128 --> 00:45:38,320
As I'm in an infrastructure team, uh,

1240
00:45:38,389 --> 00:45:39,369
the platform team,

1241
00:45:39,769 --> 00:45:41,849
we build capabilities to accelerate

1242
00:45:41,849 --> 00:45:42,360
gente

1243
00:45:43,559 --> 00:45:45,010
application development at Robinhood.

1244
00:45:45,449 --> 00:45:48,429
And we have built platform capabilities

1245
00:45:48,688 --> 00:45:49,429
that are

1246
00:45:49,889 --> 00:45:50,869
built over

1247
00:45:51,769 --> 00:45:53,688
Sagemaker AI and

1248
00:45:53,949 --> 00:45:55,409
AWS Bedrock.

1249
00:45:56,030 --> 00:45:58,309
We use SageMaker AI for training and

1250
00:45:58,309 --> 00:46:00,070
Bedrock for inferencing.

1251
00:46:02,659 --> 00:46:04,860
So, today, I'm going to talk

1252
00:46:04,860 --> 00:46:05,378
about

1253
00:46:05,739 --> 00:46:07,860
how we are accelorating AI development

1254
00:46:07,860 --> 00:46:10,019
uh through fine-tuning, but before that, let

1255
00:46:10,019 --> 00:46:11,139
me contextualize it.

1256
00:46:16,329 --> 00:46:18,530
I'll start with, like, Robin had started

1257
00:46:18,530 --> 00:46:19,750
with, uh,

1258
00:46:20,059 --> 00:46:22,199
a bold question from our co-founders, Bala

1259
00:46:22,199 --> 00:46:23,090
and Baiju.

1260
00:46:23,929 --> 00:46:25,969
What if finance were for

1261
00:46:25,969 --> 00:46:27,728
everybody, not just for ultra-wealthy?

1262
00:46:29,648 --> 00:46:32,168
This simple but powerful

1263
00:46:32,168 --> 00:46:34,188
idea sparked a movement, and

1264
00:46:34,570 --> 00:46:36,590
Robinhood broke all the barriers

1265
00:46:36,809 --> 00:46:38,389
with commission-free trading.

1266
00:46:38,728 --> 00:46:40,929
And we did not stop there. We extended

1267
00:46:40,929 --> 00:46:42,519
into crypto,

1268
00:46:42,849 --> 00:46:45,329
cash management, credit cards, and

1269
00:46:45,329 --> 00:46:46,728
recently stock tokens.

1270
00:46:47,949 --> 00:46:50,208
And enable access to

1271
00:46:50,458 --> 00:46:52,668
enable like for our users, we enable

1272
00:46:52,668 --> 00:46:54,168
access to, to the, to the market

1273
00:46:54,708 --> 00:46:56,728
in a way, once unthinkable.

1274
00:46:57,809 --> 00:47:00,119
Throughout our journey we stay true to our mission,

1275
00:47:00,139 --> 00:47:01,978
which is democratizing finance for all.

1276
00:47:02,300 --> 00:47:03,800
We build capabilities

1277
00:47:04,378 --> 00:47:05,898
which are simple,

1278
00:47:06,208 --> 00:47:07,199
ergonomic,

1279
00:47:07,619 --> 00:47:09,559
and empowering for users

1280
00:47:10,059 --> 00:47:11,800
so they can take full control

1281
00:47:12,110 --> 00:47:13,699
of their financial future.

1282
00:47:17,139 --> 00:47:18,458
Moving to our AI vision.

1283
00:47:19,769 --> 00:47:21,139
For us to truly

1284
00:47:21,648 --> 00:47:22,949
realize our mission,

1285
00:47:23,329 --> 00:47:25,090
we believe that we need to give

1286
00:47:25,449 --> 00:47:26,469
our users

1287
00:47:26,889 --> 00:47:28,889
the same level of support and

1288
00:47:28,889 --> 00:47:29,570
insight.

1289
00:47:30,340 --> 00:47:32,659
As a high net worth individual.

1290
00:47:33,019 --> 00:47:35,360
And for that we need to really harness

1291
00:47:35,360 --> 00:47:37,458
the transformative power of

1292
00:47:37,458 --> 00:47:39,010
AI and machine learning.

1293
00:47:39,340 --> 00:47:40,438
Therefore, AI

1294
00:47:40,780 --> 00:47:43,030
isn't just a feature for us,

1295
00:47:43,378 --> 00:47:45,458
it is one of the cornerstones for us

1296
00:47:45,458 --> 00:47:46,438
to fulfill our mission.

1297
00:47:47,800 --> 00:47:50,188
Let me walk you through some of the

1298
00:47:50,188 --> 00:47:51,559
applications which we have built,

1299
00:47:51,918 --> 00:47:54,010
uh, and which are one of the

1300
00:47:54,010 --> 00:47:55,079
complex applications.

1301
00:47:56,668 --> 00:47:59,199
Powering mission critical agentic apps, this is Cortex.

1302
00:47:59,458 --> 00:48:00,610
Uh, if you open

1303
00:48:02,179 --> 00:48:04,458
Uh, any stock trading app, you

1304
00:48:04,458 --> 00:48:06,639
will see like sometimes like, hey, stock is moving

1305
00:48:06,639 --> 00:48:07,599
up or down.

1306
00:48:08,300 --> 00:48:10,360
Before, you need to be really detective

1307
00:48:10,699 --> 00:48:12,780
that, hey, why it moved up, why it

1308
00:48:12,780 --> 00:48:13,550
moved down.

1309
00:48:14,958 --> 00:48:17,199
This is where we thought that AI can really

1310
00:48:17,199 --> 00:48:19,469
be that detective for you and for our users.

1311
00:48:20,179 --> 00:48:22,260
And it can crunch way

1312
00:48:22,260 --> 00:48:24,378
too much information and can

1313
00:48:24,378 --> 00:48:26,719
provide a unique, a cohesive

1314
00:48:26,719 --> 00:48:29,260
and useful information in a digestive

1315
00:48:29,260 --> 00:48:31,418
manner to our users. And this we

1316
00:48:31,418 --> 00:48:33,579
believe is very empowering and what we

1317
00:48:33,579 --> 00:48:34,378
believe is that

1318
00:48:35,110 --> 00:48:37,119
Enabling users to get the same level of

1319
00:48:37,119 --> 00:48:37,780
insight

1320
00:48:38,039 --> 00:48:38,579
what

1321
00:48:39,079 --> 00:48:41,199
somebody with a, with an extended team

1322
00:48:41,199 --> 00:48:42,760
would, would, would have received.

1323
00:48:45,898 --> 00:48:46,800
Customer support

1324
00:48:47,059 --> 00:48:49,139
is the other, other frontier where

1325
00:48:49,139 --> 00:48:51,389
we have built an LLM agent to

1326
00:48:51,389 --> 00:48:53,119
automate our customer support.

1327
00:48:54,398 --> 00:48:55,219
For users,

1328
00:48:56,289 --> 00:48:58,800
when they are dealing with trading, there are a lot of nuances,

1329
00:48:58,878 --> 00:48:59,739
there are a lot of other

1330
00:49:00,869 --> 00:49:01,619
support they need.

1331
00:49:01,918 --> 00:49:03,688
And that is where we thought that

1332
00:49:04,458 --> 00:49:07,000
Building an LLM agent for customer

1333
00:49:07,000 --> 00:49:09,280
support will be empowering for our users

1334
00:49:09,639 --> 00:49:12,079
because that is how we can scale and

1335
00:49:12,079 --> 00:49:13,418
provide users or

1336
00:49:14,039 --> 00:49:15,619
to answers to their questions.

1337
00:49:16,510 --> 00:49:18,628
Whether they are complex or whether they

1338
00:49:18,628 --> 00:49:20,628
are about exploration, a

1339
00:49:20,628 --> 00:49:21,269
product idea.

1340
00:49:23,639 --> 00:49:26,079
Our customer support agent is split

1341
00:49:26,079 --> 00:49:26,889
into 3

1342
00:49:27,878 --> 00:49:28,389
stages.

1343
00:49:28,679 --> 00:49:29,978
The first is the

1344
00:49:30,619 --> 00:49:32,648
Intent understanding where we for the

1345
00:49:32,648 --> 00:49:34,639
observability reasons and for the

1346
00:49:34,938 --> 00:49:37,500
downstream stages, we first

1347
00:49:37,500 --> 00:49:39,659
understand the intent of a user question. Hey, whether

1348
00:49:39,659 --> 00:49:41,739
it's a broker's question, whether it's a crypto question,

1349
00:49:41,780 --> 00:49:42,519
or whether it's

1350
00:49:42,780 --> 00:49:43,398
uh

1351
00:49:44,139 --> 00:49:46,429
like requires complex reasoning.

1352
00:49:46,780 --> 00:49:48,978
Then we move to planner

1353
00:49:48,978 --> 00:49:51,418
and the tool selection that, hey, to solve this

1354
00:49:51,418 --> 00:49:53,708
question, what kind of planning do I need?

1355
00:49:53,978 --> 00:49:56,389
What kind of tools or databases queries

1356
00:49:56,389 --> 00:49:57,599
I need to execute.

1357
00:49:57,978 --> 00:49:59,378
And at the end.

1358
00:49:59,760 --> 00:50:01,050
It, when it

1359
00:50:01,750 --> 00:50:03,909
makes, uh, when it figures out that this is the,

1360
00:50:04,030 --> 00:50:06,800
the, the plan it needs, it tests the tool invocations.

1361
00:50:07,119 --> 00:50:09,148
Once it does the tool invocation, it retrieves

1362
00:50:09,148 --> 00:50:11,429
all the context. Once the context is built, then

1363
00:50:11,429 --> 00:50:13,188
the final answer generation happens.

1364
00:50:14,329 --> 00:50:16,539
Many of the models here

1365
00:50:16,800 --> 00:50:19,050
do get served out of Amazon Bedrock.

1366
00:50:22,619 --> 00:50:24,519
Moving, moving forward, uh,

1367
00:50:25,340 --> 00:50:27,378
while we build these apps, we realize

1368
00:50:27,378 --> 00:50:29,280
that we need to scale them as well.

1369
00:50:29,619 --> 00:50:30,800
And that is where

1370
00:50:31,260 --> 00:50:33,719
I talk about generative AI trilemma.

1371
00:50:34,219 --> 00:50:36,378
In the, in the world of generative AI these

1372
00:50:36,378 --> 00:50:38,000
three variables cost

1373
00:50:39,289 --> 00:50:41,769
Quality, latency are often

1374
00:50:41,769 --> 00:50:42,929
fighting against each other.

1375
00:50:43,728 --> 00:50:44,760
You may think that the

1376
00:50:45,579 --> 00:50:48,188
Like sometimes you can throw a high-end hardware

1377
00:50:48,449 --> 00:50:50,570
to reduce your latency, but that

1378
00:50:50,570 --> 00:50:52,610
burns your cost budget. So the idea is

1379
00:50:52,610 --> 00:50:54,800
very simple. Like if you go with the quality,

1380
00:50:54,849 --> 00:50:57,280
you will need a high-end frontier model,

1381
00:50:57,648 --> 00:50:59,840
but that puts a lot of pressure on your

1382
00:50:59,840 --> 00:51:00,909
cost and latency.

1383
00:51:01,260 --> 00:51:03,289
But at the same time, if we are working with

1384
00:51:03,289 --> 00:51:05,489
a small size model, often you will

1385
00:51:05,489 --> 00:51:07,929
see that, and we saw in the previous session

1386
00:51:07,929 --> 00:51:10,228
as well, that there is a

1387
00:51:10,449 --> 00:51:12,708
quality hill climbing exercise

1388
00:51:12,708 --> 00:51:13,969
needs to be performed.

1389
00:51:15,070 --> 00:51:16,050
But for us,

1390
00:51:16,668 --> 00:51:18,750
this is even more challenging because we

1391
00:51:18,750 --> 00:51:20,010
are not building

1392
00:51:20,469 --> 00:51:22,070
single interaction

1393
00:51:22,938 --> 00:51:25,449
application. We are building LLMs, uh, agent.

1394
00:51:25,869 --> 00:51:28,070
These agents make any number of

1395
00:51:28,070 --> 00:51:30,090
LLM calls. So if

1396
00:51:30,708 --> 00:51:31,949
one of these stages.

1397
00:51:32,739 --> 00:51:35,079
I Either slow

1398
00:51:35,219 --> 00:51:37,938
or is inferior in quality,

1399
00:51:38,539 --> 00:51:40,219
the results are amplified.

1400
00:51:41,030 --> 00:51:43,079
That is why we had to be

1401
00:51:43,079 --> 00:51:45,289
methodological in terms of approaching,

1402
00:51:45,398 --> 00:51:47,969
uh, approaching and solving this problem.

1403
00:51:48,309 --> 00:51:49,610
Our approach here is,

1404
00:51:50,030 --> 00:51:52,389
we split into three categories. First,

1405
00:51:52,708 --> 00:51:54,750
we are very selective what

1406
00:51:54,750 --> 00:51:55,809
models to select.

1407
00:51:57,378 --> 00:51:59,500
For example, intent

1408
00:51:59,500 --> 00:52:01,780
understanding, that is one of the easiest,

1409
00:52:01,938 --> 00:52:03,398
relatively simpler

1410
00:52:03,780 --> 00:52:04,389
stages.

1411
00:52:04,869 --> 00:52:06,898
Why do we, we question, why do, do

1412
00:52:06,898 --> 00:52:09,019
we really need a high-end model for

1413
00:52:09,019 --> 00:52:11,139
that? Can we, can we work with a smaller

1414
00:52:11,139 --> 00:52:13,340
model? And that is where our approach is

1415
00:52:13,340 --> 00:52:14,659
always evolved first.

1416
00:52:16,289 --> 00:52:17,219
Whatever we do,

1417
00:52:17,539 --> 00:52:19,659
first evaluate and make sure and build

1418
00:52:19,659 --> 00:52:21,019
it, uh uh

1419
00:52:21,559 --> 00:52:23,780
uh uh like be cognitive about

1420
00:52:23,780 --> 00:52:24,519
that what

1421
00:52:25,458 --> 00:52:27,659
like model is the right fit here or

1422
00:52:27,659 --> 00:52:29,280
not. Then,

1423
00:52:29,559 --> 00:52:31,760
if we don't get the quality, like for an example in

1424
00:52:31,760 --> 00:52:33,918
the planner case and the tool selection case, which

1425
00:52:33,918 --> 00:52:34,938
where we kind of

1426
00:52:35,559 --> 00:52:37,599
understand that for a user question, these are the tools we need

1427
00:52:37,599 --> 00:52:38,409
to invoke.

1428
00:52:38,719 --> 00:52:40,340
If we don't get the quality

1429
00:52:40,639 --> 00:52:42,639
just by tweaking the prompt or optimizing

1430
00:52:42,639 --> 00:52:43,429
the prompt,

1431
00:52:44,188 --> 00:52:46,260
we inject a few short examples

1432
00:52:46,438 --> 00:52:47,300
which carry

1433
00:52:47,719 --> 00:52:49,800
high fidelity, fidelity with the

1434
00:52:49,800 --> 00:52:50,719
user cushion.

1435
00:52:51,119 --> 00:52:52,918
We call it trajectory optimization.

1436
00:52:53,539 --> 00:52:55,539
Once we have squeezed all the juice

1437
00:52:55,539 --> 00:52:57,579
out of the prompt tuning and trajectory tuning, and

1438
00:52:57,579 --> 00:52:58,800
we want to further

1439
00:52:59,659 --> 00:53:00,260
ah

1440
00:53:00,639 --> 00:53:02,039
dive into gaining more

1441
00:53:02,860 --> 00:53:05,199
Optimizing our cost or latency,

1442
00:53:05,668 --> 00:53:08,398
that at that point we go in fine tuning.

1443
00:53:09,168 --> 00:53:10,599
The idea is simple there.

1444
00:53:10,898 --> 00:53:13,099
Don't treat every problem as a nail, otherwise

1445
00:53:13,099 --> 00:53:15,418
we'll end up overutilizing the fine-tuning

1446
00:53:15,418 --> 00:53:16,000
hammer.

1447
00:53:17,898 --> 00:53:19,949
As the generative AI space is evolving, there

1448
00:53:19,949 --> 00:53:22,429
are a lot of problems still land in the fine-tuning

1449
00:53:22,429 --> 00:53:24,949
space where we end up doing cost and latency

1450
00:53:24,949 --> 00:53:25,530
optimization.

1451
00:53:27,260 --> 00:53:28,000
With that,

1452
00:53:28,530 --> 00:53:30,699
we have built, uh, I'll share the

1453
00:53:30,699 --> 00:53:33,219
fine-tuning platform which we have built at Robinhood

1454
00:53:33,539 --> 00:53:35,398
and where we, uh,

1455
00:53:35,938 --> 00:53:37,199
and how we are utilizing

1456
00:53:37,699 --> 00:53:39,139
AWS Sage Maker AI

1457
00:53:39,619 --> 00:53:41,418
and AWS Bedrock.

1458
00:53:42,590 --> 00:53:44,208
Every fine-tuning exercise

1459
00:53:44,708 --> 00:53:45,878
starts with a goal.

1460
00:53:46,148 --> 00:53:48,208
The goal definition has to be

1461
00:53:49,030 --> 00:53:51,949
clear. Often

1462
00:53:51,949 --> 00:53:53,449
you will see there may be

1463
00:53:54,139 --> 00:53:56,309
two goals, like, as I said, latency and

1464
00:53:56,309 --> 00:53:57,449
cost, but

1465
00:53:57,719 --> 00:53:59,789
we recommend, like what internally

1466
00:53:59,789 --> 00:54:00,458
we recommend,

1467
00:54:00,750 --> 00:54:01,889
have a primary goal.

1468
00:54:03,500 --> 00:54:05,360
Then once your goal is defined,

1469
00:54:06,639 --> 00:54:08,719
Do a base model selection. This is very

1470
00:54:08,719 --> 00:54:10,878
essential. And this can only happen once

1471
00:54:10,878 --> 00:54:12,300
we have an eval data set.

1472
00:54:12,760 --> 00:54:14,438
And the data set creation

1473
00:54:15,000 --> 00:54:16,860
is a challenging exercise.

1474
00:54:18,188 --> 00:54:20,239
If we, we, we say that

1475
00:54:20,239 --> 00:54:22,179
walk before you run is basically

1476
00:54:23,000 --> 00:54:25,269
spend some amount of time in

1477
00:54:25,269 --> 00:54:26,599
your data set preparation.

1478
00:54:27,079 --> 00:54:29,119
Your evals needs to be a

1479
00:54:29,119 --> 00:54:31,320
true reflection of your production use cases.

1480
00:54:31,398 --> 00:54:33,719
So it has to be well stratified. It

1481
00:54:33,719 --> 00:54:34,760
needs to have

1482
00:54:35,559 --> 00:54:37,719
good sample of complex use cases,

1483
00:54:38,119 --> 00:54:40,579
uh, and the, and the simple use cases.

1484
00:54:41,489 --> 00:54:42,898
Once we have selected a model,

1485
00:54:44,148 --> 00:54:45,659
Move to a dataset creation.

1486
00:54:46,409 --> 00:54:48,550
And the data set creation is an

1487
00:54:48,550 --> 00:54:50,699
extended exercise of how you would have created

1488
00:54:50,699 --> 00:54:51,739
an eval data set.

1489
00:54:52,260 --> 00:54:53,958
Same stratification exercise

1490
00:54:54,378 --> 00:54:56,458
that understood that, like, like for example

1491
00:54:56,458 --> 00:54:58,398
in the CXU scale which I talked about,

1492
00:54:59,059 --> 00:55:01,239
one of the dimensions which we utilize

1493
00:55:01,239 --> 00:55:01,849
is

1494
00:55:03,199 --> 00:55:03,829
Intent

1495
00:55:05,119 --> 00:55:07,188
Making sure that the questions which we

1496
00:55:07,188 --> 00:55:09,320
have are well diversified

1497
00:55:09,320 --> 00:55:10,628
across all intents.

1498
00:55:11,079 --> 00:55:11,780
The other

1499
00:55:12,320 --> 00:55:14,800
uh potential dimension here is

1500
00:55:14,800 --> 00:55:16,918
number of turns, whether the user

1501
00:55:17,159 --> 00:55:19,239
is a sing like a single turn question or a

1502
00:55:19,239 --> 00:55:21,320
multi-tone conversation with, with the, with the,

1503
00:55:21,398 --> 00:55:22,599
with an AI assistant.

1504
00:55:24,179 --> 00:55:25,610
Once we have the data,

1505
00:55:26,269 --> 00:55:28,628
move to the training, and this is where we have

1506
00:55:28,628 --> 00:55:29,269
a fork.

1507
00:55:30,260 --> 00:55:32,418
Today, we saw that there are a lot of

1508
00:55:32,418 --> 00:55:34,639
standard recipes which are available uh

1509
00:55:34,639 --> 00:55:35,719
on SageMaker.

1510
00:55:37,418 --> 00:55:39,500
We leverage those recipes,

1511
00:55:39,739 --> 00:55:42,019
and that is where we utilize Pacemaker

1512
00:55:42,019 --> 00:55:42,679
Jumpstart.

1513
00:55:43,570 --> 00:55:45,719
But if there are use cases which

1514
00:55:45,719 --> 00:55:46,780
require some customization,

1515
00:55:47,159 --> 00:55:49,349
for an example, your context length is, is

1516
00:55:49,349 --> 00:55:51,478
really long and your data set requires

1517
00:55:51,478 --> 00:55:52,478
a spatial handling.

1518
00:55:53,668 --> 00:55:55,128
At that point, we use

1519
00:55:55,829 --> 00:55:57,570
AI StageMaker AI Studio.

1520
00:55:58,320 --> 00:56:00,360
And you have the Jupiter notebook there,

1521
00:56:00,639 --> 00:56:02,800
you can attach to a P4DE instance

1522
00:56:02,800 --> 00:56:04,619
or a or a or a P5 instance,

1523
00:56:05,000 --> 00:56:07,438
and you can uh basically

1524
00:56:07,438 --> 00:56:09,059
get a machine for yourself.

1525
00:56:10,389 --> 00:56:11,030
Either way,

1526
00:56:11,309 --> 00:56:12,820
once you fine-tune your model,

1527
00:56:13,110 --> 00:56:14,269
you can serve it

1528
00:56:14,530 --> 00:56:15,329
through Bedrock,

1529
00:56:15,590 --> 00:56:17,708
and this is where we unify our serving

1530
00:56:17,708 --> 00:56:19,728
flow. We use custom model

1531
00:56:19,728 --> 00:56:21,860
import to import those models to

1532
00:56:21,860 --> 00:56:24,070
Bedrock, and once the models are imported

1533
00:56:24,070 --> 00:56:24,809
to Bedrock,

1534
00:56:25,349 --> 00:56:27,820
we integrate through our LLM gateway.

1535
00:56:28,070 --> 00:56:29,208
This is how

1536
00:56:29,510 --> 00:56:31,829
all of the applications at Robinhood

1537
00:56:32,070 --> 00:56:33,090
integrate with,

1538
00:56:33,510 --> 00:56:34,590
through LLM gateway.

1539
00:56:34,989 --> 00:56:37,579
So once the model is accessible through LLM LLM

1540
00:56:37,579 --> 00:56:39,628
gateway, it is available for our internal

1541
00:56:39,628 --> 00:56:41,929
playground, internal evaluations,

1542
00:56:42,628 --> 00:56:43,938
and, uh,

1543
00:56:44,228 --> 00:56:46,168
and, and for the production use cases.

1544
00:56:46,628 --> 00:56:48,679
So this is how we, uh,

1545
00:56:48,708 --> 00:56:50,750
operationalize the fine tuning and enab

1546
00:56:50,750 --> 00:56:52,809
and, and offer it as a platform capability

1547
00:56:52,809 --> 00:56:53,728
to our users.

1548
00:56:54,780 --> 00:56:56,469
Let me talk about the impact.

1549
00:56:57,250 --> 00:56:59,409
We, we have received more

1550
00:56:59,409 --> 00:57:01,679
than 50% of latency savings

1551
00:57:01,849 --> 00:57:03,849
uh through a fine-tuned model. Let me put it

1552
00:57:03,849 --> 00:57:04,750
in perspective.

1553
00:57:05,398 --> 00:57:06,019
Uh,

1554
00:57:06,639 --> 00:57:08,708
before we were for one of the planar stages,

1555
00:57:08,760 --> 00:57:10,378
we were using, uh,

1556
00:57:10,760 --> 00:57:12,958
a high-end model, and that was giving

1557
00:57:12,958 --> 00:57:14,840
3 to 6 seconds of latency.

1558
00:57:15,349 --> 00:57:17,559
And then at, particularly at

1559
00:57:17,559 --> 00:57:20,000
P90 and P90 95

1560
00:57:20,000 --> 00:57:20,958
or P90+,

1561
00:57:21,719 --> 00:57:23,878
we were able to cut down the latency heavily

1562
00:57:23,878 --> 00:57:25,378
and brought it under 1 2nd.

1563
00:57:26,610 --> 00:57:28,769
And with this validation,

1564
00:57:29,688 --> 00:57:31,728
Uh, once we have validated

1565
00:57:31,728 --> 00:57:33,849
this, we have started to extend it

1566
00:57:33,849 --> 00:57:35,869
to other set of agents,

1567
00:57:35,878 --> 00:57:37,989
and we are seeing, uh, trending results.

1568
00:57:39,099 --> 00:57:41,398
With that, I will invite uh Summit

1569
00:57:41,398 --> 00:57:42,000
and David.

1570
00:57:42,898 --> 00:57:45,909
Thank you. Cool.

1571
00:57:46,070 --> 00:57:47,789
Stay naked. You can stay here over us.

1572
00:57:49,289 --> 00:57:51,530
Thank you. Uh, thank you, everyone, once again

1573
00:57:51,530 --> 00:57:54,050
for coming all the way to Mandalay Bay on a Thursday

1574
00:57:54,050 --> 00:57:56,250
afternoon. Um, and thank you for

1575
00:57:56,250 --> 00:57:57,409
staying through the presentation.

1576
00:57:57,949 --> 00:58:00,250
Uh, please do, uh, go ahead

1577
00:58:00,250 --> 00:58:01,489
and, uh,

1578
00:58:01,789 --> 00:58:04,148
provide your feedback, uh, through the survey

1579
00:58:04,148 --> 00:58:04,668
in the app.

1580
00:58:04,949 --> 00:58:06,989
We would always, we love to go back and

1581
00:58:06,989 --> 00:58:09,148
look at all the feedback that you shared with us so we can

1582
00:58:09,148 --> 00:58:11,668
come back with better content and better presentations

1583
00:58:11,668 --> 00:58:12,300
every year.

1584
00:58:12,668 --> 00:58:14,750
Uh, we're gonna stay here for some more time

1585
00:58:14,750 --> 00:58:16,809
just to take any questions you might have.

1586
00:58:17,188 --> 00:58:19,228
Uh, please feel free to, uh, come to

1587
00:58:19,228 --> 00:58:21,250
the stage and, and, and, and we can chat away.

1588
00:58:21,349 --> 00:58:22,208
Thank you so much.

1589
00:58:22,550 --> 00:58:23,510
Thank you. Thank you.

