# AWS re:Invent 会议总结：通用数据连接与 ETL 和 SQL 查询

## 会议概述

本次会议主要探讨了企业在数据集成方面面临的挑战以及 AWS 提供的解决方案。演讲者 Shri Wliker（高级分析专家解决方案架构师）和 Shre Alpani（AWS 分析高级产品经理）介绍了如何通过 AWS Glue、Zero ETL 和联邦查询等功能简化数据管道，实现通用数据连接。

当今企业的数据分散在不同的系统中——客户数据、销售数据、服务分析数据存储在完全不同的位置。这导致即使是简单的数据分析也需要数周时间来整合数据。AWS 的通用数据连接策略旨在解决这一问题，通过三种不同的方法满足不同场景的需求：使用 AWS Glue 连接器进行自管理数据注入、使用 Zero ETL 进行托管数据注入，以及使用联邦查询进行就地数据访问。

会议通过一个虚拟角色 Alex（数据工程师）的实际场景，展示了如何利用这些工具从 Salesforce、SAP、ServiceNow、Snowflake 等多个数据源无缝集成数据到 Amazon Redshift 和 S3 数据湖中，帮助企业更快地获得可操作的洞察。

## 详细时间线

### 开场与问题陈述
[00:00 - 03:30] - 会议开场，演讲者介绍并提出核心问题：企业数据分散在不同系统中，就像咖啡店的原料分散在不同位置一样荒谬。数据工程师需要花费数周时间整合数据才能进行基本分析。

[03:30 - 05:45] - 介绍演讲者团队和会议主题：通过 ETL 和 SQL 查询实现通用数据连接，展示如何简化数据管道并加速数据注入。

### 企业数据挑战分析
[05:45 - 08:20] - 现场调查：有多少人正在使用多种操作数据库和企业应用程序。强调数据驱动决策的重要性以及当前面临的根本挑战：数据存在于不同的孤岛中，分析和 AI/ML 工作负载正在融合。

[08:20 - 11:15] - 展示典型企业环境的复杂性：底层有多个数据源（财务、远程信息处理、客户体验、制造、销售等），中间层包括数据湖、数据仓库、转换引擎（AWS Glue、EMR）、查询引擎（Redshift、Athena）以及 ML 平台（SageMaker、Bedrock）。不同角色（数据科学家、数据工程师、数据分析师、数据管理员）都需要访问这些系统。

### AWS 通用数据连接策略
[11:15 - 13:40] - 介绍虚拟用户 Alex（数据工程师）及其面临的挑战：如何连接数十甚至数百个数据源，如何简化数据管道而不需要为每个新工具建立深厚的专业知识。

[13:40 - 15:50] - 展示 Alex 的环境：使用 Snowflake 进行历史数据分析，CRM 数据在 Salesforce，运营数据在 SAP，IT 服务数据在 ServiceNow，同时使用 AWS 服务（Redshift、S3、RDS、Aurora）。

[15:50 - 17:30] - 定义 Alex 的三个主要任务：1) 创建 ETL 管道从多个源注入数据；2) 减少管理数据注入管道的运营负担；3) 处理临时查询请求。

### AWS Glue 连接器详解
[17:30 - 19:45] - 介绍 AWS 的三种通用连接选项：自管理注入（AWS Glue 连接器）、托管数据注入（Zero ETL）、就地数据访问（联邦查询）。

[19:45 - 24:30] - 深入介绍 AWS Glue：无服务器数据集成服务，支持数据质量管理、数据目录、成本效益高、支持所有数据用户（分析师使用可视化界面、工程师使用 Python/Scala、管理员使用 SQL）、支持所有工作负载（传统 ETL、现代 ELT、流式和批处理分析）。

[24:30 - 27:45] - 强调 AWS Glue 的 100 多个预构建连接器，包括三种类型：原生连接器（AWS 管理）、自定义连接器（用户构建）、市场连接器（第三方合作伙伴构建）。还介绍了托管目录、Apache Iceberg 表支持以及安全功能。

### 实际应用案例：AWS Glue
[27:45 - 31:20] - 展示 Alex 如何使用 AWS Glue 连接器统一客户档案：从 SAP 获取运营数据（购买历史、付款条款、信用额度），从 Salesforce 获取客户档案和销售数据。Glue 连接器处理所有 API 集成，无需学习新 API。

[31:20 - 33:50] - 介绍数据质量检查功能：检测异常（电子邮件格式、年龄、负销售额等），在数据到达分析平台之前捕获问题。最终数据以 Iceberg 表格式存储在 S3 上，可供任何分析或 AI/ML 应用查询。

[33:50 - 37:15] - 宣布新增 20 个连接器，包括 Datadog（应用监控数据）、Okta（用户交互）、Adobe Analytics（营销活动）、Asana（项目管理）。所有连接器使用 OAuth 2.0 标准认证，支持连接测试、验证和元数据浏览。

### 客户案例：Vyaire Medical
[37:15 - 40:30] - 介绍 Vyaire Medical 案例：呼吸护理公司，数据分散在 SAP、JD Edwards、ServiceNow、Salesforce 等系统中。使用 AWS Glue 和连接器将数据整合到 AWS 湖仓架构中。8 个月内转换了数百个 ETL 作业，实现 50% 成本节省，开发人员生产力大幅提高（从数周缩短到数天，分析从数天缩短到数小时）。

### Zero ETL 介绍
[40:30 - 44:20] - Shre Alpani 接手演讲，介绍 Alex 的第二个挑战：保持分析数据与运营数据库同步，但不增加运营开销。当前 ETL 管道每小时运行一次，数据至少延迟一小时，且需要维护管道。

[44:20 - 47:50] - 对比传统数据复制需求：需要针对每个源应用业务逻辑、实现复杂重试逻辑、维护基础设施、监控管道、需要专业 ETL 技能。AWS Zero ETL 提供托管集成，无需构建 ETL 管道。

[47:50 - 51:30] - 介绍 Zero ETL 的特点：AWS 托管集成、只需创建一次集成、高性能（Aurora/RDS 到 Redshift 几秒钟内复制，其他源几分钟内）、减少洞察时间、最小化源端干扰、支持加密和 VPC 控制。

[51:30 - 54:45] - 解释 Zero ETL 的工作原理（以 Aurora 到 Redshift 为例）：初始加载完整快照、自动创建表和数据类型、近实时捕获插入/更新/删除操作、自动处理架构变更（如删除列）。

### Zero ETL 演示
[54:45 - 59:30] - 现场演示创建 Salesforce 到 Redshift 的 Zero ETL 集成：在 AWS Glue 控制台创建连接、选择源和目标、过滤 Salesforce 对象、预览数据、配置加密和复制间隔、创建 Redshift 数据库。演示如何在 Redshift 查询编辑器中查询数据和查看集成指标。

### Zero ETL 支持的数据源
[59:30 - 63:20] - 宣布今年新增 11 个数据源，Zero ETL 现在支持 23 个不同的数据源，分为三类：
1. AWS 数据库（DynamoDB、RDS for MySQL/Oracle/PostgreSQL、Aurora、Oracle Database at AWS）
2. 第三方企业应用（Salesforce、SAP、ServiceNow、Zendesk 等 8 个）
3. 自管理数据库（MySQL、PostgreSQL、SQL Server、Oracle，可在本地或 EC2 上托管）

[63:20 - 65:40] - 介绍目标系统：所有 23 个源都可以注入到 Amazon Redshift；12 个源可以注入到 Amazon S3 数据湖；新增 Amazon S3 Tables 作为目标（为分析工作负载优化的存储）。

### Alex 的 Zero ETL 应用场景
[65:40 - 69:30] - 展示 Alex 如何使用 Zero ETL：销售团队需要了解顶级机会的收入，销售数据在 Aurora，机会信息在 Salesforce。Alex 设置了 Aurora 到 Redshift 和 Salesforce 到 Redshift 的 Zero ETL 集成，数据自动近实时流入 Redshift，无需管理管道维护工作。

### Zero ETL 新功能
[69:30 - 72:45] - 介绍 Zero ETL 的新功能：
- 更多控制：按需注入、历史模式（在 Redshift 中保留变更历史）
- 更多灵活性：自定义刷新间隔（15 分钟到 6 天）、从一个 Aurora 集群创建最多 5 个集成、支持 Aurora PostgreSQL 声明式分区表
- 改进的可观察性：将客户端错误记录到 CloudWatch 日志

### 客户案例：Pinex
[72:45 - 75:30] - 介绍 Pinex 案例：加密货币交易所，需要使用最新市场数据为用户提供洞察。之前使用自管理 ETL 管道导致 30 分钟延迟。转向 Zero ETL 后：延迟减少 98%、维护成本降低 80%、总体运营开销成本降低 66%。

[75:30 - 结束] - 会议总结和结束语。