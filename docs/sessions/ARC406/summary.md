# AWS re:Invent 2025 会议总结：使用 Amazon Nova 进行天气预报文本生成

## 会议概述

本次会议由英国气象局（Met Office）的数据科学 IT 研究员 Ed Steele 和 AWS 全球原型团队的应用科学家 Desh 共同主讲。会议以具有百年历史的英国航运预报（Shipping Forecast）为切入点，展示了如何利用 AI 技术，特别是 Amazon Nova 基础模型，来革新传统的天气预报服务。

英国气象局作为世界上历史最悠久的国家气象服务机构，每天处理超过 2150 亿条观测数据。航运预报自 1859 年皇家宪章号沉船事故后开始发展，至今已成为海上安全的基石和英国文化标志。传统上，气象学家需要花费数小时到一天时间来分析 31 个海域的复杂气象数据，并将其转化为符合严格格式要求的文本预报。

在仅仅四周的原型开发中，团队成功训练 Amazon Nova 模型完成这项任务，准确率达到 52-62%，处理时间缩短至 5 分钟以内。这个项目不仅展示了大语言模型在气象领域的应用潜力，更重要的是探索了天气预报"最后一公里"的价值——即如何将复杂的数值预报数据转化为用户可理解、可操作的信息。会议详细介绍了两种技术方案：基于文本的 LLM 方法和基于视频的 VLM（视觉语言模型）方法，以及完整的 AWS 架构设计和实施细节。

## 详细时间线与关键要点

### 00:00 - 开场与航运预报介绍
- 播放了 2025 年 7 月 4 日的实际航运预报音频，展示其独特的格式和内容
- 介绍航运预报作为世界上最古老、持续时间最长的天气预报服务
- 每天通过 NAVTEX 和 BBC Radio 4 向海员广播四次

### 02:30 - 航运预报的历史背景
- 追溯到 1859 年 10 月皇家宪章号蒸汽快船沉没事故
- 该风暴造成超过 450 人丧生，总计至少 800 人死亡，133 艘船只沉没
- 气象局创始人 Robert Fitzroy 上将于 1861 年 2 月推出首个英国风暴警报服务

### 05:15 - 气象局现状与价值
- 气象局是世界上少数跨越天气和气候、科学和服务、民用和军用等多个领域的组织
- 独立分析报告显示，未来 10 年将为英国经济和社会带来 560 亿英镑的效益
- 纳税人投资回报率达到 19:1

### 07:00 - 天气预报流程介绍
- 每天摄取约 2150 亿条全球观测数据
- 使用超级计算机运行数值模型，通过运动方程计算天气演变
- 气象学家解读复杂数据场，为公众提供增值服务
- 服务对象包括国防、航空、海洋等多个领域

### 09:20 - 天气预报的进步
- 物理数值模型的准确性每十年提高半天到一天
- 2013 年的 5 天预报准确度相当于 2003 年的 4 天预报
- 改进来自观测升级、数据同化、动力学和物理过程表示以及模型分辨率提升

### 11:45 - 机器学习在气象领域的崛起
- 气象局一直是大数据组织，AI 和机器学习活动持续多年
- 展示了数据驱动模型性能随时间提升的图表
- 2017 年 9 月开始，数据驱动方法稳步提升，逐渐接近物理模型性能

### 13:30 - 2022 年 12 月的突破
- 被称为"消失的圣诞节"，因为在 12 月 20 日至圣诞期间发布了大量突破性研究
- DeepMind、Nvidia、华为等非传统气象机构推动的进展
- 首次出现数据驱动方法在某些参数上超越物理模型的性能

### 15:00 - "最后一公里"的重要性
- 预报只有在用户能从中获得决策价值时才有意义
- 虽然预报能力有重大进展，但如何传达"天气将做什么"的关注较少
- 最后一公里提供了更个性化服务、多模态数据交付的机会
- 可以减少对人工解释的依赖

### 17:30 - 航运预报作为用例的技术挑战
- 需要将复杂的气象模型数据大规模转化为文本
- 处理多维大型数据阵列（空间、时间、多参数）
- 必须符合航运预报的特定措辞和格式要求
- 包括气压、海况、能见度、天气、风速、风向等多个参数

### 20:00 - 数据特征与挑战
- 数据包含大气和海洋模型输出
- 格式既有概率性也有确定性
- 多维数据：纬度、经度、时间
- 单次预报运行：大气模型约 45GB，海洋模型约 5GB
- 针对航运预报区域裁剪后：大气数据 152MB，海洋数据 7MB
- 3 个月数据总量约 85GB

### 22:45 - 数据格式说明
- 使用 NetCDF（网络通用数据格式），这是大气和海洋科学的标准
- 类似于 Pandas 或 xarray 的内存格式
- 对气象界外的人来说可能不太熟悉

### 24:00 - 解决方案概述
- 使用 Amazon Nova Light 和 Nova Pro 1.0 模型
- 传统上需要专家气象学家数小时到一天完成的任务
- 仅用四周原型开发，达到 52-62% 准确率，处理时间不到 5 分钟

### 26:30 - 两种技术方法介绍
方法一：文本中介方法（LLM）
- 提取对应航运预报不同区域的统计数据
- 将统计摘要传递给 Nova LLM
- 作为基准方法

方法二：视频能力方法（VLM）
- 将网格数据转换并编码为视频
- 通常按海域为基础处理大多数参数
- 使用气象学家之前发布的公报进行微调
- 托管后可实时运行推理

### 29:00 - Desh 接手讲解部署策略
- 介绍两种微调 Nova 模型的方式：
  1. SageMaker 训练作业
  2. SageMaker Hyperpod
- 实验使用 SageMaker 训练作业，在 P5 xlarge GPU 上运行 3 小时，使用 4 个 GPU
- 生产环境中如果需要训练数周、使用数百个 GPU，推荐使用 SageMaker Hyperpod

### 31:15 - LLM 架构深入讲解
- 使用 Claude Sonnet 3.7 和 Nova Pro 1 进行比较
- Nova Pro 1 在天气预报方面准确性更好，且未经微调
- 原始网格数据示例：多维数组，XY 表示纬度经度，值为天气属性（如波高）
- 数据准备：如果某海域 90% 的风向北，10% 向东北，则整个区域标记为北向

### 34:00 - LLM 生产架构详解
- 原始网格数据存储在 S3
- 使用 ECS 进行并行数据处理（86GB 数据，单核处理需要数月）
- 可选 EKS 或 AWS Batch 进行数据并行处理
- 处理后调用 Bedrock 基础模型
- 输出存储到 S3
- 架构适合处理大量历史数据
- Bedrock 支持批量推理（需检查具体模型支持情况）
- 使用 ECS 提供灵活性，可根据需求调整计算能力
- 原型阶段编排是手动的

### 38:30 - 生产化 LLM 架构改进
- 添加 AWS Glue Catalog 和 Lake Formation 用于细粒度数据访问控制
- 使用 Amazon SQS 解耦架构，便于追踪失败的数据和预报
- 可附加死信队列处理失败记录
- 数据预处理模块保持不变（ECS/EKS/Batch）

### 41:00 - 替代架构方案
流数据架构：
- 使用 Amazon Kinesis Data Streams
- Lambda 进行处理
- 根据处理复杂度可能使用 Batch
- 处理后的数据存储在 DynamoDB 和 OpenSearch
- 支持实时分析

无服务器事件驱动架构：
- 数据上传到 S3 触发 Lambda
- 使用 AWS Step Functions 进行处理编排
- 调用 Amazon Bedrock
- 数据存储到 S3

### 44:00 - VLM（视觉语言模型）方法详解
- 每天四次预报，覆盖 31 个海域
- 每个区域有 4-5 个天气属性
- 每个属性需要创建视频
- 每小时采集一次传感器数据快照
- 24 小时 = 24 帧图像
- 将 24 张图像拼接成 1 秒视频（24 fps）
- 这是训练数据的输入格式

### 46:30 - VLM 架构详解
- 原始网格数据存储在 S3（86GB 数值数据转换为 56GB 视频，3 个月数据）
- 需要清理数据，跳过某些专家合并两个海域预报的情况
- 使用 Amazon SageMaker AI 提交 Nova 微调作业
- 训练完成后获得模型权重输出
- 使用 Amazon Bedrock 托管模型

### 49:00 - LoRA 与全量微调对比
LoRA（低秩适应）：
- 只微调适配器权重，不改变基础模型
- 可以使用按需推理
- 只需为输入和输出 token 付费
- 基础模型权重在服务桶中，LoRA 权重在用户账户中
- 部署时将 LoRA 权重附加到基础模型

全量微调：
- 更新每一层的权重
- 训练时间更长，但模型学习更多
- 整个模型权重需要单独存储
- 必须使用预置吞吐量（Provisioned Throughput）
- 需要 24 小时在实例上托管

### 52:00 - VLM 生产架构
- 数据平面：S3 + Amazon FSX for Lustre（用于低延迟缓存）
- 添加 Lake Formation 进行访问控制
- 计算平面：使用 SQS 解耦，ECS/EKS/Batch 处理
- 处理后的视频存储在 S3
- 一次预报：24 小时记录 → 24 张图像 → 1 秒视频
- 31 个区域 × 每个天气属性 = 大量视频数据
- 使用 SageMaker AI 或 Hyperpod 训练
- 模型权重存储在 S3
- 部署到 Bedrock

### 55:30 - 为什么选择 Bedrock 部署
- 可以使用 Bedrock 的所有功能
- 可以使用 Bedrock Converse API，只需更改模型 ID
- 可以使用 Guardrails 功能
- 减少无差别的繁重工作

### 57:00 - VLM 替代架构
模型微调架构：
- 数据存储在 S3（可扩展性好，与 EKS/ECS 配合数据拉取快）
- 数据处理后存储到 S3
- 使用 SageMaker 或 Hyperpod 训练
- 部署到推理端点

推理调用架构：
- VLM 涉及大量数据处理
- 从 S3 处理原始网格数据创建视频至少需要 1 分钟
- 处理完成后调用 Amazon Bedrock 获取推理结果
- 也可以托管在 SageMaker 端点或 Amazon EKS（适用于开源模型如 Hugging Face 的 LLaMA 3）

### 59:30 - UI 展示架构方案
公网访问架构：
- CloudFront + API Gateway + Lambda
- 使用 SQS 解耦
- 调用 Bedrock/SageMaker/EKS

负载均衡架构：
- CloudFront + Application Load Balancer
- 静态网站或 EC2 实例/容器服务
- 调用 SageMaker AI/EKS/Bedrock

其他选项：
- Amazon App Runner
- Amazon Amplify 托管网站

### 01:01:00 - 实际代码演示
互动环节：
- 询问有多少人微调过大语言模型或基础模型
- 询问是否第一次尝试就成功（大多数人表示没有）
- Desh 分享运行了约 25 次实验，只有 1-2 次失败（因训练数据缺失）

### 01:02:30 - 训练数据格式展示
- System prompt: "你是英国海事气象专家"
- User prompt: "分析这个 1 秒视频并执行以下操作..."
- 输入数据：海域名称（如 Biscay）+ 天气属性
- 输入视频：1 秒视频文件
- Ground truth/输出：预期的预报文本

- 3000 个样本创建一个 JSON 文件，每行一个样本（扁平化格式）
- 需要创建训练数据集和验证数据集

### 01:04:00 - 配置文件（Recipe File）讲解
- Recipe 文件是超参数配置
- 指定要微调的模型
- Replicas：使用多少个 GPU
- 训练配置：epoch 数量、正则化参数
- 优化器：开箱即用的多种优化器
- LoRA 配置：适配器设置

### 01:05:30 - 训练脚本演示
脚本内容极其简洁：
- 定义 YAML 配置文件路径
- 输入数据：train.json（如 3000 行）
- 输出桶：存储模型权重
- 验证数据：validation.json

验证数据集的重要性：
- 模型会在训练数据上优化，训练损失会降低
- 但在实际数据上可能表现不佳
- 需要找到训练损失和验证损失都下降的最佳点
- 一旦验证损失上升，需要停止训练

### 01:07:00 - 训练配置细节
- Image URI：Docker 镜像（运行非常流畅，无库配置问题）
- 实例类型：P5.48xlarge（Nova 微调也支持 P5 和 P6）
- 推荐实例数量：4、8 或 16
- 可添加 TensorBoard 输出用于监控
- 创建 Estimator 并提供所有信息
- 调用 fit() 方法开始训练
- 3 小时内完成模型训练

### 01:08:30 - 模型部署代码
- 使用 Bedrock 客户端创建自定义模型
- 获取模型权重
- 创建自定义部署，部署到 Bedrock
- 整个过程大约需要 1 小时
- 获得自定义部署 ARN（模型 ARN 或模型 ID）

### 01:09:00 - 推理代码演示
- 展示"魔法代码"进行推理调用
- [会话在此处结束，未完整展示推理代码]

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


总结： 本次会议全面展示了如何利用 AWS 的 AI 服务（特别是 Amazon Nova 和 Bedrock）来现代化传统气象服务。从数据处理、模型微调到生产部署，提供了完整的技术栈和架构方案，为其他领域的类似应用提供了宝贵的参考。