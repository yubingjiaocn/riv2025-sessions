1
00:00:00,810 --> 00:00:02,060
- Good evening, everyone.

2
00:00:03,240 --> 00:00:05,130
I know it has been long
day for all of you,

3
00:00:05,130 --> 00:00:08,400
but I hope that re:Invent has
started great for all of you.

4
00:00:08,400 --> 00:00:11,070
And we do have a exciting topic to cover.

5
00:00:11,070 --> 00:00:13,710
As start of this session
where we will be talking about

6
00:00:13,710 --> 00:00:15,930
how we can break the legacy barrier

7
00:00:15,930 --> 00:00:19,350
and accelerate the
modernization using GenAI.

8
00:00:19,350 --> 00:00:20,611
I'm Anand Bilgaiyan,

9
00:00:20,611 --> 00:00:22,740
I'm a senior specialist
partner solution architect

10
00:00:22,740 --> 00:00:26,520
for enterprise transformation
and I'm joined by Sree.

11
00:00:26,520 --> 00:00:28,290
- Hi, good evening, everyone.

12
00:00:28,290 --> 00:00:29,700
My name is Sreekumar Nair,

13
00:00:29,700 --> 00:00:31,980
I'm a senior specialist
solution architect, migration

14
00:00:31,980 --> 00:00:36,090
and modernization at AWS and
I'm based out of Singapore.

15
00:00:36,090 --> 00:00:40,203
- Thank you Sree. So let's get started.

16
00:00:41,040 --> 00:00:43,590
Many of our customers, for them,

17
00:00:43,590 --> 00:00:46,090
their digital transformation
is a key priority

18
00:00:46,950 --> 00:00:50,340
to support their business growth, right?

19
00:00:50,340 --> 00:00:53,430
But the legacy IT applications

20
00:00:53,430 --> 00:00:55,860
and the landscape becomes the barrier

21
00:00:55,860 --> 00:00:57,600
for their business growth.

22
00:00:57,600 --> 00:01:00,810
Now, the modernizing these
legacy applications can be

23
00:01:00,810 --> 00:01:04,650
complex and they may warrant
significant amount of the cost

24
00:01:04,650 --> 00:01:06,930
as well as the effort.

25
00:01:06,930 --> 00:01:09,180
And that's where we are going to look

26
00:01:09,180 --> 00:01:12,060
how we can accelerate the modernization

27
00:01:12,060 --> 00:01:15,090
of those legacy application using some

28
00:01:15,090 --> 00:01:18,755
of the architectural
methodologies, best practices,

29
00:01:18,755 --> 00:01:23,755
and the power of genAI coming all together

30
00:01:24,510 --> 00:01:27,183
to transform those legacy
applications, right?

31
00:01:28,530 --> 00:01:30,180
So a quick agenda,

32
00:01:30,180 --> 00:01:33,060
however, next one hour going to look like.

33
00:01:33,060 --> 00:01:36,620
So we are going to talk about
a use case from monolith

34
00:01:36,620 --> 00:01:40,020
to microservices where we
are considering monolithic

35
00:01:40,020 --> 00:01:42,219
as a representation of
the legacy application

36
00:01:42,219 --> 00:01:45,764
and the microservices based
cloud native architecture as a

37
00:01:45,764 --> 00:01:47,730
to be targeted state.

38
00:01:47,730 --> 00:01:50,430
And then we are going to look upon

39
00:01:50,430 --> 00:01:53,970
how we can converge from this
legacy architectures in terms

40
00:01:53,970 --> 00:01:56,610
of monolithic to the
microservices using some

41
00:01:56,610 --> 00:01:59,220
of the architectural methodologies

42
00:01:59,220 --> 00:02:02,730
and then how we can leverage
GenAI to accelerate that.

43
00:02:02,730 --> 00:02:05,130
Since this is a level 400 session,

44
00:02:05,130 --> 00:02:09,556
so we will be covering
the different demos right

45
00:02:09,556 --> 00:02:12,090
toward the different modernization phase

46
00:02:12,090 --> 00:02:14,313
as part of this session, right?

47
00:02:16,320 --> 00:02:20,628
So let me first introduce
a sample application,

48
00:02:20,628 --> 00:02:23,880
which is a Unicorn Ecommerce Store,

49
00:02:23,880 --> 00:02:28,050
which representing a
monolithic legacy application

50
00:02:28,050 --> 00:02:29,310
for our session.

51
00:02:29,310 --> 00:02:33,060
And we will be converging this

52
00:02:33,060 --> 00:02:37,260
into the more modernization
based architecture

53
00:02:37,260 --> 00:02:38,730
throughout our session.

54
00:02:38,730 --> 00:02:43,170
And in the end we will be
having a modernized state

55
00:02:43,170 --> 00:02:46,560
of this Unicorn store application.

56
00:02:46,560 --> 00:02:49,650
Now, what are some of the
business capabilities?

57
00:02:49,650 --> 00:02:53,050
This standard e-commerce
monolith application have.

58
00:02:53,050 --> 00:02:55,440
Just have a look on that.

59
00:02:55,440 --> 00:03:00,440
So it's a standard
web-based e-com application

60
00:03:02,190 --> 00:03:04,890
which allow users to log in,

61
00:03:04,890 --> 00:03:07,950
then search the different Unicorn icon

62
00:03:07,950 --> 00:03:12,720
and then do the check on
their specification pricing.

63
00:03:12,720 --> 00:03:15,180
And then based on their need,

64
00:03:15,180 --> 00:03:19,470
they can actually select
these Unicorn icon, add them

65
00:03:19,470 --> 00:03:22,669
to the cart, review the cart,

66
00:03:22,669 --> 00:03:26,850
and then provide their payment as well

67
00:03:26,850 --> 00:03:28,560
as the shipment details.

68
00:03:28,560 --> 00:03:31,140
And then they can just place the order.

69
00:03:31,140 --> 00:03:34,150
A standard flow like what we all use to

70
00:03:35,520 --> 00:03:38,313
do on any typical e-commerce
application, right?

71
00:03:39,660 --> 00:03:41,370
So let's look the function flow,

72
00:03:41,370 --> 00:03:44,340
what we just saw from this Unicorn store

73
00:03:44,340 --> 00:03:46,260
monolith application, right?

74
00:03:46,260 --> 00:03:51,040
So users log in, they start
search for the products

75
00:03:52,110 --> 00:03:55,860
and then based on their
requirement, they add those products

76
00:03:55,860 --> 00:03:59,700
or item to the cart and
then they make the payments.

77
00:03:59,700 --> 00:04:03,220
And then after the payment,
they actually place the order.

78
00:04:03,220 --> 00:04:06,160
Now these functionality

79
00:04:07,110 --> 00:04:12,110
has been built using a standard
.net core 3.1 framework

80
00:04:14,160 --> 00:04:17,670
and what are the properties
this application have

81
00:04:17,670 --> 00:04:21,030
which make it kind of a legacy
monolithic architecture.

82
00:04:21,030 --> 00:04:24,930
If we look upon the different
modules which support these

83
00:04:24,930 --> 00:04:29,490
different business capabilities
like cart, like payments,

84
00:04:29,490 --> 00:04:33,930
like checkout, like the
product catalog, they all are,

85
00:04:33,930 --> 00:04:35,820
these all modules are built

86
00:04:35,820 --> 00:04:39,475
and bundled as part of
the single application.

87
00:04:39,475 --> 00:04:44,250
Now we have looked this flow
from the business perspective,

88
00:04:44,250 --> 00:04:46,980
let's revisit the same application

89
00:04:46,980 --> 00:04:50,730
and its property from the
architecture perspective as well.

90
00:04:50,730 --> 00:04:53,580
So again, as I mentioned,
this application comprises

91
00:04:53,580 --> 00:04:55,290
of different modules.

92
00:04:55,290 --> 00:04:57,420
We support the different
business capabilities

93
00:04:57,420 --> 00:05:01,651
around the cart products and
the payments and the order.

94
00:05:01,651 --> 00:05:05,130
All these products, all these
modules already are bundled

95
00:05:05,130 --> 00:05:07,230
as part of the same application,

96
00:05:07,230 --> 00:05:11,010
mostly also leveraging
the same common database.

97
00:05:11,010 --> 00:05:14,389
Now what's happening there
is the single application is

98
00:05:14,389 --> 00:05:16,350
doing everything,

99
00:05:16,350 --> 00:05:18,630
all the business capabilities
are being supported

100
00:05:18,630 --> 00:05:22,260
by this application and
that's where it is having lot

101
00:05:22,260 --> 00:05:23,820
of hidden complexities.

102
00:05:23,820 --> 00:05:25,020
The different modules,

103
00:05:25,020 --> 00:05:27,690
they all are dependent to
each other, maybe referring

104
00:05:27,690 --> 00:05:29,760
to each other implicitly.

105
00:05:29,760 --> 00:05:33,600
Now these are some of the
properties which make this

106
00:05:33,600 --> 00:05:35,130
application monolithic.

107
00:05:35,130 --> 00:05:36,600
And now let's look into

108
00:05:36,600 --> 00:05:38,700
what are the different challenges this

109
00:05:38,700 --> 00:05:40,413
application will have.

110
00:05:41,490 --> 00:05:44,130
So one of the challenges
around the scalability,

111
00:05:44,130 --> 00:05:47,250
let's say we are running
to the Black Friday sale

112
00:05:47,250 --> 00:05:48,660
or the Cyber Monday sale

113
00:05:48,660 --> 00:05:50,820
where we are anti anticipating the two x

114
00:05:50,820 --> 00:05:52,170
or three x amount of orders.

115
00:05:52,170 --> 00:05:54,337
Now we want to scale the order module

116
00:05:54,337 --> 00:05:57,150
to handle these Cyber Monday

117
00:05:57,150 --> 00:05:59,100
or maybe the Black Friday event.

118
00:05:59,100 --> 00:06:01,290
What we rather end up scaling this

119
00:06:01,290 --> 00:06:02,610
entire application, right?

120
00:06:02,610 --> 00:06:05,670
Because all order modules
like other module is bundled

121
00:06:05,670 --> 00:06:07,110
as part of the single application.

122
00:06:07,110 --> 00:06:11,130
Now what that causes, it causes
the operational challenges.

123
00:06:11,130 --> 00:06:14,550
It also increase the overall
cost of the deployment, right?

124
00:06:14,550 --> 00:06:16,470
Because you're actually
deploying the entire application

125
00:06:16,470 --> 00:06:19,830
as a whole, even if you want
to just scale the order module.

126
00:06:19,830 --> 00:06:22,110
The next is the
significant time to change.

127
00:06:22,110 --> 00:06:24,780
So it impact the business agility as well.

128
00:06:24,780 --> 00:06:26,640
Let's suppose the different new features

129
00:06:26,640 --> 00:06:27,990
which need to get released.

130
00:06:27,990 --> 00:06:30,640
Now any feature will warrant to

131
00:06:32,190 --> 00:06:35,130
test this entire application, right?

132
00:06:35,130 --> 00:06:37,950
And then deploy this entire
application into the production.

133
00:06:37,950 --> 00:06:41,433
So it also increase the
overall time to market, right?

134
00:06:42,540 --> 00:06:45,420
And that another challenge
which is imposed by this kind

135
00:06:45,420 --> 00:06:47,310
of monolithic applications are,

136
00:06:47,310 --> 00:06:49,830
is on if any issue in any module

137
00:06:49,830 --> 00:06:52,500
and any part of the
application may bog down

138
00:06:52,500 --> 00:06:53,850
the entire application.

139
00:06:53,850 --> 00:06:56,730
So it also impact your
business continuity.

140
00:06:56,730 --> 00:06:59,040
And apart from that it also impose a lot

141
00:06:59,040 --> 00:07:00,120
of operational challenges

142
00:07:00,120 --> 00:07:02,040
and introduce the technical depth

143
00:07:02,040 --> 00:07:03,390
in your environment, right?

144
00:07:05,850 --> 00:07:08,400
So when we talk about, okay, we understand

145
00:07:08,400 --> 00:07:10,590
what are the challenges of
the monolithic applications.

146
00:07:10,590 --> 00:07:12,870
Now, if we want to modernize that,

147
00:07:12,870 --> 00:07:16,770
the modernization is not a
single step process, right?

148
00:07:16,770 --> 00:07:21,660
Modernization is a phased
approach which required a careful

149
00:07:21,660 --> 00:07:26,370
consideration to transform these
legacy application into the

150
00:07:26,370 --> 00:07:30,360
more modern agile cloud
native architectures.

151
00:07:30,360 --> 00:07:34,230
Now, given a case of this
particular application, right?

152
00:07:34,230 --> 00:07:38,580
If we have to transform or
modernize this application,

153
00:07:38,580 --> 00:07:41,442
what could be the
possible different phases

154
00:07:41,442 --> 00:07:43,950
which we may have to think through

155
00:07:43,950 --> 00:07:47,340
and take to transform into
the more modern state?

156
00:07:47,340 --> 00:07:49,530
Let's have a view on that.

157
00:07:49,530 --> 00:07:51,300
Firs, definitely, the first phase is,

158
00:07:51,300 --> 00:07:54,810
or the first step is to
do a application analysis.

159
00:07:54,810 --> 00:07:57,570
This application analysis
is very, very important

160
00:07:57,570 --> 00:08:00,940
because this application
analysis may give you some of the

161
00:08:01,950 --> 00:08:05,190
properties around the
application which may help you

162
00:08:05,190 --> 00:08:07,230
to take the first step
toward your modernization.

163
00:08:07,230 --> 00:08:10,140
For example, as I mentioned
in the previous slide,

164
00:08:10,140 --> 00:08:12,780
this particular Unicorn store application

165
00:08:12,780 --> 00:08:17,550
is built on .net core 3.1,
which is a older framework.

166
00:08:17,550 --> 00:08:21,900
Now, the first thing is to
improve the overall performance

167
00:08:21,900 --> 00:08:24,300
and the security posture
of my application.

168
00:08:24,300 --> 00:08:28,110
So it's better to transform
this application into the latest

169
00:08:28,110 --> 00:08:29,520
version of the framework, right?

170
00:08:29,520 --> 00:08:32,370
So those kind of insight I
can get via doing the right

171
00:08:32,370 --> 00:08:33,930
application analysis.

172
00:08:33,930 --> 00:08:36,270
Once my application analysis
is done, then I want

173
00:08:36,270 --> 00:08:39,150
to definitely transform my
runtime in the framework so

174
00:08:39,150 --> 00:08:41,550
that I can improve those
performance in the security posture

175
00:08:41,550 --> 00:08:44,660
and make my application
more better in terms

176
00:08:44,660 --> 00:08:47,100
of then introducing the new capabilities

177
00:08:47,100 --> 00:08:50,010
around the modern cloud
native architectures.

178
00:08:50,010 --> 00:08:51,600
Then I definitely have to build

179
00:08:51,600 --> 00:08:52,950
and validate my application

180
00:08:52,950 --> 00:08:55,890
with whatever changes I have
done architecturally from the

181
00:08:55,890 --> 00:08:58,065
framework upgrade standpoint.

182
00:08:58,065 --> 00:09:01,200
And then once that is done, I need

183
00:09:01,200 --> 00:09:03,630
to perform a decomposition analysis

184
00:09:03,630 --> 00:09:07,572
and we will talk much in much
detail about the decomposition

185
00:09:07,572 --> 00:09:08,987
analysis and what are some

186
00:09:08,987 --> 00:09:10,980
of the architectural methodologies

187
00:09:10,980 --> 00:09:13,320
to perform this decomposition analysis.

188
00:09:13,320 --> 00:09:15,450
Once my decommission analysis is done,

189
00:09:15,450 --> 00:09:17,790
what it provide us?

190
00:09:17,790 --> 00:09:22,790
It provide us a identification
of the different services,

191
00:09:23,340 --> 00:09:25,590
in which this monolithic
application could get

192
00:09:25,590 --> 00:09:27,693
transformed or decomposed.

193
00:09:28,770 --> 00:09:30,570
And last but not the least,

194
00:09:30,570 --> 00:09:33,060
once you have identified
those right services,

195
00:09:33,060 --> 00:09:35,190
you start refactoring this application

196
00:09:35,190 --> 00:09:37,680
and then you modernize it

197
00:09:37,680 --> 00:09:40,159
accordingly with the new
architectures, right?

198
00:09:40,159 --> 00:09:44,592
So we are going to look upon
all these different phases,

199
00:09:44,592 --> 00:09:48,480
sorry, we define the right architecture

200
00:09:48,480 --> 00:09:50,910
and then perform the right decomposition

201
00:09:50,910 --> 00:09:52,650
and the refactoring of the application.

202
00:09:52,650 --> 00:09:55,320
And we are going to look upon
all these different seven

203
00:09:55,320 --> 00:09:59,700
phases, how we can perform
these different phases using

204
00:09:59,700 --> 00:10:01,440
the different architectural methodologies

205
00:10:01,440 --> 00:10:03,190
and the capability of genAI, right?

206
00:10:07,230 --> 00:10:11,670
So to perform these different step process

207
00:10:11,670 --> 00:10:15,610
to modernize a legacy application,
we are going to leverage

208
00:10:16,800 --> 00:10:20,010
some of the key genAI based capabilities

209
00:10:20,010 --> 00:10:21,123
provided by AWS.

210
00:10:22,080 --> 00:10:24,933
Now let's look upon those very quickly.

211
00:10:26,400 --> 00:10:31,400
The first one is the Kiro,
which is AI-based IDE,

212
00:10:31,500 --> 00:10:34,800
to accelerate your prototype
into the productions.

213
00:10:34,800 --> 00:10:38,190
Now there be mostly the
developer leverage the code

214
00:10:38,190 --> 00:10:42,300
companion or the AI-based IDE

215
00:10:42,300 --> 00:10:43,710
to perform the vibe coding.

216
00:10:43,710 --> 00:10:46,890
Now we want to get away from
that phase to make, instead

217
00:10:46,890 --> 00:10:49,830
of doing the white coding, we
want to write a viable code

218
00:10:49,830 --> 00:10:53,832
and then we want to go
more into the spec-driven

219
00:10:53,832 --> 00:10:58,832
software development approach
where your prompts become

220
00:10:59,610 --> 00:11:04,610
the specs so that you can
perform a right business analysis

221
00:11:05,007 --> 00:11:07,050
requirement analysis.

222
00:11:07,050 --> 00:11:09,720
And then from there you go

223
00:11:09,720 --> 00:11:12,750
and design your application
according to your requirements

224
00:11:12,750 --> 00:11:15,840
and then from there you
implement those requirements

225
00:11:15,840 --> 00:11:18,960
and then finally you execute
that particular code.

226
00:11:18,960 --> 00:11:20,910
So the end to end lifecycle

227
00:11:20,910 --> 00:11:24,030
or building the software
can be then powered

228
00:11:24,030 --> 00:11:28,590
by using the this ID,
AI-driven ID called Kiro.

229
00:11:28,590 --> 00:11:30,120
Now it has a different capabilities.

230
00:11:30,120 --> 00:11:31,922
The first capability it can help you

231
00:11:31,922 --> 00:11:35,529
to build a new application
using the spec-driven

232
00:11:35,529 --> 00:11:39,240
software development approach,
which I just spoke about.

233
00:11:39,240 --> 00:11:42,750
You can also modify existing
application where you have

234
00:11:42,750 --> 00:11:45,543
to adopt the new change request based on

235
00:11:45,543 --> 00:11:47,160
your business requirement.

236
00:11:47,160 --> 00:11:49,830
That can also be done
using this particular AI

237
00:11:49,830 --> 00:11:51,120
driven IDE Kiro.

238
00:11:51,120 --> 00:11:54,990
And last but not not least, it
also supports the refactoring

239
00:11:54,990 --> 00:11:59,010
and modernizing your existing
application code base.

240
00:11:59,010 --> 00:12:02,670
And we are going to focus on
this particular capability.

241
00:12:02,670 --> 00:12:06,210
Last capability throughout our
session when we go into the

242
00:12:06,210 --> 00:12:08,110
different phases of the modernization.

243
00:12:10,320 --> 00:12:12,960
The next very important

244
00:12:12,960 --> 00:12:15,810
and the key service which we
will be covering in our session

245
00:12:15,810 --> 00:12:17,760
is AWS transform,

246
00:12:17,760 --> 00:12:21,090
which is the first
agentic AI based service

247
00:12:21,090 --> 00:12:25,530
to perform the large scale
migration and modernization.

248
00:12:25,530 --> 00:12:28,140
This particular service has got four

249
00:12:28,140 --> 00:12:29,790
different key capabilities.

250
00:12:29,790 --> 00:12:32,400
The first one is on
around VMware migration

251
00:12:32,400 --> 00:12:35,670
where it can help us to assess

252
00:12:35,670 --> 00:12:37,653
the existing VMware environment,

253
00:12:39,240 --> 00:12:42,840
perform the right networking
design in the context

254
00:12:42,840 --> 00:12:46,920
of migrating those on AWS,
do a right way planning

255
00:12:46,920 --> 00:12:49,080
with the intelligent
grouping of the application.

256
00:12:49,080 --> 00:12:51,390
So effectively migrate
this application cloud.

257
00:12:51,390 --> 00:12:54,870
And last but not least, execute
the actual lift in shift.

258
00:12:54,870 --> 00:12:56,970
The safring capabilities
on the full stack window

259
00:12:56,970 --> 00:12:58,980
modernization, right?

260
00:12:58,980 --> 00:13:00,930
We have released some of the additional

261
00:13:00,930 --> 00:13:04,080
and advanced capabilities
today itself, right?

262
00:13:04,080 --> 00:13:06,960
And our transform has got
more powerful to perform you

263
00:13:06,960 --> 00:13:09,690
end-to-end window
modernization, where along

264
00:13:09,690 --> 00:13:11,820
with the .net modernization means

265
00:13:11,820 --> 00:13:13,770
the .net application transformation.

266
00:13:13,770 --> 00:13:18,390
It also support the modernizing
its associated databases.

267
00:13:18,390 --> 00:13:20,160
So if you have a .net
application, you want

268
00:13:20,160 --> 00:13:21,540
to transform the .net application,

269
00:13:21,540 --> 00:13:23,640
let's say from the legacy .net framework

270
00:13:23,640 --> 00:13:25,470
to the .net eight or .net 10.

271
00:13:25,470 --> 00:13:27,850
Along with that, the associated databases

272
00:13:28,800 --> 00:13:32,250
of this application from the
SQL server can get modernized

273
00:13:32,250 --> 00:13:35,700
into the Amazon Postgres,
Aurora, Aurora Postgres,

274
00:13:35,700 --> 00:13:36,873
the more open source,

275
00:13:39,390 --> 00:13:41,940
the databases which can
significantly improve

276
00:13:41,940 --> 00:13:46,350
your overall cost and give you
the window licensing freedom.

277
00:13:46,350 --> 00:13:48,630
The third is on the
mainframe modernization

278
00:13:48,630 --> 00:13:50,730
where it has got the capability

279
00:13:50,730 --> 00:13:52,582
to perform the mainframe application

280
00:13:52,582 --> 00:13:54,780
modernization assessment

281
00:13:54,780 --> 00:13:57,630
and then you know, do a right
decomposition analysis based

282
00:13:57,630 --> 00:13:59,130
on the domain driven approach.

283
00:13:59,130 --> 00:14:01,650
And then also we have got a new capability

284
00:14:01,650 --> 00:14:03,930
where it can also support all three phases

285
00:14:03,930 --> 00:14:07,980
of mainframe application
modernization form of re-imagining,

286
00:14:07,980 --> 00:14:10,680
replay forming and
refactoring the application

287
00:14:10,680 --> 00:14:13,680
and also helping to the customer

288
00:14:13,680 --> 00:14:16,380
to significantly reduce the testing effort

289
00:14:16,380 --> 00:14:18,450
for the mainframe workload.

290
00:14:18,450 --> 00:14:21,390
And last but not the least,
the custom modernization,

291
00:14:21,390 --> 00:14:24,840
we are not only the .net, you
can transform the, you know,

292
00:14:24,840 --> 00:14:28,050
the application from
Java, from .net to Python

293
00:14:28,050 --> 00:14:33,050
and even your custom application
based on your enterprise

294
00:14:33,060 --> 00:14:36,270
code pattern and the design
patterns architectural pattern

295
00:14:36,270 --> 00:14:38,400
it can adopt and then it can

296
00:14:38,400 --> 00:14:40,620
accordingly perform the
transformation, right?

297
00:14:40,620 --> 00:14:43,470
And we are going to focus
on the window modernization

298
00:14:43,470 --> 00:14:45,120
capability as part of this session

299
00:14:45,120 --> 00:14:48,240
because our Unicorn store
application is a .net based

300
00:14:48,240 --> 00:14:49,383
model application.

301
00:14:51,690 --> 00:14:56,040
Now with that, let's
look into the first phase

302
00:14:56,040 --> 00:14:59,490
of that modernization
workflow, where we want

303
00:14:59,490 --> 00:15:04,080
to perform the application
analysis of the given application

304
00:15:04,080 --> 00:15:07,440
and how AI can help us to
that to that effectively.

305
00:15:07,440 --> 00:15:09,123
So, Sree.

306
00:15:12,480 --> 00:15:14,340
- Alright thank you, Anand.

307
00:15:14,340 --> 00:15:17,397
So Anand has taken you
through the different,

308
00:15:17,397 --> 00:15:20,127
the seven phase approach that
we are gonna talk about today

309
00:15:20,127 --> 00:15:23,010
as well as the Unicorn e-commerce

310
00:15:23,010 --> 00:15:24,480
application as well, right?

311
00:15:24,480 --> 00:15:29,220
So the next step for us
is to use Kiro to actually

312
00:15:29,220 --> 00:15:31,140
look at the Unicorn application itself

313
00:15:31,140 --> 00:15:34,161
and understand its current
architecture, right?

314
00:15:34,161 --> 00:15:37,170
So in the next video
that you're gonna see,

315
00:15:37,170 --> 00:15:41,725
we will open the Unicorn
apps code base in Kiro.

316
00:15:41,725 --> 00:15:45,338
Then we'll using the natural
language query we will ask Kiro

317
00:15:45,338 --> 00:15:47,880
what is the framework
used in the application?

318
00:15:47,880 --> 00:15:49,320
What are the current technical

319
00:15:49,320 --> 00:15:51,300
and business challenges
the application has?

320
00:15:51,300 --> 00:15:54,528
And also explain the architecture
of the application, right?

321
00:15:54,528 --> 00:15:56,760
Once that is done, we will use

322
00:15:56,760 --> 00:15:58,920
that insights which Kiro has given us

323
00:15:58,920 --> 00:16:00,782
to develop a comprehensive modernization

324
00:16:00,782 --> 00:16:03,000
strategy for this application.

325
00:16:03,000 --> 00:16:06,610
Including, you know, short
term quick wins, medium term

326
00:16:07,890 --> 00:16:09,420
service decomposition, as well

327
00:16:09,420 --> 00:16:11,580
as long term architectural transformation.

328
00:16:11,580 --> 00:16:14,970
So the idea is after this
demo, you should be able

329
00:16:14,970 --> 00:16:18,935
to use this methodical approach
within your own applications

330
00:16:18,935 --> 00:16:23,935
and break down those into
manageable scalable services.

331
00:16:24,390 --> 00:16:26,013
So let's go into the demo now.

332
00:16:28,680 --> 00:16:30,990
Alright, so this is the Kiro interface.

333
00:16:30,990 --> 00:16:32,790
You can see the explorer window as well

334
00:16:32,790 --> 00:16:35,340
as the chat window on the right side.

335
00:16:35,340 --> 00:16:38,130
So I'm gonna ask Kiro
to analyze my code base,

336
00:16:38,130 --> 00:16:39,960
determine the .net version used

337
00:16:39,960 --> 00:16:43,200
and explain what are the business
and technical challenges.

338
00:16:43,200 --> 00:16:46,410
So Kiro is thinking going
through the code base.

339
00:16:46,410 --> 00:16:47,820
So it's trying to understand

340
00:16:47,820 --> 00:16:49,110
what is the current version used.

341
00:16:49,110 --> 00:16:51,210
So it says it's .net 3.0.

342
00:16:51,210 --> 00:16:54,570
What is the recommended target?.net eight

343
00:16:54,570 --> 00:16:57,600
because .net 3.0 has
already gone end of life

344
00:16:57,600 --> 00:16:58,890
a few years ago.

345
00:16:58,890 --> 00:17:00,810
Current architecture is a classic monolith

346
00:17:00,810 --> 00:17:02,370
entire application.

347
00:17:02,370 --> 00:17:05,760
It also recommends the key business

348
00:17:05,760 --> 00:17:10,020
and technical challenges
including cloud native limitation.

349
00:17:10,020 --> 00:17:12,600
It highlights the shared
data management issue

350
00:17:12,600 --> 00:17:15,120
because it's using a shared
database across multiple

351
00:17:15,120 --> 00:17:18,630
services, monolith API,
which makes it difficult

352
00:17:18,630 --> 00:17:21,720
to expand their different
business capabilities.

353
00:17:21,720 --> 00:17:23,340
What is the immediate recommendation?

354
00:17:23,340 --> 00:17:26,130
Upgrade to .net eight

355
00:17:26,130 --> 00:17:28,680
short term extract the bounded context,

356
00:17:28,680 --> 00:17:30,480
which we will explain about it later

357
00:17:30,480 --> 00:17:32,645
and medium term go into a complete

358
00:17:32,645 --> 00:17:34,920
microservices architecture.

359
00:17:34,920 --> 00:17:37,500
Yeah, so Kiro has analyzed
the code base and then

360
00:17:37,500 --> 00:17:40,233
provided us with the recommendations.

361
00:17:42,450 --> 00:17:43,710
So next step.

362
00:17:43,710 --> 00:17:48,710
So we have seen that it's using
.net 3.5 framework, right?

363
00:17:48,930 --> 00:17:51,330
And then it's recommending
to upgrade to .net eight.

364
00:17:51,330 --> 00:17:54,804
So the service that we are
gonna use is AWS transform

365
00:17:54,804 --> 00:17:59,070
to upgrade the code base to .net eight.

366
00:17:59,070 --> 00:18:00,882
So what is AWS transform?

367
00:18:00,882 --> 00:18:03,180
Anand briefed you on what it is,

368
00:18:03,180 --> 00:18:07,170
but it is the agent AI
powered service developed

369
00:18:07,170 --> 00:18:09,270
to accelerate enterprise modernization

370
00:18:09,270 --> 00:18:13,770
of .net, VMware Windows
mainframe and more.

371
00:18:13,770 --> 00:18:17,550
So it's based on 19 years of
AWS experience in migration

372
00:18:17,550 --> 00:18:20,880
and modernization using AI agents

373
00:18:20,880 --> 00:18:25,140
to automate complex tasks like
code analysis, assessment,

374
00:18:25,140 --> 00:18:29,010
refactoring, decomposition,
dependency mapping, validation,

375
00:18:29,010 --> 00:18:32,970
as well as transformation
plan for your applications.

376
00:18:32,970 --> 00:18:36,289
So in this particular demo
we will be using the AWS

377
00:18:36,289 --> 00:18:38,723
transform for .net capability

378
00:18:38,723 --> 00:18:40,380
and then there are two ways

379
00:18:40,380 --> 00:18:43,470
that you can use the AWS
transform for .net service,

380
00:18:43,470 --> 00:18:46,830
either using the web
experience or web interface

381
00:18:46,830 --> 00:18:50,910
or using the visual studio
AWS toolkit extension.

382
00:18:50,910 --> 00:18:53,610
So in this demo we'll be
using the visual studio

383
00:18:53,610 --> 00:18:55,260
toolkit extension.

384
00:18:55,260 --> 00:19:00,000
So let's see the demo,
how AWS transform does it.

385
00:19:00,000 --> 00:19:03,120
Before going that, also
want to expand on how

386
00:19:03,120 --> 00:19:05,980
the AWS transform for .net

387
00:19:08,070 --> 00:19:10,320
follows through the three
critical stages, right?

388
00:19:10,320 --> 00:19:12,420
So the first step is the analysis phase.

389
00:19:12,420 --> 00:19:15,420
So basically what it does
is it looks at the existing

390
00:19:15,420 --> 00:19:17,700
Windows dependent application,

391
00:19:17,700 --> 00:19:20,760
identify the components
which needs to be modified

392
00:19:20,760 --> 00:19:22,500
for Linux compatibility.

393
00:19:22,500 --> 00:19:25,470
Next it does goes through the
transformation phase, right?

394
00:19:25,470 --> 00:19:28,110
Where the agents, the
AI agents will convert

395
00:19:28,110 --> 00:19:32,550
the applications into
.net eight applications.

396
00:19:32,550 --> 00:19:35,460
This is where AWS transform
does the heavy lifting.

397
00:19:35,460 --> 00:19:39,360
So it basically handles the
framework upgrade as well

398
00:19:39,360 --> 00:19:42,236
as platform specific code
changes that is required

399
00:19:42,236 --> 00:19:46,560
for the application to run on
Linux, which is .net eight.

400
00:19:46,560 --> 00:19:48,660
So finally it does a validation.

401
00:19:48,660 --> 00:19:51,570
So it ensures that the
transform application functions

402
00:19:51,570 --> 00:19:54,420
correctly before the deployment,
which is key to make sure

403
00:19:54,420 --> 00:19:58,290
that the migration and
modernization is successful.

404
00:19:58,290 --> 00:20:01,304
So how it does this key tasks.

405
00:20:01,304 --> 00:20:04,740
So first is it upgrades
the language version.

406
00:20:04,740 --> 00:20:09,740
So if it finds a outdated
C# code in your application,

407
00:20:11,010 --> 00:20:12,840
what it does is it replaces it with

408
00:20:12,840 --> 00:20:14,916
Linux-compatible C# code.

409
00:20:14,916 --> 00:20:18,420
Next it does upgrade the packages from

410
00:20:18,420 --> 00:20:20,880
a Windows dependent .net framework

411
00:20:20,880 --> 00:20:25,080
to a more Linux compatible, more .net,

412
00:20:25,080 --> 00:20:26,790
which is compatible with Linux.

413
00:20:26,790 --> 00:20:30,960
And third, it rewrites the
code for Linux compatibility.

414
00:20:30,960 --> 00:20:34,200
And finally for open-ended tasks

415
00:20:34,200 --> 00:20:36,450
where you require human intervention,

416
00:20:36,450 --> 00:20:39,330
where the transform is not
able to make the changes,

417
00:20:39,330 --> 00:20:42,180
it provide you a detailed
report of what are the changes

418
00:20:42,180 --> 00:20:46,950
that you need to make so that
you can get the application

419
00:20:46,950 --> 00:20:50,370
build and successfully
run on Linux, right?

420
00:20:50,370 --> 00:20:53,490
So like Anand was explaining earlier,

421
00:20:53,490 --> 00:20:55,650
by modernizing your .net applications,

422
00:20:55,650 --> 00:20:57,924
you can break free from
the Windows dependencies,

423
00:20:57,924 --> 00:21:01,108
reduce cost, and gain
the flexibility of the

424
00:21:01,108 --> 00:21:02,940
Linux environments.

425
00:21:02,940 --> 00:21:05,730
So next, let's see the demo.

426
00:21:05,730 --> 00:21:07,840
So you can see that we have opened up

427
00:21:09,027 --> 00:21:11,427
the Unicorn store in the GitHub

428
00:21:11,427 --> 00:21:16,427
and then now we are gonna
open the Visual Studio code

429
00:21:16,650 --> 00:21:18,480
and then go to the AWS toolkit.

430
00:21:18,480 --> 00:21:20,820
So you need to make sure
that the AWS transform is

431
00:21:20,820 --> 00:21:24,450
connected, authenticated using IAM.

432
00:21:24,450 --> 00:21:28,074
So we have the project opened
on the right side window.

433
00:21:28,074 --> 00:21:31,830
Now we right click on
the, on the project itself

434
00:21:31,830 --> 00:21:34,902
and then go to port solution
with AWS transform option.

435
00:21:34,902 --> 00:21:38,670
So here it shows the target versions.

436
00:21:38,670 --> 00:21:42,570
So you can see .net eight
and .net 10 are available.

437
00:21:42,570 --> 00:21:43,830
So you click on start.

438
00:21:43,830 --> 00:21:47,490
So it opens the AWS
transform hub, which is used

439
00:21:47,490 --> 00:21:51,000
to track the the entire
transformation plan.

440
00:21:51,000 --> 00:21:51,900
So it shows the plan.

441
00:21:51,900 --> 00:21:53,910
So you can either customize the plan

442
00:21:53,910 --> 00:21:57,060
which it provides, or you
can also use the default plan

443
00:21:57,060 --> 00:21:58,980
that transform provides, right?

444
00:21:58,980 --> 00:22:02,040
So customization, you can add more steps.

445
00:22:02,040 --> 00:22:03,840
So it's going through
the transformation plan.

446
00:22:03,840 --> 00:22:06,090
So essentially it tries
to build the application,

447
00:22:06,090 --> 00:22:08,218
make sure all the
dependencies are available,

448
00:22:08,218 --> 00:22:10,740
and then it completes a transformation.

449
00:22:10,740 --> 00:22:12,000
So you can see on the top

450
00:22:12,000 --> 00:22:14,340
that the transformation
has been completed.

451
00:22:14,340 --> 00:22:18,454
Now, you can download the
detailed transformation report.

452
00:22:18,454 --> 00:22:21,340
So in the transformation
report you can see

453
00:22:22,334 --> 00:22:24,210
the packages, it has updated the APIs

454
00:22:24,210 --> 00:22:27,210
it has changed whether it
is a partially successful

455
00:22:27,210 --> 00:22:29,880
transformation or a fully
successful transformation.

456
00:22:29,880 --> 00:22:34,020
In partially successful
transformations, you can go down

457
00:22:34,020 --> 00:22:35,340
and see the project summary

458
00:22:35,340 --> 00:22:38,820
to see are there any build
errors, what are the packages

459
00:22:38,820 --> 00:22:41,040
that are updated?

460
00:22:41,040 --> 00:22:43,294
So you can see the files
that has been changed

461
00:22:43,294 --> 00:22:46,260
to make sure it is Linux compatible.

462
00:22:46,260 --> 00:22:49,170
You can use a diff view of
the files so you can see

463
00:22:49,170 --> 00:22:51,060
what was there and what has been changed.

464
00:22:51,060 --> 00:22:53,760
So you can view that option as well.

465
00:22:53,760 --> 00:22:56,850
And then again, you can
go to the Linux readiness.

466
00:22:56,850 --> 00:23:00,510
So it provides a detailed
report on the Linux readiness.

467
00:23:00,510 --> 00:23:03,180
Again, what are the
current framework stack

468
00:23:03,180 --> 00:23:04,502
that is being used?

469
00:23:04,502 --> 00:23:06,630
You can download the next steps.

470
00:23:06,630 --> 00:23:10,375
So that'll actually tell you
what are the critical errors

471
00:23:10,375 --> 00:23:14,070
that you need to resolve to
make sure this application

472
00:23:14,070 --> 00:23:16,921
is ready to run on Linux.

473
00:23:16,921 --> 00:23:19,173
You can go through validate the steps

474
00:23:19,173 --> 00:23:20,910
to make sure you execute it.

475
00:23:20,910 --> 00:23:22,710
So it provides all the
commands, the changes

476
00:23:22,710 --> 00:23:26,520
that is required before you can do it.

477
00:23:26,520 --> 00:23:28,996
Then you can view the
diffs on all the files

478
00:23:28,996 --> 00:23:31,710
and then you can select all

479
00:23:31,710 --> 00:23:35,520
and you can do an apply changes
which will do an in place

480
00:23:35,520 --> 00:23:37,142
change of all the files.

481
00:23:37,142 --> 00:23:40,590
And then now the
application is, you can see

482
00:23:40,590 --> 00:23:43,020
that it's already on .net eight, right?

483
00:23:43,020 --> 00:23:46,902
So it has been now upgraded
to .net eight version, which

484
00:23:46,902 --> 00:23:49,263
is Linux compatible.

485
00:23:50,460 --> 00:23:52,890
Now it has been built, sorry,

486
00:23:52,890 --> 00:23:54,930
it has been upgraded to .net eight.

487
00:23:54,930 --> 00:23:55,950
Now we need to make sure

488
00:23:55,950 --> 00:23:58,357
that this application
runs successfully, right?

489
00:23:58,357 --> 00:24:01,718
So again, I'm gonna use Kiro
to build that application.

490
00:24:01,718 --> 00:24:06,718
So I'll go into Kiro,
I'm gonna prompt Kiro to

491
00:24:07,200 --> 00:24:09,960
ask what is the .net version
that is being currently used.

492
00:24:09,960 --> 00:24:13,710
So it tells me that now
it is .net eight, right?

493
00:24:13,710 --> 00:24:17,100
Which was our target version
that Kiro suggested earlier.

494
00:24:17,100 --> 00:24:18,667
Now I'm gonna ask Kiro

495
00:24:18,667 --> 00:24:21,930
to build the application
and run it locally.

496
00:24:21,930 --> 00:24:25,770
So the Kiro is actually doing
the build, it checks the

497
00:24:25,770 --> 00:24:28,410
dependency, so it checks what
.net version I'm running on

498
00:24:28,410 --> 00:24:29,400
the local computer.

499
00:24:29,400 --> 00:24:31,770
It finds that it's already running nine.

500
00:24:31,770 --> 00:24:36,092
Then it tries to restore all
the, it runs the .net restore

501
00:24:36,092 --> 00:24:39,180
all the dependencies, everything.

502
00:24:39,180 --> 00:24:41,070
It started building the application.

503
00:24:41,070 --> 00:24:43,260
So you can see the build has succeeded.

504
00:24:43,260 --> 00:24:45,570
So it has provided me a URL saying

505
00:24:45,570 --> 00:24:47,640
that it's listening on port 8080.

506
00:24:47,640 --> 00:24:51,600
So I click on the URL, it opens
the .net, the application,

507
00:24:51,600 --> 00:24:52,920
the Unicorn application.

508
00:24:52,920 --> 00:24:56,220
Now I can go in, choose
Unicorns that I want

509
00:24:56,220 --> 00:25:00,210
to purchase from the store
and then click on summit.

510
00:25:00,210 --> 00:25:03,240
So as you can see, this was
the previous application demo

511
00:25:03,240 --> 00:25:05,490
that that Anand has showed.

512
00:25:05,490 --> 00:25:07,620
Right now it is running on .net eight.

513
00:25:07,620 --> 00:25:10,680
But key thing to remember
here is we haven't

514
00:25:10,680 --> 00:25:12,090
decomposed this application.

515
00:25:12,090 --> 00:25:14,520
So it is still running as a monolith app,

516
00:25:14,520 --> 00:25:17,103
but it's version has been
upgraded to .net eight.

517
00:25:18,150 --> 00:25:20,190
Now let me call Anand on stage

518
00:25:20,190 --> 00:25:22,653
to explain on the
decomposition process, right?

519
00:25:24,930 --> 00:25:25,763
- Thanks, Sree.

520
00:25:30,919 --> 00:25:34,232
So what we, so far that
we have application

521
00:25:34,232 --> 00:25:37,815
and now to perform the
analysis, how we can

522
00:25:39,679 --> 00:25:43,623
decompose our Unicorn
store application, right?

523
00:25:46,110 --> 00:25:51,110
So what we have covered
from our seven step process,

524
00:25:51,180 --> 00:25:52,890
the step number one, two, and three,

525
00:25:52,890 --> 00:25:55,410
we have completed, we have
done the application analysis,

526
00:25:55,410 --> 00:25:57,780
we have done the
transformation of the code,

527
00:25:57,780 --> 00:25:59,610
and then we have also validated

528
00:25:59,610 --> 00:26:01,350
that application is successfully working

529
00:26:01,350 --> 00:26:02,820
after the transformation.

530
00:26:02,820 --> 00:26:06,276
Now we need to look upon
the decomposition analysis

531
00:26:06,276 --> 00:26:09,750
to identify the probable right candidate

532
00:26:09,750 --> 00:26:11,760
of the microservices, right?

533
00:26:11,760 --> 00:26:14,827
And trust me folks, this
is the toughest part.

534
00:26:14,827 --> 00:26:19,827
How do we break a monolithic
application into the more

535
00:26:20,190 --> 00:26:24,870
modular decoupled application, right?

536
00:26:24,870 --> 00:26:28,290
So how do we break it?

537
00:26:28,290 --> 00:26:31,140
There are different ways
in which we have observed

538
00:26:31,140 --> 00:26:35,190
the application team, the
application owner, you know, try

539
00:26:35,190 --> 00:26:38,340
to decompose the existing
monolith application into the more

540
00:26:38,340 --> 00:26:40,350
decoupled microservices based architecture

541
00:26:40,350 --> 00:26:43,410
and they fall into a different pitfall.

542
00:26:43,410 --> 00:26:44,810
Now what are those pitfalls?

543
00:26:45,930 --> 00:26:49,200
The very first pitfall is
the distributed monolithic.

544
00:26:49,200 --> 00:26:52,290
Often the time we have seen
the application owners,

545
00:26:52,290 --> 00:26:56,640
they converge to the
distributed monolithic.

546
00:26:56,640 --> 00:26:57,473
How?

547
00:26:57,473 --> 00:27:00,150
Because they try to apply
a horizontal tiering

548
00:27:00,150 --> 00:27:02,610
to the existing monolithic application.

549
00:27:02,610 --> 00:27:03,720
What does it mean?

550
00:27:03,720 --> 00:27:07,800
It means grouping the related
functionally related modules

551
00:27:07,800 --> 00:27:12,390
together, which are similar or
the common component together

552
00:27:12,390 --> 00:27:16,620
and try to carve out a sub modules

553
00:27:16,620 --> 00:27:19,080
or the subgroup out of your
monolithic application.

554
00:27:19,080 --> 00:27:20,130
You have a monolithic application,

555
00:27:20,130 --> 00:27:22,230
you're grouping the
related component together

556
00:27:22,230 --> 00:27:25,590
and what you have is a smaller
submodules coming out from

557
00:27:25,590 --> 00:27:30,330
that application, but still
they are doing multiple thing

558
00:27:30,330 --> 00:27:34,530
or more than one thing and they
are inheriting the property,

559
00:27:34,530 --> 00:27:38,103
the design challenges of
monolithic applications, right?

560
00:27:38,954 --> 00:27:42,570
The other pitfall which we are
seeing the application team

561
00:27:42,570 --> 00:27:44,130
goes into is a nano service.

562
00:27:44,130 --> 00:27:45,420
What does it mean?

563
00:27:45,420 --> 00:27:48,750
It happens due to the vertical
tearing of the application.

564
00:27:48,750 --> 00:27:51,360
Now what the vertical tearing
of the application means?

565
00:27:51,360 --> 00:27:53,010
Let's say you have a UI

566
00:27:53,010 --> 00:27:55,980
and the business capability
driven by those UI pages.

567
00:27:55,980 --> 00:27:58,590
What the application owner
try to do, they try to break

568
00:27:58,590 --> 00:28:01,110
or split the application
functionalities using

569
00:28:01,110 --> 00:28:03,810
the different UI screens what they have.

570
00:28:03,810 --> 00:28:06,840
Now, imagine the situation if
your monolithic application

571
00:28:06,840 --> 00:28:09,180
comprises of the hundreds of UI pages.

572
00:28:09,180 --> 00:28:12,030
Now what could eventually
end up happening?

573
00:28:12,030 --> 00:28:13,920
You are having those many number

574
00:28:13,920 --> 00:28:17,880
of nano services in
your environment, right?

575
00:28:17,880 --> 00:28:21,090
And then it impose lot
of operational challenges

576
00:28:21,090 --> 00:28:24,060
because you need to take
care of hundreds of services

577
00:28:24,060 --> 00:28:26,346
and it also increase the check
in your environment, right?

578
00:28:26,346 --> 00:28:28,186
So these are the common pitfall

579
00:28:28,186 --> 00:28:33,186
and that is where the right granularity

580
00:28:33,494 --> 00:28:36,720
is the key to decompose these existing

581
00:28:36,720 --> 00:28:38,250
monolithic applications.

582
00:28:38,250 --> 00:28:40,440
Another question comes, how do I arrive

583
00:28:40,440 --> 00:28:43,080
to the right granularity, right?

584
00:28:43,080 --> 00:28:47,432
And that is where the key
here is to not only assist

585
00:28:47,432 --> 00:28:51,145
or analyze the existing
monolithic applications from the

586
00:28:51,145 --> 00:28:54,090
implementation, from the
technology perspective,

587
00:28:54,090 --> 00:28:57,450
but also to have the right analysis done

588
00:28:57,450 --> 00:28:59,790
from the business domain perspective

589
00:28:59,790 --> 00:29:03,600
and then combine the
right business analysis

590
00:29:03,600 --> 00:29:07,080
and the technical analysis
together to arrive

591
00:29:07,080 --> 00:29:10,260
to this right granularity, right?

592
00:29:10,260 --> 00:29:11,190
How do we achieve that?

593
00:29:11,190 --> 00:29:13,680
So there are some
architectural methodologies

594
00:29:13,680 --> 00:29:16,770
which we are going to talk
about, which can help us

595
00:29:16,770 --> 00:29:18,570
to arrive to the right granularity.

596
00:29:18,570 --> 00:29:20,820
One of them is the domain-driven design.

597
00:29:20,820 --> 00:29:23,010
First spoke by the Eric Ewan

598
00:29:23,010 --> 00:29:26,730
and what he mentioned that the
technology is not important,

599
00:29:26,730 --> 00:29:29,190
not the primary focus, should
not be the primary focus

600
00:29:29,190 --> 00:29:30,810
for the software development.

601
00:29:30,810 --> 00:29:32,970
Rather the business features

602
00:29:32,970 --> 00:29:36,930
and the capabilities
which we want to perform

603
00:29:36,930 --> 00:29:40,110
through the technology
should be the primary focus.

604
00:29:40,110 --> 00:29:41,640
And what does it mean?

605
00:29:41,640 --> 00:29:45,957
So the domain driven
design help us to arrive

606
00:29:45,957 --> 00:29:49,770
the shared understanding
from the business owners

607
00:29:49,770 --> 00:29:53,019
and the application
owners together so that

608
00:29:53,019 --> 00:29:56,250
we can build the right software,

609
00:29:56,250 --> 00:29:58,080
applying the right granularity

610
00:29:58,080 --> 00:30:00,899
and the right architectural
patterns, right?

611
00:30:00,899 --> 00:30:03,570
This is what the domain
driven design provide us

612
00:30:03,570 --> 00:30:05,340
and how domain driven design works.

613
00:30:05,340 --> 00:30:09,360
Let's look into some of its
some of its key concepts.

614
00:30:09,360 --> 00:30:12,780
So what is domain,

615
00:30:12,780 --> 00:30:15,780
the domain driven design help
us to do a right analysis

616
00:30:15,780 --> 00:30:18,360
of the given application
from the domain perspective

617
00:30:18,360 --> 00:30:20,460
and help us to understand the domain

618
00:30:20,460 --> 00:30:22,440
and its different boundaries.

619
00:30:22,440 --> 00:30:27,150
So domain could be a business
for which we want to work

620
00:30:27,150 --> 00:30:29,250
and provide the services
to our end customer.

621
00:30:29,250 --> 00:30:33,120
In our use case for Unicorn
store, the retail is a domain

622
00:30:33,120 --> 00:30:35,520
because the e-commerce
application running over the web

623
00:30:35,520 --> 00:30:38,580
and providing the different
capabilities to the end user.

624
00:30:38,580 --> 00:30:41,670
Now this retail could have
a different sub-domains.

625
00:30:41,670 --> 00:30:44,340
For example, the order
management module, right?

626
00:30:44,340 --> 00:30:45,840
It's a sub-domain which help us

627
00:30:45,840 --> 00:30:48,939
to manage the overall
orders for our application.

628
00:30:48,939 --> 00:30:51,330
The second could be the
fulfillment once the order are

629
00:30:51,330 --> 00:30:54,514
placed, how the fulfillment
of those orders happen

630
00:30:54,514 --> 00:30:56,640
and the shipment of course, so

631
00:30:56,640 --> 00:30:59,460
that you know these
products which are purchased

632
00:30:59,460 --> 00:31:02,460
by the end users, you know
can be delivered to them.

633
00:31:02,460 --> 00:31:05,490
So these could be a subdomains

634
00:31:05,490 --> 00:31:08,190
for a given domain.

635
00:31:08,190 --> 00:31:13,020
Now, in that this subdomain
further need to be categorized

636
00:31:13,020 --> 00:31:14,790
into the three different categories.

637
00:31:14,790 --> 00:31:16,950
One of them is the core subdomain.

638
00:31:16,950 --> 00:31:18,510
What does the core subdomain means?

639
00:31:18,510 --> 00:31:22,290
The core subdomain means the subdomain,

640
00:31:22,290 --> 00:31:25,260
which is a differentiator for you, right?

641
00:31:25,260 --> 00:31:28,740
Which is what you should
care about to modernize,

642
00:31:28,740 --> 00:31:31,979
which consists of your
business logic, right?

643
00:31:31,979 --> 00:31:34,350
In our case, it is the order management

644
00:31:34,350 --> 00:31:37,050
for fit management and
the shipment management.

645
00:31:37,050 --> 00:31:40,020
The second subdomain type
is a supporting subdomain.

646
00:31:40,020 --> 00:31:43,440
Supporting subdomain are
required for the core domain

647
00:31:43,440 --> 00:31:44,820
to achieve its functionality.

648
00:31:44,820 --> 00:31:47,310
Take an example for a order management,

649
00:31:47,310 --> 00:31:49,140
you might be running some loyalty program

650
00:31:49,140 --> 00:31:51,540
and that might for that the
user information might have

651
00:31:51,540 --> 00:31:54,750
to come from the the CRM system.

652
00:31:54,750 --> 00:31:57,780
So, the supporting subdomains
other domain which sometime

653
00:31:57,780 --> 00:32:00,370
can be built or sometime can be bought

654
00:32:01,620 --> 00:32:04,263
as external software products.

655
00:32:05,670 --> 00:32:07,260
The last is the generic subdomain.

656
00:32:07,260 --> 00:32:10,740
For example, if any user
has to purchase any product,

657
00:32:10,740 --> 00:32:12,960
they need to first authenticate

658
00:32:12,960 --> 00:32:15,840
and have a right access
to the application.

659
00:32:15,840 --> 00:32:18,330
And the genAI subdomain
could be our identity system,

660
00:32:18,330 --> 00:32:22,260
which often be buy bought,
not the build, right?

661
00:32:22,260 --> 00:32:24,300
Because that's not the core domain

662
00:32:24,300 --> 00:32:26,538
for the retail application, right?

663
00:32:26,538 --> 00:32:29,560
So if we just focus on the core subdomain

664
00:32:30,424 --> 00:32:33,420
in the context of our Unicorn application,

665
00:32:33,420 --> 00:32:37,380
the core subdomain will again
have a different context

666
00:32:37,380 --> 00:32:38,640
within it, right?

667
00:32:38,640 --> 00:32:41,850
Which help us to provide the
right business capabilities

668
00:32:41,850 --> 00:32:42,990
around their subdomain.

669
00:32:42,990 --> 00:32:45,540
In case of order subdomain

670
00:32:45,540 --> 00:32:47,610
the order subdomain
have a different context

671
00:32:47,610 --> 00:32:51,060
because order required items,
order requires the end users

672
00:32:51,060 --> 00:32:52,350
who purchase those items

673
00:32:52,350 --> 00:32:53,880
and then the payment which has been,

674
00:32:53,880 --> 00:32:55,770
so there are different context associated

675
00:32:55,770 --> 00:32:57,390
with it within their subdomain.

676
00:32:57,390 --> 00:33:00,960
Same could be in the case
of the fulfillment subdomain

677
00:33:00,960 --> 00:33:01,793
as well.

678
00:33:01,793 --> 00:33:04,320
So this domain domain
design help helping you

679
00:33:04,320 --> 00:33:06,450
to assess the right
analysis of the domain.

680
00:33:06,450 --> 00:33:07,350
It's subdomain.

681
00:33:07,350 --> 00:33:08,670
What is the core subdomain?

682
00:33:08,670 --> 00:33:11,130
And the core subdomain is comprising of

683
00:33:11,130 --> 00:33:13,410
what different context.

684
00:33:13,410 --> 00:33:16,110
And eventually this context will help you

685
00:33:16,110 --> 00:33:19,890
to define the right boundaries
around these subdomain

686
00:33:19,890 --> 00:33:22,470
and those boundaries will
then finally converge into the

687
00:33:22,470 --> 00:33:23,760
right services, right?

688
00:33:23,760 --> 00:33:26,490
And we will see how this happens, right?

689
00:33:26,490 --> 00:33:28,320
But the questions comes, okay,

690
00:33:28,320 --> 00:33:29,670
the domain driven design is good

691
00:33:29,670 --> 00:33:31,890
because it is helping you to come

692
00:33:31,890 --> 00:33:34,890
to the common understanding
between the business owners

693
00:33:34,890 --> 00:33:36,330
and the application owners.

694
00:33:36,330 --> 00:33:39,600
But how should I start
understanding these sub-domains?

695
00:33:39,600 --> 00:33:43,230
How should I start getting
this information about

696
00:33:43,230 --> 00:33:44,520
this different context?

697
00:33:44,520 --> 00:33:47,760
And that is where the Alberto Brandolini,

698
00:33:47,760 --> 00:33:51,097
he's inventor of Event storming,
made a very good quote,

699
00:33:51,097 --> 00:33:54,510
"What become the software
is not the expert knowledge,

700
00:33:54,510 --> 00:33:56,910
but the developer's understanding,"

701
00:33:56,910 --> 00:33:58,440
or sometime the misunderstanding

702
00:33:58,440 --> 00:34:01,350
because the business owners mean

703
00:34:01,350 --> 00:34:02,577
what understanding business owners have.

704
00:34:02,577 --> 00:34:05,460
The application owners may not
have the same understanding.

705
00:34:05,460 --> 00:34:07,710
And that's where we have to bring both

706
00:34:07,710 --> 00:34:09,306
of these parties together

707
00:34:09,306 --> 00:34:12,030
so that they understand the domain

708
00:34:12,030 --> 00:34:14,040
in the shared context, right?

709
00:34:14,040 --> 00:34:17,415
And that is where the Event storming as a

710
00:34:17,415 --> 00:34:21,874
next architecture methodologies
can help to achieve

711
00:34:21,874 --> 00:34:24,450
the business owners and
the application owners

712
00:34:24,450 --> 00:34:26,280
to have their shared
understanding of the domain.

713
00:34:26,280 --> 00:34:27,300
How this happen.

714
00:34:27,300 --> 00:34:30,150
The Event Storming is not
a any architectural tool

715
00:34:30,150 --> 00:34:32,370
or the design pattern,
it's a methodologies,

716
00:34:32,370 --> 00:34:36,510
it's a workshop which happens
between the business owners

717
00:34:36,510 --> 00:34:37,648
and the application owners.

718
00:34:37,648 --> 00:34:40,230
And the intent of the workshop is

719
00:34:40,230 --> 00:34:43,320
to understand the domain via
identifying the different

720
00:34:43,320 --> 00:34:45,990
domain events and identify

721
00:34:45,990 --> 00:34:49,620
that these domain events
producers and consumers.

722
00:34:49,620 --> 00:34:51,600
And once we identify that,

723
00:34:51,600 --> 00:34:54,550
then we can identify the different

724
00:34:55,440 --> 00:34:58,560
bounded contexts associated
with those subdomains

725
00:34:58,560 --> 00:35:01,020
and then those bounded
contexts eventually become the

726
00:35:01,020 --> 00:35:03,210
blueprint for the different services.

727
00:35:03,210 --> 00:35:06,240
So how this event is storming happen,

728
00:35:06,240 --> 00:35:09,510
even the storming has a different elements

729
00:35:09,510 --> 00:35:11,357
and the intent of the workshop is

730
00:35:11,357 --> 00:35:14,515
the event storm exercise
to identify these six

731
00:35:14,515 --> 00:35:17,580
or seven elements which are
represented by, represented

732
00:35:17,580 --> 00:35:20,100
by the different multicolor sticky notes.

733
00:35:20,100 --> 00:35:22,830
So how this happen, the first sticky note

734
00:35:22,830 --> 00:35:24,660
or the first element is the domain event.

735
00:35:24,660 --> 00:35:27,640
We identify what are the
different domain event are part of

736
00:35:28,800 --> 00:35:32,233
the given domain special
in our case, for example,

737
00:35:32,233 --> 00:35:35,430
order created, order canceled

738
00:35:35,430 --> 00:35:38,490
or order placed are these
different type of event.

739
00:35:38,490 --> 00:35:40,830
Events are always
represented in the past tense

740
00:35:40,830 --> 00:35:44,340
means something has happened
in your business context.

741
00:35:44,340 --> 00:35:47,340
The second key element to
identify under the event storm

742
00:35:47,340 --> 00:35:48,870
exercises, the command,

743
00:35:48,870 --> 00:35:51,240
like what commands generated this event.

744
00:35:51,240 --> 00:35:53,760
For example, somebody would've
placed a command, okay,

745
00:35:53,760 --> 00:35:55,710
place order or cancel my order.

746
00:35:55,710 --> 00:35:58,290
So these commands are eventually
generating those events.

747
00:35:58,290 --> 00:36:01,080
The third thing to
identify who are the actors

748
00:36:01,080 --> 00:36:02,880
who are actually issuing those command.

749
00:36:02,880 --> 00:36:05,637
In our Unicorn store
use case, I'm the user,

750
00:36:05,637 --> 00:36:07,080
I'm logging to the application

751
00:36:07,080 --> 00:36:09,420
and I'm placing those commands.

752
00:36:09,420 --> 00:36:10,830
It could be the machine as well,

753
00:36:10,830 --> 00:36:13,020
it could be business processes
as well who can become

754
00:36:13,020 --> 00:36:15,570
as an actor who are issuing
the different commands.

755
00:36:15,570 --> 00:36:18,690
The fourth key element is aggregate.

756
00:36:18,690 --> 00:36:21,900
Aggregate is something who
actually understand these command

757
00:36:21,900 --> 00:36:25,143
and execute certain business
logic to fulfill those command.

758
00:36:26,190 --> 00:36:28,140
The next one is the business policies.

759
00:36:28,140 --> 00:36:29,760
So as part of the event storming,

760
00:36:29,760 --> 00:36:31,564
we identify the different
business policies.

761
00:36:31,564 --> 00:36:35,160
And the business policies
could be like when somebody is

762
00:36:35,160 --> 00:36:38,204
placing the order, whether the
inventory has been validated,

763
00:36:38,204 --> 00:36:40,770
whether the payment is
successfully done or not,

764
00:36:40,770 --> 00:36:42,540
before even placing
the order successfully.

765
00:36:42,540 --> 00:36:44,400
So these are the business validation rule

766
00:36:44,400 --> 00:36:47,280
which will apply for the
different business flows.

767
00:36:47,280 --> 00:36:48,960
The next is the external system.

768
00:36:48,960 --> 00:36:51,300
For example, if I'm
placing the order, I need

769
00:36:51,300 --> 00:36:52,500
to perform a payment first

770
00:36:52,500 --> 00:36:54,330
and for payment I might be leveraging

771
00:36:54,330 --> 00:36:55,380
the external payment gateway.

772
00:36:55,380 --> 00:36:58,140
So what are the external
component which are involved in my

773
00:36:58,140 --> 00:36:59,790
business processes, right?

774
00:36:59,790 --> 00:37:03,238
And last but not the least, the view

775
00:37:03,238 --> 00:37:06,390
which is represented in form
of let's say a UI screen

776
00:37:06,390 --> 00:37:09,439
where the user can then
understand the current state

777
00:37:09,439 --> 00:37:12,240
of the application or
the business and then

778
00:37:12,240 --> 00:37:14,160
accordingly take the action like

779
00:37:14,160 --> 00:37:16,891
or understand, okay, whether
my order is placed by

780
00:37:16,891 --> 00:37:19,290
whether my order order is
shipped or it has been canceled.

781
00:37:19,290 --> 00:37:20,880
It could be anything for that matter.

782
00:37:20,880 --> 00:37:23,922
And if we identify all these elements,

783
00:37:23,922 --> 00:37:28,922
then we arrive to the domain event driven

784
00:37:28,950 --> 00:37:30,450
decomposition approach.

785
00:37:30,450 --> 00:37:33,540
So it's a domain events who
drive the decomposition.

786
00:37:33,540 --> 00:37:36,030
So the applying the domain
driven design principle along

787
00:37:36,030 --> 00:37:38,280
with the event storming can help us

788
00:37:38,280 --> 00:37:40,590
to identify the
microservices-based architecture.

789
00:37:40,590 --> 00:37:41,550
How this happened.

790
00:37:41,550 --> 00:37:45,649
We perform the domain analysis,
we apply the event storming

791
00:37:45,649 --> 00:37:48,120
to further advance the domain analysis

792
00:37:48,120 --> 00:37:50,940
with more bounded context
specific information,

793
00:37:50,940 --> 00:37:52,890
identify the right bounded context,

794
00:37:52,890 --> 00:37:55,800
and then from there converse
to the right microservice.

795
00:37:55,800 --> 00:37:59,370
If I take example of the order
management, how the outcome

796
00:37:59,370 --> 00:38:01,660
of the event is storming for the order

797
00:38:02,850 --> 00:38:05,130
processing use case might look like.

798
00:38:05,130 --> 00:38:09,660
So I'm actor as a user who is performing

799
00:38:09,660 --> 00:38:11,536
a command saying that place order.

800
00:38:11,536 --> 00:38:15,956
That command produce a domain
event like order is created.

801
00:38:15,956 --> 00:38:18,960
And when when this event is created,

802
00:38:18,960 --> 00:38:20,670
there are some business
policies which are getting

803
00:38:20,670 --> 00:38:23,730
validated, like validated
the inventory, right?

804
00:38:23,730 --> 00:38:25,080
And based on the inventory only you

805
00:38:25,080 --> 00:38:26,670
successfully place the order.

806
00:38:26,670 --> 00:38:27,960
And once that is done,

807
00:38:27,960 --> 00:38:30,240
then it could again
issue a separate commands

808
00:38:30,240 --> 00:38:32,430
and there could be external systems

809
00:38:32,430 --> 00:38:35,370
and like a payment gateway, right?

810
00:38:35,370 --> 00:38:37,560
They can also produce the events like

811
00:38:37,560 --> 00:38:38,860
the payment is successful.

812
00:38:39,960 --> 00:38:44,910
Now, once we do this
event storming analysis,

813
00:38:44,910 --> 00:38:47,550
do identification of these
different sticky notes

814
00:38:47,550 --> 00:38:48,990
and different domain event,

815
00:38:48,990 --> 00:38:53,580
and then what we do, we try
to group the relevant related

816
00:38:53,580 --> 00:38:56,697
domain even together and then converge to

817
00:38:56,697 --> 00:38:58,740
the right bounded context

818
00:38:58,740 --> 00:39:01,830
and that right bounded context
then represent the different

819
00:39:01,830 --> 00:39:03,210
domain services for us.

820
00:39:03,210 --> 00:39:05,880
So in this example, for the
order processing use case,

821
00:39:05,880 --> 00:39:09,030
what we saw the the entire
event is streaming analysis

822
00:39:09,030 --> 00:39:10,947
help us to identify what are some of

823
00:39:10,947 --> 00:39:13,320
the application capabilities in terms of

824
00:39:13,320 --> 00:39:16,440
what command it could support
the order management flow,

825
00:39:16,440 --> 00:39:18,420
what are some of its external system

826
00:39:18,420 --> 00:39:20,730
to which it depend upon like payment

827
00:39:20,730 --> 00:39:24,104
and what are its own
repository means the data which

828
00:39:24,104 --> 00:39:27,300
or the current state which
it need to maintain in terms

829
00:39:27,300 --> 00:39:29,070
of the order lifecycle.

830
00:39:29,070 --> 00:39:31,980
So this is how we can actually perform

831
00:39:31,980 --> 00:39:35,700
the right decomposition for a
given monolithic application

832
00:39:35,700 --> 00:39:37,470
with the right granularity.

833
00:39:37,470 --> 00:39:39,810
And now let's see how Jenny, I can help us

834
00:39:39,810 --> 00:39:42,930
to accelerate this entire event storming

835
00:39:42,930 --> 00:39:45,000
and the domain driven
design based analysis

836
00:39:45,000 --> 00:39:46,560
for our given application.

837
00:39:46,560 --> 00:39:49,170
So we again leverage the Kiro here.

838
00:39:49,170 --> 00:39:52,320
We have already done the transformation of

839
00:39:52,320 --> 00:39:56,790
our uni store application
to the .net eight.

840
00:39:56,790 --> 00:39:59,280
Now what we use, we ask Kiro

841
00:39:59,280 --> 00:40:01,800
to perform the event
storming analysis for us.

842
00:40:01,800 --> 00:40:03,630
So we provide a prompt.

843
00:40:03,630 --> 00:40:07,830
In the prompt we tell Kiro do
the event storming analysis

844
00:40:07,830 --> 00:40:10,500
and identify all these seven element

845
00:40:10,500 --> 00:40:13,980
of event storming from
the events to the commands

846
00:40:13,980 --> 00:40:16,750
to the actor external
system business policies

847
00:40:19,554 --> 00:40:21,120
and the aggregates.

848
00:40:21,120 --> 00:40:24,540
And the Kiro then introspect
the entire application code

849
00:40:24,540 --> 00:40:28,830
base and it tries to identify all these

850
00:40:28,830 --> 00:40:31,320
event storming elements

851
00:40:31,320 --> 00:40:35,220
and then try to map what
could be the, you know,

852
00:40:35,220 --> 00:40:39,400
the probable bounded context
which can be faced using

853
00:40:40,860 --> 00:40:43,590
this event storming analysis, right?

854
00:40:43,590 --> 00:40:45,660
So currently Kiro is
performing that analysis

855
00:40:45,660 --> 00:40:48,030
and it has done its analysis

856
00:40:48,030 --> 00:40:49,380
and now we can see

857
00:40:49,380 --> 00:40:52,830
what are the different
domain event which has been

858
00:40:52,830 --> 00:40:57,830
identified by Kiro for
a given application.

859
00:40:58,290 --> 00:41:00,330
So if we highlight on that, can we see

860
00:41:00,330 --> 00:41:03,750
for example the order
management event, order created,

861
00:41:03,750 --> 00:41:05,580
order completed, order failed,

862
00:41:05,580 --> 00:41:07,710
or the even the payment process, right?

863
00:41:07,710 --> 00:41:08,820
In case of shopping cart.

864
00:41:08,820 --> 00:41:10,710
Also, there are different
type of domain events

865
00:41:10,710 --> 00:41:12,540
which has been identified.

866
00:41:12,540 --> 00:41:15,480
Now the intent here is not

867
00:41:15,480 --> 00:41:17,760
to do a complete event storming

868
00:41:17,760 --> 00:41:20,700
and domain event analysis
based on the journey I,

869
00:41:20,700 --> 00:41:24,240
but this information
certainly become the base

870
00:41:24,240 --> 00:41:26,340
on which further the business owner

871
00:41:26,340 --> 00:41:29,040
and the application owners
can do their own assessment

872
00:41:29,040 --> 00:41:30,780
and refine it further.

873
00:41:30,780 --> 00:41:33,240
And we are seeing that not
only the domain events,

874
00:41:33,240 --> 00:41:34,680
the different commands

875
00:41:34,680 --> 00:41:39,043
and different aggregates, all
of those has been identified

876
00:41:39,043 --> 00:41:44,043
by Kiro for a given
monolithic application, right?

877
00:41:44,310 --> 00:41:46,337
Unicorn story in our case, right?

878
00:41:52,710 --> 00:41:55,320
So not only it's just
identifying the domain event,

879
00:41:55,320 --> 00:41:57,540
it is going one step beyond

880
00:41:57,540 --> 00:42:02,490
and then it is also giving us
those probable bounded context

881
00:42:02,490 --> 00:42:06,581
and also highlighting the
probable microservices,

882
00:42:06,581 --> 00:42:10,050
which could be carve out
from this given legacy

883
00:42:10,050 --> 00:42:11,430
monolithic application.

884
00:42:11,430 --> 00:42:14,310
So, this is important, folks,

885
00:42:14,310 --> 00:42:17,652
because this recommendation
is now not just coming

886
00:42:17,652 --> 00:42:19,470
from those horizontal tearing

887
00:42:19,470 --> 00:42:22,360
or the vertical tearing,
which we saw it is coming from

888
00:42:23,310 --> 00:42:25,650
the architectural methodologies
like domain driven

889
00:42:25,650 --> 00:42:27,840
design and even storming,
which has been applied

890
00:42:27,840 --> 00:42:29,460
and working backward from there,

891
00:42:29,460 --> 00:42:31,500
what could be the
probable boundary context

892
00:42:31,500 --> 00:42:33,783
and the respective microservices?

893
00:42:36,510 --> 00:42:38,820
Now we have done this analysis.

894
00:42:38,820 --> 00:42:42,310
The next thing is, as I
mentioned, to actually perform

895
00:42:43,230 --> 00:42:46,050
this event is coming
where the outcome of this

896
00:42:46,050 --> 00:42:49,560
Kiro become the base
for the business owner

897
00:42:49,560 --> 00:42:50,790
and application owner.

898
00:42:50,790 --> 00:42:54,630
And they can go into the
shared work workshop mode

899
00:42:54,630 --> 00:42:58,410
to further optimize this analysis

900
00:42:58,410 --> 00:43:01,590
and then modify it according
to their business understanding

901
00:43:01,590 --> 00:43:03,270
and the implementation understanding.

902
00:43:03,270 --> 00:43:06,330
And this even storming
workshop can happen in person

903
00:43:06,330 --> 00:43:07,470
or it can happen virtually.

904
00:43:07,470 --> 00:43:10,560
We are taking a use case where
it has to happen virtually.

905
00:43:10,560 --> 00:43:13,770
There are some platforms
which provides the virtual

906
00:43:13,770 --> 00:43:15,000
event storming board.

907
00:43:15,000 --> 00:43:16,740
One of such platform is Miro.

908
00:43:16,740 --> 00:43:20,820
So Miro help us to do a
virtual event storming exercise

909
00:43:20,820 --> 00:43:23,100
via providing the virtual
event storming board

910
00:43:23,100 --> 00:43:25,170
and IT support these
different sticky notes,

911
00:43:25,170 --> 00:43:26,310
what we talked about.

912
00:43:26,310 --> 00:43:29,040
So for that, what are the
prerequisite as a developer,

913
00:43:29,040 --> 00:43:30,810
you can create a developer account,

914
00:43:30,810 --> 00:43:32,610
the API keys are generated,

915
00:43:32,610 --> 00:43:35,313
and using those API keys,
you can then, you know,

916
00:43:36,180 --> 00:43:39,660
programmatically generate the
different even storming board.

917
00:43:39,660 --> 00:43:42,030
And exactly the same thing we want to do.

918
00:43:42,030 --> 00:43:44,280
And again, we are leveraging
the genAI capability

919
00:43:44,280 --> 00:43:45,390
to perform the same.

920
00:43:45,390 --> 00:43:48,700
So what we are asking
Kiro, okay, based on this

921
00:43:48,700 --> 00:43:52,623
event storming analysis,
which has been done,

922
00:43:54,180 --> 00:43:57,960
generate a script, which then can

923
00:43:57,960 --> 00:44:01,650
create a mirror board for us

924
00:44:01,650 --> 00:44:04,830
and apply all this understanding

925
00:44:04,830 --> 00:44:07,690
what we have got via
event installing analysis

926
00:44:08,658 --> 00:44:10,800
on this Unicorn store application.

927
00:44:10,800 --> 00:44:13,230
So Kiro goes ahead

928
00:44:13,230 --> 00:44:17,073
and actually generate the script, right?

929
00:44:17,073 --> 00:44:22,030
And with that script,
it is going to generate

930
00:44:23,010 --> 00:44:27,240
a virtual event storming
board for all of us.

931
00:44:27,240 --> 00:44:31,290
And the intent would be then
we use that virtual board

932
00:44:31,290 --> 00:44:33,090
and then the product owner

933
00:44:33,090 --> 00:44:36,240
and the application owner can
do their further brainstorming

934
00:44:36,240 --> 00:44:39,450
and optimize or refine the
different service boundaries

935
00:44:39,450 --> 00:44:41,973
and the bounded context
accordingly, right?

936
00:44:44,040 --> 00:44:47,761
So it has done the, it has
created the board successfully.

937
00:44:47,761 --> 00:44:50,550
And then we will quickly see how

938
00:44:50,550 --> 00:44:54,243
that board looks like with
a different bounded context.

939
00:44:56,130 --> 00:44:59,070
So it takes us to the Miro platform

940
00:44:59,070 --> 00:45:02,670
and then we open the Miro board.

941
00:45:02,670 --> 00:45:06,067
And if we can see, this is how

942
00:45:06,067 --> 00:45:09,870
all the different domain events,
it's associated commands,

943
00:45:09,870 --> 00:45:14,870
it's associated the business
policies, external systems,

944
00:45:15,030 --> 00:45:16,980
how they have been grouped together

945
00:45:16,980 --> 00:45:18,270
in the different context.

946
00:45:18,270 --> 00:45:19,440
We are just taking example

947
00:45:19,440 --> 00:45:21,630
of zooming into the
order management domain.

948
00:45:21,630 --> 00:45:24,000
If we see how the bounded context

949
00:45:24,000 --> 00:45:26,490
for the order management has been built,

950
00:45:26,490 --> 00:45:28,470
right via genAI capabilities to

951
00:45:28,470 --> 00:45:30,000
after performing the event storming

952
00:45:30,000 --> 00:45:31,830
and domain driven design based analysis.

953
00:45:31,830 --> 00:45:36,615
So we have all the different
events from the order

954
00:45:36,615 --> 00:45:38,970
processing flow in place.

955
00:45:38,970 --> 00:45:40,980
We have all this respective commands,

956
00:45:40,980 --> 00:45:43,140
we have all this
respective external system

957
00:45:43,140 --> 00:45:45,990
and the other element part of it.

958
00:45:45,990 --> 00:45:50,640
Now this become the blueprint
for us to then build

959
00:45:50,640 --> 00:45:55,640
the right microservices
with the right boundaries

960
00:45:55,650 --> 00:45:57,810
and the granularity.

961
00:45:57,810 --> 00:46:02,810
Now, for us, the next phase
is to see now based on this

962
00:46:02,970 --> 00:46:05,700
these bounded context,
what we have generated,

963
00:46:05,700 --> 00:46:08,310
how we can then refine the architecture

964
00:46:08,310 --> 00:46:10,590
for our monolithic application

965
00:46:10,590 --> 00:46:14,370
and then build these new
microservices, which we have seen

966
00:46:14,370 --> 00:46:18,120
as part of the event
storming outcome in form

967
00:46:18,120 --> 00:46:19,440
of those different bounded contexts.

968
00:46:19,440 --> 00:46:21,603
So for that I call Sree. Sree over to you.

969
00:46:23,520 --> 00:46:26,730
- I also want to explain what the MCP is.

970
00:46:26,730 --> 00:46:29,970
So MCP is an open source
protocol that standardizes

971
00:46:29,970 --> 00:46:33,330
how application talks to
large language models,

972
00:46:33,330 --> 00:46:35,460
providing them with the right context.

973
00:46:35,460 --> 00:46:39,900
Now if you look at the bottom
of the slide, you have the MCP

974
00:46:39,900 --> 00:46:41,850
on the left side you have the agents.

975
00:46:41,850 --> 00:46:46,850
So these agents could be
chatbots, autonomous workflows

976
00:46:47,070 --> 00:46:48,540
or your application.

977
00:46:48,540 --> 00:46:50,460
On the right you have data sources,

978
00:46:50,460 --> 00:46:52,920
which could be your
APIs, internal systems,

979
00:46:52,920 --> 00:46:54,330
databases, et cetera.

980
00:46:54,330 --> 00:46:58,230
So MCP sits right in the
middle. So it's access a glue.

981
00:46:58,230 --> 00:47:00,480
So instead of an agent integrating

982
00:47:00,480 --> 00:47:03,450
with every system in its own custom way.

983
00:47:03,450 --> 00:47:06,540
MCP gives you a common
consistent way to describe

984
00:47:06,540 --> 00:47:08,520
and tools and share data.

985
00:47:08,520 --> 00:47:11,718
So this means that the
agents become more portable,

986
00:47:11,718 --> 00:47:13,920
integrations are usable,

987
00:47:13,920 --> 00:47:15,270
and then you don't have to,

988
00:47:16,470 --> 00:47:18,780
you can avoid the one-off
plumping that every time

989
00:47:18,780 --> 00:47:23,250
that you have to do when a new
agent talks to a new source

990
00:47:23,250 --> 00:47:25,083
or you want a new capability.

991
00:47:25,950 --> 00:47:29,290
Now AWS has

992
00:47:30,187 --> 00:47:31,980
a GitHub rapport where we have

993
00:47:31,980 --> 00:47:34,830
provided a lot of reusable MCP servers.

994
00:47:34,830 --> 00:47:38,490
So one of the MCP server
that we will be using here is

995
00:47:38,490 --> 00:47:42,540
the AWS architecture diagram, MCP server.

996
00:47:42,540 --> 00:47:44,400
It's a Python package

997
00:47:44,400 --> 00:47:47,280
and it helps you to design
architecture diagrams,

998
00:47:47,280 --> 00:47:50,370
flow diagrams, sequence
diagrams, et cetera.

999
00:47:50,370 --> 00:47:52,230
So we'll be calling that MCP server.

1000
00:47:52,230 --> 00:47:54,990
So the next step is basically
for you to go into Kiro

1001
00:47:54,990 --> 00:47:57,210
and configure the MCP server.

1002
00:47:57,210 --> 00:47:58,500
It's a very simple step.

1003
00:47:58,500 --> 00:48:01,920
You go to GitHub, you get the MCP server,

1004
00:48:01,920 --> 00:48:03,960
the instructions that you need to follow

1005
00:48:03,960 --> 00:48:07,230
to add the MCP server into your
ID is mentioned over there.

1006
00:48:07,230 --> 00:48:09,750
So once you've configured that,
so I have already done it,

1007
00:48:09,750 --> 00:48:11,190
now I'm asking Kiro

1008
00:48:11,190 --> 00:48:13,830
to generate an architecture
diagram for me.

1009
00:48:13,830 --> 00:48:16,680
So again, by default it
creates a PNG diagram

1010
00:48:16,680 --> 00:48:18,000
or a JPEG diagram, right?

1011
00:48:18,000 --> 00:48:20,370
But I want something
that, I want to iterate,

1012
00:48:20,370 --> 00:48:21,480
I want to modify.

1013
00:48:21,480 --> 00:48:25,110
So I use a tool called
draw.io very frequently.

1014
00:48:25,110 --> 00:48:27,390
So what I'm telling Kiro is to generate

1015
00:48:27,390 --> 00:48:30,810
that architecture diagram
in a draw.io XML format.

1016
00:48:30,810 --> 00:48:32,790
So then it would be easier for me

1017
00:48:32,790 --> 00:48:34,563
to start iterating from here.

1018
00:48:35,400 --> 00:48:37,890
So let's go ahead and play the demo.

1019
00:48:37,890 --> 00:48:42,270
So I'm going to ask Kiro, use
the AWS diagram MCP server

1020
00:48:42,270 --> 00:48:45,780
to create a draw.io XML diagram
showing AWS microservices

1021
00:48:45,780 --> 00:48:48,090
architecture based on the bonded context

1022
00:48:48,090 --> 00:48:52,680
that has been identified
from the previous session.

1023
00:48:52,680 --> 00:48:55,170
So it's gonna call the MCP server.

1024
00:48:55,170 --> 00:48:58,350
You can see that it has called
the MCP tool, Get_diagram

1025
00:48:58,350 --> 00:49:00,630
and then it's gonna generate
the architecture diagram

1026
00:49:00,630 --> 00:49:01,830
for me.

1027
00:49:01,830 --> 00:49:05,070
So it has actually
generated a PNG diagram.

1028
00:49:05,070 --> 00:49:08,670
Since I have asked for a
draw.io, it's actually going

1029
00:49:08,670 --> 00:49:11,130
to recreate that file in draw.io.

1030
00:49:11,130 --> 00:49:14,490
So also if we have noticed
on the left hand side,

1031
00:49:14,490 --> 00:49:17,130
it has created that
particular file, right?

1032
00:49:17,130 --> 00:49:19,590
It has created the architecture diagram,

1033
00:49:19,590 --> 00:49:21,930
data flow patterns all
are defined over there.

1034
00:49:21,930 --> 00:49:23,700
So I have opened my draw.io.

1035
00:49:23,700 --> 00:49:26,350
So I'm going to open the
diagram that it has created.

1036
00:49:27,210 --> 00:49:30,360
Yeah, see this is created
by the MCP server directly.

1037
00:49:30,360 --> 00:49:33,400
So earlier this used to
take days for an admin

1038
00:49:34,720 --> 00:49:36,090
to be both a platform architect

1039
00:49:36,090 --> 00:49:37,530
or application owner to create it.

1040
00:49:37,530 --> 00:49:41,370
Now it has already been
done through the MCP server.

1041
00:49:41,370 --> 00:49:44,790
Now this, you can see that
it's actually organized

1042
00:49:44,790 --> 00:49:46,080
based on different domains.

1043
00:49:46,080 --> 00:49:49,020
So you have user management
domain, product catalog domain,

1044
00:49:49,020 --> 00:49:52,080
how the different data
flows works each other.

1045
00:49:52,080 --> 00:49:55,680
Again, there is Lambda
mentioned over there,

1046
00:49:55,680 --> 00:49:58,470
but it is easily replaceable
since it's microservice.

1047
00:49:58,470 --> 00:50:00,930
You can either replace it
with an ECS or any case

1048
00:50:00,930 --> 00:50:03,000
or a container solution.

1049
00:50:03,000 --> 00:50:05,970
It has also identified
the external services

1050
00:50:05,970 --> 00:50:09,940
where notifications like ECS,
third party APIs, it needs

1051
00:50:09,940 --> 00:50:13,830
to call the monitoring
and the logging capability

1052
00:50:13,830 --> 00:50:16,800
as well in the architecture diagram.

1053
00:50:16,800 --> 00:50:20,850
So this is a raw diagram that
has been created by Kiro.

1054
00:50:20,850 --> 00:50:23,913
Now again, you can iterate it
based on your requirements.

1055
00:50:25,230 --> 00:50:28,422
Okay, so next step, the
seventh that we have seen

1056
00:50:28,422 --> 00:50:30,810
next step is to actually decompose

1057
00:50:30,810 --> 00:50:34,080
and refactor this entire application into

1058
00:50:34,080 --> 00:50:35,700
microservices with Kiro.

1059
00:50:35,700 --> 00:50:38,010
Now going to ask Kiro

1060
00:50:38,010 --> 00:50:40,470
to actually break down
this monolith code into

1061
00:50:40,470 --> 00:50:41,849
different microservices.

1062
00:50:41,849 --> 00:50:44,610
So I'm gonna prompt Kiro now.

1063
00:50:44,610 --> 00:50:46,530
So I'm going to ask it to analyze

1064
00:50:46,530 --> 00:50:49,230
and decompose it to microservices.

1065
00:50:49,230 --> 00:50:52,350
I'm also asking it to generate web APIs,

1066
00:50:52,350 --> 00:50:55,290
entity framework, models,
database, data components,

1067
00:50:55,290 --> 00:50:56,850
everything separately.

1068
00:50:56,850 --> 00:51:00,630
So it has done the analysis,

1069
00:51:00,630 --> 00:51:04,590
it has completed the extraction
of the microservices.

1070
00:51:04,590 --> 00:51:06,120
So you can see that it has created

1071
00:51:06,120 --> 00:51:07,980
a comprehensive project structure.

1072
00:51:07,980 --> 00:51:12,194
So independent service
folders, shared artifacts,

1073
00:51:12,194 --> 00:51:15,960
Kubernetes manifest, and
deployment files, right?

1074
00:51:15,960 --> 00:51:20,960
So you can we'll explore the
folders, the service folders

1075
00:51:22,230 --> 00:51:24,993
and shared artifact on the left hand side.

1076
00:51:26,820 --> 00:51:28,560
So you can see that I know
the project structure.

1077
00:51:28,560 --> 00:51:33,300
So the services are organized
as catalog, cart, order, user.

1078
00:51:33,300 --> 00:51:36,510
And if we explore the folder structure

1079
00:51:36,510 --> 00:51:37,470
on the left hand side,

1080
00:51:37,470 --> 00:51:39,758
you can see the services, the cart.

1081
00:51:39,758 --> 00:51:44,190
So it can also identify the
service contracts between APIs.

1082
00:51:44,190 --> 00:51:47,310
It can identify data ownership
issues between services.

1083
00:51:47,310 --> 00:51:51,240
It can identify shared code
which it needs to extract

1084
00:51:51,240 --> 00:51:52,770
as common libraries.

1085
00:51:52,770 --> 00:51:54,360
So it'll identify all those.

1086
00:51:54,360 --> 00:51:57,510
So you can see that earlier
you saw the project files

1087
00:51:57,510 --> 00:52:00,210
actually organized under one folder.

1088
00:52:00,210 --> 00:52:02,880
If you remember the first
slide that we showed, right?

1089
00:52:02,880 --> 00:52:05,610
Now you can see that
it has been organized.

1090
00:52:05,610 --> 00:52:07,860
The project files has been organized into

1091
00:52:07,860 --> 00:52:10,200
different folder structure.

1092
00:52:10,200 --> 00:52:14,640
So I'm just running through
each of those folders

1093
00:52:14,640 --> 00:52:16,710
to make sure that all the files are here.

1094
00:52:16,710 --> 00:52:19,330
Again, it has created the
deployment files as well.

1095
00:52:19,330 --> 00:52:22,710
So depending on the
platform that you're asking.

1096
00:52:22,710 --> 00:52:25,410
So in this prompt that I gave, I asked it

1097
00:52:25,410 --> 00:52:28,856
to create a deployment file for Kubernetes

1098
00:52:28,856 --> 00:52:30,000
or EKS deployment.

1099
00:52:30,000 --> 00:52:32,760
So it has created me a
cloud formation template,

1100
00:52:32,760 --> 00:52:35,850
which I can then use to
deploy the infrastructure

1101
00:52:35,850 --> 00:52:40,293
and the application components
for that application.

1102
00:52:42,240 --> 00:52:44,220
Alright? Okay.

1103
00:52:44,220 --> 00:52:47,850
So let me invite Anand also to summarize

1104
00:52:47,850 --> 00:52:49,260
the modernization flow.

1105
00:52:49,260 --> 00:52:50,790
- Hey thanks, Sree.

1106
00:52:50,790 --> 00:52:53,070
So finally what we have achieved, right?

1107
00:52:53,070 --> 00:52:56,460
We started with the legacy
monolithic application

1108
00:52:56,460 --> 00:52:59,340
and we have run through
the seven step process

1109
00:52:59,340 --> 00:53:02,640
to modernize this Unicorn
store application.

1110
00:53:02,640 --> 00:53:06,540
So first we did the code
analysis leveraging the Kiro,

1111
00:53:06,540 --> 00:53:10,260
then we transformed the
from .net older framework

1112
00:53:10,260 --> 00:53:13,050
to .net eight for our
existing application using

1113
00:53:13,050 --> 00:53:14,160
AWS transform.

1114
00:53:14,160 --> 00:53:18,150
And then what we did, we
actually did the event storming

1115
00:53:18,150 --> 00:53:22,290
and domain driven analysis for
a given application, right?

1116
00:53:22,290 --> 00:53:25,793
And then we generated
a different event board

1117
00:53:25,793 --> 00:53:28,350
to represent a different bounded contest

1118
00:53:28,350 --> 00:53:32,400
we could arrive to with
the right granularity,

1119
00:53:32,400 --> 00:53:37,210
which then finally converge
into the right microservices

1120
00:53:37,210 --> 00:53:38,460
or the right services.

1121
00:53:38,460 --> 00:53:40,830
And then from there,
and this, we did it all

1122
00:53:40,830 --> 00:53:43,950
through the Kiro and we
leverage MCP integration of Kiro

1123
00:53:43,950 --> 00:53:46,530
to then generate the architectural diagram

1124
00:53:46,530 --> 00:53:48,330
for these new microservices.

1125
00:53:48,330 --> 00:53:52,350
And then we finally decompose

1126
00:53:52,350 --> 00:53:54,420
our legacy monolithic application

1127
00:53:54,420 --> 00:53:56,340
and refactor that into the more modern

1128
00:53:56,340 --> 00:53:58,710
microservices-based
architecture, again using Kiro.

1129
00:53:58,710 --> 00:54:01,650
So the end-to-end journey of modernization

1130
00:54:01,650 --> 00:54:05,220
has been accelerated using
our genAI-based capabilities

1131
00:54:05,220 --> 00:54:07,260
along with the different
architectural methodologies

1132
00:54:07,260 --> 00:54:08,520
and the practices, right?

1133
00:54:08,520 --> 00:54:10,980
So what are some of the key takeaways?

1134
00:54:10,980 --> 00:54:13,350
One of the key takeaways
definitely leveraging

1135
00:54:13,350 --> 00:54:16,050
the domain domain design
and the event storming

1136
00:54:16,050 --> 00:54:18,240
based approach to do a right analysis

1137
00:54:18,240 --> 00:54:21,060
of your domain and then get
the right shared understanding

1138
00:54:21,060 --> 00:54:23,370
between the application
owner and the business owners

1139
00:54:23,370 --> 00:54:26,670
to define the right boundaries
and the granularities,

1140
00:54:26,670 --> 00:54:28,740
to decompose the legacy applications.

1141
00:54:28,740 --> 00:54:33,740
Sorry, the second is on
leveraging AI based capabilities

1142
00:54:34,740 --> 00:54:37,140
like AWS transforming Kiro

1143
00:54:37,140 --> 00:54:39,150
to accelerate your modernization

1144
00:54:39,150 --> 00:54:43,435
and which can significantly
reduce your overall effort,

1145
00:54:43,435 --> 00:54:45,720
time, and the cost to modernize

1146
00:54:45,720 --> 00:54:47,280
your legacy application stack, right?

1147
00:54:47,280 --> 00:54:49,620
And you can drive the innovation faster.

1148
00:54:49,620 --> 00:54:52,926
So that's all, folks, thank you very much

1149
00:54:52,926 --> 00:54:54,855
for joining our session.

1150
00:54:54,855 --> 00:54:58,020
And if you have any queries,
me and Sree are down there

1151
00:54:58,020 --> 00:55:00,570
and we can take your
queries if you have any.

1152
00:55:00,570 --> 00:55:01,403
Thank you.

1153
00:55:01,403 --> 00:55:02,993
- [Sree] Thank you. Thanks, everyone.

