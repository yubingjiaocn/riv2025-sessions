# AWS re:Invent 2025 技术会议总结

## 会议概述

本次会议由 AWS 解决方案架构师 Mangju 主持,Netflix 的数据科学家 Chris 和高级数据工程师 Tushar 主讲,主题聚焦于如何将产品实验与 AWS 云成本关联起来。

Netflix 作为全球领先的流媒体平台,在 2025 年上半年就产生了超过 950 亿小时的内容观看量。为了持续优化用户体验,Netflix 大量使用 AB 测试来验证产品创新。然而,每个实验都会在 AWS 基础设施上产生成本影响。传统上,产品团队关注的是功能级别的实验效果,而成本报告通常在服务或应用级别,这种粒度不匹配导致了成本归因难题。

Netflix 开发了一个名为"Cost-Aware Decision Making"的框架,通过分布式追踪技术和机器学习模型,能够实时监控实验对基础设施的影响,并将其转换为可预测的业务成本。这使得产品团队在决策时不仅能看到用户参与度等传统指标,还能直接看到如果将实验推广到全部用户所需的成本。这种方法让 Netflix 从被动应对月度账单异常,转变为主动进行数据驱动的成本效率决策,在保持创新速度的同时实现运营效率。

## 详细时间线

### 开场与背景介绍 (00:00 - 05:30)

00:00 - Mangju 欢迎参会者,介绍 re:Invent 2025 会议

00:30 - 以 Netflix 用户体验为例:周五晚上浏览 Netflix,通过 AB 测试优化推荐算法和缩略图

01:45 - 强调实验不仅关乎用户参与度,每个实验在 AWS 上都有基础设施成本

02:15 - 介绍 Netflix 2025 年上半年的规模:950 亿小时内容观看量

02:45 - Netflix 将产品实验与云支出连接,将 AWS 账单视为实验指标

03:30 - Mangju 介绍演讲者:Chris 和 Tushar,来自 Netflix

04:00 - 会议目标:展示如何运行实验,既取悦用户又能在 AWS 账单中清晰可预测地体现

### Chris 介绍核心挑战 (05:30 - 15:00)

05:30 - Chris 提问:有多少人因恐惧而关闭过 AWS 账单?

06:00 - Chris 自我介绍:Netflix 数据科学家,12 年工作经验

06:30 - Netflix 产品演进:从 DVD 邮寄到流媒体,再到直播和游戏

07:15 - 核心问题:基础设施指标报告在服务级别,但创新在功能/实验级别

08:00 - 假设场景:"智能预取"功能实验,通过预加载内容提升应用响应速度

09:00 - 实验成功:用户参与度提升,决定全面推出

09:30 - 一两个月后:财务团队发现计算成本异常增长,工程团队发现中间层服务需求增加

10:30 - 问题:两个团队都不知道成本增加与新功能有关,因为缺乏数据且未参与实验开发

11:30 - 目标:防止隐藏成本和意外,让财务、实验负责人和服务团队提前获得数据做出更好决策

12:30 - 会议结构预告:核心挑战、框架深入、成果、经验教训、路线图、Q&A

13:30 - Netflix 的 AB 测试方法:同时运行数百甚至数千个实验

14:15 - 挑战:实验运行在共享基础设施上,请求分散到认证、推荐等各个系统

14:45 - 粒度归因问题:需要将任何实验的使用和成本归因到基础设施影响

### 框架介绍与归因方法 (15:00 - 30:00)

15:00 - 展示框架:Cost-Aware Decision Making,实时监控实验影响并转换为业务成本预测

15:45 - 模拟仪表板:实验结果显示流媒体改善,同时显示如果推广到 100% 用户的成本为 10 万美元

17:00 - 从被动决策(月度账单意外)转向主动决策(实验阶段就知道功能价格)

18:00 - Netflix 基础设施多样化:机器学习管道、内部工具、核心消费者产品

18:30 - 策略:从面向消费者的系统开始,因为这些系统根据用户行为动态自动扩展

19:00 - Tushar 接手,介绍框架细节

### Tushar 深入框架组件 (19:00 - 45:00)

19:00 - Tushar 自我介绍:Netflix 高级数据工程师

19:30 - 框架两大组件:归因(Attribution)和估算(Estimation)

20:30 - 归因:实验有治疗组(新功能)和对照组(默认体验),收集各层系统指标

21:30 - 归因目标:确定变化的根本原因,识别哪个功能导致基础设施指标变化

22:30 - 估算:使用机器学习和统计方法将技术变化转换为量化的业务影响

23:30 - 使用数据(Usage Data):在线请求响应应用中,指应用服务流量时完成的工作量

24:30 - 关注使用增量(Usage Delta):治疗组和对照组之间的差异,而非绝对值

25:00 - 使用指标包括:请求延迟、请求负载大小、请求量、错误率

26:00 - Netflix 大多数在线应用基于 CPU 扩展,请求延迟增加需要添加更多服务器

27:00 - 选择请求量作为主要指标,因为 CPU 与请求量成正比

28:00 - 核心问题:如何分别获取治疗组和对照组的请求量?

28:30 - 分布式追踪介绍:微服务架构中请求在应用间流动

29:30 - Trace(追踪):单个用户请求的完整路径,由多个 Span(跨度)组成

30:30 - Span:应用间单个请求,包含开始时间、延迟、标签(键值对)

### 分布式追踪与挑战 (30:00 - 40:00)

31:30 - Netflix 规模:数十亿请求流经数千个应用,每个请求代表用户操作

32:30 - 挑战:无法记录每个请求,必须依赖采样(0.05%-1% 的 Web 流量)

33:30 - 不同业务领域采样率不同,新兴领域如广告采样率更高

34:00 - 数据挑战:数据量激增(如《怪奇物语》发布或直播活动)、数据非结构化且不完整

35:00 - 即使低采样率,处理的数据量仍达数十亿行

35:30 - 统计严谨性和仔细分析至关重要

36:00 - 端到端归因流程:采样数据 + 匿名会员数据 + 应用元数据 → ETL 处理 → AB 测试使用数据

### 实际案例:智能预取实验 (37:00 - 42:00)

37:00 - 回顾智能预取实验:假设预取用户可能观看的内容可提升体验

37:45 - 治疗组:预取文本、图像、视频;对照组:按需加载

38:30 - 归因结果:治疗组对元数据服务的请求量增加 40%

39:30 - 强调:这不是猜测,而是数据驱动的结果,在大规模互联网络中隔离出主要影响

40:00 - 转向估算组件

### 估算流程 (40:00 - 48:00)

40:30 - 估算:将归因的显著信号转换为实际美元成本预测

41:00 - 智能预取案例:40% 请求量增加需转换为推广到全球用户的实际成本

41:45 - 三步估算流程:

42:00 - 第一步:从生产环境学习,基于历史数据训练机器学习模型,学习使用模式与成本关系

43:00 - 图表展示:AWS 每小时成本随元数据服务请求量增加而增长

43:45 - 第二步:模拟,生成两个平行宇宙

44:15 - 场景一:基于原始历史使用的成本(基线,绿色线)

44:45 - 场景二:应用增加使用量后的成本(红色虚线)

45:15 - 两者差异即实验的增量成本(白色箭头)

46:00 - 第三步:聚合所有有统计显著变化的应用的成本差异

46:45 - 智能预取实验结果:如推广到所有用户,预计成本增加 75 万美元

47:30 - 最大成本增加来自元数据服务(与 40% 请求量增加一致)

### 框架应用与决策 (48:00 - 52:00)

48:00 - 框架首次让 Netflix 看到产品成功的真实成本

48:30 - 两种主要使用方式:

49:00 - 1. 作为保障措施:在基础设施支出异常激增成为问题前捕获和预防

49:30 - 通过仪表板或警报通知显著成本增加

50:00 - 2. 进行有意义的权衡讨论:直接比较新功能的用户收益与预计基础设施成本

50:45 - 在推广到全部用户前做出更明智的决策

51:15 - 目标不仅是降低 AWS 成本,而是做出更明智的数据驱动决策

51:45 - 平衡运营效率与创新速度

### 经验教训 (52:00 - 60:00)

52:00 - Chris 回归,分享三个关键经验教训

52:30 - 教训一:追踪完整性

53:00 - 归因是整个框架的核心,如果这里出错,其他一切都值得怀疑

53:30 - 假设:能够追踪用户请求在整个基础设施中的路径

54:00 - 问题:如果某个服务不传播追踪头,会产生盲点,无法看到部分基础设施支出

54:45 - 可能导致成本低报或影响低报

55:15 - 解决方案:与工程团队(特别是可观测性团队)密切合作,设置自动化数据审计和警报

56:00 - 建议:从高质量基础设施追踪/归因开始

56:30 - 教训二:基础设施不断演进

57:00 - Netflix 团队快速迭代,不断升级基础设施(EC2 实例类型、服务架构、定价变化)

57:45 - 不能只构建一个模型应用于所有服务,服务行为随时间变化

58:15 - 解决方案:实施机器学习模型的持续再训练,每天甚至每小时重新训练

59:00 - 实施稳健的回退机制:检测到漂移时回退到更简单的启发式成本模型

59:30 - 启发式模型虽不如 ML 模型精确,但方向和规模准确

60:00 - 教训三:并非所有服务扩展方式相同

### 服务扩展差异与总结 (60:00 - 结束)

60:30 - 虽然专注于面向消费者的自动扩展产品,但现实更复杂

61:00 - 某些在线应用是静态配置的,需求增加时成本不变

61:30 - 原因:可能扩展到高水位以吸收流量突发,或过度扩展效率不高

62:00 - 动态自动扩展工作负载有清晰的学习关系,静态情况几乎没有关系,成本恒定直到临界点

62:45 - 解决方案:构建逻辑根据不同扩展行为对服务分类(自动扩展、静态配置等)

63:15 - 框架使用分类信息应用适当的成本模型

63:45 - 会议结束,开放 Q&A 环节