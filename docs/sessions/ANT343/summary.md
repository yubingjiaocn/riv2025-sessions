# AWS re:Invent 2025 - AN343 会议总结

## 会议概述

本次会议主题为"在AWS上构建基于Apache Iceberg的湖仓架构最佳实践"。会议由AWS Glue数据目录和Lake Formation的高级工程经理Purvajan Naranaswami主持,Medidata的首席数据架构师Mike Arojo和AWS数据与AI领域的首席解决方案架构师Shrihan Sopirala共同参与。

会议深入探讨了Apache Iceberg如何解决传统数据湖面临的核心挑战,包括数据损坏、查询性能低下和模式演进困难等问题。通过智能元数据层、表级快照和优化的文件布局,Iceberg为现代湖仓架构提供了ACID保证、时间旅行、优雅的模式演进、高性能查询和高效的行级更新能力。会议还重点介绍了AWS的集成技术栈,特别是Glue数据目录作为Iceberg REST目录的核心作用,以及S3 Table Buckets提供的全托管存储优化功能。

Medidata分享了他们从传统批处理ETL架构向基于Iceberg的流式架构转型的实际案例,展示了如何通过Flink、Kafka和Iceberg的组合实现数据延迟从天级降至分钟级,同时大幅降低存储成本并提升数据完整性。会议强调了开放标准如何实现真正的互操作性,使得多种计算引擎可以无缝访问同一份Iceberg数据。

## 详细时间线

### 开场与背景介绍
[00:00 - 02:30] 会议开场,介绍演讲嘉宾和议程安排,包括数据湖危机、Apache Iceberg在湖仓中的演进、AWS技术栈、生产就绪架构模式、客户案例以及多计算引擎集成。

### 数据湖危机与Iceberg解决方案
[02:30 - 05:45] 阐述传统数据湖面临的问题:数据损坏常见、无法回滚到时间点快照、查询速度慢(扫描TB级数据回答MB级问题)、模式演进需要重写PB级数据。介绍Iceberg的智能元数据层架构,包括表级快照、清单列表、清单文件和文件级统计信息。

[05:45 - 08:20] 详细说明Iceberg的五大核心优势:
1. ACID保证 - 通过乐观并发控制支持多写入者
2. 时间旅行 - 每次更新创建隔离且不可变的快照
3. 模式演进 - 通过列ID跟踪实现元数据级更新
4. 查询性能 - 通过元数据扫描精确定位数据文件
5. 行级更新 - 支持等值删除和位置删除

### Iceberg V3新特性
[08:20 - 11:15] 介绍Iceberg V3的四大新功能:
- **Variant类型支持** - 原生支持JSON半结构化数据,保持列式存储优化
- **删除向量(Deletion Vectors)** - 使用位图跟踪删除行,在内存中高速操作
- **行级血缘(Row Lineage)** - 跟踪每行的注入时间戳、源标识符和CDC事务ID
- **默认值支持** - 为新增列指定默认值,避免历史数据回填

### AWS技术栈集成
[11:15 - 14:30] 展示AWS的完整生态系统:
- **数据源层** - 数据仓库、本地数据库、流式数据源
- **摄取层** - Glue、EMR(批处理)、Kafka、Kinesis、Firehose(流式)
- **存储层** - S3通用桶、S3 Tables(全托管Iceberg)、Redshift托管存储
- **目录层** - Glue数据目录(技术元存储)、Lake Formation(企业级治理)、SageMaker目录(业务指标和血缘)
- **计算层** - AWS原生计算和Iceberg兼容的第三方计算引擎
- **应用层** - Bedrock(GenAI)、QuickSight(BI)、SageMaker统一工作室

### Glue数据目录深度解析
[14:30 - 17:45] 详细介绍Glue数据目录的核心能力:
- 同时作为Hive元存储和Iceberg REST目录,支持V3所有特性
- 支持多目录联邦,连接外部Iceberg兼容目录
- Lake Formation提供细粒度访问控制(目录、数据库、表、列、行、单元格级别)
- 支持基于角色、标签和属性的访问控制
- 数据网格架构支持跨组织安全数据共享
- 凭证分发确保只有授权计算获得范围化访问
- 毫秒级查找,支持直接S3访问和清单缓存
- 智能代理可通过API发现表、检测模式漂移、自愈管道和优化分区策略

### S3 Table Buckets存储优化
[17:45 - 20:30] 介绍S3 Tables的全托管优化功能:
- **自动压缩** - 支持bin-pack、sort和z-order压缩策略
- **快照保留策略** - 基于时间旅行需求自动修剪快照
- **孤立文件清理** - 自动清理未被任何活动快照引用的文件
- 提供CloudTrail审计日志和指标监控(快照大小、压缩大小、快照数量、引用文件数)
- 相比传统方案提供3倍查询性能提升和10倍吞吐量提升

### 奖章架构(Medallion Architecture)
[20:30 - 24:00] 详细说明三层数据组织架构:

青铜层(Bronze) - 原始数据摄取
- 使用爬虫进行模式发现,Kinesis/Kafka流式摄取
- 存储选择:S3通用桶 + Iceberg格式
- Iceberg优势:模式演进、V3 Variant支持、时间旅行、ACID保证
- 建议:使用S3生命周期策略将90天后数据移至Glacier

白银层(Silver) - 数据清洗与转换
- 使用EMR、Spark、Glue进行转换
- 存储选择:S3通用桶或S3 Tables
- Iceberg优势:模式强制、分区演进(从日级到小时级)、增量更新、快照检查点

黄金层(Gold) - 分析就绪数据
- 使用SageMaker、Athena、Redshift进行查询分析
- 存储选择:S3 Tables(推荐)
- Iceberg优势:物化聚合、隐藏分区、sort/z-order优化
- 建议:配置快照保留策略优化元数据布局

### 核心摄取架构模式

[24:00 - 26:30] 模式1:批量ETL
- 用例:数据湖迁移、仓库加载、历史回填、监管报告
- 架构:RDS/本地数据库 → Serverless Spark → S3 Tables → Glue目录
- Iceberg优势:模式演进、分区演进、时间旅行、ACID保证、行级血缘(V3)
- 最佳实践:使用S3 Tables、调整bin-pack文件大小、基于数据特征选择分区策略(时间序列/地理位置)、启用sort/z-order

[26:30 - 29:00] 模式2:变更数据捕获(CDC)
- 用例:从操作数据库实时复制到分析系统
- 架构:Aurora/MySQL/RDS → DMS(捕获binlog/WAL) → Kinesis/Kafka → Flink/Spark → S3 Tables
- Iceberg优势:高效upsert、合并操作、快照隔离、自动压缩
- 策略:写时复制(Copy-on-Write)vs 读时合并(Merge-on-Read),CDC场景推荐Merge-on-Read
- 最佳实践:使用删除向量(写密集型)、以Parquet格式摄取、监控整个管道延迟

[29:00 - 31:30] 模式3:高并发流式摄取
- 用例:点击流分析、金融交易、游戏遥测、IoT应用
- 架构:多个Kinesis流 → Flink(实时聚合) + Spark(复杂转换) → 同一Iceberg表 → S3 Tables
- Iceberg优势:多写入者一致性(乐观并发)、读一致性、小文件处理、精确一次语义、增量处理
- 最佳实践:使用S3 Tables自动优化、监控提交冲突、命名空间隔离避免分区冲突、调整微批大小平衡延迟与文件数量

### Medidata客户案例

[31:30 - 34:00] 公司背景与用例
- Medidata是生命科学技术公司,拥有25年以上经验
- 新产品:Data Connect和Clinical Data Studio
- 目标:单一数据源集成、通过内部数据目录丰富语义、通过AI/ML加速数据审查和洞察
- 数据规模:数百万患者、数十亿数据点

[34:00 - 37:30] 传统架构的挑战
- 旧架构:多个ETL批处理作业、多个暂存层、多个下游存储点
- 问题:
  - 延迟以天为单位而非小时或分钟
  - 批处理作业时间不一致导致数据对齐困难
  - 错误机会增加,数据不一致
  - 扩展需要系统全面改造或数据迁移
  - 数据副本遍布各处,可观测性复杂

[37:30 - 40:00] 新架构解决方案
- 架构:Rave平台 + Data Connect → Kafka缓冲 → Flink(EKS) → Iceberg(Glue目录) → 多种消费者
- 关键设计:Flink每20分钟写入一次Iceberg表,控制快照大小,同时聚合数千个Flink管道的数据
- 互操作性:直接支持流式、批处理、仓库、API、BI工具、Arrow等开源项目、MCP工具

[40:00 - 43:30] 实施成果
1. 数据可用性 - 从批处理延迟降至流式延迟,数据视图一致,Glue压缩确保及时检索,快照提供时间点访问
2. 数据完整性 - 单一数据副本(一个Iceberg表),同时满足流式和批处理需求,数据丢失显著减少
3. 可扩展性 - 数据存储在S3而非Kafka,节省大量成本,EKS和MSK自带自动扩展支持
4. 可观测性 - 单一平面监控,Prometheus指标集中管理
5. 安全性 - Glue目录作为单一数据访问层,所有访问通过IAM角色,数据不离开VPC
6. 集成能力 - 支持Snowflake、Databricks等仓库解决方案,Iceberg REST API支持高级概念,大量开源技术开箱即用

[43:30 - 45:00] 未来规划
- 为AI代理提供实时数据访问,通过MCP工具访问湖仓
- 扩展客户数据共享解决方案,允许客户直接写回湖仓
- Metadata策划的SDK,包括R Studio SDK,通过Apache Arrow Flight服务器连接本地开发环境与湖仓

### 会议总结
[45:00 - 结束] 会议展示了从数据摄取(批处理、CDC、流式)到存储优化(S3 Tables)、目录管理(Glue)、多计算引擎集成的完整Iceberg湖仓最佳实践,并通过Medidata的真实案例验证了架构的有效性和商业价值。